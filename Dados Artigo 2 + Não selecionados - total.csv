Título;Resumo;Selecionado
Sustainability Design and Software: The Karlskrona Manifesto;Sustainability has emerged as a broad concern for society. Many engineering disciplines have been grappling with challenges in how we sustain technical, social and ecological systems. In the software engineering community, for example, maintainability has been a concern for a long time. But too often, these issues are treated in isolation from one another. Misperceptions among practitioners and research communities persist, rooted in a lack of coherent understanding of sustainability, and how it relates to software systems research and practice. This article presents a cross-disciplinary initiative to create a common ground and a point of reference for the global community of research and practice in software and sustainability, to be used for effectively communicating key issues, goals, values and principles of sustainability design for software-intensive systems.The centrepiece of this effort is the Karlskrona Manifesto for Sustainability Design, a vehicle for a much needed conversation about sustainability within and beyond the software community, and an articulation of the fundamental principles underpinning design choices that affect sustainability. We describe the motivation for developing this manifesto, including some considerations of the genre of the manifesto as well as the dynamics of its creation. We illustrate the collaborative reflective writing process and present the current edition of the manifesto itself. We assess immediate implications and applications of the articulated principles, compare these to current practice, and suggest future steps.;1
Digital with Purpose: Delivering a SMARTer 2030;"Digital technology can have ‘transformational’ effect on achieving the UN Sustainable Development Goals
Members must log-in to the GeSI Intranet to download the full report.

Without the proper development and deployment of digital technology, the world will fall short of achieving the 2030 Sustainable Development Goals (SDGs) created by the United Nations (UN) four years ago, according to a new report by the Global e-Sustainability Initiative (GeSI) and Deloitte. 

The report, Digital with Purpose: Delivering a SMARTer2030, identifies and quantifies how digital technologies can help governments, businesses, and philanthropic organizations accelerate their efforts to achieve each of the 17 SDGs. The report considers seven digital technologies which have been chosen as broadly representative of the way digital capability will evolve in the medium term and for their critical influence on the world. These technologies include: digital access, faster internet, cloud, the internet of things (IoT), cognitive, digital reality, and blockchain. Of the 169 SDG targets, 103 are directly influenced by these technologies.

According to the report, which draws on input from academics, NGOs and more than 500 use cases, these technologies, if deployed with positive societal impact in mind, will help accelerate progress toward the SDGs by 22 percent and mitigate downward trends by 23 percent on average. 

The report further finds that by 2030 digital technologies will deliver reductions in carbon emissions equivalent to nearly seven times the size of the growth in the total information and communications technology (ICT) sector emissions footprint over the same period.

“These technologies can pave the way for a number of beneficial activities,” says GeSI CEO Luis Neves. “They can help in connecting citizens around the world; supporting the monitoring and tracking of human impacts on the environment; optimizing inefficient and energy-intensive industrial processes; and augmenting actions people carry out in support of sustainability goals, among many others. That is why GeSI, its members and partners are committed to action in delivering by 2030 the identified societal benefits in this report.”

While the report argues that digital technologies both established and cutting edge can be leading contributors to positive societal value, this will only become a reality if the focus on technological development and deployment is framed by a clear commitment to the SDGs. The opportunity, both for the ICT sector and the sectors and organizations at the forefront of deployment, is enormous. 

Over $3 trillion is likely to be spent on research and development in the ICT sector in the ten years up to 2030, indicating huge potential for innovative solutions to the SDGs if effectively directed and as existing technologies mature.

We are proud to introduce this new report, #DigitalWithPurpose-Delivering a Smarter2030, which identifies and quantifies the ways in which digital technologies, both established and cutting-edge, are capable of delivering transformative impact against each of the 17 SDGs. It also clearly lays out where these technologies can have a negative impact.";1
Safety, Security, Now Sustainability: The Nonfunctional Requirement for the 21st Century;Many software systems today control large-scale sociotechnical systems. These systems aren't just entangled with the environment but also with our dwindling resources and mostly unsustainable way of living, while the planet's population continues to grow. Dealing with sustainability requirements and systematically supporting their elicitation, analysis, and realization is a problem that has yet to be solved. Decades ago, the discipline of software engineering dealt with similar shortcomings in its processes by including safety and security as new system qualities. In light of the increasing consequences of inadequately addressing sustainability in developing software systems, software engineers must apply the lessons learned from these prior research efforts and identify the necessary research agenda. Considering sustainability in software engineering means more than energy efficiency and green IT, which are concerned with the first-order impacts of software systems. Software engineers must also take into account the second- and third-order impacts in the system context, even if they're hard to assess. By doing so, engineers have the potential to considerably improve civilization's sustainability. The Web extra at http://youtu.be/VC07j6a1XUw is a video in which author Birgit Penzenstadler talks about how software engineers can considerably improve civilization's sustainability by taking into account not just the first-order impacts of software systems but also their second- and third-order impacts.;1
Framing sustainability as a property of software quality;The sustainability analysis framework enables software developers to specifically consider environmental and social dimensions relative to technical and economic dimensions. The framework helps draw a more comprehensive picture of the relevant quality dimensions and, as a result, improve decision making. Sustainability is achievable only when accounting for all dimensions. Connections among the four dimensions involve different dependencies and stakeholders. The framework aims to capture the relevant qualities that characterize sustainability concerns of software systems, helping identify how these qualities influence each other with respect to the different aspects of sustainability. Moreover, interdependent quality requirements may influence one another, as in association/association-class influences among sustainability quality requirements. Integrating our four-dimensional sustainability analysis framework into the engineering processes of long-lived industrial systems provides valuable support to managers and engineers trying to satisfy not only economic and technical but also environmental and social sustainability requirements. The influences among the sustainability quality requirements must be determined by developers and/or stakeholders, as the framework can provide only the means for linking them but not the analysis itself. Constraints and parameters must be chosen by the developers, as it is not possible to list them in a way that is generic enough to be applicable in all circumstances and at the same time specific enough to be useful.;1
The GREENSOFT Model: A reference model for green and sustainable software and its engineering;The resource and power consumption of ICT is still increasing, but also the benefits of ICT, e.g. in finding more efficient solutions for environmental problems. To date, it is not clear, whether the resource and energy savings through ICT overbalance the resource and energy consumption by ICT, or not. Up to now, manifold efforts of Green IT address the environmental aspects of sustainability considering computer hardware. However, there is still a lack of models, descriptions or realizations in the area of computer software and software process models. In our contribution, we first propose definitions of the terms “Green and Sustainable Software” and “Green and Sustainable Software Engineering”, then we outline a conceptual reference model, the GREENSOFT Model. This model includes a cradle-to-grave product life cycle model for software products, sustainability metrics and criteria for software, software engineering extensions for sustainably sound software design and development, as well as appropriate guidance.;1
A green model for sustainable software engineering;Information Communication Technology (ICT) has a strong impact on sustainable development due its rising demands for energy and resources needed when building hardware and software products. Most of the efforts spent on Green ICT/IT have been dedicated to addressing the effects of hardware on the environment but little have been considering the effects of building software products as well. Efficient software will indirectly consume less energy by using up less hardware equipment to run. Our contributions in this paper are devoted to building a two level green software model that covers the sustainable life cycle of a software product and the software tools promoting green and environmentally sustainable software. In the first level we propose a new green software engineering process that is a hybrid process between sequential, iterative, and agile development processes to produce an environmentally sustainable one. Each stage of the software process is then further studied to produce a green and sustainable stage. We propose either green guidelines or green processes for each software stage in the engineering process. We add to the software life cycle the requirements stage and the testing stage. We also include in the first level a complete list of metrics to measure the greenness of each stage in terms of the first order effects of ICT on the environment for a green software engineering process. No effort has been placed before in designing a green software engineering process. The second level explains how software itself can be used as a tool to aid in green computing by monitoring resources in an energy efficient manner. Finally, we show and explain relationships that can be found between the two levels in our proposed model to make the software engineering process and product green and sustainable.;1
Impacts of software and its engineering on the carbon footprint of ICT;The energy consumption of information and communication technology (ICT) is still increasing. Even though several solutions regarding the hardware side of Green IT exist, the software contribution to Green IT is not well investigated. The carbon footprint is one way to rate the environmental impacts of ICT. In order to get an impression of the induced CO2 emissions of software, we will present a calculation method for the carbon footprint of a software product over its life cycle. We also offer an approach on how to integrate some aspects of carbon footprint calculation into software development processes and discuss impacts and tools regarding this calculation method. We thus show the relevance of energy measurements and the attention to impacts on the carbon footprint by software within Green Software Engineering.;1
Green Software Engineering: The Curse of Methodology;Computer Science often seems distant from itsnatural science cousins, especially software engineering whichfeels closer to sociology and psychology than to physics. Physicalmeasurements are often rare in software engineering, except in afew niches. One such important niche is that of software energyconsumption, green mining, green IT, and sustainable computing, which all fall under the umbrella of green software engineering. With the physical measurement of energy consumption comesall of the limitations of measurement and experimentation thatexist in the natural sciences and engineering. Issues abound, fromattribution of energy use, isolation of components, to replicableexperiments. These get further complicated by cloud computingwhereby systems are virtualized and attribution of resource usageis a serious issue. Thus in this work we discuss the current state of softwareenergy consumption, and where will it go.;1
Sustainability in software engineering: A systematic literature review;Background: Supporting sustainability in software engineering is becoming an active area of research. We want to contribute the first Systematic Literature Review(SLR) in this field to aid researchers who are motivated to contribute to that topic by providing a body of knowledge as starting point, because we know from own experience, this search can be tedious and time consuming. Aim: We aim to provide an overview of different aspects of sustainability in software engineering research with regard to research activity, investigated topics, identified limitations, proposed approaches, used methods, available studies, and considered domains. Method: The applied method is a SLR in five reliable and commonly-used databases according to the (quasi-standard) protocol by Kitchenham et al. [1]. We assessed the 100 first results of each database ordered by relevance with respect to the search query. Results: Of 500 classified publications, we regard 96 as relevant for our research questions. We sketch a taxonomy of their topics and domains, and provide lists of used methods and proposed approaches. Most of the excluded publications were ruled out because of an unfitting usage of terms within the search query. Conclusions: Currently, there is little research coverage on the different aspects of sustainability in software engineering while other disciplines are already more active. Future work includes extending the study by reviewing a higher number of publications, including dedicated journal and workshop searches, and snowballing.;1
Interactions between environmental sustainability goals and software product quality: A mapping study;"Context
Sustainability is considered as either a quality requirement or a quality characteristic that should be included in software when environmental protection concerns are being taken into account. However, addressing sustainability in software projects might have an impact on the quality of the software product delivered. Conflicting goals between sustainability and particular software product characteristics should be studied when developing application software, since achieving users’ requirements can be a hindrance in the quest to meet sustainability goals.
Objective
This paper aims to provide an overview of the approaches found in the literature for dealing with interactions between software product quality and sustainability in the context of application software.
Method
A systematic mapping study is conducted to identify practices for managing interactions between software quality characteristics and sustainability. The selected papers are classified according to the quality characteristic considered and their influence on sustainability.
Results
Most of the 66 selected papers focused on validating current technologies concerning their support for sustainability (46%%). The interaction between performance efficiency and energy efficiency is what is reported most and there is a fairly positive interaction. In addition, reliability and usability point to a positive interaction with energy efficiency, while security shows a conflicting interaction with energy efficiency. Functional suitability and maintainability can present both positive and negative interaction, with different goals derived from environmental sustainability.
Conclusions
Interactions between software quality and sustainability have been addressed within an explorative approach. There is a need for additional research work to characterize the impact of interaction on both software quality and sustainability. Furthermore, proposals should be validated in industrial settings.";1
Sustainability in software engineering;The intersection between software engineering research and the problems related to sustainability and green IT has been the subject of increasing attention. In spite of that, we observe that sustainability is still not clearly defined, or understood, in the field of software engineering. This lack of clarity leads to confusion about e.g. what is relevant to measure or the research implications over time or space. This paper provides an overview of how the research so far has defined sustainability, and how this definition has been used to guide which research areas. To this end, we carried out a systematic mapping study for selecting, classifying and analyzing relevant publications. In this study, we investigate which knowledge areas and which time scope of sustainability effects are mostly targeted in scientific research. Our analysis shows research trends and discusses gaps to be filled.;1
5Ws of green and sustainable software;"Green and Sustainable Software has emerged as a new and highly active area in the software community. After several years of research and work, we believe that it is now necessary to obtain a general snapshot of how the research in this area is evolving. To do so, we have applied the 5Ws (why, when, who, where, and what), a formula for getting the complete story on a subject. We have therefore carried out a study, using 542 publications related to Green and Sustainable Software research; these were recovered using SCOPUS. The results obtained allow us to conclude that it is important to identify key elements of the research to allow researchers be fully aware of the state of the research on Green and Sustainable Software (why); the study uses papers published between 2000 and the beginning of November 2018 (when); the most prolific authors are mainly from Europe, although the USA is the most active country, Green and Sustainable Software being a very interactive area with a good number of multinational publications (who); the top five keywords related to sustainable aspects are Green Software, Green IT, Software Sustainability, Energy Consumption, and Energy Efficiency (what); finally, as regards the places authors prefer to publish in, there is almost a complete balance between conferences and journals, with a trend towards an increase in the number of publications (where).";1
Puzzling out Software Sustainability;Software Sustainability is gaining importance and, as occurs with any other new discipline, there are still many misconceptions and misunderstandings surrounding it. In this paper we attempt to clarify the different aspects of software sustainability, from organizational sustainability to software sustainability, exploring the latter in great depth by considering its three dimensions. We also present an overview of the research that has been developed around software sustainability, which was obtained after reviewing the best known workshops and conferences on green and sustainable software and some journals. The results obtained principally address the environmental dimension, and specifically green software design, quality and requirements.;1
Editorial: Reality check for software engineering for sustainability—pragmatism required;"Welcome to this special issue on software engineering for sustainability. Note that software engineering for sustainability has a different emphasis than sustainability in software engineering. Naturally, the latter has a mainly technical focus. The first goes beyond it by looking at the purpose and wider context of a software system, for example, in how it can support social and environmental concerns that help humanity move towards a more sustainable lifestyle and help sustaining our planet and societies. This special issue takes this broad perspective.

Before introducing the articles in this special issue, the following takes a look at why sustainability matters and why software engineering for sustainability has a large potential for impact.

The general importance of sustainability as an objective for developing our future has become apparent via the Millennium Development Goals that were targeting 2015. 1 “At the Millennium Summit in September 2000” the largest gathering of world leaders in history adopted the UN Millennium Declaration, committing their nations to a new global partnership to reduce extreme poverty and setting out a series of time-bound and quantified targets, with a deadline of 2015, that have become known as the Millennium Development Goals (MDGs).” 1 They address extreme poverty in its many dimensions—income poverty, hunger, disease, lack of adequate shelter, and exclusion—while promoting gender equality, education, and environmental sustainability. They also include basic human rights—health, education, shelter, and security. The world has made significant progress in achieving many of the goals, for example, between 1990 and 2002, average overall incomes rose by approximately 21%. The number of people in extreme poverty decreased by an estimated 130 million. Child mortality rates went down from 103 deaths per 1000 live births a year to 88. Life expectancy increased from 63 years to nearly 65 years. An additional 8% of the developing world's people now have access to water. And an additional 15% have access to improved sanitation services. 1 However, there still remains a lot to be done.

The follow-up on the MDGs were the Sustainable Development Goals. 2 The Sustainable Development Goals (SDGs), also known as the Global Goals, are a “call to action to end poverty, protect the planet, and ensure that all people enjoy peace and prosperity.” 2 These 17 goals build on the successes of the MDGs, while including new priority areas such as climate change, economic inequality, innovation, sustainable consumption, peace and justice. The goals are interconnected: often the key to success on one will involve tackling issues more commonly associated with another. The SDGs provide guidelines and targets for all countries to adopt in accordance with their own priorities and the environmental challenges of the world at large. The SDGs are an inclusive agenda. They tackle the root causes of poverty and aim to unite all people to make a positive change for both people and planet. 2

Not limited to humanitarian and environmental causes, also business and economics recognize sustainability as a major objective. The newest edition of the UN Global Compact–Accenture Strategy CEO Study represents more than a decade of research on sustainable business. 5 Published every 3 years, it is the largest study of CEO attitudes to sustainability globally. The study traces the development of corporate motivations in engaging with environmental, social, and governance issues in core business. In this edition, over 1000 CEOs from 100+ countries and 25+ industries were interviewed. While in 2013, frustrated ambition was prevalent; now, there is optimism as CEOs see a mandate to solve societal challenges as a core element to gain competitive advantage. The backdrop to this edition of the study was the adoption of the United Nations 2030 Agenda for Sustainable Development and the SDGs. Results suggest that business leaders are committed to sustainability, forging a stronger global environment for business. “The majority of CEOs surveyed (87%) believe the SDGs provide an opportunity to rethink approaches to sustainable value creation—and 78% already see opportunities to contribute through core business.” 6 According to nearly half of all CEOs surveyed (49%), business will be the single most important actor in delivering the SDGs. Their major conclusion was that the private sector now has a window of opportunity to reshape the way we live and work. 6 Given the pervasive role of information and communication technology (ICT) and software solutions in all aspects of our society, it is obvious that researchers, practitioners, and decision makers in any sector need to change their mindset and include sustainability concerns by default.

More on the technical side, the Smarter 2020 and Smarter 2030 reports by the Global e-Sustainability Initiative (GeSI) presented what the future could look like by making the best of technological opportunities. GeSI's SMARTer2020 report 3 demonstrates how the increased use of ICT such as video conferencing and smart-building management could cut the projected 2020 global greenhouse gas (GHG) emissions by 16.5%, amounting to $1.9 trillion in gross energy and fuel savings and a reduction of 9.1 gigatons carbon dioxide equivalent of greenhouse gases. This is equivalent to more than seven times the ICT sector's emissions in the same period. 3 Here, ICT can work as an enabler—if we have software engineers who know how to design for sustainability. In this special issue, we have, for example, contributions on design patterns and mobile cloud apps that support energy efficiency. In the Smarter 2030 report, policy makers, businesses, and consumers were called to action. By 2030, ICT will provide benefits across the triple bottom line, from reducing CO2 emissions and resource use, to generating additional revenues, cost savings, and wider societal benefits. The report includes scenarios like “a doctor in your pocket,” “education on your terms,” “decarbonizing the energy sector,” “the future of buildings,” “feeding a growing world,” “mobile and connected reaching your destination,” “smarter customers, smarter services,” and the Internet of Things. 4 Each of those is fundamentally realized and implemented by software systems, and again, we need software engineers capable of designing these systems with individual, social, economic, technical, and environmental sustainability in mind. Furthermore, each of these topics also depends on highly interdisciplinary collaborarion. For example, the “doctor in your pocket” requires both medical expertise, user experience design, and software engineering. Each discipline has to start building its half of the bridges towards the others.

From the humanitarian perspective of MDGs and SDGs to the business perspective of the UN Global Compact study to the Smarter 2020 and 2030 future scenarios, all of the solutions involve large amounts of software systems and services. This is where software engineering comes into play as a critical facilitator. In more concrete terms, if we manage to support sustainability in business strategies, translate the related objectives into requirements, and then manage to design and implement them into the software, we can facilitate a huge potential positive impact on our lifestyle and the planet.

In our opinion, the maturity of the field is still developing. In distinct research community pockets, we have advanced specific topics quite well. Now is the time to bring those research pockets together and integrate them into the bigger picture. This is what this special issue is about.";1
Software sustainability: Research and practice from a software architecture viewpoint;"Modern societies are highly dependent on complex, large-scale, software-intensive systems that increasingly operate within an environment of continuous availability, which is challenging to maintain and evolve in response to the inevitable changes in stakeholder goals and requirements of the system. Software architectures are the foundation of any software system and provide a mechanism for reasoning about core software quality requirements. Their sustainability – the capacity to endure in changing environments – is a critical concern for software architecture research and practice.
Problem
Accidental software complexity accrues both naturally and gradually over time as part of the overall software design and development process. From a software architecture perspective, this allows several issues to overlap including, but not limited to: the accumulation of technical debt design decisions of individual components and systems leading to coupling and cohesion issues; the application of tacit architectural knowledge resulting in unsystematic and undocumented design decisions; architectural knowledge vaporisation of design choices and the continued ability of the organization to understand the architecture of its systems; sustainability debt and the broader cumulative effects of flawed architectural design choices over time resulting in code smells, architectural brittleness, erosion, and drift, which ultimately lead to decay and software death. Sustainable software architectures are required to evolve over the entire lifecycle of the system from initial design inception to end-of-life to achieve efficient and effective maintenance and evolutionary change.
Method
This article outlines general principles and perspectives on sustainability with regards to software systems to provide a context and terminology for framing the discourse on software architectures and sustainability. Focusing on the capacity of software architectures and architectural design choices to endure over time, it highlights some of the recent research trends and approaches with regards to explicitly addressing sustainability in the context of software architectures.
Contribution
The principal aim of this article is to provide a foundation and roadmap of emerging research themes in the area of sustainable software architectures highlighting recent trends, and open issues and research challenges.";1
Sustainability evaluation of software architectures: a systematic review;Long-living software systems are sustainable if they can be cost-efficiently maintained and evolved over their entire life-cycle. The quality of software architectures determines sustainability to a large extent. Scenario-based software architecture evaluation methods can support sustainability analysis, but they are still reluctantly used in practice. They are also not integrated with architecture-level metrics when evaluating implemented systems, which limits their capabilities. Existing literature reviews for architecture evaluation focus on scenario-based methods, but do not provide a critical reflection of the applicability of such methods for sustainability evaluation. Our goal is to measure the sustainability of a software architecture both during early design using scenarios and during evolution using scenarios and metrics, which is highly relevant in practice. We thus provide a systematic literature review assessing scenario-based methods for sustainability support and categorize more than 40 architecture-level metrics according to several design principles. Our review identifies a need for further empirical research, for the integration of existing methods, and for the more efficient use of formal architectural models.;1
Two perspectives on reference architecture sustainability;"In the context of software architectures, sustainability has been investigated as an important quality property to assess how well these architectures support changes over time. Several initiatives to achieve sustainable software architectures/systems can be already found. In parallel, reference architectures have served as an effective support to facilitate and standardize the development and evolution of software systems, including in complex, critical application domains. By encompassing valuable knowledge of specific domains, the reference architectures survival is considered of utmost importance, however, the most of such architectures have not been updated since their first version. Furthermore, there is a lack of works investigating how a reference architectures, by itself, can become sustainable and/or can contribute to develop sustainable systems in a domain. The main contribution of this paper is to provide a first view about sustainability on reference architectures. Resulting from our expertise on reference architectures, we bring out the two perspectives on their sustainability: (i) sustainability IN reference architectures; and (ii) sustainability OF reference architectures. In particular, for the perspective OF, we analyzed 20 existing reference architectures to assess their sustainability, and we found most of them were not updated over time. Hence, we also provide an initial set of aspects that could contribute to address sustainability of those architectures.";1
Towards suitable description of reference architectures;Due to the increasing size and complexity of many current software systems, the architectural design of these systems has become a considerately complicated task. In this scenario, reference architectures have already proven to be very relevant to support the architectural design of systems in diverse critical application domains, such as health, avionics, transportation, and the automotive sector. However, these architectures are described in many different approaches, such as using textual description, informal models, and even modeling languages as UML. Hence, practitioners are faced with a difficult decision of the better approaches to describing reference architectures. The main contribution of this work is to depict a detailed panorama containing the state of the art (from the literature) and state of the practice (based on existing reference architectures) of approaches for describing reference architectures. For this, we firstly examined the existing approaches (e.g., processes, methods, models, and modeling languages) and compared them concerning completeness and applicability. We also examined four well-known, successful reference architectures (AUTOSAR, ARC-IT, IIRA, and AXMEDIS) in view of the approaches used to describe them. As a result, there exists a misalignment between the state of the art and state of the practice, requiring an engagement of the software architecture community, through research collaboration of academia and industry, to propose more suitable means to describe reference architectures and, as a consequence, promoting the sustainability of these architectures.;1
Architectural Technical Debt Identification: The Research Landscape;Architectural Technical Debt (ATD) regards sub-optimal design decisions that bring short-term benefits to the cost of long-term gradual deterioration of the quality of the architecture of a software system. The identification of ATD strongly in uences the technical and economic sustainability of software systems and is attracting growing interest in the scientific community. During the years several approaches for ATD identification have been conceived, each of them addressing ATD from di erent perspectives and with heterogeneous characteristics. In this paper we apply the systematic mapping study methodology for identifying, classifying, and evaluating the state of the art on ATD identification from the following three perspectives: publication trends, characteristics, and potential for industrial adoption. Speci cally, starting from a set of 509 potentially relevant studies, we systematically selected 47 primary studies and analyzed them according to a rigorously-de ned classification framework. The analysis of the obtained results supports both researchers and practitioners by providing (i) an assessment of current research trends and gaps in ATD identification, (ii) a solid foundation for understanding existing (and future) research on ATD identification, and (iii) a rigorous evaluation of its potential for industrial adoption.;1
Has social sustainability been addressed in software architectures?;Research on sustainability in software engineering has gained importance as a result of the need to create better software and therefore avoid compromising future generations opportunities, whether in the social, economic, technical or environmental dimension. Social dimension encompasses the direct support of the software systems in any domain, as well as activities or processes that create benefits for social communities, such as health, education, and transportation. Although social aspects have been previously examined within the broader context of software engineering, the software systems design based on the notion of social sustainability is still poorly understood and practiced. This paper outline relevant points surrounding social sustainability as a concern in software architectures design. In particular, we discuss some issues in designing software systems that generate social values and have a positive impact on communities. We hope that this discussion will help broaden the concept of social sustainability in architectural design decisions and to bring awareness to the particular needs of software systems that have a direct impact on human well-being and contribute to sustainable development.;1
Social Sustainability in the e-Health Domain via Personalized and Self-Adaptive Mobile Apps;Within software engineering, social sustainability is the dimension of sustainability that focuses on the “support of current and future generations to have the same or greater access to social resources by pursuing social equity.” An important domain that strives to achieve social sustainability is e-Health, and more recently e-Health mobile apps.A wealth of e-Health mobile apps is available for many purposes, such as lifestyle improvement and mental coaching. The interventions, prompts, and encouragements of e-Health apps sometimes take context into account (e.g., previous interactions or geographical location of the user), but they still tend to be rigid, e.g., apps use fixed sets of rules or they are not sufficiently tailored toward individuals’ needs. Personalization to the different users’ characteristics and run-time adaptation to their changing needs and context provide a great opportunity for getting users continuously engaged and active, eventually leading to better physical and mental conditions. This chapter presents a reference architecture for enabling AI-based personalization and self-adaptation of mobile apps for e-Health. The reference architecture makes use of a dedicated goal model and multiple MAPE loops operating at different levels of granularity and for different purposes. The proposed reference architecture is instantiated in the context of a fitness-based mobile application and exemplified through a series of typical usage scenarios extracted from our industrial collaborations.;1
Systematic Mapping Studies in Software Engineering;A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest. The analysis of results focuses on frequencies of publications for categories within the scheme. Thereby, the coverage of the research field can be determined. Different facets of the scheme can also be combined to answer more specific research questions. OBJECTIVE: We describe how to conduct a systematic mapping study in software engineering and provide guidelines. We also compare systematic maps and systematic reviews to clarify how to chose between them. This comparison leads to a set of guidelines for systematic maps. METHOD: We have defined a systematic mapping process and applied it to complete a systematic mapping study. Furthermore, we compare systematic maps with systematic reviews by systematically analyzing existing systematic reviews. RESULTS: We describe a process for software engineering systematic mapping studies and compare it to systematic reviews. Based on this, guidelines for doing systematic maps are defined. CONCLUSIONS: Systematic maps and reviews are different in terms of goals, breadth, validity issues and implications. Thus, they should be used complementarily and require different methods (e.g., for analysis).;1
Guidelines for conducting systematic mapping studies in software engineering;"ContextSystematic mapping studies are used to structure a research area, while systematic reviews are focused on gathering and synthesizing evidence. The most recent guidelines for systematic mapping are from 2008. Since that time, many suggestions have been made of how to improve systematic literature reviews (SLRs). There is a need to evaluate how researchers conduct the process of systematic mapping and identify how the guidelines should be updated based on the lessons learned from the existing systematic maps and SLR guidelines. ObjectiveTo identify how the systematic mapping process is conducted (including search, study selection, analysis and presentation of data, etc.); to identify improvement potentials in conducting the systematic mapping process and updating the guidelines accordingly. MethodWe conducted a systematic mapping study of systematic maps, considering some practices of systematic review guidelines as well (in particular in relation to defining the search and to conduct a quality assessment). ResultsIn a large number of studies multiple guidelines are used and combined, which leads to different ways in conducting mapping studies. The reason for combining guidelines was that they differed in the recommendations given. ConclusionThe most frequently followed guidelines are not sufficient alone. Hence, there was a need to provide an update of how to conduct systematic mapping studies. New guidelines have been proposed consolidating existing findings.";1
Systematic literature studies: Database searches vs. backward snowballing;Systematic studies of the literature can be done in different ways. In particular, different guidelines propose different first steps in their recommendations, e.g. start with search strings in different databases or start with the reference lists of a starting set of papers. In software engineering, the main recommended first step is using search strings in a number of databases, while in information systems, snowballing has been recommended as the first step. This paper compares the two different search approaches for conducting literature review studies. The comparison is conducted by searching for articles addressing “Agile practices in global software engineering”. The focus of the paper is on evaluating the two different search approaches. Despite the differences in the included papers, the conclusions and the patterns found in both studies are quite similar. The strengths and weaknesses of each first step are discussed separately and in comparison with each other. It is concluded that none of the first steps is outperforming the other, and the choice of guideline to follow, and hence the first step, may be context-specific, i.e. depending on the area of study.;1
A general model of software architecture design derived from five industrial approaches;We compare five industrial software architecture design methods and we extract from their commonalities a general software architecture design approach. Using this general approach, we compare across the five methods the artifacts and activities they use or recommend, and we pinpoint similarities and differences. Once we get beyond the great variance in terminology and description, we find that the five approaches have a lot in common and match more or less the “ideal” pattern we introduced. From the ideal pattern we derive an evaluation grid that can be used for further method comparisons.;1
A comparative study of architecture knowledge management tools;Recent research suggests that architectural knowledge, such as design decisions, is important and should be recorded alongside the architecture description. Different approaches have emerged to support such architectural knowledge (AK) management activities. However, there are different notions of and emphasis on what and how architectural activities should be supported. This is reflected in the design and implementation of existing AK tools. To understand the current status of software architecture knowledge engineering and future research trends, this paper compares five architectural knowledge management tools and the support they provide in the architecture life-cycle. The comparison is based on an evaluation framework defined by a set of 10 criteria. The results of the comparison provide insights into the current focus of architectural knowledge management support, their advantages, deficiencies, and conformance to the current architectural description standard. Based on the outcome of this comparison a research agenda is proposed for future work on AK tools.;1
Guidelines for performing Systematic Literature Reviews in Software Engineering ;"The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or
phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.";1
Requirements engineering paper classification and evaluation criteria: A proposal and a discussion;"In recent years, members of the steering committee of the IEEE Requirements Engineering (RE) Conference have discussed paper classification and evaluation criteria for RE papers. The immediate trigger for this discussion was our concern about differences in opinion that sometimes arise in program committees about the criteria to be used in evaluating papers. If program committee members do not all use the same criteria, or if they use criteria different from those used by authors, then papers might be rejected or accepted for the wrong reasons. Surely not all papers should be evaluated according to the same criteria. Some papers describe new techniques but do not report on empirical research; others describe new conceptual frameworks for investigating certain RE problems; others report on industrial experience with existing RE techniques. Other kinds of papers can also be easily recognized. All of these types of papers should be evaluated according to different criteria. But we are far from a consensus about what classes of paper we should distinguish, and what the criteria are for each of these classes.
We see a variety of evaluation criteria in journals too. At one extreme is the set of nine genres used by IEEE Software [15], all of which have different evaluation criteria. At the other extreme is the single paper class recognized by the Requirements Engineering Journal, which has the following evaluation criteria: originality, utility, technical contribution, and relation to previous work. Apparently, the only paper class recognized by the Requirements Engineering Journal is a paper describing an original and useful solution technique. This corresponds to the ‘‘how to’’genre of IEEE Software. This leaves authors and reviewers for the Requirements Engineering Journal in the dark about how other classes of papers should be judged, such as experience reports, empirical studies, or tutorials, none of which describe an original technique. This might lead to the use, by reviewers, of evaluation criteria unknown to authors, or even to the use of mutually inconsistent evaluation criteria by different reviewers of the same submission.";1
UpSet: Visualization of Intersecting Sets;Understanding relationships between sets is an important analysis task that has received widespread attention in the visualization community. The major challenge in this context is the combinatorial explosion of the number of set intersections if the number of sets exceeds a trivial threshold. In this paper we introduce UpSet, a novel visualization technique for the quantitative analysis of sets, their intersections, and aggregates of intersections. UpSet is focused on creating task-driven aggregates, communicating the size and properties of aggregates and intersections, and a duality between the visualization of the elements in a dataset and their set membership. UpSet visualizes set intersections in a matrix layout and introduces aggregates based on groupings and queries. The matrix layout enables the effective representation of associated data, such as the number of elements in the aggregates and intersections, as well as additional summary statistics derived from subset or element attributes. Sorting according to various measures enables a task-driven analysis of relevant intersections and aggregates. The elements represented in the sets and their associated attributes are visualized in a separate view. Queries based on containment in specific intersections, aggregates or driven by attribute filters are propagated between both views. We also introduce several advanced visual encodings and interaction methods to overcome the problems of varying scales and to address scalability. UpSet is web-based and open source. We demonstrate its general utility in multiple use cases from various domains.;1
Software Sustainability in the Age of Everything as a Service;"The need for acknowledging and managing sustainability as an essential quality of software systems has been steadily increasing over the past few years, in part as a reaction to the implications of “software eating the world”. Especially the widespread adoption of the Everything as a Service (*aaS) model of delivering software and (virtualized) hardware through cloud computing has put two sustainability dimensions upfront and center. On the one hand, services must be sustainable on a technical level by ensuring continuity of operations for both providers and consumers despite, or even better, while taking into account their evolution. On the other hand, the prosuming of services must also be financially sustainable for the involved stakeholders.

In this work, we discuss the need for a software architecting approach that encompasses in a holistic manner the other two dimensions of software sustainability as well, namely the social and environmental aspects of services. We highlight relevant works and identify key challenges still to be addressed in the context of software systems operating across different models for cloud delivery and deployment. We then present our vision for an architecting framework that allows system stakeholders to work in tandem towards improving a set of sustainability indicators specifically tailored for the *aaS model.";1
The Sustainability Assessment Framework Toolkit: A Decade of Modeling Experience;"Software intensive systems play a crucial role in most, if not all, aspects of modern society. As such, both their sustainability and their role in supporting sustainable processes, must be realized by design. To this aim, the architecture of software intensive systems should be designed to support sustainability goals; and measured to understand how effectively they do so. In this paper, we present the Sustainability Assessment Framework (SAF) Toolkit – a set of instruments that support architects and design decision makers in modeling sustainability as a software quality property. The SAF Toolkit is the result of our experience gained in over a decade of cases in collaboration with industrial partners. We illustrate the toolkit with examples stemming from various cases. We extract our lessons learned, and our current research and future plans to extend the SAF Toolkit for further architecture modeling and measurement.";1
Identifying, categorizing and mitigating threats to validity in software engineering secondary studies;"Context
Secondary studies are vulnerable to threats to validity. Although, mitigating these threats is crucial for the credibility of these studies, we currently lack a systematic approach to identify, categorize and mitigate threats to validity for secondary studies.
Objective
In this paper, we review the corpus of secondary studies, with the aim to identify: (a) the trend of reporting threats to validity, (b) the most common threats to validity and corresponding mitigation actions, and (c) possible categories in which threats to validity can be classified.
Method
To achieve this goal we employ the tertiary study research method that is used for synthesizing knowledge from existing secondary studies. In particular, we collected data from more than 100 studies, published until December 2016 in top quality software engineering venues (both journals and conference).
Results
Our results suggest that in recent years, secondary studies are more likely to report their threats to validity. However, the presentation of such threats is rather ad hoc, e.g., the same threat may be presented with a different name, or under a different category. To alleviate this problem, we propose a classification schema for reporting threats to validity and possible mitigation actions. Both the classification of threats and the associated mitigation actions have been validated by an empirical study, i.e., Delphi rounds with experts.
Conclusion
Based on the proposed schema, we provide a checklist, which authors of secondary studies can use for identifying and categorizing threats to validity and corresponding mitigation actions, while readers of secondary studies can use the checklist for assessing the validity of the reported results.";1
Predictive Lane Change Decision Making Using Bidirectional Long Shot-Term Memory for Autonomous Driving on Highways;This paper presents a lane change decision algorithm for predictive decision-making for an autonomous vehicle using a Recurrent Neural Network (RNN) with a Bidirectional Long Short-Term Memory (Bi-LSTM) cell. The proposed decision-making algorithm was trained and validated by driving data collected by vision, laser scanners, and chassis sensors of autonomous vehicles. The input features for the Bi-LSTM based RNN consist of the clearance and relative velocity with the surrounding target vehicles, lane measurements, and the velocity of the autonomous vehicle. The output features are configured to generate the probability of three maneuvers, left lane change, right lane change, and lane-keeping. The Bi-LSTM based RNN is configured to decide in advance two seconds before lane changes by using two seconds of observation. The collected 20,108 datasets were accumulated in global coordinates. After processing and resampling the collected datasets, 1,120, 320, and 160 datasets were generated to train, validate, and test the Bi-LSTM based RNN. The proposed algorithm was evaluated by a case study and a driving data-based prediction accuracy analysis. The results of the predictive lane change decision by the proposed algorithm have been shown to be more accurate and similar to a driver than previous approaches.;
Multi-Criteria Group Assessment of E-Commerce Websites Based on the New PROSA GDSS Methodâ€“the Case of Poland;Due to the COVID-19 pandemic and lockdowns, the popularity and number of users of e-commerce websites has increased significantly recently. In order to retain new users in the future, e-commerce websites need to develop their quality and constantly monitor it. The problem of assessing the quality of websites is a multi-criteria problem and multi-criteria decision making methods are used in it. Taking into account the need for a consensus of experts or users evaluating the website, the article developed a new multi-criteria group decision making method, called PROSA GDSS (PROmethee for Sustainability Assessment- Group Decision Support System), which allows to reward the consensus of decision makers' preferences and penalize conflicts of preferences. This method was used in the evaluation of e-commerce websites operating on the Polish market that offer the widest range of products. In the course of research works, a wide applicability of the developed method in the problems of group assessment and its broad analytical possibilities was demonstrated. As a result of the research, it has been found that local parties have an established position on the Polish e-commerce market, and parties operating from abroad, and those entering the Polish market, must catch up with the distance that separates them from local tycoons.;
An Informative Interpretation of Decision Theory: Scalar Performance Measures for Binary Decisions;A previous formulation for the application of information accounting to binary decision theory is extended to permit the quality of the decision to be quantitatively measured by evaluation of the underlying informational support. Both a single exemplar measure of information, separability, and its ensemble average equivalent, separation, are shown to measure the information support for decision quality (i.e., how well-informed is the decision), rather than the information support for decision adjudication (i.e., which hypothesis is the better choice) provided by predecision information measures. When compared to the traditional receiver operating characteristic, these measures present several functional advantages. They are scalar in nature, and may be directly optimized over secondary parameters, as well as being rigorously well posed and universally comparable. They incorporate the effects of all relevant decision components (prior information, observational information, and decision rule) in a unified manner while still being easily related to the predecision information measures of log likelihood ratio and generalized signal-to-noise ratio. They can be applied equally well to individual trials or composite averages, and evaluation does not require knowledge of the underlying truth. Compared to false alarm-oriented methods for assessing decision performance, their construction reduces sensitivity to tail effects in the underlying distributions.;
A Novel PROMETHEE-Based Outranking Approach for Multiple Criteria Decision Analysis With Pythagorean Fuzzy Information;This paper aims to present a novel outranking approach of the preference ranking organization method for enrichment evaluations (PROMETHEEs) based on Pythagorean fuzzy sets for multiple criteria decision analysis. The proposed method utilizes a novel Pythagorean fuzzy precedence index, which is based on the difference of scalar functions under anchored judgments with respect to the superiority/inferiority Pythagorean fuzzy numbers. To appropriately describe the hesitation between indifference and preference in the Pythagorean fuzzy context, this paper introduces useful precedence-based preference functions to establish the precedence relations based on pairwise comparisons. As a multiple criteria measure under Pythagorean fuzzy uncertainty, the concept of overall preference indices is identified at the aggregation stage to exploit certain rules for generating PROMETHEE flows. Next, this paper provides effective Pythagorean fuzzy PROMETHEE I and II ranking procedures to determine partial and complete preorders, respectively, among competing alternatives. The developed Pythagorean fuzzy PROMETHEE-based outranking approach is comparatively validated using a real-world application concerning the selection problem of bridge construction methods. The solution results along with a comparison analysis demonstrate that the proposed methodology outperforms the comparative approach in terms of reasonability and stability.;
Optimal Decision Tree for Cycle Time Prediction and Allowance Determination;The due-date quotation is a key performance indicator for managing customer orders which would influence customer acceptance and/or the future potential lateness penalty. The production cycle time and allowance time are added and used as the due date of order. The objective is to maximize the hit rate which is the percentage of the orders fulfilled within the time limit of quoted due date. Under the framework of supervised machine learning, we explore the new developments in feature selection and the optimal decision tree to predict cycle time by using mixed-integer optimization. Cycle time allowance could be added to the predicted cycle time or incorporated in an optimization problem as a managerial decision variable. Case studies are used to demonstrate the effectiveness of this approach, and their performances are comparable to the other popular ensemble tree approaches, such as random forests and gradient boosting.;
Multi Attribute Decision Making Using Optimistic/Pessimistic Z-Numbers;This paper presents a novel approach for multi attribute decision making (MADM). It proposes the concept of optimistic/pessimistic Z-number, which is defined as a tuple  $(Z_{x},\delta)$  where  $Z_{x}$  is a Z-number, and  $\delta \in \{+,-\}$  determines if the evaluator is optimistic (+) or pessimistic (âˆ’) regarding the provided Z-valuation. Optimistic Z-valuation shows that the hesitation of the evaluator is toward increasing the value of the evaluated object. Pessimistic Z-valuation shows that the hesitation of the evaluator is toward decreasing the value of the evaluated object. Using optimistic/pessimistic Z-number in MADM process involves asking the decision maker to evaluate a set of alternatives with respect to a set of weighted criteria using optimistic/pessimistic Z-numbers. After that the provided evaluations are converted to crisp values using the proposed  $RANKING$  function, which considers the linguistic meaning of the components of Z-numbers. In the last stage, weighted sum model is used to find the best alternative. The proposed  $RANKING$  function shows realistic results when it is compared with a well-known method from the literature.;
Expected value method for fuzzy multiple attribute decision making;This paper presents a fuzzy multiple attribute decision-making (FMADM) method in which the attribute weights and decision matrix elements (attribute values) are fuzzy variables. Fuzzy arithmetic and the expected value operator of fuzzy variables are used to develop the expected value method to solve the FMADM problem. A numerical example is given to demonstrate the feasibility and effectiveness of the method.;
Multiple Criteria Group Decision Making Using a Parametric Linear Programming Technique for Multidimensional Analysis of Preference Under Uncertainty of Pythagorean Fuzziness;This paper aims to utilize the core structure of linear programming technique for multidimensional analysis of preference (LINMAP) to propose a parametric LINMAP methodology for addressing multiple criteria group decision-making problems based on Pythagorean fuzzy sets. To compare Pythagorean membership grades, this paper presents a Hamming distance-based approach for identifying closeness-based order relations based on Pythagorean fuzzy closeness indices. The concept of comprehensive closeness measures is introduced to measure individual order consistency and inconsistency between subjective preference relations and objective order relations. In the spirit of LINMAP, this paper determines individual goodness of fit and poorness of fit and further constructs a novel parametric LINMAP model. The applicability of the developed approach is explored by a practical application of railway project investment. Some comparative analyses are conducted to demonstrate the usefulness and advantages of the proposed methodology.;
A Hybrid Fuzzy Soft Sets Decision Making Method in Medical Diagnosis;The existing approaches for fuzzy soft sets decision-making are mainly based on different types of level soft sets. How to deal with such kinds of fuzzy soft sets decision-making problems via decreasing the uncertainty resulting from human's subjective cognition is still an open issue. To address this issue, a hybrid method for utilizing fuzzy soft sets in decision-making by integrating a fuzzy preference relations analysis based on the belief entropy with the Dempster-Shafer evidence theory is proposed. The proposed method is composed of four procedures. First, we measure the uncertainties of parameters by leveraging the belief entropy. Second, with the fuzzy preference relations analysis, the uncertainties of parameters are modulated by making use of the relative reliability preference of parameters. Third, an appropriate basic probability assignment in terms of each parameter is generated on the modulated uncertainty degrees of parameters basis. Finally, we adopt Dempster's combination rule to fuse the independent parameters into an integrated one;
New explorations for decision trees;Traditionally, the decision tree method. is defined and used. for. finding the optimal solution of a Bayesian decision problem. And it is difficult to use the decision tree method to find the sub-optimal solution, not to mention to rank alternatives. This paper discusses how to use the decision tree method for the alternative selecting and ranking. A practical case study is given to illustrate the applicability.;
A Novel Interval Value Extension of Picture Fuzzy Sets Into Group Decision Making: An Approach to Support Supply Chain Sustainability in Catastrophic Disruptions;In critical times when disasters and unpredicted events collapse human judgments, formation and structure of social infrastructure gets to be rather important. Acute risk of catastrophic events such as a rare disaster, a coronavirus pandemic, trigger a global scale setback which has a substantial impact on peopleâ€™s lives and livelihoods. Catastrophic events halt economic landscape, collapse commodity prices, and silence production engines which interact in complex ways. During this phase of volatility and opacity, roles of sustainable supply chain, productions and circular economy get more important than ever. Such disruptions are therefore to be addressed by identifying sustainable supply chain strategies. This paper intends to establish underlying patterns of disruptive factors in the supply chain to evaluate strategies in formation and structuring of sustainable supply chain by applying it to real world example in Turkish Kitchen Equipment Manufacturer (KEM). Selection of sustainable supply chain strategy is a complex Multi-Criteria Decision-Making (MCDM) issue involving various parameters that may be contradictory at the same time. Analytical-Hierarchy-Process (AHP) and VlseKriterijumska-Optimizacija-I-Kompromisno-Resenje (VIKOR) methods can be used to solve such problems. In order to strengthen these methods in terms of their lacking capability of coping with uncertainty and incomplete information, they are extended with Interval-Valued Picture-Fuzzy Set (IVPFS) to better simulate human judgment. MCDM processes can be enhanced with Group-Decision-Making (GDM) to combine individual Decision Makersâ€™ (DMs) opinions into group judgments. Found outcome reveal that supply chains to respond catastrophic disruptions, businesses should primarily diversify supply chain from a geographic perspective, and should diversify disruptive forces in motion from a physical perspective. Originality of article is based on integrated AHP and VIKOR approaches in IVPFS based GDM algorithm as a first in the literature and presentation of its application for supply chain sustainability in catastrophic disruptions as a decision support tool.;
An Integrated MCDM Approach for Cloud Service Selection Based on TOPSIS and BWM;Cloud Computing (CC) has become increasingly popular since it provides a wide variety of customized and reliable computational services. With the rapid growth of this technology, more and more IT services providers compete to offer high-quality and cost-effective cloud services that best fulfill their customers' needs. Given the vast diversity of these offers, the choice of the most appropriate Cloud Service Provider (CSP) became a dilemma that confuses most cloud customers. Many diverged criteria have to be considered to precisely evaluate services offered by several CSPs, some of these criteria cannot be quantified easily such as usability and security. The selection of the best CSP is thus a complex Multi-Criteria Decision Making (MCDM) problem that needs to be addressed efficiently. Previous studies of this problem employed MCDM methods that are either unfeasible when it is difficult or meaningless to quantify alternatives over criteria or computationally expensive and inconsistent when relative preferences of alternatives and criteria are used instead. In this paper, we propose a novel MCDM approach that is feasible, efficient and consistent using relative preferences of criteria and alternatives. The proposed approach incorporates Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) and the Best Worst Method (BWM) to rank CSPs using evaluation criteria characterizing their services. The integrated approach has been tested and validated through a use-case scenario which demonstrates its effectiveness and correctness. We have also compared the proposed approach to the most commonly used MCDM approach, Analytical Hierarchical Process (AHP). The results clearly show that the proposed approach outperforms AHP in terms of computational complexity and consistency;
Three-Way Decision in a Multi-Source Information System and Its Applications;Three-way decision (3WD) is a decision that conforms to human's cognitive pattern and offers a new visual angle for solving practical decision-making problems. An information system (IS) represents relationships between objects and attributes. And a multi-source information system (MSIS) is an IS which composes of multi-source data sets. This paper presents 3WD in an MSIS as well as gives its application in petroleum project investment. Considering that risks are uncertain, loss functions are first given by means of interval numbers. Then, multi-granulation decision-theoretic rough set (MGDTRS) models in a given MSIS are proposed from the point of view of multi-granulation. Next, based on the idea of a decision-theoretic rough set (DTRS), the optimistic and pessimistic 3WDs in the MSIS are proposed. Finally, an example of petroleum project investment is used to support the feasibility of the proposed decision method.;
A Mixed-Choice-Strategy-Based Consensus Ranking Method for Multiple Criteria Decision Analysis Involving Pythagorean Fuzzy Information;The aim of this paper is to develop a novel consensus ranking method that uses a mixed choice strategy for multiple criteria decision analysis (MCDA) under complex uncertainty based on Pythagorean fuzzy (PF) sets. The majority of MCDA methods have focused almost exclusively on â€œcriterion-specificâ€choice tasks that are the tasks in which all alternatives are decomposed into distinct components and evaluated on specific criteria. However, in certain MCDA problems in practical applications, category-based choices tend to be more holistic in nature, especially in affective-like aspects. Therefore, this paper incorporates a mixed choice strategy (i.e., a combination of a category-based strategy and a criterion-specific strategy) into the core structure of the developed MCDA method. Furthermore, this paper utilizes the theory of Pythagorean fuzziness to provide a powerful modeling tool for complex and varied decision-making environments. Employing the developed concepts of a PF precedence index based on PF information and a disagreement indicator based on distances between rankings, this paper proposes a novel consensus ranking method by means of a comprehensive disagreement-based assignment model for addressing a mixed-choice-strategy-based MCDA problem in the PF context. As an application of the proposed methodology, a real-world case study of a luxury car selection problem is investigated. The application results, along with a comparative analysis, demonstrate the practicality and effectiveness of the developed approach, which is capable of handling hybrid category-based and criterion-specific choice tasks and managing complex uncertainty in practical situations.;
Using Data Mining Techniques to Predict Student Performance to Support Decision Making in University Admission Systems;An admissions system based on valid and reliable admissions criteria is very important to select candidates likely to perform well academically at institutions of higher education. This study focuses on ways to support universities in admissions decision making using data mining techniques to predict applicants' academic performance at university. A data set of 2,039 students enrolled in a Computer Science and Information College of a Saudi public university from 2016 to 2019 was used to validate the proposed methodology. The results demonstrate that applicants' early university performance can be predicted before admission based on certain pre-admission criteria (high school grade average, Scholastic Achievement Admission Test score, and General Aptitude Test score). The results also show that Scholastic Achievement Admission Test score is the pre-admission criterion that most accurately predicts future student performance. Therefore, this score should be assigned more weight in admissions systems. We also found that the Artificial Neural Network technique has an accuracy rate above 79%, making it superior to other classification techniques considered (Decision Trees, Support Vector Machines, and NaÃ¯ve Bayes).;
Dual worth trade-off method and its application for solving multiple criteria decision making problems;To overcome the limitations of the traditional surrogate worth trade-off (SWT) method and solve the multiple criteria decision making problem more efficiently and interactively, a new method labeled dual worth tradeoff (DWT) method is proposed. The DWT method dynamically uses the duality theory related to the multiple criteria decision making problem and analytic hierarchy process technique to obtain the decision maker's solution preference information and finally find the satisfactory compromise solution of the decision maker. Through the interactive process between the analyst and the decision maker, trade-off information is solicited and treated properly, the representative subset of efficient solutions and the satisfactory solution to the problem are found. The implementation procedure for the DWT method is presented. The effectiveness and applicability of the DWT method are shown by a practical case study in the field of production scheduling.;
Novel Generalized Distance Measure of Pythagorean Fuzzy Sets and a Compromise Approach for Multiple Criteria Decision Analysis Under Uncertainty;This paper aims at developing a novel generalized distance measure of Pythagorean fuzzy (PF) sets and constructing a distance-based compromise approach for multiple criteria decision analysis (MCDA) within PF environments. The theory of Pythagorean fuzziness provides a representative model of nonstandard fuzzy sets;
An MCDM Approach for Cloud Computing Service Selection Based on Best-Only Method;Owing to the significant and continuous development of cloud computing technology and the increasing number of cloud service providers (CSPs) that have emerged, CSP selection has become a challenging decision for many organizations. To accurately evaluate the services provided by various CSPs, many independent criteria must be considered, resulting in a multi-criteria decision-making (MCDM) problem. In MCDM problems, several alternatives are assessed against several criteria to identify the optimal alternative (s). The challenges stem from complex computation as well as less consistency, resulting in less reliable results. In this paper, a new method, called the best-only method (BOM), is proposed for solving the CSP selection problem, which is viable, efficient, and fully consistent. The proposed method was evaluated and validated using a use-case scenario, demonstrating its efficiency and appropriateness. The proposed method is compared with two popular MCDM methods, analytical hierarchical process (AHP) and best-worst method (BWM), from three perspectives: efficiency, consistency ratio (CR), and total deviation (TD). Based on the obtained results, AHP and BWM require 75.3% and 46.2% more comparisons, respectively, than the proposed method. The consistency ratios for AHP, BWM, and the proposed method were 37.92%, 13.35%, and 0%, respectively. The total deviations are 21.26, 8.65, and 0 for AHP, BWM, and the proposed method, respectively. These results clearly indicate that the proposed method outperforms AHP and BWM in terms of computing complexity and consistency, making it more efficient and reliable.;
A Psychometric Approach to the VIKOR Method for Eliciting Subjective Public Assessments;Based on the concepts of sensory thresholds, the Weber-Fechner Law in psychology has usually been applied to sensory dimensions. However, some neurophysiological studies have shown that assessment of mental numbers or numerical information also follows this law. Therefore this paper proposes a modification of VIKOR that reflects the Weber-Fechner law to account for nonlinearity in evaluation scales as perceived by decision-makers. The model is applied to a case where public approval of two different types of public bus operation systems considering six criteria is pursued. The results are compared with those obtained from the multi-attribute value method (MAVT). The suggested method inflates the relative attractiveness of the alternatives that are closer to the best solutions (used by VIKOR). A numerical example is also provided to illustrate the applicability of the approach. This method can be a useful tool where public opinions based on subjective perceptions in a public participation process are of particular interest rather than assessing verifiable facts, i.e., observable, measurable data.;
Multi-criteria decision-making approach with incomplete certain information based on ternary AHP;It is not uncommon in multiple criteria decision-making that the numerical values of alternatives of some criteria are subject to imprecision, uncertainty and indetermination and the information on weights of criteria is incomplete certain. A new multiple criteria decision-making method with incomplete certain information based on ternary AHP is proposed. This improves on Takeda's method. In this method, the ternary comparison matrix of the alternatives under each pseudo-criteria is constructed, the eigenvector associated with the maximum eigenvalue of the ternary comparison matrix is attained as to normalize priority vector of the alternatives, then the order of alternatives is obtained by solving two kinds of linear programming problems. Finally, an example is given to show the feasibility and effectiveness of the method.;
Multi-Objective Decision-Making for Mobile Cloud Offloading: A Survey;Running very complex applications on mobile devices is still challenging since they are constrained by limited resources, such as memory capacity, network bandwidth, processor speed, and battery power. Mobile Cloud Computing (MCC) is a combination of cloud computing and mobile internet, which could effectively alleviate the resource constraints of mobile devices. How to efficiently offload computation intensive parts of mobile applications from mobile devices to capable cloud servers is one of the keys. In mobile environments, the resource heterogeneity of mobile devices and cloud services, the interruption of heterogeneous wireless networks, the complexity of mobile applications, and the characteristic of transferring a large amount of data, are the major bottlenecks that have prevented this technology from being widely used. This paper takes these constraints into an account at the same time and explores methods of multi-objective decision making for timeand energy-aware task offloading for MCC. It is designed to ensure the right computational tasks are executed in the right way, at the right time and place.;
New Multiparametric Similarity Measure and Distance Measure for Interval Neutrosophic Set With IoT Industry Evaluation;In the epoch of the Internet of Things (IoT), we have confronted five challenges (Connectivity, Value, Security, Telepresence, and Intelligence) with complex structures. The IoT industry decision making is critically important for countries or societies to enhance the effectiveness and validity of leadership, which can greatly accelerate the industrialized and large-scale development. In the case of IoT industry decision evaluation, the essential problem arises serious incompleteness, impreciseness, subjectivity, and incertitude. Interval neutrosophic set, disposing of the indeterminacy portrayed by truth membership T, indeterminacy membership I, and falsity membership F with interval form, is a more viable and effective means to seize indeterminacy. The main purpose of this paper is to investigate the multiparametric distance measure and similarity measure. Meanwhile, some interesting properties of distance measure and similarity measure are proved. Then, the objective weights of diverse attributes are ascertained by the deviation-based method. Moreover, we explore the combination weight, which reveals both the objective preference and subjective preference. The validity of the algorithm is illustrated by an IoT industry decision-making issue, along with the effect of diverse parameters on the ranking. Finally, a comparison of the developed with the existing interval neutrosophic decision-making methods have been executed in the light of the counter-intuitive phenomena and unauthentic issue for displaying their effectiveness.;
A New Link Between Output-Oriented BCC Model with Fuzzy Data in the Present of Undesirable Outputs and MOLP;In recent years, the relation between data envelopment analysis and multiple objective linear programming has received a great deal of attention from researchers. However, there are two difficulties in doing an objective evaluation of the performance of decision making units. The first one is how to treat undesirable factors jointly produced with the desirable factors and the second one is how to treat with imprecise data. In this paper, we establish an equivalence relation between multiple objective linear programming and the output-oriented Banker, Charnes, Cooper(BCC) model in the present of undesirable factors and fuzzy data such that the decision maker's preference can be taken into account in an interactive fashion for finding target unit.;
Engineering management - general: Long term decision-making using throughput accounting;Throughput accounting, the Theory of Constraints' alternative to product costing, is being criticised for ignoring fixed costs and emphasizing short-term optimization by assuming that variables such as product price, customer orders, technology and production design are fixed and therefore appropriate for maximizing throughput. It is argued that the Theory of Constraints and thus also throughput accounting are little more than a powerful short-run optimisation procedures.;
A New Generalized Fuzzy Divergence Measure and Applications;This paper introduces a new parametric generalized measure of fuzzy di-vergence with the proof of its validity. The particular cases are proved in the proposed generalized fuzzy divergence measure. In addition, the elegant properties are studied on the new generalized fuzzy divergence measure. A method to solve multi-criteria decision making problem is developed by using the proposed generalized fuzzy diver-gence measure. Finally, the applications of this fuzzy divergence measure to pattern recognition and multi-criteria decision making are shown using numerical examples for each.;
Safer User Interfaces: A Case Study in Improving Number Entry;Numbers are used in critical applications, including finance, healthcare, aviation, and of course in every aspect of computing. User interfaces for number entry in many devices (calculators, spreadsheets, infusion pumps, mobile phones, etc.) have bugs and design defects that induce unnecessary use errors that compromise their dependability. Focusing on Arabic key interfaces, which use digit keys 0-9-Â· usually augmented with correction keys, this paper introduces a method for formalising and managing design problems. Since number entry and devices such as calculators have been the subject of extensive user interface research since at least the 1980s, the diverse design defects uncovered imply that user evaluation methodologies are insufficient for critical applications. Likewise, formal methods are not being applied effectively. User interfaces are not trivial and more attention should be paid to their correct design and implementation. The paper includes many recommendations for designing safer number entry user interfaces.;
An Intuitionistic Linguistic DEMATEL-Based Network Model for Effective National Defense and Force Innovative Project Planning;The COVID-19 pandemic will accelerate the shift toward multipolarity, and will have major long-term impacts on territorial security within the Indo-Pacific. In addition, COVID-19 is likely to have a long-term effect on risk evaluation in the Indo-Pacific states. Therefore, it is vital to oversee and execute remedial activities quickly and successfully, amid the COVID-19 pandemic. This paper proposes a national defense and military budget planning strategy. It applies a decision-making trial and evaluation laboratory linguistic data strategy for group decision-making, in order to collect group opinions and analyze the causal relationship of complicated social science issues in indistinct situations. These concepts are divided into causal and impact groups, to provide an improved understanding of the relationship among them, as well as making recommendations to improve their general execution. This paper employed the fuzzy DEMATEL method to analyze the model and considered suggestions as the key influencing factors in budget planning strategy. Through this well-constructed fuzzy DEMATEL approach our research results show that a proper operations strategy and management of both resource usage and task arrangement in accordance with policy making will accomplish excellent budget planning strategy results. The results reveal that the Mission Requirement is a major causal factor. The study can provide a successful national defense and military budget strategy assessment with satisfactory criteria that fit the decision-makersâ€™ requirements, particularly when the assessment criteria are various and entwined. We offer recommendations for government authorities to plan national defense and military budget planning strategies.;
Developments in Fuzzy Multicriteria Analysis;Selecting or ranking available alternatives (observations/objects) with respect to multiple, often conflicting criteria in a fuzzy environment usually referred to as fuzzy multicriteria analysis is a problem of a major interest in information and engineering. Methodologies for addressing this problem have been developed from a variety of research disciplines, including statistics, econometrics, artificial intelligent, and operations research. This paper presents an overview of the developments in fuzzy multicriteria analysis. It discusses the complexity of fuzzy multicriteria analysis and analyses the existing approaches from four different perspectives for facilitating a better understanding of the recent development in this domain. Finally, the paper elaborates on the future research areas in fuzzy multicriteria analysis.;
Optimal Decision Guidance for the Electricity Supply Chain Integration With Renewable Energy: Aligning Smart Cities Research With Sustainable Development Goals;The evolution of the smart cities' research and the relevant discussion on well-being is challenging the design of policies, information systems, and computational methods toward the alignment to Sustainable Development Goals (SDG) of the United Nations. Sustainable GOAL 7-Affordable and Clean Energy-is the focus of this paper. The requirement to integrate certain levels of renewable energy sources into the electricity grids to meet sustainability measures creates unfavorable variability in the entire electricity supply chain and delays the integration of renewable energy sources into the energy systems. This paper introduces a methodology and an optimization model for the electricity supply chain that allows reducing the variability of the renewable energy sources supply by optimal planning of the supply chain operations. The methodology supports electricity decision makers to identify the optimal operation of the electricity supply chain, taking into account multiple objectives and supply chain designs, including innovative architectures. The multi-objective linearized optimization model allows regulating the flow rates of energy and water for the electricity supply chain. The methodology was evaluated, considering three possible integration architectures for the loads and real-time electricity pricing. For each of the studied architectures, the analysis showed the optimal dispatching to reduce the energy variation due to the increasing renewable energy penetration into the grid. The results show how the methodology can present decision makers with optimal operation of the supply chain, such that a minimum energy variation is achieved at a minimum cost. The key contribution of this paper to the agenda of the special section entitled â€œUrban Computing & Well-being in Smart Cities: Services, Applications, Policymaking Considerationsâ€ is multifold: It sets a scientific framework for the promotion of the SDG #7 and innovates in the design and deliverable of a fully functional eco-system for the optimization of the electricity supply chain. It also defines well-being as an affordable and clean energy primer.;
Toward Selection of Trustworthy and Efficient E-Learning Platform;The e-learning sector continues to evolve, with a growing number of eLearning resources available to businesses, government agencies, and individual people. With the fastest growth in developing economies attempting to close the educational gap, the scope of eLearning is now stronger than ever. Because of its low cost, comfort, and availability, e-learning is quickly becoming the worldâ€™s dominant educational force of the twenty-first century. Students, experts, and professors are interacting with the educational setting in new ways due to e-learning platforms. Several academics struggle with deciding which of the numerous available platforms is the most suited for their scenario. Evaluating the benefits and drawbacks of every platform can help learners all over the world in designing personalized learning options that meet their budgets and context. This innovation is resilient and ever-changing in order to suit the needs of learners and educators all over the world. This article gives a brief overview of various popular online learning platforms. The main objective of this article is to shed some light on the effective advancement of e-learning platforms and evaluate them using a hybrid multiple criteria decision making (MCDM) model-oriented analysis amid pandemics and natural calamities, as well as provide recommendations for users about how to interact with the complexities of e-learning platform selection.;
Selection and Application of Building Material Suppliers Based on Intuitionistic Fuzzy Analytic Hierarchy Process (IFAHP) Model;Scientific selection of building materials supplier is of great importance in the management of construction projects. In this work, the selection problem of building material suppliers is investigated under the background of economic globalization based on the IFAHP approach. Firstly, according to the features and key factors of building materials supplier selection, this work constructs evaluation index system by taking five aspects including cost, quality, service level, supplier qualification and risk into account. Secondly, the intuitionistic fuzzy preference relations (IFPRs) of criteria or sub-criteria and IFPRs between the alternatives with respect to each sub-criterion are determined via paired comparisons. The consistency check is carried out subsequently. Considering that the interaction process between experts and decision makers is time consuming and the experts may be not willing to participate in the adjustment and correction of IFPR continuously, an algorithm is proposed to automatically correct the inconsistency while preserving the original information even without experts involved. Consequently, the time costs of experts can be greatly shortened. Based on the above analysis, the optimal scheme can be obtained via calculating the scores of each material supplier. A case study on the selection of building material suppliers is conducted by employing the proposed framework. Results show that the scores of the three suppliers is positively correlated with the weight of the cost but negatively correlated with that of quality, service level, supplier qualification and risk. Besides, the sensitivity analysis illustrates that product quality and service level affect the ranking greatly.;
Consensus Distributionally Robust Optimization With Phi-Divergence;We study an efficient algorithm to solve the distributionally robust optimization (DRO) problem, which has recently attracted attention as a new paradigm for decision making in uncertain situations. In traditional stochastic programming, a decision is sought that minimizes the expected cost over the probability distribution of the unknown parameters. In contrast, in DRO, robust decision making can be derived from data without assuming a probability distribution;
Predicting Instructor Performance Using Data Mining Techniques in Higher Education;Data mining applications are becoming a more common tool in understanding and solving educational and administrative problems in higher education. In general, research in educational mining focuses on modeling student's performance instead of instructors' performance. One of the common tools to evaluate instructors' performance is the course evaluation questionnaire to evaluate based on students' perception. In this paper, four different classification techniques - decision tree algorithms, support vector machines, artificial neural networks, and discriminant analysis - are used to build classifier models. Their performances are compared over a data set composed of responses of students to a real course evaluation questionnaire using accuracy, precision, recall, and specificity performance metrics. Although all the classifier models show comparably high classification performances, C5.0 classifier is the best with respect to accuracy, precision, and specificity. In addition, an analysis of the variable importance for each classifier model is done. Accordingly, it is shown that many of the questions in the course evaluation questionnaire appear to be irrelevant. Furthermore, the analysis shows that the instructors' success based on the students' perception mainly depends on the interest of the students in the course. The findings of this paper indicate the effectiveness and expressiveness of data mining models in course evaluation and higher education mining. Moreover, these findings may be used to improve the measurement instruments.;
Estimating the Survivability Impact of Multi-Fiber Wavelength-Division Multiplexing Networks;The efficacy of an optical network is determined by the network's ability to hold out and pull through from failures and disruptions. Achieving the desired impact of survivability is a key imperative for optical network industries. Several practitioners and researchers are working towards realizing the target of maximum survivability of optical network systems. In this league, our research initiative intends to evaluate the impact of survivability of multi-fiber wavelength-division multiplexing networks. To evaluate the impact of survivability factor in optical network through the most accurate means, we used the hybrid multi criteria decision making methodology, the Fuzzy Analytical Hierarchy Process (FAHP) and Fuzzy Technique for Order of Preference by Similarity to Ideal Solution (FTOPSIS). For estimating the impact of survivability in the present endeavour, the authors have taken two layers (two factors at level 1, and 10 factors at level 2) of the survivability factors for calculating the weights and five alternatives for evaluating the survivability impact. The hybrid technique of FAHP and FTOPSIS was developed for our analysis. FAHP evaluated the weights of the factors with respect to their alternatives, whereas the FTOPSIS was employed to calculate the overall impact of survivability. According to the numerical analysis of the selected factors affecting the parameters of the survivability in Wavelength Division Multiplexing (WDM), restoration technique was the most prioritized alternative, and hence needs more focus while engineering the WDM network.;
Integrated Fuzzy Based Computational Mechanism for the Selection of Effective Malicious Traffic Detection Approach;A mechanism to effectively detect malicious traffic in the present context where new cyber criminals and threatening actors are emerging every day, has become a compelling need. These invaders use overwhelming tactics that mask the nature of attacks and make bad acts seem innocuous. A growing number of trustworthy electronic systems and facilities have been introduced with the fast development of pervasive digital technologies. However threats to cyber-security continue to grow, posing hindrance in the efficient use of digital services. The detection and classification of malicious traffic due to security threats can be done by an efficacious traffic detection approach. The development of a smart, precise malicious traffic detection system has therefore become a subject of extensive research. Current traffic detection systems are typically employed in conventional network traffic detection. These systems sometimes face failure and cannot recognize many known or modern security threats. This is because they rely on conventional algorithms which focus less on precise selection and classification of functions. As a result, several well-known traffic signatures remain unidentified and latent. Hence, there is a need to evaluate each significant malicious traffic detection system based on the performance of the system. In this research work, the author has used the Fuzzy AHP methodology which is designed to address the issues related to the vagueness, uncertainties and total awareness of languages. In addition, the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) was implemented in order to assess the order of preference. Furthermore, the Multi-Criteria Decision-Making (MCDM) method was used for classifying the impact of the alternatives according to their overall performance. The studyâ€™s conclusive evaluations will be a corroborative reference for the practitioners working in the domain of assessing and selecting the most effective traffic detection approach for more reliable, efficient and systematic design.;
A Dynamic Social Feedback System to Support Learning and Social Interaction in Higher Education;In this research, we examine the design, construction, and implementation of a dynamic, easy to use, feedback mechanism for social software. The tool was integrated into an existing university's online learning community (OLC). In line with constructivist learning models and practical information systems (IS) design, the feedback system provides members of the OLC with the capability to rate blog posts and provide instant feedback on the content of their peers. The software was implemented at a US university in an introductory course on IS with the goal of fostering higher levels of learning and social interaction. A content analysis showed higher levels of system usage corresponded with higher course grades. A survey analysis supported these results showing statistical significance between levels of system use and perceived levels of learning.;
Uncertainty Modeling in Risk Assessment Based on Dempster-Shafer Theory of Evidence with Generalized Fuzzy Focal Elements;Dempster-Shafer theory of evidence is one of the important tools for decision making under uncertainty. It is more useful in situations when cost of technical difficulties is involved or uniqueness of the situation under study makes it difficult/impossible to cover enough observations to quantify the models with real data. Consequently, experts provide opinions in terms of basic probability assignment for focal elements. Usually, it is seen that experts provide basic probability assignment for interval (or crisp) focal elements. However, due to presence of uncertainty focal elements can sometimes be treated as normal/generalized triangular fuzzy number (TFN in short) instead of intervals or crisp sets. TFN encodes only most likely value (mode) and the spread. This paper presents an attempt to combine Dempster-Shafer structures (DSS in short) with generalized/normal fuzzy focal elements using possibilistic sampling technique. To this end, human health risk assessment is carried out under such setting.;
Hesitant-Fuzzy Sets-Based Computational Approach for Evaluating the Survivability Impact of Multi-Fiber WDM Networks: Kingdom of Saudi Arabia Perspective;Saudi Arabia's Information and Communication Technology (ICT) industry is undergoing different stages of modernization. Over the last few decades, the ICT industry has been experiencing rapid growth. The understanding of disruption as well as fluctuation in channel capacity gives an idea about the optical fiber network. A primary necessity for the optical communication industry is to achieve the desired effect of survival and growth. Scientific researchers are trying to achieve the objective of optimum optical network services survivability. The proposed paper attempts to describe and analyze the effect of multiplexing in multi-fiber wavelength. To analyze and assess the effect in more scientific and systematic manner, the authors have used a multi criteria decision making (MCDM) approach named the hesitant fuzzy analytical hierarchy process as well as TOPSIS methods in this paper. With the help of these adopted MCDM approaches, the authors have assessed the surviving strength and capacity of multiplexing. For this empirical model, five features and two levels of alternatives were chosen. A combination of two principal alternatives was the first level, and the second level had its five based alternatives. For this analysis, the unified symmetrical decision making strategy of Hesitant-Fuzzy AHP with Hesitant-Fuzzy TOPSIS was established. The findings obtained on survivability in this research will be a point of reference for developing the next level wavelength division multiplexing in optical transmission network communication. In the sense of producing gigabits and terabits per second, this inquiry will further reinforce optical fiber connectivity.;
AUC4.5: AUC-Based C4.5 Decision Tree Algorithm for Imbalanced Data Classification;This paper presents a modification of Quinlanâ€™s C4.5 algorithm for imbalanced data classification. While the C4.5 algorithm uses the difference in information entropy to determine the goodness of a split, the proposed method, which is named AUC4.5, examines the difference in the area under the ROC curve (AUC) of a split. It implies that our method attempts to maximize the AUC value of a trained decision tree in order to cope with class imbalance in data. An extensive experimental study was performed on 20 real datasets from the machine learning repository at the University of California at Irvine, Irvine. The proposed AUC4.5 algorithm showed better classification than both the standard and cost-sensitive C4.5 algorithms.;
Selection of Alternative Fuels for Sustainable Urban Transportation under Multi-criteria Intuitionistic Fuzzy Environment;The unrestrained expansion in urbanization and increasing development of new means of transports result in major urban land use and transportation system which is socially, economically and environmentally unsustainable. Hence the major challenge for the decision makers regarding the transportation policies is to choose the alternative fuel operated vehicles resulting in a sustainable transportation system. In real life situations, it is difficult to get exact data, so to express the uncertain data, intuitionistic fuzzy data has been considered. The problem is to select the best fuel technology for land transportation subject to multiple criterions resulting in a sustainable transportation system in an uncertain environment. Here, the similarity measures of Intuitionistic fuzzy sets (IFSs) are applied for developing a methodology for identifying the best option. The weights of the attributes may be known or partially known or unknown. The unknown weights are determined by normalizing the average score functions of the intuitionistic fuzzy data for the criterion. Algorithms are given for handling different situations and numerical examples illustrate the varied cases.;
Selection of Multi-Level Deep Features via Spearman Rank Correlation for Synthetic Aperture Radar Target Recognition Using Decision Fusion;Convolutional neural networks (CNN) now become one of the most popular methods in synthetic aperture radar (SAR) target recognition. To fully exploit the deep features learned by CNN, this paper considers all the feature maps from different convolution layers. At each layer, the Spearman rank correlation is employed to evaluate the similarities between the feature maps and original SAR image. A certain proportion of feature maps with high similarities are selected and jointly represented based on the joint sparse representation (JSR) model. For the reconstruction error vectors from different layers, they are combined based on linear weighting using a random weight matrix. The fused reconstruction errors are analyzed to form a decision value for target recognition. The feature selection chooses the robust features and JSR considers the inner correlations between the feature maps from the same layer. In addition, the linear weighting using the random weight matrix could statistically reveal the correlations between the test sample and a certain training class. Therefore, the overall effectiveness and robustness of the proposed method can be enhanced. By performing experiments on the moving and stationary target acquisition and recognition (MSTAR) dataset, the proposed method could achieve a very high average recognition rate of 99.32% for ten classes of ground targets under the standard operating condition (SOC). Furthermore, under the extended operating conditions (EOCs) like configuration differences, depression angle differences, noise corruption, and partial occlusion, the proposed could also achieve superior robustness over some state-of-the-art SAR target recognition methods.;
Models for Multiple Attribute Decision Making With Fuzzy Number Intuitionistic Fuzzy Hamy Mean Operators and Their Application;In this paper, we expand the Hamy mean (HM) operator and weighted Hamy mean (WHM) with fuzzy number intuitionistic fuzzy numbers (FNIFNs) to propose fuzzy number intuitionistic fuzzy Hamy mean (FNIFHM) operator and fuzzy number intuitionistic fuzzy weighted Hamy mean (FNIFWHM) operator. Then the MADM methods are proposed with these operators. In the end, we utilize an applicable example for comprehensive evaluation of agricultural economic development quality to prove the proposed methods.;
Computerized Argument Delphi Technique;The aim of this study is the computerization of the argument Delphi method. The Delphi method is mainly designed for qualitative prediction within a group of experts, where the experts make predictions and a facilitator controls these predictions until the experts end up with a level of consensus. Argument Delphi, as opposed to the classical Delphi model, is built on the contradictions of the ideas of the experts. Argument Delphi mainly focuses on a discussion topic and asks experts to create new arguments and criticize other arguments from other experts. After a certain level of contradiction, the method yields an amount of contradictory, criticized arguments and builds a decision over these antitheses, as in the Hegelian approach. This is the first time the argument Delphi method has been modeled in a graph of arguments and the problem of qualitative decision has been transferred into a graph problem using Delphi method. This paper is also the first time that argument aggregation and evaluation methods have been proposed. Moreover, the computerized version of argument Delphi is applied to real-world problems using crowd involvement through Facebook. The problem is defined as the prediction of petroleum prices for the end of year and more than 100 contributors from all around the world argued and criticized each other. This paper also discusses the findings of this case study.;
Prediction of Rockburst Risk in Coal Mines Based on a Locally Weighted C4.5 Algorithm;Rockburst is a dynamic phenomenon characterized by the sudden, abrupt, and violent release of deformation energy in coal and rock masses around mine shafts and slopes that can result in considerable destruction. For prediction and evaluation methods are essential for the prevention and control of rockburst disasters, many machine learning methods are developed for this purpose. To accurately predict rockburst risk, the present study addresses this issue by developing a locally weighted C4.5 decision tree algorithm for predicting the risk of rockburst in coal mines. In the proposed processing, the minimum description length principle is first applied to discretize the continuous attribute data in the raw training dataset. Then, the prediction model based on the C4.5 algorithm is trained by 10-fold cross validation using the adjacent samples selected by the k-nearest neighbors method. Finally, the decision tree is completed by applying pessimistic pruning. The rockburst prediction accuracy of the proposed locally weighted C4.5 algorithm is compared with that obtained by the standard C4.5 algorithm based on field data derived from the Yanshitai coal mine, Chongqing, China. The rockburst risk prediction accuracies obtained by the proposed and standard C4.5 algorithms for the samples in the testing dataset were 100% and 71.43%, respectively. Accordingly, the proposed locally weighted C4.5 algorithm greatly outperformed the standard C4.5 algorithm for the prediction of rockburst risk based on the data considered.;
A Grey Theory Based Multiple Attribute Approach for R&D Project Portfolio Selection;In this paper, the research and development (R&D) project portfolio selection problem is introduced as a multiple attribute decision making problem. Recognizing and modeling the project interdependencies provide valuable cost savings and other greater benefits to organizations. Therefore, besides conventional attributes like cost and outcome, different type of interdependencies are also considered as attributes. Since the decision makers' preferences on the project alternatives or attributes are uncertain, a grey theory based method is proposed to cope with the uncertainty. correspondingly, the preferences and ratings of the attributes are described by linguistic variables, which are further expressed as grey numbers. Consequently, a ranking order of the projects is done using grey possibility degree and is used to determine the portfolio. To explore, an illustration is done by a case study. The methodology proposed here is shown to be an efficient approach to solve the R&D project portfolio selection problem.;
Neutrosophic Reducible Weighted Maclaurin Symmetric Mean for Undergraduate Teaching Audit and Evaluation;The undergraduate teaching audit and evaluation (UTAE) is critically important for the university to promote the establishment of a quality assurance system and improve the quality of teaching. In considering the case of UTAE, the essential question arises strong ambiguity and interaction. The Maclaurin symmetric mean (MSM), as a significant information integration tool, can seize the interrelation among multiple input values more effectively. A series of weighted MSMs have been developed to cope with diverse neutrosophic information aggregation issues by reason that the attribute variables are frequently desparate. Nevertheless, these weighted form of MSM operators is not idempotent. Moreover, the weight MSM cannot degrade into the MSM when their weights information is equivalent. In other words, it signifies without the reducibility. To resolve two issues, we develop the single-valued neutrosophic reducible weighted MSM (SVNRWMSM) operator and the single-valued neutrosophic reducible weighted dual MSM (SVNRWDMSM) operator. Meanwhile, certain interesting properties and some special cases of the SVNRWMSM and SVNRWDMSM operators are explored in detail. Afterward, we develop two multiple attribute decision-making methods based on SVNRWMSM and SVNRWDMSM. The validity of algorithms is illustrated by an undergraduate teaching evaluation issue, along with the sensitivity analysis of diverse parameter values on the ranking. Finally, a comparison of the developed with the existing single-valued neutrosophic decision-making algorithms has been executed for displaying their efficiency.;
Collaboration of software architect and test architect helps to systematically BRIDGE product lifecycle gap;"In this position paper for the BRIDGE workshop we describe an approach used at Siemens to address the gap between high-level design and low-level implementation. This approach is a key part of our organization-wide qualification and training program for software-related roles. These roles include both a ""software architect"" and a ""test architect"" and these roles (as well as other roles) must collaborate closely as a kind of ""joint venture"".";
Ripple effect to evaluate the impact of changes in architectural design decisions;Software architectures are affected by evolution cycles when requirements or the system change. When architectural elements are modified other parts of the design can be impacted by these changes, and be propagated to all software products. As the frequency and depth of architectural changes may affect the stability of the architecture, it becomes important to estimate how stable or unstable an architecture is during evolution cycles. Although this problem has been addressed at the class level there are no clues how the underpinning design decisions that lead to architectural changes impact on the stability of designs. Existing ripple effect algorithms aimed to estimate the effect of changes in code are rarely used in architecture and to the best of our knowledge never used to analyze the stability of design decisions. We suggest in the paper a new ripple effect technique to evaluate how a change in a design decision may affect other decisions and to assess software architects on the most stable and unstable decisions. We provide a categorization of dependency types between related decisions to improve the efficiency of our ripple effect approach during the analysis of the stability of decisions and architectures.;
Uncertainty expressions in software architecture group decision making: explorative study;Software architecture can be seen as a set of architectural design decisions (ADDs) that shape the resulting software solution. To make an ADD, stakeholders follow some organization- or team-specific group decisions making process. In this study, we aimed to advance the understanding of how ADDs are made by observing and learning how architects handle uncertainties in real-life settings. We employed a multiple-case studies research method. First, we examined the discussions in task management systems of three software engineering projects. Second, we conducted interviews with the projects' software architects to investigate (a) uncertainties expressed in the observed discussions and (b) how those uncertainties are comprehended by their respective authors or readers. We systematically analyzed the interviews and derived different types of uncertainties as well as proposed a hypothesis that should be verified in the future work. Results of our qualitative study show how uncertainty is used and perceived by the software architects in the group decision-making process.;
Model-based support for decision-making in architecture evolution of complex software systems;Design decision support for software architects in complex industrial software systems, such as software ecosystems and systems-of-systems, which feature extensive reuse of third-party solutions and a variety of deployment options, is still an open challenge. We describe three industrial use cases involving considerable re-architecting, where on-premises solutions were migrated to a cloud-based IoT platforms. Based on these use cases, we analyse the challenges and derive requirements for an architecture knowledge model supporting this process. The presented methodology builds upon existing approaches and proposes a model for the description of extant software applications and the management of domain knowledge. We demonstrate its use to support the evolution and/or composition of software applications in a migration scenario in a systematic and traceable manner.;
A study about architectural requirements in a transition from product to software platform;Software ecosystems gained attention from the industry by establishing a network of users, partners, and service providers. Several companies are interested in establishing their own ecosystems due to the business advantages they bring. However, it is not clear how a company should go about doing this. This paper describes a case study about the transition from a software product to a software platform aimed at supporting an ecosystem. A software platform is responsible for managing an ecosystem's extensions, therefore its software architecture is essential to facilitate the establishment of an ecosystem. This transition is supported by a set of architectural requirements for a software platform that we introduce. We also discuss the required changes in the software product architecture to support a platform.;
Reusable architectural decision models for quality-driven decision support: a case study from a smart cities software ecosystem;Architectural design decisions and architectural knowledge are becoming relevant in the current practice of software architecture. In addition, reusable architectural knowledge has gained much importance in the industrial practice. In the process of architectural decision making, quality attributes constitute key drivers for designing software systems, therefore, it is important to document quality attributes along with the decisions captured. However, most of the current tools for management of architectural decisions focus mainly on capturing or sharing of design decisions. We propose to enrich a reusable architectural decision meta-model with quality attributes and introduce a corresponding tool. Our goal is to support software architects during decision making based on reusable decisions driven by quality attributes. Our approach was motivated by and applied in an industrial case study on a large-scale software ecosystem for smart cities, that constitute a complex and challenging system-of-systems domain. We applied our proposal in a few scenarios in the smart cities domain, in which the consideration of quality attributes is required to model reusable architectural knowledge adequately.;
Designed and delivered today, eroded tomorrow?: towards an open and lean architecting framework balancing agility and sustainability;"Architecting for cost-effectiveness, longevity and endurance has multiple, often conflicting dimensions. For instance, agile practices emphasize the need for speed in software design, development and delivery, but do not necessarily prioritize mid- to long-term qualities such as extensibility and knowledge preservation. Risk- and cost-driven architecture design methods, pragmatic modeling, and technical debt management can help practicing architects to focus their efforts, but have to be tailored to be effective (e.g., according to project context, organizational constraints, and cultural factors). Architectural styles such as service-oriented architectures and its currently trending microservices incarnation promise to improve flexibility and maintainability through their principles and patterns, but still have to prove their cost-benefit efficiency in the long run (e.g., over the multi-decade lifetime of business information systems).
This keynote presentation distills a set of open, lean and sustainable architecture practices and techniques from industrial experiences and existing work in the software architecture literature, and reports on the progress towards blending these practices and techniques into a comprehensive, yet comprehensible architecture framework. The featured assets include quality stories [1], C4 architecture modeling [2], decision sharing with Y-statements [3], architecturally evident coding styles [4], architectural refactoring [1], (micro-)services principles and patterns [5], and architecture roadmapping [6]. Examples drawn from actual case studies in multiple business sectors and industries demonstrate the applicability of these practices and techniques.
The presentation concludes with a discussion of the changes to the role of the software architect in the digital age [7]. These ongoing changes drive the identification of research problems and challenges for the practical adoption and lasting impact of the practices and techniques in the framework (and other contributions to the body of knowledge on sustainable architectures).";
Context factors perceived important when looking for similar experiences in decision-making for software components: An interview study;During software evolution, decisions related to components' origin or source significantly impact the quality properties of the product and development metrics such as cost, time to market, ease of maintenance, and further evolution. Thus, such decisions should ideally be supported by evidence, i.e., using previous experiences and information from different sources, even own previous experiences. A hindering factor to such reuse of previous experiences is that these decisions are highly context-dependent and it is difficult to identify when previous experiences come from sufficiently similar contexts to be useful in a current setting. Conversely, when documenting a decision (as a decision experience), it is difficult to know which context factors will be most beneficial when reusing the experience in the future. An interview study is performed to identify a list of context factors that are perceived to be most important by practitioners when using experiences to support decision-making for component sourcing, using a specific scenario with alternative sources of experiences. We observed that the further away (from a company or an interviewee) the experience evidence is, as is the case for online experiences, the more context factors are perceived as important by practitioners to make use of the experience. Furthermore, we discuss and identify further research to make this type of decision-making more evidence-based.;
Measuring object-oriented design principles;The idea of automatizing the assessment of object-oriented design is not new. Different approaches define and apply their own quality models, which are composed of single metrics or combinations thereof, to operationalize software design. However, single metrics are too fine-grained to identify core design flaws and they cannot provide hints for making design improvements. In order to deal with these weaknesses of metric-based models, rules-based approaches have proven successful in the realm of source-code quality. Moreover, for developing a well-designed software system, design principles play a key role, as they define fundamental guidelines and help to avoid pitfalls. Therefore, this thesis will enhance and complete a rule-based quality reference model for operationalizing design principles and will provide a measuring tool that implements these rules. The validation of the design quality model and the measurement tool will be based on various industrial projects. Additionally, quantitative and qualitative surveys will be conducted in order to get validated results on the value of object-oriented design principles for software development.;
An industrial case study of performance and cost design space exploration;Determining the trade-off between performance and costs of a distributed software system is important as it enables fulfilling performance requirements in a cost-efficient way. The large amount of design alternatives for such systems often leads software architects to select a suboptimal solution, which may either waste resources or cannot cope with future workloads. Recently, several approaches have appeared to assist software architects with this design task. In this paper, we present a case study applying one of these approaches, i.e. PerOpteryx, to explore the design space of an existing industrial distributed software system from ABB. To facilitate the design exploration, we created a highly detailed performance and cost model, which was instrumental in determining a cost-efficient architecture solution using an evolutionary algorithm. The case study demonstrates the capabilities of various modern performance modeling tools and a design space exploration tool in an industrial setting,provides lessons learned, and helps other software architects in solving similar problems.;
A role-based qualification and certification program for software architects: an experience report from Siemens;"In this experience report, we describe the motivation, experience, lessons learned, and future directions of a software engineering curriculum used at a large international company. The ""Curriculum for Software Engineers"" project, which developed the content and a role-based qualification and certification program, was started at Siemens in 2006. This paper includes an overview of various kinds of certification in the software engineering area and why we chose the knowledge- and experience-based type of certification. The experience report part focuses mainly on the ""certified senior software architect"" role, as this role has the longest history and participants from many different business units and countries.";
Who leads our future leaders?: on the rising relevance of social competence in software development;Siemens is currently developing a curriculum for several software engineering roles. Our first step was the role of Senior Software Architect. As social competence becomes increasingly important for all software professionals, we argue that reflection is the key to improve a person's skill profile. We believe that a standard component of software development education should be the ability to realistically self-assess one's own effectiveness.;
Software industry awareness on green and sustainable software engineering: a state-of-the-practice survey;Sustainable computing is a rapidly growing research area spanning several areas of computer science. In the software engineering field, the topic has received increasing attention in recent years, with several studies addressing a range of concerns. However, few studies have demonstrated the awareness of software practitioners about the underlying concepts of sustainability in the software development practice. In this effect, in this study, we aim to provide some evidence about the practitioners' perception about the adoption of sustainability in software development, under four main perspectives: economic, social, environmental and technical. To accomplish such a goal, we carried out a survey study with twenty-five software engineers involved in projects in different domains. The yielded results indicate an overall lack of knowledge about the topic, in particular regarding the concepts about sustainable software, although it is a common understanding that sustainability should be treated as a quality attribute and should support the interaction between sustainability and the software development life cycle phases. Among the observed perspectives, the respondents indicate that the technical dimension is the most relevant and explored so far. This study contributes to the field with initial evidence and can be seen as a first step towards establishing a common understanding about how the software industry is receptive to the use of sustainability concepts in software development practices.;
Adopting Continuous Delivery and Deployment: Impacts on Team Structures, Collaboration and Responsibilities;"Context: Continuous Delivery and Deployment (CD) practices aim to deliver software features more frequently and reliably. While some efforts have been made to study different aspects of CD practices, a little empirical work has been reported on the impact of CD on team structures, collaboration and team members' responsibilities. Goal: Our goal is to empirically investigate how Development (Dev) and Operations (Ops) teams are organized in software industry for adopting CD practices. Furthermore, we explore the potential impact of practicing CD on collaboration and team members' responsibilities. Method:We conducted a mixed-method empirical study, which collected data from 21 in-depth, semi-structured interviews in 19 organizations and a survey with 93 software practitioners. Results: There are four common types of team structures (i.e., (1) separate Dev and Ops teams with higher collaboration; (2) separate Dev and Ops teams with facilitator(s) in the middle; (3) small Ops team with more responsibilities for Dev team; (4) no visible Ops team) for organizing Dev and Ops teams to effectively initiate and adopt CD practices. Our study also provides insights into how software organizations actually improve collaboration among teams and team members for practicing CD. Furthermore, we highlight new responsibilities and skills (e.g., monitoring and logging skills), which are needed in this regard.";
Using Text Mining to Discover Skills Demanded in Software Development Jobs in Thailand;Comprehension of knowledge and skills expected by industry helps universities design appropriate courses and improve employability for graduates. The objective of this study is to identify current technical knowledge and soft skills required by software industry in Thailand. Text mining techniques are applied to analyze the data collected from online job portal websites. The results are summarized and reported for the design of training courses to prepare students readiness for employment.;
Refactoring community smells in the wild: the practitioner's field manual;"Community smells have been defined as sub-optimal organizational structures that may lead to social debt. Previous studies have shown that they are highly diffused in both open- and closed-source projects, are perceived as harmful by practitioners, and can even lead to the introduction of technical debt in source code. Despite the presence of this body of research, little is known on the practitioners' perceived prominence of community smells in practice as well as on the strategies adopted to deal with them. This paper aims at bridging this gap by proposing an empirical study in which 76 software practitioners are inquired on (i) the prominence of four well-known community smells, i.e., Organizational Silo, Black Cloud, Lone Wolf, and Radio Silence, in their contexts and (ii) the methods they adopted to ""refactor"" them. Our results first reveal that community smells frequently manifest themselves in software projects and, more importantly, there exist specific refactoring practices to deal with each of the considered community smells.";
Towards a theory of software development expertise;Software development includes diverse tasks such as implementing new features, analyzing requirements, and fixing bugs. Being an expert in those tasks requires a certain set of skills, knowledge, and experience. Several studies investigated individual aspects of software development expertise, but what is missing is a comprehensive theory. We present a first conceptual theory of software development expertise that is grounded in data from a mixed-methods survey with 335 software developers and in literature on expertise and expert performance. Our theory currently focuses on programming, but already provides valuable insights for researchers, developers, and employers. The theory describes important properties of software development expertise and which factors foster or hinder its formation, including how developers' performance may decline over time. Moreover, our quantitative results show that developers' expertise self-assessments are context-dependent and that experience is not necessarily related to expertise.;
A Survey of DevOps Concepts and Challenges;DevOpsis a collaborative and multidisciplinary organizational effort to automate continuous delivery of new software updates while guaranteeing their correctness and reliability. The present survey investigates and discusses DevOps challenges from the perspective of engineers, managers, and researchers. We review the literature and develop a DevOps conceptual map, correlating the DevOps automation tools with these concepts. We then discuss their practical implications for engineers, managers, and researchers. Finally, we critically explore some of the most relevant DevOps challenges reported by the literature.;
A longitudinal study of identifying and paying down architecture debt;"Architecture debt is a form of technical debt that derives from the gap between the intended and the actual architecture design. In this study we measured architecture debt in two ways: 1) in terms of system-wide coupling measures, and 2) in terms of the number and severity of architecture flaws. In recent research it was shown that the amount of architecture debt has a huge impact on software maintainability and evolution. Consequently, reducing debt is expected to make software less costly and more amenable to change. This paper reports on a longitudinal study of a healthcare communications product created by BrightSquid Secure Communications Corp. This young company is facing the typical trade-off problem of desiring responsiveness to change requests, but wanting to avoid the ever-increasing effort that the accumulation of quick-and-dirty changes eventually incurs. In the first stage of the study, we analyzed the status of the ""before"" system, which showed the impacts of change requests. This initial study motivated a more in-depth analysis of architecture debt. The results of this debt analysis were used in the second stage of the work to motivate a comprehensive refactoring of the software system. The third stage was a follow-on architecture debt analysis which quantified the improvements realized. Using this quantitative evidence, augmented by qualitative evidence gathered from in-depth interviews with BrightSquid's architects, we present lessons learned about the costs and benefits of paying down architecture debt in practice.";
An experience report on the adoption of microservices in three Brazilian government institutions;Although monolithic applications are still the modus operandi of many software systems, the microservices architecture, which favors small and independent applications, is gaining increasing popularity. This is part due to its claimed benefits, which includes better scalability, productivity, and maintainability. However, little is known about how developers and architects perceive the benefits of migrating from monolithic applications to microservices, and what are the challenges towards achieving them. In this paper we discuss the motivation, benefits, and challenges related to the migration from monolithic enterprise architectures to a microservices based architecture. We report several lessons learned that arose from a two years process faced by three Brazilian Government Institutions. We also cross-validate these findings with a survey conducted with 13 practitioners in the studied companies. The results of our investigation highlight some evidence that the adoption of microservices brought several benefits for these institutions, such as (a) reducing development time and risks related to deployment activities and (b) increasing the opportunities to experiment with different technologies and development models (such as hackathons). However, our observations reveal that the adoption of microservices is still a challenging task, mainly because it not only demands the understanding of new techniques and tools, but it also increases the need to automate tasks related to software deployment and software monitoring. This study is particularly relevant for institutions interested in adopting a software architecture based on microservices, and we are currently sharing our experiences with other institutions.;
A Review of Software Architecture Evaluation Methods for Sustainability Assessment;Building sustainability-aware software requires addressing sustainability early in the software development life-cycle. It can be ensured through Software Architecture (SA) evaluation for conformance to sustainability requirements. Typically, software sustainability needs to be assessed across four dimensions (4D): economic, environmental, social and technical. The current literature lacks information about 4D-sustainability awareness of SA evaluation methods. In this paper, we present a systematic literature review to identify, categorize and characterize SA evaluation methods from 71 primary studies to ascertain their applicability for 4D-sustainability evaluation. Our results show that the majority of the methods are scenario-based, and provide support for technical sustainability but lack 4D-sustainability coverage. We conclude that extending the steps of an existing method for sustainability combined with metric-based modeling of 4D-sustainability QAs can aid in 4D-sustainability-aware SA evaluation. Also, continuous SA evaluation needs to be explored for the sustainability of SA over time.;
Harnessing Genetic Improvement for Sustainable Software Architectures;This paper introduces a visionary approach to sustainable software engineering through the lens of genetic improvement (GI). We propose leveraging GI techniques to automatically optimize software architectures for sustainability, focusing on reducing energy consumption without compromising performance. By integrating GI with architectural design processes, we envision a future where software systems evolve towards optimal sustainability through continuous, automated refinements. Our approach not only aims to enhance the greenness of software, but also to pioneer a shift in architectural practices, paving the way for a new era of environmentally conscious software development.;
Architecting for Sustainability with the SAF Toolkit;Including sustainability concerns in software architecture design decision-making is becoming imperative. In this hands-on tutorial, we will explain the notion of software sustainability and how software architecture can be pivotal to design for sustainability, setup up metrics and measures, and ultimately create a incremental process of design, measurement, and monitoring, and reassess past decisions so that the target sustainability goals can be achieved. To this aim, the tutorial will teach the sustainability assessment framework (SAF) toolkit, an open source toolkit for software sustainability design and sustainability-quality assessment.;
Sustainable Architectural Design Decisions;"Software architects must sustain design decisions to endure throughout software evolution. Several criteria can help them assess decisions' sustainability. In addition, industry and research projects have applied different techniques to make architectural design decisions sustainable; their examples offer solutions and lessons learned.";
MORPHOSIS: A Lightweight Method Facilitating Sustainable Software Architectures;Managing the cost-effective evolution of industrial software systems is a challenging task because of their complexity and long lifetimes. Limited pro-active evolution planning and software architecture erosion often lead to huge maintenance costs in such systems. However, formerly researched approaches for evolution scenario analysis and architecture enforcement are only reluctantly applied by practitioners due to their perceived overhead and high costs. We have applied several recent sustainability evaluation and improvement approaches in a case study to the software architecture of a large industrial software system currently under development at ABB. We combined our selection of approaches in a lightweight method called MORPHOSIS, for which this paper presents experiences and lessons learned. We found that reasonable sustainability evaluation and improvement is possible already with limited efforts.;
Sustainability-Aware Software Architecting for the Future Cloud;The ever-increasing digitization has created the need to address global sustainability goals at the software level. Designing the architecture for the sustainability of software-intensive systems is a grand challenge of contemporary software engineering. For cloud-based solutions, where software, platform and infrastructure are delivered as-a-service (XaaS), this under-taking becomes even more challenging due to the opaqueness of services and the diverse set of stakeholders involved. In the context of cloud computing, the primary focus of research has been on addressing the energy consumption and carbon footprint of data centers in terms of their environmental impact. This creates an emerging need to assess sustainability across other sustainability dimensions for its social, economic and technical impacts, too. Through our research, we aim to develop a sustainability-aware architecting framework for Cloud-Based Software Services (CBSSs) that enables practitioners to evaluate and design sustainability-aware architectures. We envision this framework to consist of guidelines, tactics, tools, or methods for delivering sustainability-aware architectures for CBSSs. Furthermore, we aim to evaluate the sustainability awareness of such architectures through sustainability indicators across all four sustainability dimensions (4D-sustainability) i.e. economic, technical, environmental and social.;
A survey on software architecture evaluation methods;Software architecture evaluation in software systems is an important practice to develop quality software. Evaluation is performed to analyze software architecture to reduce the possibility of risks and verify quality requirements, which are addressed during software design. Several methods and techniques have been proposed to evaluate software architecture based on quality attributes. This paper presents the comparative analysis of scenario-based software architecture evaluation methods using taxonomy. The observations will be useful to design an effective architecture evaluation method.;
Creating adaptive software architecture dynamically for recurring new requirements;Software products need to evolve continuously in order to meet the arising needs of the market. Therefore, the new requirements or the rapid context changes are common in software products. Several types of studies have addressed the adaptive architecture issue in Software Product Line Engineering. Several tools and techniques have been proposed but for the evolution of Software Product Line, there is no process that would consider step by step activities from requirements analysis to the creation of dynamic adaptive software architecture. We propose an adaptive architecture designing process that systematically defines those activities for developing adaptive architecture. Our process continuously elicits new requirements from social network services that trigger our architecture adaptation. We introduce a variability monitoring agent to investigate the change in variability model, and the agent decides whether the architecture must be reconfigured or not depending on the change. Our process may support fast accommodation of market needs, and then can improve sustainability of software systems.;
A Framework of Software Architecture Principles for Sustainability-driven Design and Measurement;Aviation connects our world by efficiently and rapidly moving people, opening new economic opportunities and transporting food and goods globally. But the notable growth of air travel in recent years has led to increasingly crowded airspace. According to the 2019 European Aviation Environment Report, aviation is responsible for about 3% of global CO2 emissions, which translates into a big ecological impact. It is imperative to steer the aviation industry towards optimizing resources, reducing costs, improving decision-making and increasing systems’ resilience to unexpected events. In this work, we study the sustainability impact of software architecture principles at Amsterdam Schiphol Airport. To this aim, we create a framework that relates architecture principles with sustainability concerns, with the aim of seeking the right balance toward a positive impact on the sustainable development of the organization and its services. We combine techniques like OGSM and Decision Maps to extend the current architecture principles, and elicit Key Performance Indicators from current industrial practice. The resulting framework is the first step towards adopting sustainability in architecting and laying the foundation to monitor the effectiveness of the implemented architecture principles on the target sustainability goals of the organization.;
Variability Features: Extending Sustainability Decision Maps via an Industrial Case Study;Over the years, various thinking frameworks have been developed to address sustainability as a quality property of software-intensive systems. Notwithstanding, which quality concerns should be selected in practice that have a significant impact on sustainability remains a challenge.In this experience report, we propose the notion of variability features, i.e., specific software features which are implemented in a number of possible alternative variants, each with a potentially different impact on sustainability. We extended sustainability decision maps to incorporate these variability features into an already existing thinking framework. Our findings were derived from a qualitative case study and evaluated in an industrial context. Data was collected by analysing a real-world application and conducting working sessions together with expert interviews.The variability features allowed us to identify and evaluate alternative usage scenarios of one real-world software-intensive system, enabling data-driven sustainability choices and suggestions for professional practices. By providing concrete measurements, we can support software architects at design time, and decision makers towards achieving sustainability goals.;
Roadmap for building effective complex enterprise architecture in digital transformation: An experience-based industry best practices summary;Enterprise software architectures play a critical role in present day digital transformations for building complex software systems and influence their overall performance. Enterprise architecture also influence the software systems sustainability to induct design changes for evolving business requirements. They provide high-level abstraction by representing structural and behavioral properties of software system and represents multiple views addressing the needs of diverse stakeholders of business organizations. This paper is an attempt to share our long-stint industry and research experiences, and best practices — that were gathered through multi-continent MNCs, various domains, tools and technologies — as a roadmap for building an effective complex enterprise architecture in this current day digital transformation era which is technology agnostic. It defines various types of architectures that are applicable in software systems design which address various problems within the context of customer and system requirements.;
Architecture Design Decision Maps for Software Sustainability;"In software engineering, sustainability can be defined as the ""capacity to endure"" and to ""preserve the function of a system over an extended period of time"". These definitions mainly point towards technical sustainability over time. Sustainability, however, may entail a much broader scope including economic, social and environmental sustainability as well. In spite of the exciting hype around sustainability, we are very much lacking suitable instruments to design software-intensive systems that are sustainable and enable sustainability goals. To fill this gap, we advocate the treatment of sustainability as a software quality property and define a software sustainability assessment method that helps make sustainability-driven design decisions. The method essentially relies on the definition of so-called ""decision maps"", i.e. views aimed at framing the architecture design concerns around the four sustainability dimensions mentioned above - technical, economic, social and environmental sustainability. This paper presents the notion of decision map. We use two illustrative examples extracted from industrial projects, to summarize our lessons learned and reflections.";
Sustainability in Software Architecture: A Systematic Mapping Study;"Sustainability is an increasingly-studied topic in software engineering in general, and in software architecture in particular. There are already a number of secondary studies addressing sustainability in software engineering, but no such study focusing explicitly on software architecture. This work aims to fill this gap by conducting a systematic mapping study on the intersection between sustainability and software architecture research with the intention of (i) reflecting on the current state of the art, and (ii) identifying the needs for further research. Our results show that, overall, existing works have focused disproportionately on specific aspects of sustainability, and in particular on the most technical and ""inward facing"" ones. This comes at the expense of the holistic perspective required to address a multi-faceted concern such as sustainability. Furthermore, more reflection-oriented research works, and better coverage of the activities in the architecting life cycle are required to further the maturity of the area. Based on our findings we then propose a research agenda for sustainability-aware software architecture.";
Learning from Failure;Growing evidence reveals that failures—whether in the classroom, at work, or in people’s personal and social lives—are difficult to learn from. Traditionally, researchers have focused on the self-threatening nature of failure as the culprit for why people struggle to learn from their past blunders. Here, we show that beyond the emotional barriers to learning from past failures (e.g., failure is unpleasant), there are also cognitive barriers (e.g., failure seems uninformative). These barriers arise when people fail to achieve their current goals (during goal striving) and when they decide whether to pursue new goals at all (during goal setting). We discuss interventions that promote learning from failure to overcome these distinct psychological barriers at each stage of goal pursuit.;
Sustainability Debt: A Portfolio-Based Approach for Evaluating Sustainability Requirements in Architectures;"Architectural Sustainability refers to the ability of an architecture to achieve its goals while sustaining its value on dimensions related to environmental, social, economic, individual and/or technical during its operation and evolution. While the process of architectural design implies a fit between the requirements, system conditions and constraints; incomplete information and uncertainty may increase the cost of the architecture, introduce risks, alter its value and influence the extent to which it can evolve and sustain. We propose an economics-driven architectural evaluation method which extends the Cost Benefits Analysis Method (CBAM) and integrates principles of modern portfolio theory to control the risks when linking sustainability concern to architectural design decisions. The method aims at identifying portfolio(s) of architecture design decisions which are more promising for adding/delivering value while reducing risk on the sustainability dimensions. The method quantifies the sustainability debt of these decisions. The ultimate goal is to develop an objective decision-support framework for reasoning about sustainability requirements in relation architecture decisions in the presence of uncertainty. We evaluate the approach with an Emergency Deployment System (EDS). The results show that the method can make the value, cost and risks of architectural design decisions and sustainability requirements explicit.";
Guiding Architectural Decisions with the Influencing Factors Method;The influencing factors (IF) method guides the architect through stakeholders' concerns to architectural decisions in line with current business goals. The result is a set of requirements on software quality attributes and business goals and highlighted trade-offs among software quality attributes and among business goals. The IF method is suitable for sustainable software systems since it allows new concerns, resulting from changes in business goals, stakeholder concerns, technical environment and organization, to be added to existing concerns.;
Measuring Architecture Sustainability;It's difficult to express a software architecture's sustainability in a single metric: relevant information is spread across requirements, architecture design documents, technology choices, source code, system context, and software architects' implicit knowledge. Many aspects influence economic sustainability, including design decisions facilitating evolutionary changes, adherence to good modularization practices, and technology choices. An approach that focuses on a single artifact or perspective is likely to neglect important factors. ABB Corporate Research is tracking the architecture sustainability of a large-scale industrial control system currently under development. A former version of the system grew to several million LOC and suffered from architecture erosion and high maintenance costs. A multiperspective approach called Morphosis will help avoid such a situation in the future by focusing on requirements, architecture design, and source code. It includes evolution scenario analysis, scoring of technology choices, architecture compliance checks, and tracking of architecture-level code metrics.;
Estimating the Complexity of Architectural Design Decision Networks;The stability and longevity of software systems rely on the quality of design decisions over time. In modern software-intensive systems the number of design decisions taken, the dependencies between those decisions, and the number of design alternatives considered, complicate software maintenance and jeopardize the system's longevity. Despite the existence of complexity metrics applied to code, there is a lack of metrics for design decisions. As estimating the complexity of a set of design decisions is needed for understanding the difficulty of software evolution, this paper proposes and validates a new metric to estimate the complexity of decision networks. The metric is based on decision topologies and provides a way to understand the complexity of decision sets and reason about the maintenance difficulty. We validate our metric empirically in two different ways: (i) evaluating the complexity of two service-based platform systems, and (ii) analyzing the evolution of complexity in four open-source projects and compare how the evolution of complexity affects to the architecture in one of the open-source projects. Our results show that certain network topologies are more difficult to maintain, so we provide a set of tactics to reduce the complexity of design decision networks.;
Sustaining Agility through Architecture: Experiences from a Joint Research and Development Laboratory;"This paper is an experience report of a long running Scrum project, conducted in a collaboration between industry and research, in a so called ""Joint Research and Development Laboratory"". Over time in the collaboration, we experienced a constant decrease in the pace of our development progress. Planning forward only within the limits of single sprints was the main reason for this. It resulted in a degenerating design and therefore a lack of flexibility that affected the agility of our project. Therefore, we introduced the concept of ""epic-architectures"", an architecture design for a coherent group of user stories. Shifting the planning horizon further, across single sprints, helped us to create more stable and reusable concepts and to construct simpler, more elegant, and more maintainable solutions. We were able to significantly reduce the refactoring effort and increase the development speed, without significant overhead. With reporting on our experiences we hope to provide practically applicable guidance on how to integrate lightweight architecting in agile development processes, to sustain agility while creating high quality products.";
Research on key technologies of knowledge-based engineering decision support system for circular economy;This paper combines with the characteristic of knowledge-based engineering decision problem for circular economy, analyses knowledge representation, rule representation, reasoning mechanism and knowledge base structure of multi-objective attribute decision problems. It proposes a software architecture of knowledge-based engineering decision support system, which lays the foundation for the realization of the dynamic monitoring of the basic conditions of regional sustainable development and accurately reflecting on the relationship of the various elements and the evolution of the process.;
A Microservice-based Software Architecture to Enhance Collaboration among heterogenous stakeholders operating in the Research Domain;Research centers or universities daily produce interesting research products thanks to their ecosystem of laboratories and small spin-offs, but this ecosystem frequently has purely academic vision and does not easily meet the demand of the productive world. At the same time, the productive world is more aware of the market needs and, although it always looks for new solutions to be designed in collaboration with the academic world, it lacks the necessary contacts and connections. This paper presents a microservice-based software architecture designed to facilitate connections between researchers and any stakeholder interested in research outcomes while also accelerating the digital transition towards a more sustainable and smart world. Within the paper, the proposed system architecture is described and functionally validated as a first step in the development of such a similar solution and to provide a useful hint for future works to researchers and experts interested in its application.;
Toward Architecture Knowledge Sustainability: Extending System Longevity;Complex software systems often require continuous refactoring to ensure longevity in the face of changing requirements. Architects can exploit the concept of architecture knowledge sustainability to measure and increase their architectures' quality, longevity, and stability.;
Practitioner's guide for building effective complex enterprise architecture in digital transformation: An experience-based industry best practices summary;Enterprise software architectures have profound influence on present day digital transformations in any complex software systems building and overall performance. Enterprise architectures also influence the software systems sustainability to induct design changes for changing business requirements. They provide high-level abstraction by representing structural and behavioral properties of software system and represents multiple views addressing the needs of diverse stakeholders of business organizations. Software architecture of a software application will be at the core in deciding the success or failure of any software system. In a typical enterprise software architecture, key design decisions that address the needs of diverse stakeholders are captured under various architectural headings and unfortunately, the usage of these terminologies have been context based leading to ambiguity. This paper attempts to explain a systematic approach in eliciting key architectural design considerations and various aspects to be considered in formulating Business Architecture, Application Architecture, Data Architecture and Technology Architecture which are key components of any Enterprise Architecture. Also, this paper unveils various types of services that are to be identified that they play in software architecture formulation.;
Quantitative evaluation of software architecture;The function and significance of mission-critical software intensive systems have got substantial recognition. Software architecture has become a new field since system software are all the time more intricate. Agile software development counters the advancement in requirement, besides to attend to the fixed plan. In this paper, effort has been made to find parameters for software architecture evaluation and then evaluate software architecture under agile environment based on the determined parameters.;
Software Architecture for Process Simulation in Biogas Plants;The work substantiates the use of modern information technologies and mathematical modeling based on the analysis of interval data as effective process management tools in biogas plants. The use of interval modeling allows you to build models with guaranteed prognostic properties. The article also presents the features of building the software architecture for mathematical modeling of processes in biogas plants. The main aspects of the implementation of software for modeling processes in biogas plants are described, the feature of which is the software interpretation of interval discrete models and an open service-oriented architecture, which ensures their integration into existing control systems of biogas plants and allows to control biochemical processes in real time and thereby increase efficiency of functioning of biogas plants. A number of diagrams illustrating the features of the software implementation of the environment for simulating processes in biogas plants are given, and the specifics of its implementation into the SIMBA#biogas universal system of simulating and simulating the operation of biogas plants are described.;
Decision Aid for Sustainable Industrial Siting;For sustainable industrial development, the need of the hour is judicious, reasonable and planned use of the finite resources of land, according to the natural environmental properties. To cater to this need, we are using geographic information systems and spatial decision support systems techniques to help proper siting of newly planned industries and industrial estates. This software tool is especially meaningful in developing and transition economy countries, where the process of sustainable industrialization is still in its initial stage. The authentic spatial decision making algorithm, as well as underlying software architecture will be presented in detail in this paper.;
A Framework for Catering Software Complexity Issues Using Architectural Patterns;Software systems need to be maintained and updated regularly to meet new requirements and to adapt to improvements in technology. However, every time an update is made, more codes are added that result in the increasing complexity of the software. High complexity in software makes it challenging for developers to update and maintain. To improve the complexity issues in software systems, architectural patterns play an important role. With the in-built concept of modularity in architectural patterns, they have a general tendency to reduce the complexity of software systems. This also improves other quality factors of the software, such as maintainability and testability. This research is conducted to study the impact of commonly used architectural patterns on different types of applications by applying the patterns on both desktop and web-based applications. As per the findings of the literature review, the survey results, and the empirical evaluation, it proves that complexity issues in software can be improved using architectural patterns. The findings of this research is used to propose a framework for improving complexity issues in software using architectural patterns. This framework will help stakeholders to reduce complexity by choosing suitable architectural patterns.;
Refactoring Decision Support for Developers and Architects Based on Architectural Impact;Refactorings are key activities for achieving sustainable software systems. However, refactorings demand high effort and features are often deemed more important. The time pressure to deliver is always high and to select important refactorings, one has to consider manifold criteria. Current approaches only relate to code smells and design flaws, and do not take architectural impact into consideration. The project aims at developing a decision framework integrating architecture smell detection, selection of appropriate refactorings and impact analysis to prioritize refactorings and support not only developers but also software architects. It shall be evaluated using control groups by measuring and comparing the required time and the resulting software quality.;
Relating Architectural Decay and Sustainability of Software Systems;Ensuring the longevity of a software system is an important concern for developers and maintainers. However, when a system's architecture decays during evolution and its quality degrades as a result, the system's long-term sustainability is highly affected. In this light, providing mediums to estimate and track the sustainability of a software system is necessary to help engineers stay aware of system health. Most existing techniques and tools estimate the level of sustainability in code, paying significantly less attention to the analysis and understanding of architectural decay. This position paper provides a taxonomy of architectural smells, metrics, and their impacted quality properties. We relate these smells to maintenance and evolution areas as a first step toward our ultimate goal of estimating the sustainability of systems. We finally report some initial results drawn from a set of subject systems as promising future work using our taxonomy.;
A Synthesis of Green Architectural Tactics for ML-Enabled Systems;The rapid adoption of artificial intelligence (AI) and machine learning (ML) has generated growing interest in understanding their environmental impact and the challenges associated with designing environmentally friendly ML-enabled systems. While Green AI research, i.e., research that tries to minimize the energy footprint of AI, is receiving increasing attention, very few concrete guidelines are available on how ML-enabled systems can be designed to be more environmentally sustainable. In this paper, we provide a catalog of 30 green architectural tactics for ML-enabled systems to fill this gap. An architectural tactic is a high-level design technique to improve software quality, in our case environmental sustainability. We derived the tactics from the analysis of 51 peer-reviewed publications that primarily explore Green AI, and validated them using a focus group approach with three experts. The 30 tactics we identified are aimed to serve as an initial reference guide for further exploration into Green AI from a software engineering perspective, and assist in designing sustainable ML-enabled systems. To enhance transparency and facilitate their widespread use and extension, we make the tactics available online in easily consumable formats. Wide-spread adoption of these tactics has the potential to substantially reduce the societal impact of ML-enabled systems regarding their energy and carbon footprint.;
On the need to merge architectural and infrastructural considerations;This work takes the position that attempting to keep a separation between the logical and deployment view of modern, cloud-native software systems only leads to a new type of technical debt that manifests during the operational side of the lifecycle. This is an issue that is fueled by the treatment of software qualities without considering where the systems under consideration are supposed to be deployed, and how long it takes until positive or negative treatments on these qualities manifest themselves. Sustainability is a particularly interesting case of a quality that requires logical and deployments views to be taken into account in a unified way.;
A sustainable software architecture for home care monitoring applications;The Ageing of population is a major concern for Western societies and leads to the development of new solutions to improve home care for elders, in order to delay their admission in specialized institutions (retirement house, healthcare facility and so on). These new solutions can be hardware or software based, and most often rely on home automation (e.g. motion sensors, temperature, light...). These sensors are used to monitor elderly or disabled people in order to detect their activities and the potential accidents that may occur. In this paper, we present a software architecture based on interoperable components for home care solutions. This architecture considers two kinds of components: the data providers, for instance a motion sensor, and the data consumers that process sensor data in order to infer higher level information such as a fall detector. The overall architecture is loosely coupled by design, in order to ease the addition of new sensors and of new functionalities.;
A Software Architecture for Video Analytics;Video analytics is the automatic understanding of complex events occurring in a captured scene, by artificial intelligence. It is a fundamental task for homeland security and crime prevention. Some video analytics tasks are being addressed by at the edge processing approach, which combines algorithmic with hardware development, within the camera system design. The at the edge processing approach looks for real-time performance on specific domains and low network bandwidth requirements. However, it implies that the already installed city-camera-network should be replaced and continuously updated since it introduces constraints to analytics capabilities related to cameras' characteristics and functionalities. Thus, city surveillance by the at the edge processing approach requires a large budget, and continuous investment, to keep the system working. In this paper, we present both faced challenges and obtained achievements during the design process of video-analytics-system software architecture. Interoperability, availability, and security were the prioritized quality attributes by the Quality Attribute Workshop method. A microservices and cloud-based design was the result of applying the Attribute Driven Design method, incorporating software engineering sustainability concerns. As a practical advantage, the designed system can work with the already installed city surveillance camera network and allows incorporating video analytics algorithms as the surveillance system evolves. The evaluation combined the functional and operative prototype as well as the ATAM method, according to which approach is more suited to evaluate a specific driver. The discussion on findings of design an evaluation processes is a takeaway for the reader.;
Sustainability Integration of Artificial Intelligence into the Software Development Life Cycle;The onslaught of artificial intelligence (AI) in the global scientific and industrial landscape has brought with it far-reaching implications into how the software development process can be transformed. This article presents a systematic literature review focused on the integration of AI into the software development life cycle (SDLC) with a specific emphasis on sustainability. The research explores the application of AI in all facets of the SDLC. To this end, we structure 34 primary studies into the different stages of the SDLC, including requirements elicitation, analysis/design, development, testing, and deployment, while considering multiple dimensions of sustainability. Our findings present a synthesis of commonly used AI approaches under various aspects. These encompass guidelines for (i) automating requirements formulation, (ii) designing sustainable software, (iii) enhancing energy efficiency and code reuse, and (iv) effectively testing software. Environmental sustainability was found to be the most common dimension in the literature, primarily addressing energy efficiency and electronic waste. Additionally, we identify gaps in the literature, particularly the absence of addressing AI in SDLC from the angle of social sustainability and the lack of integration into developer toolkits.;
To train software engineers with principles of sustainable development: a bibliometric study;Sustainability and environmental impact are important factors to consider in the software industry and especially in the training of the professionals who produce it. The non-renewable and increasingly limited resources of our planet generate the need to train engineers in the software area to assume their responsibility for sustainable development. Progress should be made in the inclusion of sustainable development principles in the curricula in the training of future software engineers. This article presents an analysis and monitoring of scientific publications, using bibliometric indicators in order to obtain and provide information on current research trends in the training of professionals in the area of software engineering with principles of sustainable development. For this reason, we conducted a bibliometric study of the Scopus database over the last 10 years, between 2010 and 2019, focusing on keywords such as software, education, teaching, learning, sustainable development and their respective variations. A systematic review method was used in this work, which produced an initial result of 581 papers. Subsequently, it was filtered through the thematic area of Computer Science, obtaining 232 documents. Subsequently, it was filtered by the Sustainable Development and education keywords, additionally filtering by documents type articles and conference publications for a result of 186 documents that resulted in 116 publications with at least one citation and 70 publications with zero citations. The analysis was performed using the search results analysis tool provided by Scopus and, in addition, VOSViewer as a tool to build and visualize bibliometric networks. The differential contribution of this study lies in the filtering, organization and analysis of 186 publications that allows it to be a source of bibliometric information that is expected to be an instrument that helps to focus future research in the area of sustainable software development. Overall and in accordance with the bibliometric indicators taken into account in this work, it is generally concluded that the Latin American region has very low impact production in the study area, than the areas of software engineering with the highest volume of Research related to sustainable development are requirements engineering, software design and architecture.;
Quantitative models and software architecture;"The development of multi-tier architecture based on knowledge and model driven for the competitiveness is discussed in Higher Education; the engine are Mathematical and Computational Models for dynamic and structural analysis of the academic governance given the student high dropout. The problem is characterized by the high social and economic costs; the layers mentioned, mainly are: Institution issues, Users (3-student levels, Faculty Teachers and Parents) and the data and knowledge, enabling management of multiple piece inter-connected environments, focusing on the governance with its sustainability impact into quality, productivity and competitiveness. Data architecture gives several figures on desertion, costs (families, institutions). The period of observation, the student's retention figures were increased significantly and the desertion control was also improved.";
Selection of quantum computing architecture using a decision tree approach;Richard Feynman proposed the idea of quantum computing for the first time in 1982 (R. P. Feynman, 1982) [1]. In the last few years, various industries have started accepting quantum solutions to their business problems. Universal quantum computers are being built by Industry tech giants to solve problems in business, engineering, and science. A variety of quantum software projects are being developed using different quantum devices, algorithms, frameworks, and quantum programming languages. To correctly identify the problems that show promise for quantum advantage, to develop proof-of-concept implementations of quantum solutions, and to actually develop software implementing these solutions is a challenging feat. This paper helps ease the decision-making process in choosing the right software architecture based on the type of the quantum project.;
Building Sustainable Software by Preemptive Architectural Design Using Tactic-Equipped Patterns;Sustainability of software architectures has gained increasing attention to cope with factors causing architectural changes such as requirements changes, technological changes, and changes in business strategies and goals. However, there has not been much work on architectural sustainability. In this paper, we present a novel approach for addressing architectural sustainability with respect to non-functional requirements changes through preemptive architectural designs built upon the combined use of architectural patterns and architectural tactics. The approach presented in this paper provides a strategic solution for practitioners to building a quality attribute into a chosen architectural pattern to proactively deal with the requirements changes of quality attribute, which may arise after the construction phase.;
Value-Focused System Quality;"Experts never tire of emphasizing that software architectures should support appropriate system qualities to be useful and sustainable. Experience, in contrast, shows that the architectures of many software systems are casually, even haphazardly, structured, making it hard to sufficiently support any system quality. The author thus advocates a design style that takes the value that nonfunctional qualities contribute to a system's business success as the ultimate measure to decide what operational and developmental qualities a system really needs, where in a system the qualities are needed, and how ""good"" these qualities must be.";
Embedded computer software loader/verifier implementation using a hardware and software architecture based upon best practices derived from multiple spiral developments and the joint technical architecture;The focus of this paper is to examine the concept of utilizing commercial-off-the-shelf (COTS) products and interfacing the products to design and implement a solution to the diverse requirements of ground support equipment for military aircraft. The challenge of sustainability during the life cycle of specific ground support equipment is examined from multiple viewpoints. The decisions and resolutions associated with using and supporting COTS products is also presented. During our examination, existing products are described, an architecture for each implementation is derived, and the strengths and weaknesses of our solution are explored. Finally, a root cause analysis for the problem of COTS interface architectures implementation in the support equipment environment is presented.;
Framing a Sustainable Architecture for Data Analytics Systems: An Exploratory Study;"Data analytics systems (DAS) with Big Data capabilities have started playing a promising role in online service ecosystems and large-scaled interconnected systems of many enterprises. The rapid development of analytics models and technologies, along with affordable infrastructures and accumulated data repositories, leads to encouraging expectations on DAS, while also bringing challenges in terms of how to deal with the increased development complexity. However, systematic methodologies for designing a sustainable DAS are still missing. To harness the dynamics raised by technology evolution, ambiguous requirements, under-explored data environments, and so on, framing a sustainable software architecture turns out to be a critical task. By exploring the complex nature of DAS, we propose a novel approach, SstADDAS (Sustainable Architecture Development for DAS), to provide practical guidelines for architecture development. A shock absorber mechanism is presented to harness the dynamics of DAS and facilitate the development of a sustainable architecture; the ’long decision chain’ challenges are handled with a generic process model; and collaborations and responsibilities of participants are suggested to enable better model implementation. SstAD-DAS allows architects to accommodate the long decision chain, leverage skill sets from multiple contributors, and evaluate architectural decisions continuously. Finally, this paper demonstrates the capability and usability of SstAD-DAS by sharing experiences and observations from the continuous development of an intelligence analysis system.";
Building Sustainable Software for Sustainable Systems: Case Study of a Shared Pick-Up and Delivery Service;Sustainability has become a major concern of the 21st century. With the digital revolution, ICT is actually part of both the problem and the solution. Despite this, sustainability-related design decisions are often left implicit and result from a process involving synergies and trade-offs among many non-functional requirements, including some constraints related to the software development and operation itself. The purpose of this paper is to identify such decisions and analyse the process that resulted into them based on a real-world industrial case with strong sustainability goals: a shared pick-up and delivery service. We also show how available methods for green software engineering help in better shaping this process and highlight some interesting lessons learned from our experience.;
Architecture Quality Revisited;There is a common belief in the software community that nonfunctional quality is fundamentally important for architecture sustainability and project success. A recent study, however, suggests that nonfunctional quality is of little relevance for users and customers, but instead mainly a concern for architects. Nontechnical constraints, such as licenses and technology providers, appear to be driving design as prominently as quality requirements. Quality requirements, such as performance, are mainly defined by architects on the basis of their experiences, and are often poorly documented and validated. This column explores whether the software community actually overestimates the relevance of nonfunctional qualities or whether the study's observations indicate a valid position on nonfunctional quality for certain types of application domains, development approaches, and organizational setups.;
A viewpoint-based evaluation method for future Automotive Architectures;The Automotive industry undergoes a major transformation. Alternative powertrains, automated driving and Vehicle-to-Everything (V2X)-communication impose new requirements for vehicle development. Automotive software (SW), hardware (HW) and Vehicle Electronics combined in Electrical/Electronic architectures (E/E-architectures) play a key role in the paradigm change. An evolution from function-oriented, distributed architectures towards domain-or even vehicle-centralized architectures is expected. Even so, the question of evaluating architecture alternatives based on quality characteristics is unsolved. Then again, measuring an E/E-architecture’s quality and suitability is necessary for developing appropriate, use case specific solutions to support a sustainable transformation. By designing a method to evaluate design alternatives for the E/E-architecture of vehicles, combining different viewpoints and evaluation metrics, a contribution to this transformation can be provided. In this work such a viewpoint-based architecture framework enabling a holistic E/E-architecture assessment is introduced. Metrics substantiating these viewpoints are linked to the model. Finally the proposed procedure is demonstrated in the context of a simplified use case.;
On Architecture Styles and Paradigms;Sustainable software architectures portray the fundamental properties of their application domains explicitly, to ensure the virtual world can 'mimic' the real world appropriately. Using Problem Frames and Domain-Driven Design, pragmatic architects get concrete guidance for choosing the 'right' architecture styles, paradigms, and realization technologies.;
Towards Architecting Sustainable MLOps: A Self-Adaptation Approach;In today's dynamic technological landscape, sustain-ability has emerged as a pivotal concern, especially with respect to architecting Machine Learning enabled Systems (MLS). Many ML models fail in transitioning to production, primarily hindered by uncertainties due to data variations, evolving requirements, and model instabilities. Machine Learning Operations (MLOps) offers a promising solution by enhancing adaptability and technical sustainability in MLS. However, MLOps itself faces challenges related to environmental impact, technical mainte-nance, and economic concerns. Over the years, self-adaptation has emerged as a potential solution to handle uncertainties. This paper introduces a novel approach employing self-adaptive principles integrated into the MLOps architecture through a MAPE-K loop to bolster MLOps sustainability. By autonomously responding to uncertainties, including data, model dynamics, and environmental variations, our approach aims to address the sustainability concerns of a given MLOps pipeline identified by an architect at design time. Further, we implement the method for a Smart City use case to display the capabilities of our approach.;
Reducing Friction in Software Development;Software is being produced so fast that its growth hinders its sustainability. Technical debt, which encompasses internal software quality, evolution and maintenance, reengineering, and economics, is growing such that its management is becoming the dominant driver of software engineering progress. It spans the software engineering life cycle, and its management capitalizes on recent advances in fields such as source code analysis, quality measurement, and project management. Managing technical debt will become an investment activity applying economic theories. It will effectively address the architecture level and will offer specific processes and tools employing data science and analytics to support decision making. It will also be an essential part of the software engineering curriculum. Getting ahead of the software quality and innovation curve will inevitably involve establishing technical-debt management as a core software engineering practice. This article is part of a special issue on the Future of Software Engineering.;
Application of SQuaRE and Generalized Nets for extended validation of CE systems;The need to develop robust, quality software architectures is more critical than ever today due to the significant complexity, size and interoperability requirements typical of modern systems. Rather than wait until the architecture, design and potentially implementation phases have been completed, this paper proposes that evaluation and testing methods should be applied during the architectural phase itself, and should be rooted in standard methodologies and processes, then complementary checked through the usage of Generalized Networks (GN) theory by a simulation platform. To guarantee the quality of the architecture the ISO/IEC CD 2504n of the SQuaRE series of standards (which describes a process for evaluating the quality of software products and also describing the requirements for the components of an architecture), are adopted as a reference methodology. (GN) is a tool for Discrete Event Simulation (DES), which is equally well suited for modelling simple and large, complex systems. For a complete assessment of quality, GNs seems to be a proper complement for the validations of the dynamics of the interoperable system, after tested by the quality procedure of SQuaRE. With these, a complete system can be validated through visualization, specification, simulation, analysis, development, and report-out of the test and evaluation procedures that is applied to the architecture and its components. By applying these quality assessment techniques earlier in the software development lifecycle, it is predicted that churn of both code and the architecture itself can be reduced. This would deliver improvements in the quality, reliability, consistency and indeed sustainability of the architecture and its implementations, compared when just either SQuaRE or GNs are used separately.;
An approach to design a robust software architecture and an intelligent model for multi-agent systems;A successful multi-agent system requires the intelligent agents to perform within a dynamically complex environment where proper and quick response in a cooperative manner is a primary key to successfully complete a task. This paper proposes a non-deterministic decision making method using electric fields and high-level decision making. Different layers are designed, defined, and implemented for the software architecture with focus on system adaptability, sustainability, and optimization. Consequently, a software architecture is proposed in this paper to complement the AI algorithms. The proposed architecture aims to provide a well-structured and managed system for control, behavior, and decision making of multi-agent systems. The proposed decision making approach in this paper is based on layered artificial intelligence implemented using vector-based fuzzy electric fields and a decision tree. Furthermore, an approach to model the world which, in this paper, is called Agent Relative Polar Localization is introduced. This world model is based on fuzzy measurements and polar coordinates. In order to optimize the overall performance of the system learning methods have been introduced to the system. The proposed system in this paper has been implemented on soccer robots to evaluate the performance of the system. The results show that the proposed system implemented on the soccer robots is reliable and robust.;
A review on quality models to analyse the impact of refactored code on maintainability with reference to software product line;Code cloning is a major problem in object oriented methodology and advanced software methodologies like Software Product Line methodology (SPL). SPL Maintainability is a critical quality factor which is influenced by code cloning detection and correction. There are quality models to study and analyze such impacts. But existing quality models fall short in assessing the impact of code clones on them. Since SPL maintainability is one of the key factors when considering software quality, our study revolves around it. Also, the fact that not much experiments have been performed to assess and measure the impact of refactored code on SPL maintainability, we wish to divulge in that particular area. A review has been done which validates the need to quantify SPL maintainability before and after it has been refactored.;
Software Engineering Education: Towards Ethical;"In this paper, we present our experience with an innovative pedagogical approach to software engineering in a graduate-level advanced software engineering course. Our approach to software engineering and software design education relies on six dimensions: 1) restating the goal of software engineering education to say that software must be conceived of, architected, designed, developed, deployed, maintained, and managed to be ethical, reliable, and beautiful; 2) software should be engineered as a service; 3) apply proven architectural principles; 4) use sound design principles; 5) create rapid multi-modal prototyping; and 6) bring the course learning objectives together by creating a term-long project that creates a solution to a real-world problem using an iterative process. The results from students' feedback have been very positive with students citing the benefits of the course particularly a) the realignment of software engineering education goals centered on creating ethical, reliable, and beautiful software, b) the focus on clean, sound, and efficient architectures, and c) blending of IEEE SWEBOK, modern microservice architectures, and emerging approaches from software engineering research and open source. We plan to continue developing the course and enhance it in the areas of software reuse, software product design, AI and software design, design for diverse users, and design for sustainability.";
Balancing Progress and Responsibility: A Synthesis of Sustainability Trade-Offs of AI-Based Systems;Recent advances in artificial intelligence (AI) capabilities have increased the eagerness of companies to integrate AI into software systems. While AI can be used to have a positive impact on several dimensions of sustainability, this is often overshadowed by its potential negative influence. While many studies have explored sustainability factors in isolation, there is insufficient holistic coverage of potential sustainability benefits or costs that practitioners need to consider during decision-making for AI adoption. We therefore aim to synthesize trade-offs related to sustainability in the context of integrating AI into software systems. We want to make the sustainability benefits and costs of integrating AI more transparent and accessible for practitioners. The study was conducted in collaboration with a Dutch financial organization. We first performed a rapid review that led to the inclusion of 151 research papers. Afterward, we conducted six semi-structured interviews to enrich the data with industry perspectives. The combined results showcase the potential sustainability benefits and costs of integrating AI. The labels synthe-sized from the review regarding potential sustainability benefits were clustered into 16 themes, with energy management being the most frequently mentioned one. 11 themes were identified in the interviews, with the top mentioned theme being employee wellbeing. Regarding sustainability costs, the review discovered seven themes, with deployment issues being the most popular one, followed by ethics & society. Environmental issues was the top theme from the interviews. Our results provide valuable insights to organizations and practitioners for understanding the potential sustainability implications of adopting AI.;
Decision support systems with dynamic architectures;As renewable technologies have become increasingly competitive, the demand for more flexible, user-centered decision support tools has increased in recent years. Existing Decision Support Systems (DSS) have limited capability to integrate new data sources into the decision-making flow without extensive assistance from software developers. This research addresses this challenge and presents the dynamic architecture of a DSS that enables the development of customizable decision-making environments at end-user level.;
Exploring Sustainable Alternatives for the Deployment of Microservices Architectures in the Cloud;As organizations increasingly migrate their applications to the cloud, the optimization of microservices architectures becomes imperative for achieving sustainability goals. Nonetheless, sustainable deployments may increase costs and deteriorate performance, thus the identification of optimal trade-offs among these conflicting requirements is a key objective not easy to achieve. This paper introduces a novel approach to support cloud deployment of microservices architectures by targeting optimal combinations of application performance, deployment costs, and power consumption. By leveraging genetic algorithms, specifically NSGA-II, we automate the generation of alternative architectural deployments. The results demonstrate the potential of our approach through a comprehensive assessment of the Train Ticket case study;
Documentation Work in Agile Teams: The Role of Documentation Formalism in Achieving a Sustainable Practice;As its second guiding principle, agile software development promotes working software over comprehensive documentation. In this paper we investigate alignment between two different documentation practices and agile development. We report upon an experiment conducted to explore the impact of formalism and media type on various dimensions of documentation practice in agile teams. 28 students in 8 teams were divided into two groups: SAD and UML. Group SAD was to update and deliver their high-level software architecture in form of a textual description defined by RUP templates. Group UML was instructed to update and deliver their low-level software design in form of UML models. Our results show that iterative documentation practices led to more extensive and more detailed textual documentation. We found that writing documentation was perceived as a intrusive task leading to task specialization and allocation of documentation to less qualified team members. Consequently, this hampered collaboration within the team. Based in our findings, we suggest that if documentation is to be delivered with the project, producing documentation should be communicated and accepted by the team as a proper product. Furthermore, we argue that codification of internal development knowledge should be a non-intrusive task.;
4th International Workshop on Green and Sustainable Software (GREENS 2015);Engineering green software-intensive systems is critical in our drive towards a sustainable, smarter planet. The goal of green software engineering is to apply green principles to the design and operation of software-intensive systems. Green and self-greening software systems have tremendous potential to decrease energy consumption. Moreover, enterprise software can and should be re-thought to address sustainability issues using innovative business models, processes, and incentives. Monitoring and measuring the greenness of software is critical towards the notion of sustainable and green software. Demonstrating improvement is paramount for users to achieve and affect change. Thus, the theme of GREENS 2015 is Towards a Green Software Body of Knowledge. The GREENS workshop series brings together researchers and practitioners to discuss both the state-of-the-art and state-of-the-practice in green software, including novel ideas, research challenges, methods, experiences, and tools to support the engineering of sustainable and energy efficient software systems.;
Architecture design of a highly scalable information system for the management of an inclusive job board that includes disability and job skills;The inclusion of people with disabilities and the consideration of labor competencies are key factors to promote labor inclusion and achieve the objectives of sustainable development in contemporary society. This scientific paper addresses the design of the architecture of a highly scalable information system for the management of an accessible job board, which contemplates both features. In line with Sustainable Development Goals (SDGs) 1, 2 and 11, to achieve this purpose, the V-methodology is employed, identifying user requirements and system characteristics through the ISO/IEC 25010 standard, involving end users and experts in the field. The design of the architecture is done through the C4 model up to level 3, on the other hand, for the detailing includes a general architecture in Amazon Web Services (AWS), a detailed description of each service and a rapid prototyping with Figma. The validation of the proposal is done through expert opinion and a proof of concept, configuring the components on AWS.;
Web-based 3D urban decision support through intelligent and interoperable services;The application of information and communications technology to support urban operational decision makers has received vast interest from industry and academia. This has helped to mature several fields of research within the smart city domain, such as the internet of things, cybernetics, and informatics. However, these fields of research remain siloed, which leads to a clear gap in the literature. The paper recognizes the mentioned gap manifesting in a new smart urban area in Wales, UK, and presents a platform which intends to demonstrate the benefits of exploiting the synergies between these fields of research. Following consultation with various stakeholders at the pilot site, the platform utilizes advanced sensing, analytics, interoperability, and visualization components to provide valuable human-machine interactions to facility managers in the district. Delivering this high value knowledge in a timely, engaging, and accessible manner through advanced decision support interfaces. The paper presents the platform's software architecture, before discussing the decision support interface, intelligent web services, and interoperability components in more detail. The solution's key contributions beyond existing internet of things platforms are the use of a 3D game engine, machine learning and optimization web services, and the integration across the knowledge value chain. This knowledge integration is achieved through semantic modelling of the buildings, urban environment, socio-technical systems, and smart devices in the district.;
Quality assurance of component based software systems;Component based software development approach is built on the notion to develop software systems by choosing appropriate off-the-shelf components and the ? to assemble them with a well-defined software architecture. Quality assurance (QA) for component-based software development is a newer concept in the software engineering community as new software development paradigm and traditional approach are much different from each other. In this paper, we survey current component-based software technologies, define their advantages and disadvantages, and debate the features they inherit. We also address QA is sues for component-based software. As a major involvement, we propose a QA model for component-based software development, which covers component requirement analysis, component development, component certification, component customization, and system architecture design, integration, testing, and maintenance.;
Embedding architectural support in industry;Software architecture plays a vital role in the development (and hence maintenance) of large complex systems with a long lifetime. It is therefore required that the software architecture is also maintained, i.e. sufficiently documented, clearly communicated, and explicitly controlled. In our experience, these requirements cannot be met without appropriate support. Commercial-off-the-shelf support for architectural maintenance is still scarcely available, if at all, implying the need to develop appropriate proprietary means. In this paper, we briefly report upon an overall approach taken within three organizations within Philips that develop professional systems. We extensively describe the experience gained with the embedding of architectural support in these three organizations. We focus on architectural support in the area of software architecture recovery, visualization, analysis, and verification. In our experience, the support must be carried by a number of elements of software development, and all of these elements have to go through a change process to ensure sustainable embedding. We distinguish four of these elements, i.e. process, organization, software development environment, and humans, and present our experience in terms of those elements.;
Integration of Information and Communication Technologies in Agriculture for Farm Management and Knowledge Exchange;The demographic growth of the last centuries has been followed by a demand for higher productivity of agriculture activities and an increase in the quality of farming products. Modern consumers seek quality by selecting foods containing high concentrations of healthy nutrients (e.g., antioxidants, vitamins, minerals) while also valuing eco-friendly practices and sustainable consumption. In line with the modern social needs, integrating Information Communication Technologies (ICT) solutions could assist in different levels of the agriculture lifecycle, such as crop monitoring, animal production, food safety, and farm management. Two aspects that are often neglected from many ICT solutions are the compilation of different data sources into the proposed software architecture and the facilitation of knowledge exchange between domain experts. In order to fill the gap of knowledge accumulation in this paper we take into consideration the PestNu architecture, as defined in section V that illustrates the different steps that are required for a complete data analysis life cycle into the development and deployment of the OpenHub platform. The OpenHub aims to cover the knowledge hub between experts with different backgrounds and promote the best practices from different users with hands-on experience.;
Exploring Transparency as a Sustainability Goal in Software Ecosystems;Software Ecosystems (SECO) is defined as a set of actors that function as a unit and their relationships and interactions with a distributed market between software and services. In this context, transparency is a key coordination mechanism for ecosystem actors because the availability of information enables them to be aware of the evolution of development activities, which is pivotal to sustainability in SECOs. However, there is an absence of SECO studies approaching sustainability issues. Therefore, exploring and analyzing SECOs based on a transparency perspective is a good opportunity to start discussing the impacts of sustainability initiatives in SECOs. As such, this study aims to express transparency as a sustainability goal in SECOs in a systematic way. To do so, we propose an approach that uses decision maps to make sustainability-driven decisions considering the transparency of SECO information and processes. Decision maps allow for an overview of relationships between SECO features or requirements and transparency concerns, which facilitate identifying and discussing transparency and sustainability issues in SECOs. The proposed approach is illustrated through a proof of concept with the analysis of two real SECOs: SOLAR 2.0 and IDUFF. As implications for academia and industry, researchers can find in this work an initial discussion of sustainability issues in SECOs based on the concept of transparency. Practitioners can find an approach to model relationships between transparency and sustainability in SECOs, which facilitates understanding the impacts on each other during decision-making.;
Analyzing the Harmful Effect of God Class Refactoring on Power Consumption;Energy efficiency and other sustainability issues are common concerns in the material production industries but rarely addressed in software development efforts. Instead, traditional software development life cycles and methodologies place an emphasis on maintainability and other intrinsic software quality features. One standard practice is to improve maintainability by detecting bad smells in a system's architecture and then applying refactoring transformations to deal with those smells. The refactoring research area is sufficiently mature for most techniques to achieve more maintainable system architectures, but the authors argue that they can also lead to both decreased sustainability and increased power consumption. Accordingly, this article analyzes the relationship between architecture sustainability and maintainability by providing empirical evidence of how power consumption increases after refactoring.;
On the Presence of Green and Sustainable Software Engineering in Higher Education Curricula;Nowadays, software is pervasive in our everyday lives. Its sustainability and environmental impact have become major factors to be considered in the development of software systems. Millennials-the newer generation of university students-are particularly keen to learn about and contribute to a more sustainable and green society. The need for training on green and sustainable topics in software engineering has been reflected in a number of recent studies. The goal of this paper is to get a first understanding of what is the current state of teaching sustainability in the software engineering community, what are the motivations behind the current state of teaching, and what can be done to improve it. To this end, we report the findings from a targeted survey of 33 academics on the presence of green and sustainable software engineering in higher education. The major findings from the collected data suggest that sustainability is under-represented in the curricula, while the current focus of teaching is on energy efficiency delivered through a fact-based approach. The reasons vary from lack of awareness, teaching material and suitable technologies, to the high effort required to teach sustainability. Finally, we provide recommendations for educators willing to teach sustainability in software engineering that can help to suit millennial students needs.;
Advancing Sustainability and Circularity in the Automotive Industry: A Data-Driven Platform Approach;"In the complex and rapidly evolving landscape of the automotive industry, sustainability and circularity are becoming increasingly crucial. However, the shift towards a Circular Economy (CE) is hindered by a multitude of barriers, especially by the limited collaboration between actors in the automotive value chain. A key challenge involves bridging the significant gap between Beginning-of-Life (BoL) and End-of-Life (EoL) actors in term of information sharing. The lack of open data exchange prevents, from one side, the optimization of End-of-Life Vehicle management processes, and from the other one, the enhancement of design practices oriented towards an easier disassembly and recycling of vehicles. Even in case data are available to decision-makers, their comprehension and elaboration process is not efficiently performed. To address these critical issues, an innovative web-based multi-layered data-driven platform has been developed, specifically designed to foster the communication and exchange of valuable and most of the time confidential information and knowledge along the automotive value chain. Integrating state-of-the-art analytics, tools, and user-friendly interfaces, the platform manages complex and disperse data and transforms them into actionable insights, facilitating informed decision-making and supporting the implementation of enhanced sustainable and circularity practices. This paper is meant to depict i. the software architecture, which follows a data-driven approach to guide the automotive sector transformation into a networked environment; and ii. the different software modules of the platform, highlighting their data requirements and interactional model. The initial validation of the platform has been conducted through a comprehensive survey within the automotive industry. Stakeholders' feedback on the platform's usability, functionality, and effectiveness in enhancing sustainability and circularity have been gathered and provided insights for further refinement. The development of the platform, thanks to its strategically designed architecture and functionalities, marks a significant step forward in the field of data management and decision-making in automotive sector. The validation results underscore the platform's potential as an indispensable tool to influence sustainable and circularity practices across the automotive value chain.";
Sustainability guidelines for long-living software systems;Economically sustainable software systems must be able to cost-effectively evolve in response to changes in their environment, their usage profile, and business demands. However, in many software development projects, sustainability is treated as an afterthought, as developers are driven by time-to-market pressure and are often not educated to apply sustainability-improving techniques. While software engineering research and practice has suggested a large amount of such techniques, a holistic overview is missing and the effectiveness of individual techniques is often not sufficiently validated. On this behalf we created a catalog of “software sustainability guidelines” to support project managers, software architects, and developers during system design, development, operation, and maintenance. This paper describes how we derived these guidelines and how we applied selected techniques from them in two industrial case studies. We report several lessons learned about sustainable software development.;
Architectural Tactics to Optimize Software for Energy Efficiency in the Public Cloud;A promise of cloud computing is the reduction of energy footprint enabled by economies of scale. Unfortunately, little research is available on how cloud consumers can reduce their energy footprint when running software in the public cloud. Moreover, cloud consumers do not have full access to information regarding their cloud infrastructure usage, which is required to understand the impact of design decisions on energy usage. The purpose of our study is to support cloud consumers in developing energy-efficient workloads in the public cloud. To achieve our goal, we collaborated with a large cloud solution provider to discover an initial set of reusable architectural tactics for software energy efficiency. Starting from interviews with 17 practitioners, we reviewed and selected available tactics to improve the energy efficiency of individual workloads in the public cloud, and synthetized the identified tactics in a reusable model. In addition, we conducted a case study to assess the impact of utilizing a tactic, which was selected following a prioritization provided by the practitioners. Our results demonstrate the possibility to architect cloud workloads for energy efficiency through reasoning and estimation of resource optimization. However, the process is not (yet) straightforward due to the current lack of transparency of cloud providers.;
2nd International workshop on green and sustainable software (GREENS 2013);ICT accounts for approximately 2% of world CO2 emissions, a figure equivalent to aviation, according to Gartner estimates. In the remaining 98% software counts for both operationalizing the private sector in doing its business and the public sector in supporting the society, as well as delivering enduser applications that permeate personal life of individuals and families. Software can contribute to decrease power consumption (i.e., become greener) in at least two ways. First, by being more energy efficient, hence using fewer resources and causing fewer CO2 emissions. Second, by making its processes more sustainable, i.e. decreasing the emissions of governments, companies and individuals. To this end, enterprise software must be rethought to address sustainability issues and support innovative business models and processes. The special theme of the second edition of GREENS is “Leveraging energy efficiency to software users”. This workshop brings together software engineering researchers and practitioners to discuss the state-of-the-art and state-of-the-practice in green software, as well as research challenges, novel ideas, methods, experiences, and tools to support the engineering of sustainable and energy efficient software systems.;
Sustainable ICT in Agricultural Value Chains;For long-term sustainability, information and communication technologies for development (ICTD) must focus on reusability and scalability from the ground up. The Sustainable Bottom Billion Architecture is a technical ICTD architecture with successful sustainable replications in two ICTD projects in Africa's cashew and shea-nut farming value chains.;
Self-Adaptation Approaches for Energy Efficiency: A Systematic Literature Review;The increasing energy demands of software systems have set an essential software quality requirement: energy efficiency. At the same time, the many contextual changes faced by software systems during execution can hamper their functionality and overall quality. To address both problems, self-adaptation approaches can empower software systems, at both design-time and runtime, to adapt to dynamic conditions. In this way, software systems can be more resilient to failure, hence more trustful to satisfy the demands of modern digital society. In this paper, we perform a systematic literature review to study the state-of-the-art on existing self-adaptation approaches for energy efficiency. We analyze the identified approaches from three different perspectives, namely publication trends, application domains, and types of software systems. Our findings can help solution providers to make guided decisions to enable self-adaptability in designing and engineering software systems.;
Risk assessment and mitigation approach for architecture evaluation in component based software development;Architecture evaluation is one of the early phases of CBSD. Analysis of the activities in this phase can provide valuable insight to the risks associated in CBSD. This paper proposes a risk assessment approach for this phase. The basis of risk identification is on the concept of 4 + 1 architecture view proposed at rational software. For this paper, UML mapping of logical view is considered for identification of activities. The impacts of the failure of the activities are estimated to identify the major concerns in this phase considering the logical view representation only. Finally, risk mitigation measures are proposed in order to prepare the architecture with a lesser probability to fail. The objective of risk assessment is to propose measures to get a better and refined output of any context than it would be without assessment done.;
Software Architecture For Integrating Devs Simulation Into BIM;Building performance is just as important as designing and constructing buildings that are aesthetically appealing. Modern buildings should be more energy efficient in terms of long-term sustainability and energy use. A high-performance building requires proper design and construction, with more energy-efficient HVAC systems, while keeping human comfort in mind. Reconstruction will be difficult and expensive if the performance measures are not achieved after the building is constructed. As a result, evaluating a building’s performance in the pre-design phase and simulating the building before construction can be beneficial. We present a solution that combines the Discrete Event System Specification (DEVS) with Building Information Modeling (BIM) to predict building efficiency. We present two case studies using simulations to show how the proposed approach helps in enhancing the building’s performance.;
Deriving Experiments from E-SECO Software Ecosystem in the Technology Transfer Process for the Livestock Domain;"The process of transferring technology from research institutes to industry involves benchmarking it in exhaustive experiments to assure it reaches the established quality criteria. This is also true for the livestock domain, in which the technologies developed to sustainably raise animals production are submitted to experiments while preserving their health and wellness. However, since such institutions often conduct several parallel innovation projects, the establishment of an infrastructure to support those experiments can be costly, repetitive, and error-prone. For that purpose, we developed E-SECO, a software ecosystem that encapsulates a lifecycle model for scientific experiments and its supporting platform and actors. The main contribution of this paper is presenting how the E-SECO architecture was successfully applied to create a livestock architecture (named e-Livestock architecture) from which two different (and independent) scientific experiments involving real systems were deployed and executed in the livestock domain. The first experiment involved a Compost Barn production system, i.e., the environment and surrounding technology where bovine milk production takes place; whilst the second experiment involved an automated monitoring environment for aviaries. Preliminary results showed the effectiveness of E-SECO to (i) abstract concepts of scientific experiments for livestock domain, (ii) support reuse and derivation of an architecture to support engineering real systems for different livestock sub-domains, and (iii) support the experiments towards a future transfer of technology to industry.CCS CONCEPTS • Applied computing ? Agriculture; • Software and its engineering ? Software architectures.";
A Proposed Architecture for Quality based Decision Making Approach for Software Re-engineering;Software re-engineering is the modification of a software system after it has been reverse engineered, typically to add new functionality or fix errors. Software re-engineering involves a set of activities aimed at reorganizing a legacy system into a new target system that conforms to quality constraints. This paper explores the reasons behind the failure of software re-engineering. This study has analyzed that some of the most common factors for failure of software re-engineering are misestimated costs and quality inefficiencies. As far as the quality factor is concerned, first the basic tool architecture is analyzed which is used by most of the tools for reverse engineering, reorganization and re-engineering. In this research study, a quality evaluation factor as well as parameters for quality evaluation are added to that particular architecture, so that customers and maintainers can analyze whether they achieve the desired goals for re-engineering. Ifthe target is achieved then the finished product is obtained again with quality and within budget, otherwise more attention should be given to the quality evaluation process.;
Development and Validation of an Open Architecture for Autonomous Vehicle Control;Teams dedicated to research in the field of autonomous vehicles can be found in many universities and research centers, but they often face the challenge of finding a suitable platform for their work. The primary reason for this challenge is the inaccessibility and high cost of commercial autonomous vehicles, leading researchers to rely on simulators.This paper introduces a new software architecture designed to automate vehicles, providing all the necessary capabilities of an autonomous vehicle in a more cost-effective and efficient manner. The architecture is designed to be modular, universal, and with a public interface, making it easy to modify, adapt to any type of vehicle, and accessible to any researcher.The new software architecture has been implemented in two platforms: a vehicle integrated with OpenPilot via ROS2 without any external hardware, and a last-mile robot. A validation test was conducted with volunteers to assess the reaction of passengers while the car was driving autonomously. The results of this implementation demonstrate the potential of this new software architecture to provide a comprehensive and accessible platform for the advancement of autonomous vehicle research.;
Ensuring Green Production with less CO2 Emission with a Digital Twin based Scheduling System;Production scheduling is the main driver of the production performance. Nowadays, manufacturers should consider not only the economic factors but also the sustainability for the production scheduling. This means that a production schedule should ensure the cost efficiency, more usage of green energy, and less CO2 emission. Designing a scheduling system that considers both sustainability and economic factors requires a smart manufacturing environment that integrates proprietary data sources for data ubiquity. In addition, the scheduling system should be able to derive solutions in a reasonable amount of time. The scheduling system should be modifiable so that it can be applied to different production situations with less effort. To address the above challenges, we present the architecture of a scheduling system for energy-optimized production. Digital twins are adopted to ensure the interoperability of the scheduling system. A Monte Carlo based scheduling method is used to derive near optimal schedules. The Monte Carlo based scheduling method is generic and can be easily configured for a specific application. To accelerate the computation, we plan to deploy the scheduling system on a supercomputer and parallelize the computation as much as possible. Our work will provide a configurable scheduling service for firms to solve small and medium-sized scheduling problems.;
Experimental Evaluation of Energy Efficiency Tactics in Industry: Results and Lessons Learned;Integrating (and evaluating) energy efficiency tactics into daily industrial practice is challenging. This paper addresses the experimental evaluation of energy efficiency tactics in industrial contexts. Based on different real-world scenarios, we assess five energy efficiency tactics for cloud-based software through individual experiments conducted across two companies. The results of the experiments show significant improvements in energy efficiency for three tactics, with two others showing enhanced efficiency albeit without statistical significance. In addition to the experiments, we draw lessons learned and practical insights into utilizing tactics in industrial contexts. Our results could guide practitioners in selecting and applying the most suitable tactic for their individual context. By linking tactics that emerged in the literature with evidence-based measures, we help including sustainability in software architecture design decision making.;
FLEXOR: User friendly wireless sensor network development and deployment;Wireless sensor networks (WSNs) penetrated the market mainly as solutions for specific application scenarios. However, this strong specialization limits WSNs reuse both in terms of development as well as in terms of technical results: Every new application scenario requires a new design, development and validation, as well as management skills. This is frustrating for any WSNs user, developer or manager. To reverse this tendency and thus improve the quality of experience and user-friendliness in WSNs, we designed FLEXOR, a sustainable software architecture optimized to support the implementation, rapid prototyping, evaluation, and testing of wireless sensor network applications, that is platform independent and user-friendly. FLEXOR is designed to accommodate many different applications and services for wireless sensor networks and foster code re-usability and cross-platform component re-usability. FLEXOR offers high modularity, well defined interfaces, remote node management functionality as well as run-time module exchange. Finally, the introduction of a unifying way for WSNs development opens to a higher homogeneity and thus to more easy comparison among different solutions. We present here an analysis of FLEXOR from these new angles and show how effective it is for several purposes and in particular for non-experts and in education.;
An approach to design a robust and intelligent multi-agent system;A successful multi-agent system requires the intelligent agents to perform within a dynamically complex environment where proper and quick response in a cooperative manner is a primary key to successfully complete a task. This paper proposes a non-deterministic decision making method using electric fields and high-level decision making. Different layers are designed, defined, and implemented for the software architecture with focus on system adaptability, sustainability, and optimization. Consequently, a software architecture is proposed in this paper to complement the AI algorithms. The proposed architecture aims to provide a well-structured and managed system for control, behavior, and decision making of multi-agent systems. The proposed decision making approach in this paper is based on layered artificial intelligence implemented using vector-based fuzzy electric fields and a decision tree. Furthermore, an approach to model the world which, in this paper, is called Agent Relative Polar Localization is introduced. This world model is based on fuzzy measurements and polar coordinates. In order to optimize the overall performance of the system learning methods have been introduced to the system. The proposed system in this paper has been implemented on soccer robots to evaluate the performance of the system. The results show that the proposed system implemented on the soccer robots is reliable and robust.;
Trio: enabling sustainable and scalable outdoor wireless sensor network deployments;We present the philosophy, design, and initial evaluation of the Trio testbed, a new outdoor sensor network deployment that consists of 557 solar-powered motes, seven gateway nodes, and a root server. The testbed covers an area of approximately 50,000 square meters and was in continuous operation during the last four months of 2005. This new testbed in one of the largest solar-powered outdoor sensor networks ever constructed and it offers a unique platform on which both systems and application software can be tested safely at scale. The testbed is based on Trio, a new mote platform that provides sustainable operation, enables efficient in situ interaction, and supports fail-safe programming. The motivation behind this testbed was to evaluate robust multi-target tracking algorithms at scale. However, using the testbed has stressed the system software, networking protocols, and management tools in ways that have exposed subtle but serious weaknesses that were never discovered using indoor testbeds or smaller deployments. We have been iteratively improving our support software, with the eventual aim of creating a stable hardware-software platform for sustainable, scalable, and flexible testbed deployments.;
A FIWARE-based IoT Framework for Smart Water Distribution Management;A key axis of design and implementation of sustainable water management solutions is based on the application of IoT, which enable the deployment of monitoring systems across the water distribution network, facilitate data acquisition in an automated manner and provide a rich set of data. Distributed software architectures are acknowledged as vital to realize smart water management systems, especially in large-scale and complex deployments with heterogeneous interacting entities. Current smart water systems mainly use commercial IoT platforms with only a few researches rooting for open source software solutions. However, both approaches have limitations as the closed APIs of commercial IoT platforms have been accused of hindering open market evolution, while open source solutions lack interoperability and data integration/sharing mechanisms. This paper presents an IoT framework based on FIWARE that aims to realize a highly flexible standards-based open source software solution for the development of smart water systems. We designed an architecture consisting of various FIWARE software components and two dashboard applications. We have also constructed a digital model of a part of a water distribution network and used a simulation dataset to showcase the framework’s functionality and data visualization aspects.;
A computational intelligence decision-support environment for architectural and building design: CIDEA;Environmentally friendly and comfortable buildings are a much sought after goal in today's architectural practice. In order to improve energy consumption of buildings without sacrificing indoor comfort, careful consideration of design decisions is needed. Simulation tools provide a solution to one aspect arising from this need, namely the requirement for accurate quantitative results. On the other hand, the complexity of the real-world design problems in question calls for decision support tools that integrate, in addition to simulation, optimization, analysis, and modeling. The aim of the paper is to present ongoing work on the development of such a tool. The focus of the tool is on abstraction of the technical complexity, while maintaining a sufficient level of flexibility. The tool is designed according to an integrated workflow beginning from sampling, data analysis, model creation and testing, up until the final analysis of the optimization results. We present the architecture of the platform, as well as its application in two case studies, one focusing on the design of an office tower, and one on the design of a sustainable facade. Results from qualitative usage cases indicate favorable performance in supporting decision-making.;
The Blockchain as a Software Connector;Blockchain is an emerging technology for decentralized and transactional data sharing across a large network of untrusted participants. It enables new forms of distributed software architectures, where components can find agreements on their shared states without trusting a central integration point or any particular participating components. Considering the blockchain as a software connector helps make explicitly important architectural considerations on the resulting performance and quality attributes (for example, security, privacy, scalability and sustainability) of the system. Based on our experience in several projects using blockchain, in this paper we provide rationales to support the architectural decision on whether to employ a decentralized blockchain as opposed to other software solutions, like traditional shared data storage. Additionally, we explore specific implications of using the blockchain as a software connector including design trade-offs regarding quality attributes.;
Towards Building a Smart Water Management System (SWAMS) in Nigeria;The water management landscape in Nigeria struggles with formidable obstacles characterized by a lack of adequate infrastructure, an uneven distribution of resources, and insufficient access to clean water, particularly in rural areas. These challenges are further compounded by the impacts of climate change, contributing to a heightened sense of water scarcity and the inefficient utilization of available water resources. In response to these challenges, collaborative endeavors involving both public and private sectors have emerged as critical components of the solution. The concerted efforts aim to establish equitable access to clean water, bolster public health initiatives, and catalyze socio-economic development across Nigeria. This comprehensive examination of the nation’s water dynamics underscores the need for innovative solutions. As part of this endeavor, we propose the implementation of a distributed service-oriented software architecture. This technological approach is designed to optimize water distribution networks and facilitate the implementation of effective water management policies, marking a pivotal step towards ensuring a more sustainable and resilient water future for Nigeria.;
Architecture Decisions in AI-based Systems Development: An Empirical Study;Artificial Intelligence (AI) technologies have been developed rapidly, and AI-based systems have been widely used in various application domains with opportunities and challenges. However, little is known about the architecture decisions made in AI-based systems development, which has a substantial impact on the success and sustainability of these systems. To this end, we conducted an empirical study by collecting and analyzing the data from Stack Overflow (SO) and GitHub. More specifically, we searched on SO with six sets of keywords and explored 32 AI-based projects on GitHub, and finally we collected 174 posts and 128 GitHub issues related to architecture decisions. The results show that in AI-based systems development (1) architecture decisions are expressed in six linguistic patterns, among which Solution Proposal and Information Giving are most frequently used, (2) Technology Decision, Component Decision, and Data Decision are the main types of architecture decisions made, (3) Game is the most common application domain among the eighteen application domains identified, (4) the dominant quality attribute considered in architecture decision-making is Performance, and (5) the main limitations and challenges encountered by practitioners in making architecture decisions are Design Issues and Data Issues. Our results suggest that the limitations and challenges when making architecture decisions in AI-based systems development are highly specific to the characteristics of AI-based systems and are mainly of technical nature, which need to be properly confronted.;
Architecting a Software-Based Ecosystem for the Automotive Aftermarket: An Experience Report;Software-based ecosystems comprise multiple software systems developed by a multitude of organizations. They are on the one hand technically integrated, often via a dedicated platform forming the center of the ecosystem. On the other hand, the organizations and their systems interact in a way that provides (business) benefits for all participants and leads to new forms of businesses. The ecosystem platform is typically defined, developed and operated by the ecosystem initiator. In the past two years, we have been working on the initiation of an ecosystem and the development of a platform for the automotive aftermarket: a data and service marketplace. As core contributions in this paper, we share the experiences and lessons learned from the early phases from an architect's point of view. As a background, we first describe our key architecture drivers, the current state of the architecture, and how architecture work is performed. We experienced a substantially extended scope for ecosystem architects, working on the overall ecosystem and the platform. Especially in the beginning, architects have to live with a high degree of uncertainty and fuzziness and have to help shaping and aligning business, technical, and legal aspects. Besides these key insights, we share lessons learned in the following categories: Requirements and Priorities, Architecture and Architecture Work, Platform Releases and Time-to-Market, Partners, Communication, Learning from other Ecosystems.;
Advanced mobile router platform with load balancing capabilities in heterogeneous networks;Future wireless networks will have to provide seamless connectivity anytime and everywhere while fulfilling conditions concerning sustainable bit rates and maximum delays. Next generation wireless networks will provide communication services not only to persons but also to machines which will have as consequence a significant increase of the number of terminals connected and involved in the communication process. In order to solve these wireless communication issues the design of new radio interfaces is considered as well as the joint usage of the transmission resources available in heterogeneous wireless networks which cover the same geographical area. This paper proposes the architecture and some design principles and implementation details of an advanced mobile router platform with combined vertical handover and load balancing capabilities in heterogeneous wireless networks. The architecture of the testbed used for functionality testing and performance evaluation of the mobile router is also presented together with some relevant test results.;
Towards green AI-based software systems: an architecture-centric approach (GAISSA);Nowadays, AI-based systems have achieved outstanding results and have outperformed humans in different domains. However, the processes of training AI models and inferring from them require high computational resources, which pose a significant challenge in the current energy efficiency societal demand. To cope with this challenge, this research project paper describes the main vision, goals, and expected outcomes of the GAISSA project. The GAISSA project aims at providing data scientists and software engineers tool-supported, architecture-centric methods for the modelling and development of green AI-based systems. Although the project is in an initial stage, we describe the current research results, which illustrate the potential to achieve GAISSA objectives.;
Towards a Reference Architecture for Large-Scale Smart Grids System of Systems;Large-Scale Smart Grids are advanced power networks that introduce intelligent management, control, and operation systems to service electricity to millions of customers and to combine traditional and renewal energies. Large-Scale Smart Grids are presented as an exemplar of System of System (SoS), since they are composed of large heterogeneous and independent systems that leverage emergent behavior from their interaction. The architectural framework of a Large-Scale Smart Grid SoS is composed of two main dimensions: the systems dimension, which is composed by the systems of the Large-Scale Smart Grid SoS, and the functional dimension, which is composed by the common functionality that these systems have to provide. In this paper, we present an architecture for Large-Scale Smart Grid SoS based on our previous experience in several industrial projects. This architecture decomposes these two dimensions into software components that support the behavior management of each system and the emergent behavior that leverage their interactions.;
Experience report: A sustainable serious educational game capstone project;Capstone courses play a key role in many Computer Science/Software Engineering curricula. They offer a summative opportunity for SE students to apply their skills and knowledge in a single experience and prepare them for work in industry. Capstones have many attributes that make them a valuable high-impact practice, yet there are several challenges that can be associated with them. These challenges include the general nature of a capstone that prevents deeper applications of skills, not to mention the difficulty of creating an interesting and engaging design project upon which students can make meaningful contributions and engage in extensive team dynamics. This experience report outlines an innovative approach to a senior design capstone course that addresses common limitations of capstone courses. The SimSYS capstone course is unique in that it involved a mixed team organization involving a more senior design team who led a development team over the course of the semester, thereby leveraging the diverse experience of capstone students completing their CS/SE degree. The results point to solutions for continuing a capstone project successfully in subsequent semesters that could be of interest to other SE curriculum designers looking to develop effective capstone courses.;
Optimizing an incremental Modular Open System Approach (MOSA) in avionics systems for balanced architecture decisions;The DoD preferred approach for implementation of open systems - Modular Open Systems Approach (MOSA) - Both a business and technical strategy for developing a new system or modernizing.;
Container-based Video Streaming Service;Video or audio streaming is highly sought after by the most of the Internet users today. Media-oriented companies offer streaming of video and audio content as a service that must be able to handle a large number of user requests, guarantee a sustainable data transmission and be constantly available for the end devices.The aim of this paper is to propose the prototype of a video streaming application that is able to manage real-time video for a larger number of users. The application must be available at all times. This objective is achieved by containerisation of the application, which contributes to the overall efficiency, high portability, modularity, and constant availability. The application is driven by a software architecture design called microservices. The containerised application is validated and compared with monolithic version of the application.;
The Design of an VIAM-USVI000 Unmanned Surface Vehicle for Environmental Monitoring Applications;Unmanned surface vehicles (USV) has become popular around the world with their capabilities in complicated and low-cost applications, also reduce the danger to humans especially in the environmental field. The environmental pollution situation is appearing more and more anywhere in the world, a large effect on the lives of people, economic development and national security. With that requirement, the design and implementation of USV systems is underway urgently but a few results have been achieved as expected. This article describes a USV's design with flexible structure, easily integrated sensors for a range of environmental monitoring applications, and the developed control algorithm verified in simulation and experiment. Also, the hardware architecture of the control system is presented and the functions of all parts are clarified. And thence, the simulation and experiment results prove that the developed control system, strategies for waypoint guidance using light of sight (LOS) algorithm and PID controller have good performance and the feasibility, reliability of the designed control system.;
An HPC Perspective on Generative Programming;Numerical software for the solution of partial differential equations is an important field in high performance computing. We study software quality criteria for such software using the Dune software framework as an example. Given these software criteria, different development models are discussed. We furthermore look at recent hardware developments and how they affect software sustainability and programmability. On this basis, we make a case for generative programming techniques in the field of high performance computing and go into detail about recent additions of such into the Dune framework.;
Design and application for Transformer District Smart Fusion Terminal under the background of Energy Internet;At present, there are many kinds of devices in distribution network. The devices have similar functions but cannot share their data with each other, causing a waste of equipment resources and high costs for operation and maintenance. To solve the problems above, we proposed a terminal design scheme with hardware of high versatility, software in the form of Application (APP) and functions based on modularization design. We developed 10 basic function apps and 20 business function apps including the data center. And we designed Smart Fusion Terminal with the functions of topology identification, load identification and distributed energy management. We conducted Smart Fusion Terminal’s pilot application in 14 provinces and conducted test on terminal’s evaluation function for meter clock accuracy. The results show that, Smart Fusion Terminal can realize all the monitoring and acquisition functions of the original de-vices with the success rate higher than 99%. By adopting expansion module and corresponding function app, it can also meet the diversified requirements in different distribution networks. The application of Smart Fusion Terminal can improve the flexibility and scalability of terminal construction, reduce the investment cost of power grid equipment and improve on-site maintenance efficiency.;
Design and Development of a sustainable telemetry system for environmental parameters;The objective of this manuscript is to show the delineation and construction process of a communication system based on the client-server software architecture, for the remote monitoring of environmental parameters. The server will be programmed in Python® on an embedded computer system such as Raspberry Pi®. An arrangement of photo-voltaic cells was added to this system, as well as a charging module in order to make it sustainable. For the reception and plotting of the measurements obtained from the environmental parameters, two clients will be programmed in different operating systems. The first client will be programmed in App Inventor® for a smartphone with Android® system. The second client will be developed in LabVIEW® for Windows® / MacOS®. The results obtained allowed to conclude that the communication scheme shown can work with multiple operating systems and is stable for sending the environmental parameters.;
A Crypto-Token Based Charging Incentivization Scheme for Sustainable Light Electric Vehicle Sharing;The ecological impact of shared light electric vehicles (LEV) such as kick scooters is still widely discussed. Especially the fact that the vehicles and batteries are collected using diesel vans in order to charge empty batteries with electricity of unclear origin is perceived as unsustainable. A better option could be to let the users charge the vehicles themselves whenever it is necessary. For this, a decentralized, flexible and easy to install network of off-grid solar charging stations could bring renewable electricity where it is needed without sacrificing the convenience of a free float sharing system. Since the charging stations are powered by solar energy the most efficient way to utilize them would be to charge the vehicles when the sun is shining. In order to make users charge the vehicle it is necessary to provide some form of benefit for them doing so. This could be either a discount or free rides. A particularly robust and well-established mechanism is controlling incentives via means of blockchain-based crypto-tokens. This paper demonstrates a crypto-token based scheme for incentivizing users to charge sharing vehicles during times of considerable solar irradiation in order to contribute to more sustainable mobility services.;
Development and Application Mode Design of Complex Ship Numerical Simulation System Based on SaaS;The current numerical simulation system is developing in the direction of large-scale, complex and service-oriented because of the high integration of numerical simulation technology development and equipment research. However, the numerical simulation research of the three important links of prediction, evaluation and optimization for the ship general performance is highly dependent on foreign commercial software. It is urgent to integrate multidisciplinary fusion methods and data knowledge engineering to implement independent research and development of numerical simulation systems. In order to remodel the research and development mode of ship general performance, the experience and lessons in the development of industrial software are summarized in this paper. The research and development concept of numerical simulation system for ship general performance including “crowd-innovation and sharing”, knowledge collaborative application, and intelligent are proposed to improve ship R & D capability.;
An experimental monitoring system for thermoelectric modules;The goal of this paper is to introduce an experimental monitoring system for thermoelectric generator modules. This system consists in using thermoelectric generator devices for producing electrical power. Also it monitors some parameters of a thermoelectric generator such as the temperature of its cold side, the temperature of its hot side, the output voltage, the output current. The system is able to control the active cooling solution of the cold side. The system uses a Raspberry Pi controller board and adjacent electronics for monitoring parameters, for data logging and work flow control.;
Emphasis on Evaluative Prerequisites for Decisive Software-in-the-Loop (SiL) Environments;Recent trends in virtualization have shown significant desideratum, for the simulations to be performed using credible SiL environments. The SiL environment is a plausible approach, which is decisive in verifying the complex control algorithms, embedded into various automotive ECUs. Major challenges would be associated with the approaches, processes, and manipulation of risks, in the course of the development of credible SiL environments. The need for a competent mitigation plan is required, which might postulate a paradigm shift in the software development processes. This is quintessentially required for the development of an effective, reliable, and credible SiL environment. With different approaches and processes, currently, for different SiL environments, created using different tools, from different vendors, emphasis on the evaluation of the standard set of prerequisites is very much necessary. The evaluation provides technical clarity and aids in the process of vECU generation, with a significant impact on the implementation of a credible SiL environment. This decisive SiL environment thus enables verifying & validating the vECU behavior and performance. In this paper, we provide insights into the evaluative prerequisites, considered before the creation of the SiL environment. The evaluation of these prerequisites is imperative in identifying and selecting the software components and evaluating its available information, integrated as part of vECU. With the help of use-cases, we try to highlight and emphasize the imperative prerequisites, evaluated, and the need for its evaluation, in creating a credible SiL environment.;
Web GIS solution and 3D visualization towards sustainability of Georgetown as world heritage site;Sustainability of Georgetown as world heritage site is a primary objective and urgent problem to be address by The State Government in Penang. The aims are to develop Web GIS solution and 3D visualization for sustainability of Georgetown as World Heritage Site. The objective of this research is to study concept and principles sustainable development and to construct the Web GIS solution with 3D visualization of Georgetown. Methodology used to generate 3D building from building footprints that have actual height and produce a virtual 3D city model environment. Through the web based, the users enable to visualize the present and for future of urban development. With the advanced Geographic Information data which were made accessible on the Internet by Web GIS solution technology offered an effective medium for public participation. For Web GIS solution each of building have information about category of building, section, architecture style, road name, building name and building number. This web based also provides or demonstrates the capacity to view, manipulate and distribute geographic data via WWW in an effective, organized user friendly manner. The platform can be used by a public and many agencies to access and acquired geospatial data and information. As the final outcome from Web GIS solution will enable user to interact with GIS data and maps on the Web without have to own GIS software. Planners, architects, urban designers, and land use planners are able to visualize the impact of urban design projects and proposed land use and zoning changes or predict the results of smart growth initiatives towards sustainability of Georgetown as world heritage site.;
Cromlech: Semi-Automated Monolith Decomposition Into Microservices;Microservices architectures conceive an application as a composition of loosely-coupled sub-systems that are developed, deployed, maintained, updated, and scaled independently. Compared to monoliths, microservices speed up evolution and increase flexibility. For these reasons they are becoming the reference architecture for many practitioners. A key challenge to embrace a microservices architecture is how to decompose an application into microservices: a choice that deeply affects all subsequent development phases in ways that are difficult to foresee and evaluate. Without any tool to support their reasoning, developers may erroneously evaluate the various alternatives, leading to inaccurate decomposition choices that would result in increased development, operations, and maintenance costs. This paper tackles the problem with Cromlech, a semi-automatic tool to decompose a software system into microservices. Cromlech (i) takes in input a high-level model of the system in terms of functionalities and data entities accessed by those functionalities, (ii) formulates decomposition as an optimization problem, and (iii) outputs a proposed placement of functionalities and data onto microservices, using a visual representation that helps reasoning on the resulting architecture. Cromlech evaluates design concerns, communication overheads, data management requirements, opportunities and costs of data replication. Our evaluation on a real-world industrial application shows that Cromlech consistently delivers more efficient solutions than simple heuristics and state-of-the-art approaches, and provides useful insights to developers.;
EcoMLS: A Self-Adaptation Approach for Architecting Green ML-Enabled Systems;The sustainability of Machine Learning-Enabled Systems (MLS), particularly with regard to energy efficiency, is an important challenge in their development and deployment. Self-adaptation techniques, recognized for their potential in energy savings within software systems, have yet to be extensively explored in Machine Learning-Enabled Systems (MLS), where runtime uncertainties can significantly impact model performance and energy consumption. This variability, alongside the fluctuating energy demands of ML models during operation, necessitates a dynamic approach. Addressing these challenges, we introduce EcoMLS approach, which leverages the Machine Learning Model Balancer concept to enhance the sustainability of MLS through runtime ML model switching. By adapting to monitored runtime conditions, EcoMLS optimally balances energy consumption with model confidence, demonstrating a significant advancement towards sustainable, energy-efficient machine learning solutions. Through an object detection exemplar, we illustrate the application of EcoMLS, showcasing its ability to reduce energy consumption while maintaining high model accuracy throughout its use. This research underscores the feasibility of enhancing MLS sustainability through intelligent runtime adaptations, contributing a valuable perspective to the ongoing discourse on energy-efficient machine learning.;
Design of Multi-Channel Integrated Platform for Electric Power Marketing Based on Microsoft Service Architecture;With the continuous advancement of power system reform and the vigorous development of the Internet industry, power marketing services are also facing higher challenges. In some scenarios, business applications using traditional monolithic architecture will become less flexible and less capable of continuous delivery, which makes business application maintenance difficult. In order to expand the multichannel service of power marketing and establish a comprehensive service platform system, this paper takes spring-boot and spring-cloud as the technical framework, divides the traditional single application into several fine-grained ones. Based on the business application characteristics of micro-service architecture, it builds a domain-driven model for the whole process of scenario, and builds a multi-channel integrated application platform for power marketing, which solves the problems of distributed data interaction caused by large business concurrency or cross-specialty in power marketing. Business applications can achieve gray-scale publishing, frequent deployment, and strong sustained delivery ability, flexible and fast to adapt to the effect of business sustainable development and change.;
SOA and EA - Sustainable Contributions for Increasing Corporate Agility;Service oriented architectures (SOA) have been introduced for various reasons over the previous couple of years. Analogous to the introduction of enterprise application integration (EAI) technologies before re-use and cost cutting potentials have been among the most prominent reasons. But considering the increasing complexity of an application landscape following the introduction of a SOA, the re-use and cost cutting arguments will lead to disappointment. However, service oriented architectures offer a great potential to increase corporate agility. To sustainable preserve corporate agility it is necessary to explicitly manage the enterprise architecture. This paper discusses the problems of re-use and cost cutting expectations in service oriented architectures and contrasts them with the potentials related to make sustainable contributions to corporate agility. Structures, processes, and instruments to realize these potentials are discussed with reference to selected case studies.;
Challenges and Opportunities for Sustainable Software;With the increasing role played by software in supporting our society, its sustainability and environmental impact have become major factors in the development and operation of software-intensive systems. Myths and beliefs hide the real truth behind Green IT: IT is energy-inefficient because software is developed to make it so - intentionally or not. But how far are we from being able to control software energy-efficiency? What makes software greener? How can we transform measuring software energy consumption in a general practice? What architectural design decisions will result in more sustainable systems? How can we ensure that new-generation software will be both cloud-ready and environmental-friendly? and How can we make evident the economic and social impact of developing software with 'energy in mind'? These are a few of the challenges ahead for a more sustainable digital society. This talk will discuss them, hence drawing directions for exciting challenges, promising opportunities, and ultimately inspiring research.;
A micro-component architecture approach for next generation embedded browsers;The mobile Internet adds the new multi-media features and takes a convergence to the wired Internet. The emerging diversity of the content languages adds a new challenge as well as the sustained challenge from the diversity of the execution environments. The author describes the mobile Internet evolution from the browser viewpoint in the three-stage model. After describing the focus shift during this evolution, the author discusses the architecture need to leverage the combination of the multimedia processing components in multiple applications in a resource-constraint environment. This leads to the new architecture demand to cope with the diversity of the content languages as well as the resource restrictions in the embedded client environment. The author proposes a micro-component architecture to enable browsers to act as a toolkit to construct a wide range of application clients on a mobile handset with optimal footprint. A case study in SVG case is shown to evaluate the effect of the proposed micro-component architecture approach.;
A Model-Based Approach to Automotive Feature Development for Updates and Upgrades;The automotive industry faces challenges due to the increasing demand for customization and individualization by consumers. With a wide range of equipment levels and feature options, it has become impossible to test all possible configurations for a single vehicle during development and especially for vehicles already in service. As a basis for solving these challenges, integrated approaches for the development of upgradeable vehicles are required. In this context, future upgrade options should be considered and planned already in the design stage to enable sustainable business models for next vehicle generations. This paper proposes a refined variability model that combines two existing approaches to address the challenges faced by the industry. The same model can perform buildability or upgradeability checks and dynamic allocation optimization. The model is evaluated qualitatively by three exemplary use cases.;
Virtualize for Architecture Sustainability in Industrial Automation;The technique of virtualization and cloud computing to manage system functionality and resources regardless of their physical locations is changing the way businesses and users interact with IT resources. Although several commercially available virtualization solutions already exist in the market, both for server and embedded real-time based systems, the deployment of virtualization and cloud-based technologies into the industrial automation domain is new. In this paper, we will first present the emerging trends of industrial automation domain and identify the architectural sustainability challenges that follow. Based on these challenges, we will then analyze how virtualization technology can contribute to cope with them, as well as the additional opportunities that it brings to industrial automation domain. The contributions of this paper are (1) to communicate the main trends happening in industrial automation, (2) clarify the architecture sustainability challenges that the automation domain is facing, and (3) identify the potentials of further utilizing virtualization technology in the industry domain.;
Mastering Reference Architectures with Modeling Assistants;Reference architectures (RA) can significantly simplify and speed up the design and evolution of software systems in virtually any domain. Rather than starting from scratch or trying to reuse models not meant for reuse, software architects can exploit RAs to initiate their designs from rigorously-defined architectural models specifically defined to support reuse. RAs can guarantee the satisfaction of key functional and non-functional requirements, including those related to technical and societal challenges, such as security and sustainability, significantly reducing the design effort and improving the design quality. The growing popularity of RAs is confirmed by the many providers, including Amazon AWS, Microsoft Azure, IBM, and Salesforce, that offer RAs for application deployment on their infrastructures. Unfortunately, RAs are expensive to define since they must comprehensively synthesize the design knowledge of specific application domains (e.g., e-commerce, automotive, etc.) and technical contexts (e.g., cloud systems, mobile apps, IoT, etc.). This challenge limits the availability of RAs to a few domains and contexts, hindering their adoption. We envision the opportunity to facilitate RA-based design by introducing a novel combination of mining in-the-wild and continuous knowledge refinement through a framework named ASSISTRA. Mining in-the-wild consists of bots crawling architectural models at scale (e.g., from public repos) and analyzing them continuously to automatically synthesize RAs and extract RAs-related practices that shall feed knowledge bases. Continuous knowledge refinement consists of a population of recommender systems that, while interactively supporting the architects in their activity using the shared knowledge bases, shall continuously refine the mined content in the knowledge base (e.g., based on architects accepting, modifying, or rejecting suggestions). This process shall generate high-quality recommendations, drastically simplifying the design activity. This paper elaborates on this vision, highlights the key challenges, and calls for novel research contributions.;
Human Behaviour Centered Design: Developing a Software System for Cultural Heritage;"This paper introduces an integrated framework for sustainability and urban security socio-technical systems. The focus is to design and develop a hardware/software system based on human expected and real behaviour.
The paper explains the steps taken through developing the Uffizi Museum crowd monitoring and queue management system. The goal of implementing such system was to remove queues outside the Museum which is in line with urban security and visitors comfort. We took advantage of a data-driven approach mapped on sustainability framework. Such approach which was fed with both real-time sensory data and prediction models, successfully eliminated long queues to access the museum. We took into consideration performance of software system as well to reduce the response time to a threshold that is compliant with real-time requirements. We started our experiments from fall 2016 and operationalized it in October, 2018. During this experimentation period, we learned a lot of lessons that we report in this paper.";
Designing Digital Twins for Enhanced Reusability;Digital Twins (DTs) are dynamic virtual models that mirror the behavior and characteristics of physical systems. They are emerging as a crucial tool in digital transformation, adaptable for various applications. DTs are used to simulate, analyze, and optimize physical and virtual assets [10, 11]. However, their complexity and resource-intensive nature make them challenging to integrate into real settings. Therefore, we propose that an efficient architectural design, flexibility, adaptability, and interoperability is key to achieving these objectives. Furthermore, by enhancing these aspects of DTs, we also contribute to their sustainability across technological, environmental, and economic dimensions.;
Microservices Architecture for Improved Maintainability and Traceability in MVC-Based E-Learning Platforms: RoadMap for Future Developments;E-learning platforms often struggle with maintainability and traceability due to the traditionally employed monolithic architecture. Such websites are faced with managing complex codebases and tracking user interactions and system behaviors efficiently. These challenges are met by migrating to microservices architecture which permits modularization as well as autonomy of components by developers. This paper demonstrates how microservices can improve maintainability by allowing independent deployment, scaling up or down, upgrading services, and fostering traceability via distributed monitoring and logging systems. This can be demonstrated by analyzing a case of transitioning an MVC-based e-learning platform to microservices and showing how this could offer practical insights for sustainable development practices that optimize user experiences.;
Ontology based framework for reverse engineering of conventional softwares;In contemporary years, integration among research areas of semantic web technologies and software engineering took place due to the reason of developers being present at different virtual, cultural, and geographical locations. Due to this amalgamation, a new collaborated field has emerged known as Semantic Web Enabled Software Engineering. This field presents researchers ample opportunities to probe issues and challenges, which are originated due to their amalgamation. Among such issues, one is the reverse engineering of conventional softwares using ontologies. This research paper presents a framework and discusses the implementation approach to resolve to the above issue.;
A complete RM-ODP case-study to integrate geospatial services and ecological niche modeling systems;Conservation and sustainable use of natural resources are relevant research areas for many different purposes, including biodiversity maintenance, global warming studies and sustainable development. An ecological niche model presents the geographic distribution of a species, considering the spatial, ecological and evolutionary perspectives. It also allows the definition of present, past and future scenarios for species distribution. The study of species distribution can be determinant for their management, so ecological niche modeling is a major current research trend. However, providing the resources for ecological niche modeling is a highly complex computational problem because it demands solutions with many integration, distribution and interoperability features. The Reference Model of Open Distributed Processing provided by the International Organization for Standardization, ISO RM-ODP, establishes five viewpoints to design a system: Enterprise, Computational, Information, Engineering, and Technology. Each viewpoint treats specifics constraints in order to describe a complex architectural solution, as the ones required for ecological niche modeling. The Open Geospatial Consortium, OGC, defined the OGC Reference Model, a guideline to provide the features for geospatial services, another major software requirement for ecological niche modeling. This work proposes an architectural solution for ecological niche modeling integrating the OGC and RM-ODP specifications in order to address all the constraints of the problem by the usage of viewpoints. The presented solution is already implemented and available on the Internet. Besides solving the problem itself, the solution is in the form of a complete RM-ODP case-study and may also be used as reference for further works in the ecological niche modeling research area.;
Providing Technical Software Documentation as a Service - An Industrial Experience Report;Technical software documentation is an essential source of knowledge supporting many different software development activities and stakeholders. In this paper we report on use cases, existing documentation practices, and open challenges for technical software documentation in a company from the manufacturing domain. Further, we present an approach for automatically providing technical software documentation as a service. The approach has been validated in an industrial setting, i.e., we report on our experiences and lessons learned. Validation shows that while up-to-date and dynamically explorable documentation could be provided, the proposed solution failed in sufficiently supporting different stakeholders and their concerns i.e., it failed in providing sustainable documentation and knowledge preservation over time.;
Vehicle Monitoring and Localization using UWB in Complex Parking Lot;Ultra wide band technology has advanced over the years under several localization applications. Its capability of indoor localization has kept several conventional technologies at bay. Complex parking lot such as of a shopping mall is customized to accommodate huge and multiple vehicles at a time. The availability of locating empty parking spaces and tracking along with monitoring of vehicles precisely are a challenge to such complex environments. To tackle such challenges, the authors have put forth a system capable of locating unoccupied parking spaces, monitoring and tracking of vehicles during the user absence and navigation of vehicles in and out of the area. The proposed system makes use of Ultra wide band technology using TDoA (Time difference of arrival) and triangulation technique for localization. The precise localization of vehicle coordinates inside the parking lot both in 2D and 3D are initiated using a data analysis software. The hardware and software architecture is explained in detail along with complete component design. The system is initially tested in a test bed with dimensions of 50m X 66 m and further expanded to a wider complex parking lot. Both the test bed and further implementations will be done in line of sight and non-line of sight scenarios. Effort has been done to eradicate error challenges in the system.;
Designing energy efficient Smart Buildings in ubiquitous environments;Smart Buildings have been the subject of research for more than two decades. The different perspectives range from monitoring and controlling energy consumption. Indeed, energy efficiency is considered as one of the promising fields of applications of the Internet of Things. Since Smart Buildings are an important part of the smart grid, their energy efficiency is vital for the environment and global sustainability. In ubiquitous computing systems, designing Smart Building applications is a challenge since these applications must ensure a trade-off between energy consumption and occupants comfort especially in ubiquitous environments. In this paper, we focus on the design of a Smart Building application in ubiquitous computing systems. The Smart Building application is able to manage energy consumption while keeping the occupants comfort. We elaborate an illustrative scenario to demonstrate the usefulness of our work.;
TechSuRe - A Method for Assessing Technology Sustainability in Long Lived Software Intensive Systems;Over the lifetime of a long lived software intensive system the (software) technologies used in the system will change. Changing technologies in such systems is typically extremely costly and painful for the organizations that have to perform these changes. Hence, wrong technology choices can jeopardize the economic viability of such systems in the long run. This paper presents TechSure, a method for assessing technology sustainability in long lived software intensive systems, together with experiences from case studies. The method makes sustainability issues an explicit part of a technology assessment and offers guidance on how to gauge the associated sustainability. Together, this supports making appropriate technology choices for long lived software intensive systems.;
An Innovative Smart System based on IoT Technologies for Fire and Danger Situations;The SAFETY project aims to create a system able to support rescuers such as fire fighters in presence of danger events, especially when they have to intervene in large buildings with many floors and rooms, with different access points, and with numerous users. In these cases, in fact, it is very important to provide a smart decision support system able to promptly guide rescuers to the critical points of the building where there is the certainty that there are users to be rescued or artworks to be kept safe, without wasting resources. In order to achieve this goal, an innovative system architecture based on the use of technologies enabling the Internet of Things including sensors, mobile devices, Cloud technologies, mobile Apps, and embedded devices have been designed and developed in the SAFETY project.;
A Microservices-based IoT Monitoring System to Improve the Safety in Public Building;Safety of public buildings' users is an important issue, especially in buildings frequented by a great number of people. In such places, in case of an emergency, like a fire, rescue workers must intervene in a timely manner, directing their efforts towards places where there are people to be saved. This work presents an Internet of Things(IoT)-based framework, aiming at monitoring environmental parameters in order to support rescuers during emergencies. The microservices paradigm allows a pattern-based specification of system components that are refined and adapted on-the-fly depending on the specific execution context, based on the changing aspects such as, user's need and requirements, context variables, user's behavior, sensor data. First results related to the validation of the proposed system mainly concerning non-functional requirements of the implemented system through a proof-of-concept are reported and discussed.;
QUEEN - A novel design flow and decision support tool for sustainable buildings;The established building design process is a very conservative one. New technologies and energy efficient systems are hardly adopted since there are few reference buildings out there. Risk minimization, cost pressure and the complexity of the design process therefore leads to a poor innovation cycle and old-fashioned, inefficient buildings. We present a design flow that overcomes this hurdle by means of simulation. A decision support tool uses facts and figures from simulation to ease the process of selecting the right system. Furthermore we present the software architecture of the implemented design flow that is already in use by construction industry. The project was initiated and actively supported by STRABAG AG, a construction and consulting company based in Austria operating in international markets.;
Digital agriculture for urban crops: design of an IoT platform for monitoring variables;This article presents the design of the hardware and software architecture of a monitoring system for some agroclimatic variables (light radiation and humidity of soil) through a set of technologies based on the Internet of Things (IoT). First, the state of the art is show for identify the more relevant research in the application of the digital agriculture concept. Second, the general architecture of the project is presented, making a description of the hardware and software used in it. Then, the information is broken down into the layers of the architecture, such as: perception layer, network layer and application layer, and the operation of each layer is detailed. Finally, the feasibility information is presented, and some recommendations are presented on future developments and what is expected to be improved in the presented prototype;
Precept-Based Framework for Using Crowdsourcing in IoT-Based Systems;Cyber-physical systems (CPS) provide the foundation of critical infrastructure, form the basis of emerging and future smart services, and improve quality of life. The technological advances such as edge-centric computing have pushed the frontier of computing applications, data, and services away from the centralized nodes to the logical extremes of a network. It enables analytics and knowledge generation to occur at the source of the data. In this paper we present the amalgamation of three paradigms, each at different level of system development. Precept is a design paradigm for modeling complex control structures of the activities. It is a declaratively modeled control component that prohibits undesired couplings that are otherwise unavoidable in imperatively programmed control components. Crowdsourcing for system integration harnesses the collective intelligence or knowledge base of crowd's wisdom when given the right set of conditions. Here we discuss the aptness of crowdsourcing in the development of IoT-based systems that integrate the smart components from varied domains. We define a precept based software development framework that uses crowdsourcing to develop and to continuously extend a more sustainable and adaptive IoT-based system.;
Challenges and Requirements of Electric Vehicle Fleet Charging at Company Parking Sites;The uprising number of electric vehicles on company parking sites creates a variety of challenges, in terms of scheduling charging processes. In uncoordinated charging, peaks loads can occur that harm the low voltage grid and make the company pay a higher electricity bill. Further, some vehicles may not be charged enough to be used for service appointments at customer homes. In a first step, this paper highlights the individual problems in detail that can appear in a company parking scenario. Next, it is shown that charging scheduling in a company case is not trivial. Finally, requirements to a software-based solution of the challenges are derived from the individual problems.;
Ontology based framework for automatic software's documentation;Over the last few years, research has continuously shown integration among research fields of Software Engineering and Semantic Technologies when development teams are present at different geographical and virtual locations. Their integration has opened fresh opportunities for development teams to develop software using Semantic Technologies. However, as opportunity comes so as the issues and challenges. Issues and challenges,which will keep this integrated field dynamic and lively for years to come. Among such issues, one is to automate the process software's documentation using ontologies. This paper presents a framework as well as implementation approach for the above issue.;
Sustainable Network Resource Management System for Virtual Private Clouds;To satisfy the requirement of secure isolation of Infrastructure-as-a-Service (IaaS) for enterprise customers, virtual private clouds, which are separated from others by using virtualization technologies, are deployed. However, isolation with virtualization technologies cannot avoid the affect of performance degradation, such as traffic congestion. Therefore, bandwidth-guaranteed virtual private clouds are needed for excluding unintentional and unwanted influence among multiple customers. In this paper, we propose a sustainable network resource management system (NRM) introducing a Changing Mechanism of software module based on the context (CHAMELEON) and a virtual network point for multipoint network provisioning. With the proposed mechanisms, we successfully demonstrated the sustainability of the NRM, which controls six kinds of network equipment without any modification itself.;
Business diagnostic technology for sharing value and social innovation in one-person companies;One-person companies largely support the economies of developing countries such as Colombia. Their commercial effectiveness need of creating strategies in Social Innovation. Our purpose in this paper is to propose a technological tool for characterizing companies either one-person, individual or family business. Our goal is to formulate a social shared value model for Colombian neighborhoods that it would search the sustainability for one-person companies. In the first part, we did a literature review about Social Innovation and the questionnaires in the state of the art to diagnosis. After that, we show the software architecture design and we validate it using the quality metrics. The technological tool could be used, by owners of restaurants, supermarkets, shops and drugstores in a neighborhood by means of diagnostic questionnaires. Our Business Diagnostic Tool will be identifying the main aspects, activities and processes that would be able to secure value add into one-person's companies chain value that allow its sustainability in the time. Percentage results of the metrics evaluated from the attributes of interoperability, traceability and install ability showed a percentage over the average in the number of interface data that has been applied according to the specifications and the number of data exchanged between different components.;
Optimization of Resource Allocation for Detection of Software Architectural Defects;"In this research, we develop a framework for performing resource allocation (budget and time) during the test process of a software system. The framework allows the usage of different reliability models. The assumed test process includes unit, integration and system tests. The process of testing each software component (i.e., the code associated with each test) is viewed as a sequence of test and repair periods. Each test and repair period consists of a test time interval, and a repair time interval. We assume that a software system has been specified, designed and coded, and that a test plan for testing the system is available. The test plan includes a hierarchy of planned tests, and possibly constraints on the number of test and repair periods for each planned test. In addition reliability requirements may be given for some parts of the software system. The system may include a number of modules and programs.
A model has been developed with the goal of finding the maximum reliability of the software system while satisfying the following constraints: total test cost cannot exceeds a given budget and requirements regarding the number of test and repair periods, and minimum reliability of components must be satisfied.
The model has been solved for a variety of different constraints and parameter values using the Solver Add-in of Microsoft Excel.";
Towards Efficient Adaptive Regulation of Adjustable Load Groups: A Prototype System;With the swift progress of demand response, distributed power generation, load-side control technology, and the self-regulation of individual power devices facilitated by smart grids, the control and optimization of power grids in the future will encounter an extensive array of control units. In this study, a prototype system is introduced for a cooperative adaptive regulation device designed for adjustable load groups. This system facilitates rapid removal and access to large-scale heterogeneous small-capacity decentralized adjustable loads while exhibiting a high level of adaptability. Ultimately, simulation experiments demonstrate that the system can fulfill the anticipated specification requirements.;
Piezo-Electricity: Paving the Way for Eco-Friendly Power Generation;This research article explores a state-of-the-art power generation system that makes use of Piezo-electric sensors. Piezo-electricity refers to the property exhibited by certain dielectric materials, where they undergo physical deformation in the presence of an electric field or generate an electrical charge when mechanically deformed. The proposed system harnesses this phenomenon to produce electricity from sources like ambient vibrations or mechanical movements. By incorporating Piezo-electric sensors, the system offers advantages such as enhanced efficiency and reduced maintenance requirements compared to traditional power generation methods. Experimental findings indicate that the system can generate a significant amount of electricity from ambient vibrations, suggesting the potential for industrial-scale implementation. This study provides valuable insights into the development of cutting-edge and sustainable power generation systems.;
Prerequisites for a Self-sustaining Embedded System with Artificial Intelligence;The article defines criteria, conditions and requirements for the development and existence of an embedded system. A concept of an algorithm for intelligent behavior of an embedded system, which will be able to recompile software modules and components by itself and by the software core, is presented. The aim is to achieve sustainability, expand the functions of embedded systems and adapting the system to work in different environments.;
Mitigating Risks by Weighting Intangibles when Investing in Renewables;Brazil has the important challenge of expanding electricity production by ensuring demand and energy security to support the development of society. In a context where data and information on energy sources are available on a large scale, there is an opportunity to develop a tool that enhances and contributes to energy business decision making. In this sense, this work weights intangibles parameters with the objective of mitigating risks to subsidize decision-making on the implementation of renewable energy projects. The results presented in the article are obtained by means of technical, economic-financial and information management analyzes that constitute the theoretical basis and of intangibles, all of them supported by information technology. This article presents both a new methodology and a new software to obtain optimum investment decisions in the power industry, focusing on renewables. The development and validation of the methodology and software are described. The best investment to be made is based on the extraction and evaluation of the knowledge of the specialists of the sector in a logical and mathematical way. The results of the research present a decision-making process based on more formal and less personal criteria, guaranteeing greater neutrality and convergence in the decision-making process.;
Cryptolysis: A Framework for Verification of Optimization Heuristics for the Automated Cryptanalysis of Classical Ciphers and Natural Language Word Segmentation;An earlier work on automated optimization heuristics for cryptanalysis of classical ciphers proposed a few algorithms for that task (e.g. genetic, simulated annealing, tabu search). A Java-language open-source Cryptolysis project has implemented these algorithms for verification and comparison purposes in a consistent frameworked environment allowing for additional algorithms. Another Java-language open-source project, MARF, has collected a number of frameworked classification algorithms (e.g. distance, neural network, similarity measure, etc.). We extend Cryptolysis with the wrappers for the algorithms implemented in MARF to add to the heuristics collection new results and compare them with the previously implemented algorithms. Conversely, we improve MARF's implementation by porting the Cryptolysis's implementations of search algorithms for various classification tasks in natural language and others. Additionally, we improve the system with the natural language word segmentation for the deciphered text corpora that lacks spacing and punctuation. As a result this work we validate the software architecture and design used in both frameworks as a sustainable and correct approach and practice that should be followed and re-enforced for such frameworks.;
A quality of service framework for adaptive and dependable large scale system-of-systems;There is growing recognition within industry that for system growth to be sustainable, the way in which existing assets are used must be improved. Future systems are being developed with a desire for dynamic behaviour and a requirement for dependability at mission critical and safety critical levels. These levels of criticality require predictable performance and as such have traditionally not been associated with adaptive systems. The software architecture proposed for such systems is based around a publish/subscribe model, an approach that, while adaptive, does not typically support critical levels of performance. There is, however, the scope for dependability within such architectures through the use of Quality of Service (QoS) methods. QoS is used in systems where the distribution of resources cannot be decided at design time. A QoS based framework is proposed for providing adaptive and dependable behaviour for future large-scale system-of-systems. Initial simulation results are presented to demonstrate the benefits of QoS.;
The Growing Divide in the Patterns World;At Microsoft, the patterns & practices group has been employing software patterns to distill, reuse, and communicate guidance about software design and development. This effort made a number of contributions to the patterns world, including several books and a community site (patternshare.org) aimed at bringing pattern authors and users together. Since then, patterns have also became a common ingredient in some of our other products, such as reusable application blocks and software factories. Our sustained investment in patterns, large user community, customer-driven development approach, and usage and customer satisfaction metrics provide us with unique insights into how practitioners use patterns. They also give us opportunities to identify and address some of their key challenges. Bridging the gap between the patterns expert community and the typical pattern user is critical to achieving the full benefits of software patterns.;
Architecting ultra-large-scale green information systems;"As environmental sustainability issues have come to the societal and governmental forefront, a new breed of Green Information Systems (IS)---Ultra-Large-Scale (ULS) Green IS---is emerging. A ULS Green IS is an open socio-technical ecosystem that differs from traditional IS in scale, complexity and urgency. Design issues found in ULS systems, System of Systems, Edge-dominant, Metropolis systems and Green IS converge and multiply in the ULS Green IS context. This paper presents a design framework and an architecture analysis method, ECO-ARCH, to address the design of such systems. Through an action research study on architecting for Demand Response systems in the Smart Grid, this article illuminates the system characteristics of ULS Green IS and endorses a fundamental shift in design thinking for its design -- from ""bounded rationality"" for problem solving to ""expandable rationality"" for design for the unknown and for innovation. ECO-ARCH advances existing software architecture analysis methods by complimenting expandable rationality design thinking with proven engineering techniques in a dual-level macroscopic-microscopic analysis. This tackles the unique architecting problems of ULS Green IS where many stakeholders are unknown and design goals are not provided, where no architecture pre-exists, where system behavior is non-deterministic and continuously evolving, and where co-creation with consumers and prosumers is essential to achieving triple bottom line goals.";
Towards Greener Software Engineering Using Software Analytics: A Systematic Mapping;Sustainability in software engineering is a relatively new and fast growing field of research. Green software engineering aims to produce sustainable software products with minimum negative impact on the environment. In order to make greener software products, software practitioners need actionable timely information, to make useful trade-offs between energy efficiency and other quality attributes, like performance, during development. Software analytics could be used to provide this support, as it combines information from different software artifacts and converts it into useful information. The objective of this paper is to provide an overview of the sub-domains, contribution types, research types, research methods, future research potentials and the role of software analytics in the field of green software engineering in 2015-16. We applied the systematic mapping method and conducted a search for studies in six online databases. Screening of papers was done according to inclusion/exclusion criteria and 50 selected studies were classified after analysis and data extraction. We found that there are many validation studies but hardly any evaluation and experience papers in the domain of green software engineering. Only 11 out of 50 papers in the green software engineering domain used software analytics techniques to foster green software engineering. Our results indicate the need to develop new/improved automated software analytics tools for software practitioners along with metrics explaining the correlation between energy usage and other quality attributes.;
Building Energy Modelling and Monitoring by Integration of IoT Devices and Building Information Models;In recent years, the research about energy waste and CO2 emission reduction has gained a strong momentum, also pushed by European and national funding initiatives. The main purpose of this large effort is to reduce the effects of greenhouse emission, climate change to head for a sustainable society. In this scenario, Information and Communication Technologies (ICT) play a key role. From one side, advances in physical and environmental information sensing, communication and processing, enabled the monitoring of energy behaviour of buildings in real-time. The access to this information has been made easy and ubiquitous thank to Internet-of-Things (IoT) devices and protocols. From the other side, the creation of digital repositories of buildings and districts (i.e. Building Information Models - BIM) enabled the development of complex and rich energy models that can be used for simulation and prediction purposes. As such, an opportunity is emerging of mixing these two information categories to either create better models and to detect unwanted or inefficient energy behaviours. In this paper, we present a software architecture for management and simulation of energy behaviours in buildings that integrates heterogeneous data such as BIM, IoT, GIS (Geographical Information System) and meteorological services. This integration allows: i) (near-) real-time visualisation of energy consumption information in the building context and ii) building performance evaluation through energy modelling and simulation exploiting data from the field and real weather conditions. Finally, we discuss the experimental results obtained in a real-world case-study.;
An Innovative Smart and Sustainable Low-cost Irrigation System for Smallholder Farmers' Communities;The agricultural sector has several difficulties today in ensuring the safety of the food supply. However, the Internet of Things (IoT) has recently come to light as a promising remedy with several cutting-edge uses in smart farming. The study presents the design and development of a low-cost and full-featured fog-IoT/AI system. The system has been created using open-source platforms that monitor agro-field data in real-time. However, the smallholder community is hesitant to adopt technology-based solutions. The PRIMA INTEL-IRRIS project aims to make digital and smart agricultural technologies more appealing and available to these communities by advancing the idea of intelligent irrigation “in-the-box” This study explains a low-cost fog-IoT/AI system of version 1.0 fully targeted toward smallholder farmer communities (SFCs) and how it may provide the notion of intelligent irrigation “in-the-box” concept.;
Decentralized Storage Algorithm of Medical Courses on Cloud Platform in Colleges Under the Background of O2O Integration;With the development of computer and Internet technology, the current cloud computing platform can be more and more widely used, and the current cloud computing platform has begun to develop in the direction of decentralization, so it is necessary to study the implementation method of this technology. And use the configuration management function of the cloud computing platform to automate its management and transformation, and cooperate with the high-availability decentralized software architecture to achieve the first main design goal proposed at the beginning of this paper, that is, the self-management of the system. This paper proposes a cloud The realization method of the decentralized storage algorithm of the platform medical nursing course to meet the current and future development requirements of cloud computing.;
Towards autonomous cleaning of photovoltaic modules: Design and realization of a robotic cleaner;Solar panels typically consist of photovoltaic (PV) cells covered by a protective glass coating, which generate electricity when subjected to radiations. However, the capability of electricity generation is constrained due to layer of dust on PV modules. In contrast with conventional method of cleaning the modules using water, this paper presents design and development of a robotic cleaner for cleaning PV modules of Quaid-e-Azam Solar Park (QASP). The hardware as well as software architectures of the proposed robotic cleaner are detailed. The novelty of the design lies in its low cost indigenous development and simplicity in design. The mechanism primarily consists of ducted fan, roller brush and blower fan to offer slippage-free motion and cleaning on a glassy surface. Series of experiments and field trials demonstrate efficiency of the mechanism in cleaning the modules effectively.;
IoT architecture for urban agronomy and precision applications;In recent years, climate change, high population rates, water scarcity, contaminated farmland, eroding soils, and other factors, have raised serious concerns in the area of sustainable food production. In addition, it has been estimated that by 2050, as much as 80 percent of the earths population will reside in cities [1]. As a consequence, new forms of food production have been explored, especially in places close to or even within the consumption areas, that is, cities. In this context, cities are evolving into intelligent infrastructures in which the aim is to automate, optimize, and improve all possible aspects, including urban agriculture and precision agronomy. Despite recent research efforts, common grounds still have to be defined in terms of how to efficiently automate and provide intelligence to the urban agriculture implementations and integrate those in a transparent and scalable manner to the overall smart city solutions. For this, we believe that smart cities must be conceptualized and abstracted on a higher and different plane than the supporting information and communications technology (ICT) infrastructure. However, the essential properties that make a city smart or a system of systems must be the architectural design assets of the underlying planes. This paper presents a conceptual IoT architecture for urban farming and precision agronomy in Smart Cities based on Software Defined Networks (SDNs) and Cyber-physical systems. Three layers comprise the proposed architecture.;
End user centred interactive software architecture and design: the creation of communities for a smart energy use;CoSSMic (Collaborating Smart Solar powered Micro-grids) is an EU funded project. It aims to develop both hardware and software which will include an ICT system for smart management and control of generated/consumed solar energy in neighbourhood communities. The creation process of energy monitoring and controlling of Graphical User Interfaces (GUIs) is described here. User Centred Design Workshops and face to face interviews were conducted with targeted neighbourhood communities in the Province of Caserta, Italy and the City of Konstanz, Germany. These workshops initiated the first part of the creation process and resulted in paper prototypes leading to functional and partially interactive hardware and software implementations. Thus linking the user to the technical development of the system. Furthermore a dedicated focus was set on the formation and sustainability of smart energy deploying user communities.;
ATE design and development for I-Level maintenance and production line of RCIED Jammer Systems;ASELSAN Inc. has developed an automated test equipment (ATE) for its own design mobile and manpack RCIED (Remote Controlled Improvised Explosive Device) Jammer Systems exported in the scope of technology transfer. This ATE has an ability to test not only the jammer systems but also their line replaceable units (LRUs) and shop replaceable units (SRUs) for intermediate (I-level) maintenance and also ones manufactured in the production line by way of the technology transfer. It eliminates the additional necessity of organizational (O-level) maintenance. LRUs to be tested are the parts such as power amplifiers, couplers, diplexers, remote control units, batteries and antennas. There are also SRUs available such as power supply boards and channel sweeping signal generator boards. In this paper, the hardware and software architecture of the developed ATE and its project special implementation is evaluated. In particular new designed ATE units by ASELSAN, hardware independency of ATE, minimum level of test operator intervention, ease of usage, safety precautions are emphasized. Pros and cons of the designed ATE, and finally the maintainability, reliability and sustainability of such ATE are also discussed.;
The Impact of Integrating Information Technology With Operational Technology in Physical Assets: A Literature Review;"The convergence of information technology (IT) with operational technology (OT), within physical assets can enhance performance but also presents challenges due to higher performance expectations and increased complexity. This study reviews the research that has been conducted to address these convergence and integration challenges by using an in-depth review of academic papers, industry standards, and reports published during the last three decades. Our investigation reveals that about a third of the existing IT/OT research really focuses on the convergence of IT/OT, by including organizational aspects into the study. Three key research domains were identified: maintenance, cybersecurity, and configuration management. The introduction of IT in assets has necessitated changes in maintenance practices, as current approaches are not suitable for these converged lifecycles. Cybersecurity risks have received the most attention in the IT/OT domain. The integration requires the management of these changes; therefore, configuration management has become more crucial than it already is to keep of actual configuration of both the IT and the OT parts of the asset. This research hereby provides relevant observations for practitioners in industry and academics in the IT and the physical asset management domain. The identified gaps suggest the need for tools and methods to better align IT and OT standards, policies, tools, processes, and people throughout the lifecycle of an IT/OT converged physical asset in a sustainable way.";
A New Web-Based Cross-Energy Optimization and Simulation Environment;Making reliable and comprehensible decisions in the context of renewable energy requires complex software solutions. Based on previous work that specifies the Cross Energy Management Programming Language (CEMPL), we present a new web-based tool chain to map real-world objectives and constraints to a set of formalized problem descriptions that is solvable in reasonable time. We describe the main components of the software and its coherence in the field of renewable energy.As proof of concept, we describe and solve a self-contained example with a cross-energy application. We prove that small, declarative programs are sufficient for a varied set of scenarios and simulation results. In particular, we focus on the examination of accumulated super-states for the energy sectors power, gas and heat. The objective is to dimension energy converters and storage systems, based on given constraints. Thus, forecasts are made to enable reliable and green fulfillments of future demands.;
A structured hardware software architecture for peptide based diagnosis of Baylisascaris Procyonis infection;The problem of inferring proteins from complex peptide cocktails (digestion products of biological samples) in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. In the current paper a model-based hardware acceleration of a structured and practical inference approach is developed and validated on a mass spectrometry experiment of realistic size. We have achieved 10 times maximum speed-up in the co-designed workflow compared to a similar software-only workflow run on the processor used for co-design.;
A model for Reflective Middleware based on fuzzy rule for context-awareness injection in ubiquitous computing environments;The next wave of communication and applications will rely on new services provided by the Internet of Things (IoT) which is becoming an important aspect in human and machines future. IoT services are a key solution for providing smart environments in homes, buildings, and cities. In the era of massive number of connected things and objects with high growth rate, several challenges have raised, such as new modeling techniques, patterns, and paradigms for composing and developing software and services able to deal with changing context and requirements. There are several factors to be considered in the design and implementation of IoT platform. One of the most important and challenging problems is the heterogeneity of different objects. This problem can be addressed by deploying a suitable 'mid-dleware' which is placed between things and applications as a reliable platform for communication among things with different interfaces, operating systems, and architectures.In this paper, we propose a solution allowing an IoT middleware to conform with reflective programming paradigm to get more flexibility and adaptivity with reference to the external context. The approach is based on a formal model in which fuzzy rules enable the actions that can be activated by the system. We implemented and validated the proposed model on a real IoT middleware in a smart home scenario.;
D?DT: the Deakin University Microgrid Digital Twin;In 2021, the largest solar farm and renewable energy microgrid to date at an Australian university commenced operation. Located at the Waurn Ponds campus of Deakin University, the microgrid will be a key enabler for the University to achieve its carbon neutrality and 100% renewable electricity targets by 2025. The 14-hectare solar farm is capable of producing up to 7.25MW power which translates to 54% of the electricity demand of the campus. To enable real time system monitoring, data analysis, power output prediction, and simulation of the microgrid for answering what-if questions, a digital twin was developed in-house. In this paper, we present the Deakin Microgrid Digital Twin (D?DT) with a focus on the health monitoring functionalities (essentially a microgrid assessment tool), including: efficiency monitoring, alarm analytics, and Artificial Intelligence (AI)-driven anomaly detection. The design of the digital twin is general in nature, with software, machine learning and visualisation components designed to make it possible for utility extensions beyond the Microgrid application.;
An IoT Based Healthcare Solution With ESP32 Using Machine Learning Model;The pandemic in 2020 has brought unprecedented changes in all possible affairs of life and the healthcare sector is no exception to it. The situation stimulated an increment of the overall use of IoT. In healthcare sector IoT can be an impactful add-on to ensure remote healthcare and non-contact treatment of patients. Such facilities can ensure continuous inspection of patients over the time to help in better treatment. Additionally, the real time data clouding can come handy where large number of documentation of data is needed. This paper proposes an IoT healthcare device with embedded temperature, beats per minute and SpO 2 and intelligent prediction of one’s health status by machine learning model named LightGBM with a prediction accuracy of 91.12%. Furthermore, data clouding system has also been developed for public and local server to share real time data with other users and doctors. The proposed technology has been designed to assist non-tech users all around the world with a user-friendly approach to get accustomed to smart health care.;
IoT-based Web-Integrated OBD-II Telematics for Real-Time Vehicle Health Monitoring System;A real-time vehicle health monitoring system remotely collects the operating status of various sub-systems in the vehicle. Vehicle diagnostic data is helpful in driver behavior analytics, vehicle data analytics, and automotive insurance markets. A live vehicle health checking system utilizing Internet of Things (IoT) technology has been proposed and implemented using the ELM327 OBD scan tool and MQTT protocol. The OBD scanner remotely acquires the data of various vehicle parameters while the vehicle is on the move. Then, the MQTT protocol forwards the data from the vehicle to a web application using an HIVEMQ broker. The received diagnostic information is displayed on the webpage using animated gauges. Alternatively, the collected data is compared with the predefined thresholds and alerts the user for any detected faults.;
Comparison of network architectures for a telemetry system in the solar car project;A solar car is an electric vehicle that runs entirely on solar energy. Designing, building and racing solar cars has been a longstanding worldwide challenge for engineering and computer science students, with the overarching goal being to design devices that use sustainable energy sources. This article describes our experience and educational outcomes (the modeling and design of computer-based systems in a way that demonstrates comprehension of the trade-offs involved in design choice) attained while designing the network architecture for a solar car project.;
Modeling flexibility on internal quality assurance system business process;The new policies and regulations of quality assurance system for higher education institutions (HEIs) in Indonesia requires many significant changes to the supporting information systems including internal quality assurance system - information system (IQAS-IS). Internal factors such as changes in organisational structures, needs of exchanging data within HEI in different formats and technology platforms also contribute to this issue. When IS didn't provide the certain level of flexibility needed, the efforts to cope with the changes and variety are usually big and time consuming. Therefore, many times it ends up with decision to rebuild the IS. This resulted in low sustainable of IQAS-IS. This article discusses about identifying the business processes which require specific level of flexibility followed by modeling flexibility for the future IQAS-IS and then, measuring wether the proposed model of business process enabling flexibility. The identification process is done by means of literatures review, observation and focus group discussion followed by modeling using Business Process Management Notations (BPMN) and then, measuring flexibility through case analysis. By enabling flexibility to IQAS business process, the future IQAS-IS will get better operational implementation and better law implementation. Thus, IQAS-IS will be sustain and be able to support continous improvement.;
Wireless Load Monitoring System for Automatic Demand Response;In this developing world, Electricity is an important one in our day-to-day life. With the development in modern communication technology, every physical device is now connecting with the internet. Improper billing and inefficient revenue collection and interruption in the power supply are the factors responsible for the downfall of SEB. The amount of energy used for the various factors is considered as the same irrespective of the loads, which becomes an injustice for the consumer as well. This can be prevented by implementing an improvised distribution system with Wireless load monitoring system are proposed to monitor the usage of electrical energy consumed by any appliance or machine at any given time to provide uninterrupted power to critical loads, penalty calculation and for the varied tariff calculation based on the usage of loads. Wireless load monitoring system evaluates the consumption of the load for a number of devices. Through this the tariff can be calculated for the consumers based on the loads that are used so that the basic electricity requirements can be provided at free of cost and the larger user may be charged.;
Study on Ejina Oasis Land Cover Using Decision Tree Classification;"The automatic recognition of images has been always one of preceding issues in the filed of remote sensing. From traditional algorithm of K-Means, maximum likelihood to new decision tree, neural networks, wavelet transform and fuzzy recognition system, the classification accuracy has been improved. In this work, based on Decision Tree Classification (DTC) and Landsat ETM+ data, Ejina Oasis land cover is classified. And the applications of NDVI, K-T transformation and Principal Component Analysis (PCA) into the decision tree classification are mainly studied. Finally, the accuracy of the classification results is analyzed. The results indicate that the built decision tree model is reasonable; the overall accuracy is up to 93.28%. It can provide scientific basis for the ecological health dynamic monitoring and regional sustainable development of Ejina Oasis.";
Design of a Smart IoT-AI Enabled Recycling Machine with Gamification Techniques;Recycling is a crucial process in decreasing pollution and waste materials. Unfortunately, many people find it a time-consuming task and are not incentivized enough to do it, thus the need for a system to simplify the process and make it more enjoyable. The system uses a Convolutional Neural Network to detect and classify the waste material and then a hardware mechanism to segregate the waste. The model utilizes a custom dataset and achieves a precision of 89%. The system is also equipped with a sensor network which connects to the Internet and views the results on an Internet-of-Things platform.;
Green Monitoring System For Energy Saving In Accommodation Services;Bali is an area that emphasizes the economy on the tourism industry. Based on the observation of accommodation services In Bali, Indonesia shows that several hotels or villas are installed with energy-intensive devices. This study aims to produce an energy monitoring system consist of an automatic electrical control system and an energy monitoring information system. The system is to help controlling and monitoring energy use in accommodation services, named the Green Monitoring System. The automatic control system uses a Programmable Logic Controller which consists of a DHT11 sensor, ACS712 electric current sensor, and infrared. Electronic devices that are controlled by this system are Air Conditioning (AC). Data obtained from the electrical control system, is then processed and displayed through a monitoring information system. The concept of monitoring information system development was developed with a green software development life cycle approach. This study produced two information system prototypes and the results of the analysis show that differences in design and coding have a significant impact on the greenness of information systems.;
Implementation of a novel complex mechatronics software framework on laser micromachining workstation;As technology brings more complex and sophisticated systems, the importance of the problem of designing and developing a mechatronic system increases as well and it becomes more complicated to obtain a reliable, accurate and sustainable system. Since complex systems are generally composed of many different types of sub-systems, a necessity for a systematic approach towards the development arises. In this paper, the problem of software development for complex mechatronic systems is addressed and a novel software framework is proposed in order to provide common design and development criteria and related software structures. As an implementation of the framework and to present a proof of concept, software for a laser micromachining workstation is developed from scratch using this framework. Experiments are conducted using the workstation and results are provided.;
COMP4DRONES Contributions for Enabling Safe and Autonomous Drones;Drone-based service and product innovation is curtailed by the growing dependence on poorly interoperable proprietary technologies as well as by the risks posed to people on the ground, to other vehicles and to property (e.g., critical infrastructure). The aim of COMP4DRONES is to provide a framework of key enabling technologies for safe and autonomous drones. In this paper, we discuss the different technical contributions of the COMP4DRONES project to create this framework. These contributions support (1) efficient customization and incremental assurance of drone-embedded platforms, (2) safe autonomous decision making concerning individual or cooperative missions, (3) trustworthy drone-to-drone and drone-to- ground communications even in presence of malicious attackers and under the intrinsic platform constraints, (4) agile and cost-effective design and assurance of drone modules and systems, and (5) sustainable impact and creation of an industry-driven community. In addition, lead applications driving ecosystem development and benchmarking on the fields of transport, inspection, logistic and agriculture are developed.;
A structured hardware software architecture for peptide based diagnosis — Sub-string matching problem with limited tolerance;The problem of inferring proteins from complex peptide samples in shotgun proteomic workflow sets extreme demands on computational resources in respect of the required very high processing throughputs, rapid processing rates and reliability of results. This is exacerbated by the fact that, in general, a given protein cannot be defined by a fixed sequence of amino acids due to the existence of splice variants and isoforms of that protein. Therefore, the problem of protein inference could be considered as one of identifying sequences of amino acids with some limited tolerance. Two problems arise from this: a) due to these (permitted) variations, the applicability of exact string matching methodologies could be questioned and b) the difficulty of defining a reference (peptide/amino acid) sequence for a particular set of proteins that are functionally indistinguishable, but with some variation in features. This paper presents a model-based hardware acceleration of a structured and practical inference approach that is developed and validated to solve the inference problem in a mass spectrometry experiment of realistic size. Our approach starts from an examination of the known set of splice variants and isoforms of a target protein to identify the Greatest Common Stable Substring (GCSS) of amino acids and the Substrings Subjects to Limited Variation (SSLV) and their respective locations on the GCSS. The hypothesis made here is that these latter substrings (SSLV) appear inside complete peptides and not cutting across peptide boundaries. Then we define and solve the Sub-string Matching Problem with Limited Tolerance (SMPLT) using the Bit-Split Aho Corasick Algorithm with Limited Tolerance (BSACLT) that we define and automate. This approach is validated on identified peptides in a labelled and clustered data set from UNIPROT. A model-based hardware software co-design strategy is used to accelerate the computational workflow of above described protein inference problem. Identification of Baylisascaris Procyonis infection was used as an application instance. This workflow can be generalised to any inexact multiple pattern matching application by replacing the patterns in a clustered and distributed environment which permits a distance between member strings to account for permitted deviations such as substitutions, insertions and deletions. The co-designed workflow achieved up to 70 times maximum speed-up compared to a similar workflow purely run on the processor used for co-design.;
IoT-WSN Self-Data Positioning and Self-Remedial Monitoring Support using XGBoost Analyzer;A self-data positioning and self-remedial monitoring refers to a structure or software architecture designed to automatically set up, adapt, and recover from failures without requiring manual intervention. These frameworks are particularly valuable in complex, dynamic environments where changes may occur frequently, and quick recovery from faults is essential. Many of IoT structures, the standard of outcome has to be guaranteed in agreement with the requisite of the execution field. The forceful character of the IoT adjoining build it complicates to manage the bonds. The standard outcome exposed to danger by a broad scale of sudden situations. Self-data positioning structure can distribute the structure sudden performance at implementation. In IoT build WSNs, the most important self-controlling goals are self-data positioning and self-remedial. In this paper Self data positioning, self-remedial monitoring support by XGBoost analyzer is implemented. The framework, the IoT data packets were categorized to different groups utilizing XGBoost Analyzer. At self-data positioning stage, the IoT gadgets were self-data positioned by assigning independent communication period, contention access period (CAPs) depends on the classification and concern. At self-remedial stage, the left over capacity of middle node is shortened or it is displaced further away, contracted way recovery track is fixed by the origin node basically. The presented framework is accomplished in NS2 simulator and out turn gives that the presented system has more data distribution ratio with minimal data loss and algorithmic value.;
SE4AI: A Training Program Considering Technical;We share our experience developing a training program that provides trainees with technical, social, and professional knowledge in the context of artificial intelligence-based software systems. Survey results indicate the program has helped trainees increase their awareness of social and ethical issues.;
A Proposal for a Models-Meet-Data Repository for Digital Twins in Construction Engineering;Digital twins enable real-time, model- and data-based simulations of physical assets or systems yielding more effective monitoring, analysis, and decision-making for enhanced performance and efficiency. The construction industry is highly interested in utilizing digital twins due to their potential to facilitate collaboration along the building life cycle, optimizing building energy usage, asset life cycle management, and data-driven decision-making to achieve sustainability objectives. Currently, necessary technological solutions that effectively tackle the inherent challenge of federating and integrating models and data that arises in these scenarios are however missing. Expanding upon the achievements of model-based engineering and its technological infrastructure, we propose a model repository for digital twins that tackles the models-meet-data challenge and establishes a technological basis for collaborative workflows. To this end, we carried out an extended requirements elicitation, architectural synthesis, and validation procedures. Preliminary empirical findings using an initial prototype suggest that the repository exhibits the necessary scalability, performance and isolation for collaborative work.;
Automotive Real-Time Operating System in Vehicular Technology Progress Review;Degrees of human intervention for vehicular technology have been decreasing in the past few years. Automated cars and even autonomous ones have been appearing in successive events. One aspect to note is that automated systems for automobiles are believed to follow the technology for electric vehicles. For instance, with electric cars, people no longer have to worry about maintenances for valves, camshafts, connecting rods, crankshafts, transmission gears, clutches, and any other complexities of a car with an engine and a transmission. With a simpler environment for car interiors, we could focus more on enhancing its performance with even less monitoring utilizing automation. It will then require a real-time control system to guarantee timely responses and task priority setups for internal and external events of real-time systems, especially for the migration of Internal Combustion Engine (ICE) vehicles to electric cars.;
Wireless Sensor Networks for Distributed Chemical Sensing: Addressing Power Consumption Limits With On-Board Intelligence;Chemicals detection and quantification is extremely important for ensuring safety and security in multiple application domains like smart environments, building automation, etc. Characteristics of chemical signal propagation make single point of measure approach mostly inefficient. Distributed chemical sensing with wireless platforms may be the key for reconstructing chemical images of sensed environment but its development is currently hampered by technological limits on solid-state sensors power management. We present the implementation of power saving sensor censoring strategies on a novel wireless electronic nose platform specifically designed for cooperative chemical sensing and based on TinyOS. An on-board sensor fusion component complements its software architecture with the capability of locally estimate air quality and chemicals concentrations. Each node is hence capable to decide the informative content of sampled data extending the operative lifespan of the entire network. Actual power savings are modeled and estimated with a measurement approach in experimental scenarios.;
Revolutionizing Agricultural Finance: Simplifying Farmer Access to Financial Tools with an Innovative Fintech Platform;Agriculture stands as the cornerstone of global sustenance and economic prosperity, yet smallholder farmers face significant financial barriers. Despite advancements in agricultural technology and markets, access to financial services remains limited for smallholders. We've thoroughly examined 25 research papers in this field to assess the extent of existing research. Subsequently, we conducted a comprehensive market analysis and competitive review to shape the design of our platform. This study introduces an innovative fintech platform aimed at bridging this gap by facilitating connections between farmers and financial service providers. By leveraging precision risk analysis, inclusive microloans, comprehensive insurance coverage and democratized investment opportunities, our platform seeks to enhance sustainable farming practices and boost productivity for smallholder farmers. Our platform utilizes data analytics to assess risk factors specific to agricultural activities, thereby providing personalized financial solutions and mitigating risks inherent in farming operations.;
Hadoop branching: Architectural impacts on energy and performance;Data centers are notorious energy consumers. In fact, studies have shown that for every 1spentonhardwareinthedatacenter,0.50 is spent on powering this hardware over its lifetime. Data centers host real or virtual (i.e., cloud) clusters that often execute large compute jobs using MapReduce, of which Hadoop is a popular implementation. Like other successful open source projects, Hadoop has been maintained and evolved over time with new resource management features being added over time in an effort to improve performance, raising questions as to whether such architectural evolution has achieved its goal, and if so, at what cost. In this work we apply Green Mining to find out that later versions of Hadoop - who exhibit more dynamic resource control - can suffer from serious energy consumption performance regressions.;
SPOT (Sales Production based On Time-Series): A Comprehensive Approach to Sales Forecasting using Contextually-tailored Time Series Analysis;"Unit sales in retail chain stores exhibit a significant degree of variance, affected by seasonality and special events. Individual products and categories also display a considerable difference in sales based on the geography of individual stores. In various businesses, a myriad of products is moved each day, and accurately predicted knowledge of sales facilitates the planning of logistics, warehousing, and procurement, besides other executive decision-making processes. Software developed for this purpose are undergoing continuous improvements. SPOT (Sales Production based On Time-Series) is an application to produce sales forecasts for customized input parameters – such as an individual store, state in which store is located, a particular product, category/sub-category of products, which will prove to be immensely useful for decision-making processes across a variety of concerned business units. SPOT delivers the results in the form of graphical summarization of selected data, along with its time-series forecasts. More incisive sales predictions can be exported as a tabular numeric file. For the purpose of demonstrating the entire process, data from Walmart was considered; however, this can be extended to any related application fields as well.";
Multi-tenant web application framework architecture pattern;Multi-tenancy is a key to successful and sustainable cloud-based systems. Creating a web application framework for multiple tenants from scratch is challenging. To create an extensible, stable and robust multi-tenant web application framework developers have to understand how a web application framework is structured and how a web request is handled for each user of a specific tenant. This knowledge often takes software architects and developers a lot of effort to obtain. In this paper, we present a novel object-oriented architecture pattern for developing multi-tenant web application frameworks in which maximum reuse and modularity can be achieved and application concerns can be separated. We evaluate the modularity, the extensibility, the reusability, the maintainability and the efficiency of our pattern by qualitative analysis based on well-known patterns used in our pattern. We validate the applicability, the correctness, the security and the performance of our pattern by testing real world systems that were built using our pattern. We believe that our pattern would reduce time and cost when developing multi-tenancy systems as well as understanding, evaluating and modifying existing web application frameworks.;
Enhanced connectivity and harmonization of data for the Adriatic Intermodal Network using modular integrated software;The realization of a modular integrated software for the management of intermodal transport services in port areas for passenger transport will enhance connectivity and harmonization of data for the Adriatic Intermodal Network in order to improve the efficiency, quality, safety and environmental sustainability of maritime and coastal transport services. Design and development of the services, interfaces and main functions integrated in modular software platform will be presented. The presented research has been supported by the European Regional Development Fund, under the Interreg V IT-HR CBC programme, project ID: 10048282 (E-CHAIN).;
Probabilistic indicators for soil and groundwater contamination risk assessment;Deterministic assessments of whether, when, and where environmental safety thresholds are exceeded by pollutants are often unreliable due to uncertainty stemming from incomplete knowledge of the properties of environmental systems and limited sampling. We present a global sensitivity analysis to rank the contribution of uncertain parameters to the probability, P, of a target quantity to exceed user-defined environmental safety thresholds. To this end, we propose a new index (AMAP) which quantifies the impact of a parameter on P and can be readily employed in probabilistic risk assessment. We apply AMAP, along with existing moment-based sensitivity indices, to quantify the sensitivity of soil and aquifer contamination following herbicide glyphosate (GLP) dispersal to soil hydraulic parameters. Target quantities are GLP and its toxic metabolite aminomethylphosphonic acid (AMPA) concentrations in the top soil as well as their leaching below the root zone. The global sensitivity analysis encompasses six scenarios of managed water amendments and rainfall events. The biodegradation of GLP and AMPA varies slightly across scenarios, while leaching below the root zone is greatly affected by the assumed hydrologic boundary conditions. AMAP shows that, among the tested uncertain parameters, absolute permeability, air-entry suction, and porosity have the greatest impact on GLP and AMPA probability to pollute the aquifer by exceeding the aqueous concentration thresholds. Our results show that AMAP is effective to thoroughly explore time histories arising from model-based predictions of environmental pollution hazards. The proposed methodology may support informed decision making in risk assessments and help assessing ecological indicators through threshold-based analyses.;
Awakening Awareness on Energy Consumption in Software Engineering;Software producing organizations have the ability to address the energy impact of their ICT solutions during the development process. However, while industry is convinced of the energy impact of hardware, the role of software has mostly been acknowledged by researchers in software engineering. Strengthened by the limited practical knowledge to reduce the energy consumption, organizations have less control over the energy impact of their products and lose the contribution of software towards energy related strategies. Consequently, industry risks not being able to meet customer requirements or even fulfillcorporate sustainability goals. In this paper we perform an exploratory case study on how to create and maintain awareness on an energy consumption perspective for software among stakeholders involved with the development of software products. During the study, we followed the development process of two commercial software products and provided direct feedback to the stakeholders on the effects of their development efforts, specifically concerning energy consumption and performance, using an energy dashboard. Multiple awareness measurements allowed us to keep track of changes over time on specific aspects affecting software development. Our results show that, despite a mixed sentiment towards the dashboard, changed awareness has triggered discussion on the energy consumption of software.;
Adopting an Agile Approach for Reflective Learning and Teaching;"Software engineering is concerned with how best to create software in ways that promote sustainable development and maximise quality. We have been largely successful at transferring software engineering knowledge into the industry, however, many challenges in software engineering training remain. A key amongst these is how best to teach practical engineering approaches along with the theoretical concepts behind them.
This paper describes our experience of adopting an agile approach for reflective learning and teaching within the context of our Software Systems Engineering module, aimed at addressing challenges identified with previous efforts to promote reflective practice. Our study attempts to strengthen the use of reflective learning approaches for our current cohort, as well as introducing reflective teaching practices, whereby we examine our teaching approach in order to improve its efficiency and effectiveness. Our analysis of student response to the module shows that it was very well-received by the students, and we were able to collect ample evidence from feedback to support this. Most of our approaches resulted in positive feedback and contributed to improvements in teaching quality, however, we also identified some key aspects in our method that could still benefit from refinement, such as the need for explicit links between learning outcomes and workshop activities, and intuitive design of feedback questions, along with feedback collection frequency. We plan to incorporate these additional updates into the revision of the module for the next academic year, and to continue collecting and analysing feedback data for further enhancement.";
Research on Distribution Line Ad Hoc Network Technology Based on Intelligent Distributed FA;Research the technology of distribution terminal that based on intelligent distributed FA, research the terminal information interaction mechanism of dynamic topology operation model, using the topological analysis algorithm of dynamic topology of ad hoc network, implementation of distributed FA line topology Ad Hoc Network Technology, improving reliability and practicability of distribution automation terminal.;
Accuracy of Compact mmWave Radar Sensor for Vital Signs Monitoring;"With rapid development in circuit design and antenna design technology, the available features of mmWave technology experience sustainable growth. With its extensive features such as high presicion and accuracy, large bandwidth and high doppler frequency; the mmWave sensor has become an essential part of automotive, medical and industrial applications. In this work, the application of mmWave sensors for non-contact vital signs monitoring is investigated. Despite the progress, existing mmWave radar sensors have inherent limitations. This work investigates the Texas Instruments IWR1443BOOST sensor's accuracy across various distances which demonstrates that the IWR1443BOOST sensor becomes ineffective after 1 m distance.";
Overview of WBAN from Literature Survey to Application Implementation;The science of Wireless Body Area Network (WBAN) and its overwhelming potential over medical treatment and body testing has greatly improved over the years, and with the globalization phenomenon hospitals are now able to treat their patients remotely, and medical camps have proved to be much more productive than before. This paper will focus on the existing trends and literature survey, the pre-laying architecture, and the working WBAN system, along with its networking capabilities and practical applications. With the growing need for medical treatment and healthcare, WBAN has become a necessity at treating patients, then and there as required. The usage of the WBAN systems is not only limited to the healthcare field, but also for military and space training. The WBAN ideology and the networking methods can be implemented for various fields that includes distributed networking and organizational needs. This study aims to provide a detailed overview over the varying aspects, structures, and applications that the WBAN can satiate. The ability to autonomously operate and provide sensor data from various parts of the human body and transfer the data to a geographically far or remote location for real-time accessing and support, has made WBAN a lifesaver. Also, the various parts of the WBAN system can be added and removed as per the application requires greatly providing flexibility, and in-turn provide better real-world support than any other smart systems.;
Fault Analysis and Debugging of Intelligent Connected Car Wire-Controlled Chassis System;This research study deals with the fault analysis and troubleshooting of the electronically controlled chassis system of the intelligent connected vehicle. The author first emphasizes the critical role of electronic and electrical architecture design in the technological innovation of intelligent connected vehicles. Special attention is given to the AUTOSAR software architecture, a collaborative project developed by automotive companies to provide leading solutions for implementing functionality. AUTOSAR emphasizes the improvement of software reusability, portability, and scalability, fostering collaboration among different manufacturers and suppliers, leading to resource sharing and cost savings. The paper reviews the latest research on intelligent connected vehicles, including multi-agent systems, communication, and joint approaches involving caching and computation. These studies demonstrate how advanced technologies and algorithms can optimize traffic flow and improve safety performance. Finally, this study introduces a novel automotive fault sensor model using the DS18B20 temperature sensor and the AWA14400 vibration sensor. This helps to detect temperature and vibration in vehicles, facilitating diagnosis and prevention of potential problems. In addition, a fuzzy fault tree model is constructed for fault analysis. In summary, this research provides an in-depth study of the fault analysis and debugging of the electronically controlled chassis system of the intelligent connected vehicle, which provides valuable insights for the future development of intelligent connected vehicles.;
Agricultural Product Quality Traceability System Based on the Hybrid Mode;Aiming at the demand of consumers for the quality and safety guarantee of agricultural products, a traceability system of agricultural products quality based on hybrid mode is designed and developed in this paper. The system connects the various links of crop planting, acquisition, processing, distribution and sales, and obtains the real-time information from crop seed cost to agricultural product sales. It can make farmland scientifically be managed according to the information of crop growth environment, improve the utilization rate of agricultural resources, and be beneficial to the sustainable development of agriculture. At the same time, the information of the processing, transportation, and sale of the crops from the seeding to the harvest to the agricultural products are recorded in real time in the database so that the consumers can understand the relevant information of the agricultural products in real time. If the unqualified agricultural products are checked out, the production of this kind of agricultural products can be controlled immediately from the source, and the circulation of unqualified agricultural products can be controlled more effectively. Therefore, the legitimate rights and interests of consumers can be effectively guaranteed.;
Does IT architecture matter?;In the last two decades, many research articles have been published about outsourcing and in recent years, some research articles have been written about IT architecture [1, 2, 3, 4]. Separate research on outsourcing and IT architectures could not shed light if IT architecture maturity has any impact on outsourcing. This research article is based on the core IS capabilities framework of Feeny and Willcocks (1998). In their framework, the authors proposed that IS core capabilities are retained, enhanced and maintained by three most important constructs. These are `business and IT vision', `IT architecture' and `outsourcing'. It is very logical to agree unanimously that `business and IT' vision construct is the nucleus of any IT based modern organization. Through literature review and analysis, this article will make in depth study of the proposed framework by Feeny and Willcocks, to find its relevance and validity after a decade and will address the following questions. Are `IT architecture' and `outsourcing' relevant and valid constructs? Are these two constructs in any way linked to each other? The focus of this article is, in general, on the IT technologies and in particular, on the IT architecture maturity. A good combination of this two should enhance the positive outcomes from outsourcing with out loosing the core competencies.;
A Blockchain Based Sustainable Digital Insurance Business Parametric Solution Architecture to Protect Realtime QSR Business Interruption Losses;An insurance policy will reimburse the company if something bad happens to something that is covered under the policy to bring sustainability to the business. The process of settling a dispute can take a long time because there are many people involved. Parametric insurance is different from traditional insurance. Traditional insurance is a type of insurance in which a company pays out a certain amount of money, no matter what happens. Parametric insurance is designed to protect policyholders from certain events, by paying out a set amount depending on the severity of the event. In the perishable food and quick service restaurant sector, disruptions caused by delays are one of the types of events that parametric insurance may be able to cover. Supply chain delays can happen for several reasons. Events like adverse weather, heavy traffic, and poor road conditions can all slow down the supply chain of perishable food items and groceries. On the other side for smaller QSRs, footfall may be reduced drastically on specific conditions. Parametric-based insurance starts processing claims when a certain event takes place. Insurance claims may be processed automatically by the terms and conditions provided in the policy definitions, and delays that result in undesired scenarios may be insured. Building parametric insurance policies using the conventional centralized database approach is possible, but there are trust difficulties because the data is vulnerable to manipulation. This study explores the approach to the issue and the software architecture of the dependable blockchain-based digital technologies supporting parametric perishable food and QSR supply chain insurance. We will go into detail about the user experience, technological solutions, deployment issues, and insurance for parametric services. The proof of concept for parametric insurance was completed, and the resulting blueprint may be applied to more use cases in adjacent industries.;
Towards a software defined reference architecture for smart city ecosystems;"With the convergence of information and telecommunication technologies, the vision of the `Smart City' is fast becoming a reality. City governments in a growing number of countries are capitalizing on these advances to ease the lives of their citizens and to increase efficiency and sustainability. In this position paper, we outline our vision for the creation of a reference architecture for Smart City projects, which could serve as the design language for creating smart cities blueprints. Such a blueprint would cater for diverse stakeholders, devices, platforms, and technologies. We argue that a new approach for designing such ultra large and ultra-heterogeneous ecosystems is needed. Hence, we propose a reference architecture inspired by several efforts in software engineering such as SOA. The proposed reference architecture would serve as a blueprint and starting point that contains architectural building blocks, best practices, and patterns; instead of starting from scratch. We present an initial meta-model with multiple views and highlight intra and inter views relationships. We survey the state of the art, outline our research approach, and suggest a research agenda for the smart city software community at large.";
Software and communications architecture for Prognosis and Health Monitoring of ocean-based power generator;This paper presents a communications and software architecture in support of Prognosis and Health Monitoring (PHM) applications for renewable ocean-based power generation. The generator/turbine platform is instrumented with various sensors (e.g. vibration, temperature) that generate periodic measurements used to assess the current system health and to project its future performance. The power generator platform is anchored miles offshore and uses a pair of wireless data links for monitoring and control. Since the link is expected to be variable and unreliable, being subject to challenging environmental conditions, the main functions of the PHM system are performed on a computing system located on the surface platform. The PHM system architecture is implemented using web services technologies following MIMOSA OSA-CBM standards. To provide sufficient Quality of Service for mission-critical traffic, the communications system employs application-level queue management with semantic-based filtering for the XML PHM messages, combined with IP packet traffic control and link quality monitoring at the network layer.;
Agriculture Water Quality Monitoring in Tunisia: Embedded Prototype Conception;Water quality monitoring plays a capital role in ensuring the sustainable and efficient use of water resources in irrigation systems. This paper presents a comprehensive analysis of the strategic sector of real time water quality monitoring in the context of irrigation systems. It focuses on the development and implementation of an IoT embedded prototype system for monitoring essential agriculture water quality parameters, including Conductivity, pH, Temperature and Dissolved Oxygen. The study highlights the significance of real-time data collection and analysis for water quality informed decision-making in agricultural practices.;
Applied Internet of Things Architecture to Unlock the Value of Smart Microgrids;This paper presents an applied Internet of Things (IoT) architecture for smart microgrids. Smart microgrids use IoT-enabling technologies conjointly with power system equipment to deliver additional services on top of the basic supply of electricity to local networks that operate in parallel with the regional grid or autonomously. Such ancillary services offered by the microgrid—e.g., local balancing, internal congestion management, and aggregation to support market or grid operator activities—can create value for its end-users and other stakeholders. A systems engineering design approach is used to apply two reference architectures from different domains (power systems and IoT) to create a novel, high-level framework for the design of information and communication technologies systems for smart microgrids. The framework covers the device layer, connectivity system, data processing and storage layers, and business applications. The IoT architecture for smart microgrids is applied to a case study of a pilot project in an industrial and commercial area in The Netherlands.;
A Survey on Electronic Voting On Blockchain;Public elections are a basic tenet of representative democracy but most current voting methods e.g., Ballot-based voting and Electronic Voting Machines are riddled with drawbacks such as a lack of trust from voters and poor voter turnouts. Blockchain voting addresses the limitations in these legacy-voting methods by serving as a secure, easy, and cost-effective alternative to these voting methods while also having various other upsides (like quicker vote tallying). This paper analyses the underlying technology of Blockchain and compares various proposed implementations available to date;
Bluetooth Based Home Automation Using Android Phone;Electronic devices and appliances have become very common in this recent year of technology especially with the fast development of smartphones. In this paper, the design of the Home Automation System compatibly with Local housing and good features for home automation via remote access is presented. Bluetooth Based Home Automation System Using Android and Arduino is design and implemented. In this research work, a part of smart home technology that using Bluetooth in a mobile device is used, so it will cheap and efficient to use. This paper describes a home automation system that would use to enable home lighting, garage door motor, water pumping motor, and smoke detection using a smartphone application with Bluetooth wireless technology. The system included three main components: an Arduino microcontroller for connecting the appliances, a Bluetooth module for signal transfer, and a smartphone with the Android application to control home appliances. Bluetooth communication technology and controlled system are that the operating range is low but it can be controlled from anywhere inside of the home, By using smartphone application we can control household appliances and provide security to decrepit peoples. The idea of the paper is to control home appliances to avoid the danger of electric shock and convenience of decrepit and physically disabled people, who can easily access and control the home appliances by staying at a particular place and access them remotely without the help of other people. By using this system, our home automation works smartly by providing increased quality of life and comforts to users.;
Research on Monitoring Technology of 5G MEC Virtualization Environment;In view of the security risks in 5G network virtualization environment, this paper describes the security monitoring components of 5G MEC network virtual machine and container environment. By monitoring the host machine, Docker, container, KVM and other environments, the security status of operation permissions, network communication, file system, resource limitation, run operation, process operation and so on can be collected. The design scheme of the monitoring module and the realization method of the key function modules are introduced in detail, and the function verification is carried out.By monitoring the virtualized environment, the security protection of MEC and other nodes can be effectively realized, the overall defense capability of 5G network in power system can be improved, and the existence of 5G network carrying power business can be seen, managed and controllable.;
Empowering Urban Accessibility: A Prototype System for People with Disability;This work demonstrates the development of a prototype system that could improve urban and digital accessibility for People with Disability - PwD. The research involves using an academic questionnaire to enable a wider perspective of the central subject and assessing the effectiveness of the proposed solution. The main goal is to help social integration and make the future solution implementable for smart cities through an experiment in an academic campus. The dissertation is related to technological and social issues that might be used as a resource by researchers, public or private bodies interested in more profound studies. The document recognizes the lack of studies on this subject, especially in Brazil because there are few available articles. The prototype system is designed to tackle the issues faced by persons with disability in urban settings through platforms, applications and mobile phones as it proposes a comprehensive set of solutions when addressing accessibility for PwDs. In turn, this research fosters knowledge advancements in the field of urban accessibility and provides vital recommendations for developing inclusive technologies and policies.;
Computer Based Emulation of Power Electronics Hardware;This paper defines a highly optimized computer architecture and FPGA technology as the most feasible approach to satisfy the challenging requirements defined by the need to emulate power electronics hardware with sub-microsecond latency and sampling time. The proposed commercial off the shelf computational platforms and the accompanying software tools based on the industry standard software platform have the potential to bring qualitative improvements in the way how power electronics software is designed, how it is tested and how its performance is verified.;
AppCivist - A Service-Oriented Software Platform for Socially Sustainable Activism;The increased adoption of mobile devices and social networking is drastically changing the way people monitor and share knowledge about their environment. Here, information and communication technologies (ICT) offer significant new ways to support social activism in cities by providing residents with new digital tools to articulate projects and mobilize activities. However, the development of ICT for activism is still in its infancy, with activists using basic tools stitched together in an ad hoc manner for their needs. Still, Internet-based technologies and related software architectures feature various enablers for civic action beyond base social networking. To that end, this paper discusses the vision and initial details of AppCivist, a platform that builds on cross-domain research among social scientists and computer scientists to revisit service-oriented architecture and relevant services to further social activism. We discuss the ICT challenges inherent in this project and present our recent work to address them.;
Applying Game Theory Economics to Clean Renewable Energy Source Implementation in Urban Areas;This paper explores the possibility of implementing urban renewable energy by merging the efforts of investors, the technical private sector and the real-estate owners. We will identify a solution that provides benefits to all involved while automatically keeping profit margins fair. The added bonus would be clean air and sustainable energy generation at the location where it is needed most: urban areas. We will define the mathematical model that matches owners with technical installers and investors. We will then proceed to analyze the model from a game-theory economics point of view in order to determine if the system reaches an equilibrium that evenly shares in the profit. In the end conclusions are drawn and system fairness is discussed. This system is presented as an alternative to bank loans by sharing the risk between three well intended stakeholders while overseen by an automated system of rules and matching strategies.;
BIM-GIS Integration for Infrastructure Management in Post-Disaster Stage;The post-disaster phase, which ensues immediately after a catastrophic event, encompasses vital activities related to reconstruction, often varying in duration based on the disaster's magnitude and local conditions. This period presents unique challenges, including data scarcity and the intricate nature of infrastructure utilities. The lack of comprehensive information regarding infrastructure utilities can lead to damages, accidents, fatalities, disruptions, and project delays. Additionally, the post-disaster phase places immense pressure on local governments to swiftly make informed decisions and execute effective responses. To address these challenges, the integration of Building Information Modeling (BIM) and Geographical Information System (GIS) technologies has emerged as a promising solution. This integration has been explored in various studies, ranging from incorporating GIS into project management software applications to devising software architectures for the seamless integration of BIM into GIS, resulting in more efficient infrastructure management. The amalgamation of BIM and GIS is instrumental in post-disaster infrastructure management, offering a plethora of benefits such as improved decision-making, cost reduction, and enhanced collaboration among stakeholders. This paper aims to fulfill several objectives, including identifying contemporary trends in BIM and GIS research, documenting the existing body of knowledge related to their fusion, and providing recommendations for future research endeavors. In this study, a comprehensive literature review was conducted. The analysis delves into the utilization of BIM-GIS integration, its present applications, and potential future prospects in the context of sustainable built environments.;
WoA - Wisdom of Age: Collaborative Learning using Human-Computer Interaction;The development and use of Cobots in industry, institutions, and healthcare, as well as the strong penetration of chatBots, reinforce the interdisciplinary nature of technological processes, which are flooded with data and information, making it almost impossible for the younger generation to go in depth and understand the requirements of a particular process. In contrast older experts (e.g., engineers aged 50–75) have a high level of expertise in technological process as well as other skills such as management knowledge, which are essential for the implementation of technological projects. The paper presents a learning management system (LMS) developed as an interactive human -computer-human online digital platform Wisdom of Age (WoA) aiming to close the gap between generations by transferring knowledge from senior experts to developing companies and opening the gates for new certified technological development. The social dimension (healthy aging for seniors, better training for juniors) and the sustainable development for companies are combined with a suitable digital dimension. The paper presents and examines based on survey results, which requirements must be placed on such a platform to optimally support and satisfy mentors and learners.;
The Role of IoT in Making Smart Cities and The Road Map to The Future Developments;Good idea to understand are needed to handle pressing challenges including transportation, medicine, power, and national infrastructure in light of the tremendous development of urbanization in contemporary cities. By building a vast worldwide presence of physically linked items integrated with hardware, algorithms, sensing, and broadband connection, the Internet of Everything (IoT) is one of the most potential technological solutions for overcoming these difficulties. IoT is perhaps also becoming foundation for the next generation of smart cities because of its ability to use sustainability communication and information technology. Numerous fields of sciences and engineering are being impacted by the IoT's quick growth. In order to assist the sustained advancement of smart cities, this article gives an extensive assessment of the scholarship on the major elements and uses of the Iot vision. The integration of Iot products with other technologies is highlighted.;
Cursor Control Using electroencephalogram (EEG) Technology;This paper aims to design an electroencephalogram (EEG)-based cursor control system that can control the computer cursor using non-invasive measurements of brain activity. The developed system is a user-friendly system that can be used by the general public, and it will mostly be convenient for people with disabilities. Moreover, the people living with upper limb paralysis will be able to control the cursor using their brain signals only. In order to develop the system, an enhancement of hardware and software was applied. The sensors were used to acquire the brain signals in real-time. These acquired signals were utilized to permit the user to move the cursor using their thoughts. Additionally, the system was able to translate the collected signals and program them into commands to control the cursor. Furthermore, the software is implemented using open-source tools to preprocess raw EEG signals, apply feature extraction, and classification.;
Digital Twins: A Maturity Model for Their Classification and Evaluation;Digital Twins represent a powerful tool for transforming production and logistics towards Industry 4.0. They mirror physical assets in the digital world, enriching them with additional capabilities and features such as decision-making or lifecycle management. Due to the diverse possibilities associated with the Digital Twin, their design and implementation are also wide-ranging. This paper aims to contribute to the formalization and standardization of the description of Digital Twins. It presents a method for evaluating them through their lifecycle, from design to operation. The paper is based on an overview of their potential functionalities and properties with ranked stages of development. This method allows for an application-specific evaluation of Digital Twins and describes how they can be improved to suit the application better. The maturity model development follows the procedure for developing maturity models for IT management. Relevant capabilities and features were identified with a systematic literature review following the PRISMA guidelines. The results of this review were ranked and categorized and constitute the core of the maturity model, which was validated on five use-cases from different domains in production and logistics. The maturity model assesses Digita Twins in seven categories (context, data, computing capabilities, model, integration, control, human-machine interface) with 31 ranked characteristics. It evaluates existing solutions for potential improvements for a given application or the transfer to a new use-case. The resulting method and a supplementary web service present a generalized model for the evaluation of Digital Twins. Based on a description of a potential application, this is the first step towards a systematic evaluation, improving the structured development of such applications;
Wireless BMS Architecture for Secure Readout in Vehicle and Second life Applications;Battery management systems (BMS) are becoming increasingly important in the modern age, where clean energy awareness is getting more prominent. They are responsible for controlling large battery packs in modern electric vehicles. Today, conventional solutions rely only on a wired design, which adds manufacturing cost and complexity. Recent research has considered wireless solutions for the BMS. However, it is still challenging to develop a solution that considers both the active in-vehicle and the external second-life applications. The battery passport initiative aims to keep track of the batteries, both during active and inactive use cases. There is a need to provide a secure design while considering energy and cost-efficient solutions. We aim to fill this gap by proposing a wireless solution based on near-field communication (NFC) that extends previous work and provides a unified architecture for both use cases. To provide protection against common wireless threats, an advanced security analysis is performed, as well as a system design analysis for the wake-up process that reduces the daily power consumption of the stored battery packs from milli- to microwatts.;
Low-Power Sleep Mode and Out-Of-Band Wake-Up for Indoor Access Points;The expected massive adoption of indoor access points requires specific solutions to meet requirements for eco-sustainability regarding consumed power and radio interferences. Since access points are unused the main part of the day, application of a sleep mode mechanism is a promising approach. However, its implementation represents a radical change in mobile networking paradigm and requires innovative mechanisms to wake up the access points and thus rapidly restore the connectivity. Our approach uses an auxiliary low-power radio to carry out-of-band control information to maintain connectivity and wake up the access points when necessary. The paper details the software and hardware architecture as well as the prototyping results on Wi-Fi technology.;
An Intelligent Text Reader based on Python;As per the World Health Organization (WHO), 285 million people are visually impaired of whom 39 million are completely blind. Though there exist enough remedies to the problems of assisting individuals who are visually impaired to read, there is a requirement for an intelligent text reader which is economical, accurate and easily accessible in order to help them read for day to day activities. This paper proposes an intelligent text reader using python. This product is built on a Raspberry Pi module connected with camera that is used to capture the input image. The input image is enhanced using Image processing techniques. The Tesseract OCR (Optical Character Recognition) engine embedded in the Raspberry Pi searches for the text in an improved image and converts it into digital document. The digital document is then analyzed using semantic check module. After the analysis, text is converted to speech by a Python based TTS (text to speech) conversion unit embedded in the Raspberry Pi. Finally, the audio output is given to the Audio Amplifier for it to be read out.;
Use of Physical Internet System to Increase Effectiveness of Sea Toll Logistics Operations in Indonesia;Sea Toll implementation provides opportunities to promote and improve welfare amongst the people of Indonesia, especially those living in the underdeveloped, remote, outer region, and the bordering areas. A study undertaken by the Ministry of Transportation in 2017 shows that Sea Toll faces challenges of low return cargo load factor of 9.5 percent. The low return cargo load factor in turn contributed to high operational cost of the Sea Toll. Physical Internet (PI) is as global logistics system based on the interconnection of logistics network by a standardized set of collaboration protocols, modular containers and smart interfaces for increased efficiency and sustainability. One of the objectives of invention of PI is to solve inefficiencies of logistics chains, including underutilized transports and distribution centers. A project exploiting PI, called Modulushca, has already been completed by the European Union (EU). Project outcomes include finalization of PI framework to enable interconnected FMCG logistics system, and identification of obstacles and success factors of a PI-enabled system. The purpose of this research is to propose high-level information technology architecture for implementation of PI in Indonesia with the objective of increasing effectiveness of Sea Toll logistics operations. The proposed architecture is modelled after that of EU's Modulushca and will exploit existing Indonesia's National e-Logistics Architecture, specifically the Indonesia National Logistics Ecosystem.;
Design and Application of An Integrated Energy Management System for Park Enterprises;An integrated energy management system (IEMS) based on energy internet architecture is proposed for the comprehensive energy management and energy-saving and emission reduction needs of park enterprises. The system has the characteristics of multi-energy data acquisition, diversity of communication channels, and excellent scalability. In order to solve the compatibility of communication between various acquisition terminals and the system, the interface converter communication conversion is added to upload to the concentrator via the RS485 bus to establish a connection with the master station. It can not only realize the acquisition of multi-energy information such as electricity, water, gas, heat/cold, etc. on the IEMS, but also introduces renewable energy and energy storage on the supply side, improves the energy supply reliability of park enterprises and reduces dependence on external energy networks. In order to meet the integrated energy business needs of enterprises in different parks, this paper studies and analyzes the applicable businesses of various algorithms in IEMS multi-energy collaborative optimal scheduling technology, designs the software architecture of the IEMS, and analyzes in detail the functions of each hierarchical unit module of IEMS and the deployment modes of the master stations in different parks. The system has been put into use and various applications have achieved corresponding results.;
Empowering Human-Computer Interaction in Securing Smartphone Sensing;In this paper, we propose and quantify the usability design of a continuous verification platform on smart mobile devices. The continuous verification platform aims at improving user experience in continuous verification of smartphone users, particularly in non-dedicated smartphone sensing campaigns. To this end, we re-design the mobile behaviometric platform in [1] by introducing enhanced usability features, as well as sustainability measures to prolong battery life of the devices while recruiting the users for non-dedicated sensing campaigns. Furthermore, we extend the continuous verification modules by introducing gesture recognition and a dual mode verification system. Through real time study, we show that the presented framework can achieve continuous verification of users on smart mobile devices by consuming 73% less memory and 46% less storage when compared to its predecessor. Moreover, the proposed framework can significantly reduce the battery drain down to an average percentage of 0.1% while operating with consistency, compliance and extensibility as opposed to its predecessor.;
Smart Agriculture: Software Platform for Telematics Monitoring in Farm Machinery;Agriculture 4.0, also known as Smart Farming or AgriTech 4.0, signifies a paradigm shift in agribusinesses. It represents the fourth agricultural revolution that uses state-of-the-art and innovative technologies, such as Internet of Things (IoT) and data analysis, to cultivate a sustainable, resilient, and more efficient agricultural practices that can address the ever-growing challenges of the 21 st century. This paper proposes the development and implementation of a software system designed to gather, store, and monitor telematics data in farm machinery. By reviewing various software components (front-end and back-end), we aim to provide insights into the key components of the software system and outline a scalable software architecture for monitoring machine telematics in smart farm machinery. Using the proposed software system (web application), users can view historical machine telematics data and monitor the operational performances to optimize farming practices. Furthermore, our system allows real-time alerts to ensure timely intervention and offers potential for integrating predictive analytics to anticipate maintenance needs and improve operational efficiencies.;
Explainability With Observation Sharing in Long Collaboration Chains of Automated Systems of Systems;This article introduces a blueprint architecture for long collaboration chains formed by systems of systems, provided by multiple companies, that can significantly improve the understanding of the processes and events taking place. We illustrate the vision with an automated supply chain scenario and utilize example use cases.;
The role of health informatics in volunteer supported healthcare for underserved populations;This paper examines the role of health informatics in bridging the gaps and augmenting volunteer supported healthcare services to underserved populations in urban, rural, conflict, minimal resource and disaster settings worldwide through the experiences and vision of AarogyaSeva, a non-profit flexible micro-volunteering sustainable platform offering services in 7 countries. Due to the rapid increase in volunteers and patients, as well as an ever-increasing need for healthcare service delivery in underserved communities globally, we address the requirements for a robust health informatics system, addressing the challenges of availability of information to multiple healthcare providers, patient privacy, interfacing with multiple platforms, robustness, ease of use by people with limited technical skills, and extensibility.;
Multi-Agent Collaborative Framework for Automated Agriculture;The use of internet-connected devices, especially small multi-rotor Unmanned Aerial Vehicles (UAVs), in scientific data gathering and applications is quite widespread. But due to limited intervention capability, the UAVs alone fail to automate agricultural tasks completely. Thereby, we propose a centralized framework capable of handling a heterogeneous mixture of UAVs and UGVs to cater to the needs of automating agriculture efficiently. The framework’s core is a novel heuristic decision module that creates new tasks by visually analyzing the farm and solves a vehicle routing problem to allocate it to agents optimally. It is also equipped with supporting modules to monitor their operation and, in case of failures, help them recover autonomously based on the task and agent assessment. The framework is used in three significant agricultural applications, namely yield prediction and drought stress detection in a simulated environment using ROS and Gazebo, and 3D mapping of a real farm. These applications demonstrate the use of the multi-agent collaborative framework in identifying agricultural tasks on a farm and executing them.;
Best-Fit Containerization as a Brokered Service;"IT consumption is rapidly moving to an everything-as-a-Service (XaaS) model wherein a cloud broker, or in general, a digital marketplace, maintains a portfolio of infrastructure, platform and software services. In the meanwhile, containerization of workloads and the immutable microservices paradigm of application software architecture has witnessed a dramatic upswing across industries. In this scenario, we see the need for a smart fulfillment engine within a cloud broker that can automatically deploy a chosen cataloged IT service into the best-performing container environment from among the set of available underpinning brokered container hosting systems. More broadly, the problem statement we address in this paper is to supply best-performing container deployment as a provisioning-time service to applications that are part of a broker's SaaS catalog, in an on-demand and pay-as-you-go manner. We show why this problem is operationally complex and time consuming, and how we heuristically prune the associated decision tree in two phases so that it becomes viable to implement this service on the fly during SaaS provisioning time. We also show that the utility of the algorithmic framework that we propose is not limited to the container fitness use case that we analyze in this paper; rather it can be extended to address a class of problems where overall time and cost complexity for provisioning-time decision making needs to be controlled under a given set of constraints. Our contribution can hence be seen as an abstraction framework for infrastructure consumption when viewed in the larger context of research devoted to simplifying the leverage of hybrid clouds.";
Designing an extensible communication platform for rural area;Rural digital connectivity in developing nations have failed to sustain themselves after subsidy is removed. The demography of users does not demand Internet connectivity for majority of their communication needs. This work proposes an extensible platform for rural communication utilizing delay tolerant networks. The platform allows quick development of localized applications for day to day communication needs. Using data driven paradigm the solution simplifies and abstracts the client and server implementations for the applications. For more intensive applications, the platform allows modular expansion on both the client and server pieces of applications. To prove the extensibility and operational efficiency, the authors present the design of multiple end user scenarios, targeting multimedia application for remote farm monitoring, video rental and another scenario for conducting online evaluations for school tests. The key contributions of the proposal are - operational sustainability of platform, ease of application development for simple communication needs, ability to handle complicated scenarios like processing high definition multimedia content over disconnected networks.;
A Blockchain Based Platform for Network Flexibility Management in Power Distribution: A Real Application Scenario;In the latest years, the huge increase of renewable energy sources introduces new challenges for smart grid management, which is changing is traditional and consolidated “centralized” approach, where system operators are the managers of the grid and the power flow is unidirectional, in a “decentralized” one, where customers become active players and there is a need to draw energy from multiple localized energy networks. This energy transition requires the development of decentralized solutions and active participation of prosumer and their own assets. Local energy flexibility markets can help in monitoring energy flows, incentivize prosumers' energy supply and demand, support the DSOs in the management of the local network issues and in the optimization of electricity flows. In this paper, we propose a blockchain-based full stack solution for the implementation of an open and fair flexibility market and a secure smart grid data management, in which the entire architecture leverages on blockchain technologies and smart contracts for the certification of the market actions and network measurements, as well as the incentivization during the settlement phase. In addition, the proposed solution includes a smart device named Light Node, which includes a blockchain node and can reads, arranges, certifies in blockchain, and sends the measurement and data provided in a secure and efficient way. The entire solution, implemented in the context of the H2020 Platone project, was already deployed, integrated, and tested on the field in a real scenario in Rome (Italy).;
Vision algorithms for automated census of animals;"Numerous military bases have a requirement, based on the Sikes Act, to maintain the base's natural environment while still meeting military mission objectives. One method used to accomplish this is by working toward the goal of achieving habitat and species sustainability. One difficulty is that there is currently no adequate baseline of the ecosystem; specifically, a critical need is the detection, identification, and tracking of animals on Federal and State endangered lists 24 hours a day. For instance, the U.S. Fish and Wildlife Service lists 130 animals as either endangered or threatened, including the desert tortoise, the Mohave ground squirrel, various species of fox, jaguar, mountain beaver, and wolf. In order to even begin to form an appropriate natural environmental baseline, the location and movements of these animals must be acquired, recorded, and made available for review. To this end, we detail technology and machine vision algorithms that can be used to recognize, track, record, and annotate sightings of these animals. We present the methods used, results of our work, current challenges, and future approaches we are taking with our research.";
A Middleware Architecture for Mastering Energy Consumption in Internet of Things Applications;The Internet of things (IoT) has been identified as a significant contributor to increasing Information and Communication Technology (ICT) energy consumption in the future. Carefully designing interactions between client applications and systems in the IoT may positively impact energy saving. For this purpose, IoT middleware, the underlying software that manages those interactions, should consider energy efficiency strategies a first-class concern. Furthermore, adding an energy-awareness capability to the middleware could significantly contribute to deepening developers' understanding of energy consumption by applications and helping them minimize the energy demand. In this paper, we propose energy-efficiency strategies and integrate them into an IoT middleware. We also offer a model to calculate the energy consumption of the interactions between an IoT consumer application and an IoT system, which the middleware could use to choose the best strategy to constrain the application's energy consumption to a given budget.;
A regional electricity market approach in view of related Smart Grid initiatives;The transformation of conventional electricity supply infrastructures towards a more decentralized and sustainable provision requires technical and economical solutions which appropriately adapt to the new requirements and exploit arising efficiency potentials. This contribution introduces a reference architecture for regional electricity markets which allows the integration of small scale actors into the conventional supply infrastructure. Moreover, we provide a schematic comparison of architecture-related Smart Grid initiatives based on different evaluation criteria and relate them to our approach. This way we show that our market-oriented approach is intended to fill a gap in the Smart Grids domain by addressing trading-related issues.;
METROFOOD-IT: a data platform proposal using Agrifood Smart Data Model;METROFOOD-IT enhances the Italian Node of the ESFRI METROFOOD-RI infrastructure and promotes research and innovation in the agri-food sector through integrated services, with an emphasis on digitization, efficiency, traceability, and sustainability. The project fosters a research paradigm focused on improving metrological data flows to enhance, quality, traceability, security in the food and nutritional domain. This paper introduces the architectural model utilized for the integration of both physical and electronic facilities. A service-oriented architecture (SOA) has been designed to facilitate efficient and scalable data sharing. The METROFOOD-IT architectural model unfolds across three levels: services, data infrastructure, and linking infrastructure. The data architecture plays a central role in managing backend systems for services, ensuring continuous data availability to each ecosystem service. To guarantee a stable and recognized data model by the scientific and industrial community, the Smart Data Model Agrifood has been adopted. This model addresses standardized data sharing and standardization issues, ensuring uniformity in data syntax and semantics, implementing access restrictions, and providing essential technical aspects in data platforms.;
Exploiting constrained IoT devices in a trustless blockchain-based water management system;We propose a technological framework based on the combination of the Internet of Things (IoT) and Blockchains aiming at incentivizing and rewarding more sustainable water management practices in agriculture. In this context, current IoT-based precision agriculture deployments prefer energy efficiency, which generally translates into power-and-resource-constrained sensing devices. For this reason, often, system integrators of this sector feel the need to interpose third-party hardware intermediaries (e.g., IoT gateways) between sensing devices and blockchain endpoints, so augmenting infrastructural costs and reducing the trustworthiness of the data acquired from the field. In this paper, we present a software architecture specifically designed for a trustless water management system where constrained IoT devices can directly transact sensed data on a public blockchain network. We deploy the proposed solution on off-the-shelf hardware devices and undertake a thorough benchmarking in terms of memory, program size, communication overheads and power consumption. Our results show that, in general, typical IoT devices can be used to directly interact with a blockchain, without severe burden. More specifically, these devices only incur an additional 6% of the energy consumed for their typical interactions with a gateway.;
Strategic architecture approach to transforming defense acquisition: A case study in moving from formal bureaucracy to lateral hierarchy;The U.S. Defense acquisition system is notoriously resistant to fundamental reform and improvement. This case study examines the fundamental change in the technical architecture of the Navy's submarine sonar system and its acquisition enterprise. Many studies and recommendations for acquisition reform focus on process and incentive structures, few focus on architecture. Rather than focus on process, this case study focuses on the inter- and intra-organizational relationships, the larger scale social and bureaucratic dynamics and the technical architecture. We find that the technical architecture changed from tightly integrated hardware/software architecture to a layered architecture. Layering enabled a spiral development process able to match system upgrades to commercial technology rates of change. We also find a layered enterprise architecture, where different organizations were connected at different hierarchical levels. This enabled fleet operators to provide unfiltered feedback to development engineers, mid-level managers to coordinate priorities and key decisions and senior leadership to provide consistent strategic guidance to the system.;
Embedded networked monitoring and control for renewable energy storage systems;Energy storage plays an important role in managing effectively the integration of distributed renewable energy generation within the electrical networks of the future. Pervasive monitoring and control of these systems makes growing use of information and communication technologies, which aim at secure and economic operation at various scales from microgrids to system-wide integration. Among these, low power wireless communication and computing embedded systems, in the main form of wireless sensor networks (WSN), have become a robust solution. Through hardware and software architectures, along with appropriate mechanisms e.g. for data collection and aggregation, wireless communication protocols and standards, they represent a valid solution in assuring continuous and reliable operation. The paper introduces a cyber-physical framework for renewable storage systems monitoring and control and discusses the application of wireless sensor networks to densely instrument such deployments. A hardware-in-the-loop type structure is designed which allows both testing various types of real storage systems, as well as more complex simulated models derived from large scale applications. We argue that the specific advantages brought forward by the advances in WSN technology can be put to efficient use for local distributed intelligence and control. Experimental data collected is analyzed in order to achieve an insight into the characteristics of the proposed solution.;
Understanding the NPM Dependencies Ecosystem of a Project Using Virtual Reality;Modern JavaScript development relies heavily on using Node Package Manager (NPM) modules. These modules are related by dependency relationships, possibly requiring dozens or hundreds of modules to build a complete JavaScript web application. Studying dependencies, in terms of their sustainability, vulnerability, size, defects, etc., is fundamental for the deployment and maintenance of JavaScript web applications. We use a 3D metaphor based on presenting dependencies as an “elevated city”, mapping both dependency relationships and characteristics of interest of each module. We developed a VR (virtual reality) scene representing the dependencies of several web applications using the elevated city metaphor, and exposed industrial experts to it to check its suitability. They explored a medium-sized project, with more than 200 dependencies, sharing their insights. The results highlight different aspects of our approach and how the combination of metrics helps experts to obtain insights from the ecosystem. The feedback shows the usefulness of the visualization to check and explore several aspects of the dependencies of an application, helping to identify problems related to maintainability, license usage, or vulnerabilities, and to design strategies to address them.;
CloudSimPer: Simulating Geo-Distributed Datacenters Powered by Renewable Energy Mix;Nowadays, studies on energy-efficient datacenters, especially the DataCenters powered by Renewable Energy mix (DCRE), have gained great attention. DCREs are large-scale, geo-distributed, and equipped with on-site renewable energy generators. For these features, it is expensive to perform empirical evaluations of proposed algorithms and solutions on the real-world DCREs, while the state-of-the-art datacenter simulators are not applicable for DCREs. In this paper, we present CloudSimPer (CLOUD SIMulator hybrid-Powered by rEnewable eneRgy), a general-purpose simulator that comprehensively supports the simulation of DCREs. Besides the functions such as renewable energy, geo-distribution, and long-term simulation, we also design evaluation metrics and an integrated simulation case for experimental studies in the future. The main challenge of CloudSimPer lies in designing a new model and software layer upon CloudSim, to solve the complexity of traceable and comparable simulations which connect renewable energies, datacenters, workloads, regions, and schedulers. We use the term schedulers broadly, encompassing any optimization approaches on DCREs for energy saving. We prove CloudSimPer and integrated case to be valid, so that simulation results are scientifically sound, by examining the expectation and the simulation results, and comparing the simulation results with selected competitors. CloudSimPer offers simulation services to datacenter designers, datacenter administrators, and academics.;
Cloud Edge Architecture Leveraging Artificial Intelligence and Analytics for Microgrid Energy Optimisation and Net Zero Carbon Emissions;Microgrids and energy platforms have become increasingly intricate in nature. This is especially true in platforms adopted in large multi functional complexes which are spread across geographies of varying climactic conditions. Many of these complexes have evolved over time as organisations have grown and diversified, this has resulted in a mix of infrastructure, technology, networks, systems and equipment woven in an inextricable web. Often managing such complex hierarchies involve interacting with heterogeneous management platforms from various vendors and built on different platforms each providing the solution to a piece of the ’energy puzzle’ of the organisation. The complexities involved in managing such a network of systems are manifold and require extensive resourcing and expertise. Sustainability and Net Zero carbon emission initiatives that aim to achieve international and national targets add a further layer of complexity to the task at hand. In this paper, we propose a Cloud Edge architecture that leverages Artificial Intelligence (AI) and data analytics for microgrid energy optimisation and net zero carbon emissions. This architecture provides an intelligent and cohesive abstraction to assist in cataloging, unifying and managing the complexities of microgrids and enabling sustainable management of energy. The proposed architecture has been operationalised as the energy management and optimisation platform at a multi-campus, multi-functional tertiary education institution. Empirical evaluations conducted on this deployment have generated results that confirm the function and effectiveness of this architecture in addressing the emerging and evolving challenges of microgrid energy optimisation and net zero carbon emissions.;
Thinking Head Framework: An open architecture for human centred robotics;Thinking Head Framework is the software architecture developed as part of a multidisciplinary research project 'Thinking Head' aimed at building and evaluating intelligent agents for human machine interaction. Firstly, the framework was designed to make the software accessible to non expert users as in the case of this project where large number of users come from a non-software engineering background. Secondly, the framework caters for both multimodal dialogue type communication between components and humans as well as high speed communication between sensors and robotic components. The framework implements a multi-threaded server and client architecture with TCP socket connections and allows components to be written in a host of popular programming languages including C++, Java and Matlab.;
Holonic architectures for IoT-empowered energy management in districts;For the future energy system, the transition from centralized fossil-based plants to a sustainable energy system means the emergence of a huge number of distributed renewable energy sources. Weather-dependent and volatile power generation as well as an increasingly spiky electric demand, arising from ongoing electrification of other sectors, require predictive and flexible control strategies already on the district level. With an increasing number of IoT-enabled field devices, multiple energy vectors thereby lead to a complex interplay, where micro and macro objectives may sometimes differ or even oppose. In this work we propose holonic whole-part architectures for multi-energy management systems. Building up a district’s energy system from self-sufficient sub-units, enables the preservation of local control schemes and reduces complexity for energy management entities or energy markets on hierarchically higher levels. Additionally, resilience and topological flexibility can be enhanced through dynamic reconfiguration of the holons. Two field examples for cross-sector realizations of IoT-based multi-energy management in districts are presented, which demonstrate the implementation of the concept once at the district level and once at the device level.;
A BPF-Based Task Scheduling Scheme for Heterogeneous Multiprocessor Systems;With the booming development in the IoT field, more and more embedded systems are required to support both real-time task processing and rich functionality. The need for Heterogeneous Multiprocessor Systems-on-Chip (HMPSoC) and task scheduling between operating systems on HMPSoC has arisen. This paper discusses a load balancing scheme, BPF-based Task Scheduling Scheme (BTSS), based on BPF technology and inter-core communication mechanisms, to transfer some computational tasks from the General Purpose Operating System (GPOS) to the Real Time Operating System (RTOS) for execution. A prototype of BTSS is implemented to verify the feasibility and evaluate the performance of the scheme, using Linux as the GPOS and an IoT operating system as the RTOS. The evaluation results demonstrate that with the BTSS, we can utilize the processor resources of HMPSoC more efficiently and increase the system computing capability.;
Optimal Operation of Adjustable Load via Intelligent Energy Terminals for Renewable Energy Consumption;Traditional power load management terminals lack precision and flexibility in controlling customer power loads, hindering efficient energy use. Developing intelligent energy terminals is essential to meet national demand-side management standards and enhance energy efficiency. This paper designs a functional architecture of intelligent energy terminals on the customer side and constructs a flexible regulation strategy set of customer-side diversified demand-side resources for the local power grid supply and demand balance as well as renewable energy consumption goals. It also explores collaborative optimization strategies for efficient energy utilization and distributed power consumption. The proposed control strategies for customer-side intelligent energy terminals enable precise regulation of diverse resources. This supports government oversight and empowers power grid companies and demand response agencies to provide high-quality services, contributing to low-carbon and efficient energy utilization while ensuring load control in compliance with safety standards.;
Towards an architecture for smart garbage collection in urban settings;Since human societies first reached a level of stability and social organization high enough to make waste collection a concern of local governmental authorities, a lot of time and resources have been invested into the matter. With the ascension of the so-called Smart Cities, many unexplored opportunities are brought up in this context. The present paper proposes a software architecture to be implemented in the context of Smart Cities. A platform for the research, simulation and implementation of route generation algorithms, that challenges the traditional models and that makes the best use of the technologies available today, such platform aims to function as an implementation of an Artificial Transportation System with the goal of suppressing the existent flaws and gaps in today's systems, be it for economic, environmental, sustainability, time-efficiency or even health related areas. The architecture's initial draft is explained and its results are presented and analysed.;
Labelling Lightweight Robot Energy Consumption: A Mechatronics-Based Benchmarking Metric Set;Compliance with global guidelines for sustainable and responsible production in modern industry requires a comparative analysis of consumer devices' energy consumption (EC). This also holds true for the newly established generation of lightweight industrial robots (LIRs). To identify potential strategies for energy optimization, standardized benchmarking procedures are required. However, to the best of the authors' knowledge, there is currently no standardized method for benchmarking the EC of manipulators. In response to this need, we have developed a comprehensive benchmarking framework to evaluate the EC of various LIR designs, delving into the theoretical power consumption under both static and dynamic conditions. Our analysis has led to the proposal of seven proposed metrics—three static and four dynamic. The static metrics—controller consumption, joint electronics consumption, and mechanical brakes' consumption—evaluate the maintenance EC of the robot. Meanwhile, we suggest three dynamic metrics that gauge the system's energy efficiency during motion, with or without payload. We extend this metrics selection by introducing the cost of transportation map for manipulators. For each of the metrics, we suggest a standardized measurement procedure based on state-of-the-art norms and literature. The metric set and experimental procedures are demonstrated using five manipulators (UR3e, UR5e, FR3, M0609, Gen3). Among the results, we can see interesting trends for future optimization of the electronic components and their architecture, e.g., reducing the robot's EC by decentralizing computation via low-consumption onboard controllers for basic tasks and external servers for complex ones.;
Distributed hybrid method to solve multiple traveling salesman problems;The traveling salesman problem (TSP) can be defined as the process of finding the shortest path for a given set of cities, starting from base city, visiting all other cities once, and returning to the base city. However, when we consider some of the real word problems such as Routing of School bus, the methods that solve the TSP are not effective to handle these types of problems since they deal with only one salesman. On the other hand, the multiple traveling salesmen problem (mTSP), which is the generalization of the TSP, is capable of handling and using more than one salesman in real-world problems. In mTSP, m salesmen start from home city, and each one visits a particular set of cities and returns to the home city, so that all cities are visited by one salesman. The objective of mTSP is to minimize the total cost. In this paper, we proposed a distributed hybrid method to solve mTSP which use multiple machines via a web service software architecture to make sure that the result we get is the best. Fundamentally, the first step is to transform the mTSP to standard TSP then apply parallel Ant colony optimization (ACO) with different pheromone exchange (PE) policies which are without PE, with 25% of PE, and with 50% of PE. Moreover, we further enhance the result by using local search techniques. Furthermore, two techniques tested for ant to choose the next city. First technique is to choose 90% from the neighborhood based on probability and 10% from neighborhood. Second technique tested is using the probabilistic equation. In the both techniques, the three PE options have been used. Moreover, a comparison is made between the hybrid method and other methods (NMACO, MACO, and MGA) and found that the hybrid method provides a reduction in cost.;
A Distributed Framework for Knowledge-Driven Root-Cause Analysis on Evolving Alarm Data–An Industrial Case Study;Root-cause Analysis (RCA) of alarms is a well-established research area in automated Production Systems (aPS). Many RCA algorithms have been proposed and successfully evaluated and new ones are being developed. Recently, researchers focus on the incorporation of formalized information about the technical process in the analysis to gather further evidence for common root causes. In industrial applications, alarm data are usually preprocessed to accommodate for use case-specific properties and prepare subsequent analysis steps. Consequently, this letter proposes a generalized RCA framework, for which an arbitrary number of preprocessing, data-driven RCA, and postprocessing algorithms can be selected, to support varying use cases. The framework was successfully evaluated in an industrial case study, using 1.8 million alarms recorded over 450 days from an industrial nonwoven production plant and analyzed using formalized information from process documentation and expert interviews. Seven preprocessing algorithms, one data-driven RCA algorithm, and nine postprocessing algorithms typical for continuous and hybrid technical processes were realized in an otherwise entirely use case-agnostic implementation.;
Connected and Intelligent Framework for Vehicle Automation in Smart-Ports;"The increase in maritime traffic due to the globalization of trade has led to an exponential growth in logistics operations and port traffic management is becoming increasingly complicated. The need to improve the efficiency, safety, and sustainability of operations is leading to a strong demand for automation in port processes. A significant challenge is the optimization and automation of loading and unloading systems, given their complexity and repetitive nature. Advances in automated systems, through ongoing research and application in various transportation scenarios, are addressing these challenges. However, automating vehicles alone is insufficient; it is also important to have a connected, infrastructure-based collaborative framework to manage the complex logistics of port operations effectively and in a synchronized manner. In this sense, ESTIBA+2022, a Spanish-funded project, is addressing this challenge, aiming to develop strategic technologies for Smart-Ports. Its goal is to design and validate a scalable collaborative framework that meets the specifications and functions of port services using Industry 4.0 technologies and advanced wireless communications through Connected Intelligent Transportation Systems (C-ITS). This article presents the proposed architecture and its validation in the comprehensive use case of the project, focusing on communication from the supervision platform to Automated Guided Vehicles (AGVs) to ensure optimal traffic flow and management in ports. Specifically, the scenario involves three different forklifts equipped with an On-Board Unit (OBU) that interact with each other and the infrastructure via Roadside Units (RSU). The outcome of the project shows that the framework can meet the requirements for Smart-Port logistics, showing the feasibility of the implementation with a collaborative maneuver between three forklifts, a supervision station, and connected traffic lights.";
A Multi-Interface DTN-like Communication System;The networking industry is quickly adopting IP as the technology to run all the communication applications people need. Yet, there exists a lot of use cases and deployments, where end-to-end IP is not available. This is the domain Delay Tolerant Networking (DTN) is targeting. The Multi Interface Communications Software (MICS) is a robust DTN-like messaging platform for heterogeneous communications equipment. MICS can provide message delivery in networks that lack essentials required by traditional TCP/IP-solutions, like end-to-end connectivity or compatible addressing methods. MICS abstracts the used communications medium, that is the network and link layer, from applications. Applications and network interfaces connect to MICS core using well known and standardized APIs. Familiar email addresses and APIs are used to interface applications with the MICS system. The high-level operation of MICS resembles DTN since we make use of store-and-forward message delivery and multipath message routing together with flooding. This paper concentrates on the overall concept of the MICS system, software architecture, IPC methods, details design choices, message routing and discusses real world deployment scenarios.;
BurstMem: A high-performance burst buffer system for scientific applications;The growth of computing power on large-scale systems requires commensurate high-bandwidth I/O systems. Many parallel file systems are designed to provide fast sustainable I/O in response to applications' soaring requirements. To meet this need, a novel system is imperative to temporarily buffer the bursty I/O and gradually flush datasets to long-term parallel file systems. In this paper, we introduce the design of BurstMem, a high-performance burst buffer system. BurstMem provides a storage framework with efficient storage and communication management strategies. Our experiments demonstrate that BurstMem is able to speed up the I/O performance of scientific applications by up to 8.5× on leadership computer systems.;
EDEN Versatile End-effector (EVE): An Autonomous Robotic System to Support Food Production on the Moon;Spacefaring nations have already expressed their plans for a sustainable human and robotic exploration on the Moon. This endeavor highlighted in the Global Exploration Roadmap (GER) foresees the development of infrastructures such as habitats, greenhouses, science labs, power plants, and mining facilities. Following this long-term vision, the German Aerospace Center (DLR) EDEN LUNA Project presents a Moon-analogue greenhouse facility which can demonstrate nearly closed-loop bio-regenerative life support systems technology and aim to produce fresh food for astronauts on the Moon in the near future. To optimize the food production and overcome challenges inherent to space missions, the EDEN Versatile End-effector (EVE) is integrated to the EDEN LUNA Greenhouse. This support system is a valuable payload which will automatize the tasks of the entire plant cultivation process: from germination to harvesting. The automatization is particularly relevant when the food production is intensified either seasonally or in a future scaled-up scenario. The EVE system encompasses a linear rail system installed on the ceiling of the greenhouse, a 7-Degrees of Freedom (DOF) autonomous robotic arm with high precision joint configuration, a sensorized robotic hand which can grasp delicate objects, and a sophisticated computer vision camera with plant monitoring capabilities. When in operation, the EVE system uses shared autonomy features. Thus, while it maintains the human in the loop for some of the decision-making processes, it can also function with some level of autonomy. A set of tasks previously defined by an astronaut in the end of an operational day and carried out autonomously during the night by the EVE system is one example of this human-robot collaboration. In addition, an optimized motion planning will ensure that the EVE system can perform constrained manipulation tasks in a limited workspace observing energy efficiency and safety requirements. This is explained in the paper with the abstraction of the different robotic control levels which range from the high-level view for non-experts in robotics to the motion planning level and their interconnections. The EVE system is currently in development at the DLR Robotic and Mechatronics Center (RMC) in Oberpfaffenhofen. In 2024, it will be integrated to the EDEN LUNA Greenhouse at the DLR Institute of Space Systems in Bremen. Finally, by the end of 2025, it will start operations in the ESA/DLR LUNA facility at the European Astronaut Centre (EAC) in Cologne.;
Sensing through the continent: Towards monitoring migratory birds using cellular sensor networks;This paper presents CraneTracker, a novel sensor platform for monitoring migratory birds. The platform is designed to monitor Whooping Cranes, an endangered species that conducts an annual migration of 4,000 km between southern Texas and north-central Canada. CraneTracker includes a rich set of sensors, a multi-modal radio, and power control circuitry for sustainable, continental-scale information delivery during migration. The need for large-scale connectivity motivates the use of cellular technology in low-cost sensor platforms augmented by a low-power transceiver for ad-hoc connectivity. This platform leads to a new class of cellular sensor networks (CSNs) for time-critical and mobile sensing applications. The CraneTracker is evaluated via field tests on Wild Turkeys, Siberian Cranes, and an on-going alpha deployment with wild Sandhill Cranes. Experimental evaluations demonstrate the potential of energy-harvesting CSNs for wildlife monitoring in large geographical areas, and reveal important insights into the movements and behaviors of migratory animals. In addition to benefiting ecological research, the developed platform is expected to extend the application domain of sensor networks and enable future research applications.;
TRAFAIR: Understanding Traffic Flow to Improve Air Quality;Environmental impacts of traffic are of major concern throughout many European metropolitan areas. Air pollution causes 400 000 deaths per year, making it first environmental cause of premature death in Europe. Among the main sources of air pollution in Europe, there are road traffic, domestic heating, and industrial combustion. The TRAFAIR project brings together 9 partners from two European countries (Italy and Spain) to develop innovative and sustainable services combining air quality, weather conditions, and traffic flows data to produce new information for the benefit of citizens and government decision-makers. The project is started in November 2018 and lasts two years. It is motivated by the huge amount of deaths caused by the air pollution. Nowadays, the situation is particularly critical in some member states of Europe. In February 2017, the European Commission warned five countries, among which Spain and Italy, of continued air pollution breaches. In this context, public administrations and citizens suffer from the lack of comprehensive and fast tools to estimate the level of pollution on an urban scale resulting from varying traffic flow conditions that would allow optimizing control strategies and increase air quality awareness. The goals of the project are twofold: monitoring urban air quality by using sensors in 6 European cities and making urban air quality predictions thanks to simulation models. The project is co-financed by the European Commission under the CEF TELECOM call on Open Data;
Automatic Guidance Vehicle using Modularised Instruction Cards;In this respect, modularity of instruction cards can be employed. This gives the AGV an adaptable and flexible technology. Technology should be in a position to personalise the operating of AGVs concerning the activities and locations within a facility. Small-scale firms have a lot of unpredictable challenges, and therefore, they need to have settings of their production and processes change at their convenience. It is easy to AGV behavioural changes with modularised instruction cards in use. The adaptability of the AGV can, therefore be made according to the industrial requirement in time using unique instruction cards in use for the said process. This adaptability will enable small-scale organizations to have their automation implemented in stages and in a cost-effective manner. That is will ensure that firms with fewer resources enjoy sustainable production. This paper, therefore seeks to enhance the GPS navigation using RFID technology. Indoor interference impairs the accuracy and reliability of a GPS signal. This restricts accurate positioning, which is required to carry out efficient material-handling activities. Signal latency and inconsistency: GPS signals can be slow in big urban areas or if the sky is hidden. This can lead to inaccurate or delayed navigational instructions. RFID cards will be mounted around the building in a manner that provides accurate waypoints for the navigation of the AGV. They will carry the location of information and AGVs navigate with accurate task completion.;
Fine-grained remote monitoring, control and pre-paid electrical service in rural microgrids;In this paper, we present the architecture, design and experiences from a wirelessly managed microgrid deployment in rural Les Anglais, Haiti. The system consists of a three-tiered architecture with a cloud-based monitoring and control service, a local embedded gateway infrastructure and a mesh network of wireless smart meters deployed at 52 buildings. Each smart meter device has an 802.15.4 radio that enables remote monitoring and control of electrical service. The meters communicate over a scalable multi-hop TDMA network back to a central gateway that manages load within the system. The gateway also provides an 802.11 interface for an on-site operator and a cellular modem connection to a cloud-backend that manages and stores billing and usage data. The cloud backend allows occupants in each home to pre-pay for electricity at a particular peak power limit using a text messaging service. The system activates each meter within seconds and locally enforces power limits with provisioning for theft detection. We believe that this fine-grained micro-payment model can enable sustainable power in otherwise unfeasible areas. This paper provides a chronology of our deployment and installation strategy that involved GPS-based site mapping along with various network conditioning actions required as the network evolved. Finally, we summarize key lessons learned and hypothesis about additional hardware that could be used to ease the tracing of faults like short circuits and downed lines within microgrids.;
Multilayer Big Data Architecture for Remote Sensing in Eolic Parks;Due to their nature, Eolic parks are situated in zones with difficult access. As a result, management of Eolic parks using remote sensing techniques is of great importance. In addition, the huge amount of data managed by Eolic parks, together with their nature (distributed, heterogeneous, produced, consumed at different times, etc.) makes them ideal to apply big data techniques. In this paper, we present a multilayer hardware/software architecture that applies cloud computing techniques for managing big data from Eolic parks. This architecture allows tackling the processing of large, distributed, and heterogeneous data sets in a remote sensing context. An innovative contribution of this work is the combination of different techniques at three different layers of the proposed hardware/software architecture for Eolic park big data management and processing.;
Dynamic Hybrid Fault Modeling and Extended Evolutionary Game Theory for Reliability;"We introduce a new layered modeling architecture consisting of dynamic hybrid fault modeling and extended evolutionary game theory for reliability, survivability, and fault tolerance analyses. The architecture extends traditional hybrid fault models and their relevant constraints in the Agreement algorithms with survival analysis, and evolutionary game theory. The dynamic hybrid fault modeling (i) transforms hybrid fault models into time- and covariate-dependent models; (ii) makes real-time prediction of reliability more realistic, and allows for real-time prediction of fault-tolerance; (iii) sets the foundation for integrating hybrid fault models with reliability and survivability analyses by integrating them with evolutionary game modeling; and (iv) extends evolutionary game theory by stochastically modeling the survival (or fitness) and behavior of `game players.' To analyse survivability, we extend dynamic hybrid fault modeling with a third-layer, operational level modeling, to develop the three-layer survivability analysis approach (dynamic hybrid fault modeling constitutes the tactical and strategic levels). From the perspective of evolutionary game modeling, the two mathematical fields, i.e., survival analysis and agreement algorithms, which we applied for developing dynamic hybrid fault modeling, can also be utilized to extend the power of evolutionary game theory in modeling complex engineering, biological (ecological), and social systems. Indeed, a common property of the areas where our extensions to evolutionary game theory can be advantageous is that the risk analysis and management are a core issue. Survival analysis (including competing risks analysis, and multivariate survival analysis) offers powerful modeling tools to analyse time-, space-, and/or covariate-dependent uncertainty, vulnerability, and/or frailty which `game players' may experience. The agreement algorithms, which are not limited to the agreement algorithms from distributed computing, when applied to extend evolutionary game modeling, can be any problem (game system) specific rules (algorithms or models) that can be utilized to dynamically check the consensus among game players. We expect that the modeling architecture and approaches discussed in the study should be implemented as a software environment to deal with the necessary sophistication. Evolutionary computing should be particularly convenient to serve as the core optimization engine, and should simplify the implementation. Accordingly, a brief discussion on the software architecture is presented.";
Towards implementation of Plug-and-Play and distributed HMI for the FREEDM system with IEC 61499;This paper presents an implementation of Plug-and-Play for the FREEDM system with IEC61499 function blocks. The FREEDM system is the envisioned next generation power distribution infrastructure which integrates DRER/ER with the legacy grid and is enabled by novel power electronics and distributed control. Plug-and-Play device integration is one of the key features of the FREEDM system that allows distributed renewable energy resources and distributed energy storage devices to be added or removed from the FREEDM distributed intelligent devices seamlessly. IEC61499 is an open standard for designing distributed control systems, which is investigated in the FREEDM project as an underlying system-level software architecture. Plug-and-Play is achieved by dynamic reconfiguration in IEC61499 to create the necessary function blocks during runtime for enabling Plug-and-Play between the DRER and the DGI devices. The developed Plug-and-Play technology is incorporated into the FREEDM infrastructure implemented in IEC61499 function blocks.;
Efficient SOAP messaging for Android;Service-Oriented Architecture (SOA) is a software architectural design pattern for constructing and deploying application functionality based on loosely coupled components. Web services is a much-used technology for implementing applications following SOA principles, and achieving interoperability between different systems. Web services are usually realized on computer systems where processing resources and network bandwidth are not a limitation, and haven't been widely employed to mobile systems that are characterized by less computational resources (e.g., small computing devices and limited power), and wireless networks characteristics (e.g., low bandwidth, often ad hoc and unreliable). Even though computing power and memory capacities of mobile devices are constantly improving, the dependency on battery power and wireless networks calls for improved solutions when implementing SOA on wireless systems. In this paper we focus on supporting SOAP on the Android platform in an efficient manner. By efficient, we mean maximizing battery life while minimizing network use. We explore and compare different transport protocols and compression techniques in order to achieve these goals. This work was performed in context of the NATO IST-118 “SOA recommendations for disadvantaged grids in the tactical domain” group.;
Online bio-robotics labs: Open hardware models and architecture;This paper is on free and open source software architecture (FOSS) for remote labs in order to address the affordability and scalability of robotic education technology for sustainable deployments. The proposed Raspberry Pi-Arduino-based model architecture ensures lower cost while allowing some scalability, interoperability, portability and interchangeability to the low-cost online laboratory. Remotely controlled lab provides training skills in bio-inspired robotics. Our previous studies had shown that the implementation of remotely controlled online labs in the curriculum improved active learning among students, collaboration, and augmented problem solving skills. The preliminary implementation involved proprietary software, as the remote experiment accessibility platform, which was later replaced with FOSS technology. The advantages with FOSS included a significantly lower cost and scalability for concurrent usage. The paper also reports on usage analysis and common issues in both cases of implementations.;
Virtual Lab platform for distance learning courses in engineering technologies for the use of renewable energies;"Harnessing energy from the renewable energy sources is coming to be more and more relevant in the coming years [1], due to this fact power energy companies and manufacturing companies producing technology facilities for the renewable energy harvesting are demanding engineers skilled in this field [2]. As a general answer to that fact, all the universities are adapting their engineering curricula to that demand creating new subjects in renewable energy (RE) technology; those new subjects needs new education tools and this motivate the investigation and creation of software simulation environment specific for those technologies with the goal of engineering education. In the present work it is shown a multi-platform software architecture specially designed for distance learning and with the target to be a complementary tool to the curricula contents of the new subjects in RE engineering with the aim to offer a virtual laboratory able to simulate the most updated energy harnessing systems. Flow diagrams, management, functionality and capabilities of this multi-platform software environment development is explained in the article.";
Advancements in the Open Data Cube and Analysis Ready Data — Past, Present and Future;The Open Data Cube (ODC), created and facilitated by the Committee on Earth Observation Satellites (CEOS), is an open source software architecture that supports analysis-ready satellite data packaged into “cubes” to minimize data preparation complexity and take advantage of modern computing for increased value and impact of Earth observation data. Since its inception in 2017, the ODC has fostered a community to develop, sustain and grow the technology and its applications. Such early success has resulted in bold goals for facilitating the implementation of country-level data cubes around the world to achieve a virtual global data cube through connected regional deployments. Advancements in the ODC infrastructure and its associated application algorithms along with a regional demonstration in Africa suggest this goal is achievable. In addition, there are also considerable advancements in the specification, production and use of Analysis Ready Data (ARD), which is the core element of any data cube deployment. Such advancements will optimize the value of ARD for global users by demonstrating increased access and use of diverse datasets, interoperability between datasets, and increased use of machine learning. This paper summarizes the past, present and future of the ODC and ARD initiatives.;
CNN Sensor Analytics With Hybrid-Float6 Quantization on Low-Power Embedded FPGAs;The use of artificial intelligence (AI) in sensor analytics is entering a new era based on the use of ubiquitous embedded connected devices. This transformation requires the adoption of design techniques that reconcile accurate results with sustainable system architectures. As such, improving the efficiency of AI hardware engines as well as backward compatibility must be considered. In this paper, we present the Hybrid-Float6 (HF6) quantization and its dedicated hardware design. We propose an optimized multiply-accumulate (MAC) hardware by reducing the mantissa multiplication to a multiplexor-adder operation. We exploit the intrinsic error tolerance of neural networks to further reduce the hardware design with approximation. To preserve model accuracy, we present a quantization-aware training (QAT) method, which in some cases improves accuracy. We demonstrate this concept in 2D convolution layers. We present a lightweight tensor processor (TP) implementing a pipelined vector dot-product. For compatibility and portability, the 6-bit floating-point (FP) is wrapped in the standard FP format, which is automatically extracted by the proposed hardware. The hardware/software architecture is compatible with TensorFlow (TF) Lite. We evaluate the applicability of our approach with a CNN-regression model for anomaly localization in a structural health monitoring (SHM) application based on acoustic emission (AE). The embedded hardware/software framework is demonstrated on XC7Z007S as the smallest Zynq-7000 SoC. The proposed implementation achieves a peak power efficiency and run-time acceleration of 5.7 GFLOPS/s/W and 48.3× , respectively.;
Quasi-static evaluation of a modular and Reconfigurable Manufacturing Cell;"Extensive cost, time and effort associated with setting up a production line often inhibits transitioning novel ideas into commercialized products. Sustainable revenue generation in such enterprises requires production in large quantities in order to lower the unit cost, and thus improving the marketability. Although this model has been successful and is being followed by most of the industries today, it also limits the scope for new, non-conventional products; especially in the early stages of development where manufacturing risks are higher. One way of reducing this risk can be through improving the reusability of the manufacturing hardware, thus allowing quick and inexpensive transition among different iterations and even different products with the same set of hardware. In this paper, we present such a novel and revolutionary solution for flexible manufacturing. Consisting of a unique set of hardware and software innovations, our proposed system offers a viable way to low volume manufacturing and low risk prototyping of novel product ideas. Called as the “Modular and Reconfigurable Manufacturing Cell (MRMC)”, this proposed system enables quick and easy setting up of a fully automated robotic manipulation and assembly platform, optimized for specific products. The system relies on a novel and proprietary multifunctional interconnect design, built-in to various hardware modules of the system, and a distributed intelligence based self-locating software architecture to achieve almost any possible assembler configuration that is suitable for a specific set of tasks. Necessary and sufficient precision level is maintained via a novel precision optimized hybrid controller and path planner throughout the automation. Competitive specifications in terms of travel range, resolution, accuracy, repeatability, force output, size, weight, power ratings etc., as compared to standard commercial manipulators, has been experimentally verified for the proposed Modular and Reconfigurable Manufacturing Cell (MRMC).";
Energy Consumption in Microservices Architectures: A Systematic Literature Review;Cloud computing emerges as a paradigm that facilitates on-demand access to technological resources through the mechanism of service virtualization. This virtualization enables the partitioning of hardware resources among applications that are organized into distinct independent modules. The concept of microservice architecture takes advantage of virtualization capabilities to embrace a software architecture strategy focused on the development of applications as assemblies of several interdependent but loosely coupled modules. Nonetheless, the adoption of microservices architecture is accompanied by substantial energy demands to meet the desired standards of performance and availability. Existing research within the domain of microservices has explored various topics pertinent to energy consumption, including elasticity, reliability, performance, and availability. Yet, the diversity of challenges and solutions presents a complex landscape for identifying prevailing research trends and unaddressed gaps in the context of microservices. This study aims to methodically discern, evaluate, and juxtapose the existing research trends and voids concerning energy consumption within microservices. It elucidates a systematic review on the subject of energy consumption in microservices architectures, offering a compilation of references to facilitate more directed future investigations. The initial selection encompassed 3625 articles, which were subsequently narrowed down through three stages of refinement, resulting in 37 articles chosen for an exhaustive review. These selected studies were cataloged and analyzed based on various criteria, including metrics, evaluation methodologies, and architectural typologies, thus uncovering research gaps and emerging trends related to energy consumption in microservice architectures. Furthermore, this inquiry delineates significant research challenges and prospective directions, structured around the key metrics that underpin the reviewed studies: performance, elasticity, scalability, reliability, sustainability, and availability.;
Software-Defined Architecture and Front-End Optimization for DO-178B Compliant Distance Measuring Equipment;Among the air navigation technologies, many of them are capable of increasing the aviation sustainability as well as accuracy improvement in Alternative Positioning, Navigation, and Timing (APNT) specially avionics Distance Measuring Equipment (DME), Very high frequency Omni-directional Range (VOR), etc. The integration of these air navigation solutions could make a robust and efficient accuracy in air mobility, air traffic management and autonomous operations. Designing a proper RF front-end, power amplifier and software-defined transponder could pave the way of reaching an optimized avionics navigation solution. In this article, the possibility of reaching an optimum front-end to be used with single low-cost Software-Defined Radio (SDR) has been investigated in order to reach a novel software-defined DME architecture. Our software-defined approach uses the firmware possibilities to design a real-time software architecture compatible with a Multi Input Multi Output (MIMO) BladeRF to estimate an accurate time delay between a Transmission (Tx) and the reception (Rx) channels using the synchronous scheduled communication. We could design a novel power amplifier for the transmission channel of the DME to pass the minimum transmission power. This article also investigates designing a proper pair pulse based on the DO-178B avionics standard. Various guidelines have been tested and the possibility of passing the certification process for each standard term have been analyzed. Finally, the performance of the DME has been tested in the laboratory environment using an IFR6000 which showed that the proposed architecture reached the accuracy of less than 0.23 Nautical mile (Nmi) with 98% probability.;
Variability Modeling for Smart City Reference Architectures;With the convergence of information and telecommunication technologies, the vision of the `Smart City' is fast becoming a reality. City governments in a growing number of countries are capitalizing on these advances to ease the lives of their citizens and to increase efficiency and sustainability. In our previous research, we have proposed a new approach for designing such ultra large and ultra-heterogeneous ecosystems. The approach is manifested as a reference architecture (smartCityRA) that can be used as the starting point, i.e. blue print, for smart city projects. In this paper, we elaborate on the reference architecture by enabling smartCityRA with variability mechanisms to accommodate the instantiations of different smart city software architectures. We do this by using variability modeling and model-driven architecture techniques. The result is smartCityML, a domain specific language (DSL) for modeling smart city systems. We first develop the abstract syntax of the language. Then, we outline the constituent constructs of the language, i.e. the concrete syntax. Finally, we propose tooling ideas for the new language and suggest evaluation criteria and plans.;
Progress and Prospects for the Development of Computer-Generated Actors for Military Simulation: Part 2â€”Reasoning System Architectures and Human Behavior Modeling;The development of realistic computer-generated synthetic environments, also calleddistributed virtual environments, relies heavily upon computer-generated actors (CGAs) to provide accurate behaviors at reasonable cost so that the synthetic environments are useful, affordable, complex, and high fidelity. Unfortunately, the pace of synthetic environment development and the level of desired CGA performance continue to rise at a much faster rate than CGA capability improvements. This insatiable demand for realism in CGAs for synthetic environments arises from the growing understanding of the significant role that modeling and simulation can play in a variety of uses. These uses include training, analysis, procurement decisions, mission rehearsal, doctrine development, force-level and task-level training, information assurance, cyberwarfare, force structure analysis, sustainability analysis, life cycle costs analysis, material management, infrastructure analysis, and many other uses. In these and other uses of military synthetic environments, CGAs play a central role because they have the potential to increase the realism of the environment while also reducing the cost of operating the environment. The progress made in addressing the technical challenges that must be overcome to realize effective and realistic CGAs for military simulation environments and the technical areas that should be the focus of future work are the subject of this paper, which surveys the technologies and progress made in the construction and use of CGAs. In this, the third installment in the series of papers discussing CGAs, we conclude our discussion of CGA technologies by concluding the discussion of human behavior modeling for CGAs, and we present some suggested future research directions for CGA technologies.;
Architecture Sustainability [Guest editors' introduction];Software architecture is the foundation of software system development, encompassing a system's architects' and stakeholders' strategic decisions. A special issue of IEEE Software is intended to raise awareness of architecture sustainability issues and increase interest and work in the area. The first Web extra at http://youtu.be/wUGHvocfix0 is an audio interview in which Davide Falessi speaks with guest editors Paris Avgeriou and Rich Hilliard about the importance of architecture sustainability including the three types of approaches they distinguish for handling change systematically, listed in an order of increasing severity: refactoring, renovating, and rearchitecting. The second Web extra at http://youtu.be/T-neSlUhAv0 is an audio interview in which Brian Brannon speaks with guest editor Michael Stal about his experiences with architecture sustainability as a principal engineer at Siemens AG's Corporate Research and Technology division.;
Architecting the Future of Software Engineering;To meet future demand for software capabilities, improvements in critical software engineering technologies are needed. This article presents a research road map and call to action that highlights the need for continual investment in software engineering research.;
1 An Application of Object Oriented Systems Engineering (OOSE) To an Army Command And Control System: A New Approach to Integration of System and Software Requirements and Design;"The purpose of this paper is to demonstrate how an Object Oriented Systems Engineering (OOSE) methodology developed at Lockheed Martin (LM) Management and Data Systems (M&DS) is being applied to the Army Global Command and Control System (GCCS-A). This system is now migrating from a legacy Army system to a modern integrated Army wide system that supports the Joint GCCS. The focus of this paper is on providing practical examples of how some fundamental issues for using System Engineering methods (previously accomplished with structured analysis and design techniques) in conjunction with software OO methods were resolved using this OOSE methodology. These include: (1) how the system and software requirements specification must be synchronized; (2) capture of requirements and system design information using Object Oriented (OO) techniques and relationships; and (3) using the system objects to better manage the allocation of functionality in the system, maintenance of a legacy system, and ease of system analytical model maintenance during periods of requirements change.";
Bridging the Gap between Interest Rates and Investments;"The links between interest rates, cost of capital, hurdle rates, and capital allocation have been remarkably weak during the last few years. For instance, whereas the current yield on the World Government Bond Index is a paltry 1.2%, survey evidence suggests that the median reported investment hurdle rate of S&P 100 companies is as high as 18%.

In this report, members of J.P Morgan's corporate finance advisory group explain why the cost of capital for most companies is unlikely to increase materially even if interest rates rise as projected. This suggests that companies have room to lower their hurdle rates. Moreover, as the authors argue, a reduction in hurdle rates is likely to be beneficial since excessively high hurdle rates can have the effect of reducing value by sacrificing profitable growth opportunities and increasing the firm's risk profile. The report concludes with a framework for corporate hurdle rates and capital allocation strategies designed to help companies make better investment decisions.";
Microservice transition and its granularity problem: A systematic mapping study;"Microservices have gained wide recognition and acceptance in software industries as an emerging architectural style for autonomic, scalable, and more reliable computing. The transition to microservices has been highly motivated by the need for better alignment of technical design decisions with improving value potentials of architectures. Despite microservices' popularity, research still lacks disciplined understanding of transition and consensus on the principles and activities underlying that transition. In this paper, we report on a systematic mapping study that consolidates various views, approaches and activities that commonly assist in the transition to microservices. The study aims to provide a better understanding of the transition; it also contributes a working definition of the transition and technical activities underlying it. We term the transition and technical activities leading to microservice architectures as microservitization. We then shed light on a fundamental problem of microservitization: microservice granularity and reasoning about its adaptation as first-class entities. This study reviews state-of-the-art and -practice related to reasoning about microservice granularity; it reviews modeling approaches, aspects considered, guidelines and processes used to reason about microservice granularity. This study identifies opportunities for future research and development related to reasoning about microservice granularity.";
Agile practices for global software development vendors in the development of green and sustainable software;"Over the last decade, the use of agile methods has grown dramatically for software development. Agile methods guarantee to accelerate the delivery of remarkable software with increased user satisfaction and reduced cost. However, in recent years, due to emergence of green software engineering, software developers are compelled to focus more on green and sustainable aspects of software. Global software engineering aims to design, develop, and use a software with limited energy and computing resources. Recently, software engineers in global software development (GSD) have adapted agile methods for quick, interactive, and environment-friendly software development. However, there is a lack of specific practices to be followed by GSD vendors in the development of green and sustainable software.

In this study, we have identified 36 agile practices through systematic literature review and applied contrived search criteria derived from the research questions; 53 relevant papers were identified and reviewed. Findings of the systematic literature review were then empirically validated through questionnaire survey in GSD industry, in which 106 relevant experts from 25 different countries participated. The identified agile practices are intended to assist GSD vendors in strengthening their agile maturity towards green and sustainable software development.";
A hybrid assessment approach for medical device software development companies;Medical device software development organizations are bound by regulatory requirements and constraints to ensure that developed medical devices will not harm patients. Medical devices have to be treated as complete systems and be evaluated in this manner. Instead of manufacturers having to ensure compliance to various regulatory standards individually, the authors previously developed a medical device software process assessment framework called MDevSPICE® that integrates the regulatory requirements from all the relevant medical device software standards. The MDevSPICE® was developed in a manner that suits plan-driven software development. To improve the usability of MDevSPICE® in agile settings, we extended the assessment approach. The hybrid assessment approach described here combines the MDevSPICE®-based process assessment method with steps for prioritization of improvement needs through value stream mapping and enabling process improvement through the use of KATA technique. This approach integrates agile methods into the medical device software development process while adhering to the requirements of the regulatory standards. This paper describes the implementation of the approach within 4 organizations that develop software in line with medical device regulations.;
Using agile methods for the development of green and sustainable software: Success factors for GSD vendors;"Over the last decade, the use of agile methods has grown dramatically for software development. Agile methods guarantee to accelerate the delivery of remarkable software with increased user satisfaction and reduced cost. However, in recent years, due to the emergence of green software engineering, software developers are compelled to focus more on green and sustainable aspects of software. Green software engineering aims to design, develop, and use the software with confined energy and computing resources. Recently, software engineers in global software development have adapted agile methods for quick, interactive, and environment-friendly software development.

In this study, we have identified 16 success factors, through systematic literature review (SLR) and applied contrived search criteria derived from the research questions; 80 relevant papers were identified and reviewed. Findings of the SLR study were then empirically validated through questionnaire survey in global software development industry, in which 106 experts from 25 different countries participated.

The findings of our industrial survey are mostly in coherence with the SLR findings. However, there is a difference in ranks of the various success factors across the 2 data sets (SLR and industrial survey).";
Architectural support in industry: a reflection using C-POSH;"Software architecture plays a vital role in the development (and hence maintenance) of large complex systems (containing millions of lines of code) with a long lifetime. It is therefore required that the software architecture is also maintained, i.e., sufficiently documented, clearly communicated, and explicitly controlled during its life-cycle. In our experience, these requirements cannot be met without appropriate support.

Commercial-off-the-shelf support for architectural maintenance is still scarcely available, if at all, implying the need to develop appropriate proprietary means. In this paper, we reflect upon software architecture maintenance taken within three organizations within Philips that develop professional systems. We extensively describe the experience gained with introducing and embedding of architectural support in these three organizations. We focus on architectural support in the area of software architecture recovery, visualization, analysis, and verification.

In our experience, the support must be carried by a number of pillars of software development, and all of these pillars have to go through a change process to ensure sustainable embedding. Managing these changes requires several key roles to be fulfilled in the organization: a champion, a company angel, a change agent, and a target. We call our reflection model C-POSH, which is an acronym for Change management of the four identified pillars of software development: Process, Organization, Software development environment, and Humans. Our experiences will be presented in terms of the C-POSH model. Copyright © 2005 John Wiley & Sons, Ltd.";
A systematic mapping study: The new age of software architecture from monolithic to microservice architecture—awareness and challenges;Microservice architecture (MSA) is an emerging architectural style as an innovative approach that is growing in quality over time. Microservices are endorsed by various researchers to shatter the issues and limitations encountered by the use of aging approaches for monolithic legacy architecture styles. Nonetheless, there exists no state of the research exhaustive study on migration to MSA from monolithic architecture. MSA has made the need to design the development methods of software and styles of architectures that satisfy these demands. The design of software architecture is the ongoing rise of MSA to address the independent deployment, scalability, and maintenance requirements. In this article, a systematic mapping study (SMS) was performed, including the literature on the migration approaches published between 2010 and 2021 to evaluate the contemporary state of the art and practice of software architecting. This study outlines the awareness and importance of MSA. Seventy-three studies were finally selected in this SMS. The following perspectives of this study are publication trends, main venues, the focus of research, migration approaches, migration challenges, successful factors after migration, and the potential for industrial adoption. We synthesize the data and give a summary of the state of the art. This study also provides future research directions and applications for adopting microservices.;
Maintaining a legacy: towards support at the architectural level;"An organization that develops large, software intensive systems with a long lifetime will encounter major changes in the market requirements, the software development environment, including its platform, and the target platform. In order to meet the challenges associated with these changes, software development has to undergo major changes as well. Especially when these systems are successful, and hence become an asset, particular care shall be taken to maintain this legacy; large systems with a long lifetime tend to become very complex and difficult to understand. Software architecture plays a vital role in the development of large software systems. For the purpose of maintenance, an up-to-date explicit description of the software architecture of a system supports understanding and comprehension of it, amongst other things. However, many large complex systems do not have an up-to-date documented softwarearchitecture. Particularly in cases where these systems have a long lifetime, the (natural) turnover of personnel will make it very likely that many employees contributing to previous generations of the system are no longer available. A need to ‘recover’ the software architecture of the system may become prevalent, facilitating the understanding of the system, providing ways to improve its maintainability and quality and to control architectural changes. This paper gives an overview of an on-going effort to improve the maintainability and quality of a legacy system, and describes the recent introduction of support at the architectural level for program understanding and complexity control.";
Transitioning the SWFTS Program Combat System Product Family from Traditional Document-Centric to Model-Based Systems Engineering;"Over the past four years, the Submarine Warfare Federated Tactical Systems (SWFTS) Systems Engineering & Integration (SE&I) program has shifted from traditional document-centric systems engineering to a model-based systems engineering (MBSE) process for managing the evolution and support of the common combat system used by most submarines in the U.S. and Royal Australian Navies. At the beginning of this transition a pilot study established technical feasibility, and projected a 13% reduction in the cost of processing a baseline if MBSE were applied to support the SWFTS system of systems baseline development process. Over the course of two years of development new modeling techniques were invented, and a large-scale system of systems model was designed, implemented, and populated.

Now the transition to operations has begun. In early 2012 SWFTS SE&I produced its first new generation of combat system interface baselines using MBSE. The technical foundation has been established, and the workforce transition is under way. Anticipated cost reductions are still a year away as the workforce ascends the learning curve, but the program is already seeing improvements in the quality and consistency of engineering products.

This paper summarizes this document-centric to model-based SE transition, describes the accomplishments and observations to date, and describes the metrics being collected to quantify the achieved return on investment once the transition is complete.";
Systems and Software Architecting: A Unified Approach;Formulating a sound architecture has become one of the most important elements in systems engineering, software engineering and systems integration. Significant work has been done in the architecting of systems and, mostly as a separate matter, the architecting of software. This paper focuses upon the issue of a unified approach to both systems and software architecting. A specific procedure for a unified method is suggested and illustrated.;
Emerging and multidisciplinary approaches to software engineering;"Software engineering is inherently a socio-technical effort with best practices based on social interaction. However, these practices are likely to vary with cultural aspects that cannot be externalised or captured by automation tools alone. Therefore, engineering software products requires a vision which involves thinking across boundaries for the future, which goes further than we have conceived. In particular, novel software development approaches are closely tied to the traditional concerns of social factors that affect the success of software development as a whole. To address these concerns and establish a strategy that will achieve a broader vision, researchers seek ways to adapt techniques from multiple academic disciplines and draw knowledge from various areas including management, sociology, anthropology, psychology, etc. Ultimately, applying best practices from multiple academic disciplines is critical for future success in engineering sustainable software products.

In this special issue, we have brought together a diversity of interdisciplinary or multidisciplinary endeavours to address open software engineering issues that cross disciplinary boundaries. Our goal is to collect current research efforts, views, and experiences among researchers and software practitioners contributing to advances in multidisciplinary research. Specifically, we seek contributions that highlight how these approaches can be utilised to address the opportunities and challenges with emerging technological advancements impacting the economic, political, environmental, social, and technical aspects of software engineering.";
Towards a reference process for software architecture reconstruction;"Nowadays, software systems remain useful and competitive; entail the inevitable need to change over time and to be adapted to new technologies, platforms, and architectures. These quick changes imply following systematic, automated, or standardised processes that provide recommendations and guidelines to architects during software architecture reconstruction. Considerable research work on architecture reconstruction has been conducted. However, it needs to be studied thoroughly to determine what are the common activities and elements to reconstruct software architectures, and to define a reference process for systematically guiding the evolution of software architectures. This work addresses the need for defining a process for software architecture reconstruction called software improvement in the reconstruction of architectures (SIRA). This process has been rigorously designed from the results of a systematic literature review and a small survey of related work. As a result, SIRA integrates and extends previous research and can be conceived as a reference process to reconstruct software architectures in a semi-automated way. In addition, this work also determines the common elements of the architecture reconstruction process: (i) techniques and activities; (ii) architectural elements, patterns, and attributes; (iii) mechanisms and strategies; and (iv) the automation and recommendation tasks of the process.";
5.4.4 Optimizing Distributed Software Architectures for Ground Based Weapon Systems;"Modern ground based weapon systems depend heavily upon electronics and software for correct and safe operations. Many of these ground based weapon systems exhibit behaviors from very different domains: automobiles (e.g. engines and transmissions), aircraft avionics systems (e.g. sophisticated sensors and advanced situational awareness), and hard real-time industrial controls (e.g. weapon loading equipment).

This paper describes the fundamental approach to Crusader's software architecture and through specific examples, demonstrates that the Crusader software architecture is highly adaptable, provides a firm technical foundation for evolutionary growth, and is capable of supporting a family of ground based weapon systems.";
National Software Industry Development: Considerations for Government Planners;Software presents an unusual set of problems for policy makers. As a major global industry, it has been successfully targeted by a growing number of countries for its potential to generate export revenue. At the same time, it is an essential, high-risk, and increasingly expensive component of Information and Communications Technology (ICT)-related programs to increase government effectiveness and to bring local firms in other industries up to globally competitive performance levels. This paper outlines the range of considerations specific to software within ICT planning and discusses government's role in accelerating and shaping that growth in support of social and economic priorities. We draw on the experience of both developed and emerging economies to argue that government should take an active role in software industry development, and to lay out the full range of possible government actions (both policies and programs). Every country's path seems to be different – the best course of action will depend on the resources available (including infrastructure and human resources), on the state of the global software industry at that specific time, and on the country's unique situation, such as languages spoken, regional or cultural ties with major markets, a tradition of entrepreneurship, or an expatriate business community.;
Realizing service migration in industry—lessons learned;In this paper, we present two descriptive case studies covering the re-engineering and further evolution of adopting service-oriented architecture (SOA) in the industry. The first case was carried out for a company in the transport sector with an application portfolio of over 700 systems. The second case study was conducted for an organization in the public sector. The goal of both case studies is to identify the possible benefits and drawbacks of realizing SOA in large organizations in order to obtain a better perspective on the real, rather than the assumed, benefits of SOA in practice. We describe how the two cases were developed and carried out, and discuss the experiences gained and lessons learned from adopting SOA in the two organizations. Based on these findings, we propose several directions for further research.;
In direct breach of managerial edicts: a practice approach to creative deviance in professional service firms;Drawing on practice as a meta-theoretical lens, we explore creative deviance (CD): wilful violation of managerial orders by employee(s) to pursue creative ideas. Data for our inquiry comes from in-depth interviews with middle managers and employees in two professional service firms (PSFs). We argue that two distinct organising processes are necessary for the emergence of CD in practice: organising configuration and formalisation of R&D processes. We develop these dimensions to produce a typology of interrelated ideal types of outcomes when employees are explicitly instructed to stop pursuing an idea. We found three salient organising practices (technical concerns for efficiency and metrics, suppression of metistic knowledge and disjointed managerial responses to violations of sanctioned organising procedures), which may operate in combination or serially, to foster CD in practice. We conclude with some key implications for the theory and practice of creativity in PSFs.;
Energy efficiency on the product roadmap: An empirical study across releases of a software product;"In the quest for energy efficient Information and Communication Technology, research has mostly focused on the role of hardware.

However, the impact of software on energy consumption has been acknowledged as significant by researchers in software engineering. In spite of that, due to cost and time constraints, many software producing organizations are unable to effectively measure software energy consumption preventing them to include energy efficiency in the product roadmap.

In this paper, we apply a software energy profiling method to reliably compare the energy consumed by a commercial software product across 2 consecutive releases. We demonstrate how the method can be applied and provide an in-depth analysis of energy consumption of software components. Additionally, we investigate the added value of these measurement for multiple stakeholders in a software producing organization, by means of semistructured interviews.

Our results show how the introduction of an encryption module caused a noticeable increase in the energy consumption of the product. Such results were deemed valuable by the stakeholders and provided insights on how specific software changes might affect energy consumption. In addition, our interviews show that such a quantification of software energy consumption helps to create awareness and eventually consider energy efficiency aspects when planning software releases.";
Software and the Scientist: Coding and Citation Practices in Geodynamics;In geodynamics as in other scientific areas, computation has become a core component of research, complementing field observation, laboratory analysis, experiment, and theory. Computational tools for data analysis, mapping, visualization, modeling, and simulation are essential for all aspects of the scientific workflow. Specialized scientific software is often developed by geodynamicists for their own use, and this effort represents a distinctive intellectual contribution. Drawing on a geodynamics community that focuses on developing and disseminating scientific software, we assess the current practices of software development and attribution, as well as attitudes about the need and best practices for software citation. We analyzed publications by participants in the Computational Infrastructure for Geodynamics and conducted mixed method surveys of the solid earth geophysics community. From this we learned that coding skills are typically learned informally. Participants considered good code as trusted, reusable, readable, and not overly complex and considered a good coder as one that participates in the community in an open and reasonable manor contributing to both long- and short-term community projects. Participants strongly supported citing software reflected by the high rate a software package was named in the literature and the high rate of citations in the references. However, lacking are clear instructions from developers on how to cite and education of users on what to cite. In addition, citations did not always lead to discoverability of the resource. A unique identifier to the software package itself, community education, and citation tools would contribute to better attribution practices.;
Open source software and economic growth: A classical division of labor perspective;The article turns to classical economic insights on the division of labor and to institutional reasoning to identify some costs and benefits of open source software (OSS) and proprietary software production. It suggests that, thanks to its licenses, OSS favors market expansion more than proprietary software does by tapping into spontaneous work input. The spontaneous tapping leads to a division of labor that exhibits what the article calls redundant economies. By generating a circle of knowledge growth, reuse, and sharing, redundant economies lead to increasing returns, which are crucial for economic growth.;
Evidence for the network perspective on organizational learning;This article provides evidence for the network perspective on organizational learning in the cases of two companies of different size, industry, and culture. It builds on an earlier article that introduced the network perspective on organizational learning, and proposes some common traits of learning networks and tests them with the help of the tools of social-network analysis. We find support for the network perspective on organizational learning. There are some traits of the learning network that are common to very different companies, such as the fact that learning occurs mainly in clusters. Some other traits depend much on the organizational culture.;
Insider Information: The Ethicality of the High Frequency Trading Industry;This study explores the ethical perceptions of employees in the financial industry. Focusing on the high frequency trading (HFT) industry, it analyses a series of interviews with HFT employees (managers, computer programmers and traders). It shows that regulations and firm rules profoundly affect HFT practices. However, they do not provide employees with answers for their ethical questions. To judge the ethicality of HFT, employees choose reference stakeholder groups and assess the way HFT impacts them. The perception that HFT has a positive effect on stakeholder groups is associated with moral satisfaction, whereas the perception that it has a negative effect is related to emotional detachment, sense of meaninglessness and turnover intent. The high variance in employees’ choices of stakeholder reference groups emphasizes the subjectivity and uncertainty that HFT ethicality entails. Therefore, this study suggests that the financial industry may lack moral leadership. It makes empirical and theoretical contributions to the ‘business ethics as practice’ theory and examines management and regulatory applications.;
Microservice reference architecture design: A multi-case study;Microservice architecture (MSA) is an architectural style that is designed to support the modular development of software systems within a particular domain. It is characterized by the use of small, independently deployable services, which can be developed and deployed autonomously. The benefits of MSA include improved scalability, fault-tolerance, and ease of deployment and maintenance. However, developing MSA for a specific domain can be challenging and requires a thorough consideration of various concerns such as service boundaries, communication protocols, and security. To support the easy development and guidance of an MSA for practitioners, we present a reference architecture design for MSA. The reference architecture has been designed after a comprehensive domain analysis of MSA in the literature and the MSAs of key vendors. This analysis has been used to identify best practices and common patterns that can be applied to the development of MSA. Additionally, relevant architecture viewpoints have been selected to model the corresponding architecture views, providing a clear and comprehensive understanding of the architecture. To validate the proposed reference architecture, a multi-case study research approach has been used. In this approach, two industrial case studies have been used to demonstrate the practical applicability of the proposed reference architecture. The results of these case studies have shown that the reference architecture can be used to effectively guide the development of MSA in real-world scenarios.;
An industry survey on approaches, success factors, and barriers for technology transfer in software engineering;One central aspect of software engineering research is the transfer of the proposed approaches into industrial practice. In the past, a number of technology transfer approaches and experiences from technology transfer projects in software engineering have already been reported. However, many researchers still struggle to get their research results noticed by practitioners. To investigate what is important to practitioners, we conducted a mixed-methods study that provides us with reliable quantitative data as well as deeper insights from qualitative data. Our results show that there is a mismatch between industry professionals' needs and commonly proposed technology transfer approaches in the software engineering field. For instance, collaboration between industry and academia as well as participation in empirical evaluations is not deemed important from an industry point of view. In contrast, industry professionals emphasize the use of company-specific pilot projects conducted by industry and the need for experts to be available in every phase of technology transfer.;
