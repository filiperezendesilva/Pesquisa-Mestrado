Título;Resumo;Selecionado
Value-based software engineering: reinventing;"The Value-Based Software Engineering (VBSE) agenda described in the preceding article has the objectives of integrating value considerations into current and emerging software engineering principles and practices, and of developing an overall framework in which they compatibly reinforce each other. In this paper, we provide a case study illustrating some of the key VBSE practices, and focusing on a particular anomaly in the monitoring and control area: the ""Earned Value Management System."" This is a most useful technique for monitoring and controlling the cost, schedule, and progress of a complex project. But it has absolutely nothing to say about the stakeholder value of the system being developed. The paper introduces an example order-processing software project, and shows how the use of Benefits Realization Analysis, stake-holder value proposition elicitation and reconciliation, and business case analysis provides a framework for stakeholder-earned-value monitoring and control.";1
Value-based knowledge management: The contribution of group processes;Knowledge management has recently received much attention in software engineering, but the main focus has been on information systems to support learning. For most software companies, the most valuable knowledge remains in the people, and this knowledge needs different methods to be managed. In this chapter, we discuss the learning contribution of two people-oriented methods: postmortem reviews and process workshops.;1
Towards estimating the value of an idea;Today software industry lives in a very competitive environment and firms need to improve constantly. One way to achieve this goal can be the introduction of innovative ideas into the products, processes or services of the firms, allowing thus to increase the value delivered to the customer. Various sources of innovation are already identified in literature to obtain new ideas. It is hard to identify the most effective idea sources. Moreover, to introduce new ideas without a defined goal could turn out lots of waste for the company. In this research work it is pointed out why the estimation of the value of an idea is difficult, more when the item to evaluate is a new unimplemented idea. As a solution to this a framework that facilitates and supports the idea value estimation is proposed. Based on a the available literature, the authors outline a framework for innovation that will facilitate organizations to identify new ideas and to estimate their potential value. This framework will facilitate the introduction of innovation in software intensive systems industry.;1
Value and viability considerations in information systems development;The question of value is being increasingly discussed in various disciplines in recent years. Value-Based Management and Value-Based Software Engineering (VBSE) have emerged as promising attempts for employing the value concept in generating information systems which satisfy the needs of all stakeholders. We analyzed several package software implementation projects for assessing applicability of value based approach and found that seldom sufficient value for stakeholders has been produced. VBSE might have helped to achieve better results, although the theory itself is not fully matured yet. We found that stressing the role of agency in value analysis by utilizing the life metaphor can significantly enhance the explanatory power of the theory. This facilitates understanding of many advanced qualities of systems and development of theoretical framework for transforming the enterprise together with its information system. Our analysis will be concluded with suggestions for conducting projects similar to those analyzed in this article;1
A proposed value-based software process tailoring framework;Software process tailoring is the act of customising the existing software process to suit the specific software project. Current practices in software process tailoring consider project characteristics as the sole input to tailor the software process. In addition, it maintains the traditional approach whereby all the project characteristics factors are treated as being equally important. There is a need to shift the traditional software process tailoring approach to a value-centric approach by using a value-based software engineering concept. This study aims to propose a value-based software process tailoring framework to tailor the software process. A review was conducted to analyse the components embedded and input factors in the selected prior studies on software process tailoring. The framework proposed in this study uses value-based factors as input factors to tailor the software process. The framework also considers value prioritisation component, which rank the process elements according to value priority.;1
Value-Based Coverage Measurement in Requirements-Based Testing: Lessons Learned from an Approach Implemented in the TOSCA Testsuite;Testing is one of the most widely practiced quality assurance measures and also one of the most resource-intensive activities in software development. Still, however, most of the available methods, techniques and tools for software testing are value-neutral and do not realize the potential value contribution of testing. In this paper we present an approach for value-based coverage measurement that can be used to align the testing effort with the achievable value associated with requirements and functional units. It has been implemented as part of a commercial test tool and was successfully applied in real-world projects. The results demonstrated its ability to adequately capture the distribution of the business value and risks involved in different requirements. The paper concludes with sharing important lessons learned from developing value-based coverage measurement in the practical setting of commercial tool development and real-world test projects.;1
Creating software product value in China;China has become a formidable player and continues to experience strong growth in a dynamic global market for software development. This highly competitive environment makes maximizing the creation of software product value both difficult and important. When looking at a software product, different stakeholder groups—purchasers, users, software managers, and developers—have different notions of value. This study examines the stakeholder perspectives and criteria used to select and prioritize software release requirements in three groups of software development companies: Chinese companies with a domestic market, Chinese companies with an international market, and Western companies operating in China. The results are similar for all three groups, except for after-sales support, which was a significantly greater concern for Chinese companies with an international market.;1
Decision theoretic requirements prioritization A two-step approach for sliding towards value realization;Budget and schedule constraints limit the number of requirements that can be worked on for a software system and is thus necessary to select the most valuable requirements for implementation. However, selecting from a large number of requirements is a decision problem that requires negotiating with multiple stakeholders and satisficing their value propositions. In this paper I present a two-step value-based requirements prioritization approach based on TOPSIS, a decision analysis framework that tightly integrates decision theory with the process of requirements prioritization. In this two-step approach the software system is initially decomposed into high-level Minimal Marketable Features (MMFs) which the business stakeholders prioritize against business goals. Each individual MMF is further decomposed into low-level requirements/features that are primarily prioritized by the technical stakeholders. The priorities of the low-level requirements are influenced by the MMFs they belong to. This approach has been integrated into Winbook, a social-networking influenced collaborative requirements management framework and deployed for use by 10 real-client project teams for the Software Engineering project course at the University of Southern California in Fall 2012. This model allowed the clients and project teams to effectively gauge the importance of each MMF and low-level requirement and perform various sensitivity analyses and take value-informed decisions when selecting requirements for implementation.;1
Global software engineering: Challenges in customer value creation;Global Software Engineering (GSE) involves software engineering projects executed with virtual teams from different time zones and diverse cultures. Over the past decade GSE has become the norm influenced by several factors such as optimal costs, availability of skilled pool of resources and globalization trends such as mergers and acquisitions. Adoption of Customer Value Management (CVM) and implementing value-based practices in GSE context is at a nascent stage. Realizing stakeholder values and implementing value-based practices are crucial to offer tangible as well as intangible value additions besides ensuring high quality deliverables on schedule. On GSE perspective it is mandatory to align the values offered by projects with stakeholder values in order to improve customer satisfaction and retention. This paper is based on our experience in executing Outsourced Product Development & Testing engagements. This paper discusses the challenges we faced in implementing value-based practices in a set of projects, and the approach we followed to overcome some of these challenges. Also, this paper presents our findings and results obtained through annual Customer Experience Surveys.;1
Offshore insourcing: A case study on software quality alignment;Background: Software quality issues are commonly reported when off shoring software development. Value-based software engineering addresses this by ensuring key stakeholders have a common understanding of quality. Aim: This work seeks to understand the levels of alignment between key stakeholders on aspects of software quality for two products developed as part of an offshore in sourcing arrangement. The study further aims to explain the levels of alignment identified. Method: Representatives of key stakeholder groups for both products ranked aspects of software quality. The results were discussed with the groups to gain a deeper understanding. Results: Low levels of alignment were found between the groups studied. This is associated with insufficiently defined quality requirements, a culture that does not question management and conflicting temporal reflections on the product's quality. Conclusion: The work emphasizes the need for greater support to align success-critical stakeholder groups in their understanding of quality when off shoring software development.;1
An approach to defining a value-based software development process;Much research has been performed on value-based requirements engineering, value-based design, value-based testing, and other related activities. However, to date, there is no holistic approach to help software engineers and project managers transform value-neutral software development processes to value-based processes. Current works on value-based software engineering (VBSE) mainly focus on how to make specific software process activities bring value. In this paper, we present an approach that helps convert or tailor value-neutral processes to value-based processes. The resulting new processes bring more value to the stakeholders, because the process is more capable to manage the cost and benefit of the software. An experiment is conducted to verify the proposed approach.;1
A lightweight value-based software architecture evaluation;Current software engineering practice is focused on value-neutral processes. Value-based architecting, one of value-based software engineering agendas, involves the further consideration of the system objectives associated with different stakeholder values in selecting an optimal architectural alternative. There are several value-based architectural evaluation techniques and cost benefit analysis method (CBAM) is a widely used, established technique based on return on investment (ROI). The weaknesses of the existing techniques are uncertainties from several subjective errors and the heavyweight process, which requires many steps and participation of stakeholders. This paper proposes a lightweight value-based architecture evaluation technique, called LiVASAE, using analytic hierarchy process (AHP), which can support a multi-criteria decision-making process. The proposed technique can help overcome the major weakness of the existing techniques such as the uncertainties caused by subjective decision making and heavy-weight process for architecture evaluations. LiVASAE provides a way to measure the uncertainty level using AHP's consistency rate (CR) and It also provides three simplified evaluation steps. In addition, the LiVASAE presents a framework for decision makers to make technical decisions associated with business goals (or values) such as cost, time-to-market, and integration with legacy system.;1
Value based fuzzy requirement prioritization and its evaluation framework;Requirement engineering is one of the most significant phases of software engineering. Success or failure of any software project relies heavily on better requirement engineering process. Better awareness of the requirements is fundamental for requirements engineering. Requirement Prioritization is an important component of requirement engineering process. In this paper, we have highlighted some serious shortcomings related to existing requirement prioritization techniques. Based on these findings, we have proposed an intelligent fuzzy logic based technique for requirements prioritization based on the perceived value of each requirement. We have also proposed a framework for evaluation of existing as well as proposed requirement prioritization techniques.;1
Multi-aspects based requirements priortization technique for value-based software developments;In requirements engineering (RE), different activities are carried on to add up business values to the software products. In value-base software (VBS), financial impacts on business are measured, and this phenomenon makes VBS different than other traditional software applications. In VBS systems, determination of valuable requirements is a crucial task and depends on multiple aspects or factors. Requirement prioritization is a part of RE and is considered as a crucial decision-making activity. Requirements prioritization is a process where requirements are arranged in an order to create a stakeholder priority list. Different requirements prioritization techniques are used by the experts in the industry to partially support the prioritization process for VBS development. Business and technical aspects play a vital role to make prioritization process effective. In existing requirements prioritization techniques, technical aspects are not applied well, and their consideration is partial only. Moreover, the business aspects are ignored which are highly vital for VBS development. There is a need to introduce multi-aspects requirements prioritization technique to support the selection of candidate requirements for VBS development. Hence, this paper focuses on a new requirements prioritization technique for VBS.;1
Capturing consumer preferences as requirements for software product lines;Delivering great consumer experiences in competitive market conditions requires software vendors to move away from traditional modes of thinking to an outside-in perspective, one that shifts their business to becoming consumer-centric. Requirements engineers operating in these conditions thus need new means to both capture real preferences of consumers and then relate them to requirements for software customized in different ways to fit anyone. Additionally, because system development models require inputs that are more concrete than abstract, the indistinct values of consumers need to be classified and formalized. To address this challenge, this study aims to establish a conceptual link between preferences of consumers and system requirements, using software product line (SPL) as a means for systematically accommodating the variations within the preferences. The novelty of this study is a conceptual model of consumer preference, which integrates generic value frameworks from both psychology and marketing, and a method for its transformation to requirements for SPL using a goal-oriented RE framework as the mediator. The presented artifacts are grounded in an empirical study related to the development of a system for online education.;1
Aspects of software quality assurance in open source software projects: Two case studies from Apache Project;Open source software (OSS) solutions provide mission- critical services to industry and government organizations. However, empirical studies on OSS development practices raise concerns on risky practices such as unclear requirement elicitation, ad hoc development process, little attention to quality assurance (QA) and documentation, and poor project management. Event then the ability to produce high quality products in such an environment may seem surprising and thus warrants an investigation on effective QA mechanism in OSS projects. This paper provides a preliminary exploration to improve our understanding of software quality practices in different types of OSS projects. We propose a framework of QA in an OSS project, elicit OSS stakeholder value propositions for QA, and derive performance indicators. For an initial empirical evaluation we applied these indicators to 5 releases of 2 large Apache projects (Tomcat and MyFaces) to analyze the extent to which QA aspects are commonly performed during development process.;1
Quantitative analysis of value-based software processes usingdecision-based stochastic object Petri-Nets;"The value-based software process (VBSP) is gaining more and more attention. However, the quantitative analysis techniques for VBSPs could not closely follow up the fast developing paces of the modeling techniques. In this paper, we proposes a decision-based stochastic extension of object petri nets (OPN) to resolve the issues. OPNs are well suited for modeling VBSPs and stochastic object petri nets (SOPN) combine the benefits of OPNs and the stochastic theory. The decision-based stochastic object petri net (DB-SOPN) model is economics driven and links value creation with decision making, multi-stakeholder satisfying, and risk management. It includes two levels: the high level models the guideline of the software process life cycle; and the low-level represents the different stakeholder's perspectives of the process. Some activities of a process have candidate policies that will produce different value reward. Our model simulates the entire software process, and compares various combinations of candidate policies to make the value reward of the process maximum.";1
The value gap model: Value-based requirements elicitation;The user requirements of many web-based services are dynamically and continuously changing even during the service time itself. For that reason, web service companies always keep trying to satisfy users' needs from the market. Requirements elicitation, among the processes in requirements engineering, is a process requiring high costs and time. Thus, a company planning to conduct the process wants to catch the points users don't satisfy in their needs by taking advantage of an effective process of requirements elicitation. In this paper, we propose value based requirements elicitation, so called, the value gap model aiming to clarify need selection and focus on key factors to a requirements engineer who should take into account the value on behalf of users. To do that, the process, at first, recognizes a value gap between the value users currently have and the value a system understand as users' one, and then it figures out the components that a requirements engineer has to select and focus on in his or her requirements elicitation process. In order to focus on and invest effectively the resources of elicitation process, the proposed process finds the part where most of users feel unsatisfying so that it eventually elicits the valuable requirements from users.;1
Value-oriented requirements prioritization in a small development organization;Requirements engineering, especially requirements prioritization and selection, plays a critical role in overall project development. In small companies, this often difficult process can affect not only project success but also overall company survivability. A value-oriented prioritization (VOP) framework can help this process by clarifying and quantifying the selection and prioritization issues. A case study of a small development company shows a successful VOP deployment that improved communications and saved time by focusing requirements decisions for new product releases on core company values;1
A five-step method for value-based planning and monitoring of systems engineering projects;"Main activities of project management for the development of complex software-intensive systems are currently: (a) to plan the project by selecting processes, methods and resources; and (b) to control the project by monitoring mainly cost and schedule, the so-called ''earned values"". Concentrating solely on these values bears the disadvantage that other important measures are not under observation. These often neglected measures comprise e.g. requirements clarity, which also contributes to the ""system value"" as it will be recognized by its stakeholders. Therefore the meaning of the term ""value "" has to be extended, taking also into account less- and non-monetary values and their monitoring has to start at early project phases (e.g. during requirements engineering). This paper describes a five-step method which enriches the ""earned value"" concept with other important value aspects. This shall support project managers in their value-based planning and monitoring of systems engineering projects, thus increasing the value for the addressed stakeholders";1
Value-based selection of requirements engineering tool support;"In large software and systems engineering companies like Siemens PSE there are several requirements tools in use. There is no ""one tool fits all projects/departments"" solution for requirements engineering due to the variety of departments and project types. Thus, project managers and requirements engineers usually face the problem of selecting the most suitable tool sets available for their given situation. In this paper, we report on a value-based requirements tool selection approach developed at PSE that helps to find the optimal tool support. This selection is based on rating the value contribution of suitably-defined tool features for the given project context. We conducted an initial feasibility study with a number of typical requirements tools at PSE. Main results were: the approach is straight-forward and seems to be a good means for project managers to compare requirements tools and select the most valuable tool for a particular project";1
How much software quality investment is enough: A value-based approach;"A classical problem facing many software projects is determining when to stop testing and release the product for use. Risk analysis helps address this issue by balancing the risk exposure of doing too little with the risk exposure of doing too much. A quantitative approach based on the COCOMO II cost-estimation model and the COQUALMO quality-estimation model helps answer the question, ""How much software quality investment is enough?"" The authors use the models and some representative empirical data to assess the relative payoff of value-based testing as compared to value-neutral testing. They include examples of the approach's use under differing value profiles.";1
The ROI of software dependability: The iDAVE model;In most organizations, proposed investments in software dependability compete for limited resources with proposed investments in software and system functionality, response time, adaptability, speed of development, ease of use, and other system capabilities. The lack of good return-on-investment models for software dependability makes determining the overall business case for dependability investments difficult. So, with a weak business case, investments in software dependability and the resulting system dependability are frequently inadequate. Dependability models will need to support stakeholders in determining their desired levels for each dependability attribute and estimating the cost, value, and ROI for achieving those. At the University of Southern California, researchers have developed software cost- and quality-estimation models and value-based software engineering processes, methods, and tools. We used these models and the value-based approach to develop an Information Dependability Attribute Value Estimation model (iDAVE) for reasoning about software dependability's ROI.;1
Prioritization of stakeholder value using metrics;Given the reality of resource constraints, software development always involves prioritization to establish what to implement. Iterative and incremental development methods increase the need to support dynamic prioritization to identify high stakeholder value. In this paper we argue that the current prioritization methods fail to appropriately structure the data for stakeholder value. This problem is often compounded by a failure to handle multiple stakeholder viewpoints. We propose an extension to an existing prioritization method, impact estimation, to move towards better capture of explicit stakeholder value and to cater for multiple stakeholders. A key feature is the use of absolute scale data for stakeholder value. We use a small industry case study to evaluate this new approach. Our findings argue that it provides a better basis for supporting priority decision-making over the implementation choices for requirements and designs.;1
Taming inconsistency in value-based software development;The main objective in value-based software engineering is to align value considerations with the full range of existing and emerging software engineering principles and practices so as to increase value for software assets. However, inconsistencies that arise during software development pose a threat to the objective, if they are not properly tamed. In this paper, we review the current landscape of inconsistency management in the value-neutral software engineering setting. After examining the dimensions of inconsistency as a phenomenon in software development process, we propose some guidelines on how to tame conflicting descriptions and inconsistencies in value-based software engineering. The take-home message is that inconsistency is an issue to be reckoned with in value-based software engineering.;1
Machine learning and value-based software engineering: A research agenda;Software engineering research and practice thus far are primarily conducted in a value-neutral setting where each artifact in software development such as requirement, use case, test case, and defect, is treated as equally important during a software system development process. There are a number of shortcomings of such value-neutral software engineering. Value-based software engineering is to integrate value considerations into the full range of existing and emerging software engineering principles and practices. Machine learning has been playing an increasingly important role in helping develop and maintain large and complex software systems. However, machine learning applications to software engineering have been largely confined to the value-neutral software engineering setting. In this paper, the general message to be conveyed is to apply machine learning methods and algorithms to value-based software engineering. The training data or the background knowledge or domain theory or heuristics or bias used by machine learning methods in generating target models or functions should be aligned with stakeholders’ value propositions. An initial research agenda is proposed for machine learning in value-based software engineering.;1
Aligning the software project selection process with the business strategy: A pilot study;This report aims to present the significance of requirements engineering approaches in guiding the project selection process with an overall objective of ensuring that selected projects align fully with an established business strategy. We analyze software practitioners’ views on managing the software project selection process in Cape Town, South Africa. We designed this empirical study following on from our previous literature survey. Using data categorization techniques, our findings suggest that software vendors ought to ensure that organizational business strategy is well explained to all stakeholders, including the technical personnel who produce the software. Similarly, the engineering approaches directed towards mitigating selection of risky business must be utilized and integrated into the development process. Failure to take these factors into perspective renders the organizational competitive strategy ineffective. Detailed research methods used in the study are given as well as approaches undertaken for data collection and analysis.;1
Requirement prioritization decision factors for agile development environments;In an agile development environment, project planners continuously prioritize work tasks so requirements that provide the most value are delivered first. This strategy is based on Value Based Software Engineering principles that different requirements deliver different levels of value and diverse stakeholders view the importance of the value of various requirements differently and thus, will prioritize them differently. However, we found that there are several core values that stakeholders have more agreement in terms of relevancy and importance than others. By knowing these core values, project planners have increased insights as to which requirements should be prioritized higher, hence, hopefully increasing overall stakeholder satisfaction and reducing project risk.;1
VRRM: Avalue-based requirements risk management process;"The technological, cost, people and schedule issues faced by software development, make it vulnerable for several types of risks. Among these the requirements' risks are proven to have the highest contribution. An effective risk management is critical while developing software systems. Moreover, a project can never be successful if stakeholders don't get their ""valued"" things. Every requirement contributes towards some value for a stakeholder. Therefore it is important to manage requirement risks effectively. Also, as different stakeholders have different perception of risk, it is necessary to have a process that can manage requirements' risks and fulfills the values of stakeholders as well. This paper contributes by presenting a VRRM process that is designed to manage requirements related risks in a value based manner.";1
A product management challenge: Creating software product value through requirements selection;It is important for a software company to maximize value creation for a given investment. The purpose of requirements engineering activities is to add business value that is accounted for in terms of return on investment of a software product. This paper provides insight into the release planning processes used in the software industry to create software product value, by presenting three case studies. It examines how IT professionals perceive value creation through requirements engineering and how the release planning process is conducted to create software product value. It also presents to what degree the major stakeholders’ perspectives are represented in the decision-making process. Our findings show that the client and market base of the software product represents the most influential group in the decision to implement specific requirements. This is reflected both in terms of deciding the processes followed and the decision-making criteria applied when selecting requirements for the product. Furthermore, the management of software product value is dependant on the context in which the product exists. Factors, such as the maturity of the product, the marketplace in which it exists, and the development tools and methods available, influence the criteria that decide whether a requirement is included in a specific project or release.;1
Developing a process framework using principles of value-based software engineering: Research sections;In this article we present a software process framework using the 4 + 1 theory and principles of value-based software engineering (VBSE). The value-based process framework serves as a 6-step process guide, and explains critical interactions between the five theories in the 4 + 1 theory of value-based software engineering. This article also applies the process framework to a supply chain organization through a case study analysis to illustrate its strength in practice.;1
A decision modelling approach for analysing requirements configuration trade-offs in time-constrained web application development;"""Release planning is a key phase in a time-constrained web development process, enabling stakeholders to find an appropriate trade-off between time-to-market and quality/ functional characteristics of the delivered artifact Despite the importance of conducting release planning activities, many web development projects still employ ad-hoc methods for deciding on the next release to be developed In this paper, we discuss an effective release planning and configuration method underpinned by a decision modelling framework aimed at supporting small development teams to analyze, prioritize requirements, and to find a candidate release configuration that can be developed within the time, quality and functionality constraints relating to the project The method is value-based, taking into account the stakeholders' belief in what is regarded as the most valuable release configuration The method is also consensus-driven, seeking to promote a consensual agreement with regard to the next release to be implemented.""";1
A study of value in agile software development organizations;The Agile manifesto focuses on the delivery of valuable software. In Lean, the principles emphasise value, where every activity that does not add value is seen as waste. Despite the strong focus on value, and that the primary critical success factor for software intensive product development lies in the value domain, no empirical study has investigated specifically what value is. This paper presents an empirical study that investigates how value is interpreted and prioritised, and how value is assured and measured. Data was collected through semi-structured interviews with 23 participants from 14 agile software development organisations. The contribution of this study is fourfold. First, it examines how value is perceived amongst agile software development organisations. Second, it compares the perceptions and priorities of the perceived values by domains and roles. Third, it includes an examination of what practices are used to achieve value in industry, and what hinders the achievement of value. Fourth, it characterises what measurements are used to assure, and evaluate value-creation activities.;1
Using Bayesian network to estimate the value of decisions within the context of value-based software engineering: A multiple case study;The software industry's current decision-making relating to product/project management and development is largely done in a value neutral setting, in which cost is the primary driver for every decision taken. However, numerous studies have shown that the primary critical success factor that differentiates successful products/projects from failed ones lie in the value domain. Therefore, to remain competitive, innovative and to grow, companies must change from cost-based to value-based decisionmaking where the decisions taken are the best for that company's overall value creation. This paper details a case study where value-based decisions made by key stakeholders to select features for the next sprint of an Internet of Things (IoT) project, stored in a decisions database, were used to build and validate a value estimation model. This model's goal was to estimate the overall value contribution that each feature being discussed during a decision-making meeting would bring to the company, if selected for implementation. The estimation technique employed was Bayesian Network, and validation results were quite positive.;1
Integrating collaborative requirements negotiation and prioritization processes: A match made in heaven;Selecting system and software requirements to implement in a particular product or release is a challenging decision problem. Business stakeholders strive to maximize return on investment by selecting the most valuable requirements for implementation. Deciding on the requirements to be selected entails a great deal of communication and coordination amongst the stakeholders to ascertain the priorities of the individual requirements. The prioritized requirements aid in the planning and sequencing of implementation activities associated with the software system and provides a basis of a prioritized backlog from which the requirements can be ‘pulled’ for development. Changing business priorities may require a complete reprioritization of the backlog, leading to wasted effort. Individual change requests and new requirements need to be prioritized and inserted into the correct location in the backlog requiring high communication overhead. In this paper we summarize a two-step prioritization approach using a decision theoretic model to prioritize system and software requirements that alleviates these concerns. The system is initially decomposed into high-level Minimal Marketable Features (MMFs) and each MMF is further decomposed into low-level requirements. The MMFs are prioritized against the business goals of the organization and the low-level requirements with respect to ease of realization and business value. The priorities of the individual requirements are influenced by that of the MMFs they belong to. This two-step approach serves as an important prelude for a dynamically prioritizable product backlog. In this paper we present a proof-of-concept of having implemented this approach with 24 real-client student project teams at the Software Engineering project course at the University of Southern California.;1
Supporting business calculations in a product line engineering tool suite;Software Product Line Engineering (SPLE) involves defining the commonalities and variability of similar products to leverage extensive reuse and to accelerate the derivation of customized products. However, sales people and customers do not only care about technical properties of product features during product derivation. They also need information concerning the business value of product features. Existing approaches have addressed this issue by combining business information with variability models, e.g., by defining feature attributes or by integrating third party tools. However, a solution that seamlessly integrates variability and business calculations within a SPLE tool is still lacking. We report on our ongoing efforts to integrate business calculations in the DOPLER tool suite. We use examples of product lines from the industrial plant automation domain to motivate and demonstrate our solution.;1
A Review of Value Based Software Engineering and its Impacts;Profitability is the main goal of every software organization. Software companies develop products to capture greater market place and gain the attention of targeted customers or stakeholder. In the past the software engineering field was not able to determine the stakeholder’s value of the developing product as mostly systems were based on value neutral setting. With the emergence of Value based software engineering (VBSE) the traditional software engineering discipline is vastly changed as during product development the stakeholder’s value proposition plays an important part and the development is done accordingly. In this article I cover some important aspects of value based software engineering regarding their impact in software reusability and quality. Different value based pricing criteria are discussed. Empirical research and value based selection of best suitable automated tools and existing Component off the shelf (COTS) and conflicts between different stakeholders of the same system are also taken into account. In the 3rd section Critical review of the all papers is performed and their plus and negative points are mentioned. At last the Conclusion and future work in value based software engineering field is presented.;1
Value-based software architecture knowledge management tool;Proper management of architectural knowledge (AK) is essential in order to reduce high evolution and maintenance costs and to avoid architectural erosion. Researchers have proposed different tools and techniques for managing architectural knowledge, but practitioners are reluctant in applying such tools and techniques because of certain inhibitors such as extra time and effort required, unclear benefits of documenting AK etc. To deal with such inhibitors, there is a need to manage AK in a value based manner. This paper presents a value-based approach for managing architectural knowledge. Value Based approach takes into account value consideration of stakeholders and only documents the information required by stakeholders. The value based approach is implemented on an existing open source software architecture management tool. Results are presented from the experiments which were conducted to evaluate the effectiveness of the value based knowledge management approach and the modified tool.;1
Utilizing GQM + Strategies for business value analysis: An approach for evaluating business goals;Business value analysis (BVA) quantifies the factors that provide value and cost to an organization. It aims at capturing value, controlling risks, and capitalizing on opportunities. GQM+Strategies is an approach designed to aid in the definition and alignment of business goals, strategies, and an integrated measurement program at all levels in the organization. In this paper we describe how to perform business value analysis (BVA) using the GQM+Strategies approach. The integration of these two approaches provides a coupling of cost-benefit and risk analysis (value goals) with operationally measurable business goals and supports the evaluation of business goal success and the effectiveness of the chosen strategies. An application of the combined approach is provided to illustrate the feasibility of the proposed method. It deals with the business goal of modernizing the product for the evolving market.;1
Value-driven software maintenance;This paper extends the concept of value-based software engineering as proposed by Boehm to the field of software maintenance. The various approaches to assessing the value of software products and to calculating the return on investment (ROI) on software projects are reviewed. The authors propose a methodology of value-driven software maintenance for assessing the value of software maintenance based on Hayek's theory of maintaining the value of capital goods in an evolving capital structure. A method for predicting costs of maintenance tasks based on impact analysis is combined with a method for assessing the added value produced by the maintenance tasks to compute the ROI on software projects. The validity of the approach is illustrated through a case study of the German social services payment system.;1
A value-based process for achieving software dependability;Since different systems have different success-critical stakeholders, and these stakeholders depend on the system in different ways, using traditional one-size-fits-all dependability metrics to drive the system and software development process is likely to lead to delivered systems that are unsatisfactory to some stakeholders. This paper proposes a Value-Based Software Dependability Achievement (VBSDA) process generated from the WinWin Spiral Model’s risk-driven approach coupled with a set of value-based dependability analysis frameworks, methods, and models for reasoning about software and system dependability. It helps project success-critical stakeholders define, negotiate and develop mission-specific combinations of dependability attributes. The NASA/USC Inspector SCRover (ISCR) project is used as a case study to elaborate the process.;1
Value-based processes for COTS-based applications;Economic imperatives are changing the nature of software development processes to reflect both the opportunities and challenges of using COTS products. Processes are increasingly moving away from the time-consuming composition of custom software from lines of code (although these processes still apply for developing the COTS products themselves) toward assessment, tailoring, and integration of COTS or other reusable components. Two factors are driving this change: COTS or other reusable components can provide significant user capabilities within limited costs and development time, and more COTS products are becoming available to provide needed user functions.;1
A framework for eliciting value proposition from stakeholders;Eliciting the value proposition in Value Based Software Engineering (VBSE) is critical. Everything within VBSE is dependent on the value propositions of success critical stakeholder (SCSs). This paper present presents a novel approach for elicitation of value from the SCSs from different dimensions. We propose a Value Elicitation Framework (VEF) in order to resolve the problem of selection and application of appropriated value elicitation technique for a given situation. We applied the VEF on a small commercial project to demonstrate the execution of VEF in practice and evaluate its effectiveness. Results show that decision makers felt more confident in decision making while using VEF as decisions are taken on basis of actual value rather than mere guess. We also found that SCSs were mainly using Business, Economic and Technical Values in making decisions.;1
Software process improvement in Europe: potential of the new V-modell XT and research issues;The goal of European industrial practice to support high-value software production in diversified domains has led to the development of a huge number of process model variants. However, these diverse models are hard to compare, which hinders efficient collaboration and software process improvement on a European level. Process managers see a growing need for approaches that support stakeholder collaboration, systematic process mapping, and transformation of processes to improve their leverage in software process improvement. In this article we present the V-Modell XT (VM XT), a flexible software process model approach that has recently been announced as the standard for public-sector IT projects in Germany, as promising opportunity to help provide a unifying European software process model ‘umbrella’. On the basis of strengths of the VM XT, we suggest research directions for advanced support of software projects: (i) effective business value translation to engineering solutions that strengthens stakeholder collaboration, (ii) process mapping that enables collaboration in projects that have to reconcile several process models, and (iii) process ‘product lines’ to capture the variability of software processes on domain and company levels and thus systematically help investigate best-practice approaches to software construction. We discuss these concepts, the contribution of the VM XT, and conclude with next steps for research and validation;1
Collaborative usability testing to facilitate stakeholder involvement;Stakeholder involvement is an essential part of Value-Based Software Engineering. A critical part of the software engineering life cycle concerns usability testing. System usability refers to the effectiveness, efficiency, and satisfaction with which users can use the system for their relevant tasks. Unfortunately stakeholder involvement in usability testing is costly and challenging to organize. This chapter presents a repeatable collaborative usability testing process supported by a Group Support System that was developed and evaluated in a series of workshops involving a real system. The results show that the collaborative usability testing process facilitates stakeholder involvement through stakeholder expectation management, visualization and tradeoff analysis, prioritization of usability action items, the use of advanced groupware tools, and a simple business case analysis. Furthermore, the process can be considered productive and stakeholders reported substantial levels of satisfaction with it.;1
Value-based management of software testing;Testing is one of the most resource-intensive activities in software development and consumes between 30 and 50% of total development costs according to many studies. Testing is however often not organized to maximize business value and not aligned with a project’s mission. Path, branch, instruction, mutation, scenario, or requirement testing usually treat all aspects of software as equally important, while in practice 80% of the value often comes from 20% of the software. In order to maximize the return of investment gained from software testing, the management of testing needs to maximize its value contribution. In this chapter we motivate the need for value-based testing, describe practices supporting the management of value-based testing, outline a framework for value-based test management, and illustrate the framework with an example.;1
Valuation of software initiatives under uncertainty: Concepts, issues, and techniques;State of the practice in software engineering economics often focuses exclusively on cost issues and technical considerations for decision making. Value-based software engineering (VBSE) expands the cost focus by also considering benefits, opportunities, and risks. Of central importance in this context is valuation, the process for determining the economic value of a product, service, or a process. Uncertainty is a major challenge in the valuation of software assets and projects. This chapter first introduces uncertainty along with other significant issues and concepts in valuation, and surveys the relevant literature. Then it discusses decision tree and options-based techniques to demonstrate how valuation can help with dynamic decision making under uncertainty in software development projects.;1
An initial theory of value-based software engineering;This chapter presents an initial “4+1” theory of value-based software engineering (VBSE). The engine in the center is the stakeholder win-win Theory W, which addresses the questions of “which values are important?” and “how is success assured?” for a given software engineering enterprise. The four additional theories that it draws upon are utility theory (how important are the values?), decision theory (how do stakeholders’ values determine decisions?), dependency theory (how do dependencies affect value realization?), and control theory (how to adapt to change and control value realization?). After discussing the motivation and context for developing a VBSE theory and the criteria for a good theory, the chapter discusses how the theories work together into a process for defining, developing, and evolving software-intensive systems. It also illustrates the application of the theory to a supply chain system example, discusses how well the theory meets the criteria for a good theory, and identifies an agenda for further research.;1
Value-based software engineering: Overview and agenda;Much of current software engineering practice and research is done in a value-neutral setting, in which every requirement, use case, object, test case, and defect is equally important. However, most studies of the critical success factors distinguishing successful from failed software projects find that the primary critical success factors lie in the value domain. The value-based software engineering (VBSE) agenda discussed in this chapter and exemplified in the other chapters involves integrating value considerations into the full range of existing and emerging software engineering principles and practices. The chapter then summarizes the primary components of the agenda: value-based requirements engineering, architecting, design and development, verification and validation, planning and control, risk management, quality management, people management, and an underlying theory of VBSE. It concludes with a global road map for realizing the benefits of VBSE.;1
Value-based software engineering: Seven key elements and ethical considerations;"This chapter presents seven key elements that provide candidate foundations for value-based software engineering:
1.Benefits Realization Analysis
2.Stakeholder Value Proposition Elicitation and Reconciliation
3.Business Case Analysis
4.Continuous Risk and Opportunity Management
5.Concurrent System and Software Engineering
6.Value-Based Monitoring and Control
7.Change as Opportunity
Using a case study we show how some of these elements can be used to incorporate ethical considerations into daily software engineering practice.";1
Measurement and decision making;Value-Based Software Engineering requires the capability to measure and analyze value in order to make informed decisions. The difficulty experienced by many organizations in measuring concepts that are even simpler than value suggests that this requirement will be hard to meet. The goal of this chapter is to build an understanding of measurement and decision making and the relationship between them. A multi-view model of measurement is presented as a way to cope with the complexity of measuring concepts such as value. A behavioral decision making model is presented that identifies the points at which measurement products impact the decision making behavior of a manager or software engineer. This model attempts to satisfactorily account for the idiosyncrasies of human behavior, while preserving some elements of the rational model of decision making. The chapter concludes with an application of these models to a case study in which achieving value is a key goal.;1
A context-based approach to the development of decision support systems;After more than three decades of research, the Decision Support Sys-tems (DSS) community is still looking for a unified and standardized DSS de-velopment methodology. In this paper, we argue that the existing solutions re-main too distinct and project-specific because they fail to properly consider the context of the target DSS in their processes. This paper describes a new approach, whose goal is to formalize the notion of context in the study of DSS development. The proposed approach is based on the concept of value-based software engineering. It is structured around two techniques called the benefits-realization approach and the realization feedback process. An example is provided to illustrate how an impractical, context-free DSS development life cycle can be turned into a context-based life cycle focus-ing on the most success-critical aspects of the target DSS.;1
Tailor the value-based software quality achievement process to project business cases;This paper proposes a risk-based process strategy decision-making approach. To improve the flexibility in applying the Value-Based Software Quality Achievement (VBSQA) process framework, we embed the risk-based process strategy decision-making approach into the VBSQA process framework. It facilitates project managers to tailor the VBSQA process framework to different project business cases (schedule-driven, product-driven, and market trend-driven). A real world ERP (Enterprise Resource Planning) software project (DIMS) in China is used as an example to illustrate different process strategies generated from process tailoring.;1
Estimating the value of decisions relating to managing and developing software-intensive products and projects;The software industry's current decision-making relating to product/project management and development is largely done in a value neutral setting, in which cost is the primary driver for every decision taken. However, numerous studies have shown that the primary critical success factor that differentiates successful products/projects from failed ones lie in the value domain. Therefore, to remain competitive, innovative and to grow, companies must change from cost-based decision-making to value-based decision-making where the decisions taken are the best for that company's overall value creation. Our vision to tackle this problem and to provide a solution for value estimation is to employ a combination of qualitative and machine learning solutions where a probabilistic model encompassing the knowledge from different stakeholders will be used to predict the overall value of a given decision relating to product management and development. This vision drives the goal of a 3-year research project funded by the Finnish Funding Agency for Technology and Innovation (Tekes), with the participation of several industry partners.;1
An empirical study on creating software product value in India – An analytic hierarchy process approach;India is growing strongly in the software industry and has a dynamic global market in software development. In today's competitive market it is necessary for the software companies to maximise the creation of software product value to remain a success in the market. The value of a software product is largely derived through the fulfilment of requirements. Therefore, it is necessary to carefully select the requirements to include in a specific software release. This paper presents an empirical study to understand how the value is created by finding the importance of different decision-making criteria and the perspectives that motivates them. The study is carried out among multinational software companies operating in India. The analytic hierarchy process is used to find the relative importance of the 13 criteria and to prioritise them by considering what creates business value in a software product. The results depict that for any product to be accepted in the market or by the potential customers business perspective is vital.;1
Value-driven V-model: From requirements analysis to acceptance testing;The goal of software testing should go beyond simply finding defects. Ultimately, testing should be focused on increasing customer satisfaction. Defects that are detected in areas of the software that the customers are especially interested in can cause more customer dissatisfaction. If these defects accumulate, they can cause the software to be shunned in the marketplace. Therefore, it is important to focus on reducing defects in areas that customers consider valuable. This article proposes a value-driven V-model (V2 model) that deals with customer values and reflects them in the test design for increasing customer satisfaction and raising test efficiency.;1
Applying the Value/Petri process to ERP software development in China;"Commercial organizations increasingly need software processes sensitive to business value, quick to apply, and capable of early analysis for subprocess consistency and compatibility. This paper presents experience in applying a lightweight synthesis of a Value-Based Software Quality Achievement (VBSQA) process and an Object-Petri-Net-based process model (called VBSQA-OPN) to achieve a manager-satisfactory process for software quality achievement in an on-going ERP software project in China. The results confirmed that 1) the application of value-based approaches was inherently better than value-neutral approaches adopted by most ERP software projects; 2) the VBSQA-OPN model provided project managers with a synchronization and stabilization framework for process activities, success-critical stakeholders and their value propositions; 3) process visualization and simulation tools significantly increased management visibility and controllability for the success of software project.";1
A value-based approach for documenting design decisions rationale: a replicated experiment;The explicit documentation of the rationale of design decisions is a practice generally encouraged but rarely implemented in industry because of a variety of inhibitors. Known methods for Design Decisions Rationale Documentation (DDRD) are aimed to maximize the benefits for practitioners who should utilize the DDRD by imposing the burden on the developers of documenting all the potentially useful information. In our view, the adoption of a tailored DDRD, consisting only of the required set of information, would mitigate the effects of DDRD inhibitors. This paper focuses on confirming empirically the feasibility of a value-based approach for documenting the rationale behind design decisions, and the importance of different DDRD information categories. In this context, this work describes a replicated experiment carried out at the University Rey Juan Carlos of Madrid (Spain) aimed to validate previous results from an analogous study conducted at the University of Roma Tor Vergata (Italy). Results confirm that the level of utility related to the same category of DDRD information significantly changes depending on its purpose.;1
A value-based framework for software evolutionary testing;The fundamental objective in value-based software engineering is to integrate consistent stakeholder value propositions into the full extent of software engineering principles and practices so as to increase the value for software assets. In such a value-based setting, artifacts in software development such as requirement specifications, use cases, test cases, or defects, are not treated as equally important during the development process. Instead, they will be differentiated according to how much they are contributing, directly or indirectly, to the stakeholder value propositions. The higher the contributions, the more important the artifacts become. In turn, development activities involving more important artifacts should be given higher priorities and greater considerations in the development process. In this paper, a value-based framework is proposed for carrying out software evolutionary testing with a focus on test data generation through genetic algorithms. The proposed framework incorporates general principles in value-based software testing and makes it possible to prioritize testing decisions that are rooted in the stakeholder value propositions. It allows for a cost-effective way to fulfill most valuable testing objectives first and a graceful degradation when planned testing process has to be shortened.;1
Application of value based requirement prioritization in a banking product implementation;"This paper describes the need for Value Based Requirement Prioritization (VBRP) in Core Banking transformation programs. We describe the VBRP tool selected for this purpose and how it was customized for use in a large product implementation in a bank. In the original VBRP tool developed before this experience we had hierarchical prioritization for various levels for requirements like modules, sub modules and requirements but we did not have goal hierarchies. We now came to know that hierarchies are also needed for goals and hence we introduced ""value levers"" and goals as two levels of the goal hierarchy. Also based on experience from the implementations of the product at various banks we came up with an exhaustive set of 22 goals for core banking transformation projects and used this knowledge to customize the generic VBRP tool for Core banking product implementations. This paper will help one understand the concept behind VBRP and get expertise to customize the concept to take care of special needs of projects in other domains.";1
VIRE: Sailing a blue ocean with value-innovative requirements;"Value-innovative requirements engineering guides software development organizations in creating new markets based on new product values for potential customers. Most requirements-engineering techniques and practices focus on eliciting requirements from existing, known customers. However, these techniques and practices aren't sufficient for surviving in current highly competitive markets. In particular, small organizations typically lack sufficient resources to compete effectively with large companies. W. Chan Kim and Renee Mauborgne proposed the blue-ocean strategy to create new marketplace value and so make competition irrelevant. A ""blue ocean"" is a potential market where competition doesn't yet exist.";1
Understanding customer expectations for system development;Meaning of expectations and differences among needs, expectations and requirements are ambiguous in literatures and practice. In this paper, we contribute to give a possible clarification of this ambiguity. The relationships among needs, expectations and requirements are examined together with characterization of customer expectations. We also introduce the expectations elicitation process based on engineering approach, which provides an explicit and controllable elicitation with a corresponding expectations elicitation quality model. Our goal is finally to connect expectations with value dimensions to enable value based requirements engineering.;1
A Brechó-EcoSys extension to support negotiation in the software ecosystems context;The treatment of economic and social issues in Software Engineering was pointed out as a challenge in the coming years. Organizations have opened up their platforms and assets to others, including partners and third-party developers around the world, generating software ecosystems (SECOs). SECOs research can contribute to minimize nontechnical barriers of software reuse in industry because it explores potential relations among companies and stakeholders. However, an inhibitor is the complexity in defining value for reusable assets. This paper presents an extension of the Brechó-EcoSys environment to support components negotiations in reuse repositories. The focus is on complementing the stakeholders' value proposition and realization, as well as incorporating a nontechnical mechanism in components repositories.;1
Customer value-based HW/SW partitioning decision in embedded systems;In launching a product, requirement change is always risk to an embedded system designer. Including requirements change, limited resources (e.g. development time and cost) are also risk factors to designing a system. However, the time to market constraint among several limitations is most critical especially to embedded system products (e.g. cellular phone, PDA, etc.). For that reason, many strategy makers try to find effective way to a HW/SW partitioning decision in early designing phase. Only ideal way to reduce requirements change and satisfy customers is reflecting their value to decision making steps in early phase prior to fixing HW and SW component design. In this paper, Customer Value based Partitioning Decision (CVPD) method is proposed to identify, analyze, and calculate the value of the customerspsila requirements, reflecting the value on the partitioning decision making process.;1
Selecting an appropriate framework for value-based requirements prioritization;There are usually more requirements than feasible in a given schedule. Thus, it's imperative to be able to choose the most valuable ones for implementation to ensure the delivery of a high value software system. There are myriad requirements prioritization frameworks and selecting the most appropriate one is a decision problem in its own right. In this paper we present our approach in selecting the most appropriate value based requirements prioritization framework as per the requirements of our stakeholders. Based on our analysis a single framework was selected, validated by requirements engineers and project managers and deployed for company-wide use by a major IT player in India.;1
Choosing the best design strategy from requirements. A value-based approach;Various different valid software design solutions may respond satisfactorily to the same product requirements. In addition, a great part of the success of a software project depends on the software design selected. However, there are very few methods that quantify how much value will be added by each particular design strategy, and hence very little time is spent in choosing the best design option. We propose a method that estimates the value of a design strategy, starting from requirements. This method is based on the probability of change of each requirement as well as of its relative importance. Those parameters will later be traced into better design artifacts. The proposed approach takes into account the cost of each strategy, the probability, or risk, and the cost of introducing a better design solution.;1
SimVBSE: Developing a Game for Value-Based Software Engineering;The development of games in aid of improving and enriching a student’s learning experience is again on the rise. The beer game [6] in the field of system dynamics was developed to instill the key principles of production and distribution. SimSE [5] provides a simulated game for its players to take on the role of a project manager, and experience the fundamentals of software engineering through cause-effect models. In this paper we present an initial design of SimVBSE as a game for students to better understand value-based software engineering [1], and its underlying theory [3].;1
Value-based software project management – A business perspective on software projects;When an organisation decides to invest in a software project it expects to get some value in return. Thus, decisions in software project management should be based on this expected value by trying to understand and influence its driver factors. However, despite the significant progress software engineering and project management has experienced in recent years, both disciplines work in a 'value neutral' context, by which is meant focusing on technical correctness and adherence to plans. This paper intends to contribute to a view of software project management based on business value by identifying value determinant factors in a software project and proposing some tools for recording and monitoring them. The proposed approach will be tested in a real project, in order to evaluate its applicability and usefulness in decision-making.;1
Developing a theory of value-based software engineering;"This paper presents an initial ""4+1"" theory of value-based software engineering (VBSE) that builds around the stakeholder win-win Theory W, and addresses the questions of ""which values are important?"" and ""how is success assured?"" for a given software engineering enterprise. The central Theory W then draws upon four additional theories - utility theory (how important are the values?), decision theory (how do stakeholders' values determine decisions?), dependency theory (how do dependencies affect value realization?), and control theory (how to adapt to change and control value realization?).";1
Value-based software engineering: A case study;The information technology field's accelerating rate of change makes feedback control essential for organizations to sense, evaluate, and adapt to changing value propositions in their competitive marketplace. Although traditional project feedback control mechanisms can manage the development efficiency of stable projects in well-established value situations, they do little to address the project's actual value, and can lead to wasteful misuse of an organization's scarce resources. The value-based approach to software development integrates value considerations into current and emerging software engineering principles and practices, while developing an overall framework in which these techniques compatibly reinforce each other.;1
Empirical results from an experiment on value-based review (VBR) processes;As part of our research on value-based software engineering, we conducted an experiment on the use of value-based review (VBR) processes. We developed a set of VBR checklists with issues ranked by success-criticality, and a set of VBR processes prioritized by issue criticality and stakeholder-negotiated product capability priorities. The experiment involved 28 independent verification and validation (IV&V) subjects (full-time working professionals taking a distance learning course) reviewing specifications produced by 18 real-client, full-time student e-services projects. The IV&V subjects were randomly assigned to use either the VBR approach or our previous value-neutral checklist-based reading (CBR) approach. The difference between groups was not statistically significant for number of issues reported, but was statistically significant for number of issues per review hour, total issue impact, and cost effectiveness in terms of total issue impact per review hour. For the latter, the VBRs were roughly twice as cost-effective as the CBRs.;1
Value-based requirements prioritization: Usage experiences;There are usually more requirements than feasible given budget and schedule constraints. Thus it's important to select the most valuable ones for implementation in order to ensure the delivery of a high value system. Simple prioritization approaches like 1- 10 ranking or MoSCoW lead to numerous ties requiring one to repeat the process for the tied items. In a previous study [1] we analyzed 17 different prioritization frameworks that could be used to perform value-based requirements prioritization (VBRP). The Technique of Ordered Preference by Similarity to Ideal Solution (TOPSIS) was selected as the framework of choice, as a result of the analysis. TOPSIS was deployed for use by a premier IT company in India. In this paper we present our experiences in using a decision analysis framework like TOPSIS to perform VBRP. We have seen successful applications of using such a decision analysis framework for prioritizing test-cases, scoping to select the most valuable requirements for a release or product roadmap, value focused resource allocation and value-oriented product customization. We aim to provide evidence showing how VBRP and decision analysis frameworks can help channelize various systems engineering activities by focusing on the most valuable items first. Our experience in deploying the framework for various prioritization activities provides strong evidence making explicit the need for VBRP as a first-class citizen for value-based planning, implementation and delivery of systems and software applications.;1
A value-based review process for prioritizing artifacts;As a new contribution to Value-based V&V process development, a systematic and multi-criteria process is proposed to quantitatively determine the Value-based V&V artifact priority that reviewers can follow for their reviews. This process enables reviewers to prioritize artifacts to be reviewed in a more cost-effective way based on more sophisticated and comprehensive factors, such as importance, quality risks, dependency and cost of V&V investments. Some qualitative and quantitative evidence is provided from a comparative experiment with 22 real-client e-services projects over two years of a graduate software engineering team-project course. It shows that the value-based artifact prioritization enabled reviewers to better focus on artifacts with high importance and risks, to capture issues with high impact in a timely manner, and to improve the cost-effectiveness of reviews.;1
Assessing quality processes with ODC COQUALMO;"Software quality processes can be assessed with the Orthogonal DefectClassification COnstructive QUALity MOdel (ODC COQUALMO) thatpredicts defects introduced and removed, classified by ODC types. Using parametriccost and defect removal inputs, static and dynamic versions of themodel help one determine the impacts of quality strategies on defect profiles,cost and risk. The dynamic version provides insight into time trends and issuitable for continuous usage on a project. The models are calibrated with empiricaldata on defect distributions, introduction and removal rates; and supplementedwith Delphi results for detailed ODC defect detection efficiencies. Thiswork has supported the development of software risk advisory tools for NASAflight projects. We have demonstrated the integration of ODC COQUALMOwith automated risk minimization methods to design higher value quality processes,in shorter time and with fewer resources, to meet stringent quality goalson projects.";1
Determining how much software assurance is enough? A value-based approach;"A classical problem facing many software projects is how to determine when to stop testing and release the product for use. On the one hand, we have found that risk analysis helps to address such ""how much is enough?"" questions, by balancing the risk exposure of doing too little with the risk exposure of doing too much. In some cases, it is difficult to quantify the relative probabilities and sizes of loss in order to provide practical approaches for determining a risk-balanced ""sweet spot"" operating point. However, we have found some particular project situations in which tradeoff analysis helps to address such questions. In this paper, we provide a quantitative approach based on the COCOMO II cost estimation model and the COQUALMO qualify estimation model. We also provide examples of its use under the differing value profiles characterizing early startups, routine business operations, and high-finance operations in marketplace competition situation. We also show how the model and approach can assess the relative payoff of value-based testing compared to value-neutral testing based on some empirical results. Furthermore, we propose a way to perform cost/schedule/reliability tradeoff analysis using COCOMO II to determine the appropriate software assurance level in order to finish the project on time or within budget.";1
A value-based software process framework;This paper presents a value-based software process framework that has been derived from the 4+1 theory of value-based software engineering (VBSE). The value-based process framework integrates the four component theories – dependency, utility, decision, and control, to the central theory W, and orients itself as a 7-step process guide to practice value-based software engineering. We also illustrate applying the process framework to a supply chain organization through a case study analysis.;1
Integrating value and utility concepts into a value decomposition model for value-based software engineering;Value-based software engineering (VBSE) is an emerging stream of research that addresses the value considerations of software and extends the traditional scope of software engineering from technical issues to business-relevant decision problems. While the concept of value in VBSE relies on the well-established economic value concept, the exact definition for this key concept within VBSE domain is still not well defined or agreed upon. We argue the discourse on value can significantly benefit from drawing from research in management, particularly software business. In this paper, we present three aspects of software: as a technology, as a design, and as an artifact. Furthermore, we divide the value concept into three components that are relevant for software product development companies and their customers: intrinsic value, externalities and option value. Finally, we propose a value decomposition matrix based on technology views and value components.;1
Brechó-VCM: A value-based approach for component markets;The treatment of economic and social aspects in Software Engineering was pointed out as a challenge for the next years. Specifically in Software Reuse, Component-Based Software Engineering needs to be evaluated considering its real applicability and feasibility against its promised benefits. However, this did not happen in an effective way yet, due to the lack of a mature and established market. One strong inhibitor is the complexity in defining value for components in the software context. Moreover, to create and maintain these markets, historical data and value considerations are strategies to be investigated. This paper proposes a value-based approach to address these strategies, focusing on the stakeholders’ value realization and on building a value chain, called Brechó-VCM, which aims at incorporating nontechnical aspects to a component library, generating a marketplace where sociotechnical networks contribute to calibrate the market growth.;1
Value estimation for software product management;Value-based approach of software engineering proved to be one of the most important branches of software engineering because it elicits and reconciles stakeholder¿s value propositions with respect to the system into a mutually satisfactory set of objectives for the system. Thus most of software organizations in market-driven environment nowadays adopt value-based approach with the focus on maximizing the value gained from their products against consumed resources. This leads to a need for a value estimation methodology to incorporate all the software product value aspects altogether while measuring the product value. Most of the existing methodologies focus on measuring product financial value and neglect the nonfinancial value. Value point measurement will facilitate quantifying the total value obtained from the product and compare it against planned product budget at early phases of the product life cycle. Such comparison will be used as a sort of justification for product feasibility. This paper illustrates a new estimation methodology for the software product value called ¿Value Point¿. VP measures value gained from the software product through quantifying value obtained from each product requirement. The process for value point counting will be illustrated through a designed product management framework. A case study is performed to demonstrate the added value from the proposed methodology.;1
Value-based design decision rationale documentation: Principles and empirical feasibility study;"The explicit documentation of the rationale of design decisions is a practice generally encouraged, but rarely implemented in industry because of a variety of inhibitors. Methods proposed in the past for design decisions rationale documentation (DDRD) aimed to maximize benefits for the DDRD consumer by imposing on the producer of DDRD the burden to document all the potentially useful information. We propose here a compromise which consists in tailoring DDRD, based on its intended use or purpose. In our view, the adoption of a tailored DDRD, consisting only of the required set of information, would mitigate the effects of DDRD inhibitors. The aim of this paper is twofold: i) to discuss the application of value-based software engineering principles to DDRD, ii) to describe a controlled experiment to empirically analyze the feasibility of the proposed method. Results show that the level of utility related to the same category of DDRD information significantly changes depending on its purpose; such result is novel and it demonstrates the feasibility of the proposed value-based DDRD.";1
An approach to measure value-based productivity in software projects;Nowadays, after a lot of evolution in software engineering area, there is not yet a simple and direct answer to the question: What is the best software productivity metric? The simplest and most commonly used metric is the SLOC and its derivations, but these are admittedly problematic for this purpose. In another way, there are some indications of maturation in this topic, the new studies point to the use of more labored models, which are based on multiple dimensions and in the idea of produced value. Based in this tendency and on the evidence that each organization must define its own way to assess their productivity, we defined a process to support the definition of productivity measurement models in software organizations. We also discuss, in this paper, some issues about the difficulties related with the process adoption in real software organizations.;1
Integrating Lean principles with value based software engineering;Lean Six-sigma principles and methods have been successfully applied in a variety of industries. Many of the core principles of Lean Six-sigma can be applied to software development to dramatically improve performance with some industry specific adaptations. In this regard, Lean Six-sigma principles can be made to further leverage the benefits of software engineering best practices to improve work flow and the tactical management of the project. The Value Based Software Engineering (VBSE) process as practiced today, begins the software development lifecycle (SDLC) with a sophisticated customer value analysis (CVA) which is coupled with a quantitative evaluation of pricing and profitability options followed by development of the software. The CVA yields a wealth of information not only for product features, but also for improving all processes within the organization that touch the customer. This paper seeks to present and articulate how applicable Lean Six-sigma principles can be coupled with the VBSE to improve the SDLC by improving the identification and delivery of customer value as well as the reduction of wasted resources. The net result is to substantially enhance the VBSE SDLC and the the organization's overall ability to deliver value.;1
Improving software testing process: Feature prioritization to make winners of success-critical stakeholders;"For a successful software project, acceptable quality must be achieved within an acceptable cost, demonstrating business value to customers and satisfactorily meeting delivery timeliness. Testing serves as the most widely used approaches to determine that the intended functionalities are performed correctly and achieve the desired level of services; however, it is also a labor-intensive and expensive process during the whole software life cycle. Most current testing processes are often technique-centered, rather than organized to maximize business value. In this article, we extend and elaborate the ‘4+1’ theoretical lenses of Value-based Software Engineering (VBSE) framework in the software testing process; propose a multi-objective feature prioritization strategy for testing planning and controlling, which aligns the internal testing process with value objectives coming from customers and markets. Our case study in a real-life business project shows that this method allows reasoning about the software testing process in different dimensions: it helps to manage the testing process effectively and efficiently, provides information for continuous internal software process improvement, and increases customer satisfaction, which makes winners of all success-critical stakeholders (SCSs) in the software testing process.";1
Feature usage as a value indicator for decision making;The number of features that add a high business value to a software product is stated to be lower in comparison to a total number of features. Some of the features lose their value in time, others are less valuable than intended from the very beginning. This might bloat the system with unnecessary features, which decrease the performance speed, require higher hardware capacities and increase maintenance costs. Therefore, the challenge is to monitor the customer's perceived value of the features in order to define strategies how to improve the product. In this paper, we investigate whether a combination of feature usage measures could be used as an indicator to monitor value of features and hence support decision making process. To this end, we conducted a case study in a startup company selecting a web based movie recommender system as the case.;1
Design decision rationale: Experiences and steps ahead towards systematic use;Design decisions crucially influence the success of every software project. While the resulting design is typically documented quite well, the situation is usually different for the underlying rationale and decision-making process. Despite being recognized as a helpful approach in general, the explicit documentation of Design Decision Rationale (DDR) is not yet largely utilized due to some inhibitors (e.g., additional documentation effort). Experience with other qualities, e.g. software reusability, evidently shows that an improvement of these qualities only pays off on a large scale and therefore has to be pursued in a strategic, pre-planned, and carefully focused way. In this paper we argue that this also has to be considered for documenting DDR. To this end the paper presents: (i) the Decision, Goal, and Alternatives (DGA) DDR framework, (ii) experience in dealing with DGA, (iii) motivators and inhibitors of using DDR, and (iv) an approach for systematic DDR use that follows value-based software engineering principles.;1
A case study on value-based requirements tracing;"Project managers aim at keeping track of interdependencies between various artifacts of the software development lifecycle, to find out potential requirements conflicts, to better understand the impact of change requests, and to fulfill process quality standards, such as CMMI requirements. While there are many methods and techniques on how to technically store requirements traces, the economic issues of dealing with requirements tracing complexity remain open. In practice tracing is typically not an explicit systematic process, but occurs rather ad hoc with considerable hidden tracing-related quality costs. This paper reports a case study on value-based requirements tracing (VBRT) that systematically supports project managers in tailoring requirements tracing precision and effort based on the parameters stakeholder value, requirements risk/volatility, and tracing costs. Main results of the case study were: (a) VBRT took around 35% effort of full requirements tracing; (b) more risky or volatile requirements warranted more detailed tracing because of their higher change probability.";1
Examining value-based factors in software development: A survey study in Malaysian public sector;Software development plays a major role in the production of software products. This process must be carefully designed in order to successfully deliver the end product, and at the same time fulfill the values desired. Value-Based Software Engineering (VBSE) aims to convert the value-neutral setting in developing software to become a more value-centric approach. This study presents exploratory survey results for the purpose of examining value-based factors that are most commonly used in software development. The survey conducted at the Malaysian public sector involving a software development team as the target population. Exploratory factor analysis was used as the main data analysis strategy in this study. The results reveal that there are 28 value-based factors that are most commonly used in software development which can be classified into four classifications (success-critical stakeholders, business strategy, project characteristics and product characteristics). Our objective in further research is to develop value-based factors profile as imperative input to conduct software process tailoring.;1
Exploring how feature usage relates to customer perceived value: A case study in a startup company;Most of the business value of a software product comes from only a small proportion of its features. Product managers face the challenge of identifying the high value features in an application and weeding out the ones of low value from the next releases. What creates this challenge is the fact that customer perceived value is an attribute, dimensions of which are not well-known yet. Currently, software companies try to assess the value of features through interviewing a number of key stakeholders. However, the literature suggests that, this kind of evaluation could be misleading due to stakeholders having different understanding of what value refers to. In this paper, through an exploratory case study, we investigate how usage of features relate to their perceived value and shed light into the factors affecting this relationship. The results show that feature usage metric has a significant potential to estimate value of features.;1
Modeling customer-centric value of system architecture investments;"""System architecture investments aim at improving the quality of the system in alignment with (current and future) business goals. While the costs of architecture changes are routinely calculated, identifying benefits of architecture changes and translating them to a monetary value has been a challenge in practice. Currently, architecture value estimation is largely based on cost-savings or on risk mitigation, without much reliance on potential customer benefits. This article reports on our experience in modeling the customer value and evaluating its potential use in choosing between different system architectures in two case studies conducted in an organization developing healthcare systems. To model the customer value, we exploit best practices in management and marketing. Management tools, in particular strategy maps and balanced scorecards, are used to identify customer-centric benefits caused by architecture design decisions. Furthermore, two marketing concepts, customer value-in-use and customer segments, are adopted to quantify the value of architecture changes for a single customer and multiple customers, respectively. The paper shows that using the customer value in addition to the existing value indicators in the organization has several advantages but also calls for future improvements to be adopted in practice.""";1
The software value map – Aan exhaustive collection of value aspects for the development of software intensive products;In software intensive products such as cars or telecom systems, software has traditionally been associated with cost, and there has been no real perception of its value in relation to the entire product offering. However, because software is becoming a larger part of the main competitive advantage, driving innovation and product differentiation, hardware is becoming more standardized, thus the valuation of software is becoming critical. In existing literature, several value constructs and corresponding valuation/measurement solutions needed for making decisions about software product development are presented. However, the contributions are often isolated with respect to a certain perspective such as focusing on product's internal or external quality aspects only. Consequently, a complete view of value constructs relevant from different perspectives required for making decisions about software product development is missing. This paper presents a consolidated view of the software value concept utilizing the major perspectives and introduces a software value map. The created value map was evaluated through an industry case study through the development of impact evaluation patterns, which were subsequently used by professionals in industry, and experiences gathered. During industry evaluation, practitioners found substantial benefits of having a consolidated, vastly improved, and extended value aspect's view of software.;1
Software quality across borders: Three case studies on company internal alignment;Context: Software quality issues are commonly reported when offshoring software development. Value-based software engineering addresses this by ensuring key stakeholders have a common understanding of quality. Objective: This work seeks to understand the levels of alignment between key stakeholder groups within a company on the priority given to aspects of software quality developed as part of an offshoring relationship. Furthermore, the study aims to identify factors impacting the levels of alignment identified. Method: Three case studies were conducted, with representatives of key stakeholder groups ranking aspects of software quality in a hierarchical cumulative exercise. The results are analysed using Spearman rank correlation coefficients and inertia. The results were discussed with the groups to gain a deeper understanding of the issues impacting alignment. Results: Various levels of alignment were found between the various groups. The reasons for misalignment were found to include cultural factors, control of quality in the development process, short-term versus long-term orientations, understanding of cost-benefits of quality improvements, communication and coordination. Conclusions: The factors that negatively affect alignment can vary greatly between different cases. The work emphasises the need for greater support to align company internal success-critical stakeholder groups in their understanding of quality when offshoring software development.;1
A value-based approach for understanding cost-benefit trade-offs during automated software traceability;"Many software development standards mandate establishing trace links among software artifacts such as requirements, architectural elements, or source code. However, for typical real-world systems it is currently too expensive and error prone to generate highly detailed trace links. We previously developed an approach to semi-automatically generate trace links and analyzed cost-benefit trade-offs in this context. We consider it as imperative to include value considerations into planning the generation of trace dependencies. This paper discusses three key trade-off decisions for planning the trace generation process: (a) the level of detail of traces among artifacts; (b) the value of the artifacts that are traced; and (c) the points in time of trace generation (early vs. late). We present cost-benefit considerations, empirical data, and argue for a pragmatic value-based planning approach.";1
Bridge the gap between software test process and business value: A case study;For a software project to succeed, acceptable quality must be achieved within an acceptable cost, providing business value to the customers, and keeping delivery time short. Software testing is a strenuous and expensive process and is often not organized to maximize business value. In this article, we propose a practical value based software testing method which aligns the internal test process with the value objectives coming from the customers and the market. Our case study in a real-life business project shows that this method helps manage testing process effectively and efficiently.;1
Preference-based decision support in software engineering;Throughout the lifecycle of a software system, complex decisions have to be made. One major source of complexity in decision problems is the need to simultaneously consider different, and sometimes conflicting, criteria. When a decision involves multiple criteria, it cannot be made in a purely objective way, but requires subjective judgement to evaluate the trade-offs between criteria. In the field of decision analysis, several methods have been developed to help decision makers to specify their preferences and apply them to a decision problem in a consistent way. In this chapter, we review several methods for multicriteria decision making, in particular additive weighting methods, methods based on aspiration levels, and outranking methods. We present the theoretical background of these methods, their specific ways of evaluating alternatives, and discuss their applicability to decision problems in software engineering. A concluding section discusses issues related to sensitivity analysis and the use of incomplete information.;1
Estimating the software product value during the development process;Nowadays software companies are facing a fierce competition to deliver better products but offering a higher value to the customer. In this context, software product value has becoming a major concern in software industry, leading for improving the knowledge and better understanding about how to estimate the software value in early development phases. Other way, software companies encounter problems such as releasing products that were developed with high expectations, but they gradually fall into the category of a mediocre product when they are released to the market. These high expectations are tightly related to the expected and offered software value to the customer. This paper presents an approach for estimating the software product value, focusing on the development phases. We propose a value indicators approach to quantify the real value of the development products. The aim is early identifying potential deviations in the real software value, by comparing the estimated versus the expected. We present an internal validation to show the feasibility of this approach to produce benefits in industry projects.;1
Decision support for value-based software release planning;Incremental software development replaces monolithic-type development by offering a series of releases with additive functionality. To create optimal value under existing project constraints, the question is what should be done when? Release planning (RP) provides the answer by assigning features to a sequence of releases in the most beneficial way within the resources available. In this chapter, we extend the existing hybrid intelligence-based release planning method called EVOLVE* to accommodate financial value in the form of net present value estimates of proposed features. This extension enables us to perform financial value-based software release planning. The new approach called F-EVOLVE* is illustrated by an example. The results show that the F-EVOLVE* model may be used to decide which features to produce and when based on their financial contributions. Specifically, F-EVOLVE* may be used to determine which features generate the highest returns, with the shortest development time.;1
What is important when deciding to include a software requirement in a project or release?;The requirements on software systems are so many that not all requirements may be included in the next development project or the next release. This means that it is necessary to select a set of requirements to implement in the forthcoming project, and hence to postpone the implementation of other requirements to a later point in time. In this selection process different criteria are used. In many cases, the criteria are not officially stated, but rather implicitly used by the decision-makers. However, to be able to support this decision-making process, it is important to know and understand the underlying reasons for the decisions. This paper presents an empirical study of the decision criteria. In particular, the paper focuses on how different perspectives have different influence on the decision-making process. It is concluded that business-oriented and management-oriented criteria are more important than technical concerns related to software architecture, impact analysis, dependency between requirements and software evolution.;1
Improving scenario testing process by adding value-based prioritization: An industrial case study;"""Most of the current testing strategies treat all aspects of software equally important in a value-neutral way; this becomes more risky when the testing resources are limited. Our goal in this case study aims at improving the testing cost-effectiveness of an industrial scenario testing process under time constraints. We proposed a value-based testing prioritization strategy which allows tests to be ranked by how well the tests can reduce risk exposure. Combining this with the tests’ relative costs enables them to be prioritized in terms of return on investment (ROI) or risk reduction leverage (RRL). Besides, a new metric Average Percentage of Business Importance Earned (APBIE) is proposed to measure how quickly the testing can reduce the quality uncertainty and earn the relative business importance of the system under test (SUT).The results from one case study to prioritize operational testing scenarios in Galorath Inc. show that our method can improve the testing cost-effectiveness in terms of APBIE.""";1
Stakeholder value proposition elicitation and reconciliation;This chapter motivates the need of methods and tools for understanding and reconciling stakeholder value propositions in software engineering. We present EasyWinWin, an example of a groupware-supported negotiation method that provides process structure and mediation to stakeholders. We identify challenges of stakeholder value proposition elicitation and negotiation and discuss possible extensions to EasyWinWin that address these challenges.;1
Value-based design of software V&V processes for NASA flight projects;Software risk advisory tools have been developed to support Verification and Validation (V&V) processes for NASA flight projects on the Constellation program. The Orthogonal Defect Classification COnstructive QUALity MOdel (ODC COQUALMO) predicts software defects introduced and removed classifying them with ODC defect types, allowing various tradeoff analyses. We have been exploring methods to design and optimize V&V processes with static and dynamic versions of the quality model by integrating it with different risk minimization techniques. These techniques allow “what-if” experimentation to determine the impact of V&V techniques on specific risks and overall flight risk. V&V techniques are quantified from a value-based perspective when the defect model is integrated with machine learning, strategic optimization and JPL’s Defect Detection and Prevention (DDP) risk management method. Results to-date show that the automated methods are practical for flight projects to design higher value V&V processes in shorter time and with fewer resources.;1
A value-based approach in requirements engineering: Explaining some of the fundamental concepts;Today’s rapid changes and global competition forces software companies to become increasingly competitive and responsive to consumers and market developments. The purpose of requirements engineering activities is to add business value that is accounted for in terms of return-on-investment of a software product. This article introduces some of the fundamental aspects of value by borrowing theories from economic theory, discusses a number of the challenges that face requirements engineers and finally provides a model that illustrates value from business, product and project perspectives.;1
Balancing opportunities and risks in component-based software development;The increasingly rapid change in information technology makes it essential for software development projects to continuously monitor and adapt to new sources of opportunity and risk. Software projects and organizations can increase their success rates in software development by better assessing and balancing their opportunities and risks. The authors summarize the incremental commitment model (ICM), a process framework for improved project monitoring and decision making based on balancing opportunities and risks. They give an example of how the ICM framework can improve component-based development choices based on assessment of opportunities and risks. They show how different opportunistic solutions result from different stakeholder value propositions. They elaborate on the risks involved in architectural mismatches among components, present a tool called the Integration Studio (iStudio) that enables projects to assess the most common sources of architectural mismatch between components. Finally, they present representative examples of its use.;1
Risk based decision support system for stakeholder quantification for value based software systems;Stakeholder identification and quantification (SIQ) is one of the core processes in software requirements engineering (RE). The significance of stakeholders becomes more vital when a software project is a valuebased software (VBS) and the value-based requirements engineering (VBRE) is involved in it.VBS systems are developed based on business concepts in order to gain market leverage in terms of financial or economic benefits. Different SIQ approaches are presented in literature. However, most of the approaches are partially effective and SIQ process is still immature. The techniques are presented and applied under different conditions in order to monitor the performance of the approach. The presented techniques are vague and difficult to initiate. In this research, a decision support system is presented for stakeholders’ quantification. The proposed system predicts the risk associated with the stakeholders using backpropagation neural network (BPNN).;1
Quest for a silver bullet: Creating software product value through requirements selection;This paper provides results of an empirical study on how software product value is both understood and created through release planning for software products in Australia. We examine how IT professionals perceive value creation through requirements engineering and how the release planning process is conducted to create software product value. We then look at the degree to which the major stakeholders' perspectives are represented in the decision making process. Our findings show that the client and market base of the software product represents the most influential group in the decision to implement specific requirements. This is reflected both in terms of deciding the processes followed and the decision making criteria applied when selecting requirements for the product. It is concluded that the creation of software product value is dependant on the context in which the software product exists, including issues such as the market or the age of the product;1
Value-based software engineering: Reinventing;"The Value-Based Software Engineering (VBSE) agenda described in the preceding article has the objectives of integrating value considerations into current and emerging software engineering principles and practices, and of developing an overall framework in which they compatibly reinforce each other. In this paper, we provide a case study illustrating some of the key VBSE practices, and focusing on a particular anomaly in the monitoring and control area: the ""Earned Value Management System."" This is a most useful technique for monitoring and controlling the cost, schedule, and progress of a complex project. But it has absolutely nothing to say about the stakeholder value of the system being developed. The paper introduces an example order-processing software project, and shows how the use of Benefits Realization Analysis, stake-holder value proposition elicitation and reconciliation, and business case analysis provides a framework for stakeholder-earned-value monitoring and control.";1
Maintenance cost of a software design: A value-based approach;Alternative valid software design solutions can give response to the same software product requirements. In addition, a great part of the success of a software project depends on the selected software design. However, there are few methods to quantify how much value will be added by each design strategy, and hence very little time is spent choosing the best design option. This paper presents a new approach to estimate and quantify how profitable is to improve a design solution. This will be achieved by estimating the maintenance cost of a software project using two main variables: The probability of change of each design artifact, and the cost associated to each change. Two techniques are proposed in this paper to support this approach: COCM (Change-Oriented Configuration Management) and CORT (Change-Oriented Requirement Tracing).;1
Adding value to software requirements: An empirical study in the Chinese software industry;The rapid growth of the Chinese software industry has attracted attention from all over the world. Meanwhile, software requirements selection has a crucial impact on the final value of a software product and the satisfaction of stakeholders. This paper presents an empirical study, which focuses on the decision-making criteria for requirements selection in market-driven software development projects in international companies in China. The outcome shows that some criteria, such as business strategy, customer satisfaction, and software features, are more important than others when making decisions for requirements selection.;1
The effects of perceived value and stakeholder satisfaction on software project impact;"Context In this paper we present a multiple case study on the insights of software organizations into stakeholder satisfaction and (perceived) value of their software projects. Our study is based on the notion that quantifying and qualifying project size, cost, duration, defects, and estimation accuracy needs to be done in relation with stakeholder satisfaction and perceived value. Objectives We contrast project metrics such as cost, duration, number of defects and estimation accuracy with stakeholder satisfaction and perceived value. Method In order to find out whether our approach is practically feasible in an industrial setting, we performed two case studies; one in a Belgian telecom company and the other in a Dutch software company. Results In this study we evaluate 22 software projects that were delivered during one release in the Belgian telecom company, and 4 additional large software releases (representing an extension of 174% in project size) that were delivered in a Dutch software company. Eighty-three (83) key stakeholders of two companies provide stakeholder satisfaction and perceived value measurements in 133 completed surveys. Conclusions We conclude that a focus on shortening overall project duration, and improving communication and team collaboration on intermediate progress is likely to have a positive impact on stakeholder satisfaction and perceived value. Our study does not provide any evidence that steering on costs helped to improve these. As an answer to our research question - how do stakeholder satisfaction and perceived value relate to cost, duration, defects, size and estimation accuracy of software projects? – we found five take-away-messages.";1
Requirements negotiation using multi-criteria preference analysis;"Many software projects have failed because their requirements were poorly negotiated among stakeholders. Reaching agreements of negotiated requirements among stakeholders who have different concerns, responsibilities, and priorities is quite challenging. Formal (fully-automated) approaches of requirements negotiation require significant efforts of knowledge representation and validation, whereas informal (manual) approaches do not provide systematic methods of requirements negotiation. This paper proposes a novel light-weighted, yet systematic requirements negotiation model, called ""Multi-Criteria Preference Analysis Requirements Negotiation (MPARN)"" to guide stakeholders to evaluate, negotiate, and agree upon alternatives among stakeholders using multi-criteria preference analysis theory. This eight-step MPARN model was applied to requirements gathered for an industrial-academic repository system. The result showed that the MPARN model assisted stakeholders to have unbiased aspects within a requirements negotiation in a light-weighted way and increase stakeholders' levels of cooperation and trust by measuring each stakeholder's preference and value function explicitly through a step-by-step process.";1
Value Assignment Process (VAP): Establishing Value of Software Through a New Definition of Value;"With rapid developments in the field of software products and services, it has assumed vital significance to define ""Value"" in a new perspective. With advent of new software engineering approaches like value based software engineering, this has become really relevant to look at value from specific perspective. We have proposed a new definition of value after briefly summarizing the earlier work to justify this proposal. A discussion on potential advantages and limitations of this new development is also made part of this work. We have presented a new approach for assigning value to software products or services which applies this new definition of value.";1
Simulation for business value and software process/product trade off decisions;Business value goals should be considered when making software process and product decisions, but it is usually difficult to integrate the perspectives quantitatively. This research uses simulation to assess product/process tradeoffs for economic business case analysis. A system dynamics model for commercial software enterprises relates the dynamics between product specifications, investment costs, schedule, software quality practices, market size, license retention, pricing and revenue generation. It allows one to experiment with different product strategies, software processes, marketing practices and pricing schemes while tracking financial measures over time. It can be used to determine the appropriate balance of process activities to meet business goals and product criteria. Applications are demonstrated for varying scope, reliability, delivery of multiple releases, and determining the quality sweet spot for different time horizons. Results show that optimal policies depend on various stakeholder value functions, opposing market factors and business constraints. Future model improvements are also identified.;1
Towards improving decision making and estimating the value of decisions in value-based software engineering: the VALUE framework;"To sustain growth, maintain competitive advantage and to innovate, companies must make a paradigm shift in which both short- and long-term value aspects are employed to guide their decision-making. Such need is clearly pressing in innovative industries, such as ICT, and is also the core of Value-based Software Engineering (VBSE). The goal of this paper is to detail a framework called VALUE—improving decision-making relating to software-intensive products and services development—and to show its application in practice to a large ICT company in Finland. The VALUE framework includes a mixed-methods approach, as follows: to elicit key stakeholders’ tacit knowledge regarding factors used during a decision-making process, either transcripts from interviews with key stakeholders are analysed and validated in focus group meetings or focus-group meeting(s) are directly applied. These value factors are later used as input to a Web-based tool (Value tool) employed to support decision making. This tool was co-created with four industrial partners in this research via a design science approach that includes several case studies and focus-group meetings. Later, data on key stakeholders’ decisions gathered using the Value tool, plus additional input from key stakeholders, are used, in combination with the Expert-based Knowledge Engineering of Bayesian Network (EKEBN) process, coupled with the weighed sum algorithm (WSA) method, to build and validate a company-specific value estimation model. The application of our proposed framework to a real case, as part of an ongoing collaboration with a large software company (company A), is presented herein. Further, we also provide a detailed example, partially using real data on decisions, of a value estimation Bayesian network (BN) model for company A. This paper presents some empirical results from applying the VALUE Framework to a large ICT company; those relate to eliciting key stakeholders’ tacit knowledge, which is later used as input to a pilot study where these stakeholders employ the Value tool to select features for one of their company’s chief products. The data on decisions obtained from this pilot study is later applied to a detailed example on building a value estimation BN model for company A. We detail a framework—VALUE framework—to be used to help companies improve their value-based decisions and to go a step further and also estimate the overall value of each decision.";1
What we have learned about the value of software assurance;"Context: There is a pervasive feeling that somehow software assurance is important. For example, national space agencies, such as the National Aeronautics and Space Administration (NASA) and the Japan Aerospace Exploration Agency (JAXA), require assurance for their critical software systems. Their assurance effort goes beyond testing, and includes activities such as process compliance checks, artifact audits, and traceability validation. These activities can be costly and their benefits, particularly in managing risk, are poorly understood. This inevitably leads to tough questions concerning value such as ""Is assurance worth doing?"" and ""How much assurance do we actually need?""
Goal: For many years the software assurance community has been struggling with how to rationalize investing in software assurance. Numerous value models have been suggested, but these have not been able to explicitly connect assurance activities to their expected benefits, making them difficult to use for value assessment. As a consequence, assurance managers are ill equipped to plan and justify their budgets, frequently finding that assurance is first on the chopping block when cuts are made. We discuss some common value propositions and how why they are not operationally useful within our assurance practice. Method: From our ongoing empirical study of assurance practice at NASA and JAXA, we are led to a fundamental assurance value proposition that implies an operational and justifiable proposition of assurance value. We depart from contemporary views that focus on defect-centric factors such as defect avoidance or early defect mitigation. Rather, we have observed that assurance value stems from enabling more confident quality-critical decision-making. Results: From this new viewpoint value can be tangibly measured as a reduction in the risk of making a bad decision due to uncertainty in quality factors. This has some surprising and consequential implications. For example, from this viewpoint, assurance value does not depend on the actual number of defects found; instead it depends on the degree of coverage an assurance activity provides, regardless if defects are found.
Conclusions: By exploring what we have learned about assurance value we better understand and from an industry standpoint it is an important issue to address.";1
The value proposition for assurance of JPL systems;This paper presents a value proposition for systems assurance. The need for a value proposition is motivated by common misconceptions about the definition of assurance and the value of performing systems assurance activities. The focus of the value proposition is that assurance reduces uncertainty so that projects can make more confident decisions about their systems. Applying the value proposition has led to insights into the nature of assurance and has improved the practice of software assurance, where it has been applied at the Jet Propulsion Laboratory (JPL). Ongoing work on using the value proposition for “value-based tailoring” of requirements and integrating value considerations into assurance cost models are also discussed.;1
Business value is not only dollars – Results from case study research on agile software projects;Business value is a key concept in agile software development. This paper presents results of a case study on how business value and its creation is perceived in the context of agile projects. Our overall conclusion is that the project participants almost never use an explicit and structured approach to guide the value creation throughout the project. Still, the application of agile methods in the studied cases leads to satisfied clients. An interesting result of the study represents the fact that the agile process of many projects differs significantly from what is described in the agile practitioners’ books as best practices. The key implication for research and practice is that we have an incentive to pursue the study of value creation in agile projects and to complement it by providing guidelines for better client’s involvement, as well as by developing structured methods that will enhance the value-creation in a project.;1
Value-based intelligent requirement prioritization (VIRP): Expert driven fuzzy logic based prioritization technique;Requirement Prioritization is a very critical but often neglected area of requirement engineering. Experience has shown that without proper prioritization of requirements presented by various stakeholders, the end product usually fails to meet its objectives optimally. In fact in many instances, the product is considered a failure because it fails to meet its core objectives. Several requirement prioritization techniques have been presented by various researchers over the past years. Working with these techniques has exposed several limitations when applied in software projects. In this paper, we have presented a novel multi-level value based intelligent requirement prioritization technique using fuzzy logic. We have introduced and applied the concept of requirement value to prioritize requirements. We have performed extensive experimentation using our proposed technique along with existing techniques. Results have shown that our technique has achieved superior prioritization results and consistency. The experiments have also shown that proposed technique is capable of delivering impressive prioritization under various circumstances.;1
Providing tool-support for value-based decision making: A usability assessment;Numerous companies worldwide make their decisions related to software projects/products in a value neutral way, using only earned value systems, which represent short-term goals. Better decisions can be made using a value-based approach, achieving cost-effective results and reliable construction and maintenance of products. However, moving from a value-neutral to a value-based paradigm can be a challenge. We provide tool-support, which was co-created in collaboration with three software companies, to ease the paradigm shift. Our tool supports both individual and group-based decisions using several visualization mechanisms. Despite the co-creation process employed while developing the VALUE tool, there are specific issues relating to its usability that must also be assessed in order to reduce any possible drawbacks for its adoption by industry. This paper details three usability studies that were carried out to assess the VALUE tool's usability. The results also suggest that the tool is ready to be taken into use in the industry.;1
Improving software development process through economic mechanism design;We introduce the novel concept of applying economic mechanism design to software development process, and aim to find ways to adjust the incentives and disincentives of the software organization to align them with the motivations of the participants in order to maximize the delivered value of a software project. We envision a set of principles to design processes that allow people to be self motivated but constantly working toward project goals. The resulting economic mechanism will rely on game theoretic principles (i.e. Stackelberg games) for leveraging the incentives, goals and motivation of the participants in the service of project and organizational goals.;1
Do we know enough about requirements prioritization in agile projects: Insights from a case study;Requirements prioritization is an essential mechanism of agile software development approaches. It maximizes the value delivered to the clients and accommodates changing requirements. This paper presents results of an exploratory cross-case study on agile prioritization and business value delivery processes in eight software organizations. We found that some explicit and fundamental assumptions of agile requirement prioritization approaches, as described in the agile literature on best practices, do not hold in all agile project contexts in our study. These are (i) the driving role of the client in the value creation process, (ii) the prevailing position of business value as a main prioritization criterion, (iii) the role of the prioritization process for project goal achievement. This implies that these assumptions have to be reframed and that the approaches to requirements prioritization for value creation need to be extended.;1
An integrated approach to formulate a valuebased software process tailoring framework;Software process tailoring is an approach to customise the existing software development process or model that able to meet the software project’s needs. Software development project is unique and identical from one and another whereby the practices and decision should not be equally treated. Software process tailoring requires knowledge and intuition to make decision such as factors involved in the software project, selection of the suitable software process elements and tailoring operations. Software process tailoring practices focusing more on project characteristics factors and employs ad hoc approach in making the decision. In the absent of value-based factors and systematic method in software process tailoring, subjectivity is embedded in decision making process and the software development project suffers from satisfying the stakeholder. This study presents an integrated approach to formulate a Value-Based Software Process Tailoring Framework (VBSPTF) to overcome this problem. The framework is a combination of value-based factors, MoSCoW rules, Quality Functional Deployment (QFD), Activity-Based Costing (ABC), Priority Map, Value Index and Value Graph. This study perhaps can contribute to the software process tailoring practitioners to be exposed with a systematic method to conduct software process tailoring as well as improving the practices and reducing subjectivity in decision making.;1
An earned-value approach to assess and monitor software project uncertainty: A case study in software test execution;In this study, we proposed an earned-value approach to assess and monitor software uncertainty. It combines the value-at-risk method in financial field and the earned-value-feedback process of earned value project management and proposes a framework which contains value-at-uncertainty system, consumed-value-feedback system and experienced base to support in-process uncertainty measurement and contingency buffer management. Value-at-uncertainty system is used to assess the uncertainty in progress of a project and consumed-value-feedback system is applied to provide the decision support of how to deal with the buffer at that specific time. A case study in software test execution of 24 projects is conducted to evaluate the approach. The study shows how our approach works to measure the uncertainty and manage the buffer size in different project shapes. With the approach, both the accuracy and the effectiveness of uncertainty assessment can be improved along with the test execution progress.;1
Toward big data value engineering for innovation;"This article articulates the requirements for an effective big data value engineering method. It then presents a value discovery method, called Eco-ARCH (Eco-ARCHitecture), tightly integrated with the BDD (Big Data Design) method for addressing these requirements, filling a methodological void. Eco-ARCH promotes a fundamental shift in design thinking for big data system design -- from ""bounded rationality"" for problem solving to ""expandable rationality"" for design for innovation. The Eco-ARCH approach is most suitable for big data value engineering when system boundaries are fluid, requirements are ill-defined, many stakeholders are unknown and design goals are not provided, where no architecture pre-exists, where system behavior is non-deterministic and continuously evolving, and where co-creation with consumers and prosumers is essential to achieving innovation goals. The method was augmented and empirically validated in collaboration with an IT service company in the energy industry to generate a new business model that we call ""eBay in the Grid"".";1
The value of certifying software release readiness: An exploratory study of certification for a critical system at JPL;A software release is a decision to deliver code to an organization outside of the development team usually for testing or operational purposes. For critical systems this can be a risky decision where failure to pass a test or holding up the project schedule can have a major impact. The release decision is primarily based on the understanding on the level of quality the software currently has (be it high quality, low quality, or unknown). But for large, complex systems, determining the level of quality with high confidence is a challenge. A poor understanding of the confidence in the quality level increases decision risk leading potentially to a bad release decision that possibly could have been avoided had the confidence in the quality been better known. Certification of release readiness attempts to address this risk by building confidence in the quality level. But this comes at a cost and the relationship between certification and decision risk reduction has not been well understood. This work describes our experience investigating the value of certification and our efforts to improve the mandated software readiness certification record (SRCR) process. A well known critical system at JPL is used as a case study to exemplify this effort.;1
Algorithmic solution for effective selection of elicitation techniques;"The process of software development involves many significant knowledge-intensive areas. To execute a software project successfully, Requirement elicitation (RE) plays a critical role and need to be focused. RE is a process to establish information about the end user's requirements clearly. Normally, the requirement engineer and organization policies affect the selection of the usual requirement elicitation technique. Furthermore, there is no concrete rule or direction available on an effective selection of elicitation techniques for a new or existing software project. In this paper, we proposed an algorithm for effective selection of elicitation technique, as the first step; we developed a matrix of different parameters and populated the matrix with the list of consolidated parameters along with possible values, suggested by various practitioners and researchers, for different elicitation techniques. Parameters are broadly categorized into three categories Project, Stakeholders and Requirement Engineer. As a second step, we designed an algorithm based on the mapping matrix which takes situational values as input and suggests a suitable and effective elicitation technique. For validation, we executed an algorithm for various examples and found better results. We can add new parameters and categories to the matrix for selection of elicitation technique without any inconvenience.";1
A study on the perceived value of software quality assurance at JPL;As software quality assurance (SQA) moves from being a compliance-driven activity to one driven by value, it is important that all stakeholders involved in a software development project have a clear understanding of how SQA contributes to their efforts. However, a recent study at JPL indicates that different groups of stakeholders have significantly different perceptions about the value of SQA activities and their expectations of what constitutes SQA success. This lack of a common understanding of value has fragmented SQA efforts. Activities are driven by the desires of whichever group of stakeholders happens to hold the greatest influence at the moment leading the project as a whole not realizing the full or needed value of SQA. We examine this and other results of the recent study and how these impact both the real and the perceived value of SQA.;1
Criteria for selecting software requirements to create product value: An industrial empirical study;Product value is based on which requirements are included in a specific release of a software product. This chapter provides an overview of the value concept and presents an empirical study conducted as an industrial survey. The objective of the survey was to quantify the importance of different decision making criteria when deciding whether to include a requirement in a project or release. The results reported from the survey are based on responses from two companies. It was discovered that there were similarities in responses at a company level, although major differences existed between individual respondents to the survey. The most important criteria were found to be those related to specific customers or markets and criteria, such as development cost-benefit, delivery date, and resources. The least important criteria were those related to development and maintenance. The results also indicate that a better balance between the most important and least important criteria ought to be achieved in the future.;1
Value based management and agile methods;Agile methods strive for clarity at the level of operations. Value Based Management strives for clarity at the level of the business. This paper discusses how they complement each other. Particular attention is focused on metrics for measuring value creation and efficient resource usage.;1
Understanding stakeholder values as a means of dealing with stakeholder conflicts;"This paper reports on a quantitative study, which examines the link between software characteristics, sought after consequences and personal values in software evaluation, whilst investigating the stakeholders' understanding of software quality. The study involved a survey of 403 subjects, which were then analyzed quantitatively with bi-variate analysis, and multivariate analysis of variance. The research argues that trade-offs in software development projects are often experienced in software development because of conflicts. These conflicts involve schedules, priorities and are very much caused by the different stakeholder views of quality, different desired consequences sought by the different stakeholders and more importantly influenced by the desired values of the different stakeholders. The research finds that different classes of stakeholders have different views of software quality. The research also finds that certain values sought by the stakeholder influences their sought after consequences required in the developed software product. However, it is not just any values that affect the stakeholder, but rather, it is the values affected by the evaluated software, which influences the selection of characteristics and sought after consequences. Values, which are important, but are not affected by software use, do not influence the stakeholder. As such, these results help us gain a better understanding of what types of values influence the choice of characteristics in software evaluation, and the desired consequences in a software product, and why conflicts exist during software development life-cycle. The results provide a number of important insights and suggest several conclusions. The study showed (1) that stakeholders differ in their priorities in the sought after consequences of the software being developed; (2) that the desired values, which are perceived to be affected by the software differ between stakeholders and influence the choice of characteristic and consequence; (3) that the consequence, value relationship as described in the Software Evaluation Framework can be valuable to understand the conflicts and trade-offs fond in software development.";1
Towards a component and service marketplace with Brechó Library;Component and service libraries are important to meet cost-effectiveness and productivity goals in Software Reuse with Component-and Service-Based Software Engineering. These libraries need to provide diversified mechanisms to help the service and component management processes, exploring aspects such as organization, evolution, trading, and underlying markets. This is important to a broad definition of value for components and services. This paper presents Brechó, a Web-based library that provides publication, documentation, storage, search, and retrieval mechanisms for components and services. Apart from these main functionalities, Brechó has features and advanced mechanisms that distinguishes it from other component libraries, such as market analysis for pricing activities and automatic generation for services.;1
Value-based requirements traceability: Lessons learned;Software development standards demand requirements traceability without being explicit about the appropriate level of quality of trace links. Unfortunately, long-term trace utilizations are typically unknown at the time of trace acquisition which represents a dilemma for many companies. This paper suggests ways to balance the cost and benefits of requirements traceability. We present data from 3 case studies. Lessons learned suggest a traceability strategy that (1) provides trace links more quickly, (2) refines trace links according to user-definable value considerations, and (3) supports the later refinement of trace links in case the initial value considerations change.;1
Value-based migration of legacy data structures;The maintenance and evolution of legacy applications and legacy data structures poses a significant challenge for many organizations that rely on large-scale information systems, e.g. in the financial services domain: Not only is the budget for modernizations that add more technical stability and flexibility than business functionality often slim, but it is also difficult to understand and design the best migration strategies for a large and organically grown system landscape. We report on the experiences from a migration project at a large bank that pursued a value-based approach, in which migration efforts were first focused on a small set of business processes that were identified as most crucial for the enterprise. The migration strategies developed and validated in this pilot phase could later be successfully applied to the larger system landscape.;1
A value-based approach to predicting system properties from design;Traditional engineering requires evaluating designs before implementing them. Evaluating a design predicts the properties of a reasonable implementation and the value of these properties to a stakeholder. Software engineering has some (though not enough) relevant evaluation techniques but lacks frameworks to compare, develop, and apply those techniques in a manner that respects h value varies by stakeholder. We present an adaptation of economists' value models that, given a design and a development method, predicts value to a client. We give examples supporting our approach. Even in its preliminary state, our approach helps to explain and characterize design evaluation techniques and shows sufficient promise to justify further development.;1
Diversifying software architecture for sustainability: A value-based perspective;We use real options theory to evaluate the options of diversity in design by looking at the trade-offs between the cost and long-term value of different architectural strategies under uncertainty, given a set of scenarios of interest. As part of our approach, we extend one of the widely used architecture trade-offs analysis methods (Cost-Benefit Analysis Method) to incorporate diversification. We also use a case study to demonstrate how decision makers and architects can reason about sustainability using a diversified cost-value approach.;1
Time is not money: The case for multi-dimensional accounting in value-based software engineering;"""Time is money,"" or so goes the old saying. Perhaps, influenced by this aphorism, some strategies for incorporating costs in the analysis of software design express all costs in currency units for reasons of simplicity and tractability. Indeed, in theoretical economics all costs can, in principle, be expressed in dollars. Software engineering problems, however, often present situations in which converting all costs to a common currency is problematical. In this paper we pinpoint some of these situations and the underlying causes of the problems, and we argue that it is often better to treat costs as a multidimensional value, with dimensions corresponding to distinct types of resources. We go on to highlight the differences among cost dimensions that need to be considered when developing cost-benefit analyses, and we suggest mechanisms for mediating among heterogeneous cost dimensions";1
Minimizing the stakeholder dissatisfaction risk in requirement selection for next release planning;Context: The requirements to be delivered in the next software release are selected according to the stakeholders’ perceived value, expected implementation cost, budget availability, and precedence and technical dependency constraints. Existing approaches to the requirement selection problem do not take into account the risk of stakeholders’ dissatisfaction possibly resulting from divergence in the stakeholders’ estimates of the requirement value. Objective: We present a novel risk-aware, multi-objective approach to the next release problem that aims at reducing the stakeholder dissatisfaction risk in a given cost/value region of interest provided by stakeholders. Method: We have devised an exact algorithm to address the risk-aware formulation of the next release problem and implemented the algorithm using two well-known SMT solvers, Yices and Z3. To allow the application of the proposed formulation to large size problems, we have also implemented an approximate algorithm based on the NSGA-II metaheuristic. Results: Results show that (1) the stakeholder dissatisfaction risk can be minimised with minimum impact on cost/value, and (2) our approach is scalable when NSGA-II is used. SMT solvers scale up to problems that are not overly large in terms of the number of requirements and/or are not too sparse in terms of dependencies, but the metaheuristic can quickly find good solutions even for large size problems. Conclusion: We recommend the users of our approach to apply an SMT solver and to resort to a metaheuristic algorithm only if the SMT solver does not terminate within reasonable time, due to the actual combination of number of requirements and dependency density.;1
Mixed integer programming helping requirements allocation for the NRP in SCRUM teams;This paper proposes an approach based on mathematical modeling to provide decision making support for the Next Release Problem (NRP) arising in software development and maintenance companies that use SCRUM to manage teams and new releases of its software products. This approach aims to support the decisions from Product Owners and Teams about which requirements should be implemented for the next software release. Therefore it is proposed to use mixed integer programming in three different objective functions: (i) maximization of the customer satisfaction (considering their business value), (ii) minimization of software development time and (iii) minimization of the costs to produce the requirements. We consider constraints such as team availability, dependencies among requirements, the team's performance among others. The modeling was performed with the help of the AIMMS tool and some case studies were performed in three software development and maintenance companies using real data. The results show that it was possible to adapt the NRP for this kind of companies, achieving a better customer's satisfaction and business results using our approach.;1
Multi-aspects intelligent requirements prioritization technique for value based software systems;Requirements engineering (RE) is an important phase of software engineering. During this phase, an important set of activities are carried out to manage requirements elicitation, verification, prioritization and validation. Dimension and dynamics of software development are changing with the passage of time. Economic growth in different sectors is increasing the demand for software development. This enhancement has introduced the concept of Value Base Software (VBS) development. Requirements prioritization is playing a vital role in ordering requirements to support the release planning of the software. A prioritization process is considered as highly complex process and depends on the nature and size of requirements. VBS systems are entirely different from typical software development, and prioritization process for VBS is also very challenging. A need arises from the provision of prioritization techniques to support the technical and business aspects-based prioritization. Existing techniques are not qualified to meet the expectation of the industry for VBS development. Therefore, this research contribution is an effort made, based on an intelligent decision support system for requirements prioritization in the domain of VBS system. Aspects based requirements prioritization is applied to many requirements and results are produced in two clusters. Results are claimed as a prioritized list of requirements for traditional as well as value-based system.;1
How does the value provided by a software product and users’ psychological needs interact to impact user loyalty;A multi-disciplinary review of literature shows that products can provide three types of value to the users – utilitarian, hedonic and social. Further, these values impact user outcomes such as their loyalty to the product. However, in this study we suggest that the relative impacts of these values on user loyalty to the product will vary with user needs. To test this contention we conducted a study with actual users of three software products – Producteev, Kerbal and Facebook. The results of the study confirm that user needs selectively moderate the impact of the various values provided by the software product to the users on their loyalty for the software product. These findings have implications for software product managers. They highlight the relevance of developing software products aligned with the profile of the targeted users to maximize their loyalty to the software product and the importance of the hitherto unexplored SV in the context of software products.;1
Value-based requirements engineering: Method and experience;"‘Socio-political’ issues, such as emotions, values and people’s feelings, are often cited as problems in the RE process. A method is described for analysing such issues. The method consists of a taxonomy of stakeholders’ values, motivations and emotions (VME), with process guidance for eliciting and analysing these issues for the RE process and design implications. Values are personal attitudes or long-term beliefs which may influence stakeholder functional and non-functional requirements. Motivations are psychological constructs related to personality traits which may be viewed as stakeholders’ long-term goals in RE. Emotions are cues to stakeholders’ reactions arising from value/motivation conflicts. The method is supported by a website which illustrates the taxonomy with explanations and scenarios describing problems arising from value conflicts, and from poor understanding of stakeholder values. Two method validation studies were undertaken: first, an evaluation of the website and method by novices and RE experts; and second, case study applications of RE value analysis in real-world industrial practice. The method was used by all practitioners, although in different ways, some used it to create an agenda of issues for analysis while others employed the VMEs to interpret stakeholders’ views and manage stakeholder negotiations. The validation studies provide evidence for the acceptability of the method for industrial practitioners, illustrating how value-related problems are identified and analysed effectively by the method. The utility of analysing VMEs is compared to other ‘socio-political issues’-oriented methods in RE and methods which focus on monetized values in product requirements.";1
Using fuzzy linguistic 2-tuples to collectively prioritize software requirements based on stakeholders evaluations;Efficient consideration of all stakeholders' needs and perspectives in a software project is a key challenge, especially when prioritizing the software requirements to be developed in the next software release. This paper presents a new requirements prioritization approach that aims to collectively prioritize software requirements based on their ratings expressed from different stakeholders. The proposed approach follows the steps of a value-oriented process in which multiple and possibly distributed stakeholders assess the values of candidate requirements with respect to various prioritization criteria. The approach applies a group-based, fuzzy multi-criteria technique requiring from involved stakeholders to evaluate requirements using linguistic terms. Stakeholders' linguistic evaluations are aggregated to collectively derive more objective and reasonable assessments on the final requirements' priorities1.;1
A model for assessing and re-assessing the value of software reuse;Background: Software reuse is often seen as a cost avoidance rather than a gained value. This results in a rather one-sided debate where issues such a resource control, release schedule, quality, or reuse in more than one release are neglected. Aims: We propose a reuse value assessment framework, intended to provide a more nuanced view of the value and costs associated with different reuse candidates. Method: This framework is constructed based on findings from an interview study at a large software development company. Results: The framework considers the functionality, compliance to standards, provided quality, and provided support of a reuse candidate, thus enabling an informed comparison between different reuse candidates. Furthermore, the framework provides means for tracking the value of the reused asset throughout subsequent releases. Conclusions: The reuse value assessment framework is a tool to assist in the selection between different reuse candidates. The framework also provides a means to assess the current value of a reusable asset in a product, which can be used to indicate where maintenance efforts would increase the utilized potential of the reusable asset.;1
AHP_GORE_PSR: Applying analytic hierarchy process in goal oriented requirements elicitation method for the prioritization of software requirements;Goal Oriented Requirements Engineering (GORE) is concerned with the identification of goals of the software according to the need of the stakeholders. In GORE, goals are the need of the stakeholders. These goals are refined and decomposed into sub-goals until the responsibility of the last goals are assigned to some agent or some software system. In literature different methods have been developed based on GORE concepts for the identification of software goals or software requirements like fuzzy attributed goal oriented software requirements analysis (FAGOSRA) method, knowledge acquisition for automated specifications (KAOS), i* framework, attributed goal oriented requirements analysis (AGORA) method, etc. In AGORA, decision makers use subjective values during the selection and the prioritization of software requirements. AGORA method can be extended by computing the objective values. These objective values can be obtained by using analytic hierarchy process (AHP). In AGORA, there is no support to check whether the values provided by the decision makers are consistent or not. Therefore, in order to address this issue we proposed a method for the prioritization of software requirements by applying the AHP in goal oriented requirements elicitation method. Finally, we consider an example to explain the proposed method.;1
Value-based decisionmaking using a Web-based tool: A multiple case study;"[Context]: To remain competitive, innovative and to grow, companies should use a value-based decision-making where decisions are the best for that company's overall value creation. However, without tool support, the use of explicit value propositions and aggregation of different key stakeholders' decisions during decision-making may be a challenge for many companies. [Goal]: The goal of this paper is to investigate the extent to which a Web-based tool for value-based decision-making can successfully support stakeholders' decision-making process. [Method]: We conducted three case studies across four software projects, during six weeks, in the contexts of feature selection, test cases execution prioritization and user interfaces design selection. Prior to using the tool, stakeholders' value propositions were elicited via focus-group meetings; later, during a post-mortem phase, data was gathered via observation, semi-structured interviews and structured questionnaires. [Results]: Participants reported an improvement of their decision-making process and quality of decisions; further, they also felt confident about using the tool, and that it can be useful to their work. [Conclusions]: Results suggested that the use of tool support by the stakeholders in the investigated company for value-based decision-making improved their decision-making process and the quality of decisions.";1
Using Bayesian Network to estimate the value of decisions within the context of Value-Based Software Engineering;The software industry's current decision-making relating to product/project management and development is largely done in a value neutral setting in which cost is the primary driver for every decision taken. However numerous studies have shown that the primary critical success factor that differentiates successful products/projects from failed ones lie in the value domain. Therefore to remain competitive innovative and to grow companies must change from cost-based to value-based decisionmaking where the decisions taken are the best for that company's overall value creation. This paper details a case study where value-based decisions made by key stakeholders to select features for the next sprint of an Internet of Things (IoT) project stored in a decisions database were used to build and validate a value estimation model. This model's goal was to estimate the overall value contribution that each feature being discussed during a decision-making meeting would bring to the company if selected for implementation. The estimation technique employed was Bayesian Network and validation results were quite positive.;
Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018;In software engineering the role of human aspects is an important one especially as developers indicate that they experience a wide range of emotions while developing software. Within software engineering researchers have sought to understand the role emotions and sentiment play in the  development of software by studying issues pull-requests and commit messages.  To detect sentiment automated tools are used and in this doctoral thesis we plan to study the use of these sentiment analysis tools their applications best practices for their usage and the effect of non-natural language on their performance. In addition to studying the application of sentiment analysis tools we also aim to study self-admitted technical debt and bots in software engineering to understand why developers express sentiment and what they signal when they express sentiment. Through studying both the application of sentiment analysis tools and the role of sentiment in software engineering we hope to provide practical recommendations for both researchers and developers.;
Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Well-trained machine-learning models which leverage large amounts of open-source software data have now become an interesting approach to automating many software engineering tasks. Several SE tasks have all been subject to this approach with performance gradually improving over the past several years with better models and training methods. More and more diverse clean labeled data is better for training but constructing good-quality datasets is time-consuming and challenging. Ways of augmenting the volume and diversity of clean labeled data generally have wide applicability. For some languages (e.g. Ruby) labeled data is less abundant in others (e.g. JavaScript) the available data maybe more focused on some application domains and thus less diverse. As a way around such data bottlenecks we present evidence suggesting that human-written code in different languages (which performs the same function) is rather similar and particularly preserving of identifier naming patterns we further present evidence suggesting that identifiers are a very important element of training data for software engineering tasks. We leverage this rather fortuitous phenomenon to find evidence that available multilingual training data (across different languages) can be used to amplify performance. We study this for 3 different tasks: code summarization code retrieval and function naming. We note that this data-augmenting approach is broadly compatible with different tasks languages and machine-learning models.;
Proceedings of the 44th International Conference on Software Engineering;Six months ago an important call was made for researchers globally to provide insights into the way Software Engineering is done in their region. Heeding this call we hereby outline the position Software Engineering in Australasia (New Zealand and Australia). This article first considers the software development methods practices and tools that are popular in the Australasian software engineering community. We then briefly review the particular strengths of software engineering researchers in Australasia. Finally we make an open call for collaborators by reflecting on our current position and identifying future opportunities.;
Social science theories in software engineering research;As software engineering research becomes more concerned with the psychological sociological and managerial aspects of software development relevant theories from reference disciplines are increasingly important for understanding the field's core phenomena of interest. However the degree to which software engineering research draws on relevant social sciences remains unclear. This study therefore investigates the use of social science theories in five influential software engineering journals over 13 years. It analyzes not only the extent of theory use but also what how and where these theories are used. While 87 different theories are used less than two percent of papers use a social science theory most theories are used in only one paper most social sciences are ignored and the theories are rarely tested for applicability to software engineering contexts. Ignoring relevant social science theories may (1) undermine the community's ability to generate elaborate and maintain a cumulative body of knowledge and (2) lead to oversimplified models of software engineering phenomena. More attention to theory is needed for software engineering to mature as a scientific discipline.;
Proceedings of the 44th International Conference on Software Engineering;Due to globalization many software projects have become large-scale and distributed tasks that require software engineers to learn and apply techniques for distributed requirements analysis modeling development and deployment. Globally-distributed projects require special skills in communication across different locations and time zones in all stages of the project. There has been advancement in teaching these concepts at universities but adapting global software engineering in a curriculum is still in infancy.The main reasons are the effort and coordination required by teachers to set up the project manage distributed development and enable distributed delivery. It becomes even more difficult when teaching distributed software engineering involving Internet of Things (IoT) applications. The situation has changed with recent advances in continuous deployment and cloud platform services that make globally-distributed projects more feasible teachable and learnable even for short-term projects. However no experience report in education research describes a truly distributed global setup in continuous software engineering for IoT applications.This paper describes a ten-day project involving three universities in different countries with 21 students located across the world to substantiate this claim. It provides teachers with recommendations for conducting a global software engineering course in a global setting. Recommendations include access for all students to (remote) hardware stable network infrastructure in all locations the use of a central development platform for continuous integration and deployment and the application of distributed pair deployment.;
Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Software Engineering Education and Training;This paper describes our first offering of a project-based software engineering course for undergraduate seniors. The course was given to 72 undergraduates mostly seniors majoring in computer engineering. Our project taught the full engineering cycle with a narrative based on supporting the re-use of software. In two parts spanning 13 weeks successful teams deployed a web service. We identify lessons learned and opportunities for improvement.;
Proceedings of the First International Workshop on Designing and Running Project-Based Courses in Software Engineering Education;Decision making in automated GI-based software engineering tasks can significantly affect the performance of the system. However modern SE usually presents high uncertainty in such decision making process due to the existence of multiple solutions that reply on heuristics. We propose to apply the theory of Fuzzy System to obtain a final decision with lower uncertainty and higher accuracy. We also demonstrate a motivating example and discuss the challenges and opportunities for applying fuzzy system to SE tasks.;
Proceedings of the Genetic and Evolutionary Computation Conference Companion;Students can often graduate with a degree in computer science without working with legacy code bases yet when they join the workforce they will almost certainly work on an existing project with thousands if not millions of lines of existing code. In order to give students a realistic experience without overwhelming them we added scaffolding to an existing open source project and used it in our third year software engineering course. We asked students to complete a series of 5 tasks from bug fixing to feature addition with this scaffolded project. Our scaffolding consisted of enhanced documentation demonstration videos compilation videos enhanced task descriptions and hints for task completion. After running this course project we collected feedback via a survey (n=87) and a small focus group (n=7). We found that students appreciated the realistic experience but that they recommend further scaffolding especially within source code to better balance between difficulty and learning.;
Proceedings of the First International Workshop on Designing and Running Project-Based Courses in Software Engineering Education;[Background:] Experimentation in Software Engineering plays a central role on sharing and verifying scientific findings. As experiments have increased significantly in Software Engineering area we observe that most of them fail to provide a way to be repeated replicated or reproduced thus jeopardizing or delaying the evolution of the Software Engineering area. [Aims:] In this vision paper we present and discuss techniques and infrastructure to continuously improve experiments towards repeatability replicability and reproducibility. [Method:] We define these techniques and infrastructure based on experiences of our research groups and existing literature. Furthermore we follow Open Science principles. [Results:] We provide incipient results and foresee a central infrastructure composed of two repositories and two recommendation systems to support techniques for: reporting experiments developing ontologies for experiments and open educational resources mining and recommending experiments specifying data management plans identifying families of experiments and teaching and learning experimentation. [Conclusions:] Our techniques and infrastructure will prospectively motivate and benefit Software Engineering evolution by improving the conduction and further reproducibility of experiments.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;In this paper we introduce the notion of Modal Software Engineering: automatically turning sequential deterministic programs into semantically equivalent programs efficiently operating on inputs coming from multiple overlapping worlds. We are drawing an analogy between modal logics and software application domains where multiple sets of inputs (multiple worlds) need to be processed efficiently. Typically those sets highly overlap so processing them independently would involve a lot of redundancy resulting in lower performance and in many cases intractability. Three application domains are presented: reasoning about feature-based variability of Software Product Lines (SPLs) probabilistic programming and approximate programming.;
Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results;Video games have characteristics that differentiate their development and maintenance from classic software development and maintenance. These differences have led to the coining of the term Game Software Engineering to name the emerging subfield that intersects Software Engineering and video games. One of these differences is that video game developers perceive more difficulties than other non-game developers when it comes to locating bugs. Our work proposes a novel way to locate bugs in video games by means of evolving simulations. As the baseline we have chosen BLiMEA which targets classic software engineering and uses bug reports and the defect localization principle to locate bugs. We also include Random Search as a sanity check in the evaluation. We evaluate the approaches in a commercial video game (Kromaia). The results for F-measure range from 46.80%. to 70.28% for five types of bugs. Our approach improved the results of the baseline by 20.29% in F-measure. To the best of our knowledge this is the first approach that is designed specifically for bug localization in video games. A focus group with professional video game developers has confirmed the acceptance of our approach. Our approach opens a new research direction for bug localization for both game software engineering and possibly classic software engineering.;
Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems;The generalization of knowledge is a necessary part of every scientific field. Meta-analysis is already advocated as a tool for generalization in different areas such as medicine psychology business and this process is already standardized for them. Software engineering started using meta-analysis as a tool for aggregating results from families of experiments but not so long for generalization of results coming from different studies and for this purpose the meta-analytical approach is not yet clarified. In this paper we attempt to systematize the application of meta-analysis as a secondary study to the software engineering field suggesting our preliminary protocol. To see the reliability of the proposed protocol we conducted several studies using it. Following even uniform protocol with these studies we identified the issues preventing the wide usage of meta-analysis in software engineering and proposed our solutions for them.;
Proceedings of the 2021 European Symposium on Software Engineering;Grounded Theory while becoming increasingly popular in software engineering is also one of the most misunderstood misused and poorly presented and evaluated method in software engineering. When applied well GT results in dense and valuable explanations of how and why phenomena occur in practice. GT can be applied as a full research method leading to mature theories and also in limited capacity for data analysis within other methods using its robust open coding and constant comparison procedures. This technical briefing will go through the social origins of GT present examples of grounded theories developed in SE discuss the key challenges SE researchers face and provide a gentle introduction to socio-technical grounded theory a variant of GT for software engineering research.;
Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings;This paper describes an investigation into value-based software engineering and proposes a comprehensive value taxonomy with interpretation of design feature implications. The value taxonomy is used to assess the design of Covid-19 symptom tracker applications contrasting the UK's NHS phase 1 and 2 designs which adopted centralized then decentralized architectures. The value/feature analysis is also applied to the King's/Zoe Covid app which does not detect proximity instead relying on user self-reporting. Value analysis illuminated design choices but was insufficient to account for download acceptance of the apps. We argue that motivational cost-benefit analysis needs to complement a values-based approach.;
Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Society;Background: Software development results in the production of various types of artifacts: source code version control system metadata bug reports mailing list conversations test data etc. Empirical software engineering (ESE) has thrived mining those artifacts to uncover the inner workings of software development and improve its practices. But which artifacts are studied in the field is a moving target which we study empirically in this paper. Aims: We quantitatively characterize the most frequently mined and co-mined software artifacts in ESE research and the research purposes they support. Method: We conduct a meta-analysis of artifact mining studies published in 11 top conferences in ESE for a total of 9621 papers. We use natural language processing (NLP) techniques to characterize the types of software artifacts that are most often mined and their evolution over a 16-year period (2004â€“2020). We analyze the combinations of artifact types that are most often mined together as well as the relationship between study purposes and mined artifacts. Results: We find that: (1) mining happens in the vast majority of analyzed papers (2) source code and test data are the most mined artifacts (3) there is an increasing interest in mining novel artifacts together with source code (4) researchers are most interested in the evaluation of software systems and use all possible empirical signals to support that goal. Conclusions: Our study presents a meta analysis of the usage of software artifacts in the field over a period of 16 years using NLP techniques.;
Proceedings of the 16th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement;Although AI is transforming the world there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations principles and frameworks for responsible AI have been issued recently. However they are high level and difficult to put into practice. On the other hand most AI researchers focus on algorithmic solutions while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems and (iii) building responsible-AI-by-design into AI systems through system-level architectural style patterns and techniques.;
Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI;Startups play a key role in software-based innovation. They make an important contribution to an economyâ€™s ability to compete and innovate and their importance will continue to grow due to increasing digitalization. However the success of a startup depends primarily on market needs and the ability to develop a solution that is attractive enough for customers to choose. A sophisticated technical solution is usually not critical especially in the early stages of a startup. It is not necessary to be an experienced software engineer to start a software startup. However this can become problematic as the solution matures and software complexity increases. Based on a proposed solution for systematic software development for early-stage startups in this paper we present the key findings of a survey study to identify the methodological and technical priorities of software startups. Among other things we found that requirements engineering and architecture pose challenges for startups. In addition we found evidence that startupsâ€™ software development approaches do not tend to change over time. An early investment in a more scalable development approach could help avoid long-term software problems. To support such an investment we propose an extended model for Entrepreneurial Software Engineering that provides a foundation for future research.;
Proceedings of the International Conference on Software and System Processes and International Conference on Global Software Engineering;Search-Based Software Engineering (SBSE) approaches adopt search-based techniques to solve Software Engineering (SE) optimization problems. Among these techniques evolutionary algorithms are the most popular and successfully used such as multi-objective evolutionary algorithms. However some challenges still need to be addressed. Firstly SE problems are complex and commonly impacted by many conflicting factors. In this context the use of many-objective algorithms is necessary. Secondly the users very often do not recognise the found solutions as feasible because these solutions are usually not generated considering the usersâ€™ needs and preferences. Thus to deal properly with this situation preference-based algorithms should be applied. Moreover there are some practical issues regarding the choice of operators evaluation of algorithms and visualization of solutions. Existing frameworks do not provide support to address these challenges. To overcome these limitations we present Nautilus an open-source Java web-platform tool that works with plugins to ease the addition of new problem instances implementation of search operators and different multi and many-objective optimization algorithms guided (or not) by human participation. This paper describes Nautilus-NRP an extension implemented to address the Next Release Problem (NRP). NRP refers to the selection of requirements to be implemented in the next release of a software and is used to illustrate Nautilusâ€™ main functionalities and how it can be extended to solve a SE problem. Link for the video: https://youtu.be/2dbwslTrvhg.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;Many practitioners might struggle with becoming productive in different software engineering (SE) roles due to misalignment of the skills learnt during the university time with what is expected in the industry. Companies spend significant resources to train the personnel whose academic backgrounds are not only based on â€œcomputing disciplinesâ€. Hiring properly trained practitioners allows employers to spend less time while incorporating them more efficiently into the workforce for employees knowing the most important skillset is helpful to increase their chance of employability. On the other hand for academia understanding the necessary skillset is critical to make curriculum updates. To achieve these objectives we conducted a survey which was responded to by 628 software practitioners who completed their undergraduate degree in Turkey working in 13 countries. This paper sheds light on the most important (hard and soft) skills in the industry by presenting various cross-factor analyses as well as their coverage in the academic curriculum (mostly in Turkish universities). The results showed that the most important skills are related to various factors such as profiles of the practitioners (e.g. SE role(s) work experience) and the characteristics of the product developed by the practitioner. The findings revealed that both academia and industry should invest in skills improvement: academia can make necessary educational updates according to industrial needs whereas industry can provide practical experiences to students. By creating the awareness of the expected skillset both practitioners and academics will benefit from the results which help close the gaps that can and should be achieved through more Industry Academia Collaborations (IACs).;
A Classification for Managing Software Engineering Knowledge;This taxonomy paper presents a novel way of knowledge engineering in the software engineering research community. Till now research papers are organized digitally as documents mostly in PDF files. Not much effort is spent on effective knowledge classification retrieval storage and representation. In contrast to the current paper-based approach for knowledge documentation we present a statement-based approach where each statement is linked to arguments and data of its evidence as well as to related statements. We argue that in this way knowledge will be easier to retrieve compare and evaluate in contrast to current paper-based knowledge engineering in scientific search engines and digital libraries. Therefore we present as a first step a novel multi-dimensional classification for statements in software engineering research. Statements are classified according to their research object their kind (e.g. relevance) and their underlying evidence. This classification is validated and extended with a first systematic literature review. Additionally we provide an example for illustration purpose.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;There is a long-standing challenge to narrow the gap between software engineering research and industrial practice. This gap is reinforced by a number of challenges including differing timelines metrics expectations and perceptions of these two communities. We believe that these and other related challenges need be analyzed and discussed to discover synergies and strengthen collaborations between researchers and practitioners in software engineering. In this report we present insights from the 7th International Workshop on Software Engineering Research and Industrial Practice held virtually at the International Conference on Software Engineering 2020.;
Exploring Security Procedures in Secure Software Engineering: A Systematic Mapping Study;Various new technologies have developed as software security solutions have become more critical. One of the essential parts of software quality is the product's security. Though providing examples covering all phases of secure software development is necessary very few of these situations have been documented. More than a few approaches have been proposed and implemented to handle software security but only a few of them provide valid evidence for developing secure software applications. This paper presents the results of a Systematic Mapping Study (SMS) which was carried out to determine the existence of software security metrics tools standards and security-related research topics mainly discussed and addressed. A total of 116 studies were chosen for inclusion in this review. Selected studies led us to discover 55 Secure Software Engineering (SSE) metrics 68 SSE tools 33 SSE standards and 12 SSE research topics that have been discussed and addressed. This effort will aid software development firms in better understanding existing security measures employed in creating secure software. It can also serve as a foundation for researchers to build and create new software security solutions and identify new research directions.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;In order to solve today's complex problems in the world of software development technical knowledge is no longer enough. Previous studies investigating and identifying nontechnical skills of software engineers show that creative skills also play an important role in tackling difficult problems. However creativity is typically a very vague concept to which everyone gives their own interpretation. Also there is little research that focuses specifically on creativity in the field of software engineering. To better understand the role of creativity in this field we conducted four focus groups inviting 33 experts from four nationally and internationally renowned companies in total. This resulted in 399 minutes of transcripts further coded into 39 sub-themes grouped into seven categories: technical knowledge communication constraints critical thinking curiosity creative state of mind and creative techniques. This study identifies the added value of creativity which creative techniques are used how creativity can be recognized the reasons for being creative and what environment is needed to facilitate creative work. Our ultimate goal is to use these findings to instill and further encourage the creative urge among undergraduate students in higher education.;
Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Society;Video game development is one of the fastest-growing industries in the world. The use of software product lines (SPLs) has proven to be effective in developing different types of software at a lower cost in less time and with higher quality. There are recent research efforts that propose to apply SPLs in the domain of video games. Video games present characteristics that differentiate their development from the development of classic software for example game developers perceive more difficulties than other non-game developers when reusing code. In this paper we evaluate if the adoption of an SPL in game software engineering (GSE) can generate the same benefits as in classic software engineering (CSE) considering the case study of Kromaia. As in other disciplines dealing with human behaviour empirical research allows for building a reliable knowledge base in software engineering. We present an experiment comparing two development approaches Clone and Own (CaO) and an SPL in terms of correctness efficiency and satisfaction when subjects develop elements of a commercial video game. The results indicate that the elements developed using the SPL are more correct than those developed with CaO but do not indicate significant improvement in efficiency or satisfaction. Our findings suggest that SPLs in GSE may play a different role than the one they have played for decades in CSE. Specifically SPLs can be relevant to generating new video game content or to balancing video game difficulty.;
Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume A;Augmented reality changes the way we perceive reality and how we interact with computers. However we argue that to create augmented reality solutions we need to rethink the way we develop software. In this paper we review the state of the art in software engineering for augmented reality applications derive open questions and define a research agenda. For this purpose we consider different engineering phases and evaluate conventional techniques regarding their applicability for AR development. In requirements engineering we found the integration of AR experts and the associated collaboration between actors to be of key aspect in the development process. Additionally requirements about the physical world must be considered which in turn has a huge impact on UI design. The relevance of the physical environment is not yet sufficiently addressed in applicable techniques which also applies to current implementation frameworks and tools complicating the AR development process. When evaluating AR software iterations we found interaction testing and test automation to have great potential although they have not yet been sufficiently researched. Our paper contributes to AR research by revealing current core challenges within the AR development process and formulating explicit research questions that should be considered by future research.;
Exploring Task Equivalence for Software Engineering Practice Adaptation and Replacement;Practice adaptation in the domain of software engineering (SE) is ubiquitous and well-studied. The main rationale for tailoring lies in the complexity of the environments within which SE projects are implemented. This complexity means that the practices that make up software methodologies are often not fit-for-purpose as-is and must be replaced or adapted to suit local context. However there is a risk that a practice may be changed in an inappropriate way with unintended side-effects. For example altering a practice to reduce documentation may result in a failure to meet standards expectations or the expectations of downstream practices. In this paper we describe a study that explored the notion of practice equivalence. Our goal was to identify aspects of a practice that are â€˜similarâ€™ and might support adaptation. We found that adapted practices must be within the same software function perform the same action be compatible in terms of creativity reasoning and perspectives and have a compatible interface type. Our contributions are the consideration of an as-yet unexplored area of software process that we hope will generate discussion and future research studies and the creation of a strawman framework that will be a starting point for further exploration and evaluation.;
Proceedings of the 2022 ACM SIGPLAN International Symposium on New Ideas New Paradigms and Reflections on Programming and Software;Context: Evidence-based software engineering (EBSE) can be an effective resource to bridge the gap between academia and industry by balancing research of practical relevance and academic rigor. To achieve this it seems necessary to investigate EBSE training and its benefits for the practice. Objective: We sought both to develop an EBSE training course for university students and to investigate what effects it has on the attitudes and behaviors of the trainees. Method: We conducted a longitudinal case study to study our EBSE course and its effects. For this we collect data at the end of each EBSE course (2017 2018 and 2019) and in two follow-up surveys (one after 7 months of finishing the last course and a second after 21 months). Results: Our EBSE courses seem to have taught students adequately and consistently. Half of the respondents to the surveys report making use of the new skills from the course. The most-reported effects in both surveys indicated that EBSE concepts increase awareness of the value of research and evidence and EBSE methods improve information gathering skills. Conclusions: As suggested by research in other areas training appears to play a key role in the adoption of evidence-based practice. Our results indicate that our training method provides an introduction to EBSE suitable for undergraduates. However we believe it is necessary to continue investigating EBSE training and its impact on software engineering practice.;
Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Software Engineering Education and Training;The Communications website http://cacm.acm.org features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications we'll publish selected posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMhttp://cacm.acm.org/blogs/blog-cacmAndrei Sukhov considers the potential for reducing international tensions through competitive events while Vivek S. Buzruk looks at the evolution of teaching Internet software engineering.;
Towards a Framework for Continuous Software Engineering;Characteristics and demands of the modern and digital society have transformed the software development scenario and presented new challenges to software developers and engineers such as the need for faster deliveries frequent changes in requirements lower tolerance to failures and the need to adapt to contemporary business models. The adoption of agile practices has allowed organizations to shorten development cycles and increase customer collaboration. However this has not been enough. Continuous actions of planning construction operation deployment and evaluation are necessary to produce products that meet customers' needs and behaviors to make well-informed decisions and identify business opportunities. Thus organizations should evolve from traditional to continuous and data-driven development in a continuous software engineering approach. Continuous Software Engineering (CSE) consists of a set of practices and tools that support a holistic view of software development with the purpose of making it faster iterative integrated continuous and aligned with business. It is a recent topic of Software Engineering thus there are many open questions. This paper introduces a CSE framework that represents CSE processes points out some research questions and discusses proposals to address them.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;In empirical software engineering benchmarks can be used for comparing different methods techniques and tools. However the recent ACM SIGSOFT Empirical Standards for Software Engineering Research do not include an explicit checklist for benchmarking. In this paper we discuss benchmarks for software performance and scalability evaluation as example research areas in software engineering relate benchmarks to some other empirical research methods and discuss the requirements on benchmarks that may constitute the basis for a checklist of a benchmarking standard for empirical software engineering research.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;Context. Software Engineering (SE) teaching is evolving continually with new methods being developed and evaluated. In this sense it is important to gain more knowledge of how such methods are actually implemented. Objective. The aim of this study is to systematically examine the literature on the use of the flipped classroom method in SE teaching. Method. To achieve the study objective we conducted a Systematic Mapping Study (SMS) starting with 769 studies. After the filtering process we extracted data from 26 primaries studies which meet the study selection criteria. Results. We found papers from 2008 to 2020 most of them published in SE conferences. In fifteen papers the content is delivered to the students before class nine of them using a specific system developed to this task. We found that the in-class activities follow three main strategies: (1) project-based learning (38.3%) (2) problem-based learning and self-direct learning (50.0%) and (3) team-based learning (7.7%). Reviewed studies reported challenges in implementing FC in ES course such as overworked and time-constrained professors and difficulty in sustaining student motivation. Also we found studies reporting improvements in student learning and motivation Conclusion. Based on our findings we conclude the use of an active method has proved to be useful for in-class practical activities especially related to the software development field. We also observed that adaptive educational content delivery has not been explored in software engineering studies with flipped classes.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;"The 3rd International Workshop on Software Engineering Education for the Next Generation was held remotely on May 24 2021. The workshop was an integral component of the Joint Track on Software Engineering Education and Training at the 43rd International Conference on Software Engineering. It specifically supported the general theme of Educating the Next Generation of Software Engineers"". Building on its predecessors the workshop used a highly interactive format structured around eight short paper presentations to generate discussion topics an activity to select the most interesting topics and structured breakout sessions to allow participants to discuss those topics in detail. Participants presented the results of the breakout sessions using mind maps.""";
When software engineering meets quantum computing;The Experimental Software Engineering (ESE) area investigates improvements that can be considered in carried out Software Engineering (SE) experiments. During the life cycle of an experiment different artifacts are developed such as processes scripts and data. These artifacts straightforwardly contribute to increase the capability of experiments reproducibility thus consequently to SE evolution. Organizing such artifacts into proper experimental/laboratory packages facilitates their comprehension for prospective findings and reproducibility. The lack of reproducibility for SE results and experiments has been explained in the current literature. However such artifacts treatment usually fails thus jeopardizing findings and external reproductions to confirm and audit SE experiments. In this context this paper describes a research work in progress for the development of an open science-based framework that aids in the management of SE experimental data. Specific data and metadata groups will be formed and integrated to formally describe SE experiments in terms of open science common practices as preservation provenance curation management and data/metadata storage. The framework will support the elaboration of experimental packages thus it intends to promote the reproducibility of SE controlled experiments and quasi-experiments.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;In this paper we share our experience in designing and running a project-based exam for a Software Engineering course at the undergraduate level. We underline the teaching objectives and content of the course which aim to prepare students for the industrial environment e.g. various design perspectives on the project software quality assurance and evaluation tools for development and software quality assessment project management and team work. We present our project-based exam and summarize hints on its design organization and evaluation. Project examples are also introduced.;
Proceedings of the First International Workshop on Designing and Running Project-Based Courses in Software Engineering Education;A meaningful and deep understanding of the human aspects of software engineering (SE) requires psychological constructs to be considered. Psychology theory can facilitate the systematic and sound development as well as the adoption of instruments (e.g. psychological tests questionnaires) to assess these constructs. In particular to ensure high quality the psychometric properties of instruments need evaluation. In this article we provide an introduction to psychometric theory for the evaluation of measurement instruments for SE researchers. We present guidelines that enable using existing instruments and developing new ones adequately. We conducted a comprehensive review of the psychology literature framed by the Standards for Educational and Psychological Testing. We detail activities used when operationalizing new psychological constructs such as item pooling item review pilot testing item analysis factor analysis statistical property of items reliability validity and fairness in testing and test bias. We provide an openly available example of a psychometric evaluation based on our guideline. We hope to encourage a culture change in SE research towards the adoption of established methods from psychology. To improve the quality of behavioral research in SE studies focusing on introducing validating and then using psychometric instruments need to be more common.;
Text and Team: What Article Metadata Characteristics Drive Citations in Software Engineering?;Context: Citations are a key measure of scientific performance in most fields including software engineering. However there is limited research that studies which characteristics of articlesâ€™ metadata (title abstract keywords and author list) are driving citations in this field. Objective: In this study we propose a simple theoretical model for how citations come to be with respect to article metadata we hypothesize theoretical linkages between metadata characteristics and citations of articles and we empirically test these hypotheses. Method: We use multiple regression analyses to examine a data set comprising the titles abstracts keywords and authors of 16131 software engineering articles published between 1990 and 2020 in 20 highly influential software engineering venues. Results: We find that number of authors number of keywords number of question marks and dividers in the title number of acronyms abstract length abstract propositional idea density and corresponding authors in the core Anglosphere are significantly related to citations. Conclusion: Various characteristics of articlesâ€™ metadata are linked to the frequency with which the corresponding articles are cited. These results partially confirm and partially go counter to prior findings in software engineering and other disciplines.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;Engineering software to be inclusive of all those that might/could/should use the software is important. However today data used to engineer software can have inherent biases (e.g. gender identity) with inclusiveness concerns. While much attention has been given to this topic in the AI/ML space in this paper we examine another data-centric software engineering process A/B testing for which we have a dearth of understanding today. Using real-world data from the Windows out of box experience (OOBE) feature we provide a case-study of how inclusiveness concerns can manifest in A/B testing practical adjustments to A/B testing towards inclusive software engineering and insights into ongoing challenges. We discuss implications for research and practice.;
Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice;Goal-oriented analysis techniques analyzes goal models in order to help analysts making decisions about the system to be developed. These analyses can for example identify conflicts of interest among stakeholders or prioritize their goals. Although many techniques of this type have been proposed the vast majority of them focus on the concept of satisfaction resulting in a value-neutral approach. This means that all the elements in a goal model (e.g. stakeholders' goals) are considered to be equally important. Moreover almost all these techniques use either a qualitative or a quantitative approach to assign weight or importance to the elements in a goal model.This paper presents a tool that provides technical support to a goal-oriented analysis technique that uses the concept of value (thereby considering that not all intentional elements are equally important). The technique uses fuzzy logic to combine a qualitative prioritization of individual intentional elements with a quantitative systematic propagation of the relationships among these intentional elements by means of Fuzzy Multi-Criteria Decision-Making (FM-CDM). This propagation calculates how valuable each intentional element of a goal model is with respect to the other elements of the model.;
Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;Deep Learning (DL) is being used nowadays in many traditional Software Engineering (SE) problems and tasks. However since the renaissance of DL techniques is still very recent we lack works that summarize and condense the most recent and relevant research conducted at the intersection of DL and SE. Therefore in this paper we describe the first results of a mapping study covering 81 papers about DL &amp SE. Our results confirm that DL is gaining momentum among SE researchers over the years and that the top-3 research problems tackled by the analyzed papers are documentation defect prediction and testing.;
Proceedings of the 36th Annual ACM Symposium on Applied Computing;Requirements can be documented using different notations that vary for example on expressivity formality and visualization. Each of them have advantages and disadvantages on different contexts. In fact there is not much information on which and how requirements notations are being used most of all when considering not only the Software Engineering industry but also its research community. Therefore this study investigates researchers' applications for requirements notations. Furthermore we explore their reasoning behind the choice for a notation and how formally these notations are defined. First we reviewed the literature to identify general requirements notations and their definition methods. Then we conducted a survey study with Software Engineering researchers asking them about the notations they have used. We received 251 usable responses from 24 countries. Our main findings are that participants' preferred notations are Use Case Class Diagram and User Stories and they choose notations based mainly on their suitability to the problem their adequacy to the stakeholders and common usage.;
Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing;Background: Given the social aspects of Software Engineering (SE) in the last twenty years researchers from the field started using research methods common in social sciences such as case study ethnography and grounded theory. More recently case survey another imported research method has seen its increasing use in SE studies. It is based on existing case studies reported in the literature and intends to harness the generalizability of survey and the depth of case study. However little is known on how case survey has been applied in SE research let alone guidelines on how to employ it properly. Aims: This article aims to provide a better understanding of how case survey has been applied in Software Engineering research. Method: To address this knowledge gap we performed a systematic mapping study and analyzed 12 Software Engineering studies that used the case survey method. Results: Our findings show that these studies presented a heterogeneous understanding of the approach ranging from secondary studies to primary inquiries focused on a large number of instances of a research phenomenon. They have not applied the case survey method consistently as defined in the seminal methodological papers. Conclusions: We conclude that a set of clearly defined guidelines are needed on how to use case survey in SE research to ensure the quality of the studies employing this approach and to provide a set of clearly defined criteria to evaluate such work.;
Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);The rapid growth of software engineering research publications forces an amount of scholarly knowledge that needs to be managed organized and communicated in digital libraries and scientific search engines. Thus there is a need for classified papers to accomplish these tasks but the classification process is cumbersome. Moreover in case of new schemas one would need to reclassify previously published research. We propose to automate the classification and present different possible techniques for doing so: Using natural language models a rule-based approach or an approach based on topic-labeling. In this proposal paper we initially implemented a prototype for text classification of software engineering research papers.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;Software processes together with software quality assurance focus on ensuring and attesting that the engineering processes result in the appropriate software quality. Complex processes and regulations (e.g. in safety-critical systems) time pressure or coordination needs often cause engineers to deviate from prescribed processes producing a cascade of inconsistencies whose repair is typically troublesome. Accordingly guidance is needed to help engineers to fix the inconsistencies and understand the implications of postponing inconsistency resolution until engineers reach a consensual agreement of the most convenient repair. To this end we bring together techniques and methods from process engineering model inconsistency checking and formal methods. Preliminary evaluations with real industry data have demonstrated the ability of our early prototype to track process inconsistencies across time and the potential for automated repair.;
Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results;Background: Physical aspects are essential human factors that play a key role in a researcher's career and development. Aging is one of the most important physical aspects that can impact the productivity of a researcher (e.g. in terms of publications). In parallel aging adds experience and proficiency on the scientific research work such as assuring the quality and reliability of research.Objective: We aim to understand the impact of aging and the academic age on research publications productivity of research software engineers - the people actively developing software or conducting research in an academic research environment - and explore their Golden Age aspect.Method: We performed a first study on the age distribution of researchers who have published at three famous and prestigious software-engineering conferences: ASE ESEC/FSE and ICSE including 4620 research-track papers and their 7337 authors.Results: The results suggest that the academic productivity is maximized at year 15 (Golden Age) and it is held roughly constant for further 15 years before it declines. The results also find that half authors disappear after their first publication year reflecting dropout rates that academia suffers from.Conclusion: Through this pilot study we share insights on the age distribution and thus representation of software-engineering researchers at major conferences and try to understand whether certain groups of researchers are over- or underrepresented.;
Proceedings of the 15th International Conference on Cooperative and Human Aspects of Software Engineering;[Background:] Experimentation in Software Engineering (ESE) has increased in the last several years as a way to provide evidence by using statistical techniques. These techniques contribute to an auditable and reliable body of knowledge towards evolving a given topic. Therefore teaching ESE becomes an essential task while disseminating and establishing an experimental culture to both academia and industry. [Aims:] In this paper we seek to understand how ESE has been taught including contents materials used strategies employed and evaluation method applied. We also provide a research agenda on the subject. [Method:] We conducted a web-based questionnaire survey with 31 instructors who teach ESE. [Results:] We see several aspects such as: ESE is mainly taught in an exclusive course most of the materials used to teach ESE concepts are from third parties and some of them themselves most people do not use any type of license the core materials used to define the content of the courses are papers and books learning management systems are most often used to share materials with students key learning practices used are active learning project-based learning and problem-based learning and most instructors assess their students with experimental projects and seminars. Based on such results we provide and discuss a research agenda to improve teaching of ESE. [Conclusions:] This survey provides results towards planning a research agenda to improve teaching of ESE thus benefiting instructors researchers and practitioners.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;Security is a non-functional requirement difficult-to-handle during software development. However it appears to be common in software engineering that security is taken care of during the design- and test-phase only. If security is neglected during the implementation phase flaws will be introduced. Those may be - if at all - found during testing where the cost-to-fix is higher as if found during the implementation phase. Hence this research proposal suggests to investigate the extent to which code analysis tools can be used as a step towards continuous security inspection in software engineering projects. By automating security testing in development flaws can be found as soon as they are introduced. This could greatly reduce the cost to fix flaws and help building more secure software.;
Classification of Software Engineering Contributions to Support Validation Techniques and Research Applications;Science and thereby software engineering (SE) research enables progress and innovation. SE research has high economic relevance and serves as an enabler for innovations in other research fields as well. Researchers in this field perform many activities and face corresponding challenges. They have to design and conduct research while deciding on an appropriate method design for a scientific or practical problem. They have to review research while critically assessing research outcomes in a systematic and comparable way. They have to search for research outcomes to find research gaps to build upon. Likewise by finding related information they are able to justify relevance of own research work. These searching processes are done via keyword-based searches while struggling with information overload due to immensely growing number of SE papers published every year. Thus there is the need for conceptual approaches automated mechanisms and a rethinking about scholarly communication to support these research activities and challenges in an effective efficient and comprehensible way. There are a variety of available classifications for research methods in literature. Additionally empirical standards for research methods are continuously developed and adapted from other research fields. However there is no consistency in the covered research methods nor in the used terminology as well as no systematic approach to structure this body of research knowledge (e.g. template research questions research methods validity threats replication types). Therefore this doctoral thesis will provide a unified classification scheme to describe the characteristics of SE research. This further enables classification of SE papers and a corresponding queryable knowledge management system and thus advance state of practice.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;Background. Most Mining Software Repositories (MSR) studies cannot obtain causal relations because they are not controlled experiments. The use of cohort studies as defined in epidemiology could help to overcome this shortcoming.Objective. Propose the adoption of cohort studies in MSR research in particular and empirical Software Engineering (SE) in general. Method. We run a preliminary literature review to show the current state of the practice of cohort studies in SE. We explore how cohort studies overcome the issues that prevent the identification of causality in this type of non-experimental designs.Results. The basic mechanism used by cohort studies to try to obtain causality consists of controlling potentially confounding variables. This is articulated by means of different techniques.Conclusion. Cohort studies seem to be a promising approach to be used in MSR in particular and SE in general.;
Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);There is an ongoing interest in the Software Engineering field for multivocal literature reviews including grey literature. However at the same time the role of the grey literature is still controversial and the benefits of its inclusion in systematic reviews are object of discussion. Some of these arguments concern the quality assessment methods for grey literature entries which is often considered a challenging and critical task. On the one hand apart from a few proposals there is a lack of an acknowledged methodological support for the inclusion of Software Engineering grey literature in systematic surveys. On the other hand the unstructured shape of the grey literature contents could lead to bias in the evaluation process impacting on the quality of the surveys. This work leverages an approach on fuzzy Likert scales and it proposes a methodology for managing the explicit uncertainties emerging during the assessment of entries from the grey literature. The methodology also strengthens the adoption of consensus policies that take into account the individual confidence level expressed for each of the collected scores.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;Assessing the personality of software engineers may help to match individual traits with the characteristics of development activities such as code review and testing as well as support managers in team composition. However self-assessment questionnaires are not a practical solution for collecting multiple observations on a large scale. Instead automatic personality detection while overcoming these limitations is based on off-the-shelf solutions trained on non-technical corpora which might not be readily applicable to technical domains like software engineering. In this article we first assess the performance of general-purpose personality detection tools when applied to a technical corpus of developersâ€™ e-mails retrieved from the public archives of the Apache Software Foundation. We observe a general low accuracy of predictions and an overall disagreement among the tools. Second we replicate two previous research studies in software engineering by replacing the personality detection tool used to infer developersâ€™ personalities from pull-request discussions and e-mails. We observe that the original results are not confirmed i.e. changing the tool used in the original study leads to diverging conclusions. Our results suggest a need for personality detection tools specially targeted for the software engineering domain.;
The who what and how of the current research at the Brazilian Symposium on Software Engineering;Software engineering is a socio-technical activity and while many contributions focus on technical aspects its research should benefit human stakeholders. The Who-What-How framework aims to capture the head beneficiary of a research study (the who) the predominant type of research contribution produced (the what) and the research strategies used in a study (the how) evaluating how these studies address the human aspects. This paper performs a replication study of â€œThe who what how of software engineering research: a socio-technical frameworkâ€ [50] which addressed the question of how papers from the ICSE and EMSE considered human aspects. This study uses the Who-What-How framework to analyze works published at the Brazilian Symposium on Software Engineering between 2019 and 2021. We analyzed 90 papers and found a significant amount of work that claims to benefit human stakeholders most presented descriptive contributions and adopted the Respondent research strategy. Triangulation of research was low as only 15 papers reported using mixed strategies.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;In 2014 a Microsoft study investigated the sort of questions that data science applied to software engineering should answer. This resulted in 145 questions that developers considered relevant for data scientists to answer thus providing a research agenda to the community. Fast forward to five years no further studies investigated whether the questions from the software engineers at Microsoft hold for other software companies including software-intensive companies with different primary focus (to which we refer as software-defined enterprises). Furthermore it is not evident that the problems identified five years ago are still applicable given the technological advances in software engineering. This paper presents a study at ING a software-defined enterprise in banking in which over 15000 IT staff provides in-house software solutions. This paper presents a comprehensive guide of questions for data scientists selected from the previous study at Microsoft along with our current work at ING. We replicated the original Microsoft study at ING looking for questions that impact both software companies and software-defined enterprises and continue to impact software engineering. We also add new questions that emerged from differences in the context of the two companies and the five years gap in between. Our results show that software engineering questions for data scientists in the software-defined enterprise are largely similar to the software company albeit with exceptions. We hope that the software engineering research community builds on the new list of questions to create a useful body of knowledge.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Context: Even though Open Peer Review (OPR) is one of the pillars of Open Science informed discussions are still necessary to understand its impact on the social behavior of reviewers and the quality of reviews. Goal: The main goal of this study is to understand the audience effect on reviewersâ€™ behavior and reviewsâ€™ quality from the perspectives of reviewers and authors of a Software Engineering (SE) workshop. Method: We performed a survey with the workshop participants including authors and experienced reviewers in the SE field. Results: Our results show that while the OPR model did not change the reviewersâ€™ behavior it reinforced reviewers to avoid hostile comments and help the authors improve their manuscript. Results also show that reviewers were comfortable with revealing their identities and reviews. Finally both reviewers and authors agreed that although the OPR model did not increase the quality of reviews it encouraged reviewers to think more carefully about scientific issues contributing to the writing of evidence-supported feedback. Conclusions: Open Peer Review is innovative in interacting with reviewers and authors in Brazilian SE academic venues. OPR is also inspiring given the potential for reinforcing positive reviewersâ€™ behaviors. However the thematic still requires further investigation and attention from the community.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Teaming is increasingly a core aspect of professional software engineering and most undergraduate computer science curricula. At NC State University we teach communication and project-management skills explicitly through a junior-level software engineering course. However some students may have a dysfunctional team experience that imperils their ability to learn these skills. Identifying these teams during a team project is important so the teaching staff can intervene early and hopefully alleviate the issues. We propose a weekly reflection survey to help the course teaching staff proactively identify teams that may not be on track to learn the course outcomes. The questions on the survey focus on team communication and collaboration over the previous week. We evaluate our survey on two semesters of the undergraduate software engineering course by comparing teams with poor end-of-project grades or peer evaluations against teams flagged on a weekly basis through the surveys. We find that the survey can identify most teams that later struggled on the project typically by the half-way mark of the project and thus may provide instructors with an actionable early-warning about struggling teams. Furthermore a majority of students (64.4%) found the survey to be a helpful tool for keeping their team on track. Finally we discuss future work for improving the survey and engaging with student teams.;
Proceedings of the 53rd ACM Technical Symposium on Computer Science Education - Volume 1;Search-Based Software Engineering (SBSE) has been beneficial for optimizing the solution of several Software Engineering (SE) problems. The incorporation of Decision Makers (DM) preferences during the search process may help the algorithms to find more adequate solutions for their profiles. Some interactive approaches allow the DM to evaluate solutions rating them with scores during the search process. These scores represent the adequacy level of the solutions in relation to the DM preferences and should influence the evolution of the search algorithm. In previous work we proposed an interactive ranking operator for NSGA-II to support the complete prioritization of solutions for any SE problem domain. Although this operator worked satisfactorily in an application example its validation is required so that it can be used in real application contexts. In this sense we instantiated the interactive ranking operator for NSGA-II presented in previous work and we conducted an exploratory study with a twofold goal: (i) validate the impact in the ranking of solutions and (ii) check the diversity of them. To accomplish such goals we made statistical tests such as correlation and regression analysis using quality metrics for Product Line Architecture (PLA) Design. The results pointed out that the interactive ranking operator can properly deal with the DM preferences giving a greater chance of surviving to those solutions with higher scores without compromising their diversity.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Background: Mining online accounts of practitioner experience can provide new evidence for software engineering researchers. However we need methods for assessing quality at vast scale. Objectives: We investigate the challenge of finding high-quality grey literature defining high-quality in terms of a documentâ€™s relevance to the consumer and its credibility. Method: Building on previous research we use a version of the case survey methodology for automating the identification and assessment of high-quality grey literature. Results: We develop a model of credibility assessment within software engineering research and demonstrate our case survey methodology and credibility assessment model in practice. We use it to conduct a grey literature review of High Performing Teams (HPT). Conclusions: The paper provides a foundation for future research on automated quality and credibility assessment. Adoption of the tools and methodology presented can help researchers effectively search for and select higher-quality blog-like content.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;Robots that support humans by performing useful tasks (a.k.a. service robots) are booming worldwide. In contrast to industrial robots the development of service robots comes with severe software engineering challenges since they require high levels of robustness and autonomy to operate in highly heterogeneous environments. As a domain with critical safety implications service robotics faces a need for sound software development practices. In this paper we present the first large-scale empirical study to assess the state of the art and practice of robotics software engineering. We conducted 18 semi-structured interviews with industrial practitioners working in 15 companies from 9 different countries and a survey with 156 respondents from 26 countries from the robotics domain. Our results provide a comprehensive picture of (i) the practices applied by robotics industrial and academic practitioners including processes paradigms languages tools frameworks and reuse practices (ii) the distinguishing characteristics of robotics software engineering and (iii) recurrent challenges usually faced together with adopted solutions. The paper concludes by discussing observations derived hypotheses and proposed actions for researchers and practitioners.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Gamification is not a new term in the field of education. Visual Novels (VN) are text-based and afford interaction with their users. This work discusses the use of VNs as a gamification approach in software engineering education. VNs tell stories and can therefore offer a facilitated introduction to complex topics in higher education. Such a topic is the Waterfall model (WM) a process model for software development. It is lectured within a software engineering course at the University of Applied Sciences Kempten (Germany). This lecture is taught to the students in form of an online video. In order to familiarize students with this topic we developed and implemented a learning scenario in form of a VN. The aim of this approach is to motivate students and thus improve their learning success.;
Proceedings of the 4th European Conference on Software Engineering Education;Software Engineering (SE) researchers are increasingly paying attention to organizational and human factors. Rather than focusing only on variables that can be directly measured such as lines of code SE research studies now also consider unobservable variables such as organizational culture and trust. To measure such latent variables SE scholars have adopted Partial Least Squares Structural Equation Modeling (PLS-SEM) which is one member of the larger SEM family of statistical analysis techniques. As the SE field is facing the introduction of new methods such as PLS-SEM a key issue is that not much is known about how to evaluate such studies. To help SE researchers learn about PLS-SEM we draw on the latest methodological literature on PLS-SEM to synthesize an introduction. Further we conducted a survey of PLS-SEM studies in the SE literature and evaluated those based on recommended guidelines.;
Towards facilitating software engineering for production systems in industry 4.0 with behavior models;With the growing adoption of Industry 4.0 concepts in production systems new challenges arise in engineering control software. Highly distributed control with tight real-time constraints and safety regulations results in increasingly complex software. Current research focuses on increasing the abstraction with new architectures and modularization of software. The presented PhD research addresses modeling of the interactions between control software components and of the emergent behavior of these compositions. Such behavior models can support the initial implementation and facilitate (semi-)automated testing and monitoring of control software. Finally visualizing behavior in a model can enhance under-standability of existing control software when software developers need not access abstracted hierarchy levels to deduct their functionality. This work aims at optimizing the benefit of behavior models in developing control software: Modeling the expected behavior directly for new software will allow using them throughout the software life-cycle. For legacy software the initial development effort of behavior models will be minimized by automatically capturing behavior models from the implementation. The approach is evaluated in case studies and user studies to integrate experiences from the industrial domain into this software engineering research.;
Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings;We need to built software rapidly and with a high quality. These goals seem to be contradictory but actually implementing automation in build and deployment procedures as well as quality analysis can improve both the development pace and the resulting quality at the same time. Rapid Continuous Software Engineering describes novel software engineering approaches that focus on short release cycles continuous deployment delivery and continuous improvement through rapid tool-assisted feedback to developers. To realize these approaches there is a need for research and innovation with respect to automation and tooling and furthermore for research into the organizational changes that support high pace development. This paper reports on the results of the 6th International Workshop on Rapid Continuous Software Engineering (RCoSE 2020) which focuses on the challenges and potential solutions in the area of Rapid Continuous Software Engineering before reporting on our discussions regarding the state of the practice and open research topics.;
On the Reproducibility and Replicability of Deep Learning in Software Engineering;Context: Deep learning (DL) techniques have gained significant popularity among software engineering (SE) researchers in recent years. This is because they can often solve many SE challenges without enormous manual feature engineering effort and complex domain knowledge.Objective: Although many DL studies have reported substantial advantages over other state-of-the-art models on effectiveness they often ignore two factors: (1) reproducibilityâ€”whether the reported experimental results can be obtained by other researchers using authorsâ€™ artifacts (i.e. source code and datasets) with the same experimental setup and (2) replicabilityâ€”whether the reported experimental result can be obtained by other researchers using their re-implemented artifacts with a different experimental setup. We observed that DL studies commonly overlook these two factors and declare them as minor threats or leave them for future work. This is mainly due to high model complexity with many manually set parameters and the time-consuming optimization process unlike classical supervised machine learning (ML) methods (e.g. random forest). This study aims to investigate the urgency and importance of reproducibility and replicability for DL studies on SE tasks.Method: In this study we conducted a literature review on 147 DL studies recently published in 20 SE venues and 20 AI (Artificial Intelligence) venues to investigate these issues. We also re-ran four representative DL models in SE to investigate important factors that may strongly affect the reproducibility and replicability of a study.Results: Our statistics show the urgency of investigating these two factors in SE where only 10.2% of the studies investigate any research question to show that their models can address at least one issue of replicability and/or reproducibility. More than 62.6% of the studies do not even share high-quality source code or complete data to support the reproducibility of their complex models. Meanwhile our experimental results show the importance of reproducibility and replicability where the reported performance of a DL model could not be reproduced for an unstable optimization process. Replicability could be substantially compromised if the model training is not convergent or if performance is sensitive to the size of vocabulary and testing data.Conclusion: It is urgent for the SE community to provide a long-lasting link to a high-quality reproduction package enhance DL-based solution stability and convergence and avoid performance sensitivity on different sampled data.;
Automatic management analysis of computer software engineering project based on data mining;In recent years with the continuous development of data technology especially with the continuous improvement and research and development of software systems software development has become a very complex system engineering. Because the backward software production method can't meet the increasing demand of computer software a series of problems have appeared in the development and maintenance of software engineering. Software projects are different from other projects and the general project management method can't be applied to all software project management. This paper puts forward the application of data mining in software engineering. Data mining is an interdisciplinary subject involving many fields and it has many mature technologies. The quantitative analysis method of demand evolution influence based on data mining clusters the new demand and the existing demand of software projects and puts forward corresponding strategies to solve them thus improving the automation management level of computer software engineering.;
2021 International Conference on Aviation Safety and Information Technology;The COVID-19 worldwide pandemic caused sudden and unexpected changes in how we teach software engineering and other university courses. This paper presents an empirical study that aims to improve our understanding on how the assessment of student learning changed in response to the transition from in-class to online courses. A questionnaire was distributed to instructors across the globe. The results indicate that the evaluation methodologies for most reported learning objectives have changed. Not surprising in-class oral presentations and in-class exams are no longer used by the instructors for evaluations. We observed a trend of having fewer exams and more project-related evaluations after the transition. Not all instructors changed the way they evaluated student learning after the transition however the majority reported their effort in student learning assessment increased after the transition whether they made changes in methodologies or not.;
Proceedings of the 2nd ACM SIGSOFT International Workshop on Education through Advanced Software Engineering and Artificial Intelligence;Building shared understanding of requirements is key to ensuring downstream software activities are efficient and effective. Nonfunctional requirements (NFR) which include performance availability and maintainability are vitally important to overall software quality. Research has shown NFRs are in practice poorly defined and difficult to verify especially in agile environments. Continuous software engineering (CSE) practices which extend agile practices emphasize fast paced automated and rapid release of software that poses additional challenges to NFRs. However the level of shared understanding achieved across an organization is not well-understood. This dissertation builds the foundations towards a theory of the complex and intricate relationship between shared understanding of NFRs and CSE.;
Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings;Software and information technologies are becoming increasingly integrated and pervasive in human society and range from automated decision making to running critical infrastructure like utilities and financial institutions. There is also a growing awareness of the need to develop leaders who will harness these technologies in fair and inclusive ways. Many academic and industry researchers are advocating for the responsible use of information technologies and some academic and research institutions such as IEEE and ACM have published codes of ethics to spread awareness about these issues. In this regard a number of academic researchers including the authors of this paper have expressed the need to teach students computer and information ethics as well as professional and leadership skills. In this paper we propose an approach that is potentially effective in helping students develop leadership and communication skills as well as learn broader skills of professional responsibility. The proposed approach is modeled after Toastmasters a very successful association present in over 140 countries with almost 350000 members across more than 16000 clubs. We describe our goal and give a general description of a Toastmasters club and how it is conducted. Further we describe some activities and projects having CS/SE context that can be done by students as part of a relevant class. Finally we briefly describe the approach that we are undertaking in our first pilot activities and their integration with additional synergetic strategies.;
Proceedings of the 15th International Conference on Cooperative and Human Aspects of Software Engineering;The availability of open source projects on platforms like GitHub has led to the wide use of the artifacts from these projects in software engineering research. These publicly available artifacts have been used to train artificial intelligence models used in various empirical studies and the development of tools. However these advancements have missed out on the artifacts from non-open source projects due to the unavailability of the data. A major cause for the unavailability of the data from non-open source repositories is the issue concerning data privacy. In this paper we propose using federated learning to address the issue of data privacy to enable the use of data from non-open source to train AI models used in software engineering research. We believe that this can potentially enable industries to collaborate with software engineering researchers without concerns about privacy. We present the preliminary evaluation of the use of federated learning to train a classifier to label bug-fix commits from an existing study to demonstrate its feasibility. The federated approach achieved an F1 score of 0.83 compared to a score of 0.84 using the centralized approach. We also present our vision of the potential implications of the use of federated learning in software engineering research.;
Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering;The research focuses on designing gender-neutral Software Engineering programs as a tool to reach gender balance in this domain. There is a general lack of female students and subsequently employees in Computer Science Engineering Mathematics and Physics. The attempts of attracting females in technologies have a long history and most topic related studies agree that the main reason for the low ratio of women in STEM is a result of gender stereotypes. This article reviews how gender stereotypes affect students' interest in Software Engineering. The reason we considered gender-neutrality as a tool to achieve gender balance in Software Engineering lies in the fact that both genders experience the pressure of the stereotypes. Studies show that men are not likely to choose feminine products/jobs. Thus making the educational program more attractive for females could discourage some males from enrolling. Our work considers different approaches to archive gender-neutrality and we present recommendations for gender-neutral program designs which combine the considered approaches to gender-neutrality.;
Proceedings of the Third Workshop on Gender Equality Diversity and Inclusion in Software Engineering;Defining and classifying software requirements are critical tasks for determining software functionality and overall software architecture. In this sense several types of research are being developed aiming to automate the classification of software requirements through the use of machine learning algorithms. However the feasibility of such studies runs counter to the existence of a public database that is adequate in terms of quantity and quality of sample requirements. A requirement base widely used in this type of task is the PROMISE. However the number of requirements is considered low for practical applications involving machine learning. This research presents an expansion of the PROMISE corpus. New software requirements were incorporated and the resulting dataset was evaluated through the use of well-known machine learning algorithms. We observed some improvement in the performance of these algorithms regarding the identification of some types of software requirements.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;Software systems have evolved from being 'stand-alone systems' to 'systems of systems' to meet the challenging needs of societies. Contemporary software systems such as socio-technical systems are composed of distributed and heterogeneous agents the em- bedded environment and software components. Addressing the disruptions caused by run-time changes in the environment while designing software systems remains a challenging task in practice. Ensembles enable systems with collective adaptability to be built as emergent aggregations of autonomous and self-adaptive agents. The phenomenal aspect of this type of systems allows agents (i.e services people and things) a ected by an issue to adapt collabo- ratively with minimal impact on their own preferences through a collective resolution process. In this paper we report the outcomes of the 2nd ACM SIGSOFT International Workshop on Ensemble- Based Software Engineering for Modern Computing Platforms (EnSEmble 2019) which was held as part of the 27th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2019) in Tallinn Estonia on August 26th 2019.;
A Systematic Literature Review on the Use of Deep Learning in Software Engineering Research;An increasingly popular set of techniques adopted by software engineering (SE) researchers to automate development tasks are those rooted in the concept of Deep Learning (DL). The popularity of such techniques largely stems from their automated feature engineering capabilities which aid in modeling software artifacts. However due to the rapid pace at which DL techniques have been adopted it is difficult to distill the current successes failures and opportunities of the current research landscape. In an effort to bring clarity to this cross-cutting area of work from its modern inception to the present this article presents a systematic literature review of research at the intersection of SE &amp DL. The review canvasses work appearing in the most prominent SE and DL conferences and journals and spans 128 papers across 23&nbspunique SE tasks. We center our analysis around the components of learning a set of principles that governs the application of machine learning techniques (ML) to a given problem domain discussing several aspects of the surveyed work at a granular level. The end result of our analysis is a research roadmap that both delineates the foundations of DL techniques applied to SE research and highlights likely areas of fertile exploration for the future.;
Peer-Reviewing and Submission Dynamics Around Top Software-Engineering Venues: A Juniorsâ€™ Perspective;Academic research by its nature is notorious for being a challenging and demanding field. However these challenges may become more complicated for certain groups of researchers rather than others. For instance junior researchers who make up a large group of the current scientific community particularly in the computer science domain may face various types of impediments. A notable hindrance to realizing the impediments is the difficulty of precisely delineating them. In this paper we report an empirical investigation to measure the level of awareness of any kind of obstacles that might hinder junior researchersâ€™ publishing ability and disturb their involvement. For this purpose we conducted a survey targeting active researchers from the Software Engineering field with a total of 52 respondents. We mainly focus on two types of aspects: peer reviewing models and collaboration. Our findings indicate that junior researchers seem to be more comfortable with double-blind reviewing models with more than half (approximately 67.2%) of them voting in favor of this model. The results also show a significant agreement that a lack of experience especially in academic writing and supervision problems constitute the most influential barriers to publishing. Our findings can help understand the needs of junior researchers and provide insights into our research community and its specific groups.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;Software engineering occupies an increasingly critical role in companies across all sectors but too many software initiatives end up both off target and over budget. A surer path is optimized for speed open to experimentation and learning agile and subject to regular course correcting. Good ideas tend to be abundant though execution at high velocity is elusive. The good news is that velocity is controllable companies can invest systematically to increase it.;
Software engineering for machine learning: a case study;"Recent advances in machine learning have stimulated widespread interest within the Information Technology sector on integrating AI capabilities into software and services. This goal has forced organizations to evolve their development processes. We report on a study that we conducted on observing software teams at Microsoft as they develop AI-based applications. We consider a nine-stage workflow process informed by prior experiences developing AI applications (e.g. search and NLP) and data science tools (e.g. application diagnostics and bug reporting). We found that various Microsoft teams have united this workflow into preexisting well-evolved Agile-like software engineering processes providing insights about several essential engineering challenges that organizations may face in creating large-scale AI solutions for the marketplace. We collected some best practices from Microsoft teams to address these challenges. In addition we have identified three aspects of the AI domain that make it fundamentally different from prior software application domains: 1) discovering managing and versioning the data needed for machine learning applications is much more complex and difficult than other types of software engineering 2) model customization and model reuse require very different skills than are typically found in software teams and 3) AI components are more difficult to handle as distinct modules than traditional software components --- models may be entangled"" in complex ways and experience non-monotonic error behavior. We believe that the lessons learned by Microsoft teams will be valuable to other organizations.""";
Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice;The software industry is a key engine of economic growth in Africa which calls for sustainable and innovative approaches to build capacities in software engineering research and education for the continent. This paper presents the BRIGHT project as an example for a collaboration that aims to build such capacity. The collaboration includes institutions in Sweden and Uganda. The goal of the collaboration is to train faculty in software en- gineering and to build a supporting research environment which includes the creation of networks with the software engineering community at a global scale as well as connecting academia and the local software industry. So far the project has resulted in 50 publications a software engineering research centre software engineering summer schools and conferences.;
Teaching Accessibility to Software Engineering Students;This paper describes the development process of a graduate course on accessibility that is offered as an elective for software engineering students. The paper reports on the three iterations of the course evolution as topics and pedagogy are updated from one iteration to the next. The main motivation of the course updates was to cover the educational needs of software engineering students which are not the same as HCI or design students. Software engineering students learned better and became more engaged with the topic of accessibility when it was tied to programming and development- based activities. The final form of the course was evaluated using a survey and the results showed that students found the course beneficial to their education and relevant to their career. We discuss the challenges of creating teaching and maintaining a course on accessibility and we offer insights on what research is needed in this area to support accessibility educators.;
Proceedings of the 51st ACM Technical Symposium on Computer Science Education;For computer software engineering the important technical means of database programming should run through the whole process of safe operation of software engineering aiming at using professional programming technology principles to edit database running programs and then achieving the goal of ensuring the integrity and safety of database storage information. With the development of mobile computing technology it appears or shows wide applications in many fields. Such as public information publishing location-related query mobile commerce etc. all depend on the support of mobile database system. In order to improve the efficiency of computer software development and reduce the probability of software vulnerabilities and running errors technicians are required to take necessary test methods in the process of development and design to realize the summary analysis of computer software information data. This paper expounds the existence value of computer database analyzes the process of establishing computer database and studies the database programming technology of computer software engineering based on multi-platform testing.;
2021 International Conference on Aviation Safety and Information Technology;Cyber-physical systems (CPS) have been developed in many industrial sectors and application domains in which the quality requirements of data acquired are a common factor. Data quality in CPS can deteriorate because of several factors such as sensor faults and failures due to operating in harsh and uncertain environments. How can software engineering and artificial intelligence (AI) help manage and tame data quality issues in CPS? This is the question we aimed to investigate in the SEA4DQ workshop. Emerging trends in software engineering need to take data quality management seriously as CPS are increasingly datacentric in their approach to acquiring and processing data along the edge-fog-cloud continuum. This workshop provided researchers and practitioners a forum for exchanging ideas experiences understanding of the problems visions for the future and promising solutions to the problems in data quality in CPS. Examples of topics include software/hardware architectures and frameworks for data quality management in CPS software engineering and AI to detect anomalies in CPS data or to repair erroneous CPS data. SEA4DQ 2021 which took place on August 24th 2021 was a satellite event of the ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC / FSE) 2021. The workshop attracted 35 international participants and was exciting with a great keynote six excellent presentations and concluded on a high note with a panel discussion. SEA4DQ was motivated by the common research interests from the EU projects for Zero-Defects Manufacturing such as InterQ and Dat4.Zero.;
Quality Indicators in Search-based Software Engineering: An Empirical Evaluation;Search-Based Software Engineering (SBSE) researchers who apply multi-objective search algorithms (MOSAs) often assess the quality of solutions produced by MOSAs with one or more quality indicators (QIs). However SBSE lacks evidence providing insights on commonly used QIs especially about agreements among them and their relations with SBSE problems and applied MOSAs. Such evidence about QIs agreements is essential to understand relationships among QIs identify redundant QIs and consequently devise guidelines for SBSE researchers to select appropriate QIs for their specific contexts. To this end we conducted an extensive empirical evaluation to provide insights on commonly used QIs in the context of SBSE by studying agreements among QIs with and without considering differences of SBSE problems and MOSAs. In addition by defining a systematic process based on three common ways of comparing MOSAs in SBSE we present additional observations that were automatically produced based on the results of our empirical evaluation. These observations can be used by SBSE researchers to gain a better understanding of the commonly used QIs in SBSE in particular regarding their agreements. Finally based on the results we also provide a set of guidelines for SBSE researchers to select appropriate QIs for their particular context.;
Towards a Methodology for Participant Selection in Software Engineering Experiments: A Vision of the Future;"Background. Software Engineering (SE) researchers extensively perform experiments with human subjects. Well-defined samples are required to ensure external validity. Samples are selected purposely or by convenience limiting the generalizability of results. Objective. We aim to depict the current status of participants selection in empirical SE identifying the main threats and how they are mitigated. We draft a robust approach to participants' selection. Method. We reviewed existing participants' selection guidelines in SE and performed a preliminary literature review to find out how participants' selection is conducted in SE in practice. Results. We outline a new selection methodology by 1) defining the characteristics of the desired population 2) locating possible sources of sampling available for researchers and 3) identifying and reducing the distance"" between the selected sample and its corresponding population. Conclusion. We propose a roadmap to develop and empirically validate the selection methodology.""";
Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);In order to give students an authentic learning experience and better prepare them for the life-long learning required in contemporary workplaces educational institutions increasingly use project-based learning in teams. However this poses the challenge of developing authentic and equitable assessment criteria that reflect individual contributions in a team-work setting without jeopardizing project outcomes. We present a novel and innovative portfolio-based assessment framework that focuses on qualitative outcomes and ensures that the level of achievement reflects a student's competency across each of the defined learning dimensions including professional behaviour teamwork process and relevant contributions towards project deliverables. In this paper we present the main motivation behind devising and introducing the framework and also reflect on the educational outcomes and challenges of implementing the framework in the context of two final year Software Engineering project units.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training;The International Workshop on Realizing Arti cial Intelligence Synergies in Software Engineering (RAISE) aims to present the state of the art in the crossover between Software Engineering and Arti cial Intelligence. This workshop explored not only the appli- cation of AI techniques to SE problems but also the application of SE techniques to AI problems. Software has become critical for realizing functions central to our society. For example software is essential for nancial and transport systems energy generation and distribution systems and safety-critical medical applications. Software development costs trillions of dollars each year yet still many of our software engineering methods remain mostly man- ual. If we can improve software production by smarter AI-based methods even by small margins then this would improve a crit- ical component of the international infrastructure while freeing up tens of billions of dollars for other tasks.;
Biofeedback augmented software engineering: monitoring of programmers' mental effort;This paper presents emergent experimental results showing that mental effort of programmers in code understanding tasks can be monitored through HRV (heart rate variability) using non-intrusive wearable devices. Results suggest that HRV is a good predictor for cognitive load when analyzing code and HRV results are consistent with the mental effort perceived by programmers using NASA-TLX. Furthermore code complexity metrics do not correlate entirely with mental effort and do not seem a good indicator of the subjective perception of complexity felt by programmers. These first results are presented in the context of the project BASE-Biofeedback Augmented Software Engineering which is briefly sketched and proposes a radical neuroscience enabled approach to introduce biofeedback in software development.;
Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results;The fields of Software Engineering and Human-Computer Interaction have traditionally evolved in parallel with little cross-pollination both in industry and academia. However effectively delivering software products offering superior user experiences requires a tight collaboration between professionals from both fields. In recent years some approaches combining the two perspectives have been proposed in industry including dual-track agile software development. Yet very few courses cover those integrated approaches in academia and it appears that no publication so far has reported the existence of a scholarly course covering dual-track agile. This paper introduces a course that addresses the divide between Software Engineering and Human-Computer Interaction through an integrated approach to requirements engineering and interaction design in the context of dual-track agile. The course design combines traditional and flipped-classroom delivery together with project-based learning. During the course project students learn to design and implement software systems that address real problems and satisfy real stakeholders' needs by being useful usable and enjoyable to use. This paper documents the author's experience designing and teaching the course over the past four years. It aims to convince inspire and enable others to teach similar courses bringing interaction design to the forefront of agile software development.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training;"Harmful software has resulted in loss of life societal and environmental damage alongside economic losses from fines and sales embargoes. When someone perceives their team or organisation is creating or operating harmful software (e.g. defective vulnerable malicious or illegal) one way to attempt to change the situation is to blow the whistle"" and disclose the situation internally or externally. Studying harmful situations and the effectiveness of interventions up to and including whistleblowing can help identify technical and human successes and failings in software engineering (SE).The aim of this paper is to explore the extent to which whistle-blowing is studied in SE with the objective of identifying themes research approaches gaps and concerns and the implications for future SE research and practice.We find that whistleblowing is an under-explored area of SE research and where research exists it often takes the view that reporting harm is a matter of individual moral responsibility we argue this poorly reflects SE collaborative practice where professional responsibilities are distributed across the software development lifecycle. We conclude by 1) recommending approaches that can help a more timely identification and mitigation of harm in SE 2) suggesting mechanisms for improving the effectiveness and the personal safety of harm-reporting in SE and 3) reflecting on the role that professional bodies can have in supporting harm reporting up to and including whistleblowing.""";
Proceedings of the 2022 ACM/IEEE 44th International Conference on Software Engineering: Software Engineering in Society;Context: Tertiary studies in software engineering (TS@SE) are widely used to synthesise evidence on a research topic systematically. As part of their protocol TS@SE define inclusion and exclusion criteria (IC/EC) aimed at selecting those secondary studies (SS) to be included in the analysis. Aims: To provide a state of the art on the definition and application of IC/EC in TS@SE and from the results of this analysis we outline an emerging framework TSICEC to be used by SE researchers. Method: To provide the state of the art we conducted a systematic mapping (SM) combining automatic search and snowballing over the body of SE scientific literature which led to 50 papers after application of our own IC/EC. The extracted data was synthesised using content analysis. The results were used to define a first version of TSICEC. Results: The SM resulted in a coding schema and a thorough analysis of the selected papers on the basis of this coding. Our TSICEC framework includes guidelines for the definition of IC/EC in TS@SE. Conclusion: This paper is a step forward establishing a foundation for researchers in two ways. As authors understanding the different possibilities to define IC/EC and apply them to select SS. As readers having an instrument to understand the methodological rigor upon which TS@SE may claim their findings.;
Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Project-based learning (PBL) is a student-centered and learn-by-doing approach that organizes learning around projects. While entrepreneurship and PBL in SE education are thrilling research topics there seems to be very little work focusing on the pros and cons of involving external stakeholders to support real demands in software engineering education. Working on real projects also supports students to acquire leadership skills such as communication project management and teamwork. This paper describes a case study integrating students from different Software Engineering programs and involving external stakeholders underpinned by PBL concepts. We present how this study was designed and implemented in a large institution in four steps summarized as follows: (I) requirements gathering and design (II) information system development and implementation (III) integration tests and deployment process (IV) support and maintenance activities.The study had the participation of 59 students from a professional technical course in step one working in teams and 10 undergraduate students from a Bachelor's program in Information Systems in the following steps working in pairs. Overall the feedback from stakeholders and students exceeded expectations although it increased the workload of teachers. We were able to distill a new set of lessons learned and we expect that at least some of them will be useful for anyone implementing a similar course. As a consequence of this study we plan to institutionally formalize the PBL course improvement process by defining specific outcomes and measurements.;
Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training;Authorship attribution (i.e. determining who is the author of a piece of source code) is an established research topic. State-of-the-art results for the authorship attribution problem look promising for the software engineering field where they could be applied to detect plagiarized code and prevent legal issues. With this article we first introduce a new language-agnostic approach to authorship attribution of source code. Then we discuss limitations of existing synthetic datasets for authorship attribution and propose a data collection approach that delivers datasets that better reflect aspects important for potential practical use in software engineering. Finally we demonstrate that high accuracy of authorship attribution models on existing datasets drastically drops when they are evaluated on more realistic data. We outline next steps for the design and evaluation of authorship attribution models that could bring the research efforts closer to practical use for software engineering.;
Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Statistical analysis is the tool of choice to turn data into information and then information into empirical knowledge. However the process that goes from data to knowledge is long uncertain and riddled with pitfalls. To be valid it should be supported by detailed rigorous guidelines that help ferret out issues with the data or model and lead to qualified results that strike a reasonable balance between generality and practical relevance. Such guidelines are being developed by statisticians to support the latest techniques for Bayesian data analysis. In this article we frame these guidelines in a way that is apt to empirical research in software engineering.To demonstrate the guidelines in practice we apply them to reanalyze a GitHub dataset about code quality in different programming languages. The datasetâ€™s original analysis&nbsp[Ray et&nbspal.&nbsp55] and a critical reanalysis&nbsp[Berger et&nbspal.&nbsp6] have attracted considerable attentionâ€”in no small part because they target a topic (the impact of different programming languages) on which strong opinions abound. The goals of our reanalysis are largely orthogonal to this previous work as we are concerned with demonstrating on data in an interesting domain how to build a principled Bayesian data analysis and to showcase its benefits. In the process we will also shed light on some critical aspects of the analyzed data and of the relationship between programming languages and code qualityâ€”such as the impact of project-specific characteristics other than the used programming language.The high-level conclusions of our exercise will be that Bayesian statistical techniques can be applied to analyze software engineering data in a way that is principled flexible and leads to convincing results that inform the state-of-the-art while highlighting the boundaries of its validity. The guidelines can support building solid statistical analyses and connecting their results. Thus they can help buttress continued progress in empirical software engineering research.;
Software Engineering Research at the International Conference on Software Engineering in 2016;"With the goal of helping software engineering researchers understand how to improve their papers Mary Shaw presented Writing Good Software Engineering Research Papers"" in 2003. Shaw analyzed the abstracts of the papers submitted to the 2002 International Conference of Software Engineering (ICSE) to determine trends in research question type contribution type and validation approach. We revisit Shaw's work to see how the software engineering research community has evolved since 2002. The goal of this paper is to aid software engineering researchers in understanding trends in research question design research question type and validation approach by analyzing the abstracts of the papers submitted to ICSE 2016. We implemented Shaw's recommendation for replicating her study through the use of multiple coders and the calculation of inter-rater reliability and demonstrate that her approach can be repeated. Our results indicate that reviewers have increased expectations that papers have solid evaluations of the research contribution. Additionally the 2016 results include at least 17% mining software repository (MSR) papers a category of papers not seen in 2002. The advent of MSR papers has increased the use of generalization/characterization research questions the production of empirical report contribution and validation by evaluation.""";
On a Factorial Knowledge Architecture for Data Science-powered Software Engineering;Given the data-intensive and collaborative trend in science the software engineering community also pays increasing attention to obtaining valuable and useful insights from data repositories. Nevertheless applying data science to software engineering (e.g. mining software repositories) can be blindfold and meaningless if lacking a suitable knowledge architecture (KA). By observing that software engineering practices are generally recorded through a set of factors (e.g. programmer capacity different environmental conditions etc.) involved in various software project aspects we propose a factor-based hierarchical KA of software engineering to help maximize the value of software repositories and inspire future software data-driven studies. In particular it is the organized factors and their relationships that help guide software engineering knowledge mining while the mined knowledge will in turn be indexed/managed through the relevant factors and their interactions. This paper explains our idea about the factorial KA and concisely demonstrates a KA component i.e. the early-version KA of software product engineering. Once fully scoped this proposed KA will supplement the well-known SWEBOK in terms of both the factor-centric knowledge management and the coverage/implication of potential software engineering knowledge.;
Proceedings of the 2020 4th International Conference on Software and E-Business;Teaming is a core component in practically all professional software engineering careers and as such is a key skill taught in many undergraduate Computer Science programs. However not all teams manage to work together effectively and in education this can deprive some students of successful teaming experiences. In this work we seek to gain insights into the characteristics of successful and unsuccessful undergraduate student teams in a software engineering course. We conduct semi-structured interviews with 18 students who have recently completed a team-based software engineering course to understand how they worked together what challenges they faced and how they tried to overcome these challenges. Our results show that common problems include communicating setting and holding to deadlines and effectively identifying tasks and their relative difficulty. Additionally we find that self-reflection on what is working and not working or external motivators such as grades help some but not all teams overcome these challenges. Finally we conclude with recommendations for educators on successful behaviours to steer teams towards and recommendations for researchers on future work to better understand challenges that teams face.;
Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1;Contracts are agreements between parties engaging in economic transactions. They specify deontic modalities that the signatories should be held responsible for and state the penalties or actions to be taken if the stated agreements are not met. Additionally contracts have also been known to be source of Software Engineering (SE) requirements. Identifying the deontic modalities in contracts can therefore add value to the Requirements Engineering (RE) phase of SE. The complex and ambiguous language of contracts make it difficult and time-consuming to identify the deontic modalities (obligations permissions prohibitions) embedded in the text. State-of-art neural network models are effective for text classification however they require substantial amounts of training data. The availability of contracts data is sparse owing to the confidentiality concerns of customers. In this paper we leverage the linguistic and taxonomical similarities between regulations (available abundantly in the public domain) and contracts to demonstrate that it is possible to use regulations as training data for classifying deontic modalities in real-life contracts. We discuss the results of a range of experiments from the use of rule-based approach to Bidirectional Encoder Representations from Transformers (BERT) for automating the classification of deontic modalities. With BERT we obtained an average precision and recall of 90% and 89.66% respectively.;
Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Identification and eradication of waste are the principal emphases of lean thinking. Waste is defined as any activity that consumes resources but does not deliver any value to the stakeholder and it can also be demarcated as an impediment to process flow. Lean thinking has been applied in the software engineering domain concerning overall software development however still there is a need to take action regarding waste identification and elimination concerning specific software engineering activities. This paper describes the wastes generated during Modern Code Review (MCR). MCR is a socio-technical software engineering activity and acknowledged as a lightweight process for defect identification code improvement and software quality enhancement. It involves coordination and communication among multiple software engineers having different personalities preferences and technical skills thus it can generate multiple types of wastes. Therefore the study has two objectives that are to recognize and report various wastes generated during MCR and to map the identified MCR wastes on the existing software engineering wastes. Systematic Literature Review and grounded theory has been utilized to recognize and produce a unique list of the waste generated during MCR. The identified unique list of MCR wastes and their mapping on existing software engineering wastes are validated through software engineering experts. The study findings report 28 unique wastes out of which 25 wastes map to the existing software engineering wastes. However 3 wastes such as negative emotions inequality/biasness and insignificant feedback are not reported in the existing software engineering literature. The study will be useful for researchers to identify the wastes in same context or for other software engineering activities and to provide the strategies to minimize the generation of identified wastes.;
Proceedings of the 3rd International Conference on Software Engineering and Information Management;Students' experience with software testing in undergraduate computing courses is often relatively shallow as compared to the importance of the topic. This experience report describes introducing industrial-strength testing into CMPSC 156 an upper division course in software engineering at UC Santa Barbara. We describe our efforts to modify our software engineering course to introduce rigorous test-coverage requirements into full-stack web development projects requirements similar to those the authors had experienced in a professional software development setting. We present student feedback on the course and coverage metrics for the projects. We reflect on what about these changes worked (or didn't) and provide suggestions for other instructors that would like to give their students a deeper experience with software testing in their software engineering courses.;
Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1;For a long time the teaching of Software Engineering (SE) has been carried out in a traditional way without taking into account relevant aspects of the student's personality reflected in their learning. There is still a lack of research focused on SE that promotes adequate teaching methods so that new generations of students and future professionals have a humanistic critical and reflexive formation. A novel teaching method called Thinking-based Learning (TBL) was proposed to develop effective thinking in students using thinking skills habits of the mind and the metacognition during the teaching of subject content. The action research as a methodology to improve their teaching practices in education has been seen as a positive change in educational practices. The aim of this research was to perform an action research based on TBL method to assist in the development of competencies that are less attended by traditional methods currently used during the teaching and learning process of students in SE. Moreover a Systematic Literature Review (SLR) was conducted to identify gaps in the contribution of teaching methods in SE until the present. The data are obtained by comparing the competencies achieved with TBL with the traditional methods previously used in the discipline and additionally with the data obtained from the SLR. The results indicated that critical thinking autonomy problem solving and creativity were the most developed competencies by students during the course period. We are planning to expand the TBL and applying it in other disciplines of the same course as well as in other research areas to determine its functionality and interdisciplinarity. We hope that this experience with TBL will encourage the development of competencies among SE teachers.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;"Context: gamification has been used to motivate and engage participants in software engineering education and practice activities. Problem: There is a significant demand for empirical studies for the understanding of the impacts and efficacy of gamification. However the lack of standard procedures and models for the evaluation of gamification is a challenge for the design comparison and report of results related to the assessment of gamification approaches and its effects. Goal: The goal of this study is to identify models and strategies for the evaluation of gamification reported in the literature. Method: To achieve this goal we conducted a systematic mapping study to investigate strategies for the evaluation of gamification in the context of software engineering. We selected 100 primary studies on gamification in software engineering (from 2011 to 2020). We categorized the studies regarding the presence of evaluation procedures or models for the evaluation of gamification the purpose of the evaluation the criteria used the type of data instruments and procedures for data analysis. Results: Our results show that 64 studies report procedures for the evaluation of gamification. However only three studies actually propose evaluation models for gamification. We observed that the evaluation of gamification focuses on two aspects: the evaluation of the gamification strategy itself related to the user experience and perceptions and the evaluation of the outcomes and effects of gamification on its users and context. The most recurring criteria for the evaluation are engagement"" ""performance"" ""satisfaction"" and ""motivation"". Finally the evaluation of gamification requires a mix of subjective and objective inputs and qualitative and quantitative data analysis approaches. Depending of the focus of the evaluation (the strategy or the outcomes) there is a predominance of a type of data and analysis.""";
Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training;It is vital for educators to teach learners in accordance with their aptitude which can be useful to help learners reach their full potential. Educators have been taking the Myers-Briggs Type Indicator (MBTI) as a powerful tool to understand the differences in studentsâ€™ learning styles adopting appropriate teaching strategies to accommodate the learning styles of different types of students can effectively prevent students from being tired of studying. It is a problem worthy of research to recognize the studentsâ€™ personality traits with technological means. Therefore we propose a method to recognize learnersâ€™ MBTI from videos which can be applied in the course learning and practice stages of software engineering education. We propose a novel approach to recognize the MBTI personality traits of learners from videos. Personality and emotion unconsciously affect facial expression the speaking style in social contexts. However in the current literature there is no publicly available source of images dataset labeled with the MBTI personality scale nearly all the available data are text. In this paper we use two datasets: images extracted from ChaLearn First Impressions dataset and the Myer-Briggs Personality Type Dataset from Kaggle for our training tasks. Furthermore we take plentiful text data labeled with the MBTI personality scale as the source domain and image data as the target domain for borrowing knowledge from the source domain to facilitate the learning task in a target domain. By adopting feature transfer a bridge is built between the source domain and the target domain. We perform experiments on the transfer task and evaluate the effectiveness of this approach the results of this study can assist educators in regards to the identification of learnersâ€™ MBTI personality types in a new way.;
Proceedings of the ACM Turing Award Celebration Conference - China;The rapid pace with which software needs to be built together with the increasing need to evaluate changes for end users both quantitatively and qualitatively calls for novel software engineering approaches that focus on short release cycles continuous deployment and delivery experiment-driven feature development feedback from users and rapid tool-assisted feedback to developers. To realize these approaches there is a need for research and innovation with respect to automation and tooling and furthermore for research into the organizational changes that support flexible data-driven decision-making in the development lifecycle. Most importantly deep synergies are needed between software engineers managers and data scientists. This paper reports on the results of the joint 5th International Workshop on Rapid Continuous Software Engineering (RCoSE 2019) and the 1st International Workshop on Data-Driven Decisions Experimentation and Evolution (DDrEE 2019) which focuses on the challenges and potential solutions in the area of continuous data-driven software engineering.;
The Role of Rapid Reviews in Supporting Decision-Making in Software Engineering Practice;Context: Recent work on Evidence Based Software Engineering (EBSE) suggests that systematic reviews lack connection with Software Engineering (SE) practice. In Evidence Based Medicine there is a growing initiative to address this kind of problem in particular through what has been named as Rapid Reviews (RRs). They are adaptations of regular systematic reviews made to fit practitioners constraints.Goal: Evaluate the perceptions from SE practitioners on the use of Rapid Reviews to support decision-making in SE practice.Method: We conducted an Action Research to evaluate RRs insertion in a real-world software development project.Results: Our results show that practitioners are rater positive about Rapid Reviews. They reported to have learned new concepts reduced time and cost of decision-making improved their understanding about the problem their facing among other benefits. Additionally two months after the introduction of the Rapid Review in a follow up visit we perceived that the practitioners have indeed adopted the evidence provided.Conclusions: Based on the positive results we obtained with this study and the experiences reported in medicine we believe RRs could play an important role towards knowledge transfer and decision-making support in SE practice.;
Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018;Software information sites (e.g. Jira Stack Overflow) are now wide-ly used in software development. These online platforms for collaborative development preserve a large amount of Software Engineering (SE) texts. These texts enable researchers to detect developersâ€™ attitudes toward their daily development by analyzing the sentiments expressed in the texts. Unfortunately recent works reported that neither off-the-shelf tools nor SE-specified tools for sentiment analysis on SE texts can provide satisfying and reliable results. In this paper we propose to incorporate pre-trained transformer models into the sentence-classification oriented deep learning framework named TextCNN to better capture the unique expression of sentiments in SE texts. Specifically we introduce an optimized BERT model named RoBERTa as the word embedding layer of TextCNN along with additional residual connections between RoBERTa and TextCNN for better cooperation in our training framework. An empirical evaluation based on four datasets from different software information sites shows that our training framework can achieve overall better accuracy and generalizability than the four baselines.;
Proceedings of the 13th Asia-Pacific Symposium on Internetware;Software development is a collaborative task and hence involves different persons. Research has shown the relevance of social aspects in the development team for a successful and satisfying project closure. Especially the mood of a team has been proven to be of particular importance. Thus project managers or project leaders want to be aware of situations in which negative mood is present to allow for interventions. So-called sentiment analysis tools offer a way to determine the mood based on text-based communication. In this paper we present the results of a systematic literature review of sentiment analysis tools developed for or applied in the context of software engineering. Our results summarize insights from 80 papers with respect to (1) the application domain (2) the purpose (3) the used data sets (4) the approaches for developing sentiment analysis tools and (5) the difficulties researchers face when applying sentiment analysis in the context of software projects. According to our results sentiment analysis is frequently applied to open-source software projects and most tools are based on support-vector machines. Despite the frequent use of sentiment analysis in software engineering there are open issues e.g. regarding the identification of irony or sarcasm pointing to future research directions.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;This experience report presents the summary outcomes and experiences of the 2nd Workshop on Emerging Software Engineering Education (WESEE) co-located with Innovations in Software Engineering Conference (ISEC 2019) which was held on 14th February 2019 at College of Engineering Pune (India). WESEE is an activity-oriented workshop and consists of an expert talk two hands-on activities and an open discussion session. We have collected a variety of data from the participants while conducting the two activities namely 'wall of ideas' and 'design thinking'. We analyze the data gathered in the form of sticky notes responses to worksheets documented ideas and feedback sheets. The data helped us to determine whether the workshop was successful and simultaneously we can plan for the next edition of the workshop by incorporating the feedback.;
Teaching Software Engineering Tools to Undergraduate Students;Today software development is characterized by keywords such as collaborative teamwork distributed agile dynamic qualitative and tool-supported among many others. In this paper we present our experience in teaching three software development tools often used in industry in a software engineering course for undergraduate students: GitHub SonarQube and Microsoft Project. The main reasons behind the use of these tools during the development of a software project were: (1) students become familiar with examples of tools adopted in industry and academia (2) students are enabled to collaborate in teams for the achievement of a common goal and (3) students become aware of the management tasks needed by a project developed in teams. We exploited these tools in the software engineering course in the last three academic years. The students feedback on using these tools gathered through a questionnaire was positive. Students were enthusiastic in learning about new tools and their support for software development and management. In this paper we summarize the students feedback during three academic years and the lessons we have learned from their feedback.;
Proceedings of the 11th International Conference on Education Technology and Computers;Online sports betting is a $50B industry that is heavily driven by software. The domain imposes significant demands on developers: the resulting solutions are large complex distributed concurrent software systems with strict availability real-time performance scalability reliability and security requirements. This paper describes our experience with EmpireBet a family of online sports betting platforms built and deployed over the past 15 years. The initial solution implemented by four developers in a start-up catered to users who connected to the system intermittently for limited periods via dial-up connections. Todayâ€™s system engineered and maintained in 27 programming and markup languages by a team of 20 developers is deployed in over 30 countries integrated with over 50 third-party systems and processes tens of millions daily transactions by over 680000 players who are continuously using the system. This was accomplished via an an explicit focus on EmpireBetâ€™s critical non-functional requirements a modular extensible architecture a set of novel abstractions we introduced into the system and several reusable libraries developed in the process.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;In the teaching of software engineering for computer related majors there is a gap between high-level logic design and implementation which leads to the students' unreasonable software design and the implementation code does not follow the design scheme. Therefore it is necessary to carry out heuristic teaching for students starting from the programming students are most familiar with gradually transition to software design using reverse thinking teaching mode so that students can master the transformation relationship between design and implementation. In the implementation of case teaching it is necessary to restore high-level design or demand analysis through code realize the conversion from code to document and effectively improve the theoretical level of students in terms of practical skills implement task driven teaching deepen the understanding of cases and knowledge transfer and exercise the practical ability of students. Through the performance analysis of 2015 and 2016 students the reverse engineering case teaching and task driven practice can significantly improve students' practical ability stimulate students' enthusiasm for software development and highlight students' software development ability in computer skills competition college students' innovation training project and graduation design.;
Proceedings of the 2021 6th International Conference on Distance Education and Learning;Robotic systems have been increasingly employed in everyday tasks. Considering that software plays a crucial point in robot systems to investigate how software engineering concepts in a software quality perspective can improve robotic systems. In this work we present a systematic mapping to identify and classify the state-of-art of software engineering for robotic systems in a quality software perspective. We selected and systematically analyzed a final set of 35 primary studies extracted from an automated search on Scopus digital library.This work presents three main contributions. Firstly we organize a catalogue of research studies about software engineering more specifically software quality applied in robotic systems. Next we systematically analyze software quality areas used in robotic systems. Finally we discuss insights into research opportunities and gaps in software engineering to robotic systems for future studies.As a result we observed that there are studies in the robotic systems area addressing in a combined way software engineering approaches and software quality aspects. The less investigated software quality aspect is security. Due to this fact we presented an overview of the state-of-art on blockchain applying in robotics systems. Blockchain brings opportunities for changing the ways that robots interact with humans. Finally we identify research opportunities and gaps in software quality on robotic systems presenting an overview for future studies.;
Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops;Execution logs capture the run-time behavior of software systems. To assist developers in their maintenance tasks many studies have proposed tools to analyze execution information from logs. However it is as yet unknown how industry developers analyze logs in embedded software engineering.In order to bridge the gap we study how developers analyze logs by interviewing 25 software developers from ASML which is a leading company in developing lithography machines. In particular we explore the type of logs developers analyze the purposes for which developers analyze logs the information developers need from logs and their expectation on tool support. As the main contribution we observed that the lack of domain knowledge lack of familiarity with code base and software design and presence of concurrency raise major challenges in log analysis for such complex and multidisciplinary systems. Particularly we observed that inspecting execution information at different levels of abstraction is useful to develop comprehension of such complex systems. However obtaining the abstraction is difficult with current tools. Our study has several implications. The empirical evidence provided by our study implies the need to support log inspection and comparison with multiple levels of abstraction categorize log differences and recover links between different types of logs.;
Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice;We wish to change developers' behaviors to increase software engineering efficiency and the previous research shows that gamification method can change user's behaviors. Gamification has become a popular topic in many areas including software engineering. We sum up some pairs of gamification features which can influence people's specific behavior like engagement. Thus we build a general gamification processing model for software development life cycle. Also we built a metrics model of software engineers' contribution based on gamification processing model for gamifying software engineer's contribution. The next step we will gamify the contribution of software engineers to change engineer's behaviors for converting junior software engineers to senior software engineers.;
Proceedings of the 2020 4th International Conference on Management Engineering Software Engineering and Service Sciences;"Context: With the growing popularity of rapid software delivery and deployment the methods practices and technologies of Continuous Software Engineering (CSE) are evolving steadily. This creates the need for understanding the recent trends of the technologies practitioners' challenges and views in this domain. Objective: In this paper we present an empirical study aimed at exploring CSE from the practitioners' perspective by mining discussions from Q&ampA websites. Method: We have analyzed 12989 questions and answers posted on Stack Overflow. Topic modelling is conducted to derive the dominant topics in this domain. Further a qualitative analysis was conducted to identify the key challenges discussed. Findings: Whilst the trend of posted questions is sharply increasing the questions are becoming more specific to technologies and more difficult to attract answers. We identified 32 topics of discussions among which Error messages in Continuous Integration/Deployment"" and ""Continuous Integration concepts"" are the most dominant. We also present the most challenging areas in this domain from the practitioners' perspectives.""";
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;The global pandemic of COVID19 demanded that professors rethink teaching strategies considering the use of online environments due to the social isolation stipulated to reduce the rate of contagion of the disease. A challenge for software engineering professors is to develop fundamental professional skills in students who are in the process of learning using these virtual environments. The purpose of this study is to identify how an online educational hackathon can support students of a Software Engineering program to develop professional skills. We also seek to understand how intense collaboration takes place between student teams considering the digital context for the production of a technological solution. We conducted a Case Study on an educational hackathon that took place in the online context collecting data through questionnaires interviews and observations. As some results the skills that students most considered that this hackathon helped them to develop were communication initiative and creativity/innovation among others. Also the strategies of collaboration adopted by the students during this competition considering the remote context. Therefore the main contribution is the identification of how the realization of this event supported students to develop professional skills and to practice collaboration skills with each other.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;Artificial intelligence is predicted to impact many industries (including the software industry) changing how we produce manufacture and deliver. The rise of artificial intelligence may significantly transform the practice of software engineering helping us build better software faster.;
Scrum Based Framework for Teaching Software Engineering for Game Development;This paper proposes a scrum-based game development framework (GDF) to teach students software engineering concepts essential for video game development. It proposes adaptations to the Scrum management framework to iterate through the game design and development process from concept to completion. The proposal converts a theoretical software engineering course into a project-oriented course to better prepare the students for industry demands. A learn by doing approach is followed to allow students to apply current and previously learned knowledge to design and develop a video game in a studio-like environment.;
Proceedings of the 2020 2nd International Conference on Video Signal and Image Processing;From tectonic plate to F-16.;
The State of the Art on Secure Software Engineering: A Systematic Mapping Study;"Secure Software Development (SSD) is becoming a major challenge due to the increasing complexity openness and extensibility of Information and Communication Technologies (ICTs). These make the overall security requirements analysis very difficult. Many techniques have been theoretically developed however there is a lack of empirical evidence of its application in building secure software system. A Systematic Mapping Study (SMS) has been conducted in this paper to examine the existence of software security frameworks models and methods. In total we selected 116 primary studies. After examining the selected studies we identified 37 Secure Software Engineering (SSE) paradigms/frameworks/models. The results show that the most frequently used SSE frameworks/models are Microsoft Software Development Life Cycle (MS-SDL)"" ""Misuse case modeling"" ""Abuse case modeling"" ""Knowledge Acquisition for Automated Specification"" ""System Security Engineering-Capability Maturity Model (SSE-CMM)"" and ""Secure Tropos Methodology"". This work will help organizations in the development of software to better understand existing security initiatives used in the development of secure software. It can also provide researchers with a basis for designing and developing new methods of software security and identifying new axis of research.""";
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;Bots automate many tasks in software engineering projects often in the form of chatbots. Bots have been proposed for example for testing maintenance or automating bug fixes. Following the success of the first BotSE workshop we organized this second edition collocated with ICSE 2020 to bring together the research community that investigates bots for software engineering. Specifically the workshop's goal was to share experiences and challenges discuss new types of bots and map out future directions. The workshop program comprised the presentation of 8 papers and 2 keynotes followed by extensive discussion. Overall the community matured by discussing how to design build and evaluate bots. The community aims to organise a 3rd edition of the workshop. Website: http://botse.org/;
FLOSS in Software Engineering Education: Supporting the Instructor in the Quest for Providing Real Experience for Students;Software engineering courses play an important role in computer science programs and are expected to provide the required basic knowledge and skills for professional practice in software industry. However teaching software engineering principles concepts and practices and relating them to real-world scenarios are challenging tasks. The adoption of open source software projects may address such challenges. In this paper we report on an experience of the teaching object-oriented modeling with Unified Modeling Language (UML) Class Diagrams using open source projects. We conducted a case study with students of the software engineering discipline of the Computer Science course. We supported the instructor in some activities related to syllabus planning including the selection of a Free/Libre/Open Source Software (FLOSS) projects and the creation of examples to be used in the classroom. The instructor selected and used a small FLOSS project to support the modeling activities. Then the instructor applied an evaluation activity and a perception questionnaire about the methodology used. After the end of the classes we conducted an interview with the instructor to present a brief report of his experience in the classroom. In the perception of students the experience with FLOSS projects enhanced their ability to handle real projects and third-party code and to deal with the job market. They also reported developing skills such as proactivity and communication. From the instructor's perspective the group was enthusiastic and dynamic and interacted more during practical activities.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;In an age of geographically distributed software development teams international communication skills are becoming ever more important to IT students. During the Covid-19 pandemic contact and travel restrictions have made it almost impossible for students to gain international experience by spending a semester in a foreign country. One possible solution is to conduct distributed courses in software engineering as a virtual cooperation between two universities. Experiences gained during a hybrid distributed course on global software engineering are presented. The challenges encountered when coordinating a course that takes place simultaneously in two countries are reported. Feedback from students and professors are discussed and recommendations for future work are derived from these lessons learned.;
Proceedings of the 8th International Conference on Frontiers of Educational Technologies;With the development and widespread of digital technologies ev- eryday life has been profoundly transformed. The general public as well as specialized audiences have to face an ever-increasing amount of knowledge and learn new abilities. The EASEAI work- shop series addresses that challenge by looking at software en- gineering education and arti cial intelligence research elds to explore how they can be combined. Speci cally this workshop brings together researchers teachers and practitioners who use advanced software engineering tools and arti cial intelligence tech- niques in the education eld and through a transgenerational and transdisciplinary range of students to discuss the current state of the art and practices and establish new future directions. More information at https://easeai.github.io.;
Shifting traditional undergraduate software engineering instruction to a DevOps focus;Classical Software Engineering education often includes traditional methodologies that do not adequately describe today's industry practice. DevOps is a culture that promotes fast delivery continuous feedback and an environment of learning. Its non-linear path requires a shift in software engineering pedagogy. This case study describes the redevelopment of a second-semester course in software engineering to focus on DevOps principles. The study evaluates student performance using formative and summative assessment through a team project tracked throughout the semester and final exam results. Results indicated that students developed DevOps skills during the course but may have needed more reinforcement of some traditional Software Engineering topics.;
Software Engineering for Smart Cyber-Physical Systems (SEsCPS 2018) - Workshop Report;Smart Cyber-Physical Systems (sCPS) are a novel kind of Cyber- Physical System engineered to take advantage of large-scale cooperation between devices users and environment to achieve added value in the face of uncertainty and changing environments. Examples of sCPS include modern traffic systems Industry 4.0 systems systems for smart buildings and smart energy grids. The uniting aspect of all these systems is that to achieve their high level of intelligence adaptivity and ability to optimize and learn they rely heavily on software. This makes them software-intensive systems where software becomes their most complex part. Engineering sCPS thus becomes a recognized software engineering discipline which due to specifics of sCPS can only partially rely on the existing body of knowledge in software engineering. In fact it turns out that many of the traditional approaches to architecture modeling and software development fall short in their ability to cope with the high dynamicity and uncertainty of sCPS. This calls for innovative approaches that jointly reflect and address the specifics of such systems. This paper maps the discussions and results of the Fourth International Workshop on Software Engineering for Smart Cyber-Physical Systems (SEsCPS 2018) which focuses on challenges and promising solutions in the area of software engineering for sCPS.;
The ABC of Software Engineering Research;A variety of research methods and techniques are available to SE researchers and while several overviews exist there is consistency neither in the research methods covered nor in the terminology used. Furthermore research is sometimes critically reviewed for characteristics inherent to the methods. We adopt a taxonomy from the social sciences termed here the ABC framework for SE research which offers a holistic view of eight archetypal research strategies. ABC refers to the research goal that strives for generalizability over Actors (A) and precise measurement of their Behavior (B) in a realistic Context (C). The ABC framework uses two dimensions widely considered to be key in research design: the level of obtrusiveness of the research and the generalizability of research findings. We discuss metaphors for each strategy and their inherent limitations and potential strengths. We illustrate these research strategies in two key SE domains global software engineering and requirements engineering and apply the framework on a sample of 75 articles. Finally we discuss six ways in which the framework can advance SE research.;
Incorporating real projects into a software engineering undergraduate curriculum;Software engineering researchers and practitioners are increasingly more concerned about non-technical issues like user involvement and interaction as a way to improve software development process efficiency. This issue is also present in software engineering education. The IEEE/ACM software engineering guidelines highlights that an undergraduate course in this matter should have a real-world basis. In this paper we present an undergraduate program that connect students with real-world projects throughout their studies. To evaluate educational results we performed a survey with 111 students from this software engineering program. The results indicate that students in the end of this program has a much better chance of taking users' desires into consideration instead of focusing on software implementation.;
Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings;Training existing and future software project managers presents a challenge to the academic community. Software project management is usually taught as part of software engineering bachelor or master programs which are generally based on SWEBOK. However evidence shows that even when SWEBOK provides some software project management knowledge it is not enough to satisfy the software industry requirements. On the other hand the Software Extension to the PMBOK Guide was recently published. The extension complements the original PMBOK with software specific contents so it constitutes valuable referential information for software project managers. This paper describes a smooth transition to enrich our traditional software engineering curricula based on SWEBOK with specific software project management knowledge. To that end we identify which software project management knowledge suggested by the Software Extension to the PMBOK provides special added value to the SWEBOK contents. The results can be useful for academia but also for software engineering practitioners that can identify training opportunities to complement their SWEBOK background.;
Proceedings of the 38th International Conference on Software Engineering Companion;Background: Despite the mutual benefit of the industry-academia partnership the level of joint work is still low. For this reason the interest in connecting research and practice has increased recently in the academic community. Objective: This research aims to design and apply approaches to improve the knowledge exchange between academic researchers and software engineering practitioners. Methodology: This work can be seen from a design science perspective. Following the design-science paradigm the knowledge regarding a phenomenon is obtained through the design and evaluation of solutions that apply in a specific context. Consequently this research work proposes and evaluates approaches to bridge the communication gap. Results: Two approaches have been explored and partially evaluated. The SERP-taxonomy architecture that can be used to describe and link research results and industry challenges and rapid reviews to foster communication between industry and academia. Conclusion: This thesis will provide empirical evidence of the application of collaborative approaches to improve industry-academia communication and get closer research and practice.;
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;There is a long-standing challenge to narrow the gap between software engineering research and industry practice to align their interests and realize true synergies between the two communities. Some difficulties to this challenge include mismatched agendas priorities and expectations from the research collaboration on both sides. To overcome these difficulties an initial step is to gain a clearer understanding of collaboration challenges from both perspectives. With this goal in mind we organized the 5th International Workshop on Software Engineering Research and Industrial Practice collocated with the International Conference on Software Engineering 2018. The workshop featured two keynote talks one from industry and one from academia followed by paper presentations and a round-table discussion session. Here we summarize experiences shared by the keynotes from industry and academia along with findings from paper presentations and overall discussions by workshop participants on the ways of aligning software engineering research and industry practice.;
Towards concept based software engineering for intelligent agents;The development of AI and machine learning applications at an industry mature level while maintaining quality and productivity goals is one of today's major challenges. Research in the field of intelligent agents has achieved many successes in recent years especially due to various reinforcement learning techniques and promises a high benefit in times of automation and autonomous systems. Bringing them into production however requires optimization against many other criteria than just accuracy. This leads to the emerging field of machine teaching. We already know many of the objectives used there from software engineering research which has led to many well-established principles in recent decades. One of them is the component-based development whose idea finds an interesting counterpart in hierarchical reinforcement learning. We show that both areas can benefit from each other and introduce our approach of concept based software engineering which is focused on supporting productivity and quality goals during the development of such systems.;
Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering;Software applications have grown increasingly complex to deliver the features desired by users. Software modularity has been used as a way to mitigate the costs of developing such complex software. Active learning-based program inference provides an elegant framework that exploits this modularity to tackle development correctness performance and cost in large applications. Inferred programs can be used for many purposes including generation of secure code code re-use through automatic encapsulation adaptation to new platforms or languages and optimization. We show through detailed examples how our approach can infer three modules in a representative application. Finally we outline the broader paradigm and open research questions.;
Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas New Paradigms and Reflections on Programming and Software;There is a gap between the abstract concepts taught in the classroom and the skills needed for students to succeed once they join the workplace. The Undergraduate Capstone Open Source Projects (UCOSP) program was developed to narrow this gap by enabling undergraduate computer science students to have an experiential software engineering learning opportunity. Over the past 8 years 737 students from 30 universities have taken part in this program.In this paper we sought to understand student perceptions of how UCOSP complements traditional classwork by providing real-world software engineering exposure. We report on a qualitative analysis of 2203 quotes collected from 167 students from 18 universities over six academic terms. We analyzed these data using a grounded theory approach based on open coding to gain insight into the key benefits of the program from the students' perspective. We found that students highly value being able to apply their classroom knowledge to real novel tasks for real projects with a community of users while receiving real mentorship from a member of the development team. Further we found that contributing to real software systems provides greater understanding of software engineering than might otherwise be obtained through more traditional means.Our goal is that our analysis can help fellow educators add additional experimentalism into their existing programs.;
Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training;This experience report describes the delivery of round-the-clock help to students using Discord (a popular messaging and voice/video calling platform) in a remote software engineering course. Students in the course learn full-stack web development using Ruby on Rails and PostgreSQL and work in teams to develop web applications. Our central goal in offering round-the-clock help using Discord was to increase the amount of help that students receive from teachers (i.e. teaching assistants and the instructor). Indeed we found that our 24/7-Discord approach led to a considerable increase in the amount of student-teacher interaction versus the approach used previously which emphasized in-person office hours and a question-and-answer forum in Piazza. Moreover students from underrepresented groups in computer science interacted with teachers at a rate comparable to other students and we received consistently positive feedback from students regarding the approach. We also made several key observations about when students tended to seek help including that they sought help the most between 7:00 p.m. and midnight that help seeking spiked right before deadlines that students posted the fewest help messages on weekends and that students posted significantly more messages during the first half of the course which emphasized skills assignments versus the second half which focused on team project work.;
Proceedings of the 53rd ACM Technical Symposium on Computer Science Education - Volume 1;Background. The increasing reliance on applications with machine learning (ML) components calls for mature engineering techniques that ensure these are built in a robust and future-proof manner.Aim. We aim to empirically determine the state of the art in how teams develop deploy and maintain software with ML components.Method. We mined both academic and grey literature and identified 29 engineering best practices for ML applications. We conducted a survey among 313 practitioners to determine the degree of adoption for these practices and to validate their perceived effects. Using the survey responses we quantified practice adoption differentiated along demographic characteristics such as geography or team size. We also tested correlations and investigated linear and non-linear relationships between practices and their perceived effect using various statistical models.Results. Our findings indicate for example that larger teams tend to adopt more practices and that traditional software engineering practices tend to have lower adoption than ML specific practices. Also the statistical models can accurately predict perceived effects such as agility software quality and traceability from the degree of adoption for specific sets of practices. Combining practice adoption rates with practice importance as revealed by statistical models we identify practices that are important but have low adoption as well as practices that are widely adopted but are less important for the effects we studied.Conclusion. Overall our survey and the analysis of responses received provide a quantitative basis for assessment and step-wise improvement of practice adoption by ML teams.;
Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Informal technology 'meetups' have become an important aspect of the software development community engaging many thousands of practitioners on a regular basis. However although local technology meetups are well-attended by developers little is known about their motivations for participating the type or usefulness of information that they acquire and how local meetups might differ from and complement other available communication channels for software engineering information. We interviewed the leaders of technology-oriented Meetup groups and collected quantitative information via a survey distributed to participants in technology-oriented groups. Our findings suggest that participants in these groups are primarily experienced software practitioners who use Meetup for staying abreast of new developments building local networks and achieving transfer of rich tacit knowledge with peers to improve their practice. We also suggest that face to face meetings are useful forums for exchanging tacit knowledge and contextual information needed for software engineering practice.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering;The development of soft skills is essential for future software engineers since the development process requires creativity communication and problem-solving skills. Instructors can adapt pedagogical strategies to train students' soft skills and the technical knowledge needed for the profession. Design Thinking (DT) is a methodology that promotes the production of creative and innovative software solutions. Teaching DT in Software Engineering (SE) courses can promote students with an interdisciplinary teaching practice that stimulates soft skills to understand and explore problems and design innovative software solutions. This paper presents research exploring how DT provides practical experiences and it supports the development of students' soft skills from SE courses. We proposed and developed a dynamic based on the DT phase that simulates practical situations of a software project. The students' perceptions of the dynamics were analyzed qualitatively. The results showed that the dynamics promoted practical experiences and the development of soft skills such as problem-solving creativity teamwork diversity and critical thinking.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;This paper discusses the results of partially replicating and modifying a study performed by Zingaro and Porter examining the relationship between fine grained clicker data from in class Peer Instruction and students' performance in quizzes and exams. Whereas Zingaro and Porter worked with a CS1 course we worked with a sophomore software engineering course. We report overall answer correctness when students vote before and after PI discussion track student response patterns from in-class to the quizzes and exam and quantify absolute percentages of students that demonstrate longer-term learning from the PI process. Our results show that students who learn in class from PI perform well on the quizzes and the final exam nearly as well as those who understood concepts prior to the classes in which those concepts were taught. We also found that those who fail to learn from the PI process in the class perform worse on quizzes and the final exam. We found PI to be an effective way to teach our software engineering course based on student learning before and after PI a result unique to our study. Our results were consistent across the different topics in software engineering in which we employed PI.;
Proceedings of the 52nd ACM Technical Symposium on Computer Science Education;"Practitioners and researchers study best practices to develop and maintain ML application systems and software to address quality and constraint problems. Such practices are often formalized as software patterns. We discovered software-engineering design patterns for machine-learning applications by doing a thorough search of the literature available on the subject. Among the ML patterns found we describe three ML patterns in the standard pattern format so that practitioners can (re)use them in their contexts: Different Workloads in Different Computing Environments"" ""Encapsulate ML Models Within Rule-base Safeguards"" and ""Data Flows Up Model Flows Down""""";
Proceedings of the 27th Conference on Pattern Languages of Programs;Object-orientation (OO) is a key concept of current software development approaches. Most of the students who start their studies in the field of computer science have no prior software engineering experience.A programming course implementation which only involves virtual aspects of programming can be an issue for beginners. The missing correlation of virtual objects in code and real objects in the physical world makes the learning process of object-oriented thinking more difficult.The fischertechnik Training Factory Industry 4.0 shall be used to support this learning step. The factory consists of six TXT-controllers (TXT) with ARM processors. Each of these controllers manage one specific part of the factory. An object-oriented application programming interface (API) which represents individual parts of this factory shall be developed. There shall be a 1-to-1 relationship between each factory component and the respective programming element. By letting students use this interface they can instantaneously see the consequences of their programs on the physical factory. With this learning arrangement we want students to increase their competencies in object-orientation.;
Proceedings of the 4th European Conference on Software Engineering Education;The swift advancement of computerization has resulted in an increased need for individuals skilled in a variety of highly technical fields. This demand is currently inadequately met by the United States? domestic workforce and rural areas are underserved by technological resources and opportunities. Due to political and legislative volatility fixing this workforce shortage is not feasible. Instead the long-term solution is the cultivation of domestic workforce with high technical expertise. Therefore we propose a software engineering curriculum that follows the 2 + 2 educational model to meet the needs of community college students in North Carolina as a model for similar initiatives on a regional and national scale. In this paper we discuss the current status of computer science and software engineering education in North Carolina community colleges including the current degree programs and relevant curriculum content. Finally we discuss our proposed curriculum for a 2 + 2 articulation program in software engineering.;
Proceedings of the 21st Annual Conference on Information Technology Education;The Software Engineering (SE) curriculum in undergraduate computer science (CS) education is designed to train students in the process of software and systems development. Traditionally topics such as software development methodologies industry nomenclatures and solution analysis are delivered through lectures and group projects. We propose a novel approach in teaching SE that we call MACROVR: &ltu&gtMA&lt/u&gtchine learning to select project team members &ltu&gtC&lt/u&gtloud technologies required for project control code versioning and team communications &ltu&gtRO&lt/u&gttational schedules in Agile/Scrum roles an individual &ltu&gtV&lt/u&gtideo of the team project story board and &ltu&gtR&lt/u&gtubrics for all presentations. Our teaching strategy with this approach utilizes the latest technologies currently employed in industry and corresponds to soft skills commonly assessed in interviews.The goal of our study is to measure if using the MACROVR approach contributes to preparedness for a computing job interview. Most often this course is taken towards the end of a four-year CS degree program while students are job hunting or seeking an internship in the computing industry. We use an anonymous fifteen question survey instrument sent to volunteers that indicated they are seeking a computing job and have successfully completed the SE course. The sample is comprised of three sections of the SE course using the MACROVR approach (135 students) and four sections that did not use all of the required strategies and technologies which we call MACROVR-lite (184 students). Our two cohorts MACROVR and MACROVR-lite are each given the same survey questions. We analyze their Likert scale data responses using non-parametric methods. Our findings indicate the MACROVR approach better prepares students with the skills and highly valued qualities for success in computing industry interviews.;
Proceedings of the 9th Computer Science Education Research Conference;Automated vehicles are AI-based safety-critical robots that fulfill transportation needs while interacting with the general public in traffic. Software engineering for automated vehicles requires a DevOps-style process with special considerations for functions based on machine learning and incremental safety assurance at vehicle and fleet level. This technical briefing reviews current challenges industry practices and opportunities for future research in software engineering for automated vehicles.;
Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings;Skills and competencies in entrepreneurship such as the ability to generate innovative ideas and the courage to engage with stakeholders and society have gained importance in engineering curricula. In this case study paper we report on how we have integrated entrepreneurial experiences into a software engineering project course and made the creation of value and reflection on the application of a structured process the heart and soul of the course. Based on current research on entrepreneurship education as well as the definition of entrepreneurial competencies used by the European Union we show how the learning objectives the teaching moments the integration of external stakeholders and the assessment work together to create an entrepreneurial environment in which students are encouraged and rewarded to work in an entrepreneurial way. Based on data from reflection reports course evaluations and interviews we discuss the pros and cons of our approach and how the student perception and expectations often run counter to the motivations of the course design. We thus contribute guidance for other teachers based on our own experiences in relation to the findings of our peers.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training;Failure to account for human values in software (e.g. equality and fairness) can result in user dissatisfaction and negative socio-economic impact. Engineering these values in software however requires technical and methodological support throughout the development life cycle. This paper investigates to what extent top Software Engineering (SE) conferences and journals have included research on human values in SE. We investigate the prevalence of human values in recent (2015 -- 2018) publications in these top venues. We classify these publications based on their relevance to different values against a widely used value structure adopted from the social sciences. Our results show that: (a) only a small proportion of the publications directly consider values classified as directly relevant publications (b) for the majority of the values very few or no directly relevant publications were found and (c) the prevalence of directly relevant publications was higher in SE conferences compared to SE journals. This paper shares these and other insights that may motivate future research on human values in software engineering.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering;"This paper summarizes an experience in designing and delivering a course Software Development Essentials"" a second year computer science course designed to teach software engineering skills without a project component. This paper describes the motivation design and implementation of the course.This course was offered as a pilot course that enrolled approximately 65 students at the University of Virginia. The need for the course emerged as we found many later project-centric courses assumed students already had knowledge and skills related to build configuration database usage design version control and incremental development despite none of them materials being covered in our intro programming sequence. Further in the project-centric software engineering course (typically a third-year course) students often were expected to start on a project before concepts such as design principles design patterns and incremental development were covered. Thus students were often learning these principles and techniques after they had already been working on a project for weeks and often too late to implement these into the project naturally.This course is not intended to replace a software engineering course. Rather this course is intended to prepare students for future project courses including a software engineering course. In this paper we describe our experience designing and delivering this course in the Spring semester 2020. We review both student and faculty feedback of the course and what changes may be made when this course is made available in the future to a large population of students.""";
Proceedings of the 52nd ACM Technical Symposium on Computer Science Education;Standard Reviewing Procedures The final acceptance decision for a paper can be taken by following different alternative peer-reviewing processes (these review processes are implemented for both conferences and journals). The standard setup can be described as follows: while authors are usually not aware of the reviewers' identity (so-called blind review setting) reviewers may be aware of the authors' identity or not resulting in single-blind or double-blind review processes respectively. In the rare cases when the authors are aware of the reviewers' identity the reviewing process is considered zero-blind. Other feasible alternatives are characterized by the amount of stages implemented before the acceptance decision is made (single-stage vs. multi-stage review processes) and the public visibility of review comments (open/public vs. closed review processes). The actual process of finding agreement regarding the papers' acceptance or rejection has also a certain bandwidth ranging from delegating the responsibility of the decision-making to few people over staged committee and board setups to organizing physical/virtual meetings involving many people.;
What prevents finnish women from applying to software engineering roles? a preliminary analysis of survey data;Finland is considered a country with a good track record in gender equality. Whilst statistics support the notion that Finland is performing well compared to many other countries in terms of workplace equality there are still many areas for improvement. This paper focuses on the problems that some women face in obtaining software engineering roles. We report a preliminary analysis of survey data from 252 respondents. These are mainly women who have shown an interest in gaining programming roles by joining the Mimmit koodaa initiative which aims to increase equality and diversity within the software industry. The survey sought to understand what early experiences may influence later career choices and feelings of efficacy and confidence needed to pursue technology-related careers. These initial findings reveal that women's feelings of computing self-efficacy and attitudes towards software engineering are shaped by early experiences. More negative experiences decrease the likelihood of working in software engineering roles in the future despite expressing an interest in the field.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training;Context: Continuous Software Engineering (CSE) involves a set of practices that aims at making software development continuous and integrated to business. However moving from traditional to integrated agile and data-driven software development requires changes in the organizationÂ´s culture practices and structure which may not be easy. Objective: Our focus is to help organizations get an overall view of the CSE practices they perform identify where they are in the CSE evolutionary path and which areas should be improved. Method: We created a diagnosis instrument called Zeppelin to evaluate the adoption of CSE practices and applied it in five Brazilian software organizations. Results: Zeppelin was recognized as a useful tool to help organizations have a more comprehensive view of their CSE practices and envision the evolution and improvement path they can follow. Conclusion: Zeppelin supports software development organizations to get a big picture of CSE practices and identify their position in the CSE evolution path. Moreover it contributes to identify strategies to advance software development towards a CSE environment.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;Modern software projects consist of more than just code: teams follow development processes the code runs on servers or mobile phones and produces run time logs and users talk about the software in forums like StackOverflow and Twitter and rate it on app stores. Insights stemming from the real-time analysis of combined software engineering data can help software practitioners to conduct faster decision-making. With the development of CodeFeedr a Real-time Software Analytics Platform we aim to make software analytics a core feedback loop for software engineering projects. CodeFeedr's vision entails: (1) The ability to unify archival and current software analytics data under a single query language and (2) The feasibility to apply new techniques and methods for high-level aggregation and summarization of near real-time information on software development. In this paper we outline three use cases where our platform is expected to have a significant impact on the quality and speed of decision making dependency management productivity analytics and run-time error feedback.;
Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results;"As China promotes the realization of the Carbon peaking and carbon neutrality"" goal determining the investment value of wind power projects is an important way to ensure expected investment returns and reduce investment risks. Use real options to evaluate the investment strategy of wind power investment projects and introduce the BS model and the Geske option model into the project investment decision-making analyze the investment decision-making of wind power projects by stages and the two stages of the first-phase construction and the second-phase expansion of wind power investment in compound options. This paper expounds the use of the real option model to solve the uncertainty problem in the investment decision-making of wind power projects in installments and through the analysis of actual cases the investor's delay option expansion option and compound option in wind power investment and construction are analyzed. comparative analysis of the value.""";
Proceedings of the 4th International Conference on Management Science and Industrial Engineering;"This paper considers sensemaking as it relates to everyday software engineering (SE) work practices and draws on a multi-year ethnographic study of SE projects at a large global technology company building digital services infused with artificial intelligence (AI) and machine learning (ML) capabilities. Our findings highlight the breadth of sensemaking practices in AI/ML projects noting developers' efforts to make sense of AI/ML environments (e.g. algorithms/methods and libraries) of AI/ML model ecosystems (e.g. pre-trained models and upstream"" models) and of business-AI relations (e.g. how the AI/ML service relates to the domain context and business problem at hand). This paper builds on recent scholarship drawing attention to the integral role of sensemaking in everyday SE practices by empirically investigating how and in what ways AI/ML projects present software teams with emergent sensemaking requirements and opportunities.""";
Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops;This paper makes the case for the study of human values in Software Engineering (SE) as a highly important emerging area of research with significant societal implications. We offer two key principles in order to advance this research agenda: firstly the significance of values as distinguished from though connected to ethics and secondly the need for clear theoretical frameworks for values study. We provide the emerging findings from an initial study (N=12 participants) using a Values Q-Sort tool that was designed in accordance with these two principles. We conclude with discussion around lessons learnt ongoing challenges and future directions.;
Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering;An analogy is an identification of structural similarities and correspondences between two objects. Computational models of analogy making have been studied extensively in the field of cognitive science to better understand high-level human cognition. For instance Melanie Mitchell and Douglas Hofstadter sought to better understand high-level perception by developing the Copycat algorithm for completing analogies between letter sequences. In this paper we argue that analogy making should be seen as a core primitive in software engineering. We motivate this argument by showing how complex software engineering problems such as program understanding and source-code transformation learning can be reduced to an instance of the analogy-making problem. We demonstrate this idea using Sifter a new analogy-making algorithm suitable for software engineering applications that adapts and extends ideas from Copycat. In particular Sifter reduces analogy-making to searching for a sequence of update rule applications. Sifter uses a novel representation for mathematical structures capable of effectively representing the wide variety of information embedded in software.;
Proceedings of the 2020 ACM SIGPLAN International Symposium on New Ideas New Paradigms and Reflections on Programming and Software;This work aims to investigate the relationship be- tween English language proficiency and the academic perfor- mance of students enrolled in a software engineering course. The English language proficiency was measured using a reading assessment test as well as the student grades obtained from two English courses the students took during their preparatory year. Data was collected from 63 students in the Department of Information Technology King Saud University. The results indi- cate that there is a significant but moderate positive correlation between the students proficiency in English and their academic performance in the software engineering course. The analysis also reveals that the students academic background do not play a role in their academic performance. We also find a positive correlation between the students self-perception of English abilities and their performance on the assessment test. However a negative correlation was concluded between the easiness of the test (rated by the students) and their scores.;
Proceedings of the 2021 4th International Conference on Data Storage and Data Engineering;Context: Free/Libre/Open Source Software (FLOSS) projects have been used in Software Engineering Education (SEE) to address the need for more realistic settings that reduce the gap between software engineering (SE) courses and industry needs. A systematic mapping study (SMS) performed in 2013 structured the research area on the use of FLOSS projects in SEE. Objective: Update the 2013 SMS with studies published in the last five years classifying and summarizing them to discuss trends and identify research gaps in the context of the use of FLOSS projects in SEE. Method: We retrieved and analyzed a set of 4132 papers published from 2013 to 2017 from which 33 papers were selected and classified. We analyzed the new results and compared them with those from the previous SMS to confirm or discover trends. Results: The updated mapping summarizes the studies published in the last five years most of them in conferences. Our analysis confirmed trends previously observed for three facets (SE area curriculum choice and assessment type) and discovered new trends for other facets. Conclusion: Studies report the use of FLOSS projects in regular comprehensive SE courses. The prevalence of experience reports over solution proposals in the last five years may indicate that researchers are more concerned with the use and evaluation of existing proposals although there are still opportunities for more empirical work based on sound educational research methods.;
Proceedings of the XXXII Brazilian Symposium on Software Engineering;Sentiment analysis in software engineering (SE) has shown promise to analyze and support diverse development activities. Recently several tools are proposed to detect sentiments in software artifacts. While the tools improve accuracy over off-the-shelf tools recent research shows that their performance could still be unsatisfactory. A more accurate sentiment detector for SE can help reduce noise in analysis of software scenarios where sentiment analysis is required. Recently combinations i.e. hybrids of stand-alone classifiers are found to offer better performance than the stand-alone classifiers for fault detection. However we are aware of no such approach for sentiment detection for software artifacts. We report the results of an empirical study that we conducted to determine the feasibility of developing an ensemble engine by combining the polarity labels of stand-alone SE-specific sentiment detectors. Our study has two phases. In the first phase we pick five SE-specific sentiment detection tools from two recently published papers by Lin et&nbspal.&nbsp[29 30] who first reported negative results with stand alone sentiment detectors and then proposed an improved SE-specific sentiment detector POME&nbsp[29]. We report the study results on 17581 units (sentences/documents) coming from six currently available sentiment benchmarks for software engineering. We find that the existing tools can be complementary to each other in 85-95% of the cases i.e. one is wrong but another is right. However a majority voting-based ensemble of those tools fails to improve the accuracy of sentiment detection. We develop Sentisead a supervised tool by combining the polarity labels and bag of words as features. Sentisead improves the performance (F1-score) of the individual tools by 4% (over Senti4SD&nbsp[5]) â€“ 100% (over POME&nbsp[29]). The initial development of Sentisead occurred before we observed the use of deep learning models for SE-specific sentiment detection. In particular recent papers show the superiority of advanced language-based pre-trained transformer models (PTM) over rule-based and shallow learning models. Consequently in a second phase we compare and improve Sentisead infrastructure using the PTMs. We find that a Sentisead infrastructure with RoBERTa as the ensemble of the five stand-alone rule-based and shallow learning SE-specific tools from Lin et&nbspal.&nbsp[29 30] offers the best F1-score of 0.805 across the six datasets while a stand-alone RoBERTa shows an F1-score of 0.801.;
Software Engineering for Smart Cyber-Physical Systems: Models System-Environment Boundary and Social Aspects;Smart Cyber-Physical Systems (sCPS) are a novel kind of Cyber- Physical Systems engineered to take advantage of large-scale cooperation between devices users and environment to achieve added value in face of uncertainty and various situations in their environment. Examples of sCPS include modern traffic systems Industry 4.0 systems systems for smart-buildings smart energy grids etc. The uniting aspect of all these systems is that to achieve their high-level of intelligence adaptivity and ability to optimize and learn they heavily rely on software. This makes them software-intensive systems where software becomes their most complex part. Engineering sCPS thus becomes a recognized software engineering discipline which however due to specifics of sCPS can only partially rely on the existing body of knowledge in software engineering. In fact it turns out that many of the traditional approaches to architecture modeling and software development fail to cope with the high dynamicity and uncertainty of sCPS. This calls for innovative approaches that jointly reflect and address the specifics of such systems. This paper maps the discussions and results of the Third International Workshop on Software Engineering for Smart Cyber-Physical Systems (SEsCPS 2017) which specifically focuses on challenges and promising solutions in the area of software engineering for sCPS.;
Open Tools for Software Engineering: Validation of a Theory of Openness in the Automotive Industry;Context: Open tools (e.g. Jenkins Gerrit and Git) offer a lucrative alternative to commercial tools. Many companies and developers from OSS communities make a collaborative effort to improve the tools. Prior to this study we developed an empirically based theory for companies' strategic choices on the development of these tools based on empirical observations in the telecom domain. Aim: The aim of this study is to validate the theory of openness for tools in software engineering in another domain automotive. Specifically we validated the theory propositions and mapped the case companies onto the model of openness. Method: We run focus groups in two automotive companies collecting data in a survey and follow-up discussions. We used the repertory grid technique to analyze the survey responses in combination with qualitative data from the focus group to validate the propositions. Results: Openness of tools has the potential to reduce development costs and time and may lead to process and product innovation. This study confirms three out of five theory propositions on cost and time reduction and the complementary role of open tools. One propositions was not possible to validate due to lack of investment in OSS tools communities by both companies. However our findings extend the fifth proposition to require management being involved for both the proactive and reactive strategy. Further we observe that the move towards open tools happen with a paradigm shift towards openness in the automotive domain and lead to standardization of tools. Both companies confirm that they need legal procedures for the contribution as well as an internal champion driving the open tools strategy. Conclusion: We validated the theory originating from the telecom domain partially using two automotive companies. Both case companies are classified as laggards (reactive cost saving) in the model of openness presented in the theory. Furthermore we would like to have more validations studies to validate the remaining quadrants (e.g. leverage lucrativeness and leaders).;
Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering;Taking the software engineering series courses of Shenyang Institute of technology as an example this paper designs and practices the teaching process design course teaching methods curriculum evaluation methods and other elements. It emphasizes that the good teaching design which is close to the needs of enterprises and centered on the development of students can improve the classroom teaching and classroom quality from the perspective of training objectives close to the needs of enterprises. This mechanism can be extended to other curriculum construction cultivate high-quality and high-capacity applied talents and make more contributions to regional economic development.;
2021 2nd International Conference on Computers Information Processing and Advanced Education;Challenges of implementing successful research collaborations between industry and academia in software engineering are varied and many. Differing timelines metrics expectations and perceptions of these two communities are some common obstacles which need be analyzed and discussed to discover synergies and strengthen collaborations between researchers and practitioners. In this report we present insights from the 6th International Workshop on Software Engineering Research and Industrial Practice held at the International Conference on Software Engineering 2019. Specifically one particular topic dominated the discussion - the resurgence of artificial intelligence and machine learning algorithms in software engineering research and industry practice and its implications for the collaboration between these two communities. We present takeaways from keynote talks on this subject insights from paper presentations and findings from the discussion session.;
An immersive future for software engineering: avenues and approaches;Software systems are increasingly becoming more intricate and complex necessitating new ways to be able to comprehend and visualize them. At the same time the nature of software engineering teams itself is changing with people playing more fluid roles often needing seamless and contextual intelligence for faster and better decisions. Moreover the next-generation of software engineers will all be post-millennials which may have totally different expectations from their software engineering workplace. Thus we believe that it is important to have a re-look at the way we traditionally do software engineering and immersive technologies have a huge potential here to help out with such challenges. However while immersive technologies devices and platforms have matured in past few years there has been very little research on studying how these technologies can influence software engineering. In this paper we introduce how traditional software engineering can leverage immersive approaches for building delivering and maintaining next-generation software applications. As part of our initial research we present an augmented-reality based prototype for project managers which provides contextual and immersive insights. Finally we also discuss important research questions that we are investigating further as part of our immersive software engineering research.;
Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results;The introduction of e-Government enabled services has resulted in the public- sector wide integration of different software applications often scaled up to a national level. Out of observation the way these initiatives are handled differs in the way software-development projects are managed in the private sector. The anticipated value of these projects tends to differ significantly in the long run. We have particularly picked interest in the health sector in which e-Health initiatives have been defined. We aim at understanding how value proliferation can be understood and quantified from the onset on such large-scale projects using requirement engineering techniques. In this work we infer that effective planning of large scale ICT initiatives such as e-Health should be long term driven so as to ensure effective sector management. Novel approaches in this realm should strive at linking strategy measurement and operational decisions from the onset. In here we examine what has been done key opportunities challenges and gaps that can be addressed by the research community. In bridging these gaps we propose an agenda by formulating key research questions which both the industry and academia can address as future direction to align this view.;
Proceedings of the 2018 International Conference on Software Engineering in Africa;The teaching of Software Engineering (SE) has become challenging due to the large amount of content taught and the constant evolution of the software industry directly impacting the requirements necessary to apply for a position in the area of Information Technology (IT). In this context it is clear that students of computer courses still find it difficult to know how to prepare for the job market and Higher Education Institutions (HEIs) may have difficulties in aligning themselves with market expectations with their syllabus in SE. This paper aims to provide a holistic view of the teaching-learning process involving the views of students HEIs and IT companies in the context of the state of Maranh\~{a;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;Sentiment analysis has been applied to various software engineering (SE) tasks such as evaluating app reviews or analyzing developers' emotions in commit messages. Studies indicate that sentiment analysis tools provide unreliable results when used out-of-the-box since they are not designed to process SE datasets. The silver bullet for a successful application of sentiment analysis tools to SE datasets might be their customization to the specific usage context.We describe our experience in building a software library recommender exploiting developers' opinions mined from Stack Overflow. To reach our goal we retrained---on a set of 40k manually labeled sentences/words extracted from Stack Overflow---a state-of-the-art sentiment analysis tool exploiting deep learning. Despite such an effort- and time-consuming training process the results were negative. We changed our focus and performed a thorough investigation of the accuracy of commonly used tools to identify the sentiment of SE related texts. Meanwhile we also studied the impact of different datasets on tool performance. Our results should warn the research community about the strong limitations of current sentiment analysis tools.;
Proceedings of the 40th International Conference on Software Engineering;While project-based software engineering courses aim to provide learning opportunities grounded in professional processes it is not always possible to replicate every process in classrooms due to course constraints. Previous studies observed how students react to various processes and gave retroactive recommendations. In this study we instead combine a field study on professional Agile (eXtreme Programming XP) teams and an established team process taxonomy to proactively select team processes to incorporate in a project-based software engineering course. With collected knowledge from the field study we choose three XP processes to augment the design of a mature software engineering project course. We choose processes that are 1) considered important by professionals and 2) complete with respect to coverage of the taxonomy's main categories. We then compare the augmented course design with the original design in a case study. Our results suggest that 1) even without extra resources adding these new processes does not interfere with learning opportunities for XP processes previously existing in the course design 2) student teams experience similar benefits from these new processes as professional teams do and students appreciate the usefulness and value of the processes. In other words our approach allows instructors to make conscious choices of XP processes that improve student learning outcomes while exposing students to a more complete set of processes and thus preparing them better for professional careers. Course designers with limited resources are encouraged to use our methodology to evaluate and improve the designs of their own project-based courses.;
Proceedings of the 51st ACM Technical Symposium on Computer Science Education;Research on the impact of static analysis tools on software quality is often targeted towards practitioners or open source projects in general. Research in the field of software education concentrates on the usefulness of static analysis in introductory courses to programming. Contrary we want to find out whether students doing their first larger programming project (projects of 3000 to 5000 LOC) can benefit from applying static analysis tools. We therefore prepared a SonarQube based quality profile with 448 coding best practices and set up an environment that helped us to analyze code submitted by the students throughout a semester. Students were asked to frequently have a look at the provided data (using the SonarQube dashboard) and to fix those violations of best practices where they thought it makes sense. There were no incentives or penalties for fixing or not fixing these violations of best practices. The case study shows that there are substantially different kinds of violations of best practices depending on the experience level of the student teams. Additionally while high experience and moderate experience student teams learn quickly and substantially during a semester students with low experience have difficulties in understanding the underlying problems of the reported violations of best practices.;
Proceedings of the 2020 9th International Conference on Educational and Information Technology;Synthesizing data extracted from primary studies is an integral component of the methodologies in support of Evidence Based Software Engineering (EBSE) such as System Literature Review (SLR). Since a large and increasing number of studies in Software Engineering (SE) incorporate qualitative data it is important to systematically review and understand different aspects of the Qualitative Research Synthesis (QRS) being used in SE. We have reviewed the use of QRS methods in 328 SLRs published between 2005 and 2015. We also inquired the authors of 274 SLRs to confirm whether or not any QRS methods were used in their respective reviews. 116 of them provided the responses which were included in our analysis. We found eight QRS methods applied in SE research two of which narrative synthesis and thematic synthesis have been predominantly adopted by SE researchers for synthesizing qualitative data. Our study determines that a significant amount of missing knowledge and incomplete understanding of the defined QRS methods in the community. Our effort also identifies an initial set factors that may influence the selection and use of appropriate QRS methods in SE.;
Proceedings of the 40th International Conference on Software Engineering;Sustainable computing is a rapidly growing research area spanning several areas of computer science. In the software engineering field the topic has received increasing attention in recent years with several studies addressing a range of concerns. However few studies have demonstrated the awareness of software practitioners about the underlying concepts of sustainability in the software development practice. In this effect in this study we aim to provide some evidence about the practitioners' perception about the adoption of sustainability in software development under four main perspectives: economic social environmental and technical. To accomplish such a goal we carried out a survey study with twenty-five software engineers involved in projects in different domains. The yielded results indicate an overall lack of knowledge about the topic in particular regarding the concepts about sustainable software although it is a common understanding that sustainability should be treated as a quality attribute and should support the interaction between sustainability and the software development life cycle phases. Among the observed perspectives the respondents indicate that the technical dimension is the most relevant and explored so far. This study contributes to the field with initial evidence and can be seen as a first step towards establishing a common understanding about how the software industry is receptive to the use of sustainability concepts in software development practices.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;Context: Data synthesis is one of the most significant tasks in Systematic Literature Review (SLR). Software Engineering (SE) researchers have adopted a variety of methods of synthesizing data that originated in other disciplines. One of the qualitative data synthesis methods is meta-ethnography which is being used in SE SLRs. Objective: We aim at studying the adoption of meta-ethnography in SE SLRs in order to understand how this method has been used in SE. Method: We conducted a tertiary study of the use of meta-ethnography by reviewing sixteen SLRs. We carried out an empirical inquiry by integrating SLR and confirmatory email survey. Results: There is a general lack of knowledge or even awareness of different aspects of meta-ethnography and/or how to apply it. Conclusion: There is a need of investment in gaining in-depth knowledge and skills of correctly applying meta-ethnography in order to increase the quality and reliability of the findings generated from SE SLRs. Our study reveals that meta-ethnography is a suitable method to SE research. We discuss challenges and propose recommendations of adopting meta-ethnography in SE. Our effort also offers a preliminary checklist of the systematic considerations for doing meta-ethnography in SE and improving the quality of meta-ethnographic research in SE.;
Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering;This paper introduces Data-Driven Search-based Software Engineering (DSE) which combines insights from Mining Software Repositories (MSR) and Search-based Software Engineering (SBSE). While MSR formulates software engineering problems as data mining problems SBSE reformulate Software Engineering (SE) problems as optimization problems and use meta-heuristic algorithms to solve them. Both MSR and SBSE share the common goal of providing insights to improve software engineering. The algorithms used in these two areas also have intrinsic relationships. We therefore argue that combining these two fields is useful for situations (a) which require learning from a large data source or (b) when optimizers need to know the lay of the land to find better solutions faster.This paper aims to answer the following three questions: (1) What are the various topics addressed by DSE? (2) What types of data are used by the researchers in this area? and (3) What research approaches do researchers use? The paper briefly sets out to act as a practical guide to develop new DSE techniques and also to serve as a teaching resource.This paper also presents a resource (tiny.cc/data-se) for exploring DSE. The resource contains 89 artifacts which are related to DSE divided into 13 groups such as requirements engineering software product lines software processes. All the materials in this repository have been used in recent software engineering papers i.e. for all this material there exist baseline results against which researchers can comparatively assess their new ideas.;
Proceedings of the 15th International Conference on Mining Software Repositories;Development of machine learning (ML) applications is hard. Producing successful applications requires among others being deeply familiar with a variety of complex and quickly evolving application programming interfaces (APIs). It is therefore critical to understand what prevents developers from learning these APIs using them properly at development time and understanding what went wrong when it comes to debugging. We look at the (lack of) guidance that currently used development environments and ML APIs provide to developers of ML applications contrast these with software engineering best practices and identify gaps in the current state of the art. We show that current ML tools fall short of fulfilling some basic software engineering gold standards and point out ways in which software engineering concepts tools and techniques need to be extended and adapted to match the special needs of ML application development. Our findings point out ample opportunities for research on ML-specific software engineering.;
Companion Proceedings of the 4th International Conference on Art Science and Engineering of Programming;In the past years with the development and widespread of digi- tal technologies everyday life has been profoundly transformed. The general public as well as specialized audiences have to face an ever-increasing amount of knowledge and learn new abilities. The EASEAI workshop series addresses that challenge by look- ing at software engineering education and arti cial intelligence research elds to explore how they can be combined. Speci cally this workshop brings together researchers teachers and practi- tioners who use advanced software engineering tools and arti cial intelligence techniques in the education eld and through a trans- generational and transdisciplinary range of students to discuss the current state of the art and practices and establish new future directions. More information at https://easeai.github.io.;
Categorizing user stories in the software engineering classroom;User story documentation is a significant aspect of Agile development in which developers document possible actions that users may take within a software system. It is essential to educate students in a software engineering curriculum on how to create this documentation so they can be competent developers in their future careers. This study uses the INVEST user story rating system to assess user stories that students wrote for a term project in a two-part software engineering course series. We demonstrate potential issues that students experience in user story creation based on the INVEST analysis and propose potential solutions to this problem.;
Team composition in software engineering project courses;Composing well-balanced effective development teams for software engineering project courses is important for facilitating learning fostering student motivation as well as obtaining a successful project outcome. However team composition is a challenging task for instructors because they have to consider a variety of possibly conflicting criteria such as practical constraints skill distribution or project motivation.In this paper we describe our process for composing development teams based on a pre-defined set of criteria that we have established from our experience conducting project courses since 2008 and constantly refined since. We reflect on these criteria by analyzing the team synergy and project satisfaction of participating students as well as their perspective on challenges in their teams in one concrete instance of a multi-project capstone course. Our findings show that lack of motivation problems with interpersonal relationships and communication issues affect the less satisfied teams more than the others.;
Proceedings of the 2nd International Workshop on Software Engineering Education for Millennials;Computer science students need to learn a wide variety of skills to succeed in their future careers. In addition to technical skills like programming information science and statistics the globalization of the software industry requires graduates to learn non-technical skills as well such as distributed project management and intercultural communication to collaborate on large international software development projects. A series of distributed virtual courses to teach global software engineering have been conducted between the Ritsumeikan University in Japan and the University of Applied Sciences Nuremberg in Germany. Cross-site student teams collaborated virtually to develop solutions to a real-world software engineering project. A combination of project-based learning collaborative learning and context-based learning is discussed. Experiences from both sides are explored. Lessons learned and best practices from these and other collaborative teaching experiences are presented.;
Proceedings of the 2020 11th International Conference on E-Education E-Business E-Management and E-Learning;Software Engineering (SE) community has recently been investing significant amount of effort in qualitative research to study the human and social aspects of SE processes practices and technologies. Ethnography is one of the major qualitative research methods which is based on constructivist paradigm that is different from the hypothetic-deductive research model usually used in SE. Hence the adoption of ethnographic research method in SE can present significant challenges in terms of sufficient understanding of the methodological requirements and the logistics of its applications. It is important to systematically identify and understand various aspects of adopting ethnography in SE and provide effective guidance. We carried out an empirical inquiry by integrating a systematic literature review and a confirmatory survey. By reviewing the ethnographic studies reported in 111 identified papers and 26 doctoral theses and analyzing the authors' responses of 29 of those papers we revealed several unique insights. These identified insights were then transformed into a preliminary checklist that helps improve the state-of-the-practice of using ethnography in SE. This study also identifies the areas where methodological improvements of ethnography are needed in SE.;
Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Civic grassroots have proven their ability to create useful and scalable software that addresses pressing social needs. Although software engineering plays a fundamental role in the process of creating civic technology academic literature that analyses the software development processes of civic tech grassroots is scarce. This paper aims to advance the understanding of how civic grassroots tackle the different activities in their software development processes. In this study we followed the formation of two projects in a civic tech group (Code for Ireland) seeking to understand how their development processes evolved over time and how the group carried out their work in creating new technology. Our preliminary findings show that such groups are capable of setting up systematic software engineering processes that address software specification development validation and evolution. While they were able to deliver software according to self-specified quality standards the group has challenges in requirements specification stakeholder engagement and reorienting from development to product delivery. Software engineering methods and tools can effectively support the future of civic technologies and potentially improve their management quality and durability.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Society;Background: The Systems Engineering and Software Engineering disciplines are highly intertwined in most modern Systems of Systems (SoS) and particularly so in industries such as defense transportation energy and health care. However the combination of these disciplines during the architecting of SoS seems to be especially challenging the literature suggests that major integration and operational issues are often linked to ambiguities and gaps between system-level and software-level architectures.Aims: The objective of this paper is to empirically investigate: 1) the state of practice on the interplay between these two disciplines in the architecting process of systems with SoS characteristics 2) the problems perceived due to this interplay during said architecting process and 3) the problems arising due to the particular characteristics of SoS systems.Method: We conducted a questionnaire-based online survey among practitioners from industries in the aforementioned domains having a background on Systems Engineering Software Engineering or both and experience in the architecting of systems with SoS characteristics. The survey combined multiple-choice and open-ended questions and the data collected from the 60 respondents were analyzed using quantitative and qualitative methods.Results: We found that although in most cases the software architecting process is governed by system-level requirements the way requirements were specified by systems engineers and the lack of domain-knowledge of software engineers often lead to misinterpretations at software level. Furthermore we found that unclear and/or incomplete specifications could be a common cause of technical debt in SoS projects which is caused in part by insufficient interface definitions. It also appears that while the SoS concept has been adopted by some practitioners in the field the same is not true about the existing and growing body of knowledge on the subject in Software Engineering resulting in recurring problems with system integration. Finally while not directly related to the interplay of the two disciplines the survey also indicates that low-level hardware components despite being identified as the root cause of undesired emergent behavior are often not considered when modeling or simulating the system.Conclusions: The survey indicates the need for tighter collaboration between the two disciplines structured around concrete guidelines and practices for reconciling their differences. A number of open issues identified by this study require further investigation.;
Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Machine Learning and Artificial Intelligence allow the development of a new type of applications that automatically identify hidden patterns process large amounts of data and classify data according to aforementioned patterns. While they offer interesting solutions for several problems they also impose challenges on software engineers in charge of structuring the development effort. The new applications require to incorporate additional specialists and their work into an overall development effort. We thus propose a software engineering process for data-driven applications.;
Proceedings of the 7th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering;Software Engineering Researchers in India from both academia and industry are widely contributing to various research problems. In this report we brie y summarize the key insights from 1st Software Engineering Research in India Update Meeting (SERI 2019) which provides a platform for all the researchers to present and discuss their research work. The essence of this research meeting is to examine the current research areas within the software engineering research community and discover the scope of collaboration. Speci cally the rst SERI update meeting had a series of invited research talks presented by researchers from academia and industry representing various software engineering labs across India. These talks unveiled notable views through presentations and group discussions and cogitation of topics that can lead to fruitful collaborations between software engineering researchers and industry practitioners. The main objective of this update meeting is the exchange of research areas that promotes successful short-term and long-term collaborations.;
Report on the 2nd International Workshop on Robotics Software Engineering (RoSE'19);The 2nd edition of the 2nd International Workshop on Robotics Software Engineering (RoSE) was held at the International Conference on Software Engineering (ICSE) in the city of Montreal Canada on the 27th of May 2019. The focus of this edition of the workshop was on multi-robot systems and facilitating robot programming. In this report we rst present an overview of the workshop sessions before we highlight challenges identi ed in workshop's interactive discussion sessions.;
What Do We Do When We Teach Software Engineering?;Many UK higher education institutions offer software engineering programmes but the purpose and relevance of these programmes within computing science departments is not always obvious. The reality is that while advanced economies require many more skilled software engineers universities are not delivering them. This is at least true in the context of the United Kingdom where there are high numbers of software engineering vacancies and unemployed software engineering graduates. A possible explanation could be that curriculum content of software engineering programmes in universities needs to be reconsidered to meet the needs of industry. However reconsidering curriculum content alone is unlikely to be transformative as there is little to be gained from changing to an emerging methodology language or framework. Instead an alternative direction could be to reconsider curriculum delivery and the identity of software engineering within computing science itself. In this paper we contextualise the challenge by considering the history of software engineering education and some of its key developments. We then consider some of the alternative delivery approaches before arguing cooperative programmes provide a opportunity for institutions to reconsider software engineering education.;
Proceedings of the 2019 Conference on United Kingdom &amp Ireland Computing Education Research;Context: Following on other scientific disciplines such as health sciences the use of Grey Literature (GL) has become widespread in Software Engineering (SE) research. Whilst the number of papers incorporating GL in SE is increasing there is little empirically known about different aspects of the use of GL in SE research.Method: We used a mixed-methods approach for this research. We carried out a Systematic Literature Review (SLR) of the use of GL in SE and surveyed the authors of the selected papers included in the SLR (as GL users) and the invited experts in SE community on the use of GL in SE research. Results: We systematically selected and reviewed 102 SE secondary studies that incorporate GL in SE research from which we identified two groups based on their reporting: 1) 76 reviews only claim their use of GL 2) 26 reviews report the results by including GL. We also obtained 20 replies from the GL users and 24 replies from the invited SE experts. Conclusion: There is no common understanding of the meaning of GL in SE. Researchers define the scopes and the definitions of GL in a variety of ways. We found five main reasons of using GL in SE research. The findings have enabled us to propose a conceptual model for how GL works in SE research lifecycle. There is an apparent need for research to develop guidelines for using GL in SE and for assessing quality of GL. The current work can provide a panorama of the state-of-the-art of using GL in SE for the follow-up research as to determine the important position of GL in SE research.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering;Neural Machine Translation (NMT) is the current trend approach in Natural Language Processing (NLP) to solve the problem of auto- matically inferring the content of target language given the source language. The ability of NMT is to learn deep knowledge inside lan- guages by deep learning approaches. However prior works show that NMT has its own drawbacks in NLP and in some research problems of Software Engineering (SE). In this work we provide a hypothesis that SE corpus has inherent characteristics that NMT will confront challenges compared to the state-of-the-art translation engine based on Statistical Machine Translation. We introduce a problem which is significant in SE and has characteristics that challenges the abil- ity of NMT to learn correct sequences called Prefix Mapping. We implement and optimize the original SMT and NMT to mitigate those challenges. By the evaluation we show that SMT outperforms NMT for this research problem which provides potential directions to optimize the current NMT engines for specific classes of parallel corpus. By achieving the accuracy from 65% to 90% for code tokens generation of 1000 Github code corpus we show the potential of using MT for code completion at token level.;
Proceedings of the 1st ACM SIGSOFT International Workshop on Representation Learning for Software Engineering and Program Languages;Software engineering (SE) students not only need sufficient technical knowledge and problem solving ability but also social and interpersonal skills in order to be industry ready. To prepare the students for the 'real world' the SE educators frequently use 'Authentic Assessment' and 'Project Based Learning (PBL)' approaches in their curricula. However the level of 'authenticity' should vary within PBL courses offered in different years of a degree program. In this paper we present and discuss the results of the data collected and analyzed from the first SE course offered to the students. The aim of our research is to explore how much authenticity can be achieved in the first SE course. Our study was conducted at the University of Calgary with 64 software development project teams totaling 229 undergraduate students. The data is collected from three semesters (2016--2018) in order to assess and monitor students performance. The course design used seven authentic assessments that focused on students skills while covering a complete software development lifecycle. The results from data analysis show that students made progress in some areas of problem solving skills however they struggled in their social skills (e.g. people handling skills negotiations skills and organizational skills) understanding software quality and adaptability.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training;In this paper we discuss gender disparity in software engineering (SE) conferences. We have examined the roles of General Chair Program Chair and main track Program Committee members in six highly ranked conferences in SE for a period of ten years in order to understand the pattern of gender disparity in visible roles. We also present the opinions elicited from ten participants on this topic who have served at some of these SE conferences in leadership roles. Our aim is to reflect on the current state and initiate the debate on gender equality in SE conferences.;
Proceedings of the 2nd International Workshop on Gender Equality in Software Engineering;Software engineering practices are challenging activities in the startups' context due their limited resources and need to create high-tech and innovative products. The challenge becomes even bigger when taking into consideration the startups' search for highly scalable business models. Problem - Since they cannot rely on such a heavyweight software processes they need to resort to alternative practices. Goal - Thus the main goal of this study is to contribute to the understanding of the software startups' practices. Method - In this sense we conducted a single embedded case study in four local software startups incubated/first born in an academic environment. The case study consisted of semi-structured interviews questionnaires non-participative observations and archiving data covering the software engineering practices. Results - The results allowed us to build an Academic Startup Model to capture the software startups' practices and the relationship among them. Conclusions - Moreover we encourage further investigation of some aspects such as: investigate industrial context add more units of analysis and select units of analysis from different business domains.;
Proceedings of the 1st International Workshop on Software Engineering for Startups;With an increasing emphasis on unit testing in computer science curricula we examined students' work on testing assignments to investigate their adoption of test smells---practices that indicate potential problems in unit tests. We discovered three common causes of test smells in students' unit tests: multiple member function calls multiple assertions and conditional logic. We also explored how each might be associated with test inaccuracies.In a quasi-experimental study we evaluated the quality of students' unit tests by evaluating test accuracy---tests' reliability in distinguishing between a corpus of acceptable production code and a separate corpus containing faults. Correlational and comparative analyses revealed that unit tests with calls to multiple member functions and/or conditional logic were associated with worse test accuracy. However no relationship was found between test accuracy and whether or not unit tests contained multiple assertions.;
Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1;Mentoring is one of the most effective pedagogical tools holding great promise for software engineering education. When done badly however it can lead to dysfunctional inter-personal relationships and may turn off mentees from careers in software engineering. In this qualitative interview-based study we examine how socio-technical dimensions of software impact the formation of social ties important for satisfying two goals of mentorship building technical skill and interpersonal development. We find that mentees working on user facing interdependent software form a balance of ties that facilitate both goals while mentees working on non-user facing software mostly form ties important for building technical skill. Work practices that create opportunities for unstructured contact between mentees and community members such as code review in a mentee cohort can help to overcome this imbalance. Our findings have important implications for task definition in software engineering e-mentoring program schemes.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Context: Job rotation is a managerial practice to be applied in the organizational environment to reduce job monotony boredom and exhaustion resulting from job simplification specialization and repetition. Previous studies have identified and discussed the use of project-to-project rotations in software practice gathering empirical evidence from qualitative and field studies and pointing out set of work-related factors that can be positively or negatively affected by this practice. Goal: We aim to collect and discuss the use of job rotation in software organizations in order to identify the potential benefits and limitations of this practice supported by the statement of existing theories of work design. Method: Using a survey-based research design we collected and analyzed quantitative data from software engineers about how software development work is designed and organized as well as the potential effects of job rotations on this work design. We investigated 21 work design constructs along with job burnout role conflict role ambiguity and two constructs related to job rotation. Results: We identified one new benefit and six new limitations of job rotation not observed in previous studies and added new discussions to the existing body of knowledge concerning the use of job rotation in software engineering practice. Conclusion: We believe that these results represent another important step towards the construction of a consistent and comprehensive body of evidence that can guide future research and also inform practice about the potential positive and negative effects of job rotation in software development companies.;
Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering;Replication is essential to build knowledge in empirical science. Experiment replications reported in the software engineering context present variabilities on their experiment elements e.g. variables materials. Further understanding these variabilities could help planning lack of strategy to support the representation of experiment variabilities and commonalities. In addition there is also a gap related to effective reuse and traceability of experiment elements. These problems are likely to hamper the replication understanding and planning. In order to overcome these gaps we intend to create a conceptual model and a tool to support replication planning. To develop these solutions we will use concepts of experimentation and software product lines. Our idea is to build a core structure which allows the configuration of experiment elements based commonalities with previous replications and desired variabilities to fit the specific replication purposes. In this paper we describe related work our research methodology as well as the current research progress and expected future contributions.;
A systematic mapping study of diversity in software engineering: a perspective from the agile methodologies;Diversity is being discussed intensively by different knowledge areas. Some studies show that diversity builds better teams delivers better results and more. Cognitive diversity is linked to better outcomes and studies show that cognitive diversity is influenced by identity diversity (e.g. gender race age etc.) mainly when tasks are related to problem-solving and prediction. The discussions about diversity in Software Engineering are increasing as well. There is a known lack of representativeness from some groups when we talk about identity diversity as for example gender and race. To support diversity in Software Engineering is valuable and it is especially relevant once we are dealing with problem-solving. In this work we are interested in understanding how the subject is being conducted in Software Engineering-related research and more specifically in Agile Methodologies. For that we conducted a Systematic Mapping so we can have an overview of the research area through classification and counting contributions related to the subject. The outcome is an inventory of papers on how Diversity is being discussed in Software Engineering and Agile Methodologies. We list the most common publication venues the frequency publication through the years the main areas in software engineering that are interested in the subject and finally a first discussion on how Agile Methodologies and their intrinsic characteristics can support better deliveries from more diverse development teams.;
Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering;Background: In Software Engineering (SE) the term maturity is often linked to the work process and product quality. In many cases team maturity is seen as a backdrop to the process of SE and sometimes as something that is known to exist but which cannot be understood neither measured accurately nor even dimension its value. Aim: In this article we seek to understand the concept of mature teams in the context of SE from the perspective of the software engineers themselves. Methods: We performed an exploratory qualitative research collecting data from 26 practitioners from 6 companies in 4 cities in Brazil. Data was analyzed using coding techniques from qualitative research. Results: Our findings pointed out three major dimensions of the concept of Team Maturity - Learning Relationship and Technical Maturity - which when kept in balance can enhance the collective productivity product quality and also the customer satisfaction. Conclusions: These results extend our current understanding of maturity of SE teams shedding light on aspects that have been little explored so far in this field. The proposed model can serve as a guide for teams to enhance their approach of teamwork and for future research in this area.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Software Engineering is a crucial discipline present in several undergraduate courses often due to the incorporation in its curriculum and many times focusing only in technical artifacts analysis which leads to restricting social and business aspects and limiting a global vision. Software Ecosystem (SECO) is a collection of software products with some degree of symbiotic relationship consisting of a set of actors working as a unit interacting with a market distributed between software and services along with the relationships between these entities. Motivated by the SECO diffusion the idea of incorporating its teaching in the Software Engineering discipline seems to be attractive. However a drawback to SECO research is the lack of modeling support. Furthermore there is a need for more examples of SECO models mainly close to the students' reality. This work aims to report the teaching of SECO in the Software Engineering discipline. For this a qualitative analysis of a questionnaire with students' answers was designed. As a result of this work we concluded that adding the teaching of ECOS in the Software Engineering discipline provides a global view of the systems development mainly social aspects and evolution.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;Globalization has allowed organizations to intensify the search for solutions that minimize challenges reduce costs and optimize processes. In this way global software development has emerged as an attempt to use the best resources for its limitations.In distributed environments the use of Ontologies brings some benefits such as a uniform understanding of information among teams and ease of communication as well as making for the lack of a reference model that can be applied in a distributed context.This work aims to propose a viable form of validation for DKDonto a domain ontology developed for Global Software Engineering. The validation allowed a broader and more targeted assessment different from its original validation which was carried out in a controlled environment limited to answering questions already known by the knowledge base itself.The main result of this work is a satisfactory evaluation of the ontology enabling it to be used and shared by companies or institutions as well as the presentation of a set of methods and ways to evaluate and verify domain ontologies to be used in different domains.;
Proceedings of the 22nd International Conference on Information Integration and Web-Based Applications &amp Services;Teaching Software Engineering is not a trivial duty since several pedagogical strategies can be used and sometimes the impact of these on students is uncertain. Hackathons are similar to marathons however used to produce solutions to solve a specific problem in a short period of time and based on intense collaboration. Educational hackathons aim to promote learning in such an environment. The Undergraduate computing programs of PUCRS decided to use a hackathon as a pedagogical strategy aiming to motivate the students to practice the adoption of software development practices and to work in groups as a means to practice the development of social skills. Therefore we conducted a case study to investigate: 1) The motivations to students to attend or not attend an educational hackathon 2) The students perceptions about this hackathon 3) The Software Engineering practices adopted by students. In this study we identified factors that may affect students motivation to participate (e.g. improve the teamwork skills) some students expectations about the hackathon (e.g. work in teams) and the practices adopted by the students (e.g. pair programming). Some of our findings include that students enjoy participating in an informal educational environment (e.g. hackathons) to improve their technical skills and to build network with some colleagues. This study can provide insights to teachers that wants to organize some activity than traditional teaching and the students perspective about this kind of strategy.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;Over the past years we are witnessing a paradigm shift on software development operations where software life-cycle phases form a continuous process model as opposed to discrete process steps. In this respect researchers and practitioners propose methods tools and frameworks that allow for continuous software engineering activities which achieve controlled short release cycles. More specifically such activities that are bound in a continuum include business analysis implementation integration delivery testing and compliance verification. To implement such a model we require infrastructures that provide continuous verification and gathering of new requirements continuous run-time monitoring continuous assessment of software health and automatic or semi-automatic deployment and integration.;
Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering;To bridge the digital skills gap we need to train more people in Software Engineering techniques. This paper reports on a project exploring the way students solve tasks using collaborative development platforms and version control systems such as GitLab to find patterns and evaluation metrics that can be used to improve the course content and reflect on the most common issues the students are facing. In this paper we explore Learning Analytics approaches that can be used with GitLab and similar tools and discuss the challenges raised when applying those approaches in Software Engineering Education with the objective of building a pipeline that supports the full Learning Analytics cycle from data extraction to data analysis. We focus in particular on the data anonymisation step of the proposed pipeline to explore the available alternatives to satisfy the data protection requirements when handling personal information in academic environments for research purposes.;
Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering;"Cryptocurrencies and their foundation technology the Blockchain are reshaping finance and economics allowing a decentralized approach enabling trusted applications with no trusted counterpart. More recently the Blockchain and the programs running on it called Smart Contracts are also finding more and more applications in all fields requiring trust and sound certifications. Some people have come to the point of saying that the Blockchain revolution"" can be compared to that of the Internet and the Web in their early days. As a result all the software development revolving around the Blockchain technology is growing at a staggering rate. The feeling of many software engineers about such huge interest in Blockchain technologies is that of unruled and hurried software development a sort of competition on a first-come-first-served basis which does not assure neither software quality nor that the basic concepts of software engineering are taken into account.This paper tries to cope with this issue proposing a software development process to gather the requirement analyze design develop test and deploy Blockchain applications. The process is based on several Agile practices such as User Stories and iterative and incremental development based on them. However it makes also use of more formal notations such as some UML diagrams describing the design of the system with additions to represent specific concepts found in Blockchain development. The method is described in good detail and an example is given to show how it works.""";
Proceedings of the 14th Central and Eastern European Software Engineering Conference Russia;In an effort to regulate Machine Learning-driven (ML) systems current auditing processes mostly focus on detecting harmful algorithmic biases. While these strategies have proven to be impactful some values outlined in documents dealing with ethics in ML-driven systems are still underrepresented in auditing processes. Such unaddressed values mainly deal with contextual factors that cannot be easily quantified. In this paper we develop a value-based assessment framework that is not limited to bias auditing and that covers prominent ethical principles for algorithmic systems. Our framework presents a circular arrangement of values with two bipolar dimensions that make common motivations and potential tensions explicit. In order to operationalize these high-level principles values are then broken down into specific criteria and their manifestations. However some of these value-specific criteria are mutually exclusive and require negotiation. As opposed to some other auditing frameworks that merely rely on ML researchersâ€™ and practitionersâ€™ input we argue that it is necessary to include stakeholders that present diverse standpoints to systematically negotiate and consolidate value and criteria tensions. To that end we map stakeholders with different insight needs and assign tailored means for communicating value manifestations to them. We therefore contribute to current ML auditing practices with an assessment framework that visualizes closeness and tensions between values and we give guidelines on how to operationalize them while opening up the evaluation and deliberation process to a wide range of stakeholders.;
Proceedings of the 2022 ACM Conference on Fairness Accountability and Transparency;Considering the highly relevant gender equality gaps in the scientific field in Spain the present work has the objective of analyzing the pertinence and impact requirements of a proposal designed to contribute to improve gender relations at the Technical University of Madrid (UPM) and at the Universidad Complutense de Madrid (UCM).This proposal intends to guide the introduction of gender-related contents in various subjects so that both teachers and students can gain a gender perspective in addressing different issues. Some other proposals related to technical subjects are also included.The methodology that has been used is based on a gender mainstreaming literature review and on an analysis of worldwide good practices on gender equality in high education institutions. A case study is also provided.Our main conclusion is that our proposal may have very strong impact in reducing the gender gaps and in creating a basis for a wider mainstreaming strategy. This is relevant now as the Equality Plan in the UPM and UCM have been recently approved.;
Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings;Model-based Software Engineering (MBSwE) and the use of automatic code generation has become popular for safety-critical aerospace applications. For these applications verification and validation (V&ampV) is of utmost importance. With models as another layer of artifacts however V&ampV can become more complex in general as V&ampV tasks can be carried out at the model level or at the code level. In this short paper we present a V&ampV architecture specifically designed for MBSwE which reflects the interrelationships between the different levels tasks and tools and which aims to provide a clear picture on the V&ampV approaches for MBSwE. We illustrate the architecture with a detailed analysis of two NASA missions and discuss their approaches to model use and understanding automatic code generation V&ampV and model synchronization.;
Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;"In order to adapt to the new situation of international competition and the new demand of strategic development Emerging Engineering Education (3E) is the new direction of China's engineering education reform. Based on the analysis of the characteristics of software engineering major this paper discusses the current predicament of software engineering talent training and puts forward the model of iterative software engineering talent training under the background of 3E. This mode is implemented in three stages in teaching arrangement: iterative advancement in teaching objectives project-centered practice teaching and curriculum group mode in teaching organization. This mode practices the idea of industry-university cooperation in educating people supports the natural extension of integration of the core and master programs"" in the mode expansion and has been widely recognized in the practical talent training.""";
2021 2nd International Conference on Computers Information Processing and Advanced Education;In this article we present our design of an (otherwise completely ordinary) undergraduate introduction to software engineering with an emphasis on contemporary software modelling.A distinguishing aspect of our course is that we aim at a comprehensive introduction of modelling in two regards. Firstly we introduce proper sub-languages of common modelling languages like UML class diagrams (rather than sampling examples or covering as many building blocks as possible) with a complete formal abstract syntax and semantics (so to give exact meaning to all models from the sub-language). Secondly we emphasise issues arising from software models in the context of software engineering e.g. that (formal) analysis results needs proper interpretation wrt. the considered software.We discuss our objectives wrt. modelling in software engineering and outline the content of the course and the narratives that we use to reach these objectives. Evaluation results from four seasons of teaching the course give no indication of over-straining students wrt. level or workload.;
Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems;Balancing theory and practice is a recurring challenge in Software Engineering (SE) education. However the curriculum guidelines of the ACM/IEEE and Brazilian Computer Society emphasize the need of providing students with sufficient practical experiences for the development of competences expected for SE professional. Student-centered and learn-by-doing approaches such as Project-Based Learning (PBL) have been advocated as suited for the development of competences. These approaches aim to promote higher motivation for the learner a more active role in the learning process and better learning in the application level. The goal of this paper is to evaluate the students' perception on the adoption of PBL in SE education. To achieve this goal we performed a long-term study spanning for about 2 years. This study includes a survey to collect responses of 32 undergraduate students enrolled in an introductory SE course that used PBL. We compare the results to the responses of 17 students who participated in a SE course with similar syllabus but with a traditional teacher-centered learning method (non-PBL). Our results show a positive reception of the PBL method and an increased perception of the contribution of a practical software development assignment in learning specific SE topics in the context of the PBL course in comparison to a non-PBL method.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;In this work we acknowledge the need for software engineers to devise specialized tools and techniques for blockchain-oriented software development. Ensuring effective testing activities enhancing collaboration in large teams and facilitating the development of smart contracts all appear as key factors in the future of blockchain-oriented software development.;
Proceedings of the 39th International Conference on Software Engineering Companion;The cultivation of graduatesâ€™ scientific research ability is not only related to their scientific research and innovation abilities but also related to the quality of graduate education in China. The cultivation process for the traditional software engineering graduatesâ€™ scientific research ability pays more attention to graduatesâ€™ capability in engineering application. However under the background of world First class universities and disciplines construction in China more emphasis should be placed on cultivating graduatesâ€™ scientific research and innovation capabilities. In this paper the scientific research ability of software engineering graduates has been divided into multiple dimensions including solid professional foundation the ability to discover problems the ability to analyze and solve problems the ability to express the opinions of scientific research and comprehensive scientific research literacy. We propose a scientific research ability cultivating system for software engineering graduates oriented to whole process control and management and implement it with seven graduates majoring in software engineering as cases. The results show that compared with the previous graduatesâ€™ cultivation the scientific research ability of graduates in 2020 has been improved faster in all aspects. The system achieves relatively satisfactory results.;
Proceedings of the 2021 4th International Conference on Education Technology Management;Competition in the software development businesses makes some companies are race in producing qualified product in which expected by its stakeholder. Case XYZ is an IT solutions company currently has a problem in the completion of a software product. The purpose of this research is to establish the priority improvements to the software engineering process in Case XYZ. To overcome these problems use a framework-QFD CMMI continuous representation consisting of four phases Requirement Elicitation/Integration CMMI PAs Prioritization Practices Prioritization and Prioritization Action Plan. From CMMI PAs Prioritization phases there are five process areas with the highest priority that project monitoring and control requirements management project planning requirements development and process and product quality assurance. Then evaluated using the SCAMPI C against five selected process areas. Based on the evaluation that has been done the five selected process areas are still at the level 0. Furthermore capability of the evaluation results is then arranged on prioritizing improvements along with software engineering process.;
Proceedings of the 2019 2nd International Conference on Intelligent Science and Technology;Distributed software engineering and agility are strongly pushing on today's software industry. Due to inherent incompatibilities for years studying Scrum and its application in distributed setups has been subject to theoretical and applied research and an increasing body of knowledge reports insights into this combination. Through a systematic literature review this paper contributes a collection of experiences on the application of Scrum to global software engineering (GSE). In total we identified 40 challenges in 19 categories practitioners face when using Scrum in GSE. Among the challenges scaling Scrum to GSE and adopting practices accordingly are the most frequently named. Our findings also show that most solution proposals aim at modifying elements of the Scrum core processes. We thus conclude that even though Scrum allows for extensive modification Scrum itself represents a barrier for global software engineering and development teams have to customize Scrum properly to benefit from agile software development in GSE.;
Proceedings of the 12th International Conference on Global Software Engineering;Empirical evaluations developed in the software engineering area have been widely applied as a formalism to validate and ensure the credibility of the works proposed by the researchers. Even though the adoption of empirical evaluation techniques has gained popularity in recent years its application has been questioned both qualitatively and quantitatively. This study aims at analyzing how empirical software engineering research has evolved in the Brazilian Symposium on Software Engineering (SBES) community. We performed a controlled quasi-experiment using published papers over the last 10 years in SBES. Our experiment was divided into two phases: classification by type and quality assessment of the main empirical types. In the first phase the sample was 201 papers in the second one the sample decreased to 126 papers. The results have shown failures and gaps in the application of empirical methods when assessing the quality of the Software Engineering works. We believe that we can contribute to improve how the studies were conducted and consequently help to produce more reliable results reducing or eliminating biases: an important qualitative factor in scientific work. In addition due to the lack of assessment supporting tools we developed a theoretical protocol to support the assessment process and proposed improvements for papers that obtained below-expected rates.;
Proceedings of the XXXI Brazilian Symposium on Software Engineering;A recurring theme in discussions about the adoption of Model-Based Engineering (MBE) is its effectiveness. This is because there is a lack of empirical assessment of the processes and (tool-)use of MBE in practice. We conducted a multiple-case study by observing 2 two-month MBE projects from which software for a Mars rover were developed. We focused on assessing the distribution of the total software development effort over different development activities. Moreover we observed and collected challenges reported by the developers during the execution of projects. We found that the majority of the effort is spent on the collaboration and communication activities. Furthermore our inquiry into challenges showed that tool-related challenges are the most encountered.;
Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems;Project-based learning is an important teaching method in software engineering education. However it is unclear how student projects can be evaluated objectively and systematically in classrooms. Measurements used in industry such as quality of the codebase are not the only expected outcomes in classrooms informative assessments in project-based learning require more details about how students behave as individuals and as a team. In this paper we establish the importance of measuring processes in project-based software engineering courses and present metrics mined from software development tools for monitoring and observing processes to facilitate teaching. A case study at a US university confirms that 1) teams with better conformance to software development processes achieve better outcomes and 2) our approach can be used to design metrics that serve as early detectors of violations to software development processes. Our results suggest that instructors for software engineering courses can use our approach to design process metrics for systematic targeted and automatic evaluation of team projects. Furthermore metrics designed using our approach can be used as building blocks for automated systems and thus increase the scalability of project-based software engineering courses.;
Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education;As Artificial Intelligence (AI) techniques become more powerful and easier to use they are increasingly deployed as key components of modern software systems. While this enables new functionality and often allows better adaptation to user needs it also creates additional problems for software engineers and exposes companies to new risks. Some work has been done to better understand the interaction between Software Engineering and AI but we lack methods to classify ways of applying AI in software systems and to analyse and understand the risks this poses. Only by doing so can we devise tools and solutions to help mitigate them. This paper presents the AI in SE Application Levels (AI-SEAL) taxonomy that categorises applications according to their point of application the type of AI technology used and the automation level allowed. We show the usefulness of this taxonomy by classifying 15 papers from previous editions of the RAISE workshop. Results show that the taxonomy allows classification of distinct AI applications and provides insights concerning the risks associated with them. We argue that this will be important for companies in deciding how to apply AI in their software applications and to create strategies for its use.;
Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering;Applying current software engineering practices in the game development industry is a rapidly growing but under researched area. Whether game development studios align to traditional software engineering practices such as agile methodologies to develop their games is not known. It is also unknown how studios perceive their own adherence to such agile development practices. Furthermore struggling start-up studios could benefit from implementing development practices based on the experiences of established studios. Hence an exploratory survey was conducted to determine the practice of and perception of agile game development in New Zealand. The results show that while studios universally state and perceive that they use the agile framework Scrum and sometimes Kanban their actual practices often differ from these frameworks in key areas. Furthermore studios collectively overestimated their level of adherence with Scrum. This has general implications for related academic studies as well as for the game industry's own evaluation and improvement of their practices.;
Extended Abstracts of the Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts;Knowledge Graph (KG) is extremely efficient in storing and retrieving information from data that contains complex relationships between entities. Such a representation is relevant in software engineering projects which contain large amounts of inter-dependencies between classes modules functions etc. In this paper we propose a methodology to create a KG from software engineering documents that will be used for automated generation of test cases from natural (domain) language requirement statements. We propose a KG creation tool that includes a novel Constituency Parse Tree (CPT) based path finding algorithm for test intent extraction Conditional Random field (CRF) based Named Entity Recognition (NER) model with automatic feature engineering and a Sentence vector embedding based signal extraction. This paper demonstrates the contributions on an automotive domain software project.;
Proceedings of the 7th ACM IKDD CoDS and 25th COMAD;Background Examples of questionable statistical practice when published in high quality software engineering (SE) journals may lead to novice researchers adopting incorrect statistical practices.Objective Our goal is to highlight issues contributing to poor statistical practice in human-centric SE experiments.Method We reviewed the statistical analysis practices used in the 13 papers that reported families of human-centric SE experiments and were published in high quality journals.Results Reviewed papers related to 45 experiments and involved a total of 1303 human participants. We searched for issues that were related to questionable statistical practice that were found in more than one paper. We observed three types of bad practice: incorrect use of terminology incorrect analysis of repeated measures designs and post-hoc power testing. We also found two analysis practices (i.e. multiple testing and pre-testing for normality) where statisticians disagree about good practice.Conclusions Identified issues pose a problem because readers may expect the statistical methods used in papers published in top quality peer-reviewed journals to be correct. We explain why the practices are problematic and provide recommendations for improved practice.;
Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering;Testing is crucial to successfully engineering reliable automotive software. The manual derivation of test cases from ambiguous textual requirements is costly and error-prone. Model-based development can reduce the test case derivation effort by capturing requirements in structured models from which test cases can be generated with reduced effort. To facilitate the automated test case derivation at BMW we conducted an anonymous survey among its testing practitioners and conceived a model-based improvement of the testing activities. The new model-based test case derivation extends BMW's SMArDT method with automated generation of tests which addresses many of the practitioners' challenges uncovered through our study. This ultimately can facilitate quality assurance for automotive software.;
Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice;Using software for large-scale simulations has become an important research method in many disciplines. With increasingly complex simulations simulation software becomes a valuable assest. Yet the quality of many simulation codes is worrying. In this paper we want to collect and structure the challenges for a systematic simulation software engineering as a reference and the basis for further research. We describe our own experiences with developing simulation software and collaborating with non-computer-scientists. We complement our experienced challenges with a brief literature review. We structured the challenges for simulation software engineering into six areas: motivation and recognition education and training developer turnover software length of life verification validation and debugging and efficiency vs. maintainability. Overcoming these challenges needs efforts from research agencies scientific computing researchers as well as software engineering researchers.;
Proceedings of the 3rd International Workshop on Software Engineering for High Performance Computing in Computational Science and Engineering;Context: Work Design refers to how work is conceived assigned across organizational levels and structured into tasks performed by individuals or teams. Recent studies have argued that work characteristics need further investigation to improve our understanding of how to design work and tasks in this software engineering practice. Goal: The aim of this research is to explore work characteristics in software engineering research and to investigate the relationship between these characteristics and work outcomes. We expect that these results can lead us toward a proposal of an instrument for measuring work characteristics in software engineering and the understanding of how to use such measures to improve software development practice. Method: The methodological strategy to conduct this research includes a non-exact replication of two surveys performed in other fields. Further we plan to execute the same survey enlarging the sample and enhancing the procedures. We also intend to perform a qualitative research with a sample of the participants of the previous survey. Current status: This thesis proposal is in early stage of development. We divided this study in three phases: First we carried out a non-exact replication of two surveys performed in other areas. Professionals of Brazilian software organizations composed our sample and this phase aimed to identify the work characteristics of software development and assess the potential relationships of these characteristics with work outcomes. The second step of this study aims to enlarge our sample by including international software professionals. We also intend to enhance the variability of software development roles of the professionals in our sample. Finally we will perform qualitative research which aims to triangulate data collected in the previous phases and deepen our understanding about work characteristics in software engineering;
A concern-oriented software engineering methodology for micro-service architectures;Component-Based Systems (CBS) allow for the construction of modular highly scalable software. Decomposing a system into individually maintainable and deployable components enables a targeted replication of performance bottlenecks and promotes code modularity. Over the last years the Micro-Service Architecture (MSA) style has become a popular approach to maximize the benefits of CBS. However MSA introduces new challenges by imposing a conceptual and technological stack on adherent projects which require new critical design choices. Throughout my PhD I want to investigate to which extent a systematic reuse of MSA solutions of various granularity can streamline MSA application development by guiding design decisions.;
Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;Context: Following on other scientific disciplines such as health sciences the use of grey literature (GL) is becoming widespread in Software Engineering (SE) research. Whilst the number of papers incorporating GL on SE is increasing there is little empirically known about different aspects of the use of GL in SE research. In particular there is a lack of excellent evaluation standard for the quality of GL. Aim: Our research is aimed at systematically reviewing the use of GL in SE empirically exploring SE researchers' views on GL and providing a guide for using GL in SE and for quality assessment of the GL to be included. Method: We used a mixed-methods approach for this research. We carried out a Systematic Literature Review (SLR) of the use of GL in SE. Then we surveyed the authors of the papers included in the SLR (as GL users) and the invited experts in the SE community on the use of GL in SE research. Results: We systematically selected and reviewed 102 SE secondary studies that incorporate GL in SE research from which we identified two groups based on their reporting: 1) 76 reviews only claim their use of GL 2) 26 reviews report the results by including GL. We also obtained 20 replies from the GL users and 24 replies from the invited SE experts. Conclusion: There is no common understanding of the meaning of GL in SE. Researchers define the scopes and the definitions of GL in a variety of ways. We found five main reasons of using GL in SE research. The findings have enabled us to propose a conceptual model for how GL works in SE research lifecycle. In the next workThere is a need for research to develop guidelines for using GL in SE and for assessing quality of GL.;
Proceedings of the International Conference on Software and System Processes;Background: Studies involving industry-academia collaboration (IAC) have been growing in recent years. On the one hand scientific research is encouraged to solve real problems and on the other the sector in search of promoting innovation in its field. However IAC support is still a challenging activity for Software Engineering (SE). In recent studies the Action Research (AR) method has shown promising results in IAC projects. However more research still needs to be done to verify the effects of applying this method. Goal: In this article we investigate the perceptions of postgraduate students from an academic masterâ€™s and doctoral program in Computer Engineering at a Brazilian University about the benefits and challenges faced with the application of the AR method as a strategy to promote IAC. Method: The case study was carried out with three teams of students conducting an AR in three software development companies (two private and one public). Results: As for the degree of satisfaction with the course results revealed that 86% of the students were satisfied with the course. As for the Perception of learning with the use of AR 100% of the students agreed that the AR method contributed positively to your learning. Conclusion: Finally we conclude that conducting IAC projects using the AR method was a satisfactory even though this task has been extremely challenging for all students. We observed that the reasons for this were first the fact that students have little experience with research methods directed to Empirical Software Engineering second due to the resistance faced in the industry to apply the AR method.;
Proceedings of the XIX Brazilian Symposium on Software Quality;Ethical guidelines of software engineering journals require authors to provide statements related to the conflict of interest and the process of obtaining consent (if human subjects are involved). The objective of this study is to review the reporting of the ethical considerations in Empirical Software Engineering - An International Journal. The results indicate that two out of seven studies reported some ethical information however not explicitly. The ethical discussions were focussed on anonymity and confidentiality. Ethical aspects such as competence comprehensibility and vulnerability of the subjects were not discussed in any of the papers reviewed in this study. It is important to not only state that consent was obtained however the procedure of obtaining consent should be reported to improve the accountability and trust.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Many courses incorporate exercises at the end of the semester to help students review course topics. In computer science courses review activities are often small coding problems interactive games or review lectures. In this paper we describe our experience with replacing student-led review presentations with a collaborative software engineering exercise to serve as a review of CS1 programming concepts. The objective of this review exercise is to increase engagement and self-reflection on course topics by engineering a real-world software application to help students review programming concepts and prepare for the subsequent CS1.5 course. During the final two weeks of the course students spend three class sessions working to complete the comprehensive exercise. During the final class session each team presents its software. In this paper we describe the comprehensive exercise lessons learned from the past eight semesters (over 1400 students) and suggestions for adopting the comprehensive exercise in other CS1 courses.;
Proceedings of the 51st ACM Technical Symposium on Computer Science Education;Technological growth affects the way we live communicate and work. Over the coming decades up to 60% of existing jobs might be lost to automation. This creates pressure on the job market demanding more tech professionals while creating job insecurity for positions that might be automated. Although tech and computing is an appealing career choice with high salary job security working flexibility space for creativity and career growth vast majority of women are dropping their interest in tech during adolescence with very limited recovery in later years when preventable reasons are stopping them from reconsidering their decision and joining tech.In this paper we share our experience with a project assisting women in their 20s and 30s in changing career towards tech. The project has been implemented within our education non-profit organization called Czechitas which is recognized as the leading platform for addressing gender diversity in tech and software engineering in the Czech Republic.;
Proceedings of the 13th European Conference on Software Architecture - Volume 2;The amount of autonomy in software engineering tools is increasing as developers build increasingly complex systems. We study factors influencing software engineersâ€™ trust in an autonomous tool situated in a high stakes workplace because research in other contexts shows that too much or too little trust in autonomous tools can have negative consequences. We present the results of a ten week ethnographic case study of engineers collaborating with an autonomous tool to write control software at the National Aeronautics and Space Administration to support high stakes missions. We find that trust in an autonomous software engineering tool in this setting was influenced by four main factors: the toolâ€™s transparency usability its social context and the organizationâ€™s associated processes. Our observations lead us to frame trust as a quality the operator places in their collaboration with the automated system and we outline implications of this framing and other results for researchers studying trust in autonomous systems designers of software engineering tools and organizations conducting high stakes work with these tools.;
Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems;As a natural social evolution new generations tend to bring a shift in behavior and mindset. Studies have shown that millennial students prefer an active learning approach instead of traditional lectures. In Active Learning instead of passively listening students learn by participating in more engaging activities. As a way to gradually transition to that approach in a Software Engineering course we started experimenting LEGO-based activities which provide a simplified way to understand concepts that would be too large or too difficult to demonstrate if using programming languages to build software from scratch. In this paper we present an experience report on students learning and practicing software engineering concepts using LEGO bricks in two different activities: requirements engineering and agile project management. We adapted practices taken from industry-tailored training approaches and applied them in an undergraduate course classroom collecting feedback from students through quantitative and qualitative data. We describe the approach the perception of students and the lessons learned while teaching using that approach.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;All experimental studies are prone to risk with regard to the validity of their results. After applying a determined action to control a threat during planning or executing an experiment new risks to the study validity can arise. Aim. To improve the quality of controlled experiments in Software Engineering (SE) setting out strategies that permit researchers giving priority to specific threats in causes virtue and consequences (trade-offs) which exist between threats to validity and possible measures for control. Method. We will employ a knowledge base acquired through a survey and a Systematic Literature Review to model an approach for prioritizing and controlling threats to validity. The proposed approach will also be evaluated through experiments. Contribution. To improve the control processes for threats to validity considered to be critical reducing efforts required by researchers thereby improving the quality of future controlled experiments in the Software Engineering area by increasing its results? validity.;
Supporting software engineering research and education by annotating public videos of developers programming;Software engineering has long studied how software developers work building a body of work which forms the foundation of many software engineering best practices tools and theories. Recently some developers have begun recording videos of themselves engaged in programming tasks contributing to open source projects enabling them to share knowledge and socialize with other developers. We believe that these videos offer an important opportunity for both software engineering research and education. In this paper we discuss the potential use of these videos as well as open questions for how to best enable this envisioned use. We propose creating a central repository of programming videos enabling analyzing and annotating videos to illustrate specific behaviors of interest such as asking and answering questions employing strategies and software engineering theories. Such a repository would offer an important new way in which both software engineering researchers and students can understand how software developers work.;
Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering;Work-based learning has been in practice in Software Engineering for some time but only in recent years has it been introduced as a pathway to an honours-level undergraduate degree across the UK. Through the lens of one such scheme the Graduate Apprenticeship programme in Scotland we have investigated what challenges work-based learning degree programmes are likely to face and took this question to 26 industry partners. Also since we are aware of a persistent skills gap between Software Engineering graduates and entry-level industry roles we investigated the skills that Software Development teams are looking for in Scotland. This paper details our findings concerning perceived challenges to industry the skills and knowledge to be imparted at university and the workplace learning opportunities which can be exploited by companies.;
Proceedings of the 2019 Conference on United Kingdom &amp Ireland Computing Education Research;This experience report describes the idea of making teammates aware of personality differences and its influence on team work. This is a topic that has relevance in any team work setting in particular in Software Engineering (SE) where team work is central.We augment the teaching of team work skills to tertiary SE students through the application of the Jungian personality types. We describe how we introduce the Jungian personality dimensions. We propose an innovative method to gather information about the personality preferences of our students. The method deviates from the usual as it does not use a personality inventory survey. Instead it relies on self-rating and observations made by peers.We give an account of the activities we implement to instil understanding of the personality concepts associated with the Jungian personality types. We discuss how the students' participation in these activities helped them to apply these concepts to improve their interpersonal skills and teamwork skills. We discuss the implications of our observations. Our method to teaches students about differences between people using the Jungian personality types as a basis to highlight these differences and how they can capitalise on these differences. At the same time knowledge of these differences help students who may feel different because they gain awareness of the value of these differences. We conclude that the practicality of knowledge of the Jungian personality types is beneficial in our context.;
Proceedings of the 52nd ACM Technical Symposium on Computer Science Education;In the software engineering industry today companies primarily conduct their work in teams. To increase organizational productivity it is thus crucial to know the factors that affect team effectiveness. Two team-related concepts that have gained prominence lately are psychological safety and team norms. Still few studies exist that explore these in a software engineering context.Therefore with the aim of extending the knowledge of these concepts we examined if psychological safety and team norm clarity associate positively with software developers' self-assessed team performance and job satisfaction two important elements of effectiveness.We collected industry survey data from practitioners (N = 217) in 38 development teams working for five different organizations. The result of multiple linear regression analyses indicates that both psychological safety and team norm clarity predict team members' self-assessed performance and job satisfaction. The findings also suggest that clarity of norms is a stronger (30% and 71% stronger) predictor than psychological safety.This research highlights the need to examine in more detail the relationship between social norms and software development. The findings of this study could serve as an empirical baseline for such future work.;
Proceedings of the 11th International Workshop on Cooperative and Human Aspects of Software Engineering;As the importance of non-technical skills in the software engineering industry increases the skill sets of graduates match less and less with industry expectations. A growing body of research exists that attempts to identify this skill gap. However only few so far explicitly compare opinions of the industry with what is currently being taught in academia. By aggregating data from three previous works we identify the three biggest non-technical skill gaps between industry and academia for the field of software engineering: devoting oneself to continuous learning being creative by approaching a problem from different angles and thinking in a solution-oriented way by favoring outcome over ego. Eight follow-up interviews were conducted to further explore how the industry perceives these skill gaps yielding 26 sub-themes grouped into six bigger themes: stimulating continuous learning stimulating creativity creative techniques addressing the gap in education skill requirements in industry and the industry selection process. With this work we hope to inspire educators to give the necessary attention to the uncovered skills further mitigating the gap between the industry and the academic world.;
A roadmap for ethics-aware software engineering;Today's software is highly intertwined with our lives and it possesses an increasing ability to act and influence us. Besides the renown example of self-driving cars and their potential harmfulness more mundane software such as social networks can introduce bias break privacy preferences lead to digital addiction etc. Additionally the software engineering (SE) process itself is highly affected by ethical issues such as diversity and business ethics. This paper introduces ethics-aware SE a version of SE in which the ethical values of the stakeholders (including developers and users) are captured analyzed and reflected in software specifications and in the SE processes. We propose an analytical framework that assists stakeholders in analyzing ethical issues in terms of subject (software artifact or SE process) relevant value (diversity privacy autonomy ...) and threatened object (user developer ...). We also define a roadmap that illustrates the necessary steps for the SE research and practice community in order to fully realize ethics-aware SE.;
Proceedings of the International Workshop on Software Fairness;In 2003 the original paper with this title was published as part of CSEET 2003. It focused on resolving communication issues between software project managers and developers and introduced a corporate strategy based means of evaluating software engineers. Now more than a decade later we could benefit from what we have learned in other fields about managing people involved in knowledge work and how to improve our success in software development. But are we? This paper is intended to present what Software Engineering students can be taught today that will help them to be successful as software project managers now and in the future. It is based on the premise that effective software project managers are not born but made through education.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Novel research ideas require strong evaluations. Modern software engineering research evaluation typically requires a set of benchmark programs. Open source software repositories have provided a great opportunity for researchers to find such programs for use in their evaluations. Many tools/techniques have been developed to help automate the curation of open source software. There has also been encouragement for researchers to provide their research artifacts so that other researchers can easily reproduce the results. We argue that these two trends (i.e. curating open source software for research evaluation and the providing of research artifacts) drive the need for Software Engineer Collaboratories (SEClabs). We envision research communities coming together to create SEClab instances where research artifacts can be made publicly available to other researchers. The community can then vet such artifacts and make them available as a service thus turning the collaboratory into a Collaboratory as a Service (CaaS). If our vision is realized the speed and transparency of research will drastically increase.;
Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Software productivity is perceived by practitioners as one of the most important subjects of Software Engineering (SE) because it establishes a connection between technical and economic concerns. Nonetheless software processes are complex and productivity means different things to different people. In order to realize the full contribution of productivity research to the practice of SE the compilation and analysis of the diverse practitioner viewpoints and concerns is required. In this paper we develop a systematic literature review to confirm the existence of different empirical perceptions of productivity from the distinct business sectors and knowledge areas covered in practice by SE identifying also commonalities that may exist. This review was compiled by analyzing 73 papers on empirical studies published from 1987 to 2017. The review found great variability of study findings particularly concerning the impacts of agile and hybrid development practices on software productivity and research gaps that could be investigated in the future.;
Proceedings of the International Conference on Software and System Processes;"Smart Cyber--Physical Systems (sCPS) are modern CPS systems that are engineered to seamlessly integrate a large number of computation and physical components they need to control entities in their environment in a smart and collective way to achieve a high degree of effectiveness and efficiency. At the same time these systems are supposed to be safe and secure deal with environment dynamicity and uncertainty cope with external threats and optimize their behavior to achieve the best possible outcome. This smartness"" typically stems from highly cooperative behavior self--awareness self--adaptation and selfoptimization. Most of the ""smartness"" is implemented in software which makes the software one of the most complex and most critical constituents of sCPS. As the specifics of sCPS render traditional software engineering approaches not directly applicable new and innovative approaches to software engineering of sCPS need to be sought. This paper reports on the results of the Second International Workshop on Software Engineering for Smart Cyber--Physical Systems (SEsCPS 2016) which specifically focuses on challenges and promising solutions in the area of software engineering for sCPS.""";
Incorporating devops into undergraduate software engineering courses: a suggested framework;DevOps is a current trend for application development and delivery in the industry. Teaching about DevOps in an undergraduate software engineering course is difficult because the number of new concepts involved is high and most students lack experience with them. This paper presents our initial experience integrating DevOps into undergraduate software engineering coursework. It discusses DevOps itself and introduces a basic framework for introducing DevOps into a software engineering sequence. Finally we discuss how we currently approach DevOps instruction and where we need to go to fit within the suggested framework.;
Leveraging small software engineering data sets with pre-trained neural networks;Many software engineering data sets particularly those that demand manual labelling for classification are necessarily small. As a consequence several recent software engineering papers have cast doubt on the effectiveness of deep neural networks for classification tasks when applied to these data sets. We provide initial evidence that recent advances in Natural Language Processing that allow neural networks to leverage large amount of unlabelled data in a pre-training phase can significantly improve performance.;
Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results;Agile Methodologies have brought insights into how to develop software by focusing on individuals and relationships and valuing diversity teams. Moreover only professional diversity is considered where different skills and knowledge facilitate self-sufficiency and consequently self-performance. However the concept of diversity goes beyond this perspective. In this context this paper aims at identifying the main techniques that allow an open concept of social inclusion and diversity in agile software development teams and propose any necessary adaptations to help absolute diversity. In order to do so techniques found in the literature review were presented to experts (i) within the software development industry and working under agile methodologies and (ii) with disabilities or people who coordinate teams with people with disabilities. The results show techniques to promote inclusion in agile teams including Daily Meeting Pair Programming Review Retrospective Effort Estimating Workshop and Code Challenges. Despite the use of these techniques specific tools knowledge of sign language and inattention to make an environment suitable for professionals to feel confident and empowered are the main challenges faced by agile teams with people with disabilities.;
Proceedings of the XIX Brazilian Symposium on Software Quality;Construct validity is essentially the degree to which our scales metrics and instruments actually measure the properties they are supposed to measure. Although construct validity is widely considered an important quality criterion for most empirical research many software engineering studies simply assume that proposed measures are valid and make no attempt to assess construct validity. Researchers may ignore construct validity because evaluating it is intrinsically difficult or due to lack of specific guidance for addressing it. In any case some research inevitably produces erroneous conclusions because due to invalid measures. This article therefore attempts to address these problems by explaining the theoretical basis of construct validity presenting a framework for understanding it and developing specific guidelines for assessing it. The paper draws on a detailed example involving 15 software metrics which ostensibly measure the size coupling and cohesion of Java classes.;
Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018;Sentiment analysis has various application scenarios in software engineering (SE) such as detecting developers' emotions in commit messages and identifying their opinions on Q&ampA forums. However commonly used out-of-the-box sentiment analysis tools cannot obtain reliable results on SE tasks and the misunderstanding of technical jargon is demonstrated to be the main reason. Then researchers have to utilize labeled SE-related texts to customize sentiment analysis for SE tasks via a variety of algorithms. However the scarce labeled data can cover only very limited expressions and thus cannot guarantee the analysis quality. To address such a problem we turn to the easily available emoji usage data for help. More specifically we employ emotional emojis as noisy labels of sentiments and propose a representation learning approach that uses both Tweets and GitHub posts containing emojis to learn sentiment-aware representations for SE-related texts. These emoji-labeled posts can not only supply the technical jargon but also incorporate more general sentiment patterns shared across domains. They as well as labeled data are used to learn the final sentiment classifier. Compared to the existing sentiment analysis methods used in SE the proposed approach can achieve significant improvement on representative benchmark datasets. By further contrast experiments we find that the Tweets make a key contribution to the power of our approach. This finding informs future research not to unilaterally pursue the domain-specific resource but try to transform knowledge from the open domain through ubiquitous signals such as emojis.;
Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;New teaching approaches like the flipped classroom are an interesting alternative to educate new generations but they represent new challenges for teachers. This paper describes our experience re-designing our classes and study materials in order to adopt a flipped classroom approach combined with some other non-traditional teaching techniques. This experience is focused on the Software Engineering course at Universidad Nacional de Tres de Febrero. In this paper we share details of our strategy the positive results we obtained and the concerns we still need to address.;
Proceedings of the 1st International Workshop on Software Engineering Curricula for Millennials;On the background of Emerging Engineering Education (3E) in China it has been an important topic in school-enterprise collaboration in software engineering education. In this paper our outcome-based school-enterprise cooperative software engineering training is proposed to increase student engagement of engineering practice and address some real complicated engineering issue. Contributions of our method are project-driven agile practice using pair programming and extreme programming school-enterprise collaboration to address complicated engineering issues and outcome-based encouragement to formulate a case library. Finally complete time estimation and quality of work order and detailed survey and feedbacks of students are analyzed to illustrate the effect of our software engineering training.;
Proceedings of ACM Turing Celebration Conference - China;Social psychology researchers have traditionally focused on the construct of thinking rather than on feeling. Since the beginning of the 21st century social science researchers have however increasingly explored the effects of affect. Their work has repeatedly recognized that affects play a crucial role in determining people's behavior. In this short paper we argue that software engineering studies on affect would benefit from using more of the knowledge that social science researchers have acquired. Without accounting for their findings we risk re-inventing the wheel. Also without a profound understanding of the complex interplay between social context and affect we risk creating overly simplistic solutions that might have considerable long-term adverse effects for software engineers.;
Proceedings of the 4th International Workshop on Emotion Awareness in Software Engineering;The features developed by a software engineer (system specification) for a software system may significantly differ from the features required by a user (user requirements) for their envisioned system. These discrepancies are generally resulted from the complexity of the system the vagueness of the user requirements or the lack of knowledge and experience of the software engineer. The principles of software engineering and the recommendations of the ACM's Software Engineering Education Knowledge (SEEK) document can provide solutions to minimize these discrepancies in turn improve the quality of a software system and increase user satisfaction. In this paper a software development framework called SETh is presented. The SETh framework consists of a set of visual models that support software engineering education and practices in a systematic manner. It also enables backward tracking/tracing and forward tracking/tracing capabilities - two important concepts that can facilitate the greenfield and evolutionary type software engineering projects. The SETh framework connects every step of the development of a software system tightly hence the learners and the experienced software engineers can study understand and build efficient software systems for emerging data science applications.;
Proceedings of the 2018 ACM Southeast Conference;Context. Member checking can be defined as a research phase performed during a qualitative research in which the researcher compares her interpretations and understanding obtained from the data analysis with the view-points of participants to increase accuracy and consistency of results. This is an important step for any qualitative research. However considering a sample of 66 case studies developed and published in the context of software engineering only 10 studies briefly described the use of this technique. Method. In this article we present a set of lessons learned obtained from planning and performing member checking to validate the results of an industrial case study performed in a large software company. Results. Member checking was effective to validate the findings obtained from the qualitative case study and was also useful to reveal important information not observed in the data analysis process. It has also shown to be effective to observe divergences among different groups of participants. Conclusion. We described how the member checking can be performed and discussed seven lessons learned in this process. We expect that our experience can be useful to software engineering researchers while performing this research phase in case studies.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Context: Researchers from different groups and institutions are collaborating towards the construction of groups of interrelated replications. Applying unsuitable techniques to aggregate interrelated replications' results may impact the reliability of joint conclusions.Objectives: Comparing the advantages and disadvantages of the techniques applied to aggregate interrelated replications' results in Software Engineering (SE).Method: We conducted a literature review to identify the techniques applied to aggregate interrelated replications' results in SE. We analyze a prototypical group of interrelated replications in SE with the techniques that we identified. We check whether the advantages and disadvantages of each technique---according to mature experimental disciplines such as medicine---materialize in the SE context.Results: Narrative synthesis and Aggregation of p-values do not take advantage of all the information contained within the raw-data for providing joint conclusions. Aggregated Data (AD) meta-analysis provides visual summaries of results and allows assessing experiment-level moderators. Individual Participant Data (IPD) meta-analysis allows interpreting results in natural units and assessing experiment-level and participant-level moderators.Conclusion: All the information contained within the raw-data should be used to provide joint conclusions. AD and IPD when used in tandem seem suitable to analyze groups of interrelated replications in SE.;
Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;This industry case study explores where and how Design Thinking supports software development teams in their endeavour to create innovative software solutions. Design Thinking has found its way into software companies ranging from startups to SMEs and multinationals. It is mostly seen as a human centered innovation approach or a way to elicit requirements in a more agile fashion. However research in Design Thinking suggests that being exposed to DT changes the mindset of employees. Thus this article aims to explore the wider use of DT within software companies through a case study in a multinational organization. Our results indicate that once trained in DT employees find various ways to implement it not only as a pre-phase to software development but throughout their projects even applying it to aspects of their surroundings such as the development process team spaces and team work. Specifically we present a model of how DT manifests itself in a software development company.;
Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Continuous software engineering (CSE) emerged as a process that is increasingly applied by practitioners. However different perceptions of CSE among practitioners might impede its adoption in industry. We aim to support practitioners by giving a comprehensive overview of current CSE practices. Our observations provide guidance for practice on how to establish assess and advance CSE in their company. We conducted an interview study with 24 practitioners from 17 companies during 20 interviews. Following a semi-structured approach we asked for their definition of CSE most relevant elements for CSE their experiences and plans for further additions to their CSE process. From the practitioners' statements we identified five perspectives on CSE and found tool- and methodology-driven definitions most prevalent. Automated tests involved users and a shared ruleset are perceived as most relevant for CSE. Practitioners' positive experiences with CSE are more frequent than negative ones however more than half of the responses were neutral. Practitioners' future plans focus on enhancement expansion and on-demand adaption of current practices. We conclude that CSE remains partially difficult to capture for practitioners. Therefore we structure CSE in a model the Eye of CSE.;
Proceedings of the 2018 International Conference on Software and System Process;Software Engineering courses often incorporate large-scale projects with collaboration between students working in teams. However it is difficult to objectively assess individual students when their projects are a product of collaborative efforts. This study explores measurements of individuals' contributions to their respective teams.I analyzed ten Software Engineering team projects (n=42) and evaluations of individual contributions using automated evaluation of the version control system history (Git logs) and user stories completed on their project management (Kanban) boards. Unique insights from meta-data within the Git history and Kanban board user stories reveal complicated relationships between these measurements and traditional assessments such as peer review and subjective instructor evaluation. From the results I suggest supplementing and validating traditional assessments with insights from individuals' commit history and user story contributions.;
Proceedings of the 51st ACM Technical Symposium on Computer Science Education;Software producing organizations have the ability to address the energy impact of their ICT solutions during the development process. However while industry is convinced of the energy impact of hardware the role of software has mostly been acknowledged by researchers in software engineering. Strengthened by the limited practical knowledge to reduce the energy consumption organizations have less control over the energy impact of their products and lose the contribution of software towards energy related strategies. Consequently industry risks not being able to meet customer requirements or even fulfill corporate sustainability goals.In this paper we perform an exploratory case study on how to create and maintain awareness on an energy consumption perspective for software among stakeholders involved with the development of software products. During the study we followed the development process of two commercial software products and provided direct feedback to the stakeholders on the effects of their development efforts specifically concerning energy consumption and performance using an energy dashboard. Multiple awareness measurements allowed us to keep track of changes over time on specific aspects affecting software development. Our results show that despite a mixed sentiment towards the dashboard changed awareness has triggered discussion on the energy consumption of software.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Society Track;Creating a graduate-level software engineering breadth course is challenging. The scope is wide. Students prefer hands-on work over theory. Industry increasingly values soft skills. Changing software technology requires the syllabus to be technology-agnostic yet abstracting away technology compromises realism. Instructors must balance scope with depth of learning. At Carnegie Mellon University we designed a flipped-classroom course that tackles these tradeoffs. The course has been offered since Fall 2014 in the Silicon Valley campus. In this paper we describe the course's key features and summarize our experiences and lessons learned while designing teaching and maintaining it. We found that the pure flipped-classroom format was not optimal in ensuring sufficient transfer of knowledge especially in remote settings. We initially underestimated teaching assistantship resources. We gradually complemented video lectures and hands-on live sessions with additional live components: easily replaceable recitations that focus on current technology and mini lectures that address application of theory and common wisdom. We also provided the students with more opportunities to share their successes and experiments with their peers. We achieved scalability by increasing the number of teaching assistants paying attention to teaching assistant recruitment and fostering a culture of mentoring among the teaching team.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Many challenges in software projects are sociological psychological or managerial in nature. Without knowledge of social science developers managers and researchers may misunderstand the social aspects of their projects leading to ineffective decisions and actions. Yet social science theories are rarely applied to Software Engineering (SE). Furthermore understanding a single software project frequently necessitates combining multiple theories---often from several disciplines. This paper therefore aims to illustrate how certain social theories work together in a complementary manner to understand various dynamics of a software development project. To illustrate this seven theories to understand key dynamics --- Actor Network Theory Theory of Boundary Objects Complexity Theory Theory of Cognitive Biases Effectuation Theory Sensemaking-Coevolution-Implementation Theory and Transactive Memory Theory --- are used to explain a longitudinal study of a software development project. This study illustrates the need for integrating more social science into SE research and curriculum.;
Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering;Context: Task interdependence is one of the social characteristics of work design which has been related by some authors to the level of interaction between team members and their results. In recent years more research aiming to investigate the interactions between people and teamwork in Software Engineering (SE) has been conducted. However few of these initiatives have been associated with work design especially as related to task interdependence in SE. Goal: To investigate the perception of the individuals in a software development team concerning task interdependence and their individual impact on teamwork dynamics. Method: We investigated a development team from a Brazilian software development company. For data collection interviews were conducted and qualitative coding techniques were used to analyze and synthesize our findings. In addition we have the support of an analytical framework built at the commencement of our research. Results: Task interdependence increases the need for information sharing and synchronization of tasks it also favors the creation of an environment conducive to redundancy of knowledge and mutual help and it is moderated by interpersonal relationships a sense of belonging and individual competencies and skills favoring the generation of better results in software development teams. Conclusion: Task interdependence is an important practice and an essential and impacting factor in teamwork dynamics which can enhance the performance of software development teams.;
Proceedings of the 11th International Workshop on Cooperative and Human Aspects of Software Engineering;With the advent of social media developers are increasingly using it in their software development activities. Twitter is one of the popular social mediums used by developers. A recent study by Singer et al. found that software developers use Twitter to â€œkeep up with the fast-paced development landscape.â€ Unfortunately due to the general-purpose nature of Twitter itâ€™s challenging for developers to use Twitter for their development activities. Our survey with 36 developers who use Twitter in their development activities highlights that developers are interested in following specialized software gurus who share relevant technical tweets.To help developers perform this task in this work we propose a recommendation system to identify specialized software gurus. Our approach first extracts different kinds of features that characterize a Twitter user and then employs a two-stage classification approach to generate a discriminative model which can differentiate specialized software gurus in a particular domain from other Twitter users that generate domain-related tweets (aka domain-related Twitter users). We have investigated the effectiveness of our approach in finding specialized software gurus for four different domains (JavaScript Android Python and Linux) on a dataset of 86824 Twitter users who generate 5517878 tweets over 1 month. Our approach can differentiate specialized software experts from other domain-related Twitter users with an F-Measure of up to 0.820. Compared with existing Twitter domain expert recommendation approaches our proposed approach can outperform their F-Measure by at least 7.63%.;
Specification-Based Testing in Software Engineering Courses;"In 2016 we introduced a tool called Spest// for the automated generation of software tests from formal specifications. That introductory presentation of Spest described its basic functionality and our initial results of using Spest in software engineering courses. Here we describe further experience of using Spest in classes including qualitative and quantitative analyses of its effectiveness. The analysis consists of a qualitative survey of students/ experience a quantitative study of the readability of Spest-generated tests and a quantitative analysis that compares the coverage quality of hand-written student tests with Spest-generated tests. The results of the analyses are mixed. The experience survey finds that a majority of students did not enjoy using Spest nor fully understand how to use it effectively. The results of the readability study show that Spest-generated tests are not as readable for students as tests written by human experts however the differences in readability are not extreme. Finally the results of the coverage comparison are good showing that Spest-generated tests achieve better code coverage than students/ hand-written tests. Given the mixed results we discuss how we are moving forward to make Spest a more usable and effective tool.""";
Proceedings of the 49th ACM Technical Symposium on Computer Science Education;"In specialization courses normally the students have concepts from some subjects already consolidated in the undergraduate program. To motivate these students in those disciplines is a challenge to the teacher. The use of gamification"" concepts that is application of games in activities that are not games per se is a methodological solution for the motivation in the classes. In order to evaluate the usage of this technique an experiment was conducted with a Software Engineering specialization class. The class was divided into teams and through various play activities the executed works were being scored. Three teaching methodologies were applied: Learning based in problems based in projects and mental maps. At the end of the course a questionnaire was applied so that the students could evaluate the methodology. The obtained results were satisfactory because there was a greater engagement of the students during class.""";
Proceedings of the XXXI Brazilian Symposium on Software Engineering;The employment opportunity for Computer Science (CS) Information Technology and Software Engineering and Development (SE) related occupations is projected to grow much faster than the average of all other occupations. Therefore increase in student enrollment retention and graduation rate is becoming very important so is the need for effective teaching in these subjects. Many universities commonly use formal institutional Student Evaluation of Teaching (SET) systems to measure the teaching effectiveness. After each semester through SET students provide feedback and comments for their courses and instructors. However evaluations are private and only a handful people have access to these. Therefore these evaluations cannot be utilized to create a common understanding of the students' expectations perspective desired characteristics of the courses and instructors. On the other hand third party online platforms like RateMyProfessor.com (RMP) are public solicit anonymous student feedback and host tremendous amount of data about the instructors and their courses. These platforms are also popular among students. We mined and analyzed the RMP data for some research questions e.g.: What are the common characteristics of the popular CS instructors? How different are they for the SE instructors? Are there any examples of special characteristics tools and techniques popular CS instructors use? We captured and analyzed more than 9000 students' comments for over 300 CS instructors for the top 20 universities in the U.S. and Canada. The paper contributes by presenting the findings for the research questions and making the data and the scripts available for public use for future research.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training;Modern web application development provides an attractive application area for introductory software engineering education as students have direct experience with the domain and it provides them with the potential to gain practical real-world skills. Achieving this potential requires the development of competency with a multiple component tech stack for web application development which is challenging to acquire within a single semester. In this research we designed implemented and evaluated a new pedagogy called â€œathletic software engineeringâ€ which is intended to help students efficiently and effectively acquire competency with a multiple component tech stack as a precursor to a web application development project. We evaluated the pedagogy over 4 years and six semesters with 286 students and found strong evidence for its effectiveness.;
Towards a body of knowledge for model-based software engineering;Model-based Software Engineering (MBSE) is now accepted as a Software Engineering (SE) discipline and is being taught as part of more general SE curricula. However an agreed core of concepts mechanisms and practices --- which constitutes the Body of Knowledge of a discipline --- has not been captured anywhere and is only partially covered by the SE Body of Knowledge (SWEBOK). With the goals of characterizing the contents of the MBSE discipline promoting a consistent view of it worldwide clarifying its scope with regard to other SE disciplines and defining a foundation for a curriculum development on MBSE this paper provides a proposal for an extension of the contents of SWEBOK with the set of fundamental concepts terms and mechanisms that should constitute the MBSE Body of Knowledge.;
Proceedings of the 21st ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings;Understanding how the concepts of sustainability could be incorporated to the Software Engineering (SE) concepts has gained increased attention in the last years particularly in terms of the Software Development Life Cycle (SDLC). Several studies have addressed the impact of sustainability in the SE practice from a range of perspectives. This study presents a systematic mapping study that aggregates summarizes and discusses the state-of-the-art approaches for sustainable SE practice. We analyzed 75 relevant primary studies addressing methods processes tools and metrics proposed to support the software development in a sustainable way. The included primary studies were selected using inclusion and exclusion criteria applied to studies published prior to 2017. They were analyzed based on a set of classification criteria including contribution types SDLC phases evidence types research types application domains publication venues distribution between academia and industry and research methods. The results indicated a growing interest by the SE research community in the Green and Sustainable software domain. Besides there is an observed need for more studies on techniques tools and metrics covering construction testing and maintenance. The results also point out a clear view of the SE community about the need for a better alignment between research and practice in this domain.;
Proceedings of the XVII Brazilian Symposium on Software Quality;Context: Women are generally underrepresented in software development and probably their behavior is biased by the fact that they are usually a minority within teams. The Engineering School at the Universidad de Chile has put in practice a strong women recruitment program. This brought that for the first time women reached 20% of the students enrolled in the fifth year software engineering capstone course.Problem: More women are entering the work force but there is still certain prejudice about women performance in STEM in general and in software development in particular since it is perceived as a man's activity.Method: In the context of the fifth year capstone course at the CS Department of the Universidad de Chile we conducted a field study in order to analyze the progression of self and peer assessment of men and women students along one semester.Results: We found that even though peer assessment is similar for women and men self assessment tends to be lower for women. Also peer assessment does not vary much along the semester neither for men nor for women.Conclusions: Women performance in software development teams is highly regarded by teammates. However women do not seem to be willing to acknowledge their own performance. More research is needed in order to understands the causes of this behavior.;
Proceedings of the 2nd International Workshop on Gender Equality in Software Engineering;This paper presents an analysis of the skills and professional competencies that recent graduates from computing and software engineering programmes recommend for current students. Previous studies have not investigated the viewpoints of early-career engineers and the current study addresses this research gap. The data used in this study comes from nationwide career monitoring surveys for former university students who graduated five years earlier. We analyzed the responses to questions about the skills and competencies needed in the software or computing jobs and compared them with the satisfaction and career paths of the respondents. According to the results three types of skills and competencies are paramount: Soft skills in general programming skills and the practical experience gained during university studies. A logistic regression analysis revealed that soft skills are recommended by those who are most satisfied with their careers. Practical skills are more likely to be recommended if the respondent is less satisfied with their studies. Based on the findings we concluded that the responses from the career monitoring survey could be used as an indicator of how well studies prepare graduates for the industry.;
Proceedings of the 2022 Conference on United Kingdom &amp Ireland Computing Education Research;Context: Software development process is executed by professionals with different roles who are responsible for distinct activities. These roles can have different degrees of autonomy depending on some factors such as the adopted process and hierarchy. Goal: This study aims to identify what factors can impact autonomy and also investigate how autonomy is given to an employee based on two main factors: education level and professional experience. Methodology: Initially a survey was carried out to understand how autonomy is perceived by 102 software engineers as well as by 83 professionals from other areas. The next step was applying semi-structured interviews with software engineers to find a better understanding of the quantitative findings. Results: In general education level and professional experience do not have an impact on autonomy. Only when autonomy is evaluated from the education level perspective there is a significant difference among the respondents. During the interviews we also could identify some topics that respondents mentioned which were related to autonomy. For example the experience that software engineer has in a current project and the development process adopted by the company influence how autonomy is perceived. Conclusion: While professional qualification and experience are not directly related to autonomy the lack of process and the amount of work experience on specific projects seem to be relevant factors to be aware of.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Psychology and Business Administration have been studying maturity for a long time. On Software Engineering field most of work has been focusing on maturity of technical practices and processes. Teams with high levels of maturity are associated to more positive relations between the quality of intra-team relationships and the quality and quantity of team outcomes. Aiming to understand how Software Engineers understand the concept of Team Maturity we performed a qualitative research collecting data from 32 team members from 6 different companies in Brazil in the cities of Brasilia Recife and Rio de Janeiro. So far we identified some characteristics that are described as making part of a mature team which also leaded us to some hypothesis to be confirmed in future studies.;
Proceedings of the 10th International Workshop on Cooperative and Human Aspects of Software Engineering;Society becomes more dependent on software and the quality of software has a direct and vital impact on the life of people. Therefore the importance of software engineering ethics is highlighted. Further it is necessary to increase the emphasis on ethics education in software engineering curricula. However in practice there is generally not a single software engineering ethics course. Even if there is it is a marginal role. How to effectively integrate ethics topics into software engineering education is a key issue. In this paper we first analyze the relevance of two domains: Software Engineering Code of Ethics and Professional Practice and software engineering management that is a subdomain of Software Engineering Body of Knowledge. The results show that they are highly related. Therefore it is feasible and reasonable to integrate ethics issues into the course of software engineering management which is usually a required course. This integration brings a solid position for the ethical education. In addition we suggest new description of codes to promote their fusion further put forward some ideas about their fusion in education practice. Our contribution is to put forward a new idea for the ethics education in software engineering field.;
Proceedings of ACM Turing Celebration Conference - China;With the pervasive need for digitization in modern information society publicly funded research projects increasingly focus on engineering digital approaches to manage societal processes. Such projects inherently face the challenge of establishing a sustainable software engineering culture. A major challenge thereby is that project consortia need to establish a distributed developer community that effectively and resource-efficiently aligns development efforts with the goals and needs of complex societal constellations beyond project lifetime. In this paper we extract empirical evidence from longitudinal studies in two large-scale research projects to outline typical challenges in such problem contexts and to develop an open source software engineering methodology for research projects including supportive infrastructure and social instruments of community building and awareness. We thus contribute a comprehensive strategy preparing collaborative research projects for sustainable societal software engineering.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Society Track;Software engineers must be able to manage complex projects so that skills such as teamwork leadership or initiative are critical to their successful development. Because of this it is fundamental that the learning of software engineering as an academic discipline provides solid links between theory and practice. Educational frameworks such as those derived from the European Higher Education Area state that student-centered approaches are a useful tool for achieving these objectives. In this context we present a project-based learning (PBL) experience report in a software engineering program of a Spanish university. The experience is based on the formation of small heterogeneous teams which face the initial phases of a software methodology during the development of a project close to a real one. Through a strategy of role rotation and documentation transfer all students perform different tasks and face different challenges throughout the project. Summative assessment is also adopted considering not only teacher ratings but also students' peer assessment. The results prove the positive effect of using PBL to improve the training of students in acquiring different skills as future software engineers.;
Proceedings of the 51st ACM Technical Symposium on Computer Science Education;Video tutorials are an emerging form of documentation in software engineering and can efficiently provide developers with useful information needed for their daily tasks. However to get the information they need developers have to find the right tutorial for their task at hand. Currently there is little information available to quickly judge whether a tutorial is relevant to a topic or helpful to the task at hand which can lead to missing the best tutorials and wasting time watching irrelevant ones. We present the first efforts towards new tagging approaches using text retrieval that describe the contents of software engineering video tutorials making it easier and faster to understand their purpose and contents. We also present the results of a preliminary evaluation of thirteen such approaches revealing the potential of some and limitations of others.;
Proceedings of the 39th International Conference on Software Engineering Companion;We discuss the design of a class project which we have introduced to improve our Software Engineering course presented on the third-year graduate level at our institution. For this project the whole class collaborate to design and implement a single reasonably large software system. We believe that the class project has the potential to provide an intensive learning experience for our students and may have several educational benefits.We investigate the impact of the class project on student academic achievement and project success in terms of the quality of the code of the developed system. We gauge the impact of the class project by analysing differences the academic performance of the students in the course. Further we analyzed the differences in assessment marks assigned to projects. We also evaluate the code quality by observing variations in selected software code metrics of the source code of the software systems delivered by the students.Although the results are inconclusive we feel the class project provides a unique opportunity for students to get hands-on experience in the development of real-world software for industry.;
Proceedings of the 8th Computer Science Education Research Conference;Teaching software engineering design to large diverse cohorts poses many challenges. Many students lacking object oriented programming skills find UML designs difficult while large class sizes limit opportunities for interaction. The need to consider different design aspects such as reusability extensibility etc. makes the manual assignment feedback a slow process. Moreover such feedback is subjective being a reflection of the individual marker's view about various design aspects. There have been little or no past attempts to provide instant and consistent feedback using constructivist tools as with programming tasks mainly because a good or correct design is difficult to define and verify.This paper presents the result of our action research to improve student design skills. Our approach combines project-based learning with weekly quizzes tests and active learning tasks. Quiz questions tagged with underlying concepts and cognitive levels allowed us to identify common misconceptions. Quizzes set at analysis and synthesis levels appear to foster better software design skills. Active learning tools devised helped to correct common misconceptions by providing immediate and holistic feedback. The new teaching approach helped us to improve student retention satisfaction and performance substantially.;
Proceedings of the Nineteenth Australasian Computing Education Conference;"Commonly the instruction of Software Engineering implements processes that are inherent to the theory and practice of software development. Traditional and Agile methods lay the foundation for building functional software products"" that meet the requirements of a system of a larger scope. However if we consider software as a product that frequently has the mission of satisfying the needs of human users we can go beyond the typical ""analysis - design - implementation - testing"" process to reinterpret it with the ""empathize - define - ideate - prototype - testing"" proposed by Design Thinking a development methodology commonly used in creative and innovative professional settings. In this work we study the use of Design Thinking as a methodological approach for the instruction of Software Engineering at undergraduate level in courses that have the particular aim of creating innovative software products from scratch. We describe the similarities and differences between Design Thinking and Software Development Processes taking as instance Agile Practices. We compare evidence on methods and deliverables produced by students in their learning path using Agile Practices and Design Thinking in two different educational environments. Finally we discuss coincidences weaknesses and opportunities to keep investigating in this topic as a research subject toward finding practices to promote in students both creativity and technical discipline to develop innovative software solutions""";
Proceedings of the 19th Annual SIG Conference on Information Technology Education;With the rapid development of information technology the traditional industry is changing dramatically. There are big opportunities in the domain Aerospace &amp Aviation at the same time. As the core software of the aero engine control unit FADEC software is a kind of safety critical software which the processes of its development must do the compliance of RTCA DO-178C [1] and cost-effective of its development is a grand challenge.Information technology provides a new method for impoving the efficiency of safety critical software[2].Through information technology some tasks of software development were automatically run by machines such as source code building static analysis and unit test of source code and so on.Because of the particularly of FADEC software all run tasks needs to meet strict process specifications in order to ensure high guality of software[3]. Meanwhile the construction of information has invested huge costs to ensure the stability and reliability of the environment which was depended by autorun tasks.As an information-based builder of software engineering we need to be able to master the effectiveness of information technology to software development.This paper introduces a method to measure information technology effect based on data classification collection and visualization. Through the data Visualization the software support team and the R&ampD team will be able to cooperate more efficiently and improve efficiency of FADEC software project.;
Proceedings of the 2018 International Conference on Computing and Data Engineering;The recent upsurge of Apps APIs and Cloud platforms combined with the perpetual need of shorter time to market motivates the need for approaches for rapid software engineering to compose applications quickly. In this paper we propose a portal based approach to intelligently assist in creating composite applications. We discuss the underlying concepts and the techniques proposed in our approach and demonstrate its usage through a liquid application portal. Our approach aims to help automate the processing of visual requirements intelligently identify reusable components based on the requirements and help in designing the application on a visual canvas using these components. The approach results in a manifest that can serve as a blueprint to compose the application quickly on modern platforms. We show a use-case to walk-through all stages of our proposed approach and describe the proof-of-concept for the same.;
Proceedings of the 3rd International Workshop on Rapid Continuous Software Engineering;Green and sustainable software engineering is an emerging research field which aims at creating using and disposing the energy-efficient software in an environment friendly manner with less negative impacts. The research community strongly believes that the energy efficiency and sustainability of the software can be improved by modifying the existing software engineering methods. This systematic mapping study identifies and map such methods for green and sustainable software development. Especially this study identifies the research types research goals software engineering research topics accepted validation methods and publication fora that are used in the field of green and sustainable software engineering. This study was conducted with 7 research questions and analyzed 82 relevant studies. We have used snowballing reading to find out the relevant studies that were published from 2010 to May 2016. One of the important finding of this study is there are less number of contributions on software design and construction. In future sufficient research works and tools support must be provided to make this research field more matured. The main contribution of this study is to summarize the body of knowledge in the field of green and sustainable software engineering and provides a platform to conduct future research.;
Proceedings of the 10th Innovations in Software Engineering Conference;Background: Blog posts offer potential benefits for research but also present challenges. The use of blog posts in SE research is contentious for some members of the community. Also there are no guidelines for evaluating the credibility of blog posts.Objective: To empirically investigate SE researchers' opinions on the credibility of blog posts and identify criteria for evaluating blog posts.Method: We conduct an online survey of software engineering researchers (n=43) to gather opinions on blog-post credibility and credibility criteria.Results: There is diversity of opinion. The majority of researchers provide a qualified response to the credibility of blog posts: essentially it depends. Several credibility criteria are valued by researchers such as Reasoning Clarity of writing Reporting empirical data and Reporting methods of data collection. Approximately 60% of respondents thought the criteria generalised to other practitioner-and researcher--generated content.Conclusion: The survey constitutes the first empirical benchmark of the credibility of blog posts in SE research and presents an initial set of criteria for evaluating the credibility of blog posts. The study would benefit from independent replication and evaluation.;
Proceedings of the 23rd International Conference on Evaluation and Assessment in Software Engineering;"An important part of software engineering (SE) research is to develop new analysis techniques and to integrate these techniques into software development practice. However since access to developers is non-trivial and research tool adoption is slow new analyses are typically evaluated as follows: a prototype tool that embeds the analysis is implemented a set of projects is identified their revisions are selected and the tool is run in a controlled environment rarely involving the developers of the software. As a result research artifacts are brittle and it is unclear if an analysis tool would actually be adopted.In this paper we envision harnessing the rich interfaces provided by popular social coding platforms for automated deployment and evaluation of SE research analysis. We propose that SE analyses can be deployed as analysis bots. We focus on two specific benefits of such an approach: (1) analysis bots can help evaluate analysis techniques in a less controlled and more realistic context and (2) analysis bots provide an interface for developers to subscribe"" to new research techniques without needing to trust the implementation the developer of the new tool or to install the analysis tool locally. We outline basic requirements for an analysis bots platform and present research challenges that would need to be resolved for bots to flourish.""";
Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track;Empirical software engineering has produced a steady stream of evidence-based results concerning the factors that affect important outcomes such as cost quality and interval. However programmers often also have strongly-held a priori opinions about these issues. These opinions are important since developers are highly-trained professionals whose beliefs would doubtless affect their practice. As in evidence-based medicine disseminating empirical findings to developers is a key step in ensuring that the findings impact practice. In this paper we describe a case study on the prior beliefs of developers at Microsoft and the relationship of these beliefs to actual empirical data on the projects in which these developers work. Our findings are that a) programmers do indeed have very strong beliefs on certain topics b) their beliefs are primarily formed based on personal experience rather than on findings in empirical research and c) beliefs can vary with each project but do not necessarily correspond with actual evidence in that project. Our findings suggest that more effort should be taken to disseminate empirical findings to developers and that more in-depth study the interplay of belief and evidence in software practice is needed.;
Proceedings of the 38th International Conference on Software Engineering;Context: Every experimental study has some threats to validity hindering its results. Goal: Improve software engineering controlled experiments quality by better understanding threats to validity control process. Method: A systematic Survey was executed to collect information from software engineering controlled experiments specialists. Data was quantitative and qualitatively analyzed. Results: 115 researchers took part in the study. Most of them (78.26%) consider extremely important to identify threats to validity during experiments planning to adjust it reducing the probability of threats to validity impacting experiment execution. Conclusions: Results bring participants point of view about identifying controlled experiments threats to validity. However the study reveals some concerns since a considerable number (18.26%) of participants are not aware of threats to their studies or to new threats raised by actions took to address previous threats hindering results validity.;
Proceedings of the XXXII Brazilian Symposium on Software Engineering;Education methods for millennials must accommodate their expectations and behaviors. Active learning methodologies seem to be adequate for this requirement. In particular in this paper we discuss the design and deployment of Team-Based Learning (TBL) in two undergraduate Software Engineering courses. TBL is a type of Active Learning Methodology that makes extensive use of small groups to accommodate learning and empower students with the learning responsibilities in the classroom.This paper describes our concerns and the decisions we made when designing two TBL courses at ORT University. Furthermore we evaluated the results of our deployment and compared them with published results. Our results are aligned with the expectations inferred from the literature. Students had a positive perception of the methodology and the learning outcomes.;
Proceedings of the 1st International Workshop on Software Engineering Curricula for Millennials;The Tech Startup model is an approach to learning software engineering methods by partnering with students studying entrepreneurship to collaborate on real software products. Agile software development methods align with Lean Startup practices so that students in sister classes experience leading contemporary practices in their respective fields. This paper describes a pilot study of interdisciplinary Tech Startup projects with a heuristic evaluation of software engineering realism and formative assessment of students' surveyed experiences. The study found several similar student outcomes to other project models however it also identified limitations in the pilot with corresponding recommendations for future implementations.;
Proceedings of the 2017 ACM Conference on Innovation and Technology in Computer Science Education;"In recent years Agile development has been adopted in project practices of Software Engineering (SE) courses. However it is a great challenge to provide timely assessment and feedback to project teams and individual students with a frequency that catches up with iterative incremental and cooperative software development with continuous deliveries. Conventional project reviews are mostly dependent upon instructors and teaching assistants in a manual reviewing/mentoring approach which are simply not scalable.In this paper we argue that agile projects warrant a continuous delivery"" of personalized assessment and feedback. To this end we propose an online-offline combined approach and built a system upon GitLab. An online platform was built by integrating DevOps tool chains so that personalized reports and assessments are delivered automatically to the teams/students which serve as the very efficient trigger and basis for the close and targeted offline interactions between students and TAs: daily discussion over instant messaging and weekly in person meeting. This system has been in operation since 2014 for an undergraduate SE course with over 500 students participating in over 130 project teams in total. Our results show that such a continuous assessment/feedback delivery system is very effective in educating Agile projects in SE courses.""";
Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training;The peer review process is central to the scientific method the advancement and spread of research as well as crucial for individual careers. However the single-blind review mode currently used in most Software Engineering (SE) venues is susceptible to apparent and hidden biases since reviewers know the identity of authors. We perform a study on the benefits and costs that are associated with introducing double-blind review in SE venues. We surveyed the SE community's opinion and interviewed experts on double-blind reviewing. Our results indicate that the costs mostly logistic challenges and side effects outnumber its benefits and mostly regard difficulty for authors in blinding papers for reviewers in understanding the increment with respect to previous work from the same authors and for organizers to manage a complex transition. While the surveyed community largely consents on the costs of DBR only less than one-third disagree with a switch to DBR for SE journals all SE conferences and in particular ICSE the analysis of a survey with authors of submitted papers at ICSE 2016 run by the program chairs of that edition corroborates our result.;
Proceedings of the 39th International Conference on Software Engineering Companion;In the last few years many books online puzzles apps and games have been created to teach young children programming. However most of these do not introduce children to broader concepts from software engineering such as debugging and code quality issues like smells duplication refactoring and naming. To address this we designed and ran an online introductory Scratch programming course in which we teach elementary programming concepts and software engineering concepts simultaneously. In total 2220 children actively participated in our course in June and July 2016 most of which (73%) between the ages of 7 and 11. In this paper we describe our course design and analyze the resulting data. More specifically we investigate whether 1) students find programming concepts more difficult than software engineering concepts 2) there are age-related differences in their performance and 3) we can predict successful course completion. Our results show that there is no difference in students' scores between the programming concepts and the software engineering concepts suggesting that it is indeed possible to teach these concepts to this age group. We also find that students over 12 years of age perform significantly better in questions related to operators and procedures. Finally we identify the factors from the students' profile and their behaviour in the first week of the course that can be used to predict its successful completion.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Cyber-Physical Systems (CPS) are characterized by the interplay between digital and physical spaces. This characteristic has extended the attack surface that could be exploited by an offender to cause harm. An increasing number of cyber-physical incidents may occur depending on the configuration of the physical and digital spaces and their interplay. Traditional investigation processes are not adequate to investigate these incidents as they may overlook the extended attack surface resulting from such interplay leading to relevant evidence being missed and testing flawed hypotheses explaining the incidents. The software engineering research community can contribute to addressing this problem by deploying existing formalisms to model digital and physical spaces and using analysis techniques to reason about their interplay and evolution. In this paper we use a motivating example to describe some emerging software engineering challenges to support investigations of cyber-physical incidents. We review and critique existing research proposed to address these challenges and sketch an initial solution based on a meta-model to represent cyber-physical incidents and a representation of the topology of digital and physical spaces that supports reasoning about their interplay.;
Proceedings of the 3rd International Workshop on Software Engineering for Smart Cyber-Physical Systems;Mistaking versatility for universal skills some companies tend to categorize all software engineers the same not knowing a difference exists. For example a company may select one of many software engineers to complete a task later finding that the engineer's skills and style do not match those needed to successfully complete that task. This can result in delayed task completion and demonstrates that a one-size fits all concept should not apply to how software engineers work. In order to gain a comprehensive understanding of different software engineers and their working styles we interviewed 21 participants and surveyed 868 software engineers at a large software company and asked them about their work in terms of knowledge worker actions. We identify how tasks collaboration styles and perspectives of autonomy can significantly effect different approaches to software engineering work. To characterize differences we describe empirically informed personas on how they work. Our defined software engineering personas include those with focused debugging abilities engineers with an active interest in learning experienced advisors who serve as experts in their role and more. Our study and results serve as a resource for building products services and tools around these software engineering personas.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Deep learning subsumes algorithms that automatically learn compositional representations. The ability of these models to generalize well has ushered in tremendous advances in many fields. We propose that software engineering (SE) research is a unique opportunity to use these transformative approaches. Our research examines applications of deep architectures such as recurrent neural networks and stacked restricted Boltzmann machines to SE tasks.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;The role or professionally trained and skilled human resource for a self-sustained IT infrastructure in any economy is very significant. The growth of IT industry in several emerging economies in last couple of decades owes mainly to mature curriculum in IT Software Engineering and related curriculum. In one of my previous research I had evaluated and analyzed the impact of software engineering curriculum from the perspective of students. In this work we have expanded upon the same topic by conducting analysis of feedback from professionals and graduating students in various universities of kingdom of Saudi Arabia. The work is aimed to explore what professional areas of current software engineering curriculum are driving the professional market for students and what need further strengthening. The research as yielded some very interesting results which would be discussed in the following sections;
Proceedings of the 2020 9th International Conference on Educational and Information Technology;This paper presents a case study of a gamified learning experience designed with a guiding gamification frame-work for a software engineering study group. The group was formed to evaluate the learning experience in a laboratory-like setting and the results are intended to inform the design process. Grounded-theory procedures were used to analyze qualitative data about students' perceptions of the gamified experience. Students reported positive effects such as improved content comprehension retention and recap. They also highlighted a positive change in the study dynamics especially due to the practical application of concepts the game-like experience and a reduced amount of time for studying. The latter however was associated with a specific type of challenge proposed as part of the gamified structure. The other type of challenge actually made them face difficulties related to a lack of time. They also did not progress to higher levels of evolution proposed in the gamified structure. These are indicative of the need to improve the learning experience. These improvements also discussed in this paper will be evaluated in real settings in future work.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Empirical software engineering like every rigorous empirical discipline uses statistics for two purposes: summarizing data and assessing whether data support a hypothesized model. The second purpose is more subtle because it has to address the problem of induction: generalizing a widely applicable model from specific observational data.;
Proceedings of the 39th International Conference on Software Engineering Companion;Context The research literature on software development projects usually assumes that effort is a good proxy for cost. Practice however suggests that there are circumstances in which costs and effort should be distinguished. Objectives: We determine similarities and differences between size effort cost duration and number of defects of software projects. Method: We compare two established repositories (ISBSG and EBSPM) comprising almost 700 projects from industry. Results: We demonstrate a (log)-linear relation between cost on the one hand and size duration and number of defects on the other. This justifies conducting linear regression for cost. We establish that ISBSG is substantially different from EBSPM in terms of cost (cheaper) and duration (faster) and the relation between cost and effort. We show that while in ISBSG effort is the most important cost factor this is not the case in other repositories such as EBSPM in which size is the dominant factor. Conclusion: Practitioners and researchers alike should be cautious when drawing conclusions from a single repository.;
Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering;Automated sentiment analysis in software engineering textual artifacts has long been suffering from inaccuracies in those few tools available for the purpose. We conduct an in-depth qualitative study to identify the difficulties responsible for such low accuracy. Majority of the exposed difficulties are then carefully addressed in developing SentiStrength-SE a tool for improved sentiment analysis especially designed for application in the software engineering domain. Using a benchmark dataset consisting of 5600 manually annotated JIRA issue comments we carry out both quantitative and qualitative evaluations of our tool. SentiStrength-SE achieves 73.85% precision and 85% recall which are significantly higher than a state-of-the-art sentiment analysis tool we compare with.;
Proceedings of the 14th International Conference on Mining Software Repositories;Semiotic engineering is based upon the semiotic theory of Human-Computer Interaction (HCI) which focuses on communication between designers and users. Semiotic engineering tries to improve users' interpretation through meta-communication and emphasizes that designers should play the role of legitimate interlocutors in interactive systems. On the other hand there is a gap in software engineering on how to obtain systems specifications efficiently how to create easy-to-understand and communicative models and how to produce comprehensive modeling languages and development processes. In this paper we explore several contributions of semiotic engineering to software engineering and discuss how the theory can facilitate the creation of comprehensive artifacts. We also discuss semiotic engineering for assessing and improving software modeling languages in our case UML. We anticipate that our work would lead to the semiotic theory becoming recognized as a centraltheory driving software engineering research and practice.;
Proceedings of the 5th International Workshop on Theory-Oriented Software Engineering;We define and advocate the subfield of educational software engineering (i.e. software engineering for education) which develops software engineering technologies (e.g. software testing and analysis software analytics) for general educational tasks going beyond educational tasks for software engineering. In this subfield gaming technologies often play an important role together with software engineering technologies. We expect that researchers in educational software engineering would be among key players in the education domain and in the coming age of Massive Open Online Courses (MOOCs). Educational software engineering can and will contribute significant solutions to address various critical challenges in education especially MOOCs such as automatic grading intelligent tutoring problem generation and plagiarism detection. In this position paper we define educational software engineering and illustrate Pex for Fun (in short as Pex4Fun) one of our recent examples on leveraging software engineering and gaming technologies to address educational tasks on teaching and learning programming and software engineering skills.;
Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive Progressive Change;Researchers have been arguing that there is a lack of connection between Secondary Studies (SSs) and Software Engi-neering (SE) practice. The medical eld has faced the same prob-lem and recently introduced the concept of brie ngs/summaries and Rapid Reviews as alternatives to transfer knowledge to prac-tice.Goal: The overarching goal of this research is to investigate pro-pose and evaluate strategies to support researchers to transfer knowledge from SSs to SE practice.Method: First we investigated how SSs in SE cover practition-ersÂ» issues reported in StackExchange a leading Question &amp An-swer platform. Second we generated Evidence Brie ngs based on those SSs in order to propose a medium to transfer knowledge to practice. Third we are planning to conduct an action research with close collaboration with practitioners in order explore and evaluate the applicability of Rapid Reviews in SE practice. Preliminary Results: Among 424 practitionersÂ» issues on Stack Exchange that were considered as related to a set o selected SSs the SSs could successfully cover 14.1% (60) of them. Based on a qualitative techniques we identi ed 45 recurrent issues spread in many SE topics. Additionally both practitioners and researchers positively evaluated the content and format of 12 Evidence Brief-ings that we created based on SSs.Conclusions: Our results until now corroborate with claims that SSs lack connection with practice. On the other side the good reception of the Evidence Brie ngs shows a possible route toward an e ective knowledge transfer from SSs to practice.;
Plug-in software engineering case studies;Empirical software engineering is a growing research area. Industrial experience gathered by systematic empirical case studies is extremely important for further evolution of the software engineering discipline. Scientific theory cannot provide effective means for software industry without fundamental understanding of the evolutionary development of complex software systems. However there are certain limitations in performing observational quantitative case studies in real software engineering environments and to enable their replication. In this paper we propose a framework that would allow plug-in case studies for industries aiming to overcome obstacles of engagement and wide replications of industrial empirical studies.;
Proceedings of the 4th International Workshop on Conducting Empirical Studies in Industry;The software engineering community has proposed numerous approaches for making software self-adaptive. These approaches take inspiration from machine learning and control theory constructing software that monitors and modifies its own behavior to meet goals. Control theory in particular has received considerable attention as it represents a general methodology for creating adaptive systems. Control-theoretical software implementations however tend to be ad hoc. While such solutions often work in practice it is difficult to understand and reason about the desired properties and behavior of the resulting adaptive software and its controller.This paper discusses a control design process for software systems which enables automatic analysis and synthesis of a controller that is guaranteed to have the desired properties and behavior. The paper documents the process and illustrates its use in an example that walks through all necessary steps for self-adaptive controller synthesis.;
Proceedings of the 10th International Symposium on Software Engineering for Adaptive and Self-Managing Systems;As an application's performance can significantly impact the user satisfaction and consequently the business success companies need to test performance before delivery. Though load testing allows for testing the performance under representative load by simulating user behavior it typically entails high maintenance and execution overhead hindering application in practice. With regard to the trend of continuous software engineering with its parallel and frequently executed delivery pipelines load testing is even harder to be applied. In this paper we present our vision of automated context-specific and low-overhead load testing in continuous software engineering. First we strive for reducing the maintenance overhead by evolving manual adjustments to generated workload models over a changing environment. Early evaluation results show a seamless evolution over changing user behavior. Building on this we intend to significantly reduce the execution time and required resources by introducing online-generated load tests that precisely address the relevant context and services under test. Finally we investigate minimizing the amount of components to be deployed by utilizing load-test-capable performance stubs.;
Companion of the 2018 ACM/SPEC International Conference on Performance Engineering;Context. Job Rotation is an organizational practice whereby individuals are moved among jobs or projects in the same organization. In software companies job rotation is a common practice as well especially to promote the movement of professionals among different software projects. For several years researchers from different research areas have studied the effects of this practice on the work of employees however in software engineering research the studies regarding this practice are still wispy. Goal: The goal of this PhD research is to build a substantive theory of job rotation in software engineering along with the construction and validation of a set of guidelines to improve the use of job rotation in software companies. Thus we seek to provide instruments to plan execute and evaluate the effects of this practice on the work of software engineers. Method: Consistent with the nature of our problem and the investigated phenomenon a multi-method approach specially based on longitudinal and exploratory studies is being performed to understand interpret and explain the effects of job rotation in software engineers and posteriorly in the software development process. So far we have concluded a systematic literature review and an industrial case study on this theme. Moreover a cross-sectional survey is being concluded and ethnographically-supported multiple case studies are being planned to improve and complement the current findings. Results: Until this point this PhD work has presented a set of contributions both to academic research and to industrial practice. Our initial theory contributes to raise the awareness of the potential conflicts associated to the practice of job rotation and start to prepare practitioners to deal with negative impacts of this practice. However further research is still needed to improve this theory and to construct guidelines to industry;
Essence-based goal-driven adaptive software engineering;The OMG Essence standard has recently been published as the kernel for software engineering methods [1]. We show that the Essence view of software engineering is reminiscent of a nondeterministic multidimensional finite state machine and that the Essence lends support to a semi-Markov decision process model of software engineering which in practice facilitates a goal-driven adaptive software engineering. We develop an activity-state mapping algorithm and a goal-activity cover algorithm based on the Essence which can help automate the health monitoring of project states and the adaptive planning of project activities in a software engineering project.;
Proceedings of the Fourth SEMAT Workshop on General Theory of Software Engineering;A recent research trend has emerged to identify developers' emotions by applying sentiment analysis to the content of communication traces left in collaborative development environments. Trying to overcome the limitations posed by using off-the-shelf sentiment analysis tools researchers recently started to develop their own tools for the software engineering domain. In this paper we report a benchmark study to assess the performance and reliability of three sentiment analysis tools specifically customized for software engineering. Furthermore we offer a reflection on the open challenges as they emerge from a qualitative analysis of misclassified texts.1;
Proceedings of the 15th International Conference on Mining Software Repositories;The transformation of old and new kinetic energy emphasizes that Chinese universities should actively set up and develop a number of new engineering majors on the one hand and promote the reform and innovation of existing engineering majors on the other hand. The transformation of new and old kinetic energy is essentially the innovation and transformation of talent training mode. Software engineering is a course offered by most colleges and universities. However each school's talent training program specific implementation process and final training effect are different. Starting from the teaching practice of software engineering education based on the analysis of international software engineering professional norms and teaching practice this paper gives the curriculum system of software engineering major in engineering colleges focuses on setting up the teaching concept of software engineering and cultivating the ability of software system construction and discusses the innovative setting scheme of software engineering courses in detail which can provide reference for international and domestic software engineering teaching plan designers.;
2021 4th International Conference on Information Systems and Computer Aided Education;This paper outlines challenges practices and successes in establishing and sustaining software engineering research collaborations between academia and industry. These activities were observed over a period of 25 years while in a variety of research tech transfer and change agent roles at Cisco Qualcomm and BNR/Nortel. This experience was complemented by serving as a Visiting Scientist for one year at Carnegie Mellon University's Software Engineering Institute (SEI) while on loan from BNR/Nortel. Research collaborations were incubated brokered and sustained through: the cultivation of internal relationship sponsorship by executives and company experts tech scouting to identify relevant projects information sharing seed funding (gift and sponsored research agreements) and talent migration to accelerate technology transfer.;
Proceedings of the Second International Workshop on Software Engineering Research and Industrial Practice;Grounded Theory (GT) has proved an extremely useful research approach in several fields including medical sociology nursing education and management theory. However GT is a complex method based on an inductive paradigm that is fundamentally different from the traditional hypothetico-deductive research model. As there are at least three variants of GT some ostensibly GT research suffers from method slurring where researchers adopt an arbitrary subset of GT practices that are not recognizable as GT. In this paper we describe the variants of GT and identify the core set of GT practices. We then analyze the use of grounded theory in software engineering. We carefully and systematically selected 98 articles that mention GT of which 52 explicitly claim to use GT with the other 46 using GT techniques only. Only 16 articles provide detailed accounts of their research procedures. We offer guidelines to improve the quality of both conducting and reporting GT studies. The latter is an important extension since current GT guidelines in software engineering do not cover the reporting process despite good reporting being necessary for evaluating a study and informing subsequent research.;
Proceedings of the 38th International Conference on Software Engineering;This paper presents a new multidisciplinary robotics programming course reports initial results and describes subsequent improvements. With equal emphasis on software engineering and robotics the course teaches students how software engineering applies to robotics. Students learn independently and interactively and gain hands-on experience by implementing robotics algorithms on a real robot. To understand the effects of the course we conducted an exit and an 8-month survey and measured software quality of the students' solutions. The analysis shows that the hands-on experience helped everyone learn and retain robotics well but the students' knowledge gain in software engineering depended on their prior programming knowledge. Based on these findings we propose improvements to the course. Lastly we reflect our experience on andragogy minimalism and interactive learning.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;We discuss key challenges of software engineering for distributed autonomous real-time systems and introduce a taxonomy for areas of interest with respect to the development of such systems.;
Proceedings of the 2nd International Workshop on Software Engineering for Smart Cyber-Physical Systems;The objective of this paper is to summarize our experience in teaching a software engineering course that emphasizes student learning through activities. It provides an outline and a template for educators interested in combining traditional topics with formal contract specification and verification topics and engaging students in the classroom with a variety of activities that span the entire software lifecycle. Some of the activities are paper-based and are concerned with topics such as processes requirements analysis and design whereas others are tool-based and focus on specification and reasoning. Some activities involve pairs of students and others involve larger groups. The paper contains several illustrative examples. Student responses indicate that they find the activities engaging and conducive to learning.;
Proceedings of the 3rd European Conference of Software Engineering Education;The need of skills other than technical from software developers is becoming evident. The DevOps movement is an example of that applied to operational tasks. Startup development methodologies focus on business activities in innovative organizations. Several universities offer courses based on these methodologies to software engineering students mainly to improve their creativity problem solving and business skills. This paper investigates how software engineering students learned startup development methodologies and discusses what are the challenges and benefits in their learning process. We conducted a multi-method study in three different universities. The data was collected in two phases and analyzed using thematic analysis. Our study reveals that students realized the importance of collaboration with other courses and the importance of user involvement in development. However students tend to over-simplify concepts trying to adapt them to what they are familiar with. The results indicate the necessity of business education for technical students and directions for improvements.;
Proceedings of the 50th ACM Technical Symposium on Computer Science Education;Software Engineering (SE) is a new field compared to other sciences. The term Software Engineering first appeared in late 1950s. SE from its beginning has been continuously in the process of evolution. New approaches methods tools and techniques are introduced frequently. The future of Software Engineering is a hot topic and every year many publications discuss the same. The focus of this paper is to explore subareas of SE predict the possible future of SE and provide a guide to practitioners to choose their careers according to the evolution of SE.;
Can software engineering students program defect-free? an educational approach;Quality of software intensive systems is the priority concern and focus in industry and the research community. In practice the increasing demand for experienced software developers in industry requires developers mature themselves in a timely manner to be able to produce high quality programs. It has become a realistic challenge to both software engineering educators and researchers. To address this challenge we devised the PSP+ process in particular for students majored in software engineering that enhances the original PSP (Personal Software Process) with an ultimate goal at Defect-Free Programming (DFP). Based on the original PSP the PSP+ incorporates a set of explicitly defined practices to facilitate experience gaining and sharing among students with the special concern on DFP. This paper elaborates the proposed PSP+ process and also reports a controlled experiment that was designed and executed to investigate the effectiveness of the PSP+ within an educational setting. The experiment results indicate that students using the PSP+ are more likely to perform high quality programming without extra effort. They also gain higher confidence with DFP compared to those using the original PSP.;
Proceedings of the 38th International Conference on Software Engineering Companion;This paper describes an approach for assessment in a large software engineering project course. We propose an approach for continuously collecting information from a source code repository and collaboration tool and using this information for assessing student contributions and also for assessing the course as a whole from the teacher's standpoint. We present how we display metrics for how the students perform in relation to some of the requirements of the course. We argue that continuous summative assessment feedback to the students on how they are performing in the project is a suitable strategy for ensuring active participation from the students for the duration of the project course.;
Proceedings of the 15th International Symposium on Open Collaboration;A process theory is an explanation of how an entity changes and develops. While software engineering is fundamentally concerned with how software artifacts change and develop little research explicitly builds and empirically evaluates software engineering process theories. This lack of theory obstructs scientific consensus by focusing the academic community on methods. Methods inevitably oversimplify and over-rationalize reality obfuscating crucial phenomena including uncertainty problem framing and illusory requirements. Better process theories are therefore needed to ground software engineering in empirical reality. However poor understanding of process theory issues impedes research and publication. This paper therefore attempts to clarify the nature and types of process theories explore their development and provide specific guidance for their empirically evaluation.;
Proceedings of the 37th International Conference on Software Engineering - Volume 1;In this work we present an approach for creating Personal Web applications by reusing existing content that can be extracted even from third-party Web sites. Our approach starts with the harvesting of content from diverse Web sites by DOM manipulation. Users without programming skills are empowered with tools for transforming DOM elements into meaningful classes of objects that can be reused to build other domain-specific applications such as mashups Web augmentations PIM systems etc.;
Proceedings of the 39th International Conference on Software Engineering Companion;ProcessPAIR is a novel tool for automating the performance analysis of software developers. Based on a performance model calibrated from the performance data of many developers it automatically identifies and ranks potential performance problems and root causes of individual developers. We present the results of a controlled experiment involving 61 software engineering master students half of whom used ProcessPAIR in a performance analysis assignment. The results show significant benefits in terms of students' satisfaction (average score of 4.78 out of 5 for ProcessPAIR users against 3.81 for other users) quality of the analysis outcomes (average grades achieved of 88.1 out of 100 for ProcessPAIR users against 82.5 for other users) and time required to do the analysis (average of 252 min for ProcessPAIR users against 262 min for other users but with much room for improvement).;
Proceedings of the 39th International Conference on Software Engineering Companion;We propose a pattern-based approach to effectively and efficiently analyzing sequential software engineering (SE) data. Different from other types of SE data sequential SE data preserves unique temporal properties which cannot be easily analyzed without much programming effort. In order to facilitate the analysis of sequential SE data we design a sequential pattern query language (SPQL) which specifies the temporal properties based on regular expressions and is enhanced with variables and statements to store and manipulate matching states. We also propose a query engine to effectively process the SPQL queries. We have applied our approach to analyze two types of SE data namely bug report history and source code change history. We experiment with 181213 Eclipse bug reports and 323989 code revisions of Android. SPQL enables us to explore interesting temporal properties underneath these sequential data with a few lines of query code and low matching overhead. The analysis results can help better under- stand a software process and identify process violations.;
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering;Context: Autonomy and interdependence are work characteristics related to motivation that each individual has to complete her task. Objective: Verify if there is a correlation between autonomy and interdependence. Method: We made a survey of 185 Brazilian professionals of diverse areas most of them belonging to Pernambuco State. The professionals were divided into two main groups one of software engineers and another of other professions. We investigate five different constructors three of them grouped as autonomy and remaining constructors as interdependence. Results: The comparison between samples showed that there are distinct characteristics between autonomy and interdependence. In addition our sample and sub-samples showed different behaviors between both initiated and received interdependence. Conclusion: We were able to support some of the predicted hypotheses and identify areas for further research.;
Proceedings of the 10th International Workshop on Cooperative and Human Aspects of Software Engineering;Twitter has created an unprecedented opportunity for software developers to monitor the opinions of large populations of end-users of their software. However automatically classifying useful tweets is not a trivial task. Challenges stem from the scale of the data available its unique format diverse nature and high percentage of spam. To overcome these challenges this extended abstract introduces a three-fold procedure that is aimed at leveraging Twitter as a main source of technical feedback that software developers can benefit from. The main objective is to enable a more responsive interactive and adaptive software engineering process. Our analysis is conducted using a dataset of tweets collected from the Twitter feeds of three software systems. Our results provide an initial proof of the technical value of software-relevant tweets and uncover several challenges to be pursued in our future work.;
Proceedings of the 39th International Conference on Software Engineering Companion;Educational games have been used as an innovative instructional strategy in order to achieve learning more effectively in Software Engineering (SE) education. However it is essential to systematically evaluate such games in order to obtain sound evidence on their benefits. And although several SE games have been evaluated adopting diverse research designs and measurements so far no larger scale study across different games has been conducted. In this respect this article presents a comprehensive analysis in order to summarize empirical evidence on the benefits of digital and non-digital games used for SE education. The analysis is based on data collected from 43 case studies that use MEEGA the most commonly used model for educational game evaluation evaluating 20 different SE games involving a total population of 723 students. Our analysis indicate evidence that digital and non-digital games can yield a positive effect on the learning of SE providing a pleasant and engaging experience to the students and motivate them. Our analysis also points out that non-digital games more easily seem to promote a more positive experience principally in terms of fun and social interaction than the digital ones used for teaching SE. These results may guide SE instructors in the selection of educational games as instructional methods and guide game creators with respect to the development of new games.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Due to the rapidly changing nature of today's work environment software engineering (SE) students are required to have self-regulated learning (SRL) and problem solving skills. Previous research suggests that training students in the use of domain-specific cognitive strategies and using scaffolded instruction for strategy training improves students' SRL and problem solving task performance. In order to identify SE-specific cognitive strategies we conducted a survey of advanced-level SE students. We then conducted a pre-test and post-test experiment with one control and two treatment groups to analyze the effectiveness of identified strategies in improving students' task performance. The control group was not exposed to any strategies while one treatment group was instructed verbally in the use of strategies and the other was trained using a newly developed scaffolded strategy training module. The results of the experiment demonstrate significant improvement in post-test task performance for both treatment groups with a further increase in performance for those undertaking the training module.;
Proceedings of the 2017 ACM Conference on Innovation and Technology in Computer Science Education;Bibliometric analysis is a commonly used technique to analyze scholarly publications to extract useful insights about research and scientific papers which can then be used for decision making by policy makers and administrators. Bibliometric analysis helps in understanding various aspects of scientific knowledge creation and dissemination such as author and institute productivity impact of articles in terms of citations university and industry collaboration geographical contributions and ethnic and gender minority in authorship. ACM SIGSOFT Software Engineering Notes (SEN) is a non-refereed but a reputed and edited publication for informal writings and reports about Software Engineering (SE). ACM SIGSOFT SEN publishes various types of submissions such as paper report column announcement and book review. These submissions are published in the ACM Digital Library (DL). We conduct a bibliometric analysis of articles published in ACM SIGSOFT SEN during a ten year period from 2007 to 2016. Our objective is to provide a historical overview (one decade) of ACM SIGSOFT SEN and reflect on the past so that the ACM SIGSOFT community and contributors can assess the strengths and shortcomings of the SEN. We believe that the bibliometric analysis presented in this paper can provide insights on the extent to which the SEN is meeting its desired objectives.;
Student experiences using GitHub in software engineering courses: a case study;GitHub has been embraced by the software development community as an important social platform for managing software projects and to support collaborative development. More recently educators have begun to adopt it for hosting course content and student assignments. From our previous research we found that educators leverage GitHub's collaboration and transparency features to create reuse and remix course materials and to encourage student contributions and monitor student activity on assignments and projects. However our previous research did not consider the student perspective.In this paper we present a case study where GitHub is used as a learning platform for two software engineering courses. We gathered student perspectives on how the use of GitHub in their courses might benefit them and to identify the challenges they may face. The findings from our case study indicate that software engineering students do benefit from GitHub's transparent and open workflow. However students were concerned that since GitHub is not inherently an educational tool it lacks key features important for education and poses learning and privacy concerns. Our findings provide recommendations for designers on how tools such as GitHub can be used to improve software engineering education and also point to recommendations for instructors on how to use it more effectively in their courses.;
Proceedings of the 38th International Conference on Software Engineering Companion;Global industrial demand for highly skilled professional software engineers is increasing. Many countries already experience shortage of developer workforce and it is predicted that the industrial need for software engineers will grow on a higher rate than educational institutes are able to train new workforce. The main reasons for this deficit are in the education system's inability to adapt to current market needs and in difficulties in matching available skills with existing jobs. Therefore increasing the industrial and market relevance of the education can be a key solution. Another significant contributor is teaching more efficient working methods such as automating repetitive parts of developer work to help to concentrate on tasks that directly create customer and business value. This paper presents the design and execution of a Continuous Delivery and DevOps course organized in company-university collaboration. The objective is to investigate how university courses requiring multidisciplinary lecturer skills and complex execution architectures can be organized in industry-academia collaboration to improve the industrial relevance of higher education.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training;The ACM and IEEE Computer Society have created curriculum guidelines in several computing disciplines one of which is the SE2014 (Software Engineering 2014). The aim of this work is to support the conformity checking of software engineering degree curricula with respect to this curriculum guidelines. The Unified Modeling Language (UML) and Object Constraint Language (OCL) are applied to check the conformity of a degree curriculum. The USE tool is adopted to demonstrate the practicality of this technique for automating the checking which can be tedious and error-prone when perform manually.;
Proceedings of the 2017 International Conference on Management Engineering Software Engineering and Service Sciences;Situated learning theory supports engaging students with materials and resources that reflect professional standards and best practices. Starting with our introductory courses we incorporate situated learning to support student engagement in software engineering practices and processes through the use of industrial strength open-source tools in several classes throughout the undergraduate computer science curriculum at NC State University. Additionally these tools support several logistical and educational needs in computer science classrooms including assignment submission systems and automated grading. In this tools paper we present our Canary Framework for supporting software engineering practices through the use of Eclipse for development GitHub for submission and collaboration and Jenkins for continuous integration and automated grading. These tools are used in five of ten core courses by more than 3000 students over ten semesters. While the use of these tools in education is not unique we want to share our model of using professional tools in a classroom setting and our experiences on how this framework can support multiple courses throughout the curriculum and at scale.;
Proceedings of the 49th ACM Technical Symposium on Computer Science Education;Addressing the needs of professional software development.;
On the value of user preferences in search-based software engineering: a case study in software product lines;Software design is a process of trading off competing objectives. If the user objective space is rich then we should use optimizers that can fully exploit that richness. For example this study configures software product lines (expressed as feature maps) using various search-based software engineering methods. As we increase the number of optimization objectives we find that methods in widespread use (e.g. NSGA-II SPEA2) perform much worse than IBEA (Indicator-Based Evolutionary Algorithm). IBEA works best since it makes most use of user preference knowledge. Hence it does better on the standard measures (hypervolume and spread) but it also generates far more products with 0% violations of domain constraints. Our conclusion is that we need to change our methods for search-based software engineering particularly when studying complex decision spaces.;
Proceedings of the 2013 International Conference on Software Engineering;Although most computer science graduates develop their professional careers as software engineers there are no academic program with a specific focus on software engineering in Chile. Considering ACM/IEEE Software Engineering 2014 Curriculum Guidelines as a starting point we analyzed the curricula of the CS Engineering and CS Technology programs offered by the most traditional Chilean universities in order to establish to what extent they address the knowledge areas included in that recommendation. We also gathered information about theoretical and/or practical approaches of their courses their types of evaluations and temporality. The results of this status report indicate that most knowledge areas of the ACM/IEEE curricula are covered but not all with the same emphasis. Programs count on three or four mandatory software engineering courses most of them have a practical approach are evaluated through exams and projects and start between the seventh and eight semesters. These results let us learn that some knowledge areas are not emphasized as they deserve. For example Software Quality or Software Process are skills that industry often requires but academia does not seem to take into account. Similarly it might be necessary to have students learn about software engineering earlier during their career. Knowing the actual status actions can be taken.;
Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education;Conflict and dependency analysis (CDA) of graph transformation has been shown to be a versatile foundation for understanding interactions in many software engineering domains including software analysis and design model-driven engineering and testing. In this paper we propose a novel static CDA technique that is multi-granular in the sense that it can detect all conflicts and dependencies on multiple granularity levels. Specifically we provide an efficient algorithm suite for computing binary coarse-grained and fine-grained conflicts and dependencies: Binary granularity indicates the presence or absence of conflicts and dependencies coarse granularity focuses on root causes for conflicts and dependencies and fine granularity shows each conflict and dependency in full detail. Doing so we can address specific performance and usability requirements that we identified in a literature survey of CDA usage scenarios. In an experimental evaluation our algorithm suite computes conflicts and dependencies rapidly. Finally we present a user study in which the participants found our coarse-grained results more understandable than the fine-grained ones reported in a state-of-the-art tool. Our overall contribution is twofold: (i) we significantly speed up the computation of fine-grained and binary CDA results and (ii) complement them with coarse-grained ones which offer usability benefits for numerous use cases.;
Proceedings of the 40th International Conference on Software Engineering;Emotional arousal increases activation and performance but may also lead to burnout in software development. We present the first version of a Software Engineering Arousal lexicon (SEA) that is specifically designed to address the problem of emotional arousal in the software developer ecosystem. SEA is built using a bootstrapping approach that combines word embedding model trained on issue-tracking data and manual scoring of items in the lexicon. We show that our lexicon is able to differentiate between issue priorities which are a source of emotional activation and then act as a proxy for arousal. The best performance is obtained by combining SEA (428 words) with a previously created general purpose lexicon by Warriner et al. (13915 words) and it achieves Cohen's d effect sizes up to 0.5.;
Proceedings of the 14th International Conference on Mining Software Repositories;Software development involves the resolution of technical problems related to a certain domain. However in order to provide a suitable technical solution it is necessary to take the organizational environment related to the software into account. Use cases have been often used to elicit requirements and represent functionalities that the software must provide to its users. However use cases are not expressive enough to represent the organizational environment. Moreover this is not the purpose of use cases. In this context Enterprise Architecture (EA) emerges as a way to describe the organization's domain. EA provides architectural descriptions that support the alignment between information technology (IT) and organizational processes and thus helps developers to properly understand the requirements the software must meet. In this paper we propose an approach that uses EA models as a basis to define use cases named CEA (use Cases definition oriented by Enterprise Architecture modeling). To demonstrate the proposal use we applied it in a project in the Public Security domain. Additionally CEA was evaluated in an experimental study. The results indicate that EA models helped requirements engineers to define use cases.;
Proceedings of the XVII Brazilian Symposium on Software Quality;For the last ten years we have been teaching a capstone course for fifth year students of the Computer Science Department of the Universidad de Chile. Five year ago we redesigned the course shifting from projects following a waterfall process and focused on technical aspects to one centered in soft skills following agile practices. Since then we provide out students a concrete learning outcome: to internalize how relevant is having and developing critical soft skills to succeed in projects. Last year we wondered whether our students were actually getting what we declared. We conducted a survey on students' initial and final perception about the relative value and difficulty of different dimensions involved in their projects: technical challenge teamwork planning and negotiation with the client. Also we applied a one-tailed dependent pair sample t-test to determine the statistical significance of the surveys result. We found out that the relative value of soft skills grows while that of the technical challenge drops and that the students find that planning and teamwork are harder than they expected. Also we found statistically significant evidence that for the soft skills we have measured the perceived relative relevance actually changes throughout the course.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Problem-Based Learning (PBL) has been adopted by undergraduate degree programs in different knowledge areas. In Brazil although there are reports about the use of this approach in different formats on Computing Programs we are not aware of many works available in the literature regarding its integration into the curriculum. On Software Engineering undergraduate degree programs the only experience that mentions the PBL integration we know until the current date is that being applied at Federal University of Pampa (Unipampa). This paper shows how the PBL approach is integrated into the curriculum of this program by means of six problem-solving courses distributed along the curriculum and organized within thematic axes. Moreover this work presents and discusses the students' perception regarding PBL adoption. These perceptions were obtained through a research instrument applied to both undergraduate students and bachelors in the program. Based on the results we concluded that most students agree that the objectives of the PBL adoption in the curriculum have been achieved. However current results suggest that collaborative work still is a challenge to be addressed.;
Proceedings of the XXXI Brazilian Symposium on Software Engineering;"Context: In recent years there has been growing concern about conflicting experimental results in empirical software engineering. This has been paralleled by awareness of how bias can impact research results.Objective: To explore the practicalities of blind analysis of experimental results to reduce bias.Method: We apply blind analysis to a real software engineering experiment that compares three feature weighting approaches with a na\{\i""";
Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering;Context: Small and non-probabilistic samples represent relevant issues when discussing the external validity of empirical studies in Software Engineering. Goal: To investigate alternatives to improve the quality of samples (size heterogeneity and level of confidence). Method: To replicate a survey on characteristics of agility in software processes by applying a systematic recruitment strategy over a professional social network. Results: It resulted in a sampling frame composed by 19 groups stratified according two perspectives: sharing of groups' members and main software engineering skills reported by the subjects. In total 7745 subjects were randomly recruited resulting in 291 contributions. Conclusions: This sample was significantly larger more heterogeneous and presents some strata with higher confidence levels than previous trials samples.;
Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Software engineering research and practice are hampered by the lack of a well-understood top-level dependent variable. Recent initiatives on General Theory of Software Engineering suggest a multifaceted variable â€“ Software Engineering Success. However its exact dimensions are unknown. This paper investigates the dimensions (not causes) of software engineering success. An interdisciplinary sample of 191 design professionals (68 in the software industry) were interviewed concerning their perceptions of success. Non-software designers (e.g. architects) were included to increase the breadth of ideas and facilitate comparative analysis. Transcripts were subjected to supervised semi-automated semantic content analysis including a software developer vs. other professionals comparison. Findings suggest that participants view their work as time-constrained projects with explicit clients and other stakeholders. Success depends on stakeholder impacts â€“&nbspfinancial social physical and emotional â€“ and is understood through feedback. Concern with meeting explicit requirements is peculiar to software engineering and design is not equated with aesthetics in many other fields. Software engineering success is a complex multifaceted variable which cannot sufficiently be explained by traditional dimensions including user satisfaction profitability or meeting requirements budgets and schedules. A proto-theory of success is proposed which models success as the net impact on a particular stakeholder at a particular time. Stakeholder impacts are driven by project efficiency artifact quality and market performance. Success is not additive e.g. â€˜lowâ€™ success for clients does not average with â€˜highâ€™ success for developers to make â€˜moderateâ€™ success overall rather a project may be simultaneously successful and unsuccessful from different perspectives.;
Proceedings of the 36th International Conference on Software Engineering;Civic hackathons gained momentum in the last years mainly propelled by city halls and government agencies as a way to explore public data repositories. These initiatives became an attempt to crowdsource the development of software applications targeting government transparency and urban life under the smart cities umbrella. Some authors have been criticizing the results of these competitions complaining about the usefulness and quality of the software that is produced. However academic literature has much anecdotal evidence on that being scarce on empirical analysis of civic hackathons. Therefore we intended to gather preliminary data not only to help verifying those claims but also to understand how teams in these competitions are tackling the different activities in their software development process from requirements to application release and maintenance. In this work we present preliminary results of these findings.;
Proceedings of the 4th International Workshop on CrowdSourcing in Software Engineering;This paper describes a new design for a software engineering course: CSC446 Software Engineering: Analysis and Design offered in Saint Martin's University (SMU). A software engineering course usually has a term project but such a project can have some limitations. Thus CSC446 was redesigned as a project-based course. In the new design other than finishing a series of mini assignments and quizzes the students will simultaneously work on two projects as the main coursework and for different purposes from the beginning of the semester. One project is from the instructor's research area but tailored for the class. The objectives are to help students better understand various skills and techniques covered in class and acquire undergraduate research experience. The other is selected from industry helping the students get experience with real-world software development and prepare for their senior project (a capstone project) finished in CSC481 and then CSC482.;
Taking a Studio Course in Distributed Software Engineering from a Large Local Cohort to a Small Global Cohort;One of the challenges of global software engineering courses is to bring the practices and experience of large geographically distributed teams into the local and time-limited environment of a classroom. Over the last 6 years an on-campus studio course for software engineering has been developed at the University of Queensland (UQ) that places small teams of students on different features of a common product. This creates two layers of collaboration as students work within their teams on individual features and the teams must interoperate with many other teams on the common product. The class uses continuous integration practices and predominantly asynchronous communication channels (Slack and GitHub) to facilitate this collaboration. The original goal of this design was to ensure that students would authentically experience issues associated with realistically sized software projects and learn to apply appropriate software engineering and collaboration practices to overcome them in a course without significant extra staffing. Data from the development logs showed that most commits take place outside synchronous class hours and the project operates as a temporally distributed team even though the students are geographically co-located. Since 2015 a course adapted from this format has also been taught at the University of New England (UNE) an Australian regional university that is also a longstanding provider of distance education. In this course most students study online and the class has to be able to work globally because as well as students taking part from around Australia there are also typically a small number of students taking part from overseas. Transferring the course to a smaller but predominantly online institution has allowed us to evaluate the distributed nature of the course by considering what aspects of the course needed to change to support students who are geographically distributed and comparing how the two cohorts behave. This has produced an overall course design to teach professional distributed software engineering practices that is adaptable from large classes to small and from local to global.;
Active and inductive learning in software engineering education;If software engineering education is done in a traditional lecture-oriented style students have no other choice than believing that the solutions they are told actually work for a problem that they never encountered themselves. In order to overcome this problem this paper describes an approach which allows students to better understand why software engineering and several of its core methods and techniques are needed thus preparing them better for their professional life. This approach builds on active and inductive learning. Exercises that make students actively discover relevant software engineering issues are described in detail together with their pedagogical underpinning.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Computational Thinking (CT) has been recognized as one of the fundamental skills that all graduates should acquire. For this reason motivational concerns need to be addressed at an early age of a child and reaching students who do not consider themselves candidates for science technology engineering and mathematics disciplines is important as well if the broadest audience possible is to be engaged. This article describes a framework for teaching and assessing CT in the context of K-12 education. The framework is based on Agile software engineering methods which rely on a set of principles and practices that can be mapped to the activities of CT. The article presents as well the results of an experiment applying this framework in two sixth-grade classes with 42 participants in total. The results show that Agile software engineering methods are effective at teaching CT in middle schools after the addition of some tasks to allow students to explore project and experience the potential product before using the software tools at hand. Moreover according to the teachersâ€™ feedback the students reached all the educational objectives of the topics involved in the multidisciplinary activities. This result can be taken as an indicator that it is possible to use computing as a medium for teaching other subjects besides computer science.;
Modeling human behavior for software engineering simulation games;Simulation games are a well-known concept for teaching in a practical way. Especially for project management training simulation games are helpful. Students can try out different management strategies and gain experience without endangering real projects. To provide a good learning environment it is important to simulate the employees managed by the player as realistically as possible. However existing approaches only use simple models to simulate human behavior missing psychological aspects like motivation and interpersonal interaction and therefore are not detailed enough for leadership and project management training. We present a new decision-making model based on findings of psychology which can be used for simulating a more realistic human behavior. We use heuristics for calculating the motivational force of all potential actions an employee has in order to decide which he will choose. This calculation is not only based on the project's state and schedule but also on emotional factors like the preferences and aversions of the employee. Within our approach we implemented a decision-making model which is not limited to our game concept and can also be adapted for other simulation games.;
Proceedings of the 5th International Workshop on Games and Software Engineering;In the rapidly growing field of Big Data we note that a disproportionately larger amount of effort is being invested in infrastructure development and data analytics in comparison to applications software development -- approximately a 80:20 ratio. This prompted us to create a context model of Big Data Software Engineering (BDSE) containing various elements --- such as development practice Big Data systems corporate decision-making and research --- and their relationships. The model puts into perspective where various types of stakeholders fit in. From the research perspective we describe example challenges in BDSE specifically requirements architectures and testing and maintenance.;
Proceedings of the First International Workshop on BIG Data Software Engineering;With the aim of identifying good structures and examples for papers in the software engineering field we conducted a study of the type of papers accepted along four decades in the Research Track of the International Conference on Software Engineering (ICSE). We used for this purpose a categorization scheme for Software Engineering papers that was obtained by merging extending and revising a few existing paper scheme proposals. This paper summarizes some outcomes relative to what topics and problems are addressed what types of contribution are presented and how they are validated. Insights from the study could help ICSE authors reviewers and conference organizers in focusing and improving future efforts.;
Proceedings of the 39th International Conference on Software Engineering Companion;Exposure to safety-critical thinking grows in importance as society increasingly depends upon software to control physical devices with potential safety impacts. In this unique graduate capstone experience we engaged graduate Software Engineering students in the specification design implementation validation and assurance of potentially safety-critical software-intensive products involving physical devices such as Unmanned Autonomous Vehicles health-sensors and/or environmental monitors. While each product had at least one safety-critical usage scenario it also had harmless test-scenarios which enabled students to design and build with safety-in mind but to test their product in a safe context. Students engaged in safety-related practices such as hazard analysis safety-design safety-assurance and certification processes. We describe the goals and logistics of the course discuss student outcomes based on an analysis of the deliverables and student feedback and suggest ideas for replication and improvement.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;In the fall semester of 1996 RIT (Rochester Institute of Technology) launched the first undergraduate software engineering program in the United States. The culmination of five years of planning development and review the program was designed from the outset to prepare graduates for professional positions in commercial and industrial software development.;
Towards an Understanding of Value Creation in Agile Software Development;Recently studies involving the creation of business value in Agile Software Development (ASD) have been growing substantially. However the concept of value creation in ASD has not yet been clearly defined. Besides the literature does not define practices that can create business value for ASD. Identifying these practices can change the mindset of agile teams since surveys indicate that from the point of view of the agile team the creation of value is poorly understood. Thus this study carried out a Systematic Literature Review to identify how value creation is defined in ASD and how practices can improve this value creation. Despite the lack of studies on the subject we identified practices and its positive and negative influence on value creation.;
Proceedings of the XV Brazilian Symposium on Information Systems;Problem-Based Learning (PBL) has often been seen as an all-or-nothing approach difficult to apply in traditional curricula based on traditional lectured courses with exercise and lab sessions. Aalborg University has since its creation in 1974 practiced PBL in all subjects including computer science and software engineering following a model that has become known as the Aalborg Model. Following a strategic decision in 2009 the Aalborg Model has been reshaped. We first report on the software engineering program as it was in the old Aalborg Model. We analyze the programme wrt competence levels according to Bloomâ€™s taxonomy and compare it with the expected skills and competencies for an engineer passing a general software engineering 4-year program with an additional 4 years of experience as defined in the IEEE Software Engineering Body of Knowledge (SWEBOK) [Abran et al. 2004]. We also compare with the Graduate Software Engineering 2009 Curriculum Guidelines for Graduate Degree Programmes in Software Engineering (GSwE2009) [Pyster 2009]. We then describe the new curriculum and draw some preliminary conclusions based on analyzing the curriculum according to Bloomâ€™s taxonomy and the results of running the program for 2 years. As the new program is structured to be compliant with the Bologna Process and thus presents all activities in multipla of 5 European Credit Transfer System points we envision that elements of the program could be used in more traditional curricula. This should be especially easy for programs also complying with the Bologna Process.;
An empirical study of practitioners' perspectives on green software engineering;The energy consumption of software is an increasing concern as the use of mobile applications embedded systems and data center-based services expands. While research in green software engineering is correspondingly increasing little is known about the current practices and perspectives of software engineers in the field. This paper describes the first empirical study of how practitioners think about energy when they write requirements design construct test and maintain their software. We report findings from a quantitative targeted survey of 464 practitioners from ABB Google IBM and Microsoft which was motivated by and supported with qualitative data from 18 in-depth interviews with Microsoft employees. The major findings and implications from the collected data contextualize existing green software engineering research and suggest directions for researchers aiming to develop strategies and tools to help practitioners improve the energy usage of their applications.;
Proceedings of the 38th International Conference on Software Engineering;This paper introduces the 4th International Workshop on Software Engineering for E-learning (ISELEAR'13) track of the Technological Ecosystems for Enhancing Multiculturality (TEEM) Conference held in Salamanca by November 14--15 2013. The paper includes an introduction to some of the concerns covered by the discipline of Software Engineering for eLearning. It also contains a brief history of the ISELEAR workshop series as well as a brief presentation of the papers accepted for the 4th edition of the workshop ISELEAR'13.;
Proceedings of the First International Conference on Technological Ecosystem for Enhancing Multiculturality;The Stevens Institute School of Systems and Enterprises (SSE) was founded on the principle of the Open Academic Model -- which has the fundamental intent of enabling rich collaboration among Academia Industry and Government. This paper describes different methods used by the Software Engineering (SwE) Program to enable this collaboration and gives examples of the results obtained. The collaboration primarily takes the form of SwE knowledge transfer and deployment into industry and government through graduate education and sponsored research. This paper is a case study of the experiences in one small SwE Masters' program in the methods used to transfer research knowledge into industry and in some cases create new SwE knowledge. Examples of student papers and sponsored research topics are used as evidence.;
Proceedings of the Second International Workshop on Software Engineering Research and Industrial Practice;"What happened to software engineering? What happened to the promise of rigorous disciplined professional practices for software development like those observed in other engineering disciplines? What has been adopted under the rubric of software engineering"" is a set of practices largely adapted from other engineering disciplines: project management design and blueprinting process control and so forth. The basic analogy was to treat software as a manufactured product with all the real ""engineering"" going on upstream of that - in requirements analysis design modeling etc.""";
Predicting the Impact of Software Engineering Topics: An Empirical Study;Predicting the future is hard more so in active research areas. In this paper we customize an established model for citation prediction of research papers and apply it on research topics. We argue that research topics rather than individual publications have wider relevance in the research ecosystem for individuals as well as organizations. In this study topics are extracted from a corpus of software engineering publications covering 55000+ papers written by more than 70000 authors across 56 publication venues over a span of 38 years using natural language processing techniques. We demonstrate how critical aspects of the original paper-based prediction model are valid for a topic-based approach. Our results indicate the customized model is able to predict citations for many of the topics considered in our study with reasonably high accuracy. Insights from these results indicate the promise of citation of prediction of research topics and its utility for individual researchers as well as research groups.;
Proceedings of the 26th International Conference on World Wide Web Companion;"Background/Context: Gathering empirical knowledge is a time consuming task and the results from empirical studies often are soon outdated by new technological solutions. As a result the impact of empirical results on software engineering practice is often not guaranteed.Objective/Aim: In this paper we summarize the ongoing discussion on Empirical Software Engineering 2.0"" as a way to improve the impact of empirical results on industrial practices. We propose a way to combine data mining and analysis with domain knowledge to enable fast feedback cycles in empirical software engineering research.Method: We identify the key concepts on gathering fast feedback in empirical software engineering by following an experience-based line of reasoning by argument. Based on the identified key concepts we design and execute a small proof of concept with a company to demonstrate potential benefits of the approach.Results: In our example we observed that a simple double feedback mechanism notably increased the precision of the data analysis and improved the quality of the knowledge gathered.Conclusion: Our results serve as a basis to foster discussion and collaboration within the research community for a development of the idea.""";
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Software engineering activities like code reviews change management knowledge management issue tracking etc. tend to be heavily process oriented. Gamification of such activities by composing the core activities with game design elements like badges and points can increase developers' interest in performing such activities. While there are various frameworks/applications that assist in gamification extending the frameworks to add any/all desired game design elements has not been adequately addressed. In this paper we propose an extensible architectural framework for gamification of software engineering activities where in the game design elements are modeled as services. We create an example instance of our framework by building a prototype for code review activity and note the challenges of designing such an extensible architectural framework. The example instance uses python's Flask micro framework and has five game design elements implemented as services and exposed using restful APIs.;
Proceedings of the 9th India Software Engineering Conference;Nowadays software is pervasive in our everyday lives. Its sustainability and environmental impact have become major factors to be considered in the development of software systems. Millennials-the newer generation of university students-are particularly keen to learn about and contribute to a more sustainable and green society. The need for training on green and sustainable topics in software engineering has been reflected in a number of recent studies. The goal of this paper is to get a first understanding of what is the current state of teaching sustainability in the software engineering community what are the motivations behind the current state of teaching and what can be done to improve it. To this end we report the findings from a targeted survey of 33 academics on the presence of green and sustainable software engineering in higher education. The major findings from the collected data suggest that sustainability is under-represented in the curricula while the current focus of teaching is on energy efficiency delivered through a fact-based approach. The reasons vary from lack of awareness teaching material and suitable technologies to the high effort required to teach sustainability. Finally we provide recommendations for educators willing to teach sustainability in software engineering that can help to suit millennial students needs.;
Proceedings of the 1st International Workshop on Software Engineering Curricula for Millennials;Sentiment analysis (SA) of text-based software artifacts is increasingly used to extract information for various tasks including providing code suggestions improving development team productivity giving recommendations of software packages and libraries and recommending comments on defects in source code code quality possibilities for improvement of applications. Studies of state-of-the-art sentiment analysis tools applied to software-related texts have shown varying results based on the techniques and training approaches. In this paper we investigate the impact of two potential opportunities to improve the training for sentiment analysis of SE artifacts in the context of the use of neural networks customized using the Stack Overflow data developed by Lin et al.We customize the process of sentiment analysis to the software domain using software domain-specific word embeddings learned from Stack Overflow (SO) posts and study the impact of software domain-specific word embeddings on the performance of the sentiment analysis tool as compared to generic word embeddings learned from Google News. We find that the word embeddings learned from the Google News data performs mostly similar and in some cases better than the word embeddings learned from SO posts. We also study the impact of two machine learning techniques oversampling and undersampling of data on the training of a sentiment classifier for handling small SE datasets with a skewed distribution. We find that oversampling alone as well as the combination of oversampling and undersampling together helps in improving the performance of a sentiment classifier.;
Proceedings of the 16th International Conference on Mining Software Repositories;The number of software engineering research papers over the last few years has grown significantly. An important question here is: how relevant is software engineering research to practitioners in the field? To address this question we conducted a survey at Microsoft where we invited 3000 industry practitioners to rate the relevance of research ideas contained in 571 ICSE ESEC/FSE and FSE papers that were published over a five year period. We received 17913 ratings by 512 practitioners who labelled ideas as essential worthwhile unimportant or unwise. The results from the survey suggest that practitioners are positive towards studies done by the software engineering research community: 71% of all ratings were essential or worthwhile. We found no correlation between the citation counts and the relevance scores of the papers. Through a qualitative analysis of free text responses we identify several reasons why practitioners considered certain research ideas to be unwise. The survey approach described in this paper is lightweight: on average a participant spent only 22.5 minutes to respond to the survey. At the same time the results can provide useful insight to conference organizers authors and participating practitioners.;
Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering;Online education is rapidly being adopted in major universities. Software engineering programs are early adopters among engineering disciplines due to the ability to leverage advances in cloud computing and personal computing environments to support software engineering environments. Online modalities have several benefits but present challenges as well. This extended abstract suggests that the continuing rise of online education combined with the increases in software engineering enrollments create unique challenges for software engineering educators chief among them the ability to effectively utilize project-centric pedagogy to contextualize learning experiences for our students.;
Proceedings of the First International Workshop on Designing and Running Project-Based Courses in Software Engineering Education;"Background. Practical use of a measure X for an internal attribute (e.g. size structural complexity cohesion coupling) of a software module often requires setting a threshold on X to make decisions as to which software modules may be estimated to be potentially faulty. To keep quality under control practitioners may want to set a threshold on X to identify early symptoms"" of possible faultiness of a module which should be closely monitored and possibly modified.Objective. We propose and evaluate an approach to setting a threshold on X to identify ""early symptoms"" of possible faultiness of software modules.Method. Our proposal is based on the existence of a statistically significant model that relates X to fault-proneness defined as the probability that a module contains at least one fault. The curve representing a fault-proneness model is usually fairly ""flat"" for relatively small values of X and becomes steeper and steeper for larger values of X. We define two ways in which values of X can be used as ""early symptoms"" of possible faultiness. First we use the value of X where the fault-proneness model curve changes direction the most i.e. has maximum convexity. Second we use the value in which the slope of the curve reaches a proportion (e.g. one half) of the maximum slope that is relevant for the developers.Results. First we provide the theoretical underpinnings for our approach. Second we show the empirical results obtained by applying our approach to data from the PROMISE repository by using fault-proneness models built via Binary Logistic and Probit regressions. Our results show that the proposed thresholds are actually effective in showing ""early symptoms"" of possible faultiness of a module while achieving a level of accuracy in classifying faulty modules that is fairly close to other typical fault-proneness thresholds.Conclusions. Our method can be practically used for setting ""early symptom"" thresholds based on evidence captured by statistically significant models. In particular the threshold based on the maximum convexity depends on characteristics of the models alone so software project managers do not need to devise the thresholds themselves. If they choose to use the other kind of slope-based threshold software project managers can choose a different proportion based on the level of risk-aversion they need when recognizing early symptoms of faultiness.""";
Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering;Software Engineering (SE) is an important topic to be taught in Computer Science courses. However teaching of theoretical concepts with no link to their practical applications or no examples in the student's context may discourage learning justifying why teaching and learning are great challenges of education in universities. In attempt to bridge such gap several approaches have been proposed and applied to improve teaching and learning SE such as project based learning (PBL) a well-known approach already applied to teach SE. Nevertheless there's a lack of understanding about how to better apply PBL and how to take advantage of this approach for future use. There is also a lack of experience report describing how to use its challenges and difficulties what could be hampering to widely adopt it. We present our experience applying a PBL approach combined with project management to create an environment considering aspects such as dealing with managers and real stakeholders. The goal is to bring students closer to the reality of developing a software project in the business context. Our experience indicates positive results on the adoption of a PBL approach. In general students were enthusiastic and positive about the use of this approach the presence of a manager and the importance of using real-world problems with real stakeholders.;
Proceedings of the 49th ACM Technical Symposium on Computer Science Education;Nowadays invoking third party code increasingly involves calling web services via their web APIs as opposed to the more traditional scenario of downloading a library and invoking the library's API. However there are also new challenges for developers calling these web APIs. In this paper we highlight a broad set of these challenges and argue for resulting opportunities for software engineering research to support developers in consuming web APIs. We outline two specific research threads in this context: (1) web API specification curation which enables us to know the signatures of web APIs and (2) static analysis that is capable of extracting URLs HTTP methods etc. of web API calls. Furthermore we present new work on how we combine (1) and (2) to provide IDE support for application developers consuming web APIs. As web APIs are used broadly research in supporting the consumption of web APIs offers exciting opportunities.;
Proceedings of the 1st International Workshop on API Usage and Evolution;What happened to the promise of rigorous disciplined professional practices for software development?;
Process simulation for software engineering education;Training and learning are one important purpose of Software Process Simulation (SPS). Some previous reviews showed a noticeable number of studies that combine SPS and Soft- ware Engineering Education (SEE). The objective of this research is to present the latest state-of-the-art of this area and more importantly provide practical support for the effective adoption of SPS in educational context. We conducted an extended Systematic Literature Review (SLR) based on our previous reviews. The review identified 42 primary studies from 1992 to 2013. This paper presents the preliminary results by answering the research questions. The overall findings confirmed the positive impact of SPS on education. The detailed discussions and recommendations may offer reference value to the community.;
Proceedings of the 2015 International Conference on Software and System Process;The underlying principles of Sustainable Software Engineering are a core set of competencies Software Engineers need for defining building and running sustainable software applications. However despite its importance recently published studies have shown that Software Engineers have not reached a common and clear understanding of Sustainable Software Development (SSD). Consequently it might be challenging to understand the value of the principles behind sustainability and how Software Engineers should apply them in practice. Therefore the first step is to promote a field characterization to mitigate such effects to bridge such a gap. This paper reports on qualitative data analysis to leverage the sustainability principles through the support of the Grounded Theory method. We conducted this study using unstructured data retrieved from a systematic mapping study on sustainable software engineering and a survey applied in the software industry. To achieve the principles we considered five critical dimensions: economic social individual environmental and technical. The key results are: (i) technical environmental and social concerns are present in all software development life-cycle (SDLC) phases (ii) software engineers should consider sustainability requirements in the early SDLC phases (iii) there is a need for stakeholder engagement focused on sustainability (iv) software quality requirements support the development of sustainable software and (v) sustainable concerns could generate trade-offs in the project. The yielded results might trigger further discussions around the SSDâ€™s underlying principles and concepts and serve as a basis for the research community to identify models techniques and tools to support SSD.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Regression tests are executed after every change in software. In a software development environment that adopts Continuous Software Engineering practices such as Continuous Integration Continuous Delivery and Continuous Deployment software is changed built and tested many times. Every regression test execution may include different situations and problems that are treated in isolated way. Data provenance is concerned with the origins and processes that some data has gone through until it becomes information. Ontologies are formal models that contain axioms and relationships between classes and individuals from a specific context and can be used to infer implicit knowledge. Considering that Continuous Software Engineering activities are based on feedback cycles in this paper we propose an architecture based on the use of an ontology and provenance model to capture and provide regression tests data to support the continuous improvement of software testing processes. Moreover using ontology and provenance to track execution performance and issues in this scenario may increase the chances of those issues not happening again since practitioners can address and solve them for future executions.;
Proceedings of the 2nd Brazilian Symposium on Systematic and Automated Software Testing;There is an acknowledged need for teaching realistic software development in project courses. The design space for such courses is wide ranging from single-semester to two-semester courses from single-client to multicustomer courses from local to globally distributed courses and from toy projects to projects with real clients. The challenge for a nontrivial project course is how to make the project complex enough to enrich studentsâ€™ software engineering experience yet realistic enough to have a teaching environment that does not unduly burden students or the instructor. We describe a methodology for project courses that is realizable for instructors improves studentsâ€™ skills and leads to viable results for industry partners.In particular recent advances in release management and collaboration workflows reduce the effort of students and instructors during delivery and increase the quality of the deliverables. To enable release and feedback management we introduce Rugby an agile process model based on Scrum that allows reacting to changing requirements. To improve early communication we use Tornado a scenario-based design approach that emphasizes the use of informal models for the interaction between clients and students. The combination of Rugby and Tornado allows students to deal with changing requirements produce multiple releases and obtain client feedback through the duration of the course.We describe our experience with more than 300 students working on 40 projects with external clients over a 4-year period. In the latest instance of our course the students have produced more than 7000 builds with 600 releases for eleven clients. In an evaluation of the courses we found that the introduction of Rugby and Tornado significantly increased studentsâ€™ technical skills especially with respect to software engineering usability engineering and configuration management as well as their nontechnical skills such as communication with the client teamwork presentation and demo management. Finally we discuss how other instructors can adapt the course concept.;
Measuring code behavioral similarity for programming and software engineering education;In recent years online programming and software engineering education via information technology has gained a lot of popularity. Typically popular courses often have hundreds or thousands of students but only a few course staff members. Tool automation is needed to maintain the quality of education. In this paper we envision that the capability of quantifying behavioral similarity between programs is helpful for teaching and learning programming and software engineering and propose three metrics that approximate the computation of behavioral similarity. Specifically we leverage random testing and dynamic symbolic execution (DSE) to generate test inputs and run programs on these test inputs to compute metric values of the behavioral similarity. We evaluate our metrics on three real-world data sets from the Pex4Fun platform (which so far has accumulated more than 1.7 million game-play interactions). The results show that our metrics provide highly accurate approximation to the behavioral similarity. We also demonstrate a number of practical applications of our metrics including hint generation progress indication and automatic grading.;
Proceedings of the 38th International Conference on Software Engineering Companion;Systems-of-Systems (SoS) often support critical domains. They must be trustworthy i.e. they must keep their operation in progress being not subject to failures as they can cause potential damages and hazards to human integrity. Simulations are a recurrent approach in SoS development as they can anticipate potential failures consequently increasing the level of trustworthiness and quality exhibited by a SoS. Nevertheless simulation is still software and demands engineering. Moreover many simulation formalisms are not trivial of specifying sometimes tangling software an hardware details to program an executable simulation. Thus the aim of this paper is contributing for software engineering of SoS by externalizing two patterns for the conception of SoS simulations. We evaluated our patterns by applying them in a case study in two different domains. For both patterns were successfully applied during automatic generation of functional code supporting the execution of SoS simulations and prediction of SoS behavior at design-time.;
Proceedings of the 33rd Annual ACM Symposium on Applied Computing;"The four GTSE (General Theory of Software Engineering) Workshops have brought awareness to more or less mature differing approaches candidate theories for SE (Software Engineering). But one asks how to appraise the generality of these theories? And in case they are specialized sub-theories are they amenable to combination into more general theories? The papers of the fourth GTSE Workshop addressed these questions by means of what can be collectively refer to as Separability Principles. In a sense participants used well known techniques applied to design software systems to design SE theories. Separability is a powerful tool for understanding relations among SE candidate theories and guide how to assemble sub-theories into a general framework. Participants enthusiastically debated a series of related issues. The specialized vs. general theories questions were raised in diverse forms such as SE meaning multiple things good predictive theories for narrow problems ability of General theories to generate specific theories and last but not least whether General"" capture the contents of the workshop itself. The 4th GTSE edition was collocated with ICSE 2015 (International Conference of Software Engineering) in Firenze Italy""";
Bringing together undergraduate and postgraduate students in software engineering team project: experiences and lessons;Software Engineering education requires exposing students to real-world problems providing a framework to simulate real-world conditions. For this purpose computer science students usually work in teams with each member undertaking a specific role. In this paper we are discussing our experiences when adopting a different approach to teaching software engineering courses. In an attempt to provide students the possibility to develop different skills at each education level we brought together undergraduate and postgraduate students in the same team with postgraduates adopting the role of a software project manager. Different roles were assigned to the undergraduate students in the team by the project manager but all students worked towards the same goal. We present in this paper the approach followed and how we applied it we discuss the exchange of skills among the team members and finally a discussion is provided on the lessons learned from our side and the students' point of view.;
Proceedings of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education;Software Engineering (SE) educators worldwide are attempting to create learning environments that can effectively achieve their desired learning objectives. However there exist additional needs that impact the learning process and the overall quality of a learning environment. We identified two sets of differentiating requirements Climatic and Systemic whose inclusion in design can assist in an effective sustainable and usable SE learning environment. In this paper we will describe the Systemic requirements i.e. the desired system wide capabilities that impact the sustainability of a SE learning environment by affecting its operationalization and use in short and long term. We will also discuss through few examples the interactions between various differentiating requirements. Current SE course design and evaluation consider these as challenges to deal later instead of addressing them through a conscientious design. Such courses find it hard to sustain and evolve with time despite using powerful pedagogies.We intend to change this design approach by identifying and recording the various needs (as requirements) and their influence on the learning environment. Our aim is to draw attention to these differentiating requirements and help the educators look beyond learning objectives and move towards a more holistic and systematic design of SE learning environments.;
Proceedings of the 8th India Software Engineering Conference;Background. In order to understand research on a particular computing topic practitioners and researchers often need to obtain an overview of its research methods. Current research methods coding schemes either capture insufficient details to support a full critical assessment or are specialised to a particular research type. Aim. This paper defines and demonstrates RSML a Research Schema Modelling Language that captures a high level of detail and is applicable to most types of computing research. Method. RSML was designed using concepts from the research methods literature then refined inductively. An RSML editor was created to assist coders and help reduce coding errors. To demonstrate the feasibility of modelling research with RSML and to exemplify the summary information that can be derived from a database of RSML encodings a trial review of 24 articles from one journal was conducted. Results. The review illustrates quantitatively the journal's focus on artifact construction and empiricism. It also reveals that observations are rarely used to inform artifact construction and purely empirical studies are scarce. Conclusion. RSML can be used to model sophisticated multifaceted research spanning a wide range of software engineering topics yielding insights that are not easily captured by current coding schemes.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;During the past few years psychological diseases related to unhealthy work environments such as burnouts have drawn more and more public attention. One of the known causes of these affective problems is time pressure. In order to form a theoretical background for time pressure detection in software repositories this paper combines interdisciplinary knowledge by analyzing 1270 papers found on Scopus database and containing terms related to time pressure. By clustering those papers based on their abstract we show that time pressure has been widely studied across different fields but relatively little in software engineering. From a literature review of the most relevant papers we infer a list of testable hypotheses that we want to verify in future studies in order to assess the impact of time pressures on software developers' mental health.;
Proceedings of the 2nd International Workshop on Emotion Awareness in Software Engineering;Using scientific disciplines as inspiration some researchers have called for the creation of general theories for software engineering. I present a contrary view drawing on recent work in the philosophy of engineering. Engineering theories are different to scientific theories and are not judged by the same criteria. Software engineering researchers should strive to create valid theories about the uses of software-based systems even if that leads to a multitude of theories that have narrow overlapping scopes are approximate and have little explanatory power. The engineering imperative is that the predictions of software engineering theories should be consistent with actual behaviour of software-based systems and that theories and should support assurances and explicit justification that systems will meet their requirements. Process theories are about the organisation of work and project management and are relevant to cost and schedule requirements in software engineering. However to directly provide evidence that software-based systems meet their main functional and non-functional requirements software engineering researchers should focus on product theories about the specifications designs code and behaviours of software-based systems.;
Proceedings of the Fourth SEMAT Workshop on General Theory of Software Engineering;It is increasingly recognised that successful Software Engineering not only depends on technical or process issues but requires attention to human factors. Researchers include such aspects which has led to both new theories and refined methods. However it is not clear if professionals in the software industry agree that human factors are critical and what the related challenges and possibilities are. The purpose of the present study is to address this discrepancy. Using a qualitative research method we elicited information about how and why human factors affect Software Engineering projects which challenges are of special interest and the context in which they arise. Thematic analysis of data from interviews with nine senior software professionals in multiple Swedish software companies of differing size identified four main challenging areas. As supported by existing research customer relations and communications were highlighted as important but so too is the need for more holistic and multidimensional solutions and the importance of human factors in software organisational change. In addition quantitative results indicate that the professionals see the organisational and group aspects as more important than the individual aspect. Our results can help to focus future research on matters that software practitioners consider important.;
Proceedings of the Eighth International Workshop on Cooperative and Human Aspects of Software Engineering;One of the goals of software engineering research is to achieve generality: Are the phenomena found in a few projects reflective of others? Will a technique perform as well on projects other than the projects it is evaluated on? While it is common sense to select a sample that is representative of a population the importance of diversity is often overlooked yet as important. In this paper we combine ideas from representativeness and diversity and introduce a measure called sample coverage defined as the percentage of projects in a population that are similar to the given sample. We introduce algorithms to compute the sample coverage for a given set of projects and to select the projects that increase the coverage the most. We demonstrate our technique on research presented over the span of two years at ICSE and FSE with respect to a population of 20000 active open source projects monitored by Ohloh.net. Knowing the coverage of a sample enhances our ability to reason about the findings of a study. Furthermore we propose reporting guidelines for research: in addition to coverage scores papers should discuss the target population of the research (universe) and dimensions that potentially can influence the outcomes of a research (space).;
Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering;One of the most widely used techniques to improve the quality of existing software systems is refactoringâ€”the process of improving the design of existing code by changing its internal structure without altering its external behavior. While it is important to suggest refactorings that improve the quality and structure of the system many other criteria are also important to consider such as reducing the number of code changes preserving the semantics of the software design and not only its behavior and maintaining consistency with the previously applied refactorings. In this article we propose a multi-objective search-based approach for automating the recommendation of refactorings. The process aims at finding the optimal sequence of refactorings that (i) improves the quality by minimizing the number of design defects (ii) minimizes code changes required to fix those defects (iii) preserves design semantics and (iv) maximizes the consistency with the previously code changes. We evaluated the efficiency of our approach using a benchmark of six open-source systems 11 different types of refactorings (move method move field pull up method pull up field push down method push down field inline class move class extract class extract method and extract interface) and six commonly occurring design defect types (blob spaghetti code functional decomposition data class shotgun surgery and feature envy) through an empirical study conducted with experts. In addition we performed an industrial validation of our technique with 10 software engineers on a large project provided by our industrial partner. We found that the proposed refactorings succeed in preserving the design coherence of the code with an acceptable level of code change score while reusing knowledge from recorded refactorings applied in the past to similar contexts.;
Artificial Intelligence meets Software Engineering in Computing Education;In this paper we report on the experience of using artificial intelligence systems as the basis of educating IT students in software engineering practices. These systems have been evolving over nearly a dozen years and the process has been generating a steady stream of graduates at the undergraduate and postgraduate level whose dissertations and projects demonstrate the strong interplay of artificial intelligence and software engineering. The AI domains where we have applied a software engineering approach for instruction are focused on decision tree lifecycle management and board game learning mechanisms. Quite as importantly both approaches have also delivered working research tools.;
Proceedings of the 9th Hellenic Conference on Artificial Intelligence;"This report provides an overview of the presentations and discussions of the 2nd IEEE ICSE Workshop on Software Engineering Research and Industrial Practice"" held May 17 2015 in Florence Italy. The program consisted of keynotes paper presentations a panel and a group dinner.""";
Architecting in global software engineering;This paper summarizes the results of the First Workshop on Arc-hitecting in Global Software Engineering (GSE) which was or-ganized in conjunction with the 6th International Conference on Global Software Engineering (ICGSE 2011). The workshop aimed to bring together researchers and practitioners for defining and advancing the state-of-the-art and state-of-the practice in architecture design of global software development systems.;
Collaborative and cooperative-learning in software engineering courses;Collaborative learning is a key component of software engineering (SE) courses in most undergraduate computing curricula. Thus these courses include fairly intensive team projects the intent being to ensure that not only do students develop an understanding of key software engineering concepts and practices but also develop the skills needed to work effectively in large design and development teams. But there is a definite risk in collaborative learning in that there is a potential that individual learning gets lost in the focus on the team's success in completing the project(s). While the team's success is indeed the primary goal of an industrial SE team ensuring individual learning is obviously an essential goal of SE courses. We have developed a novel approach that exploits the affordances of mobile and web technologies to help ensure that individual students in teams in SE courses develop a thorough understanding of the relevant concepts and practices while working on team projects indeed that the team contributes in an essential manner to the learning of each member of the team. We describe the learning theory underlying our approach provide some details concerning the prototype implementation of a tool based on the approach and describe how we are using it in an SE course in our program.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Context: Since the mid-2000s numerous recommendation systems based on text retrieval (TR) have been proposed to support software engineering (SE) tasks such as concept location traceability link recovery code reuse impact analysis and so on. The success of TR-based solutions highly depends on the query submitted which is either formulated by the developer or automatically extracted from software artifacts.Aim: We aim at predicting the quality of queries submitted to TR-based approaches in SE. This can lead to benefits for developers and for the quality of software systems alike. For example knowing when a query is poorly formulated can save developers the time and frustration of analyzing irrelevant search results. Instead they could focus on reformulating the query. Also knowing if an artifact used as a query leads to irrelevant search results may uncover underlying problems in the query artifact itself.Method: We introduce an automatic query quality prediction approach for software artifact retrieval by adapting NL-inspired solutions to their use on software data. We present two applications and evaluations of the approach in the context of concept location and traceability link recovery where TR has been applied most often in SE. For concept location we use the approach to determine if the list of retrieved code elements is likely to contain code relevant to a particular change request or not in which case the queries are good candidates for reformulation. For traceability link recovery the queries represent software artifacts. In this case we use the query quality prediction approach to identify artifacts that are hard to trace to other artifacts and may therefore have a low intrinsic quality for TR-based traceability link recovery.Results: For concept location the evaluation shows that our approach is able to correctly predict the quality of queries in 82% of the cases on average using very little training data. In the case of traceability recovery the proposed approach is able to detect hard to trace artifacts in 74% of the cases on average.Conclusions: The results of our evaluation on applications for concept location and traceability link recovery indicate that our approach can be used to predict the results of a TR-based approach by assessing the quality of the text query. This can lead to saved effort and time as well as the identification of software artifacts that may be difficult to trace using TR.;
Industry/university collaboration in software engineering education: refreshing and retuning our strategies;This panel session will explore strategies for industry/university collaboration in software engineering education. Specific discussion topics will include new strategies for successful industry/university collaboration exploration of reasons why some of the old strategies no longer work and regional/geographical differences noted by the international set of panelists. The panel hopes to identify new promising strategies for such collaborations. Specific industry representatives will be invited to attend and participate in the discussion.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Recommendation System in Software Engineering (RSSE) represents a new promising research area whose goal is to help software developers in their tasks by providing them with context-dependent insights extracted from their current project or taken from best practices. A key challenge here is to retrieve the context from the programming task in order to provide useful recommendations. In this paper we conduct a survey of RSSEs with a particular focus on different approaches used to extract the context. We propose a feature model to represent some important characteristics of such extraction and identify some open issues.;
Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering;The role of software systems on societal sustainability has generally not been the subject of substantive research activity. In this paper we examine the role of software engineering practice as an agent of change/impact for societal sustainability through the manifestation of value sensitive concerns. These concerns remain relatively neglected by software design processes except at early stages of user interface design. Here we propose a conceptual model that can contribute to a translation of value sensitive design from its current focus in participatory design to one located in mainstream software engineering processes. Addressing this need will have an impact of societal sustainability and we outline some of the key research challenges for that journey.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Model-driven software engineering in industrial practice has been the focus of different empirical studies and experience reports. Particularly positive effects of model-driven software engineering have been reported in the domain of embedded and safety-critical systems.We report in this paper on the experiences of the openETCS European research project whose goal was to formalize the System Requirements Specification and to develop an open source reference implementation of the European Train Control System including open source modeling tools. Furthermore we will discuss lessons learned e.g. about using open source modeling toolchains in safety-critical contexts and about using the SCADE Suite for the development of the safety-critical parts.;
Proceedings of the ACM/IEEE 19th International Conference on Model Driven Engineering Languages and Systems;In this review we discuss and compare the previous studies based on human factors in the field of software engineering. Human factors are of utmost importance when we focus on the qualities of a software engineer as they can help predict various industry trends and improve the performance of the process as a whole. Various software engineering researchers have applied different theoretical models to comprehend software developers' personalities. These models prove to be beneficial in improving the performance of engineers and encouraged effective team work by providing an insight on the personality traits which were favourable for certain role type in the software industry. Hence in this research we look at the current chunk of information on software developers' personalities. Our work includes contrasting research work on students in graduation/post graduation programmes effectiveness of a team software project manager's role software engineer's personality and programming in pairs. The comparison shows MBTI (Myers-Briggs Type Indicator) and FFM (Five Factor Model) as significantly used personality models. The rationale behind this paper is to identify the current level of published data on human factors relating to software engineering discussing its significance and benefit to the industry.;
Proceedings of the Third International Symposium on Women in Computing and Informatics;Multi-objective evolutionary algorithms (MOEAs) have been successfully applied for software product lines (SPLs) to search for optimal or near-optimal solutions that balance multiple objectives. However MOEAs usually produce invalid solutions that violate the constraints predefined. As invalid solutions are unbuildable in practice we debate the preservation of invalid solutions during the search. We conduct experiments on seven real-world SPLs including five largest SPLs hitherto reported and two SPLs with realistic values and constraints of quality attributes. We identify three potential limitations of preserving invalid solutions. Furthermore based on the state-of-the-art we design five algorithm variants that adopt different evolutionary operators. By performance evaluation we provide empirical guidance on how to preserve valid solutions. Our empirical study demonstrates that whether or not to preserve invalid solutions deserves more attention in the community and in some cases we have to preserve valid solutions all along the way.;
Proceedings of the 40th International Conference on Software Engineering;"The software engineering curriculum offered by the University of Stuttgart emphasizes project work from the first to the last semester. While some of the projects are similar to those in other programs others are less common. In this paper we describe an introductory course called Program Understanding"" and the so called ""Consulting Task"". We also give a short description of what we call the First Software Project and the Large Software Project. In the Program Understanding course new students learn to understand a fairly large complex program in order to implement some modifications. In the Large Software Project some ten people work on a serious software development for one year. In the Consulting Task a group of three students analyses a problem usually one given by an industrial partner. The students investigate possible solutions and finally deliver a recommendation. Both our experience and feedback from students including feedback from alumni prove that these projects are very successful and highly esteemed.""";
Proceedings of the First International Workshop on Software Engineering Education Based on Real-World Experiences;Software engineering is a sub-discipline of computer science and an important focus of the movement to bring CS education to New York City public schools. From the ACM Software Engineering is about developing and maintaining software systems. The focus on the creation and maintenance of systems or artifacts allows for project-based curriculum implementation focusing not only on the abstractions of computer science but the application of it as well. In the 2013--2014 school year twenty (20) schools in New York City offered software engineering programs. Students participating in these programs completed pre- and post-surveys detailing their understanding of computer science and their desire to pursue computer science both before and after the program. In this paper we give a report of the programs and their curricula as well as results of the surveys for all subgroups. Results from the surveys indicate that exploring the topic of computer science and software engineering is an important recruiting message. Data also suggests that an increasing number of students have access to technology in the home environment despite socioeconomic barriers.;
Proceedings of the 9th Workshop in Primary and Secondary Computing Education;LEGO Serious Play (LSP) is a methodology that helps people brainstorm and discuss complex ideas through storytelling and metaphors. LSP has been successfully applied in higher education as a mechanism for team building and promoting creativity. In this paper we discuss using LSP to teach several core software engineering topics through hands-on case studies. Initial results suggest that LSP has a positive impact on student learning while also improving student engagement with the course material. This paper describes the details of two LSP-based case studies along with many practical aspects of using LSP to teach software engineering.;
Proceedings of the 2015 ACM Conference on Innovation and Technology in Computer Science Education;This paper introduces a method for incorporating software engineering concepts into the computer science curriculum earlier by using a structured project in CS1. The project is designed such that it must be completed using phases of a software development cycle. This approach provides the students earlier exposure to software engineering and grounds software engineering practice throughout the curriculum. With a better understanding of and appreciation for the software development process students are better prepared to handle future academic and professional projects. This paper presents a detailed discussion of the CS1 project and its execution accompanied by results and feedback from a post-project survey administered to students.;
Proceedings of the 18th ACM Conference on Innovation and Technology in Computer Science Education;Continuous software engineering refers to the organizational capability to develop release and learn from software in very short rapid cycles typically hours days or a very small numbers of weeks. This requires not only agile processes in teams but in the complete research and development organization. Additionally the technology used in the different development phases like requirements engineering and system integration must support the quick development cycles. Finally automatic live experimentation for different system alternatives enables fast gathering of required data for decision making. The workshop the second in the series after the first one at ICSE 2014 aims to bring the research communities of the aforementioned areas together to exchange challenges ideas and solutions to bring software engineering a step further to being a holistic continuous process. The workshop program is based on eight papers selected in the peer-review process and supplemented by interaction and discussions at the workshop. The topics range from agile methods continuous software engineering practices to specific techniques like visualization and testing.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Errors in con gurations rather than source code have become one of the major causes of system failures resulting in security vulnerabilities application outages and incorrect program execu- tions. We report on the structure and results of the rst Interna- tional Workshop on Software Engineering for Infrastructure and Con guration Code. Our aim in organizing this jworkshop was to;
Teaching evidence-based software engineering: learning by a collaborative mapping study of open source software;In this paper we share our experiences about teaching evidence-based software engineering to students of a Master degree program in Computer Science. We provided a semester-long course composed of lessons about empirical and experimental methods. It also included a collaborative project concerning a systematic mapping study of the challenges in the adoption of open source software in a business context. All students collaborated on the project by analyzing emerging results in the scientific literature. They evaluated the proposals in terms of level of novelty and evidence and delivered a complete report which summarized the risk factors in the adoption of open source software and offers technical knowledge about evolutionary patterns and development community support with practical implications. As a side effect this problem-based learning approach provides a positive impact in terms of students' participation teamwork attitude professional interest in open source software and exam passing.;
Context-oriented software engineering: a modularity vision;There are a number of constructs to implement context-dependent behavior such as conditional branches using if statements method dispatching in object-oriented programming (such as the state design pattern) dynamic deployment of aspects in aspect-oriented programming and layers in context-oriented programming (COP). Uses of those constructs significantly affect the modularity of the obtained implementation. While there are a number of cases where COP improves modularity it is not clear when we should use COP in general.This paper presents a preliminary study on our software development methodology the context-oriented software engineering (COSE) which is a use-case-driven software development methodology that guides us to a specification of context-dependent requirements and design. We provide a way to map the requirements and design formed by COSE to the implementation in our COP language ServalCJ. We applied COSE to two applications in order to assess its feasibility. We also identify key linguistic constructs that make COSE effective by examining existing COP languages. These feasibility studies and examination raise a number of interesting open issues. We finally show our future research roadmap to address those issues.;
Proceedings of the 13th International Conference on Modularity;Students in a maintenance-centric introductory software engineering course were expected to understand analyze and extend an open source software project of their choice selected from a limited set of prepared applications. Students fell into two groups: those who chose a project based on its perceived and estimated difficulty and those who chose a project based on the appeal of the subject matter. Students in both groups however cited value for themselves in terms of enhanced learning experience and for users in terms of increased benefit as reasons for their selection. These insights into students' thinking can guide future efforts in selecting projects that can simultaneously support the learning objectives as well as motivate the students not only in software engineering but also in broader computing courses.;
Proceedings of the 2014 Conference on Innovation &amp Technology in Computer Science Education;This paper presents an initial framework for managing emergent ethical concerns during software engineering in society projects. We argue that such emergent considerations can neither be framed as absolute rules about how to act in relation to fixed and measurable conditions. Nor can they be addressed by simply framing them as non-functional requirements to be satisficed. Instead a continuous process is needed that accepts the 'messiness' of social life and social research seeks to understand complexity (rather than seek clarity) demands collective (not just individual) responsibility and focuses on dialogue over solutions. The framework has been derived based on retrospective analysis of ethical considerations in four software engineering in society projects in three different domains.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;The development of high performance computing applications is considerably different from traditional software development. This distinction is due to the complex hardware systems inherent parallelism different software lifecycle and workflow as well as (especially for scientific computing applications) partially unknown requirements at design time. This makes the use of software engineering practices challenging so only a small subset of them are actually applied. In this paper we discuss the potential for applying software engineering techniques to an emerging field in high performance computing namely large-scale data analysis and machine learning. We argue for the employment of software engineering techniques in the development of such applications from the start and the design of generic reusable components. Using the example of the Juelich Machine Learning Library (JuML) we demonstrate how such a framework can not only simplify the design of new parallel algorithms but also increase the productivity of the actual data analysis workflow. We place particular focus on the abstraction from heterogeneous hardware the architectural design as well as aspects of parallel and distributed unit testing.;
Proceedings of the 1st International Workshop on Software Engineering for High Performance Computing in Computational and Data-Enabled Science &amp Engineering;Currently adult higher education software engineering pedagogy isolates the student in a controlled environment during delivery with application of their learning temporally distant from their professional practice. Delivering software engineering teaching that is immediately relevant to professional practice remains an open challenge. In this paper we discuss a new pedagogical model which addresses this problem by embedding the validation of the student's learning within their rich professional context. We discuss our experience of applying the model to the design and delivery of a new post-graduate software development module a core component in our new software engineering Masters qualification at the Open University UK a market leader in adult higher education at a distance.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Empirical studies revealed that computer science and engineering students have difficulty in mastering concepts such as interfaces and information hiding. These concepts are central to component-based software engineering (CBSE) a challenging subject to address in a university course given that some degree of software development complexity is necessary for effectively practicing it. This paper describes an experiment carried in an advanced programming course offered at our institution consisting of having a collaborative course project targeting the practice of CBSE. In this collaborative project different student teams developed parts of an IDE whose designs were tested by other teams in terms of component interoperability and extensibility. Although students were able to practice the CBSE-related concepts in approximate real settings the necessary technical supervision from instructors might consist of a pitfall.;
Proceedings of the 15th Koli Calling Conference on Computing Education Research;MOOCs are popular for online education because of their convenience and excellent educational resources. However online education for software engineering on MOOCs faces many challenges: (1) Software Engineering has wide coverage but the teaching time is limited. So it is difficult to make in-depth education (2) Because teachers and students are not face-to-face it is difficult for teachers to know if students understand the lectures or not and how to improve the online education for software engineering.In this paper we propose an approach to using Coursera clickstream data to improve online education for software engineering. The key to the approach is to use the clickstream data produced by students while they are studying for further analysis to find out some useful information such as important content and difficult content of the course. Then the teachers use the analysis result to know students' learning status and improve the teaching quality. Also above all the results we have analyzed we put forward several ways to improve the course Software Engineering.;
Proceedings of the ACM Turing 50th Celebration Conference - China;The India Software Engineering Conference (ISEC) is an annual conference in the field of Software Engineering (SE) in India. ISEC started in the year 2008 and completed 9 years in 2016. The ISEC conference has evolved into a high-quality academic event for SE researchers from universities and industry in India with considerable international participation. Assessment and evaluation of ISEC conference quality status and evolution is important for the national SE scientific community ISEC steering committee sponsors and science and technology-related government bodies. In this paper we conduct scientific paper publication mining and scientometric and bibliometric analysis of 9 years of ISEC publications and programs. We conduct an in-depth multi-dimensional analysis of the conference across various aspects such as a summary of 9 years of ISEC programs (paper submission data tutorials workshops keynotes invited talks geographical location program and general chairs) author-affiliation-based geographical contribution (analysis at the international and national levels) topic analysis university and industry collaborations contributions across university types in India prolific and new authors gender equality and imbalance program committee characteristics open-source or closed-source datasets and citation-based impact. We also present our recommendations for future editions of the ISEC based on our comprehensive analysis study presented in this paper.;
Survey on research synthesis in software engineering;Building trustworthy knowledge in software engineering depends on the systematic synthesis of empirical evidence. In recent years the number of published syntheses has increased but only a few showed high quality and scientific rigor. We performed an online survey of software engineering researchers to identify difficulties experienced when synthesizing evidence. The results confirm that the state of primary research and the low quality of reports are perceived as the most important difficulties. Respondents who were experienced in quantitative and qualitative synthesis methods claim a lack of support for selecting and applying synthesis methods. This indicates the need for identifying criteria for selecting synthesis methods deriving recommendations and developing more rigorous guidelines for applying them.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;As in any academic discipline the evaluation of proposed methodologies and techniques is of vital importance for assessing the validity of novel ideas or findings in Software Engineering. Over the years a large number of evaluation approaches have been employed some of them drawn from other domains and other particularly developed for the needs of software engineering related research. In this paper we present the results of a survey of evaluation techniques that have been utilized in research papers that appeared in three leading software engineering journal and propose a taxonomy of evaluation approaches which might be helpful towards the organization of knowledge regarding the different strategies for the validation of research outcomes. The applicability of the proposed taxonomy has been evaluated by classifying the articles retrieved from ICSE'2012.;
Proceedings of the 7th Balkan Conference on Informatics Conference;Employers require software engineers to work in teams when developing software systems. It is therefore important for graduates to have experienced teamwork before they enter the job market.We describe an experiential learning exercise that we designed to teach the software engineering process in conjunction with teamwork skills. The underlying teaching strategy applied in the exercise maximises risks in order to provide maximal experiential learning opportunities. The students are expected to work in fairly large yet short-lived instructor-assigned teams to complete software engineering tasks. After undergoing the exercise our students form self-selected teams for their capstone projects. In this article we determine and report on the influence the teaching exercise had on the formation of teams for the capstone project. By analysing data provided by the students through regular peer reviews we gain insight into the team dynamics as well as to what extent the members contributed to the team effort.We develop and present a graphical model of a capstone project team which highlights participation of individuals during the teaching exercise. The participatory history of the members is visualised using segmented concentric rings. We consider how this visualisation can aid the identification of capstone project teams that are at risk. In our experience the composition of the team and the behaviour of other members in the team may have a marked impact on the behaviour of each individual in the team. We established a team classification in order to model information about teams. We use a statistical clustering method to classify teams. For this we use team profiles that are based on the participatory levels of its members. The team types that emerge from the clustering are used to derive migration models. When we consider migration we build spring models to visualise the teams through which individuals migrate. We colour code the teams to characterise them according to the team types that were identified during the cluster classification of the teams. Owing to the complexity of the resulting model only migrations for capstone team members who have worked together during the exercise or for solitary capstone team members are modelled. These models support the identification of areas of interest that warrant further investigation.To conclude we present our observations from the analysis of team compositions team types and team migrations and provide directions for future work and collaborations.;
The adoption of capture-recapture in software engineering: a systematic literature review;Context: Capture-recapture method has long been adopted in software engineering as a relatively objective way for defect estimation. While many relevant studies have been carried out to evaluate various capture-recapture models and estimators there still lacks common understanding on the adoption status of the method in software engineering. It is necessary to systematically collect empirical evidence of Capture-recapture adoption hence form necessary understanding on the method.Objective: This study aims to synthesize relevant primary studies on the adoption of capture-recapture method in software engineering and try to identify possible gaps between the state-of-practice and the state-of-art so as to provide clues for future research.Method: By following the guidelines of Kitchenham we conducted a Systematic Literature Review(SLR) on studies of the adoption of capture-recapture method in software engineering.Results: From 5 common digital libraries we retrieved 506 published articles among them 44 were identified as relevant primary studies. We identified 18 capture-recapture estimators under 4 basic models. Types of the currently existing studies as well as the relevant influencing factors to adoption of the capture-recapture method are also discussed.Conclusion: Results show that there are no conclusive decisions on the best capture-recapture models and estimators. Besides the number of inspectors and their capability to detect defects as well as the difficulty to detect defects are most critical influencing factors. In addition lacking of industrial application may be the major issue of current adoption status of capture-recapture method in software engineering.;
Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering;We describe a collaborative software engineering course between sighted college students and high school students with visual impairments. We designed the course as a mentorship experience in which one college student mentor is connected to one high school student mentee. Each pair of students is responsible for a programming project. The students must learn to communicate programming concepts and software designs to work with colleagues with very different levels of software engineering knowledge and to overcome problems related to visual accessibility. We have implemented our course in a pilot program with five mentors and five mentees. This paper covers our course design initial experiences and recommendations for future implementations.;
Proceedings of the 38th International Conference on Software Engineering Companion;Software engineering students need the ability to identify security concerns and then be able to design and build solutions that implement those security requirements. Similarly security students would benefit from knowledge of standard software engineering design practices. This paper discusses methods developed to address both concerns.;
Model-driven software engineering in practice: privacy-enhanced filtering of network traffic;Network traffic data contains a wealth of information for use in security analysis and application development. Unfortunately it also usually contains confidential or otherwise sensitive information prohibiting sharing and analysis. Existing automated anonymization solutions are hard to maintain and tend to be outdated.  We present Privacy-Enhanced Filtering (PEF) a model-driven prototype framework that relies on declarative descriptions of protocols and a set of filter rules which are used to automatically transform network traffic data to remove sensitive information. This paper discusses the design implementation and application of PEF which is available as open-source software and configured for use in a typical malware detection scenario.;
Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering;We present a summary of the 4th ICSE Workshop on Games and Software Engineering. The full day workshop is planned to include a keynote speaker game-jam demonstration session and paper presentations on game software engineering topics related to software engineering education frameworks for game development and infrastructure quality assurance and model-based game development. The accepted papers are overviewed here.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;"In a one semester course on software engineering for upper level computer science students students typically learn the fundamental software processes spanning the software development lifecycle --- from requirements specification through architectural design implementation testing and evolution along with the software tools that support the development activities. Courses in software engineering often incorporate semester long team projects where students collaborate on a software development project. Thus in addition to developing the technical skills associated with software development the software engineering course is a common place where computer science students develop their skills in teamwork and collaboration as well as in communications. The nature and type of projects in such courses varies. Some integrate projects where students develop software for real clients"" such as on campus departments or local non-profits while others have been increasing exposure to open source development with students contributing to existing open source projects. In our software engineering course we have recently introduced course projects where teams of students specify design and implement software that assists computer science students in learning fundamental computer science topics. In this paper we present our experience with such CS learning tool projects including a discussion of the impact on student outcomes in a senior-level course on software engineering. We compare this experience to our prior use of ""real projects for real clients"" in this same course. We find that students who participate in the CS learning tool projects perceive an increase in learning progress on fundamental principles theories and factual knowledge as compared to their peers in course sections with ""real projects for real clients"" with an equivalent effect on teamwork and collaboration skills. Most surprisingly the students who develop CS learning tools report a significantly higher level of progress on industrial relevant skill development as compared to the students who develop so called ""real projects for real clients.""""";
Research opportunities for the big data era of software engineering;Big Data Analysis is becoming a widespread practice on many software development projects and statisticians and data analysts are working alongside developers testers and program managers. Because data science is still an emerging discipline in software projects there are many opportunities where software engineering researchers can help improve practice. In terms of productivity data scientists need support for exploratory analysis of large datasets relief from clerical tasks like data cleaning and easier paths for live deployment of new analyses. In terms of correctness data scientists need help in preserving data meaning and provenance and non-experts need help avoiding analysis errors. In terms of communication and coordination teams need more approachable ways to discuss uncertainty and risk and support for data-driven decision making needs to become available to all roles. This position paper describes these open problems and points to ongoing research beginning to tackle them.;
Proceedings of the First International Workshop on BIG Data Software Engineering;Modeling of requirements and software architecture involves abstraction and critical reasoning that is the most complex stage of development. This knowledge area is the hardest for students to acquire within computer science curricula. The main problem is the fact that the full understanding of this knowledge may only be visible while developing and evolving large scale complex software systems. The learning strategy may have significant impact on students ability to capture this knowledge. On the other hand we may need different learning strategies depending on the context of study programme and student's knowledge base. Here in this paper we present different strategies taken within software engineering courses but in different study programme context. We discuss lessons learned from two courses that belong to two different study programmes at Croatian Universities. Also the deviate learning strategies involving approach and modeling tools and techniques used in these courses are different.;
Proceedings of the 2015 European Conference on Software Architecture Workshops;Academia and industry recognize the effectiveness of teaching Software Engineering through group-based project work supported by lectures discussing software engineering theory. However while undertaking such project work only a very small number of students in the team are exposed to team leadership and project management. This is because teams usually struggle with organization and timely task completion and there is usually no time left to rotate leadership roles. To alleviate this problem several gaming approaches have been proposed. In this paper we analyze GameDevTycoon the most recent addition to such games. We include a gameplay and reflection component in our group-based project course and perform a quantitative analysis of a team management and leadership aspects that the students encountered during their gameplay. We further compare and evaluate GameDevTycoon against five other software engineering-focused games. Our analysis shows the advantages and disadvantages of using GameDevTycoon for teaching project management and highlight further directions towards better inclusion in the curriculum.;
Proceedings of the 45th ACM Technical Symposium on Computer Science Education;Context: The quality of an Systematic Literature Review (SLR) is as good as the quality of the reviewed papers. Hence it is vital to rigorously assess the papers included in an SLR. There has been no tertiary study aimed at reporting the state of the practice of quality assessment used in SLRs in Software Engineering (SE).Objective: We aimed to study the practices of quality assessment of the papers included in SLRs in SE.Method: We conducted a tertiary study of the SLRs that have performed quality assessment of the reviewed papers.Results: We identified and analyzed different aspects of the quality assessment of the papers included in 127 SLRs.Conclusion: Researchers use a variety of strategies for quality assessment of the papers reviewed but report little about the justification for the used criteria. The focus is creditability but not relevance aspect of the papers. Appropriate guidelines are required for devising quality assessment strategies.;
Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering;Background: Most of the experiments in software engineering (SE) employ students as subjects. This raises concerns about the realism of the results acquired through students and adaptability of the results to software industry. Aim: We compare students and professionals to understand how well students represent professionals as experimental subjects in SE research. Method: The comparison was made in the context of two test-driven development experiments conducted with students in an academic setting and with professionals in a software organization. We measured the code quality of several tasks implemented by both subject groups and checked whether students and professionals perform similarly in terms of code quality metrics. Results: Except for minor differences neither of the subject groups is better than the other. Professionals produce larger yet less complex methods when they use their traditional development approach whereas both subject groups perform similarly when they apply a new approach for the first time. Conclusion: Given a carefully scoped experiment on a development approach that is new to both students and professionals similar performances are observed. Further investigation is necessary to analyze the effects of subject demographics and level of experience on the results of SE experiments.;
Proceedings of the 37th International Conference on Software Engineering - Volume 1;Code review is an important task in software development. However performing code review is perceived for the most part as an undesired task presenting several challenges to the required collaboration and knowledge transfer between programmers and reviewers. In order to overcome these challenges and improve the effectiveness of code review we developed SCRUT: Social Code Review Unifying Tool. By recruiting relevant cognitive theories and implementing gamification elements to motivate collaboration and knowledge sharing between programmers and reviewers we plan to enhance the task of code review. This paper presents our vision for enhancing software engineering via gamification and the theoretical cognitive foundation on which this vision is based starting with the example of code review.;
Proceedings of the Eighth International Workshop on Cooperative and Human Aspects of Software Engineering;Mentorship schemes in software engineering education usually involve professional software engineers guiding and advising teams of undergraduate students working collaboratively to develop a software system. With or without mentorship teams run the risk of experiencing team dysfunction: a situation where lack of engagement internal conflicts and/or poor team management lead to different assessment outcomes for individual team members and overall frustration and dissatisfaction within the team. The paper describes a mentorship scheme devised as part of a 33 week software engineering group project course where the mentors were undergraduate students who had recently completed the course successfully and possessed at least a year's experience as professional software engineers. We measure and discuss the impact the scheme had on: (1) student satisfaction and engagement (2) team performance and (3) team dysfunction.;
Proceedings of the 51st ACM Technical Symposium on Computer Science Education;Context: Software organizations have faced several challenges such as the need for faster deliveries frequent changes in requirements lower tolerance to failures and the need to adapt to contemporary business models. Agile practices have allowed organizations to shorten development cycles and increase customer collaboration. However this has not been enough. Organizations should evolve to continuous and data-driven development in a continuous software engineering approach. Continuous Software Engineering (CSE) consists of a set of practices and tools that support a holistic view of software development with the purpose of making it faster iterative integrated continuous and aligned with business. Implementing CSE requires changes in the organizationâ€™s culture practices and structure which may not be easy. Objective: We aim to provide a preliminary picture of CSE adoption in Brazilian organizations. Method: We adapted and used Zeppelin a diagnostic instrument of CSE adoption based on the Stairway to Heaven Model (StH) to perform a survey with 28 Brazilian organizations aiming at investigating the adoption of CSE practices. Results: The results indicate that organizations have better addressed agile and continuous deployment practices than the ones related to continuous integration and continuous experimentation but this scenario changes a bit depending on the organization type. They also show that CSE adoption has been heterogeneous but there are patterns in the adoption of some practices. Conclusion: Although the StH model proposes a sequential and evolutionary path for CSE adoption organizations have not always followed it systematically. There are indeed CSE practices that depend on others and thus contribute to sequential implementation. However organizations tend to adopt the practices gradually covering different stages and evolving according to the organization needs.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Systematic mapping studies are an important research method and have been used in software engineering to provide an overview of a research area by a process of classification and counting of the outputs in a particular area. They have also been used to examine the outputs found in specific publication outlets. In this paper we report on the results of a systematic mapping study conducted to review the entire publication output of the Indian Software Engineering Conference (ISEC) series. We use the outputs of the study to present visual depictions of the nature of Indian Software Engineering academic research from 2008--2015. A second contribution of the work reports on comparison of the ISEC series with that of the pre-eminent international conference in software engineering (ICSE). We contextualise the results within the wider picture of the national Indian IT community.;
Proceedings of the 9th India Software Engineering Conference;Open source software (OSS) communities are often able to produce high quality software comparable to proprietary software. The success of an open source software development (OSSD) community is often attributed to the underlying governance model and a key component of these models is the decision-making (DM) process. While there have been studies on the decision-making processes publicized by OSS communities (e.g. through published process diagrams) little has been done to study decision-making processes that can be extracted using a bottom-up data-driven approach which can then be used to assess whether the publicized processes conform to the extracted processes. To bridge this gap we undertook a large-scale data-driven study to understand how decisions are made in an OSSD community using the case study of Python Enhancement Proposals (PEPs) which embody decisions made during the evolution of the Python language. Our main contributions are:(a) the design and development of a framework using information retrieval and natural language processing techniques to analyze the Python email archives (comprising 1.48 million emails) and(b) the extraction of decision-making processes that reveal activities that are neither explicitly mentioned in documentation published by the Python community nor identified in prior research work. Our results provide insights into the actual decision-making process employed by the Python community.;
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;Empirical methods have grown common in software engineering but there is no consensus on how to apply them properly. Is practical relevance key? Do internally valid studies have any value? Should we replicate more to address the tradeoff between internal and external validity? We asked the community how empirical research should take place in software engineering with a focus on the tradeoff between internal and external validity and replication complemented with a literature review about the status of empirical research in software engineering. We found that the opinions differ considerably and that there is no consensus in the community when to focus on internal or external validity and how to conduct and review replications.;
Proceedings of the 37th International Conference on Software Engineering - Volume 1;The management of global and distributed software projects is a very difficult task further complicated by the emergence of new challenges inherent in stakeholder dispersion. Software cost estimation plays a central role to face challenges in the context of Global Software Development (GSD). The objective of this study is to identify software cost attributes related to GSD context to present an integrative framework encompassing these attributes. Thirty cost attributes were identified using a Systematic Literature Review (SLR) and later compiled into a framework inspired by the Software Engineering Institute (SEI) taxonomy.;
Proceedings of the 13th International Conference on Intelligent Systems: Theories and Applications;Background: Stories and story-work (in the fuller sense of those words) are recognised as a legitimate focus of study in other scientific disciplines.Information Idea Arguments: We are considering forming an inter-disciplinary research programme to explore how story-work can contribute to human-centric software engineering.Vote: What should we focus on to help ensure the proposed programme produces scientifically-valid impactful research?;
Proceedings of the 15th International Conference on Cooperative and Human Aspects of Software Engineering;Many academic disciplines have general theories which apply across the discipline and explain diverse phenomena. General theories facilitate developing a cumulative body of knowledge increase a field's resistance to fads and pseudoscience and help us respond to novel situations where old heuristics break down. The goal of the SEMAT General Theory of Software Engineering (GTSE) workshop is therefore to promote developing and testing general theories for software engineering. The Third GTSE workshop was co-located with the International Conference on Software Engineering (ICSE) in 2014. Participants explored different types of theories and how to assemble them into a framework. Participants debated how to make theories practical to practitioners and agreed that different types of practitioners (e.g. developers) have different needs for theories.;
Organizational social structures for software engineering;Software engineering evolved from a rigid process to a dynamic interplay of people (e.g. stakeholders or developers). Organizational and social literature call this interplay an Organizational Social Structure (OSS). Software practitioners still lack a systematic way to select analyze and support OSSs best fitting their problems (e.g. software development). We provide the state-of-the-art in OSSs and discuss mechanisms to support OSS-related decisions in software engineering (e.g. choosing the OSS best fitting development scenarios). Our data supports two conclusions. First software engineering focused on building software using project teams alone yet these are one of thirteen OSS flavors from literature. Second an emerging OSS should be further explored for software development: social networks. This article represents a first glimpse at OSS-aware software engineering that is to engineer software using OSSs best fit for the problem.;
Learning game design and software engineering through a game prototyping experience: a case study;This report describes a case study of small-scale effort in employing game playtesting as a starting point for learning about mainstream issues and challenges found in modern software engineering projects and practices. The goal is to be descriptive and informing through a qualitative rendering rather than prescriptive and quantitative analysis. This study draws attention to the case of where a student with no prior experience in software development or programming must take on the task of learning how to make a game and along the way learn about many common challenges in modern SE practice through personal discovery and experience. The game itself also imposes challenges in that we have chosen a new unfamiliar game genre and domain that emphasizes science learning as its purpose for play. Along the way we discuss issues in requirements design prototyping testing user experience assessment and evolutionary software extension all prior to a formal education in coding or introductory level Computer Science or SE. Though our efforts may seem unusual or anomalous we believe our methods are open for adoption and reuse by those interested in lowering the barriers to entry into game software development in specific and into SE more generally.;
Proceedings of the 5th International Workshop on Games and Software Engineering;This research explores the influence of the agile practices daily stand-ups and retrospectives on negative effects of subgroups i.e. of having several smaller groups within a team on group conflict satisfaction and performance. Based on extant literature in agile software development (ASD) and group research a model of effects of ASD practices and the constructs elaboration i.e. direct sharing of information and team reflexivity i.e. how much teams reflect on processes and outcomes is developed and assessed using a survey of agile teams. Previous findings on negative effects of subgroups on conflict and satisfaction are corroborated in an agile setting. Retrospectives enhance team reflexivity and elaboration of information. As expected elaboration of information significantly attenuates effects on conflict. Surprisingly reflexivity is seen to further exacerbate the negative effects of perceived subgroups on conflict and satisfaction.;
Proceedings of the 2018 ACM SIGMIS Conference on Computers and People Research;Empirical research studies are the principal mechanism through which the software engineering research community studies and learns from software engineering practice. The focus on empirical studies has increased significantly in the past decade more or less coinciding with the emergence of evidence-based software engineering an idea that was proposed in 2004. As a consequence the software engineering community is familiar with a range of empirical methods. However while several overviews exist of popular empirical research methods such as case studies and experiments we lack a 'holistic' view of a more complete spectrum of research methods. Furthermore while researchers will readily accept that all methods have inherent limitations methods such as case study are still frequently critiqued for the lack of control that a researcher can exert in such a study their use of qualitative data and the limited generalizability that can be achieved. Controlled experiments are seen by many as yielding stronger evidence than case studies but these can also be criticized due to the limited realism of the context in which they are conducted. We identify a holistic set of research methods and indicate their strengths and weaknesses in relation to various research elements.;
Proceedings of the Third International Workshop on Conducting Empirical Studies in Industry;Increasing the international visibility of their papers is an old desire of the Brazilian Symposium on Software Engineering (SBES) community. In that regard the community has taken several actions throughout the years such as incentivizing the submission of papers in English and since 2009 publishing the symposiumâ€™s proceedings in closed-access international digital libraries. However thus far there have been no studies aimed at evaluating the real impact of such initiatives. In this paper we report on a bibliometric study whose goal was to assess the impact of SBESâ€™s internationalization effort. To this end we have collected and classified language and citation data from papers published in the SBES Research Track from 2010 to 2020. One can examine the results of our study from multiple views. A more generous view (the â€œgoodâ€) reveals that by obtaining around 40-60% of its citations from the international community SBES might have achieved its internationalization goals with reasonable success. A more rigorous view (the â€œbadâ€) in turn highlights that by still attracting at least 40% of its citations from the Brazilian community SBESâ€™s internationalization might not compensate for its inevitable weight on the community i.e. the international librariesâ€™ publication costs and their non-compliance to well established Open Science principles. Finally a more critical view (the â€œuglyâ€) calls attention to the relatively high percentage (25-50%) of SBES papersâ€™ self-citations well above the average rate in Computer Science and other disciplines.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Agile methods are used for different kinds of software development even for complex and distributed projects. This leads to a mixture of traditional company organisation as well as project organisation and agile concepts especially when agile methods are applied within traditionally organised corporations. Therefore the main objective of this exploratory semi-structured interview study is to phrase out the occurring problems of this mixture to describe them to name their possible effects and to suggest potential solutions. Practitioners as well as researchers can use those information to improve their projects and to investigate possible solutions to lessen the described problems. During our study we have interviewed seven persons in six interviews who were working for five different companies in Germany. Our analysis revealed eight problems of agile global software engineering projects. Three of them are more likely and more harmful when traditionally organised corporations are involved. But one of those three problems seems solely occurring in global software engineering projects where one or more traditionally organised corporations take part.;
Proceedings of the Ninth International C* Conference on Computer Science &amp Software Engineering;Modern software development communities are increasingly social. Popular chat platforms such as Slack host public chat communities that focus on specific development topics such as Python or Ruby-on-Rails. Conversations in these public chats often follow a Q&ampA format with someone seeking information and others providing answers in chat form. In this paper we describe an exploratory study into the potential usefulness and challenges of mining developer Q&ampA conversations for supporting software maintenance and evolution tools. We designed the study to investigate the availability of information that has been successfully mined from other developer communications particularly Stack Overflow. We also analyze characteristics of chat conversations that might inhibit accurate automated analysis. Our results indicate the prevalence of useful information including API mentions and code snippets with descriptions and several hurdles that need to be overcome to automate mining that information.;
Proceedings of the 16th International Conference on Mining Software Repositories;To systematically collect evidence and to structure a given area in software engineering (SE) Systematic Literature Reviews (SLR) and Systematic Mapping (SM) studies have become common. Data extraction is one of the main phases (activities) when conducting an SM or an SLR whose objective is to extract required data from the primary studies and to accurately record the information researchers need to answer the questions of the SM/SLR study. Based on experience in a large number of SM/SLR studies we and many other researchers have found the data extraction in SLRs to be time consuming and error-prone thus raising the real need for heuristics and guidelines for effective and efficient data extraction in these studies especially to be learnt by junior and young researchers. As a 'guideline' paper this paper contributes a synthesized list of challenges usually faced during SLRs' data extraction phase and the corresponding solutions (guidelines). For our synthesis we consider two data sources: (1) the pool of 16 SLR studies in which the authors have been involved in as well as (2) a review of challenges and guidelines in the existing literature. Our experience in utilizing the presented guidelines in the near past have helped our junior colleagues to conduct data extractions more effectively and efficiently.;
Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering;The research purpose of software development is to try to develop various software that can meet the needs of users with low cost and high reliability. At present many new software development technologies and methods are still difficult to adapt to the main trends of software development in the new era in a short period of time and how to make good use of software development models to better meet the needs of software development is still one of the urgent problems to be solved. From the perspective of software engineering this paper deeply analyzes the advantages and existing problems of typical software development models and analyzes the reasonable application of software development models in computer software development which is for reference only.;
Proceedings of the 5th International Conference on Information Science and Systems;Context: Systematic literature reviews have become common in software engineering in the last decade but challenges remain.Goal: Given the challenges the objective is to describe improvement areas in writing primary studies and hence provide a good basis for researchers aiming at synthesizing research evidence in a specific area.Method: The results presented are based on a literature review with respect to synthesis of research results in software engineering with a particular focus on empirical software engineering. The literature review is complemented and exemplified with experiences from conducting systematic literature reviews and working with research methodologies in empirical software engineering.Results: The paper presents three areas where improvements are needed to become more successful in synthesizing empirical evidence. These three areas are: terminology paper content and reviewing.Conclusion: It is concluded that it must be possible to improve the primary studies but it requires that researchers start having synthesis in mind when writing their research papers.;
Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Can the methods of empirical software engineering give us answers to the truly important open questions in the field?;
Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering;Text Retrieval (TR) approaches have been used to leverage the textual information contained in software artifacts to address a multitude of software engineering (SE) tasks. However TR approaches need to be configured properly in order to lead to good results. Current approaches for automatic TR configuration in SE configure a single TR approach and then use it for all possible queries. In this paper we show that such a configuration strategy leads to suboptimal results and propose QUEST the first approach bringing TR configuration selection to the query level. QUEST recommends the best TR configuration for a given query based on a supervised learning approach that determines the TR configuration that performs the best for each query according to its properties. We evaluated QUEST in the context of feature and bug localization using a data set with more than 1000 queries. We found that QUEST is able to recommend one of the top three TR configurations for a query with a 69% accuracy on average. We compared the results obtained with the configurations recommended by QUEST for every query with those obtained using a single TR configuration for all queries in a system and in the entire data set. We found that using QUEST we obtain better results than with any of the considered TR configurations.;
Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering;Context: The utility of prediction models in empirical software engineering (ESE) is heavily reliant on the quality of the data used in building those models. Several data quality challenges such as noise incompleteness outliers and duplicate data points may be relevant in this regard. Objective: We investigate the reporting of three potentially influential elements of data quality in ESE studies: data collection data pre-processing and the identification of data quality issues. This enables us to establish how researchers view the topic of data quality and the mechanisms that are being used to address it. Greater awareness of data quality should inform both the sound conduct of ESE research and the robust practice of ESE data collection and processing. Method: We performed a targeted literature review of empirical software engineering studies covering the period January 2007 to September 2012. A total of 221 relevant studies met our inclusion criteria and were characterized in terms of their consideration and treatment of data quality. Results: We obtained useful insights as to how the ESE community considers these three elements of data quality. Only 23 of these 221 studies reported on all three elements of data quality considered in this paper. Conclusion: The reporting of data collection procedures is not documented consistently in ESE studies. It will be useful if data collection challenges are reported in order to improve our understanding of why there are problems with software engineering data sets and the models developed from them. More generally data quality should be given far greater attention by the community. The improvement of data sets through enhanced data collection pre-processing and quality assessment should lead to more reliable prediction models thus improving the practice of software engineering.;
Proceedings of the 17th International Conference on Evaluation and Assessment in Software Engineering;In the past five years there has been a dramatic increase in work on Search-Based Software Engineering (SBSE) an approach to Software Engineering (SE) in which Search-Based Optimization (SBO) algorithms are used to address problems in SE. SBSE has been applied to problems throughout the SE lifecycle from requirements and project planning to maintenance and reengineering. The approach is attractive because it offers a suite of adaptive automated and semiautomated solutions in situations typified by large complex problem spaces with multiple competing and conflicting objectives.This article1 provides a review and classification of literature on SBSE. The work identifies research trends and relationships between the techniques applied and the applications to which they have been applied and highlights gaps in the literature and avenues for further research.;
MO-DM Tool: Improving teamsâ€™ engagement with Motivation-Oriented Decision-Making;A significant part of Software Engineering studentsâ€™ academic and professional life involves working on projects in collaboration with their peers. They will form teams and perform on many software-related projects. Studies based on a systematic literature review and experimental results in a multidisciplinary tech-based innovation course with undergraduate students from Computer Engineering and Computer Science indicate difficulties in two significant activities in collaborative work: decision-making and reaching consensus. These recurrent difficulties negatively affect learnersâ€™ motivation and engagement throughout the projectâ€™s life cycle besides other losses. This article aims to present a tool based on a model called MO-DM (Motivation-Oriented Decision-Making) proposed in doctoral research to address these hardships. It enables a new project view of membersâ€™ motivation and engagement considering all the choices made along the project journey. The tool is grounded on EVC (Expectancy-Value-Cost) model using it in a new way. Decisions like â€What programming language should we use?â€ are observed from the perspective of â€Which programming language can bring more engagement and motivation to the majority of the team?â€. This view makes it possible to identify which students are more susceptible to being demotivated and disengaged in each step and actions can be performed to mitigate these effects. Teams can make more engaging and motivating choices by picking the ones that will positively affect most of the group enhancing the chances of successful projects. MO-DM tool is under preliminary tests with satisfactory results. Many decision-making situations where motivation and engagement are concerns can benefit from MO-DM. Tool presentation video link here.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;This panel will discuss what characterizes the publication process in the software engineering community and debate how it serves the needs of the community whether it is fair - e.g. valuable work gets published and mediocre work rejected - and highlight the obstacles for young scientists. The panel will conclude with a discussion on suggested next steps.;
Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering;This paper is a short story of my adventures of the past 20 years trying to integrate academic research with software engineering problems in industry. I share the challenges I encountered on the way my failures and successes evolution of my research and its adoption in industry. Though I faced many hardships I feel great satisfaction in knowing that my research is applied today in the design of avionics systems automobiles and even in NASA's Orion program. My latest adventure and honor is an opportunity to participate in two visionary Defense Advanced Research Project Agency (DARPA) programs aimed at developing an innovative technology to fight the war against sophisticated malware that poses grave security threats to individuals and nations. Without working with industry it would not have been possible for me to formulate rigorous but practical research problems. These problems have shaped my research. I narrate my story to provide insights into bridging the gap between academic research and the problems industry practitioners face. My hope is the reader can benefit from the story and be able to achieve in 10 years what has taken me 20 years. I also hope that my story encourages industry practitioners to work with universities.;
Proceedings of the 3rd International Workshop on Software Engineering Research and Industrial Practice;In spite of the human-centric aspect of software engineering (SE) discipline human error knowledge has been ignored by SE educators as it is often thought of as something that belongs in the realm of Psychology. SE curriculum is also severely devoid of educational content on human errors while other human-centric disciplines (aviation medicine process control) have developed human error training and other interventions. To evaluate the feasibility of using such interventions to teach students about human errors in SE this paper describes an exploratory study to evaluate whether requirements inspections driven by human errors can be used to deliver both requirements validation knowledge (a key industry skill) and human error knowledge to students. The results suggest that human error based inspections can enhance the fault detection abilities of students a primary learning outcome of inspection exercises conducted in software engineering courses. Additionally results showed that students found human error information useful for understanding the underlying causes of requirement faults.;
Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education;The design of recommendation systems is based on complex information processing and big data interaction. This personalized view has evolved into a hot area in the past decade where applications might have been proved to help for solving problem in the software development field. Therefore with the evolvement of Recommendation System in Software Engineering (RSSE) the coordination of software projects with their stakeholders is improving. This experiment examines four open source recommender systems and implemented a customized recommender engine with two industrial-oriented packages: Lenskit and Mahout. Each of the main functions was examined and issues were identified during the experiment.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;By working on open source software projects software engineering students can benefit from working on more realistic products than traditional educational programming assignments. However careers in software engineering demand learning how to work within a professional environment and how to follow software development processes. We studied the impact of students' interactions with external collaborators on open source projects and found many similar outcomes between those who communicated remotely and those who communicated face-to-face. However we also discovered that face-to-face interactions with local software professionals following the Localized Free and Open Source (LFOSS) model had particular advantages in teaching Agile methods holding students accountable and introducing professional networking opportunities.;
Proceedings of the 2017 ACM Conference on Innovation and Technology in Computer Science Education;Software start-ups face fierce competition in the market forcing them to release their products quickly and often under tough time constraints. To meet their deadlines start-ups take shortcuts in software development leading to the accumulation of technical debt. They are able to put their product in users hands faster get feedback and improve at the expense of quality issues in the long run. As a start-up evolves through inception stabilization and growth this debt will have to be managed. Technical debt management and software product line engineering techniques have some similar benefits of increased productivity and reduced time-to-market. Our aim is to check whether software product line engineering can be a candidate technique for start-ups to employ in managing technical debt as a response to their life-cycle phase goals and challenges. We conducted expert interviews with nine start-up professionals to identify the strategies applied in relation to technical debt management and software product lines engineering and other software engineering practices in start-ups. By analyzing the responses from the interviews we found that depending on the life-cycle phase of the start-up software product line engineering proved effective in managing technical debt and helped the start-ups to advance through the life-cycle phases.;
Proceedings of the 2nd ACM SIGSOFT International Workshop on Software-Intensive Business: Start-Ups Platforms and Ecosystems;Context: Empirical studies are gaining recognition in the Software Engineering (SE) research community. In order to foster empirical research it is essential understand the environments guidelines process and other mechanisms available to support these studies in SE. Goal: Identifying the mechanisms used to support the empirical strategies adopted by the researches in the major Empirical Software Engineering (ESE) scientific venues. Method: We performed a systematic mapping study that included all full papers published at EASE ESEM and ESEJ since their first editions. A total of 898 studies were selected. Results: We provide the full list of identified support mechanisms and the strategies that uses them. The most commonly mechanisms used to support the empirical strategies were two sets of guidelines one to secondary studies and another to experiments. The most reported empirical strategies are experiments and case studies. Conclusions: The use of empirical methods in SE has increased over the years but many studies do not apply these methods nor use mechanisms to guide their research. Therefore the list of support mechanisms where and how they were applied is a major asset to the SE community. Such asset can foster empirical studies aiding the choice regarding which strategies and mechanisms to use in a research. Also we identified new perspectives and gaps that foster the development of resources to aid empirical studies.;
Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Context Software engineering activities provide practitioners with large volumes of data that software analytics tools can use for many purposes including defect prediction and effort estimation. However the adoption of such tools depends on the information they provide and the real needs of practitioners. While existing research has focused on what developers need the needs of managers are not well understood. Aims This study provides an in-depth analysis of the information needs of software practitioners from one organization that performs research development and innovation projects with industry partners. Understanding these practitionersâ€™ needs enables the development of better analytics solutions to support managerial decision-making. Method We interviewed practitioners in leadership positions and analyzed the collected data using Grounded Theory coding techniques i.e. open and selective coding. Results We identified 19 software analytics use cases and classified them into four dimensions: quality people project management and knowledge management. We also elicited several indicators to meet the identified use cases and captured key aspects concerning the organizationâ€™s analytics scenario. Conclusions Although our results are particularly relevant to organizations similar to the one in which we conducted the study they aim to serve as input for implementing new analytics solutions by practitioners and researchers in general.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;A Software Engineering project depends significantly on team performance as does any activity that involves human interaction. In the last years the traditional perspective on software development is changing and Agile methods have received considerable attention. Among other attributes the agilists claim that fostering Creativity is one of the keys to response to common problems and challenges of software development today. The development of new software products requires the generation of novel and useful ideas. In this paper eXtreme Programming (XP) is analyzed and evaluated from the perspective of the creativity in particular the creative performance and structure required at the teamwork level.;
Proceedings of the 5th International Workshop on Co-Operative and Human Aspects of Software Engineering;"Affects--emotions and moods--have an impact on cognitive processing activities and the working performance of individuals. It has been established that software development tasks are undertaken through cognitive processing activities. Therefore we have proposed to employ psychology theory and measurements in software engineering (SE) research. We have called it psychoempirical software engineering"". However we found out that existing SE research has often fallen into misconceptions about the affect of developers lacking in background theory and how to successfully employ psychological measurements in studies. The contribution of this paper is threefold. (1) It highlights the challenges to conduct proper affect-related studies with psychology (2) it provides a comprehensive literature review in affect theory and (3) it proposes guidelines for conducting psychoempirical software engineering.""";
Proceedings of the 7th International Workshop on Social Software Engineering;In this report we present a summary and a few reflections of a one day workshop on Software Engineering Education held on February 22 2012 at Indian Institute of Technology Kanpur India collocated with the 5th India Software Engineering Conference. We identify a gap and believe there is a need for creating an annual discussion forum that serves the need of having a regular workshop for software engineering education in India and also benefit the global software engineering education community by sharing the workshop insights and results by a publication process. The workshop consists of two keynotes one from academia and one from industry two subgroups discussions and presentations by the subgroups on their discussions. Three systematic techniques invitation of position statements set up of a Google group and an online survey were employed before the workshop to estimate number of participants subgroups and size of each subgroup for effective discussions. Twenty participants attended the workshop. The keynotes were on Using Collaborative Learning and Divergent Thinking to Teach Software Engineering and on Software Engineering Competency Development Model. Three topics were selected for subgroups discussions by the participants: use of various methods such as learning while playing and project-based software engineering over Power Point lecture requirements and needs of undergraduate software engineering degree program from the perspective of Indian software industry and curriculum content coverage and impact of software engineering courses. The workshop was a successful endeavor and the response in terms of the contributions by participants is a clear indicator and confirmation of the need of having a focused discussion forum for brainstorming on software engineering education in India;
From word embeddings to document similarities for improved information retrieval in software engineering;The application of information retrieval techniques to search tasks in software engineering is made difficult by the lexical gap between search queries usually expressed in natural language (e.g. English) and retrieved documents usually expressed in code (e.g. programming languages). This is often the case in bug and feature location community question answering or more generally the communication between technical personnel and non-technical stake holders in a software project. In this paper we propose bridging the lexical gap by projecting natural language statements and code snippets as meaning vectors in a shared representation space. In the proposed architecture word embeddings are first trained on API documents tutorials and reference documents and then aggregated in order to estimate semantic similarities between documents. Empirical evaluations show that the learned vector space embeddings lead to improvements in a previously explored bug localization task and a newly defined task of linking API documents to computer programming questions.;
Proceedings of the 38th International Conference on Software Engineering;Context: Empirical studies are gaining recognition in the Software Engineering (SE) research community allowing improved quality of research and accelerating the adoption of new technologies in the software market. However empirical studies in this area are still limited. In order to foster empirical research in SE it is essential to understand the resources available to aid these studies. Goal: Identify support mechanisms (methodology tool guideline process etc.) used to conduct empirical studies in the Empirical Software Engineering (ESE) community. Method: We performed a systematic mapping study that included all full papers published at EASE ESEM and ESEJ since their first editions. Were selected 891 studies between 1996 and 2013. Results: A total of 375 support mechanisms were identified. We provide the full list of mechanisms and the strategies that uses them. Despite this we identified a high number of studies that do not cite any mechanism to support their empirical strategies: 433 studies (48%). Experiment is the strategy that has more resources to support their activities. And guideline was the most used type of mechanism. Moreover we observed that the most mechanisms used as reference to empirical studies are not specific to SE area. And some mechanisms were used only in specific activities of empirical research such as statistical and qualitative data analysis. Experiment and case studies are the strategies most applied. Conclusions: The use of empirical methods in SE has increased over the years. Despite this many studies did not apply these methods and do not cite any resource to guide their research. Therefore the list of support mechanisms where and how they were applied is a major asset to the SE community. Such asset can encourage empirical studies aiding the choice regarding which strategies and mechanisms to use in a research as well as pointing out examples where they were used mainly to novice researchers. We also identified new perspectives and gaps that foster other research for the improvement of empirical research in this area.;
Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering;The paper describes SE master training plans and suggestions for a recent Russian startup the ambitious Innopolis project. Building the Innovation City is a challenge due to the differences in the objectives and goals of the participating sides: governmental industry academic and research organizations. The new city is being built from scratch next to Kazan' the capital of Tatarstan Republic - this is also a challenge by itself. The idea is to use the synergy of IT academicians researchers and practitioners in a single location. The Innovation City will incorporate a kindergarten a STEM training school a university and an IT park. Of these the university will act as the brain for the entire project. The primary focus of the university curricula is software engineering. Currently Innoplois faculty training is underway at Carnegie Mellon University (CMU) the birthplace of the software engineering and the top ranked university in the field. Research and project practice are tightly coupled within the CMU SE master's program the CMU course sequence is well justified while each individual course is thoroughly planned. However direct curricula copying from CMU to Innopolis would be too obvious solution to be correct. The paper discusses ways of context-specific adjustment of the CMU MSE courses to meet the new Russian university objectives. These curricula tailoring suggestions are based on the takeaways from the author's recent CMU visiting faculty experience the primary focus of which has been SE training to be applied at Innopolis shortly.;
Proceedings of the 10th Central and Eastern European Software Engineering Conference in Russia;Prediction of defects in software is an important investigation area in software engineering since such technique is able to return indications of parts of the code that are prone to contain problems. Thus test teams can optimize the allocation of their resources by directing them to modules that are more defect-prone. The use of supervised learning is one of the approaches to support the design of prediction models. However the erroneous use of training datasets can lead to poor models and consequently false results regarding accuracy. This work replicates important experiments of the area and shows how they could provide reliable results via the use of simple techniques of pre-processing. Based on the results we discuss the importance of replications as method to find problems in current results and how this method is being motivated inside the software engineering area.;
Proceedings of the 2015 Conference on Research in Adaptive and Convergent Systems;The formal verification of finite-state probabilistic models supports the engineering of software with strict quality-of-service (QoS) requirements. However its use in software design is currently a tedious process of manual multiobjective optimisation. Software designers must build and verify probabilistic models for numerous alternative architectures and instantiations of the system parameters. When successful they end up with feasible but often suboptimal models. The EvoChecker search-based software engineering approach and tool introduced in our paper employ multiobjective optimisation genetic algorithms to automate this process and considerably improve its outcome. We evaluate EvoChecker for six variants of two software systems from the domains of dynamic power management and foreign exchange trading. These systems are characterised by different types of design parameters and QoS requirements and their design spaces comprise between 2E+14 and 7.22E+86 relevant alternative designs. Our results provide strong evidence that EvoChecker significantly outperforms the current practice and yields actionable insights for software designers.;
Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering;Social Software Engineering (Social SE) that is SE aiming to promote positive social change is a rapidly emerging area. Here software and digital artefacts are seen as tools for social change rather than end products or 'solutions'. Moreover Social SE requires a sustained buy-in from a range of stakeholders and end-users working in partnership with multidisciplinary software development teams often at a distance. This context poses new challenges to software engineering: it requires both an agile approach for handling uncertainties in the software development process and the application of participatory creative design processes to bridge the knowledge asymmetries and the geographical distances in the partnership. This paper argues for the role of design thinking in Social SE and highlights its implications for software engineering in general. It does so by reporting on the contributions that design thinking---and in particular physical design---has brought to (1) the problem space definition (2) user requirements capture and (3) system feature design of a renewable energy forecasting system developed in partnership with a remote Scottish Island community.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Component Based Software Engineering (CBSE) constructs a quality software system by reusing existing components. For the construction of high-quality software system reusability plays an important role. Software component should be designed and implemented in such a way that many different programs can reuse them. Reuse of software can increase the productivity and quality of software by reducing effort time and cost which was elapsed in designing and developing reusable software component. In this paper a Neuro-fuzzy model has been proposed that uses software component design patterns for analysis and Chidamber and Kemerer (CK) metric for evaluation optimization and categorization of reusability for component based software. The work is divided into 2 phases. In the first phase analysis and optimization of reusability are empirically evaluated with high precision value using CK metric and unsupervised Self Organizing Map (SOM) Neural Network. In the second phase reusability is categorized as very low low medium high and very high using a supervised Back propagation Neural Network (BPNN) and fuzzy inference rules applied on CK metric values. The proposed model may help a software designer to evaluate and optimize the reusability of components while designing software to make quality software system.;
Building a theory of job rotation in software engineering from an instrumental case study;Job Rotation is an organizational practice in which individuals are frequently moved from a job (or project) to another in the same organization. Studies in other areas have found that this practice has both negative and positive effects on individuals' work. However there are only few studies addressing this issue in software engineering so far. The goal of our study is to investigate the effects of job rotation on work related factors in software engineering by performing a qualitative case study on a large software organization that uses job rotation as an organizational practice. We interviewed senior managers project managers and software engineers that had experienced this practice. Altogether 48 participants were involved in all phases of this research. Collected data was analyzed using qualitative coding techniques and the results were checked and validated with participants through member checking. Our findings suggest that it is necessary to find balance between the positive effects on work variety and learning opportunities and negative effects on cognitive workload and performance. Further the lack of feedback resulting from constant movement among projects and teams may have a negative impact on performance feedback. We conclude that job rotation is an important organizational practice with important positive results. However managers must be aware of potential negative effects and deploy tactics to balance them. We discuss such tactics in this article.;
Proceedings of the 38th International Conference on Software Engineering;Background: A number of software tools are being developed to support systematic reviewers within the software engineering domain. However at present we are not sure which aspects of the review process can most usefully be supported by such tools or what characteristics of the tools are most important to reviewers. Aim: The aim of the study is to explore the scope and practice of tool support for systematic reviewers in other disciplines. Method: Researchers with experience of performing systematic reviews in Healthcare and the Social Sciences were surveyed. Qualitative data was collected through semi-structured interviews and data analysis followed an inductive approach. Results: 13 interviews were carried out. 21 software tools categorised into one of seven types were identified. Reference managers were the most commonly mentioned tools. Features considered particularly important by participants were support for multiple users support for data extraction and support for tool maintenance. The features and importance levels identified by participants were compared with those proposed for tools to support systematic reviews in software engineering. Conclusions: Many problems faced by systematic reviewers in other disciplines are similar to those faced in software engineering. There is general consensus across domains that improved tools are needed.;
Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering;This paper projects that an important future direction in software engineering is domain-specific software engineering (DSE). From requirements specification to design and then implementation a tighter coupling between the description of a software system with its application domain has the potential to improve both the correctness and reliability of the software system and also lead to greater opportunities for software automation. In this position paper we explore the impact of this emerging paradigm on requirements specification design modeling and implementation as well as challenge areas benefiting from the new paradigm.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;It is often reported that there is a large gap between software engineering research and practice with little transfer from research to practice. While this is true in general one transfer technique is increasingly breaking down this barrier: extensions to integrated development environments (IDEs). With the proliferation of app stores for IDEs and increasing transfer effort from researchers several research-based extensions have seen significant adoption. In this talk we'll discuss our experience transferring code search research which currently is in the top 5% of Visual Studio extensions with over 9000 downloads as well as other research techniques transferred via extensions such as NCrunch FindBugs Code Recommenders Mylyn and Instasearch. We'll use the lessons learned from our transfer experience to provide case study evidence as to best practices for successful transfer supplementing it with the quantitative evidence offered by app store and usage data across the broader set of extensions. The goal of this 30 minute talk is to provide researchers with a realistic view on which research techniques can be transferred to practice as well as concrete steps to execute such a transfer.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;"The energy consumption of information and communication technology (ICT) is still increasing. Since several concepts regarding hardware solutions for Green IT exist the contribution of software to Green IT is still not well investigated. This comprises the production and the usage impact of software on energy consumption. In our paper we discuss this contribution. Especially we present a model that integrates Green IT aspects into software engineering processes with agile methods in order to produce greener"" software from scratch.""";
Proceedings of the 2nd International Workshop on Green and Sustainable Software;Opinion mining sometimes referred to as sentiment analysis has gained increasing attention in software engineering (SE) studies. SE researchers have applied opinion mining techniques in various contexts such as identifying developersâ€™ emotions expressed in code comments and extracting usersâ€™ critics toward mobile apps. Given the large amount of relevant studies available it can take considerable time for researchers and developers to figure out which approaches they can adopt in their own studies and what perils these approaches entail.We conducted a systematic literature review involving 185 papers. More specifically we present (1) well-defined categories of opinion mining-related software development activities (2) available opinion mining approaches whether they are evaluated when adopted in other studies and how their performance is compared (3) available datasets for performance evaluation and tool customization and (4) concerns or limitations SE researchers might need to take into account when applying/customizing these opinion mining techniques. The results of our study serve as references to choose suitable opinion mining tools for software development activities and provide critical insights for the further development of opinion mining techniques in the SE domain.;
Combining education industry and empirical studies in Software Engineering: an experience report;Software industry is one of the most pervasive industries today and has a great impact on our day-to-day lives. At the same time the quality of software systems is directly related to the quality of software engineers -- it is the responsibility of software engineering educators to provide students with relevant skills needed for the development of high-quality software systems. Amongst the cornerstones of developing high-quality software systems are industry-relevant experience and the ability to quantify certain aspects of the software development process. In this paper we describe our experience of performing an empirical study on students during a software engineering course on an industry-relevant topic taught by an industry expert -- the understandability of models in model-driven engineering.;
Proceedings of the 2015 European Conference on Software Architecture Workshops;There is a known and established gender imbalance in software engineering structures. The discussions about gender diversity in Software Engineering are on the table however which are the benefits and the difficulties people in software development teams see in gender diversity? For this work we conducted a survey to qualitatively understand the perceived benefits and difficulties of gender diversity in software development teams. We found out that gender-diverse workplaces are prone to have better ideas sharing better decision making creativity and innovation. Respondents mentioned that some companies worked to improve the hiring process to be more gender-inclusive. Womenâ€™s support and inspiration were shared and some men reported being touched by the subject and diligently are deconstructing their prejudice and misconceptions about women in technology. There are also difficulties. It is common to see only one woman in teams or just a few. More than that no other gender than men and women so the white cisgender man is the pattern most of the time. The same pattern repeats itself in leadership positions leading to male protectionism and privileges. Additionally other dimensions of diversity pervaded the answers like intersectionality race/ethnicity ageism and a less explored point: social vulnerability.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Globalization has long since found its way into software engineering. Many companies transfer part of their development activities to distributed countries in order to ensure their global competitiveness gain access to local markets and react to the prevailing lack of specialized workforce. The global distribution of project teams introduces new challenges: Geographic separation different time zones remote communications and culture and language barriers make the collaboration between team members more difficult.Instructors in universities are faced with the problem of how to make students with little or no experience aware of the challenges of Global Software Engineering and equip them with skills to deal with them. International practical courses are effective but require high organizational effort. In this paper we describe an exercise for teaching Global Software Engineering in a single classroom and report on our experiences. The exercise simulates a global software project within three sites. Through the exercise students experienced some of the aforementioned challenges and tried to deal with them in a simulated environment.;
Proceedings of the 47th ACM Technical Symposium on Computing Science Education;"The adoption and success of serious games for educational purposes partially depend on instructor related factors. This study proposes a simple hypothetical model on the factors that influence the instructor's acceptance of the utilization of games (whether serious or not) in undergraduate software engineering education. The suggested model is tested by means of a pilot questionnaire conducted in Turkey. Data collected from 30 instructors revealed that the number of hours per week the instructor plays game"" ""instructor's experience in using games for educational purposes in general"" and ""instructor's experience in designing games"" have significant impact on the instructor's decision to use games in software engineering education. We found no significant impact of ""instructor's previous research experience in education"" ""intention to conduct future research on education"" and ""awareness of games used in teaching software engineering"". The suggested model significantly predicted the dependent variable with R2 = 0.798.""";
Proceedings of the Fourth International Workshop on Games and Software Engineering;Deep learning (DL) models are widely used in software applications. Novel DL models and datasets are published from time to time. Developers may also tempt to apply new software engineering (SE) techniques on their DL models. However no existing tool supports the applications of software testing and debugging techniques on new DL models and their datasets without modifying the code. Developers should manually write code to glue every combination of models datasets and SE technique and chain them together.We propose SEbox4DL a novel and modular toolbox that automatically integrates models datasets and SE techniques into SE pipelines seen in developing DL models. SEbox4DL exemplifies six SE pipelines and can be extended with ease. Each user-defined task in the pipelines is to implement a SE technique within a function with a unified interface so that the whole design of SEbox4DL is generic modular and extensible. We have implemented several SE techniques as user-defined tasks to make SEbox4DL off-the-shelf. Our experiments demonstrate that SEbox4DL can simplify the applications of software testing and repair techniques on the latest or popular DL models and datasets. The toolbox is open-source and published at https://github.com/Wsine/SEbox4DL. A video for demonstration is available at: https://youtu.be/EYeFFi4lswc.;
Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings;In order to adopt games for Software Engineering (SE) education effectively it is essential to obtain sound evidence on their quality. A prominent evaluation model is MEEGA (Model for the Evaluation of Educational Games) which provides a systematic support to evaluate the game's quality in terms of motivation user experience and learning. To facilitate its application the model provides a questionnaire for collecting data on the perception of the students after they played an educational game in a case study with a one-shot post-test design. However in order to assure a valid feedback on the game's quality an important issue is the reliability and validity of the questionnaire. In this respect this article presents a large-scale evaluation of the MEEGA questionnaire in terms of reliability and construct validity. The analysis is based on data collected in 43 case studies evaluating 20 different SE games involving a population of 723 students. Our analysis indicates that the MEEGA questionnaire can be considered reliable (Cronbach's alpha Î±=.915). In terms of construct validity there exists evidence of convergent validity through an acceptable degree of correlation of almost all item pairs within each dimension. Yet we identified a need for the regrouping of items based on the results of a factor analysis mainly with respect to items related to motivation and user experience. These results allow SE researchers and instructors to rely on the MEEGA questionnaire in order to evaluate SE games and thus contribute to their improvement and to direct an effective and efficient adoption for SE education.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Crowdsourcing is increasingly revolutionizing the ways in which software is engineered. Programmers increasingly crowdsource answering their questions through Q&ampA sites. Nonprogrammers may contribute human-intelligence to development projects by for example usability testing software or even play games with a purpose to implicitly construct formal specifications. Crowdfunding helps to democratize decisions about what software to build. Software engineering researchers may even benefit from new opportunities to evaluate their work with real developers by recruiting developers from the crowd. CSI-SE will inform the software engineering community of current techniques and trends in crowdsourcing discuss the application of crowdsourcing to software engineering to date and identify new opportunities to apply crowdsourcing to solve software engineering problems.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Empirical software engineering research aims to generate prescriptive knowledge that can help software engineers improve their work and overcome their challenges but deriving these insights from real-world problems can be challenging. In this paper we promote design science as an effective way to produce and communicate prescriptive knowledge. We propose using a visual abstract template to communicate design science contributions and highlight the main problem/solution constructs of this area of research as well as to present the validity aspects of design knowledge. Our conceptualization of design science is derived from existing literature and we illustrate its use by applying the visual abstract to an example use case. This is work in progress and further evaluation by practitioners and researchers will be forthcoming.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;This article addresses one of the major end-user software engineering (EUSE) challenges namely how to motivate end users to apply unfamiliar software engineering techniques and activities to achieve their goal: translate requirements into software that meets their needs. EUSE activities are secondary to the goal that the program is helping to achieve and end-user programming is opportunistic. The challenge is then to find ways to incorporate EUSE activities into the existing workflow without users having to make substantial changes to the type of work they do or their priorities. In this article we set out an approach to EUSE for web-based applications. We also propose a software lifecycle that is consistent with the conditions and priorities of end users without programming skills and is well-aligned with EUSE's characteristic informality ambiguity and opportunisticness. Users applying this lifecycle manage to find solutions that they would otherwise be unable to identify. They also develop quality products. Users of this approach will not have to be acquainted with software engineering as a framework will take them through the web-centred EUSE lifecycle step-by-step. We also report a statistical experiment in which users develop web software with and without a framework to guide them through the lifecycle. Its aim is to validate the applicability of our framework-driven lifecycle.;
General theories of software engineering (GTSE): key criteria and an example: GTSE 2015 keynote address summary;An essential consideration for a candidate General Theory of Software Engineering (GTSE) is the criteria by which it should be evaluated. This summary will include a proposed set of criteria and their rationale an overview of an existing GTSE (Theory W: stakeholder win-win) that will be presented in the keynote address and a summary of its ability to satisfy the criteria.;
Proceedings of the Fourth SEMAT Workshop on General Theory of Software Engineering;In this paper we present the results from two surveys related to data science applied to software engineering. The first survey solicited questions that software engineers would like data scientists to investigate about software about software processes and practices and about software engineers. Our analyses resulted in a list of 145 questions grouped into 12 categories. The second survey asked a different pool of software engineers to rate these 145 questions and identify the most important ones to work on first. Respondents favored questions that focus on how customers typically use their applications. We also saw opposition to questions that assess the performance of individual employees or compare them with one another. Our categorization and catalog of 145 questions can help researchers practitioners and educators to more easily focus their efforts on topics that are important to the software industry.;
Proceedings of the 36th International Conference on Software Engineering;Research into how humans interact with computers has a long and rich history. Only a small fraction of this research has considered how humans interact with computers when engineering software. A similarly small amount of research has considered how humans interact with humans when engineering software. For the last forty years we have largely taken an artifact-centric approach to software engineering research. To meet the challenges of building future software systems I argue that we need to balance the artifact-centric approach with a human-centric approach in which the focus is on amplifying the human intelligence required to build great software systems. A human-centric approach involves performing empirical studies to understand how software engineers work with software and with each other developing new methods for both decomposing and composing models of software to to ease the cognitive load placed on engineers and on creating computationally intelligent tools aimed at focusing the humans on the tasks only the humans can solve.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;Context: Previous work that used prediction models on Software Engineering included few social metrics as predictors even though many researchers argue that Software Engineering is a social activity. Even when social metrics were considered they were classified as part of other dimensions such as process history or change. Moreover few papers report the individual effects of social metrics. Thus it is not clear yet which social metrics are used in prediction models and what are the results of their use in different contexts. Objective: To identify characterize and classify social metrics included in prediction models reported in the literature. Method: We conducted a mapping study (MS) using a snowballing citation analysis. We built an initial seed list adapting strings of two previous systematic reviews on software prediction models. After that we conducted backward and forward citation analysis using the initial seed list. Finally we visited the profile of each distinct author identified in the previous steps and contacted each author that published more than 2 papers to ask for additional candidate studies. Results: We identified 48 primary studies and 51 social metrics. We organized the metrics into nine categories which were divided into three groups - communication project and commit-related. We also mapped the applications of each group of metrics indicating their positive or negative effects. Conclusions: This mapping may support researchers and practitioners to build their prediction models considering more social metrics.;
Proceedings of the 10th International Conference on Predictive Models in Software Engineering;Over the last several years software engineering (SE) has given birth to several communities and venues related to research on SE in the context of health care systems. By and large the interest in this topic has been spurred by alarming failures of software-intensive systems that have been deployed to address some of the challenges faced in current health care environments. Today the software engineering in health care (SEHC) community faces several challenges. It needs to justify the significance of its existence towards the general SE community and towards the medical/health informatics community. The purpose of this paper is to explore some of the fundamental challenges pertaining to SEHC to consider whether these challenges require a dedicated community-based effort and to generate recommendations on how to strengthen its impact. We argue that the community should adopt a conceptual model of knowledge translation (KT) analogous those used in the medical domain to position its research and maximize its impact.;
Proceedings of the 5th International Workshop on Software Engineering in Health Care;This paper reports the experiences and lessons learned of teaching a global course on software engineering to students in Africa and United States. The paper describes the course content distributed software development project the global teaching environment assessment criteria and results. Following the summary of the experiences and lessons learned from teaching the global course we also discuss how to improve the teaching effectiveness of future global courses.;
Proceedings of the Second International Workshop on Collaborative Teaching of Globally Distributed Software Development;Background/Context: The objective of achieving higher sustainability in our lifestyles by information and communication technology has lead to a plethora of research activities in related fields. Consequently Software Engineering for Sustainability (SE4S) has developed as an active area of research. Objective/Aim: Though SE4S gained much attention over the past few years and has resulted in a number of contributions there is only one rigorous survey of the field. We follow up on this systematic mapping study from 2012 with a more in-depth overview of the status of research as most work has been conducted in the last 4 years. Method: The applied method is a systematic mapping study through which we investigate which contributions were made which knowledge areas are most explored and which research type facets have been used to distill a common understanding of the state-of-the-art in SE4S. Results: We contribute an overview of current research topics and trends and their distribution according to the research type facet and the application domains. Furthermore we aggregate the topics into clusters and list proposed and used methods frameworks and tools. Conclusion: The research map shows that impact currently is limited to few knowledge areas and there is need for a future roadmap to fill the gaps.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;Both employers and graduate schools expect computer science graduates to be able to work as developers on software projects. Software engineering courses present the opportunity in the curriculum to learn the relevant skills. This paper presents our experience from Wayne State University and reviews challenges and constraints that we faced while trying to teach these skills. In our first software engineering course we teach the iterative software development that includes practices of software change summarized in the phased model of software change. The required resources for our software engineering course are comparable to the other computer science courses. The students - while working in teams - are graded based on their individual contribution to the team effort rather than on the work of the other team members which improves the fairness of the grading and considerably lessens the stress for the best students in the course. Our students have expressed a high level of satisfaction and in a survey they indicated that the skills that they learned in the course are highly applicable to their careers.;
Proceedings of the 2013 International Conference on Software Engineering;Systems-of-Systems (SoS) refer to a new class of software-intensive systems where their constituent systems work cooperatively in order to fulfill specific missions. Characterized by managerial and operational independence geographic distribution evolutionary development and emergent behavior SoS bring substantial challenges to the software engineering area. SESoS 2015 held in Florence Italy on May 17 2015 as a joint workshop of the 37th International Conference on Software Engineering (ICSE) provided a forum to exchange ideas and experiences analyze current research and development issues discuss promising solutions and to explore inspiring visions for the future of Software Engineering (SE) for SoS.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;In recent years there has been significant interest in general theories of software engineering. In this article we explore the utility of a theory of cognition ACT-R as a component of such a general theory. The ACT-R theory was instantiated to predict the effort of programming language comprehension for two cases: (i) a C program and (ii) the corresponding Assembly program. An experiment was then conducted to generate empirical data on the two comprehension tasks. The theoretical predictions were compared to the empirical results.The theoretical model predicted that the effort of understanding the considered program in C is 37% of the effort of understanding a comparable program written in Assembly. The experiment generated 33% as the corresponding percentage number. The concordance between theoretical model and experimental data was surprisingly high encouraging further investigations into the utility of cognitive theories in software engineering.;
Proceedings of the Fourth SEMAT Workshop on General Theory of Software Engineering;Providing undergraduate and postgraduate Computer Science students with valuable practical real-life experiences during Software Engineering courses is considered a necessity. These experiences should integrate theoretical knowledge with practical skills in order to enhance employability skills and prepare students for the industry. A common practice in order to achieve this goal is having students work in groups in Software Engineering Capstone projects. Despite the numerous benefits however capstone projects impose a number of challenges for educators. One of them is the fair assessment of students within a group. This paper presents an assessment scheme that takes into consideration both the individual effort that a student places in a groupwork capstone project as well as the value of the effort as perceived by teammates via peer assessment. The assessment scheme and the utilized peer assessment form are validated through questionnaires. Students' perceptions concerning their experiences in past projects as well as their opinions about the specific assessment scheme are gathered and analyzed. The results are encouraging and provide an indication that the proposed assessment method which integrates peer assessment promotes a more fair assessment for Software Engineering Capstone projects.;
Proceedings of the 6th Balkan Conference in Informatics;Context: In organizational psychology literature Task Variety and Skill Variety are considered different aspects of work design. Albeit related to different aspects of the work it is common to find strong correlations between these constructs. After applying the Work Design Questionnaire (WDQ) on a sample of 102 software professional we found the similar correlations and conjectured that they were partly due to a misunderstanding about what a task is what a skill is and what could be considered a variety of those concepts in the practice of software development. Goal: Our goal in this study was to investigate the actual existence and the possible sources of such misunderstanding. Method: We performed semi-structured interviews with software professionals that had previously participated in the application of the WDQ and analyzed the results using qualitative research techniques. We selected four software professionals among those with higher experience in software development. Results: Qualitative data revealed insights regarding the reasons why the correlation identified in the quantitative results could have arisen in our sample. Conclusions: Our findings pointed out that the misunderstanding of such concepts might affect the results of the application of quantitative questionnaires that measure these constructs.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;There is a growing need for scalable search-based software engineering approaches that address software engineering problems where a large number of objectives are to be optimized. Software refactoring is one of these problems where a refactoring sequence is sought that optimizes several software metrics. Most of the existing refactoring work uses a large set of quality metrics to evaluate the software design after applying refactoring operations but current search-based software engineering approaches are limited to using a maximum of five metrics. We propose for the first time a scalable search-based software engineering approach based on a newly proposed evolutionary optimization method NSGA-III where there are 15 different objectives to be optimized. In our approach automated refactoring solutions are evaluated using a set of 15 distinct quality metrics. We evaluated this approach on seven large open source systems and found that on average more than 92% of code smells were corrected. Statistical analysis of our experiments over 31 runs shows that NSGA-III performed significantly better than two other many-objective techniques (IBEA and MOEA/D) a multi-objective algorithm (NSGA-II) and two mono-objective approaches hence demonstrating that our NSGA-III approach represents the new state of the art in fully-automated refactoring.;
Proceedings of the 2014 Annual Conference on Genetic and Evolutionary Computation;The new coronavirus pandemic promoted structural changes in society due to the need to elevate social isolation to the extreme. In this context the majority of educational institutions have chosen to continue their activities remotely. One of the strategies used to engage students with academic activities is the use of gamification. Due to the new scenario driven by the pandemic this study aims to present and evaluate the application of gamification by comparing its use in the remote and in-person contexts as well as the necessary adaptations for the new scenario. The comparison took place between two Software Engineering classes one being in-person and the other in remote format. As initial results a positive evaluation related to the application of the game was achieved greater than 80% for the two teaching formats.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;This paper describes issues in developing mobile device applications and using smart phone applications as projects in a software engineering course. It also describes the experiences of the students in developing such a project.;
Toward sustainable software engineering (NIER track);Current software engineering practices have significant effects on the environment. Examples include e-waste from computers made obsolete due to software upgrades and changes in the power demands of new versions of software. Sustainable software engineering aims to create reliable long-lasting software that meets the needs of users while reducing environmental impacts. We conducted three related research efforts to explore this area. First we investigated the extent to which users thought about the environmental impact of their software usage. Second we created a tool called GreenTracker which measures the energy consumption of software in order to raise awareness about the environmental impact of software usage. Finally we explored the indirect environmental effects of software in order to understand how software affects sustainability beyond its own power consumption. The relationship between environmental sustainability and software engineering is complex understanding both direct and indirect effects is critical to helping humans live more sustainably.;
Proceedings of the 33rd International Conference on Software Engineering;"The use of formal methods in software engineering has been advocated for a long time by a lot of people. Unfortunately advocates of formal methods remain a distinct minority among software engineering educators as well as industrial practitioners. A number of reasons have been cited for the lack of acceptance of formal methods. Popular among these reasons is that formal methods lack relevance and utility to the everyday work of software engineers.This paper presents a tool intended to increase the practical value of formal methods for software engineering students. The tool called Spest'' generates unit testing code from a formal program specification. There have been other such tools developed in the past but all have been difficult for us to use in our educational setting. With Spest we hope to overcome some of the difficulties with a tool that is easy to use and which generates readable and extendible testing code. Initial results of using Spest in our classes are promising and we are planning continued development.""";
Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education;We began implementing contest-based learning with a blend of software engineering and business management 10 years ago. At first a project subject was assigned. However several problems occurred: For example the students became absorbed in programming rather than design and analysis activities. Therefore the curriculum changed from project subjects to contest-based learning. Business management marketing and accounting subjects were added to the new curriculum and students made information technology (IT) business plans using their knowledge of software engineering and business management. The IT business plans were submitted to various contests held by public newspaper companies and the federation of economic organizations in Japan. As a result in the 10 years of the contest-based learning implementation 20 teams have received awards in various IT business plan contests. We investigated 10 persons who had experience submitting business plans. We confirmed that contest-based learning had clearer goals such as to win the contest prize compared to project-based learning. Further the abilities to solve problems and to investigate increased more in comparison with lecture-style and project-style education.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Software is created for and with a wide range of stakeholders from customers to management from value-added providers to customer service personnel. These stakeholders work with teams of software engineers to develop and evolve software systems that support their activities. All of these people and their interactions are central to software development. Thus it is crucial to investigate the dynamic and frequently changing Cooperative and Human Aspects of Software Engineering (CHASE) both before and after deployment in order to understand current software practices processes and tools. In turn this enables us to design tools and support mechanisms that improve software creation software maintenance and customer communication.Researchers and practitioners have long recognized the need to investigate these aspects however their articles are scattered across conferences and communities. This workshop will provide a unified forum for discussing high quality research studies models methods and tools for human and cooperative aspects of software engineering. This will be the 8th in a series of workshops which continue to be a meeting place for the academic industrial and practitioner communities interested in this area and will give opportunities to present and discuss works-in-progress.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;"The social network perspective has served as a useful framework for studying scientific research collaboration in different disciplines. Although collaboration in computer science research has received some attention software engineering research collaboration has remained unexplored to a large extent. In this paper we examine the collaboration networks based on co-authorship information of papers from ten software engineering publication venues over the 1976-2010 time period. We compare time variations of certain parameters of these networks with corresponding parameters of collaboration networks from other disciplines. We also explore whether software engineering collaboration networks manifest symptoms of the small-world phenomenon conform to the criteria of social networks"" and manifest increasing collaboration with time. In the light of these observations we highlight some general characteristics of collaboration in software engineering research. The results presented in this paper facilitate understanding of the progression of software engineering from its infancy to maturity and lay the foundation for developing theoretical models to explain the evolution of its research collaboration characteristics.""";
Proceedings of the 5th India Software Engineering Conference;Software engineering meta-data (SE data) such as revision control data Github project data or test reports is typically semi-structured it comprises a mixture of formatted and free-text fields and is often self-describing. Semi-structured SE data cannot be queried in a SQL-like manner because of its lack of structure. Consequently there are a variety of customized tools built to analyze specific datasets but these do not generalize. We propose to develop a generic framework for exploration and querying of semi-structured SE data. Our approach investigates the use of a formal concept lattice as a universal data structure and a tag cloud as an intuitive interface to support data exploration.;
Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering;Methodology implementation failure is attributed to developer mediocrity (by management) â€“ not to organizational mediocrity (rigidity or control-driven process-driven management) or to a lack of adaptation capability in the methodology. In supporting software construction as a creative process however we must promote excellence rather than conformity. We argue that we â€“ through principled research -- must pay attention to the interplay between methodology and culture â€“ the local adaptations needed to make things work understand how the two co-evolve and how they may contribute together to software quality.;
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering;Technology can be regarded as scientific knowledge embodied in products or services. Particularly in the software domain it has been recognized as a source of competitive advantage of corporations industries and nations. Cooperative technology development and transfer happen in academic environments but there is a wider context in which they can be performed. In this paper we define patterns and report examples of cooperative technological activities that reflect best development and transfer practices of persons and institutions taking advantage of our expertise in fostering the software industry in Brazil. We argue that such activities can benefit from the adoption of software patterns determining what we regard as a Software-Engineering-In-The-Large approach to this subject. We show that our patterns are compositional capture specific dialects languages and theories suggesting that they can be formalized in future works.;
Proceedings of the Second International Workshop on Software Engineering Research and Industrial Practice;Many software engineering problems are multi-objective in nature which has been largely recognized by the Search-based Software Engineering (SBSE) community. In this regard Pareto-based search algorithms e.g. Non-dominated Sorting Genetic Algorithm II have already shown good performance for solving multi-objective optimization problems. These algorithms produce Pareto fronts where each Pareto front consists of a set of non-dominated solutions. Eventually a user selects one or more of the solutions from a Pareto front for their specific problems. A key challenge of applying Pareto-based search algorithms is to select appropriate quality indicators e.g. hypervolume to assess the quality of Pareto fronts. Based on the results of an extended literature review we found that the current literature and practice in SBSE lacks a practical guide for selecting quality indicators despite a large number of published SBSE works. In this direction the paper presents a practical guide for the SBSE community to select quality indicators for assessing Pareto-based search algorithms in different software engineering contexts. The practical guide is derived from the following complementary theoretical and empirical methods: 1) key theoretical foundations of quality indicators 2) evidence from an extended literature review and 3) evidence collected from an extensive experiment that was conducted to evaluate eight quality indicators from four different categories with six Pareto-based search algorithms using three real industrial problems from two diverse domains.;
Proceedings of the 38th International Conference on Software Engineering;"Studio-based teaching is a method commonly used in arts and design that emphasizes a physical home"" for students problem-based and peer-based learning and mentoring by academic staff rather than formal lectures. There have been some attempts to transfer studio-based teaching to software engineering education. In many ways this is natural as software engineering has significant practical elements. However attempts at software studios have usually ignored experiences and theory from arts and design studio teaching. There is therefore a lack of understanding of what ""studio"" really means how well the concepts transfer to software engineering and how effective studios are in practice. Without a clear definition of ""studio"" software studios cannot be properly evaluated for their impact on student learning nor can best and worst practices be shared between those who run studios. In this paper we address this problem head-on by conducting a qualitative analysis of what ""studio"" really means in both arts and design. We carried out 15 interviews with a range of people with studio experiences and present an analysis and model for evaluation here. Our results suggest that there are many intertwined aspects that define studio education but it is primarily the people and the culture that make a studio. Digital technology on the other hand can have an adverse effect on studios unless properly recognised.""";
Proceedings of the 2013 International Conference on Software Engineering;In a 1998 note [1] I described a new study program leading to the Bachelor's Degree in Software Engineering. I now report on a new Master's level program in Software Engineering evolving from the Bachelor's Degree program and beginning in the fall semester of this year. I discuss some of the events of our 14 year old Bachelor's program and the structuring of our Master's program.;
An intensive software engineering learning experience;We describe how we presented a year-long Software Engineering (SE) module. The first part of the module entailed a process we call rocking the boat. Our objective was to create an opportunity for our students to experience a complete software engineering project (from specification to delivery) within six weeks. During the second part students worked in self-selected teams on an industry-based SE project. Again they were required to undergo the complete SE lifecycle.We firstly describe the design of our module. We then describe how we gathered and analysed information on how the students behaved in their teams as well as about what they experienced while participating in the module. Finally we discuss our observations. We conclude with remarks about the potential success and possible improvement of our teaching strategies and future research directions.;
Proceedings of Second Computer Science Education Research Conference;Cyber-physical system (CPS) have been recognized as a top-priority in research and development. The innovations sought for CPS demand them to deal effectively with dynamicity of their environment to be scalable adaptive tolerant to threats etc. -- i.e. they have to be smart. Although approaches in software engineering (SE) exist that individually meet these demands their synergy to address the challenges of smart CPS (sCPS) in a holistic manner remains an open challenge. The workshop focuses on software engineering challenges for sCPS. The goals are to increase the understanding of problems of SE for sCPS study foundational principles for engineering sCPS and identify promising SE solutions for sCPS. Based on these goals the workshop aims to formulate a research agenda for SE of sCPS.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Information technology and computer science educators are experiencing an industry-driven change from plan-based software engineering development processes to more people-oriented Agile software engineering approaches. While plan-based software engineering practices have traditionally been taught in lectures Agile practices can often be best learned by experiencing them in a realistic situation. One approach for bringing Agile practices to the learning community is a coding dojo where a group of participants solve a programming task together using test-driven development and pair programming. Coding dojo is a form of learning which values concrete experience in a realistic context. In our experiment we embedded a coding dojo into the Agile practices part of our undergraduate software engineering course. The participating students considered the coding dojo a useful experience and most of them (82%) would recommend participation in coding dojos for their fellow students as well.;
Proceedings of the 14th Annual ACM SIGITE Conference on Information Technology Education;There is increasing impetus towards 'Industry 4.0' a recently proposed roadmap for process automation across a broad spectrum of manufacturing industries. The proposed approach uses Evolutionary Computation to optimise real-world metrics. Features of the proposed approach are that it is generic (i.e. applicable across multiple problem domains) and decentralised i.e. hosted remotely from the physical system upon which it operates. In particular by virtue of being serverless the project goal is that computation can be performed 'just in time' in a scalable fashion. We describe a case study for value-based optimisation applicable to a wide range of manufacturing processes. In particular value is expressed in terms of Overall Equipment Effectiveness (OEE) grounded in monetary units. We propose a novel online stopping condition that takes into account the predicted utility of further computational effort. We apply this method to scheduling problems in the (max +) algebra and compare against a baseline stopping criterion with no prediction mechanism. Near optimal profit is obtained by the proposed approach across multiple problem instances.;
Proceedings of the Genetic and Evolutionary Computation Conference;Reliance on skilled developers reduces the return on investment for important software engineering tasks such as establishing program correctness. This position paper introduces adaptive semi-automated (ASA) tools as a means to enable less-skilled workers to perform aspects of software engineering tasks. In an ASA tool a task is decomposed and the computationally difficult subtasks are performed by less-skilled workers using an adaptive user interface reducing or eliminating the skilled developer's effort.We describe strategies for decomposing a software engineering task and propose design principles to maximize the cost effectiveness of ASA tools in the presence of imperfect decomposition. Though the approach can be applied to many different types of tasks this paper focuses on and provides examples for the software correctness tasks of test generation program verification and program synthesis. Additionally we address the auxiliary challenges of latency intellectual property risk and worker error.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;While many technologies for gesture-based interaction have been proposed and implemented few focus on core software engineering principles that are commonplace in traditional programming languages. The lack of such principles restricts the applicability of those technologies when developing large scale gesture enabled systems. This paper describes the software engineering challenges associated with developing multi-touch gesture-based interaction and proposes a solution in the form of the Midas declarative gesture specification language. Midas embeds concepts of logical programming languages and complex event processing to ease the development of gesture based applications. We show how it can be applied to multi-touch gesture recognition and evaluated our solution in real-world applications.;
Proceedings of the 2nd Workshop on Programming for Mobile &amp Touch;Lego Serious Play (LSP) is an experiential and highly creative process that has been designed to facilitate strategic planning team building and problem solving by using specialized sets of Lego bricks. In the LSP methodology team members use their intelligence both as individuals and as a group to build simple models representing various concepts in response to a question posed by the faculty facilitator. Discussing the models helps students communicate valuable aspects of their own understanding and interpretation of the problem at hand explore the team dynamics and reduce the complexity of many projects.;
Towards an E-assessment tool for advanced software engineering skills;E-assessment enjoys growing attention in university courses and is increasingly applied. Although automated feedback and grading for creative question types is a complex endeavor more and more tools are developed to support e-assessment for miscellaneous question types. This paper focuses on an automated assessment of UML class diagrams. While there are already tools which support the analysis of student solutions for UML class diagrams they only provide feedback on a low level. This paper motivates a need for assessing advanced computer science skills. For this an analysis of student exams is conducted focusing on exams which instruct the student to choose an appropriate design pattern for a given use case. Further a prototype is presented which allows for an identification of design patterns as a first step of a UML assessment tool. For this purpose an algorithm for error-tolerant subgraph isomorphisms is adopted and extended which deals with multiple design patterns at the same time in order to match them to the students' solutions. Since it is possible to model design patterns in different sizes a pattern template notation is presented which enables to specify the possible variants of each design pattern. A new algorithm then translates the pattern templates to be understood by the adopted matching algorithm. Finally the identification process is evaluated empirically showing the merits and the limitations of this approach.;
Proceedings of the 16th Koli Calling International Conference on Computing Education Research;Software Ecosystem (SECO) comprises third-party developers cooperating and competing when contributing to a platform provided by a central organization (keystone). A keystone has invested in a Developer Relations (DevRel) internal team as a global business strategy to attract and engage a critical mass of third-party developers in producing and evolving contributions. For this reason the DevRel team should promote social relationships among SECO actors and synergy among keystone' goals and developers' expectations. It can help to establish and sustain a competitive value creation network (VCN) within a SECO that must survive to inherit changes. However it is still a challenge the way DevRel team can act on a SECO to better engage the developers' communities aiming to establish a robust VCN. In this paper we advance on investigating the perceptions of 31 DevRel practitioners from large medium and small-size companies based on seven countries about value creation in DevRel. We found 55 elements of value creation distributed in retention efficiency innovation and complementarity. Based on our analysis we contribute with a set of seven insights (feedback loop loyalty program roadmap enhancement technical training processes restructuring innovative products cost reducing) and a DevRel VCN that involves elements suppliers and consumers. It fosters a common perspective for DevRel practitioners keystones and researchers for designing strategies and a research roadmap.;
Proceedings of the 15th International Conference on Global Software Engineering;We describe an experience in teaching global software engineering (GSE) using distributed Scrum augmented with industrial best practices. Our unique instructional technique had students work in both same-site and cross-site teams to contrast the two modes of working. The course was a collaboration between Aalto University Finland and University of Victoria Canada. Fifteen Canadian and eight Finnish students worked on a single large project divided into four teams working on interdependent user stories as negotiated with the industrial product owner located in Finland. Half way through the course we changed the teams so each student worked in both a local and a distributed team. We studied student learning using a mixed-method approach including 14 post-course interviews pre-course and Sprint questionnaires observations meeting recordings and repository data from git and Flowdock the primary communication tool. Our results show no significant differences between working in distributed vs. non-distributed teams suggesting that Scrum helps alleviate many GSE problems. Our post-course interviews and survey data allows us to explain this effect we found that students over time learned to better self-select tasks with less inter-team dependencies to communicate more and to work better in teams.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;There has been a recent surge in interest in the application of Artificial Intelligence (AI) techniques to Software Engineering (SE) problems. The work is typified by recent advances in Search Based Software Engineering but also by long established work in Probabilistic reasoning and machine learning for Software Engineering. This paper explores some of the relationships between these strands of closely related work arguing that they have much in common and sets out some future challenges in the area of AI for SE.;
Proceedings of the First International Workshop on Realizing AI Synergies in Software Engineering;The tourist slogan used to market South AfricaA World in One Countrycuts across many more dimensions than just those of interest to tourists. Everywhere in the country there is evidence of both a highly advanced and sophisticated economy and lifestyle as well as of poverty and underdevelopment. The purpose of this session is to reflect on whether and how this peculiar positioning of the country impacts on the IT industry in general and on software engineering in particular.Based on their experience of South African IT in general and on the practice teaching and research of software engineering in particular session panelists will give their perspectives on what is being done and on what should be done. Are the challenges and opportunities significantly different from elsewhere? Are there the opportunities threats and challenges for disseminating IT skills into the underdeveloped contexts in South Africa and Africa? What does South Africa need to do to become the outsourcing point of choice for North Atlantic IT? How do companies that operate both in South Africa and elsewhere spread the development load and what are the challenges in doing this?;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2;Trust is one of the key factors that determines success or failure of any software project. However achieving and maintaining trust in distributed software projects when team members are geographically temporally and culturally distant from each other is a remarkable challenge. This paper explores the dynamics of trust and best practices performed in software organizations to address trust-related issues in global software engineering. Semi-structured interviews were conducted in six different distributed software development organizations and a resulting trust dynamics model is presented. Based on the findings the paper also provides suggestions for the industry to achieve trust in distributed collaborations.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;The discipline of Software Engineering is continuously adapting to new challenges while gaining more and more insights. The age of globalisation has brought about a new movement of internationalisation and localisation. While practitioners fully embrace the efforts educators only marginally consider the implications for the teaching and learning of Software Engineering. While the relevance of the software deployment context has been widely recognised the intrinsic values of the development context are less evident. Besides western cultural indicators being omnipresent in software applications they are deeply rooted in Software Engineering concepts and methods. Standards and models have been established in the absence of possible deviations from other -- e.g. African -- contexts. Educators and authors of common and internationally used textbooks present Software Engineering concepts and methods as universally valid. Thus software engineering graduates all over the world continue to be ill-equipped for specific software development contexts.Moreover the necessity to localise Software Engineering education is illustrated by our vast amount of challenges experiences and best-practices of teaching Software Engineering in a Sub-Saharan country. In this paper we introduce a generic framework leading towards a Contextualised Software Engineering education (CSE2).;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1;Background: Volvo Cars is pioneering an agile transformation on a large scale in the automotive industry. Social psychological aspects of automotive software development are an under-researched area in general. Few studies on team maturity or group dynamics can be found specifically in the automotive software engineering domain.Objective: This study is intended as an initial step to fill that gap by investigating the connection between issues and problem reports and team maturity.Method: We conducted a quantitative study with 84 participants from 14 teams and qualitatively validated the result with the Release Train Engineer having an overview of all the participating teams.Results: We find that the more mature a team is the faster they seem to resolve issues as provided through external feedback at least in the two initial team maturity stages.Conclusion: This study suggests that working on team dynamics might increase productivity in modern automotive software development departments but this needs further investigation.;
Proceedings of the 15th International Conference on Cooperative and Human Aspects of Software Engineering;Health informatics is a field in which the disciplines of software engineering and machine learning necessarily co-exist. This discussion paper considers the interaction of software engineering and machine learning set within the context of health informatics where the scale of clinical practice requires new engineering approaches from both disciplines. We introduce applications implemented in large on-going research programmes undertaken between the Departments of Engineering Science and Computer Science at Oxford University the Oxford University Hospitals NHS Trust and the Guy's and St Thomas' NHS Foundation Trust London.;
Proceedings of the First International Workshop on Realizing AI Synergies in Software Engineering;Too often software engineering (SE) tool research is focused on creating small stand-alone tools that address rarely understood developer needs. We believe that research should instead provide developers with flexible environments and interoperable tools and then study how developers appropriate and tailor these tools in practice. Although there has been some prior work on this we feel that flexible tool environments for SE have not yet been fully explored. In particular we propose adopting the Web 2.0 idea of mashups and mashup environments to support SE practitioners in analytic activities involving multiple information sources.;
Proceedings of the 1st Workshop on Web 2.0 for Software Engineering;Synthesizing the evidence from a set of studies that spans many countries and years and that incorporates a wide variety of research methods and theoretical perspectives is probably the single most challenging task of performing a systematic review. In this paper we perform a tertiary review to assess the types and methods of research synthesis in systematic reviews in software engineering. Almost half of the 31 studies included in our review did not contain any synthesis of the ones that did two thirds performed a narrative or a thematic synthesis. The results show that despite the focus on systematic reviews there is currently limited attention to research synthesis in software engineering. This needs to change and a repertoire of synthesis methods needs to be an integral part of systematic reviews to increase their significance and utility for research and practice.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;Context. A recent mapping study intended to verify the current state of replication of empirical studies in Software Engineering (SE) identified two sets of studies: the empirical studies reporting actually replications and a second group of studies that were concerned with concepts classifications guidelines and other themes about replication. Objective. The purpose of this research is to analyze and discuss the content of the second set of studies about replications published between 1996 and 2013. Method. This is a mapping study in which the primary studies were collected by two previous mapping studies covering the period 1996-2012 complemented by a non-systematic search that collected some articles published in 2013. Results. We analyzed 36 papers reporting empirical and non-empirical studies about replications in SE published in the last 17 years. These papers explored different topics related to concepts and classifications presented guidelines and discussed theoretical issues that are relevant for our understanding of replication in our field.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;Context. Many reports support the fact that some psycho--social aspects of software engineers are key factors for the quality of the software development process and its resulting products. Based on the experience of some of the authors after more than a year of practising mindfulness---a meditation technique aimed to increase clearness of mind and awareness---we guessed that it could be interesting to empirically evaluate whether mindfulness affects positively not only the behaviour but also the professional performance of software engineers.Goal. In this paper we present a quasi--experiment carried out at the University of Seville to evaluate whether Software Engineering &amp Information Systems students enhance their conceptual modelling skills after the continued daily practice of mindfulness during four weeks.Method. Students were divided into two groups: one group practised mindfulness and the other---the control group---were trained in public speaking. In order to study the possible cause--and--effect relationship effectiveness (the rate of model elements correctly identified) and efficiency (the number of model elements correctly identified per unit of time) of the students developing conceptual modelling exercises were measured before and after taking the mindfulness and public speaking sessions.Results. The experiment results have revealed that the students who practised mindfulness have become more efficient in developing conceptual models than those who attended the public speaking sessions. With respect to effectiveness some enhancement have been observed although not as significant as in the case of efficiency.Conclusions. This rising trend in effectiveness suggests that the number of sessions could have been insufficient and that a longer period of sessions could have also enhanced effectiveness significantly.;
Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;In recent years computer games have become increasingly social and collaborative in nature. Massively multiplayer online games in which a large number of players collaborate with each other to achieve common goals in the game have become extremely pervasive. By working together towards a common goal players become more engrossed in the game. In everyday work environments this sort of engagement would be beneficial and is often sought out. We propose an approach to software engineering called HALO that builds upon the properties found in popular games by turning work into a game environment. Our proposed approach can be viewed as a model for a family of prospective games that would support the software development process. Utilizing operant conditioning and flow theory we create an immersive software development environment conducive to increased productivity. We describe the mechanics of HALO and how it could fit into typical software engineering processes.;
Proceedings of the 1st International Workshop on Games and Software Engineering;There are more than twenty distinct software engineering tasks addressed with text retrieval (TR) techniques such as traceability link recovery feature location refactoring reuse etc. A common issue with all TR applications is that the results of the retrieval depend largely on the quality of the query. When a query performs poorly it has to be reformulated and this is a difficult task for someone who had trouble writing a good query in the first place.  We propose a recommender (called Refoqus) based on machine learning which is trained with a sample of queries and relevant results. Then for a given query it automatically recommends a reformulation strategy that should improve its performance based on the properties of the query. We evaluated Refoqus empirically against four baseline approaches that are used in natural language document retrieval. The data used for the evaluation corresponds to changes from five open source systems in Java and C++ and it is used in the context of TR-based concept location in source code. Refoqus outperformed the baselines and its recommendations lead to query performance improvement or preservation in 84% of the cases (in average).;
Proceedings of the 2013 International Conference on Software Engineering;Context: The low quality and small size of samples in empirical studies in software engineering hamper the interpretation and generalization of their results. Therefore enlarging sample sizes and improving their quality represent an important research challenge. Goal: We aim to define a conceptual framework including requirements for establishing adequate sources for sampling subjects in software engineering surveys. Method: We use previous experience on applying systematic sampling strategies combined with contemporary web technologies in previously executed surveys to organize the conceptual framework. We analyze its application to different sources of sampling. Results: The framework was observed to be feasible after its application to nine different large-scale sources of sampling. Conclusions: The analyzed crowdsourcing tools do not support essential requirements to be considered sources of sampling while free-lancing tools and professional social network do.;
Proceedings of the 8th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Social media has changed the way that people collaborate and share information. In this paper we highlight its impact for enabling new ways for software teams to form and work together. Individuals will self-organize within and across organizational boundaries. Grassroots software development communities will emerge centered around new technologies common processes and attractive target markets. Companies consisting of lone individuals will able to leverage social media to conceive of design develop and deploy successful and profitable product lines. A challenge for researchers who are interested in studying influencing and supporting this shift in software teaming is to make sure that their research methods protect the privacy and reputation of their stakeholders.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;In this paper we describe distributed Scrum augmented with best practices in global software engineering (GSE) as an important paradigm for teaching critical competencies in GSE. We report on a globally distributed project course between the University of Victoria Canada and Aalto University Finland. The project-driven course involved 16 students in Canada and 9 students in Finland divided into three cross-site Scrum teams working on a single large project. To assess learning of GSE competencies we employed a mixed-method approach including 13 post-course interviews pre- post-course and iteration questionnaires observations recordings of Daily Scrums as well as collection of project asynchronous communication data. Our analysis indicates that the Scrum method along with supporting collaboration practices and tools supports the learning of important GSE competencies such as distributed communication and teamwork building and maintaining trust using appropriate collaboration tools and inter-cultural collaboration.;
Proceedings of the 2013 International Conference on Software Engineering;Software engineering research can be done in many ways in particular it can be done in different ways when it comes to working with industry. This paper presents a list of top 10 challenges to work with industry based on our experience from working with industry in a very close collaboration with continuous exchange of knowledge and information. The top 10 list is based on a large number of research projects and empirical studies conducted with industrial research partners since 1983. It is concluded that close collaboration is a long-term undertaking and a large investment. The importance of addressing the top 10 challenges is stressed since they form the basis for a long-term sustainable and successful collaboration between industry and academia.;
Proceedings of the 1st International Workshop on Conducting Empirical Studies in Industry;Software Engineering is an important area within industry and academia. Empirical software engineering has grown in importance in the software engineering research and education community. This means that it has become very relevant to include empirical studies or practices into computer science and software engineering curricula. This paper shows the results of applying an empirical approach to teaching software engineering through real-life projects. The computer science capstone experience is designed to bridge the gap from university expectations to those of industry.;
Proceedings of the 45th ACM Technical Symposium on Computer Science Education;"An excerpt from Thomas Friedman's famous book The World Is Flat When developing countries start thinking about the challenge of flatism...It has to ask itself"" ""To what extent is my country advancing or being left behind by the flattening of the world and to what extent is it adapting to and taking advantage of all the new platforms for collaborations and competition?"" is vividly describing the appeal of many developing countries in entering the software industry. With the globalization of crafting software and its services the software industry is seen as a lucrative economic growth opportunity. Unlike other industrial investments the software industry is convenient to developing countries for its low-cost of establishment. All is needed is an affordable real estate rental a bunch of PCs and a few skilled workers to get the business running. The globalization of the software industry with attention given to accessing the right skills no matter where and reducing costs through cheap labor is even a realization to those countries ambitions to remedy part of their economic challenges. India preceded with utilizing such potential and made good use of such globalization or flatism of the software industry positioning itself as a successful model to those nations aspiring to compete globally and establish economic growth.Egypt is no exception from this ambition. Geographically positioned in proximity to Europe at the crossroads of Europe Africa and Asia and with access to abundant low wage talent pool of multilingual technical graduates annually are all factors that made it conceivable that Egypt can compete in the global industry of software. However such entrance into competition notably with India as well as other Middle Eastern countries have shaped trends in the practices of software engineering in Egypt as well as it did emerge several challenges that Egypt should learn to remedy if it wants to stay competitive in the global software industry. This paper attempts to shed light on salient current software engineering practices and related challenges that would be affecting Egypt's progress and competitive edge. In laying a foundation to such brief survey of practices this paper also overviews major cornerstones that gave rise to the establishment and support of such industry in Egypt.""";
Validity concerns in software engineering research;Empirical studies that use software repository artifacts have become popular in the last decade due to the ready availability of open source project archives. In this paper we survey empirical studies in the last three years of ICSE and FSE proceedings and categorize these studies in terms of open source projects vs. proprietary source projects and the diversity of subject programs used in these studies. Our survey has shown that almost half (49%) of recent empirical studies used solely open source projects. Existing studies either draw general conclusions from these results or explicitly disclaim any conclusions that can extend beyond specific subject software.We conclude that researchers in empirical software engineering must consider the external validity concerns that arise from using only several well-known open source software projects and that discussion of data source selection is an important discussion topic in software engineering research. Furthermore we propose a community research infrastructure for software repository benchmarks and sharing the empirical analysis results in order to address external validity concerns and to raise the bar for empirical software engineering research that analyzes software artifacts.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;"Global Software Development (GSD) continues to grow substantially and it is fast becoming the norm and fundamentally different from local Software Engineering development. Withal agile software development (ASD) has become an appealing choice for companies attempting to improve their performance although its methods were originally designed for small and individual teams. The current literature does not provide a cohesive picture of how the agile practices are taken into account in the distributed nature of software development: how to do it who and what works in practice. This study aims to highlight how ASD practices are applied in the context of GSD in order to develop a set of techniques that can be relevant in both research and practice. To answer the research question how are agile practices adopted in agile global software development teams?"" We conducted a systematic literature review of the ASD and GSD literature. A synthesis of solutions found in seventy-six studies provided 48 distinct practices that organizations can implement including ""collaboration among teams"" ""agile architecture"" ""coaching"" ""system demo"" and ""test automation"". These implementable practices go some way towards providing solutions to manage GSD teams and thus to embrace agility.""";
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;Engineering complex systems that have to meet critical requirements is a difficult task especially if multiple engineering disciplines are involved. Common practice in domains like the automotive or avionic industry shows that formal methods improve engineering process efficiency for embedded software due to abilities like abstraction early verification and iterative refinement. This paper presents how existing formal software engineering methods can be adapted to meet the needs of the smart grid domain. A case study demonstrates how we develop a basic interdisciplinary but semantically integrated decomposition of a household including electric and software behavior. Finally we provide first simulation results to evaluate the feasibility of the model as well as the presented engineering method.;
Proceedings of the First International Workshop on Software Engineering Challenges for the Smart Grid;Massive Open Online Courses (MOOCs) have recently gained high popularity among various universities and even in global societies. A critical factor for their success in teaching and learning effectiveness is assignment grading. Traditional ways of assignment grading are not scalable and do not give timely or interactive feedback to students. To address these issues we present an interactive-gaming-based teaching and learning platform called Pex4Fun. Pex4Fun is a browser-based teaching and learning environment targeting teachers and students for introductory to advanced programming or software engineering courses. At the core of the platform is an automated grading engine based on symbolic execution. In Pex4Fun teachers can create virtual classrooms customize existing courses and publish new learning material including learning games. Pex4Fun was released to the public in June 2010 and since then the number of attempts made by users to solve games has reached over one million. Our work on Pex4Fun illustrates that a sophisticated software engineering technique -- automated test generation -- can be successfully used to underpin automatic grading in an online programming system that can scale to hundreds of thousands of users.;
Proceedings of the 2013 International Conference on Software Engineering;Personas have attracted the interest of many in the usability and software engineering communities. To date however there has been little work illustrating how personas can be integrated into software tools to support these engineering activities. This paper presents four guidelines that software engineering tools should incorporate to support the design and evolution of personas. These guidelines are grounded in our experiences modifying the open-source CAIRIS Requirements Management tool to support design and development activities for the EU FP7 webinos project.;
Proceedings of the 5th ACM SIGCHI Symposium on Engineering Interactive Computing Systems;Context: In software project management the decision-making process is a complex set of tasks largely based on specific knowledge and individual cultural background as well as human relations. The factors that affect the decisions of the software project managers (SPMs) and their potential consequences require attention because project delays and failures are usually related to a series of poor decisions. Objective: To understand how SPMs make decisions based on how they interpret their experiences in the workplace and also to identify antecedents and consequences of those decisions in order to increase the effectiveness of project management. Method: Semi-structured interviews were carried out with SPMs within a Brazilian large private organization. The data was analyzed using techniques from grounded theory approach. Results: We found that decision-making in software project management is based on knowledge sharing in which the SPM acts as a facilitator before making decisions. This phenomenon is influenced by individual factors such as experience communication negotiation self-control and systemic view of the project and by contextual factors such as the autonomy of the SPM and team members' technical competence. Also these factors are mediated by cognitive biases. Conclusions: Due to the uncertainty and dynamism inherent in software projects the SPMs focus on making monitoring and adjusting decisions in an argument-driven way.;
Proceedings of the 9th International Workshop on Cooperative and Human Aspects of Software Engineering;Background: Organizations are constantly looking for performance improvements and office layout has been widely studied because of its hypothetical influences on the social dynamics of software engineering projects. Aim: In this article we investigate the perceived outcomes of different workspace characteristics from the perspective of software engineering professionals. Methods: To achieve that we conducted a survey with software engineering practitioners and collected data on the perceptions about their current workspaces and performance from 47 participants. We used the results of a previous systematic review to design the survey questionnaire and focused on the four human aspects known to be influenced by the office layout. Results: Different workspace settings exhibited similar perceptions in most of the investigated factors. However we reveal 14 items that responsible for significant differences in the performance outcomes such as communication quality collaboration team learning privacy and others. In general open spaces were the most effective office layout to enable all these factors. Conclusions: As a conclusion our study demonstrates that there is not a generally accepted best model for software development workspace design as all types of setting have positive and negative aspects. Organizations that are considering investing any budget in such things as radical workspace redesign should ponder the change very carefully. Also there is still much room for investigation in this topic.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;Quantum computing and to an even greater extent quantum technology is changing the world. Quantum computing is not an evolution of classical computer science it is actually a revolution that completely changes the computing paradigm. Quantum computers are based on the principles of quantum mechanics such as superposition and entanglement and they seek to boost computational power exponentially. Many problems that have until now been impossible to solve in practical terms might very well be able to be addressed by means of quantum computing. The fact is that at the present time quantum computing is influencing most business sectors and research fields due to its various promising applications. To make such applications become reality quantum algorithms must be specially coded for these extremely different computers. Although some well-known quantum algorithms already exist the need for quantum software will increase dramatically in the next years. In that context quantum software has to be produced in a more industrial and controlled way i.e. aspects such as quality delivery project management or evolution of quantum software must be addressed. We are sure that quantum computing will be the main driver for a new software engineering golden age during the present decade of the 2020s.;
Customer Satisfaction in Software Development Projects;In this study research is being conducted about the Customer's Satisfaction (CS) along with factors that have an impact on it and on the Software Project Management. The research method of this study is the Systematic Literature Review (SLR) and the main conclusion derived from this study is that the customer's active involvement through agile methods in all phases of the IT project development leads to a higher level of satisfaction.;
Proceedings of the 2021 European Symposium on Software Engineering;Background The labour intensive and error prone nature of the systematic review process has led to the development and use of a range of tools to provide automated support.Aim The aim of this research is to evaluate a set of candidate tools that provide support for the overall systematic review process.Method A feature analysis is performed to compare and evaluate four candidate tools.Results Each of the candidates has some strengths and some weaknesses. SLuRp has the highest overall score and SLRTOOL has the lowest overall score. SLuRp scores well on process management features such as support for multiple users and document management and less well on ease of installation.Conclusions Although the tools do not yet support the whole systematic review process they provide a good basis for further development. We suggest a community effort to establish a set of features that can inform future tool development.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;Software engineering (SE) careers are overwhelmingly devoted to maintenance and evolution of existing large software systems rather than building such systems from ground up. Code comprehension especially in the face of inadequate documentation and support is a key challenge in efficiently conducting these maintenance activities. Therefore SE courses in the computing curricula must adequately prepare the students to meet this challenge. We believe that Open Source Software (OSS) furnishes a useful source of realistic sizeable projects for inculcating the appreciation and skills useful for comprehension and maintenance. We evaluate and observe that an OSS-based SE course emphasizing maintenance and evolution expanded students' appreciation of the difficulty in comprehending existing code and designs especially when not well documented. We hope that this learned appreciation will encourage them to value and adopt a systematic disciplined approach in building and documenting software systems.;
Learning Soft Skills through Distributed Software Development;The software industry needs universities to train developers to have besides the technical skills also strong soft skills to collaborate in globally distributed software development projects. To develop these soft skills we organized a distributed online software development project course during which student Scrum teams of 5â€“8 members from five Belarusian universities worked in industrial projects for Danish customers. The course aimed to 1) teach students the Scrum framework and soft skills such as teamwork and communication with international customers and 2) to give Belarusian teachers ideas for organizing similar courses in the future. Based on 20 post-course semi-structured interviews with students and stakeholders and the analysis of 24 student learning diaries we studied the learning outcomes and challenges related to soft skills. The main reported learning outcomes were: communication methodical use of Scrum problem solving organizational/planning skills teamwork interpersonal skills and time management.;
Proceedings of the International Conference on Software and System Processes and International Conference on Global Software Engineering;This paper presents a survey of work on Search Based Software Engineering (SBSE) for Software Product Lines (SPLs). We have attempted to be comprehensive in the sense that we have sought to include all papers that apply computational search techniques to problems in software product line engineering. Having surveyed the recent explosion in SBSE for SPL research activity we highlight some directions for future work. We focus on suggestions for the development of recent advances in genetic improvement showing how these might be exploited by SPL researchers and practitioners: Genetic improvement may grow new products with new functional and non-functional features and graft these into SPLs. It may also merge and parameterise multiple branches to cope with SPL branchmania.;
Proceedings of the 18th International Software Product Line Conference - Volume 1;Described herein is a general-purpose software engineering architecture for autonomous computer controlled opponent implementation in modern maneuver warfare simulation and training. The implementation has been developed refined and tested in the user crucible for several years. The approach represents a hybrid application of various well-known AI techniques including domain modeling agent modeling and object-oriented programming. Inspired by computer chess approaches the methodology combines this theoretical foundation with a hybrid and scalable portfolio of additional techniques. The result remains simple enough to be maintainable and comprehensible for the code writers as well as the end-users and robust enough to handle a wide spectrum of possible mission scenarios and circumstances without modification.;
Proceedings of the 2016 Winter Simulation Conference;In this paper we summarize our perspective on teaching evidence-based software engineering (EBSE) to master students. In this semester we aimed to investigate this subject as a single lecture within a master course called Software Architecture instead of an entire semester-long course called EBSE. Each of the students delivered a systematic mapping study report related to the software architecture at the end of the semester and these project reports showed that this teaching approach is quite useful for master students even though this teaching activity is too short.;
Writing good software engineering research papers: revisited;"With the goal of helping software engineering researchers understand how to improve their papers Mary Shaw presented Writing Good Software Engineering Research Papers"" in 2003. Shaw analyzed the abstracts of the papers submitted to the 2002 International Conference of Software Engineering (ICSE) to determine trends in research question type contribution type and validation approach. We revisit Shaw's work to see how the software engineering research community has evolved since 2002. The goal of this paper is to aid software engineering researchers in understanding trends in research question design research question type and validation approach by analyzing the abstracts of the papers submitted to ICSE 2016. We implemented Shaw's recommendation for replicating her study through the use of multiple coders and the calculation of inter-rater reliability and demonstrate that her approach can be repeated. Our results indicate that reviewers have increased expectations that papers have solid evaluations of the research contribution. Additionally the 2016 results include at least 17% mining software repository (MSR) papers a category of papers not seen in 2002. The advent of MSR papers has increased the use of generalization/characterization research questions the production of empirical report contribution and validation by evaluation.""";
Proceedings of the 39th International Conference on Software Engineering Companion;Understanding the personality of software developers has been an ongoing topic in software engineering research. Software engineering researchers applied different theoretical models to understand software developers' personalities to better predict software developers' performance orchestrate more effective and motivated teams and identify the person that fits a certain job best. However empirical results were found as contradicting challenging validity and missing guidance for IT personnel selection. In this research we explore the current body of knowledge on software developers' personalities by conducting a structured literature review. We provide an overview of the applied psychological models research designs contexts and results. We discuss our findings and suggest promising avenues for further research on software engineering task characteristics and the impact of personality-task fit on software development performance.;
Proceedings of the 52nd ACM Conference on Computers and People Research;The importance of capstone senior design project courses is widely recognized for undergraduate software engineering curricula. They provide students with an opportunity to integrate and apply theoretical knowledge (both from previous courses and newly acquired for the project) on a team improving both their technical and soft-skills. Here we report our experiences using an agile development method for a game project this is a radical shift from our previous course offerings that were based on waterfall model driven development. This report is unique and valuable especially for software engineering education which goes beyond the discipline-specific limits of computer science curricula.;
Proceedings of the 1st International Workshop on Games and Software Engineering;Several companies around the world are using Distributed Software Development (DSD) to reduce costs and some Software Engineering courses are trying to simulate this distributed environment. This paper shows the experience faced by students during five years from the Software Engineering course performed at the Federal University of Pernambuco Brazil which the objective was adapting the best practices from traditional development for DSD. Course lectures and materials educate students about software engineering best practices and DSD. The students developed a project organized into a set of work assignments that could be distributed across groups. At the end they learned to communicate and collaborate with each other and they also believed that the course was helpful to them which justifies the low number of dropouts. Most of the students but not all successfully completed their projects.;
Proceedings of the Second International Workshop on Collaborative Teaching of Globally Distributed Software Development;"Single-Underlying-Model (SUM) based software engineering environments are founded on the principle of dynamically generating all required descriptions and visualizations of software systems on demand"" from a single underlying information source rather than by storing them decentrally as separately-persisted artifacts. It is possible to implement such environments using traditional two-level modeling tools but for them to achieve their full potential we believe they need to be built on a multi-level modeling infrastructure that can support (a) the definition of model content across arbitrary ontological classification levels (b) the addition of new domain-specific modeling features without the need to change the linguistic meta-model and (c) flexible support for various forms of content visualization and editing in a uniform coherent and interchangeable way. In this paper we present such a multi-level modeling infrastructure and describe its use in the construction of a prototype SUM-based software engineering environment called nAOMi.""";
Proceedings of the 1st Workshop on View-Based Aspect-Oriented and Orthographic Software Modelling;Collaboration has become an important teaching method in software engineering and there are several computer supported collaboration tools to aid the development and learning process. However most studies have concentrated on intra-group studies. We believe that computer supported collaborative learning tools can also aid software engineering students to have beneficial inter-group collaboration. In this research the communication patterns in three collaborative software engineering courses were analyzed with the method of social network analysis. It was found out that students do collaborate but mostly along pre-established social connections. The main reason for this was the difficulty in matchmaking and discovering others who were struggling with the same problems. Our proposal is to study how students in similar learning scenarios benefit from computer supported collaborative tools that increase networking opportunities. The findings presented in this paper provide a baseline for comparison when performing social network analysis in future studies.;
Proceedings of the 13th Koli Calling International Conference on Computing Education Research;Background: Software organizations increasingly need developers with high skills for social interactions. Managers leaders and academics need to know the human factors influencing the individuals the development team and the software project activities. Despite the increasing number of secondary studies about human factors in Software Engineering (SE) and in Agile Software Development (ASD) there is no study synthesizing which human factors influence software development without a specific perspective from SE or human factor thematic. Objective: We aim to summarise human factors and their influence on SE development teams and ASD teams. Method: We executed a tertiary study. We used thematic analysis to examine the resulting data. Results: We found 29 systematic literature reviews and systematic mapping studies addressing the human perspective in SE teams. We identified 101 human factors and 79 influences grouped in 4 categories (Team member Team Project and Organization). Also we identified 71 human factors and 60 influences on ASD. The most investigated human factors are Communication Collaboration Knowledge and Motivation. Conclusions: The identified human factors and their influences can be considered most significant by software organizations researchers and academics in SE practices. Based on our results practitioners might propose activities that enhance human capital behaviors that influence individual motivation agile mindset team climate software quality or agile transition in traditional organizations.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;Software Processes belong to those knowledge areas of software engineering that are less suitable to be taught classically in lectures. Class projects which frequently complement lectures are limited by academic settings in various ways too. Simulation and digital game-based learning are considered to have great potential to extend the learning experiences beyond lectures and class projects help to develop insight into the necessity of software processes and to widen the perspective of software engineering students in a virtual and efficient way. Several efforts made by different research groups show encouraging results. This research gathers preliminary findings develops new ideas and gives suggestions to exhaust the potential further and to encourage the wider application of digital game-based learning in software engineering education. These suggestions are the foundation for building blocks of a new framework for simulation based digital learning games aiming to teach software engineering processes more effectively and efficiently.;
Proceedings of the Second International Workshop on Games and Software Engineering: Realizing User Engagement with Game Engineering Techniques;"In this paper we explore how legacy software logic can be re-used in a new context-of-use. In effect oftentimes existing software is required to evolve or to be integrated into a new complex environment. Technological improvements new usages regulations or financial constraints are such reasons for evolution. Parts of the legacy functions are still useful and it is certainly challenging to integrate such code as legacy systems were designed and implemented for a specific purpose in the past. Nevertheless they are an expensive investment and transforming them to allow modification and integration with other actors would not only save high investment but also enable future modifications. We consider that an adequate technique to drive the integration of legacy systems into self-adaptive systems is to transform first the legacy code into a multi-agent system (MAS) from which adaptation within the system and communication with external actors is easier to attain. We refer to this process as adaptization"". We use as an adaptation proxy conceptually intelligent agents conforming to the Belief Desire Intention (BDI) model one of the tools of Agent-Oriented Software Engineering (AOSE). This proxy permits to understand the legacy system in terms of goals to achieve and to address adaptiveness as a goal selection problem at run-time (based on context) thus abstracting away the current implementation to a high level goal-achievement mechanism. We propose KOALA a novel stepwise methodology towards adaptization.""";
Proceedings of the 31st Annual ACM Symposium on Applied Computing;For researchers and practitioners of a relatively young discipline like software engineering an enduring concern is to identify the acorns that will grow into oaks -- ideas remaining most current in the long run. Additionally it is interesting to know how the ideas have risen in importance and fallen perhaps to rise again. We analyzed a corpus of 19000+ papers written by 21000+ authors across 16 software engineering publication venues from 1975 to 2010 to empirically determine the half-life of software engineering research topics. We adapted existing measures of half-life as well as defined a specific measure based on publication and citation counts. The results from this empirical study are a presented in this paper.;
Proceedings of the 24th International Conference on World Wide Web;"Software engineering courses in computer-science departments are meant to prepare students for the practice of designing developing understanding and maintaining software in the real world. The effectiveness of these courses have potentially a tremendous impact on the software industry since it is through these courses that students must learn the state-of-the-art process and the tools of their eventual trade"" so that they can bring this knowledge to their job and thus advance the actual state of practice. The value of ""learning software engineering"" through project-based courses has long been recognized by educators and practitioners alike. In this paper we discuss our experience with a distributed project-based course which infuses the students' learning experience with an increased degree of realism which we believe further improves the quality of their learning and advances their readiness to join the profession.""";
Proceedings of the 2011 Community Building Workshop on Collaborative Teaching of Globally Distributed Software Development;Background: There is a growing awareness of the importance of human values (e.g. inclusiveness privacy) in software systems. However there are no practical tools to support the integration of human values during software development. We argue that a tool that can identify human values from software development artefacts and present them to varying software development roles can (partially) address this gap. We refer to such a tool as human values dashboard. Further to this our understanding of such a tool is limited. Aims: This study aims to (1) investigate the possibility of using a human values dashboard to help address human values during software development (2) identify possible benefits of using a human values dashboard and (3) elicit practitioners' needs from a human values dashboard. Method: We conducted an exploratory study by interviewing 15 software practitioners. A dashboard prototype was developed to support the interview process. We applied thematic analysis to analyse the collected data. Results: Our study finds that a human values dashboard would be useful for the development team (e.g. project manager developer tester). Our participants acknowledge that development artefacts especially requirements documents and issue discussions are the most suitable source for identifying values for the dashboard. Our study also yields a set of high-level user requirements for a human values dashboard (e.g. it shall allow determining values priority of a project). Conclusions: Our study suggests that a values dashboard is potentially used to raise awareness of values and support values-based decision-making in software development. Future work will focus on addressing the requirements and using issue discussions as potential artefacts for the dashboard.;
Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Software Engineering (SE) projects that emphasize maintenance and evolution can emulate industrial challenges and prepare students for careers in the software industry. Designing maintenance-centric SE projects however is difficult because software code upon which these projects must be based is not readily available. Open Source Software (OSS) can alleviate this issue by offering a rich and varied volume of code. This rich diversity of OSS projects however presents the greatest hurdle in seamlessly selecting suitable projects for integration. To better understand the scope of this diversity initially we propose to manually select uniformly difficult projects of appropriate complexity. Ultimately based on the experiences and insights acquired through the manual selection we envision the development of a systematic methodology based on software metrics to ease the project selection process. Such a systematic methodology will pave the way for the adoption of the OSS-based approach at peer institutions bringing us a step closer to injecting realism into SE projects.;
Proceedings of the First International Workshop on Software Engineering Education Based on Real-World Experiences;Agile methods are best taught in a hands-on fashion in realistic projects. The main challenge in doing so is to assess whether students apply the methods correctly without requiring complete supervision throughout the entire project.This paper presents experiences from a classroom project where 38 students developed a single system using a scaled version of Scrum. Surveys helped us to identify which elements of Scrum correlated most with student satisfaction or posed the biggest challenges. These insights were augmented by a team of tutors which accompanied main meetings throughout the project to provide feedback to the teams and captured impressions of method application in practice. Finally we performed a post-hoc tool-supported analysis of collaboration artifacts to detect concrete indicators for anti-patterns in Scrum adoption.Through the combination of these techniques we were able to understand how students implemented Scrum in this course and which elements require further lecturing and tutoring in future iterations. Automated analysis of collaboration artifacts proved to be a promising addition to the development process that could potentially reduce manual efforts in future courses and allow for more concrete and targeted feedback as well as more objective assessment.;
Proceedings of the 38th International Conference on Software Engineering Companion;A thinking framework in the form of an actionable kernel.;
Improving students' learning in software engineering education through multi-level assignments;Assignments and exercises are an essential part of software engineering education. It usually requires a variety of these assignments to cover a desired wide range of educational objectives as defined in the revised Bloom's taxonomy. But such a variety has inherent problems e.g. that students might not see the connections between the assignments and find it hard to generalize the covered concepts.In this paper we present the educational design pattern Multi-Level Assignment which addresses these problems. It enables the assignment designer to incorporate a variety of educational objectives into a single assignment by including the concepts on multiple knowledge and process levels. The description as educational design pattern and the provided three implementation examples make this approach directly applicable for other software engineering educators.;
Proceedings of the Computer Science Education Research Conference;The practices of industrial and academic data mining are very different. These differences have significant implications for (a) how we manage industrial data mining projects (b) the direction of academic studies in data mining and (c) training programs for engineers who seek to use data miners in an industrial setting.;
Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering;Distributed software development poses new software engineering challenges. To prepare student for these new challenges we have been teaching software engineering using globally distributed projects. The projects were developed in collaboration with eleven universities in ten different countries in Europe Asia and South America. This paper reports the experience teaching the course describing the settings problems faced organizing the projects and the lessons learned.;
Proceedings of the 2011 Community Building Workshop on Collaborative Teaching of Globally Distributed Software Development;Future software systems will be vast and impossible to rebuild. The tools engineers need to get them and keep them running need to take advantage of the best we have in static and dynamic languages---to begin with. Long-running systems must be repairable and extendable while they run. We can leverage this longevity by designing our languages and systems to learn about and create models for themselves to hypothesize improvements on themselves discover and propose new capabilities and to conscientiously assist in their own upkeep and continual redesign. All while the system never stops. Our lives will depend on it.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;This paper reflects on our work in deriving targeted methodologies to develop IT applications and content in a developing world environment. This paper argues that a common thread over more than a decade of experience in building Information and Communication Technology systems has been a community centred approach. We relate this to the African philosophy of ubuntu. These approaches are wrapped into an iterative Action Research paradigm to include the communities of users directly.;
Proceedings of the 2010 ICSE Workshop on Cooperative and Human Aspects of Software Engineering;The vision of model-based software engineering is to make models the main focus of software development and to automatically generate software from these models. Part of that idea works already today. But there are still difficulties when it comes to behaviour. Actually there is no lack in models for behaviour but a lack of concepts for integrating them with the other models and with existing code. In this paper we discuss some of the main challenges in behaviour modelling and integration and present some ideas on how to overcome them - and still many open issues.;
Proceedings of the Second International Workshop on Behaviour Modelling: Foundation and Applications;Software Engineering has been a fundamental part of many computing undergraduate courses for a number of years. Although many of the tools and techniques used to undertake software engineering have changed the assessment has typically stayed the same. Students are commonly tasked with producing a number of software artefacts for example designs using the Unified Modelling Language (UML). We recently attempted to extend the software engineering experience for a group of second year students with them participating in groups that attempt to replicate industrial practice. This paper reports our investigation into the correlation between the personality of group members their approach with respect to using design patterns and their learning achievements.;
Proceedings of the 2010 Special Interest Group on Management Information System's 48th Annual Conference on Computer Personnel Research on Computer Personnel Research;Software engineering is increasingly carried out in distributed settings. Software engineers are becoming more nomadic in carrying out their work working from the customer location the headquarters of their own company their home or sometimes even from their holiday locations. Technological support is needed to overcome the negative impacts of distance that are introduced by this trend. The central theme in this paper for supporting dislocated software engineers lies in increasing their awareness level to a level similar to (or even exceeding) what they experience in a co-located setting. In this paper we present the context in which we are bootstrapping a custom fit environment to support a team of fully dislocated software engineers and the incremental process we use. By working in this fashion we are discovering the requirements to support fully distributed teams while at the same time providing our setting with working solutions to help them with their day to day challenges. Finally this continuous practical use also provides us with empirical data to validate the increase in awareness levels of dislocated software engineers and helps us in pinpointing important open research challenges.;
Proceedings of the 5th International Workshop on Co-Operative and Human Aspects of Software Engineering;The process of enterprise digital transformation needs the support of large-scale and complex software system. Using swarm intelligence can realize the efficient construction of software system. However the quality of swarm intelligence cooperation organization directly affects the efficiency and quality of software system development. Swarm intelligence oriented efficient coordinated sustainable and healthy evolution demand in this paper intelligent management method based on the method of digital research groups put forward a kind of adaptive software development method of the quality system and support the team more parallel development mode of development the effectiveness evaluation method and evaluation indicators of swarm intelligence and developing digital software collaborative development platform. Effectively organize efficient collaboration of large-scale swarm intelligence deliver high-quality software products build a growth-oriented swarm intelligence software ecosystem and help enterprises realize digital transformation quickly.;
Proceedings of the 5th International Conference on Computer Science and Software Engineering;Software development is an intrinsic collaborative profession which demands a rich set of technical and non-technical skills. In particular the recent changes that shifted the software development practice (from a collaborative in-person based activity to an intrinsic geographically distributed one) accelerated the need of non-technical skills. In this work we aimed to draw the current landscape of non-technical skills in the software development area. To achieve this goal we conducted a two-phase study. We started by inspecting 566 job post advertisement to assess how often these skills are requested. In the second phase we interviewed 15 junior developers to find out which non-technical skills they think are required in their organizations and to understand how they exercise these non-technical skills. Our results suggest that 989% of the job posts mentioned at least one non-technical skill averaging 6.30 non-technical skills per job post. Our interviewees believe that non-technical skills help them to understand the organizational culture the team dynamics and their careers. In summary we believe that our work contributes to pile additional evidence on the need that software professionals have in mastering these non-technical skills.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;The microblogging service Twitter has over 500 million users posting over 500 million tweets daily. Research has established that software developers use Twitter in their work but this has not yet been examined in detail. Twitter is an important medium in some software engineering circlesâ€”understanding its use could lead to improved support and learning more about the reasons for non-adoption could inform the design of improved tools. In a qualitative study we surveyed 271 and interviewed 27 developers active on GitHub. We find that Twitter helps them keep up with the fast-paced development landscape. They use it to stay aware of industry changes for learning and for building relationships. We discover the challenges they experience and extract their coping strategies. Some developers do not want to or cannot embrace Twitter for their workâ€”we show their reasons and alternative channels. We validate our findings in a follow-up survey with more than 1200 respondents.;
Proceedings of the 36th International Conference on Software Engineering;This work was carried out as a master's level software engineering project over the course of two semesters. Software engineering methodologies were applied to try to improve the portability maintainability and performance of a fusion energy code by systematically using tools to try to map computationally intensive parts of the code to GPUs using OpenACC. Our experiences show that while the approach is promising tool support for Fortran is lacking and difficulties in working with the complex code in a supercomputing environment limit what can be achieved in a reasonable amount of time.;
Proceedings of the 2015 International Workshop on Software Engineering for High Performance Computing in Science;This paper describes a lab series component for learning multi-layer web service based software architecture in an online hybrid or traditional format software engineering course. The labs complement the software engineering process and theory course topics with practical experience using current industry standard tools and technologies. No central infrastructure is required students build the development/test environment from the ground up using free and widely used software such as Apache Tomcat Java Jersey and MySQL on a virtual machine. Survey results show that students see the labs as a valuable learning experience.;
Guidelines for snowballing in systematic literature studies and a replication in software engineering;Background: Systematic literature studies have become common in software engineering and hence it is important to understand how to conduct them efficiently and reliably.Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach and they are illustrated and evaluated by replicating a published systematic literature review.Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches.Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review.Conclusions: It is concluded that using snowballing as a first search strategy may very well be a good alternative to the use of database searches.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;We describe the activities of the Empirical Software Engi-neering (ESE) group at Microsoft Research. We highlight our research themes and activities using examples from our research on socio technical congruence bug reporting and triaging and data-driven software engineering to illustrate our relationship to the CSCW community. We highlight our unique ability to leverage industrial data and developers and the ability to make near term impact on Microsoft via the results of our studies. We also present the collaborations our group has with academic researchers.;
Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work;Software Engineering course design for undergraduates has been a challenging task in many campuses especially for those that do not have large enrollment. This is not only because the course has too many topics to be covered in one semester even two semesters but also because it crosses many different disciplines such as computer science engineering management and staffing. In this paper a course framework is designed for the undergraduate software engineering in a context with small enrollment in terms of the Software Engineering core and elective requirements in CC2001 [1] as well as ABET 2010 [2] and SE2004 [3]. Based on the author's experience the course design decisions are made against the dimensions presented in [4]. The topics covered in the course design as well as the course curriculum are presented. Activities and requirements of term-long team projects are illustrated to reflect the topics covered in the lecture and synchronized with the lecture progressing.;
An agenda for concern-oriented software engineering;The principle of separation of concerns has certainly stood the test of time in guiding the field of software engineering leading to an amazing variety of approaches available to programmers to actually separate and manage concerns in their software. In this paper we provide a novel perspective on these approaches a perspective that is guided by the observation that the underlying goal of any approach should not be to always separate concerns but instead to minimize the impact of concern scattering and tangling. Reframed as such we survey and relate existing work highlight fundamental limitations of the four canonical approaches to minimizing the impact of concern scattering and tangling and provide an agenda for future work -- at both the code level and beyond.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;Scientific progress comes from creating sound theories. However current software engineering still mostly falls short of this goal although its importance is widely accepted. Thus in this paper we discuss the importance of a successful interaction of empirical research with a strong theoretical basis and the ramifications this has. In particular we will extensively discuss the implications on theory building and the empirical vs. theory interaction etc. While not everything we will discuss is novel we present a number of insights which we at least did not see in software engineering literature. We strongly believe that a careful consideration of the insights discussed in this paper has the potential to lead to a significant improvement in software engineering research.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;Software testing traditionally receives little attention in early computer science courses. However we believe that if exposed to testing early students will develop positive habits for future work. As we have found that students typically are not keen on testing we propose an engaging and socially-oriented approach to teaching software testing in introductory and intermediate computer science courses. Our proposal leverages the power of gaming utilizing our previously described system HALO. Unlike many previous approaches we aim to present software testing in disguise - so that students do not recognize (at first) that they are being exposed to software testing. We describe how HALO could be integrated into course assignments as well as the benefits that HALO creates;
Proceedings of the 4th International Workshop on Social Software Engineering;In the last decade a large number of software repositories have been created for different purposes. In this paper we present a survey of the publicly available repositories and classify the most common ones as well as discussing the problems faced by researchers when applying machine learning or statistical techniques to them.;
Proceedings of the First International Workshop on Realizing AI Synergies in Software Engineering;In this paper we argue that the reality of today's software systems requires us to consider uncertainty as a first-class concern in the design implementation and deployment of those systems. We further argue that this induces a paradigm shift and a number of research challenges that must be addressed.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;Modelling plays a vital role in software engineering enabling the creation of larger more complex systems. Search-based software engineering (SBSE) offers a productive and proven approach to software engineering through automated discovery of near-optimal solutions to problems and has proven itself to be effective on a wide variety of software engineering problems. The aim of this workshop is to highlight that SBSE and modelling have substantial conceptual and technical synergies and to discuss and present opportunities and novel ways in which they can be combined whilst fostering the growing community of researchers working in this area.;
Proceedings of the 2013 International Conference on Software Engineering;In the context of robotic software the selection of an appropriate planner is one of the most crucial software engineering decisions. Robot planners aim at computing plans (i.e. blueprint of actions) to accomplish a complex mission. While many planners have been proposed in the robotics literature they are usually evaluated on showcase examples making hard to understand whether they can be effectively (re)used for realising complex missions with heterogeneous robots and in real-world scenarios.In this paper we propose ENFORCE a framework which allows wrapping FM-based planners into comprehensive software engineering tools and considers complex robotic missions. ENFORCE relies on (i) realistic maps (e.g fire escape maps) that describe the environment in which the robots are deployed (ii) temporal logic for mission specification and (iii) Uppaal model checker to compute plans that satisfy mission specifications. We evaluated ENFORCE by analyzing how it supports computing plans in real case scenarios and by evaluating the generated plans in simulated and real environments. The results show that while ENFORCE is adequate for handling single-robot applications the state explosion still represents a major barrier for reusing existing planners in multi-robot applications.;
Proceedings of the 8th International Conference on Formal Methods in Software Engineering;When making choices in software projects engineers and other stakeholders engage in decision making that involves uncertain future outcomes. The concept of 'intertemporal choice' describes choices between outcomes at different times in the future. Short-sighted decisions with far-reaching effects are a long-standing cause of concern in the software profession.Common models to support decisions in software projects use concepts such as expected utility and discount factors to quantify future value and enable trade-off decisions. However a growing body of behavioral research shows that these normative models do not adequately describe how people actually make choices.Our objective is to understand how developers and stakeholders actually take trade-off decisions during software projects that involve current and future benefits and to identify the human and cooperative factors that influence them. This requires empirical research on decision making in SE with a focus on trade-offs across time. To support such research this paper reports on a systematic literature review that aimed to identify whether the intersection of these concepts has been acknowledged and addressed. We discuss the assumptions about decision makers that underpin existing research and analyze how the role of time has been characterized in the study of decision making in SE.Based on this review the paper begins to develop principles for a descriptive framework to characterize intertemporal choices in empirical and behavioral software engineering research.;
Proceedings of the 10th International Workshop on Cooperative and Human Aspects of Software Engineering;Customization is considered as a promising way for better satisfying diversity of customer needs. In organizations short of resources it is a frequent challenge to get balance between development and customization workload in order to ensure product success as well as customer satisfaction. In this paper we proposed a value-based product portfolio scoping approach to determine optimal product scale for planning software product line adoption. The approach blends existing methods in domain analysis requirements clustering and valuation theory. An industrial case study is presented to demonstrate the application of the approach and its effectiveness.;
Proceedings of the Third International Workshop on Product LinE Approaches in Software Engineering;Background: Action research is a well-established research methodology. It is following a post-positivist research philosophy grounded in critical thinking. The methodology is driven by practical problems emphasis participatory research and develops practically useful solutions in an iterative manner.Objective: Two objectives are to be achieved: (1) Understanding the state of the art with respect to action research usage in the software engineering literature and (2) reflecting and providing recommendations of how to foster industry-academia collaboration through action research.Method:;
Proceedings of the 2014 International Workshop on Long-Term Industrial Collaboration on Software Engineering;Expectations to derive value from open data are high. However how value is created from open data is still largely unknown. Open data value is usually generated in constellation of actors in which each player has different capabilities and roles. To understand the open data value creation process the business model canvas is introduced in this article. The typical components of the business model canvas and open data value creation are derived from the literature. By combining these two research streams the open data value model canvas is created. The case of Coronavirus disease 2019 (COVID-19) worldwide dashboard developed by the Johns Hopkins University is used to evaluate the model's utility. Key components of the open data value model are creating an overview of various data sources from public and private organizations having capabilities to combine heterogeneous data and connecting data and needs. In this way the open data canvas helps to grasp the value creation logic.;
Extending software engineering research outside the digital box;"Since software is developed to run on computers there is a tendency to focus computer science and software engineering on how best to get software to run on computers. But engineering is different from science: the Webster definition of engineering"" is ""the application of science and mathematics by which the properties of matter and the sources of energy in nature are made useful to people."" Thus it would follow that the responsibility of software engineering and its research would include the utility to people of the software and the software-reliant artifacts they use beyond thinking within purely digital boxes. This position paper addresses two perspectives on the future of software engineering when viewed in this broader context.""";
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;Engineering research needs to be informed by (or based on) industrial needs to have impact and industrial innovation depends on research to fill the gaps in knowledge and to pave the way for better tools technologies and services. In the past few years in the Certus center at Simula Research Laboratory we have been exploring ways to foster a closer collaboration between research and industry both to align our research with practical needs and to further increase awareness about the important role that software engineering research plays as an enabler for innovation. This paper outlines our experiences with recent and successful research projects conducted in collaboration with the maritime and energy industries. We take a retrospective approach to examine the way we collaborated with our industry partners and elaborate the decisions that we believe contributed to the effectiveness of the collaborations. We report the lessons learned from our experience and illustrate these lessons using examples from several projects. The lessons focus on the applications of Model-Driven Engineering (MDE) as all the projects we draw on here were MDE projects. MDE is a fast growing discipline and is thought to be a key component of any scalable solution to long-standing software engineering problems. Our goal from structuring and sharing our experience is to contribute to a better understanding of how researchers and practitioners can collaborate more effectively and to gain more value from their collaborations.;
Proceedings of the 5th India Software Engineering Conference;Effective leadership is one of the key drivers of business and project success and one of the most active areas of management research. But how does leadership work in agile software development which emphasizes self-management and self-organization and marginalizes traditional leadership roles? To find out this study examines agile leadership from the perspective of thirteen professionals who identify as agile leaders in different roles at ten different software development companies of varying sizes. Data from semi-structured interviews reveals that leadership: (1) is dynamically shared among team members (2) engenders a sense of belonging to the team and (3) involves balancing competing organizational cultures (e.g. balancing the new agile culture with the old milestone-driven culture). In other words agile leadership is a property of a team not a role and effectiveness depends on agile team members' identifying with the team accepting responsibility and being sensitive to cultural conflict.;
Proceedings of the 44th International Conference on Software Engineering;Undergraduate students who seek a bachelor degree in Dutch universities of applied sciences are supposed to learn also research skills so that they can provide innovative solutions to real problems of the society and businesses in their future careers. Current education and textbooks on research skills are not tuned well to software engineering disciplines. This paper describes our vision about the scope and model of the research suitable for software engineering disciplines in Dutch universities of applied sciences. Based on literature study we identify a number of research models that are commonly used in computer science. Through reviewing a number of graduation reports in our university we further identify which of the research models are most suitable for the (graduation) projects of software engineering disciplines and also investigate their shortcomings with respect to the desired research skills. Our study reveals that the approach of most graduation works is close to the implementation-based (also called build-based or proof by example based) research model. In order to be considered as a realization of sound applied research however most of theses graduation works need to be improved on a number of aspects such as problem context definition system/prototype evaluation and critical literature study.;
Proceedings of the 15th Annual Conference on Information Technology Education;Aspiring software engineers must be able to comprehend and evolve legacy code which is challenging because the code may be poorly documented ill structured and lacking in human support. These challenges of understanding and evolving existing code can be illustrated in academic settings by leveraging the rich and varied volume of Open Source Software (OSS) code. To teach SE with OSS however it is necessary to select uniform projects of appropriate size and complexity. This paper reports on our search for suitable OSS projects to teach an introductory SE course with a focus on maintenance and evolution. The search turned out to be quite labor intensive and cumbersome contrary to our expectations that it would be quick and simple. The chosen projects successfully demonstrated the maintenance challenges highlighting the promise of using OSS. The burden of selecting projects however may impede widespread integration of OSS into SE and other computing courses.;
Proceedings of the 45th ACM Technical Symposium on Computer Science Education;We identify three challenges related to the provenance of the material we use in teaching software engineering. We suggest that these challenges can be addressed by using evidence-based software engineering (EBSE) and its primary tool of systematic literature reviews (SLRs). This paper aims to assess the educational and scientific value of undergraduate and postgraduate students undertaking a specific form of SLR called a mapping study. Using a case study methodology we asked three postgraduate students and three undergraduates and their supervisor to complete a questionnaire concerning the educational value of mapping studies and any problems they experienced. Students found undertaking a mapping study to be a valuable experience providing both reusable research skills and a good overview of a research topic. Postgraduates found it useful as a starting point for their studies. Undergraduates reported problems undertaking the study in the required timescales. Searching and classifying the literature was difficult.;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1;Software engineers produce code that has formal syntax and semantics which establishes its formal meaning. However it also includes significant natural language found in identifier names and comments. Additionally programmers not only work with source code but also with a variety of software artifacts predominantly written in natural language. Examples include documentation requirements test plans bug reports and peer-to-peer communications. It is increasingly evident that natural language information can play a key role in improving a variety of software engineering tools used during the design development debugging and testing of software.The focus of the NaturaLiSE workshop is on natural language analysis of software artifacts. This workshop will bring together researchers and practitioners interested in exploiting natural language informationfound in software artifacts to create improved software engineering tools. Relevant topics include (but are not limited to) natural language analysis applied to software artifacts combining natural language and traditional program analysis integration of natural language analyses into client tools mining natural language data and empirical studies focused on evaluating the usefulness of natural language analysis.;
Proceedings of the 2013 International Conference on Software Engineering;Most academic disciplines emphasize the importance of their general theories. Examples of well-known general theories include the Big Bang theory Maxwellâ€™s equations the theory of the cell the theory of evolution and the theory of demand and supply. Less known to the wider audience but established within their respective fields are theories with names such as the general theory of crime and the theory of marriage. Few general theories of software engineering have however been proposed and none have achieved significant recognition. This workshop organized by the SEMAT initiative aims to provide a forum for discussing the concept of a general theory of software engineering. The topics considered include the benefits the desired qualities the core components and the form of a such a theory.;
Proceedings of the 2013 International Conference on Software Engineering;Background: Search-based Software Engineering (SBSE) uses a variety of techniques such as evolutionary algorithms or meta-heuristic searches but lacks a standard baseline method.Aims: The KEYS2 algorithm meets the criteria of a baseline. It is fast stable easy to understand and presents results that are competitive with standard techniques.Method: KEYS2 operates on the theory that a small sub-set of variables control the majority of the search space. It uses a greedy search and a Bayesian ranking heuristic to fix the values of these variables which rapidly forces the search towards stable high-scoring areas.Results: KEYS2 is faster than standard techniques presents competitive results (assessed with a rank-sum test) and offers stable solutions.Conclusions: KEYS2 is a valid candidate to serve as a baseline technique for SBSE research.;
Proceedings of the 6th International Conference on Predictive Models in Software Engineering;The effect of cultural differences is often overlooked or neglected when analysing attractive cost-effective options for software development. This papers aims to highlight people issues that arise out of cultural differences between interacting software development teams particularly between Indians and non-Indians. The author's intent is to merely bring out the differences and not to provide solutions or recommendations or to identify root causes for the behavior. This is an experience paper mostly based on observations and sharing of personal experiences from various colleagues and coworkers.;
Proceedings of the 2nd India Software Engineering Conference;Even though software is developed by humans research in software engineering primarily focuses on the technologies methods and processes they use while disregarding the importance of the humans themselves. In this paper we argue that most studies in software engineering should give much more weight to human factors. In particular empirical software engineering studies involving human developers should always consider collecting psychometric data on the humans involved. We focus on personality as one important psychometric factor and present initial results from an empirical study investigating correlations between personality and attitudes to software engineering processes and tools. We discuss what are currently hindering a more wide-spread use of psychometrics and how overcoming these hurdles could lead to a more individualized software engineering.;
Proceedings of the 2008 International Workshop on Cooperative and Human Aspects of Software Engineering;SCORE 2011 is the second iteration of a team-oriented software engineering contest that attracts student teams from around the world culminating in a final round of competition and awards at ICSE. Each team has responded to one of the project proposals provided by the SCORE program committee usually in the context of a software engineering project course. In this second iteration we have built on the success of SCORE 2009 greatly expanding the number and geographical distribution of student teams including many of very high quality.;
Proceedings of the 33rd International Conference on Software Engineering;There are hundreds of general contests targeting undergraduate and graduate students. The prizes vary from cash trip fame conference participation and others. Contests could be class competitions school national regional or global. In this paper we compare between existing student contests that can be integrated with software engineering courses. We classify the contests and propose a framework to choose which one to suit curriculum. We also include best practices and samples of our practices in integrating software engineering course with class regional national and global contests.;
Proceedings of the 2013 International Conference on Software Engineering;In this position paper we affirm that there are synergies to be gained by using search-based techniques within software model checking. We will show from the literature how meta-heuristic search based techniques can augment both the model checking process and its applications. We will provide evidence to support this assertion in the form of existing research work and open problems that may benefit from combining Search-Based Software Engineering (SBSE) techniques and software model checking.;
Proceedings of the 1st International Workshop on Combining Modelling and Search-Based Software Engineering;This paper presents an adoption and adaptation of the Curriculum Guidelines for Graduate Degree Programs in Software Engineering (GSwE2009) proposed by the IEEE-CS and the ACM for the creation of a curriculum for a Master's degree in software engineering at the Universidad de la Rep\'{u;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;There has been some research conducted around the motivation for the use of Twitter and the value brought by micro-blogging tools to individuals and business environments. This paper builds on our understanding of how the phenomenon affects the population which birthed the technology: Software Engineers. We find that the Software Engineering community extensively leverages Twitter's capabilities for conversation and information sharing and that use of the tool is notably different between distinct Software Engineering groups. Our work exposes topics for future research and outlines some of the challenges in exploring this type of data.;
Proceedings of the 2nd International Workshop on Web 2.0 for Software Engineering;Sustainability is not supported by traditional software engineering methods. This lack of support leads to inefficient efforts to address sustainability or complete omission of this important concept. Defining and developing adequate support requires a commonly accepted definition of what sustainability means in and for software engineering.We contribute a description of the aspects of sustainability in software engineering.;
Proceedings of the 28th Annual ACM Symposium on Applied Computing;The representation of contexts is essential in tasks involving Natural Language Processing (NLP). In the field of software engineering classifying similar texts within a specific context has been a complex task considering the informality and the complexity inherent of the texts produced through many software development processes (e.g. agile methods). Word embeddings capture semantic and syntactic information about unique words allowing them to be represented in a dense and low-dimensional format. This property makes the embeddings vectors an important input feature for machine learning algorithms that aim to classify texts. Although there has been much research around the application of word embeddings in several areas up to this moment there is no knowledge about studies that have explored its application in the creation of a specific model for the domain of the area of software engineering. Thus this article presents the proposal to generate an embedding model called embeddings model for software engineering (EmbSE) which can recognize specific and relevant terms in the software engineering context. This model can be used as the main entry in the classification of several textual artifacts generated during the software development project process. The results are promising presenting a 48% improvement in the mAP values for the EmbSE concerning the model trained on the generic corpus. This reinforces the hypothesis that a model of this nature can bring significant improvements in the classification of texts of the area.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;This paper describes the use of an automated proof assistant in an introductory graduate level Formal Methods of Software Engineering course. Proof is difficult and often seen as abstract but tools can be the basis for relating proofs to practice. The proof editor JAPE can animate formal proofs in various theories providing students with a significantly self-driven exploration of theory. The existence of machine readable theory objects also presents the opportunity to automate relationships between theory and topics more familiar to the student - programming in this case. We have documented increased work and improved attitude among students toward formal methods and proof using this combined approach. Although the particular example is a graduate course we believe the increased student involvement in a structured experience leads to better outcomes and can be well-employed in many course even as a stand off module.;
Building an empirical software engineering research knowledge base from heterogeneous data sources;Recently the Systematic Knowledge Engineering (SKE) process has been introduced to help researchers build up an empirical software engineering (EMSE) Body of Knowledge (BoK) based on a systematic literature review process. However the SKE process does not explain how to effectively capture and represent the EMSE knowledge to enable efficient data analysis. In this paper we introduce the EMSE Research Knowledge Base Building (RKB) process which guides knowledge engineers in developing and using a knowledge base (KB) for the SKE process based on contributions from heterogeneous data sources. We evaluate the RKB process in the context of three research topics from the EMSE domain: software inspection experiments theory construct identification and threats to validity. Major results are that the RKB process is effective in guiding the knowledge engineer to build a KB that allows answering the EMSE-specific queries. The RKB process shows promising results in the EMSE research context and should be investigated in other research contexts as well.;
Proceedings of the 14th International Conference on Knowledge Technologies and Data-Driven Business;Context: Two of the most common external threats to validity in quantitative studies in software engineering (SE) are concerned with defining the population by convenience and nonrandom sampling assignment. Although these limitations can be reduced by increasing the number of replications and aggregating their results the acquired evidence rarely can be generalized to the field.Objective: To investigate the state of practice of meta-analysis in SE and its limitations intending to propose an alternative perspective to understand the relationships among experimentation production threats to validity and evidence. To propose and evaluate means to strengthen quantitative studies in software engineering and making them less risky due to population and sampling issues.Method: To use the underlying idea from the Theory of Food Chains to alternatively understand the impact of external threats to validity in the SE experimental cycle (experimental chains). Next to accomplish an initial technical literature survey to observe basic features of secondary studies aggregating primary studies results. Third to organize a set of experimental chain's concepts and make initial discussions regarding the observed secondary studies concerned with this metaphor.Results: By applying the experimental chains concepts it was initially observed that although important and necessary most of the current effort in the conduction of quantitative studies in SE does not produce (mainly due to population/sampling constraints) results strong enough to positively impact the engineering of software. It promotes an imbalance between research and practice. However more investigation is necessary to support this claim.Conclusion: We argue that research energy has been lost in SE studies due to population/sampling constraints. Therefore we believe more investigation must be undertaken to understand how better organizing enlarging setting up and sampling SE quantitative studies' population by using for instance alternative technologies such as social networks or other crowdsourcing technologies.;
Proceedings of the 17th International Conference on Evaluation and Assessment in Software Engineering;The development of wireless sensor networks (WSNs) software today is tackled by a code-and-fix process that relies solely on the primitive constructs provided by the operating system and the skills of developers. For WSNs to emerge from research labs and make a true impact on society at large we need methodologies techniques and abstractions that improve the development process foster the designer's confidence about the WSN behavior and whose effectiveness is demonstrated in the real world.How do we achieve these goals? The aforementioned challenges are germane to the techniques and expertise matured by software engineering (SE). Unfortunately the WSN and SE research communities have been mostly impermeable to each other. In this paper we elaborate on this state of affairs by arguing that a principled approach to development is inevitable as WSNs become more and more pervasive and by identifying and discussing specific areas where a synergy between the SE and WSN communities could provide immediate much-needed results.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;This paper summarizes our experiences integrating topics in the software development fundamentals (SDF) programming languages (PL) and software engineering (SE) knowledge areas of the ACM 2013 curriculum within a single course. It is novel in combining object-oriented programming and software development practices with fundamental analytical reasoning about software correctness. The aim is to integrate and cover the topics in an effective fashion. The course description in this paper represents an approach we have applied successfully for over 5 years. Students tend to consider this course to be one of the more challenging encountered in the first two years of study. Interestingly the challenge appears to stem equally from mastering object-oriented programming and design pattern components of the course as it does from learning to use specifications for analytical reasoning of component correctness.;
Proceedings of the 45th ACM Technical Symposium on Computer Science Education;"Software systems bridge the gap between information processing needs and available computer hardware. As system requirements grow in complexity and hardware evolves the gap does not necessarily widen but it certainly changes. Although today's applications require concurrency and today's hardware provides concurrency programming languages remain predominantly sequential. Concurrent programming is considered too difficult and too risky to be practiced by ordinary programmers"". However software engineering is moving towards a paradigm shift following which concurrency will play a more fundamental role in programming languages. We discuss some of the implications of the shift towards process-oriented programming. We outline some of the features of our own process-oriented language. Finally we review the potential impact on software engineering and on software development processes.""";
Proceedings of the 2008 C3S2E Conference;Diversity of skills is good for society it is also good in problem solving because different people see a problem from several pers-pectives so diversity should be good for software engineering too. This study tackles a difficult to study aspect of software engineer-ing that is how to best associate personnel with the various tasks in a software project. The approach uses psychological types to determine who is best suited to particular development roles. The article has four main objectives: (1) to arouse awareness of human factors among software engineers (2) to investigate how psycho-logical factors can contribute to their effectiveness at work (3) to catalyze effort among software engineers leading towards a deeper understanding and broader applications of human factors in the light of the activities involving the engineering of software and (4) to emphasize the important of skill diversity in the software engi-neering field. This article provides conceptual knowledge reports findings and presents both real and hypothesized beliefs from the software engineering community. Likewise it is hoped that the article will motivate software engineers and psychologists to con-duct more research in the area of software psychology so as to understand more profoundly the possibilities for increased effec-tiveness and fulfilment among software engineers;
Understanding the Challenges Faced by Neurodiverse Software Engineering Employees: Towards a More Inclusive and Productive Technical Workforce;Technology workers are often stereotyped as being socially awkward or having difficulty communicating often with humorous intent however for many technology workers with atypical cognitive profiles such issues are no laughing matter. In this paper we explore the hidden lives of neurodiverse technology workers e.g. those with autism spectrum disorder (ASD) attention deficit hyperactivity disorder (ADHD) and/or other learning disabilities such as dyslexia. We present findings from interviews with 10 neurodiverse technology workers identifying the challenges that impede these employees from fully realizing their potential in the workplace. Based on the interview findings we developed a survey that was taken by 846 engineers at a large software company. In this paper we reflect on the differences between the neurotypical (N = 781) and neurodiverse (N = 59) respondents. Technology companies struggle to attract develop and retain talented software developers our findings offer insight into how employers can better support the needs of this important worker constituency.;
Proceedings of the 17th International ACM SIGACCESS Conference on Computers &amp Accessibility;"Mobile computing is on the brink of becoming the most widely used form of computing. In the October-November 2012 of The Economist [4] it was reported that [b]y 2017 the volume of mobile data traffic will be 21 times greater than it was in 2011."" Smartphones and tablets will increase subscriptions for mobile-broadband to approximately 5 billion. With this predicted increase in users and devices it is essential that students majoring in computer science today be prepared for the future. If not they will be left behind. Practical software engineering requires experience in developing applications that have significant complexity and reality. Developing applications for mobile devices provides the opportunity to meet both of these requirements while introducing undergraduate and graduate students to topics and skills that can contribute to their employability. This paper describes the efforts being conducted to teach advanced software engineering concepts at Jackson State University through the use of its Innovative Mobile Application Development (iMAD) Laboratory. Topics discussed in this paper are applicable to all persons interested in establishing a similar lab and introducing students to software engineering for mobile application development.""";
On the use of time series and search based software engineering for refactoring recommendation;To improve the quality of software systems one of the widely used techniques is refactoring defined as the process of improving the design of an existing system by changing its internal structure without altering the external behavior. The majority of existing refactoring works do not consider the impact of recommended refactorings on the quality of future releases of a system. In this paper we propose to combine the use of search-based software engineering with time series to recommend good refactoring strategies in order to manage technical debt. We used a multi-objective algorithm to generate refactoring solutions that maximize the correction of important quality issues and minimize the effort. For these two fitness functions we adapted time series forecasting to estimate the impact of the generated refactorings solution on future next releases of the system by predicting the evolution of the remaining code smells in the system after refactoring using different quality metrics. We evaluated our approach on one industrial project and a benchmark of 4 open source systems. The results confirm the efficiency of our technique to provide better refactoring management comparing to several existing refactoring techniques.;
Proceedings of the 7th International Conference on Management of Computational and Collective IntElligence in Digital EcoSystems;Research in software engineering (SE) shows that freshly graduated students are usually not prepared to deal with problems occurring at the workplace. It is important to teach them how to construct the knowledge and solve the problems faced with. In this paper we present two approaches used in SE courses at the University of Zagreb Croatia: One approach is a distributed project-based course where students from Croatia and Sweden work on the projects together going through the whole life-cycle of creating a software product while solving different problems from technical obstacles to handling cultural differences. The other approach focuses on self-constructing the knowledge and presenting it to other students with students' discussions and a group project in the end of the course. Both approaches enable the practicing of soft skills which in most cases are not adequately represented in SE education.;
Proceedings of the 2008 International Workshop on Software Engineering in East and South Europe;"Global software engineering (GSE) is a business strategy to realize a business idea (i.e. the development project) faster through round-the-clock productivity. However GSE creates a volatile and unstable process in which many actors interact together against unpredictable premises (e.g. cultural or time differences) often producing unexpected outcomes (e.g. compacting effects of distance and time). So far Scrum has been used extensively for embarking in global software engineering but many of the problems in Scrum-based GSE could still benefit from the usage of ad-hoc supporting tools (e.g. information continuity between timezones cultural differences developers awareness etc.). Agile Service Networks (ASNs) are networks of service oriented applications (nodes) that collaborate adaptively towards a common goal. ASNs offer a way to represent GSE professionals through service-oriented social"" nodes in a ""small-world"" network (much like a Facebook for a specific GSE project). This paper presents a comparison between the two approaches namely Scrum and ASNs to determine ASN's potentials as mechanisms to maintain awareness in GSE.""";
Proceedings of the 4th International Workshop on Principles of Engineering Service-Oriented Systems;Advances in software engineering have led to the creation of many new software engineering techniques. However industrial adoption of these techniques is often quite low as development organizations are skeptical of their value and applicability. Empirical studies are commonly used to show this value to potential adopters with open source software used as an approximation of industrial applications. However little data exists on the similarity of open source and industrial software. We present a large metrics-based study comparing the most commonly evaluated open source programs to a large set of industrial programs. Source metrics are calculated and compared between 24 open source and 21 industrial programs. The results identify open source programs that are most similar to industrial programs. Using these identified open source programs in empirical studies can provide the best generalization to industrial software.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;In this paper we describe research that reports gender differences in usage of software engineering tools by end-user programmers. We connect these findings with possible explanations based on theories from other disciplines and then add to that our recent results that these differences go deeper than software engineering tool usage to software engineering strategies. We enumerate the strategies that work better for males and the ones that work better for females and discuss implications and possible directions for follow-up.;
Proceedings of the 4th International Workshop on End-User Software Engineering;&ltu&gtBackground.&lt/u&gt Even though the amount of researches related to the behavior of software development teams has significantly increased in recent years researches focusing on motivation as an alternative to lead software projects to success are still rare.&ltu&gtObjective/Method:&lt/u&gt This article describes a survey conducted to identify the relative importance of some factors that affect the motivation of software engineers at work. The conceptual underpinnings of human motivation used in the research are the Expectancy Theory and the Motivation-Hygiene Theory.&ltu&gtResults/Conclusion:&lt/u&gt In the study a cross-sectional survey was conducted involving 176 software engineers employed at 20 software firms from the State of Pernambuco Brazil. Data collected with the survey revealed not only the order in which the set of motivators influences the software engineers' motivation and other peripheral findings but also served as a basis to design three motivation strategies for software engineering teams.;
Proceedings of the 2010 ICSE Workshop on Cooperative and Human Aspects of Software Engineering;Component-based architectures are natural for Cloud computing. However few current software development frameworks are exploiting this fact. A proof-of-the-concept implementation of an open-source Platform-as-a-service dedicated to the development of component-based applications is shortly presented in this paper.;
Proceedings of the WICSA/ECSA 2012 Companion Volume;Modeling has become a central part of software engineering education. Students learn how to create models using modeling languages such as the UML in order to describe phenomena of the real world (or problem domain) or to document the structure and the behaviour of software systems.In my courses I teach the UML. I made the observation that students can easily get lost and become demotivated if a software engineering course is focusing too much on modeling. Students ask very soon how modeling notations their semantics etc. are related to the things they learned in previous programming courses. The core of this problems seems to be a lack of real-world projects that are both implemented in a clean way and for which useful models are available. Useful models in this respect are models which can show the students the beauty of a system or in other words the elegance of the current implementation.The purpose of this paper is to foster the collaboration among modeling experts in order to re-model existing software and to make these models publicly available. The purpose of these models is twofold: They should help (i) to teach abstractions i.e. how can one explain with few diagrams the internals of even big systems and (ii) to teach the art of programming i.e. how can models be implemented in an effective way.;
Proceedings of the 8th Edition of the Educators' Symposium;Fuzzing or fuzz testing is an established technique that aims to discover unexpected program behavior (e.g. bugs security vulnerabilities or crashes) by feeding automatically generated data into a program under test. However the application of fuzzing to test Model-Driven Software Engineering (MDSE) tools is still limited because of the difficulty of existing fuzzers to provide structured well-typed inputs namely models that conform to typing and consistency constraints induced by a given meta-model and underlying modeling framework. By drawing from recent advances on both fuzz testing and automated model generation we present three different approaches for fuzzing MDSE tools: A graph grammar-based fuzzer and two variants of a coverage-guided mutation-based fuzzer working with different sets of model mutation operators. Our evaluation on a set of real-world MDSE tools shows that our approaches can outperform both standard fuzzers and model generators w.r.t. their fuzzing capabilities. Moreover we found that each of our approaches comes with its own strengths and weaknesses in terms of fault finding capabilities and the ability to cover different aspects of the system under test. Thus the approaches complement each other forming a fuzzer suite for testing MDSE tools.;
Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering;This article presents the use of a model-centric approach to facilitate software development projects conforming to the three-tier architecture in undergraduate software engineering courses. Many instructors intend that such projects create software applications for use by real-world customers. While it is important that the first version of these applications satisfy the customer by providing the functionality the customer expects and perform reliably and efficiently it is equally important to be able to accommodate the customer's change requests over the period of the product's lifetime. The challenges in achieving these goals include the lack of real-world software development experience among the student developers and the fact that postdeployment change requests will almost certainly have to be handled by students who are not among the original developers. In this article we describe how a model-centric approach using UML has been effective in enabling students to develop and maintain eight software applications for small businesses over a 9-year period. We discuss the characteristics of our modeling technique which include the application of modeling patterns and quality check rules that enable students to create a model that can be clearly and consistently mapped to code. We also describe the nature of these mapping-to-code techniques emphasizing how they reduce coupling among the implementation's classes. We then discuss our experiences in the classroom with these techniques focusing on how we have improved our teaching over the years based on the analysis of student performance and feedback. Finally we compare our approach to related work teaching modeling and the development and maintenance of code in software engineering courses with both extensive and minimal modeling.;
Challenges and Recommendations for the Design and Conduct of Global Software Engineering Courses: A Systematic Review;"Context: Global Software Engineering (GSE) has become the predominant form of software development for global companies and has given rise to a demand for students trained in GSE. In response universities are developing courses and curricula around GSE and researchers have begun to disseminate studies of these new approaches. Problem: GSE differs from most other computer science fields however in that practice is inseparable from theory. As a result educators looking to create GSE courses face a daunting task: integrating global practice into the local classroom. Aim: This study aims to ameliorate the very difficult task of teaching GSE by delineating the challenges and providing some recommendations for overcoming them. Method: To meet our aims we pose two research questions (When teaching GSE to students in Higher Education what are the (a) challenges and (b) recommendations for addressing them"") and then conduct a systematic literature review (SLR) to determine the answers to these questions. Our SLR follows a carefully designed and validated protocol.Results: We found 82 papers that addressed our research questions. Our findings indicate that in addition to the challenges posed by GSE in general particular problems arise in educational situations. The majority of these challenges fall into the ""global distance"" category though teamwork challenges and people issues (such as trust) also commonly arise. Organizational differences between institutions differing skill sets between students in different locations and varying cultural work norms for example all operate within educational settings in quite different ways than in professional development teams. Integrating cultural training conducting teamwork exercises to build trust and instructor monitoring of team communication are all examples of techniques that have been used successfully by educators according to our review Conclusion: Despite the severity of the challenges in GSE education many institutions have successfully developed courses and curricula targeting GSE. Indeed for each of the challenges we have identified in the literature there are numerous recommendations for overcoming them. Instructors can use the recommendations given in this study as a starting point to running successful GSE courses.""";
Proceedings of the 2015 ITiCSE on Working Group Reports;Developers often ask how-to questions using search engines technical Q&ampA communities and interactive Q&ampA systems to seek help for specific programming tasks. However they often do not formulate the questions in a specific way making it hard for the systems to return the best answers. We propose an approach (TaskKG4Q) that interactively helps developers formulate a programming related how-to question. TaskKG4Q is using a programming task knowledge graph (task KG in short) mined from Stack Overflow questions which provides a hierarchical conceptual structure for tasks in terms of [actions] [objects] and [constraints]. An empirical evaluation of the intrinsic quality of the task KG revealed that 75.0% of the annotated questions in the task KG are correct. The comparison between TaskKG4Q and two baselines revealed that TaskKG4Q can help developers formulate more specific how-to questions. More so an empirical study with novice programmers revealed that they write more effective questions for finding answers to their programming tasks on Stack Overflow.;
Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering;In this paper we describe how we teach real-world software engineering to students using a project course simulating in-vivo software development projects. The course gives the students an opportunity to try out in practice the skills gained on other computer science and software engineering courses. The students execute projects in teams consisting of seven to ten students developing software for a real customer. Students spend more than 150 hours each on the project. The main stakeholders of the projects are the project team customer and mentor. The mentor represents the course personnel and provides practical guidance for the project team during the project. During the course the students are supported by mentoring and experience exchange sessions. While laborious the course is consistently ranked in the top three in the CS curriculum by the students.;
Proceedings of the First International Workshop on Software Engineering Education Based on Real-World Experiences;Software engineering is a highly multidisciplinary effort that plays a core role in today's complex systems of systems. Students need breadth and depth exposure to classroom projects based on substantial real-world problems but in a way that is manageable for them and the instructor. This work showcases a holistic approach to an extensive student-friendly Java simulation architecture for an air-traffic-control system. It addresses weaknesses and preconceived notions among students to help them understand define connect manipulate and evaluate the endless dots among vast complex resources in an intentionally unfamiliar problem domain.;
On explaining intuitiveness of software engineering techniques with user experience concepts;This paper attempts to explain intuitiveness of software engineering techniques with user experience (UX) concepts. It describes a model of relationships between intuitiveness of software techniques and refined understanding of UX for software technology. It covers both intuitiveness at the starting point and the dynamics of transforming episodic UX to cumulative UX and perception of intuitiveness. Then it discusses potential application of this model. Finally it presents examples of explanations resulting from the model.;
Proceedings of the International Conference on Multimedia Interaction Design and Innovation;As software becomes more ubiquitous and complex the cost of software bugs continues to grow at a staggering rate. To remedy this situation there needs to be major improvement in the knowledge and application of software validation techniques. Although there are several software validation techniques software testing continues to be one of the most widely used in industry. The high demand for software engineers in the next decade has resulted in more software engineering (SE) courses being offered in academic institutions. However due to the number of topics to be covered in SE courses little or no attention is given to software testing resulting in students entering industry with little or no testing experience.We propose a minimally disruptive approach of integrating software testing into SE courses by providing students access to a collaborative learning environment containing learning materials on testing techniques and testing tools. In this article we describe the learning environment and the studies conducted to measure the benefits accrued by students using the learning environment in the SE courses.;
Understanding the tenets of agile software engineering: lecturing exploration and critical thinking;"The use of agile principles and practices in software development is becoming a powerful force in today's workplace. In our quest to develop better products therefore it is imperative that we strive to learn and understand the application of agile methods principles and techniques to the software development enterprise. Unfortunately in many educational institutions courses and projects that emphasize agile software development are minimal. At best students have only limited exposure to the agile philosophy principles and practices at the graduate and undergraduate levels of education. In an effort to address this concern we offered an advanced graduate-level course entitled Agile Software Engineering"" in the Department of Computer Science at Virginia Tech. The primary objectives of the course were to introduce the values principles and practices underlying the agile philosophy and to do so in an atmosphere that encour-ages debate and critical thinking. The course was designed around three central components: (1) teaching the essentials of how one develops a product within an agile framework (2) having invited talks by notable industry experts and (3) having students present and discuss current agile research topics and issues. This paper describes our experiences during the offering of that course and in particular the unique perspectives of the class instructor the teaching assistant and a student who was enrolled in the course.""";
Proceedings of the 43rd ACM Technical Symposium on Computer Science Education;Student evaluations of teaching (SET) are commonly used in universities for assessing teaching quality. However previous literature shows that in software engineering students tend to rate certain topics higher than others: In particular students tend to value programming and software construction over software design software engineering models and methods or soft skills. We hypothesize that these biases also play a role in SET responses collected from students. The objective of this study is to investigate how the topic of a software engineering course affects the SET metrics. We accomplish this by performing multilevel regression analysis on SET data collected in a software engineering programme. We analyzed a total of 1295 student evaluations from 46 university courses in a Finnish university. The results of the analysis verifies that the student course evaluations exhibit similar biases as distinguished by previous software engineering education research. The type of the course can predict a higher SET rating. In our dataset software construction and programming courses received higher SET ratings compared to courses on software engineering processes models and methods.;
Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training;Many fields of study within computer science have benefited from the adoption of community-wide benchmarks and competitions. Software engineering has yet to fully embrace this approach. Case studies of existing uses of these techniques are presented and a hypothetical application to software engineering based on research presented in last year's FSE are elaborated.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;The primary objective of this research is to examine the advantages of combining microlearning with specific gamification elements in an academic setting and to gain a better understanding of how microlearning and gamification aid computer science students in comprehending and expanding their knowledge of project management-related topics.  Implementing microlearning methods and gamification-specific aspects in two of our faculty's courses increased students' engagement performance and retention of knowledge according to our research.  In addition students felt more driven to participate in online course discussions.;
Proceedings of the 4th International Workshop on Education through Advanced Software Engineering and Artificial Intelligence;Cyber-physical systems e.g. autonomous cars or trains interact with their physical environment. As a consequence they commonly have to coordinate with other systems via complex message communication while realizing safety-critical and real-time tasks. As a result those systems should be correct by construction. Software architects can achieve this by using the MechatronicUML process and language. This paper presents the MechatronicUML Tool Suite that offers unique features to support the MechatronicUML modeling and analyses tasks.;
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering;Privacy requirements have become increasingly important as information about us is continuously accumulated and digitally stored. However despite the many proposed methodologies and tools to address these requirements privacy engineering is often underperformed in most domains of the software industry. Two of the major reasons underlying this under-performance are (1) the low expertise and understanding of privacy by the two main actors in requirements engineering: users and analysts and (2) the fact that software developers often do not perceive privacy requirements as a priority for their companies thus neglecting to meet these requirements even when they do have the required knowledge skills and supporting tools to do so. To address these two problems we propose to integrate knowledge from software engineering and organizational psychology in an iterative customizable socio-technical environment. Such environment has the potential to support the design of systems by providing technical tools for eliciting modeling and designing privacy aspects thus addressing the knowledge gap of both data subjects and analysts and social mechanisms for achieving a supportive and sustainable organizational privacy climate within a company thus reorienting the organizational attention and engagement toward addressing privacy requirements.;
Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering;This vision paper discusses the challenges of integrating the analysis of multiple Non-Functional Properties (NFP) in the model-driven software engineering process where formal analysis models are generated by model transformations from annotated software models. The paper proposes an integration approach based on an ecosystem of inter-related heterogeneous modeling artifacts intended to support consistent co-evolution of the software and analysis models cross-model traceability incremental propagation of changes across models and (semi)automated software process steps. Another goal is to investigate new metaheuristics approaches for reducing the size of the design space to be explored in the search for a design solution that will meet all the non-functional requirements.;
Proceedings of the 2015 Workshop on Challenges in Performance Methods for Software Development;The intersection of video games and software engineering is not yet well understood. This paper highlights the varied and exciting opportunities available at the intersection of these two disciplines. We investigate four main areas: the development of games how they are designed how middleware supports the creative process and how games are tested. We hope that it inspires readers to take on the challenges available in games and software engineering and join together to create a vibrant community.;
Proceedings of the 1st International Workshop on Games and Software Engineering;Context: In software project management the decision-making process is a complex set of tasks largely based on human relations and individual knowledge and cultural background. The factors that affect the decisions of the software project managers (SPMs) as well as their potential consequences require attention because project delays and failures might be related to a series of poor decisions. Goals: To understand how SPMs make decisions based on how they interpret their experiences in the workplace. Further to identify antecedents and consequences of those decisions in order to increase the effectiveness of project management. We also aim to refine the research design for future investigations. Method: Semi-structured interviews were carried out with SPMs within a Brazilian large governmental organization and a Brazilian large private organization. Results: We found that decision-making in software project management is based on knowledge sharing in which the SPM acts as a facilitator. This phenomenon is influenced by individual factors such as experience knowledge personality organizational ability communication negotiation interpersonal relationship and systemic vision of the project and by situational factors such as the autonomy of the SPM constant feedback and team members' technical competence. Conclusions: Due to the uncertainty and dynamism inherent to software projects the SPMs focus on making monitoring and adjusting decisions in an argument-driven way. From the initial relationships among the identified factors the research design was refined.;
Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Component-based software engineering (CBSE) has become a commonly used development technique. Using it applications are composed of reusable components with well defined interfaces and behavior.Currently in the scope of CBSE research has been driven in huge number of directions and by many research teams. Naturally such conditions are ideal for mutual cooperation and collaboration.In this paper we describe our experience with research cooperation especially in the scope of Europe. We present experience gained during recent joint projects in which we have participated. Also we present our research areas and topics and ongoing work on them.;
Proceedings of the 2008 International Workshop on Software Engineering in East and South Europe;We introduce a new metric Value of Service (VoS) which enables resource management techniques for high-performance computing (HPC) systems to take into consideration the value of completion time of a task and the value of energy used to compute that task at a given instant of time. These value functions have a soft-threshold where the value function begins to decrease from its maximum value and a hard-threshold where the value function goes to zero. Each task has an associated importance factor to express the relative significance among tasks. We define the value of a task as the weighted sum of its value of performance and value of energy multiplied by its importance factor. We also consider the variation in value for completing a task at different time the value of energy reduction can change significantly between peak and non-peak periods. We define VoS for a given workload to be sum of the values for all tasks that are executed during a given period of time. Our system model is based on virtual machines (VMs) where each dynamically arriving task will be assigned to a VM with a resource configuration based on number of homogenous cores and amount of memory. Based on VoS we design evaluate and compare different resource management heuristics. This comparison is done over various simulation scenarios and example experiments on an IBM blade server based system.;
Proceedings of the ACM 7th Workshop on Scientific Cloud Computing;Today's cyberphysical systems are increasingly prone to misuse. To secure existing and future software systems introducing concepts of IT-Security and Secure Software Engineering (SecSE) in Software Engineering (SE) courses is essential for academic education of future software engineers. This is not only important for computer science students but also for engineering students studying topics of computing and SE. However only little research exists on integrating these topics into traditional SE courses especially for engineering students in non-computer science majors. To narrow this gap this paper contributes with the design and evaluation of an exercise on modeling misuse cases alongside use cases based on the inductive teaching method problem-based learning (PBL). The exercise is part of an educational design research investigating which learning content and teaching methods are suitable for integrating IT-Security and SecSE topics into traditional SE education of engineering students to convey factual knowledge as well as raise awareness and interest for both topics during software development. We present the integration of the exercise design into a traditional SE course for engineering students and its evaluation to examine its suitability. We evaluated the exercise design regarding the suitability of the design components the learning content of misuse cases and the intended learning goals as well as its impact on students' motivation and their interest in IT-security. The paper then presents indications on the feasibility and success of the exercise design for teaching misuse cases to engineering students and sparking their interest in IT-Security.;
Proceedings of the 27th ACM Conference on on Innovation and Technology in Computer Science Education Vol. 1;Context: The authors wanted to assess whether the quality of published human-centric software engineering experiments was improving. This required a reliable means of assessing the quality of such experiments. Aims: The aims of the study were to confirm the usability of a quality evaluation checklist determine how many reviewers were needed per paper that reports an experiment and specify an appropriate process for evaluating quality. Method: With eight reviewers and four papers describing human-centric software engineering experiments we used a quality checklist with nine questions. We conducted the study in two parts: the first was based on individual assessments and the second on collaborative evaluations. Results: The inter-rater reliability was poor for individual assessments but much better for joint evaluations. Four reviewers working in two pairs with discussion were more reliable than eight reviewers with no discussion. The sum of the nine criteria was more reliable than individual questions or a simple overall assessment. Conclusions: If quality evaluation is critical more than two reviewers are required and a round of discussion is necessary. We advise using quality criteria and basing the final assessment on the sum of the aggregated criteria. The restricted number of papers used and the relatively extensive expertise of the reviewers limit our results. In addition the results of the second part of the study could have been affected by removing a time restriction on the review as well as the consultation process.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;Most of the research-oriented computer science departments provide software engineering education. Providing up-to-date software engineering education can be problematic as practises used in modern software development companies have been developed in the industry and as such do not often reach teachers in university contexts. The danger and often the unfortunate reality is that institutions giving education in software engineering end up teaching the subject using outdated practices with technologies no longer in use. In this article we describe a three-year design-based research where the goal has been to design and reform a software engineering subtrack within our bachelor curriculum that would make it possible for the students to have strong up-to-date theoretical and practical skills in software engineering without a need to remove any of the existing theoretical aspects.;
Proceedings of the 13th Annual Conference on Information Technology Education;Software processes must be customized based on the project and the team working on the project. This paper discuss our use of agile software processes in an introduction to software engineering course. An overview of the strengths and weaknesses of tools used in the course over the years is given. We then present a new web application for software engineering courses;
Not going to take this anymore: multi-objective overtime planning for software engineering projects;Software Engineering and development is well- known to suffer from unplanned overtime which causes stress and illness in engineers and can lead to poor quality software with higher defects. In this paper we introduce a multi-objective decision support approach to help balance project risks and duration against overtime so that software engineers can better plan overtime. We evaluate our approach on 6 real world software projects drawn from 3 organisations using 3 standard evaluation measures and 3 different approaches to risk assessment. Our results show that our approach was significantly better (p &lt 0.05) than standard multi-objective search in 76% of experiments (with high Cohen effect size in 85% of these) and was significantly better than currently used overtime planning strategies in 100% of experiments (with high effect size in all). We also show how our approach provides actionable overtime planning results and inves- tigate the impact of the three different forms of risk assessment.;
Proceedings of the 2013 International Conference on Software Engineering;As a new contribution to Value-based V&ampV process development a systematic and multi-criteria process is proposed to quantitatively determine the Value-based V&ampV artifact priority that reviewers can follow for their reviews. This process enables reviewers to prioritize artifacts to be reviewed in a more cost-effective way based on more sophisticated and comprehensive factors such as importance quality risks dependency and cost of V&ampV investments. Some qualitative and quantitative evidence is provided from a comparative experiment with 22 real-client e-services projects over two years of a graduate software engineering team-project course. It shows that the value-based artifact prioritization enabled reviewers to better focus on artifacts with high importance and risks to capture issues with high impact in a timely manner and to improve the cost-effectiveness of reviews.;
Proceedings of the 2011 International Conference on Software and Systems Process;Students in software engineering need experiences that prepare them for a global work environment that is more and more likely to be structured around team work in which team members may come from a variety of disciplines and cultures and be geographically dispersed. New grads in software engineering are more and more likely to communicate with team members and managers solely via electronic means (e.g. teleconference videoconference e-mail e-file sharing). This paper describes a highly successful international collaboration of students from two universities enrolled in undergraduate software engineering classes one in the USA and the other in India. Within a semester these students collaborated remotely to produce software for a leading international software development company. This collaboration repeated for two semesters and planned for a third met all learning objectives while successfully producing the desired software. This experience truly engaged our students and enabled the students to learn via a standard course in software engineering about many aspects of professional practice without resorting to special programs like co-op/internships honors/research independent study or capstones.;
Proceedings of the 40th ACM Technical Symposium on Computer Science Education;"The emergence of inexpensive parallel computers powered by multicore chips combined with stagnating clock rates raises new challenges for software engineering. As future performance improvements will not come for free"" from increased clock rates performance critical applications will need to be parallelized. However little is known about the engineering principles for parallel general-purpose applications.This paper presents an experience report with four diverse case studies on multicore software development for general-purpose applications. They were programmed in different languages and benchmarked on several multicore computers. Empirical findings include: 1) Multicore computers deliver: Real speedups are achievable albeit with significant programming effort and speedups that are typically lower than the number of cores employed 2) Massive refactoring of sequential programs is required sometimes at several levels. Special tools for parallelization refactorings appear to be an important area of research 3) Autotuning is indispensable as manually tuning thread assignment number of pipeline stages size of data partitions and other parameters is difficult and error prone 4) Architectures that encompass several parallel components are poorly understood. Tuneable architectural patterns with parallelism at several levels need to be discovered.""";
Proceedings of the 1st International Workshop on Multicore Software Engineering;Today's generation of software developers frequently make use of social media either as an adjunct or integrated into a wide range of tools ranging from code editors and issue trackers to IDEs and web-based portals. The role of social media usage in software engineering is not well understood and yet the use of these mechanisms influences software development practices. In this position paper we advocate for research that strives to understand the benefits risks and limitations of using social media in software development at the team project and community levels. Guided by the implications of current tools and social media features we propose a set of pertinent research questions around community involvement project coordination and management as well as individual software development activities. Answers to these questions will guide future software engineering tool innovations and software development team practices.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;Background: Metamorphic testing emerges as a simple and effective approach for testing scientific software yet its adoption in actual scientific software projects is less studied.Aims: In order for the practitioners to better adopt metamorphic testing in their projects we set out to first gain a deep understanding about the current qualify assurance workflow testing practices and tools.Method: We propose to integrate various empirical sources including artifact analysis stakeholder interviews and gap analysis from the literature.Results: Applying our approach to the Open Water Analytics Stormwater Management Model project helped to identify four new needs requiring continued and more research: (1) systematic and explicit formulation of metamorphic relations (2) metamorphic testing examples specific to the scientific software (3) correlating metamorphic testing with regression testing and (4) integrating metamorphic testing with build tools like CMake and continuous integration tools like GitHub Actions.Conclusions: Integrating different empirical sources is promising for establishing a contextual understanding of software engineering practices and for action research such as workflow refinements and tool interventions to be carried out in a principled manner.;
Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Exploring the source code of a software system is a prevailing task that is frequently done by contributors to a system. Practitioners often use call graphs to aid in understanding the source code of an inadequately documented software system. Call graphs when visualized show caller and callee relationships between functions. A static call graph provides an overall structure of a software system and dynamic call graphs generated from dynamic execution logs can be used to trace program behaviour for a particular scenario. Unfortunately a call graph of an entire system can be very complicated and hard to understand. Hierarchically abstracting a call graph can be used to summarize an entire systemâ€™s structure and more easily comprehending function calls. In this work we mine concepts from source code entities (functions) to generate a concept cluster tree with improved naming of cluster nodes to complement existing studies and facilitate more effective program comprehension for developers. We apply three different information retrieval techniques (TFIDF LDA and LSI) on function names and function name variants to label the nodes of a concept cluster tree generated by clustering execution paths. From our experiment in comparing automatic labelling with manual labeling by participants for 12 use cases we found that among the techniques on average TFIDF performs better with 64% matching. LDA and LSI had 37% and 23% matching respectively. In addition using the words in function name variants performed at least 5% better in participant ratings for all three techniques on average for the use cases.;
Proceedings of the 15th Innovations in Software Engineering Conference;Project management is important for the success of a software project. Enhancing software project management effectiveness measurements should lead the project manager to advance practices that contribute to the successful development of software projects. This study aims to enhance project management effectiveness measurements in the direction of increase the likelihood of software project success. An enhanced evaluation model of software project management effectiveness has been proposed in this study. Correspondingly the model fed into a developed software project management effectiveness evaluation tool. This measurement tool helps software development managers to evaluate monitor and improve project management effectiveness in software projects. The developed software project management effectiveness evaluation tool has been validated by a feedback survey. Feedback survey participants have been demonstrated the importance of the developed project management effectiveness measurement tool.;
Proceedings of the 9th International Conference on Software and Information Engineering;This technical briefing provides an overview of how quantitative empirical research methods can be combined with qualitative ones generating the family of empirical software engineering approaches known as mixed-methods. The ultimate aim of such mixed-methods is supporting cause-effect claims combining multiple data types sources and analyses that provide software practitioners and academicians solid rationale and practical value to research results. This briefing offers lessons we learned in instrumenting and executing mixed-methods approaches for the benefit of the goal above.;
Proceedings of the 39th International Conference on Software Engineering Companion;Context: Software Engineering (SE) community has empirically investigated software defect prediction as a proxy to benchmark it as a process improvement activity to assure software quality. In the domain of software fault prediction the performance of classification algorithms is highly provoked with the residual effects attributed to feature irrelevance and data redundancy issues. Problem: The meta-learning-based ensemble methods are usually carried out to mitigate these noise effects and boost the software fault prediction performance. However there is a need to benchmark the performance of meta-learning ensemble methods (as fault predictor) to assure software quality control and aid developers in their decision making. Method: We conduct an empirical and comparative study to evaluate and benchmark the improvement in the fault prediction performance via meta-learning ensemble methods as compared to their component base-level fault predictors. In this study we perform a series of experiments with four well-known meta-level ensemble methods Vote StackingC (i.e. Stacking) MultiScheme and Grading. We also use five high-performance fault predictors Logistic (i.e. Logistic Regression) J48 (i.e. Decision Tree) IBK (i.e. k-nearest neighbor) NaiveBayes and Decision Table (DT). Subsequently we performed these experiments on public defect datasets with k-fold (k=10) cross-validation. We used F-measure and ROC-AUC (Receiver Operating Characteristic-Area Under Curve) performance measures and applied the four non-parametric tests to benchmark the fault prediction performance results of meta-learning ensemble methods. Results and Conclusion: we conclude that meta-learning ensemble methods especially Vote could outperform the base-level fault predictors to tackle the feature irrelevance and redundancy issues in the domain of software fault prediction. Having said that their performance is highly related to the number of base-level classifiers and the set of software fault prediction metrics.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;This paper presents work practice data of the daily activities of software engineers. Four separate studies are presented one looking longitudinally at an individual SE two looking at a software engineering group and one looking at company-wide tool usage statistics. We also discuss the advantages in considering work practices in designing tools for software engineers and include some requirements for a tool we have developed as a result of our studies.;
CASCON First Decade High Impact Papers;The skills to effectively manage software development teams and to productively interact with a project manager are important in the computing professions. Teaching these skills in a traditional academic setting however is challenging. To support the experiential learning of these skills we established a collaboration between two computing courses a sophomore-level one and a senior-level one where the seniors serve as managers of teams of sophomores on a semester-long project. This paper describes the collaboration and evaluates it in terms of student learning and experience based on three iterations of that collaboration. The associated course materials and evaluation instruments are made publicly available.;
Proceedings of the 50th ACM Technical Symposium on Computer Science Education;Introduction of a non-thesis Master of Science in Software Engineering program in Turkey is discussed along with its relations to industry. New programs in Software Engineering are flourishing in Turkey and their influence is interesting to discuss along the peculiarities of the country as presented in this article. Turkey delivers rather quality software products in non-trivial domains but could not catch the success levels of India and some other small countries especially in mass development. With well trained engineers and its proximity to Europe the capability to invite once missed IT boom opportunity depends partially on the maturity of the software industry. This article presents the first graduate degree program in Software Engineering as a tool for the transitioning of the industry.;
Proceedings of the 2008 International Workshop on Software Engineering in East and South Europe;Project Expression is a course designed to attract students into the field of computing. Participants are trained in Java programming and the art of multimedia production. By implementing a wide range of apps they learn cloud communication techniques in a software environment. The course focuses on a digital film project and participants are challenged with creating a movie that expresses an idea opinion or belief relative to society. The film project is a landscape for learning cloud-computer-programming and reaches across the computer spectrum with engaging activities that stimulate creative design. This study examines the curriculum's approach and measures its effectiveness to teach the cloud-computing mentality. It emphasizes the importance of empathy in a technology-based society. Furthermore it investigates whether or not such a course is an effective method for attracting students into the field of computing.;
Proceedings of Alice Symposium on Alice Symposium;Software engineering is a very important course in computer science program. In our software engineering education we have adopted group-based projects as an approach to improve students' learning experience. The group-based collaborative projects will not only enhance student problem solving and critical thinking skills but also will increase student motivation confidence and resilience. This paper discusses our small-group-based approach in our software engineering course.;
Understanding collaborative software development: an interview study;In globally distributed software development many software developers have to collaborate and deal with issues of collaboration. Although collaboration is challenging collaborative development produces better software than any developer could produce alone. Unlike previous work which focuses on the proposal and evaluation of models and tools to support collaborative work this paper presents an interview study aiming to understand (i) the motivations (ii) how collaboration happens and (iii) the challenges and barriers of collaborative software development. After interviewing twelve experienced software developers from GitHub we found different types of collaborative contributions such as in the management of requests for changes. Our analysis also indicates that the main barriers for collaboration are related to non-technical rather than technical issues.;
Proceedings of the 15th International Conference on Global Software Engineering;In this paper we describe the use of Scrum in an upper-division software engineering quarter-length course. We describe tools used to support both the use of Scrum and the overall objectives of an introductory course in software engineering. We do this to provide support for others who want to teach an introductory software engineering course in a format suitable for a course shorter than the typical semester-length course.;
The Influence of Cost Drivers on Effort Estimation in Distributed Software Development;Nowadays software projects are a vital element in any organizationâ€™s success. It plays the highest role in the organizationâ€™s success in most cases. Hence its main focus is to earn more money on a project and minimize the developing time cost. Sometimes due to unavailability of experts may decrease the profit of the organization. Thus the organization comes with these types of issues. They want to increase the profit and decrease the development time and on fewer budgets hire the more expert people to achieve the organizationâ€™s goal. For this purpose they are applying the new development approach called GSD (global software development). Through global software development they develop their project on a reasonable budget and maximize profit. However in GSD other challenges of team communication coordination geographical location and cultural and time zone differences increase the projectâ€™s effort. This paper shows the more critical factors in GSD and the more challenging and shows their impact. They are more challenging on which project manager or team leader more focus on these factors which can be more helpful for the projectâ€™s success. This paper is more helpful for both industries and researchers in that they can easily estimate the effort in the context of GSD.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;Context: Sustainability has become an important topic for researchers and is gaining popularity among software development companies but integrating it into their development processes is still lacking.&nbspObjectives: This paper aimed to discuss the purpose of doctoral research the research questions the steps to answer the research questions and the research's current progress concerning sustainability in the software development life cycle.Results: I have presented the high-level plans for the doctoral research and outlined the first part of the results of phase 1. As part of this phase 1 I have conducted an extensive literature review to collect data about sustainability in companies' agile methods. I found only a few studies reporting sustainability in agile software development and this finding proposes that either this field was not studied or the results have not been widely published indicating a gap in research.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;This paper describes our experience of using open source software systems in teaching a graduate level software engineering course. The motivation of this course the course structure the assessment and the outcomes are discussed. The comparative results using different approaches are also presented.;
Proceedings of the 48th Annual ACM Southeast Conference;LISE is a multidisciplinary project involving lawyers and computer scientists with the aim to put forward a set of methods and tools to (1) define software liability in a precise and unambiguous way and (2) establish such liability in case of incident. This paper provides an overview of the overall approach taken in the project based on a case study. The case study illustrates a situation where in order to reduce legal uncertainties the parties to a contract wish to include in the agreement specific clauses to define as precisely as possible the share of liabilities between them for the main types of failures of the system.;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1;This article analyzes the main body of the dual-channel supply chain value creation based on the summary of the existing literature defines the value creation of the online and offline dual-channel supply chain from three measurement dimensions and divides the 15 measurement elements into hierarchical levels find the path of influence between different elements and provide a theoretical basis for the integration of the dual-channel supply chain.;
Proceedings of the 2021 4th International Conference on E-Business Information Management and Computer Science;Everyone who develops software knows that it is a complex and risky business and its participants are always on the lookout for new ideas that will lead to better software. Fortunately software engineering is still a young and growing profession that sees innovations and improvements in best practices every year. Just look for example at the improvements and benefits that lean and agile thinking have brought to software-development teams.;
Everything is INTERRELATED: teaching software engineering for sustainability;Sustainability has become an important concern across many disciplines and software systems play an increasingly central role in addressing it. However teaching students from software engineering and related disciplines to effectively act in this space requires interdisciplinary courses that combines the concept of sustainability with software engineering practice and principles. Yet presently little guidance exist on which subjects and materials to cover in such courses and how combined with a lack of reusable learning objects. This paper describes a summer school course on Software Engineering for Sustainability (SE4S). We provide a blueprint for this course in the hope that it can help the community develop a shared approach and methods to teaching SE4S. Practical lessons learned from delivery of this course are also reported here and could help iterate over the course materials structure and guidance for future improvements. The course blueprint availability of used materials and report of the study results make this course viable for replication and further improvement.;
Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training;Today's software projects are often distributed across multiple locations. This distribution poses new challenges produced by the cooperation across different countries times zones and cultures. Software engineering courses have to prepare students accordingly. This paper reports an experience on teaching a distributed software engineering course. In this course students develop software in collaboration with five universities located in Italy Hungary Russia Switzerland and Ukraine. The projects allow students to face the difficulties of developing software in a globalized context and provide a practical experience on distributed software engineering. We describe the major obstacles on organizing such a course and we suggest best practices to achieve successful outcome.;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1;Small organizations have been claimed to manage their requirements in ways that bear no relation to what the textbooks say and what is taught in undergraduate courses. This paper explores software engineering (SE) practices in five small and medium-sized organizations in order to gain a deeper understanding on how cooperative and human aspects of the SE-related practices differ in small organizations compared to the larger ones. The paper illustrates in detail the central role of human collaboration in small organizations and the challenges an organization meets when it begins to grow and lose opportunities for face-to-face collaboration. The findings of this study suggest that studies on using social media are a valuable addition to software engineering research agenda.;
Proceedings of the 2010 ICSE Workshop on Cooperative and Human Aspects of Software Engineering;The success of software engineering projects largely depends on complex decision-making. For example which tasks should a developer do first who should perform this task is the software of high quality is a software system reliable and resilient enough to deploy etc. However erroneous decision-making for these complex questions is costly in terms of money and reputation. Thus Artificial Intelligence/Machine Learning (AI/ML) techniques have been widely used in software engineering for developing software analytics tools and techniques to improve decision-making developer productivity and software quality. However the predictions of such AI/ML models for software engineering are still not practical (i.e. coarse-grained) not explainable and not actionable. These concerns often hinder the adoption of AI/ML models in software engineering practices. In addition many recent studies still focus on improving the accuracy while a few of them focus on improving explainability. Are we moving in the right direction? How can we better improve the SE community (both research and education)?In this tutorial we first provide a concise yet essential introduction to the most important aspects of Explainable AI and a hands-on tutorial of Explainable AI tools and techniques. Then we introduce the fundamental knowledge of defect prediction (an example application of AI for Software Engineering). Finally we demonstrate three successful case studies on how Explainable AI techniques can be used to address the aforementioned challenges by making the predictions of software defect prediction models more practical explainable and actionable. The materials are available at https://xai4se.github.io.;
Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering;Abstraction is a basic foundation and a powerful means in science and engineering such as philosophy mathematics cognitive informatics computing and software engineering because any complex inference process is based on it. A Hierarchical Abstraction Model (HAM) is presented in this paper which elaborates the five levels of abstraction known as the analogue objects diagrams natural languages professional notation systems and mathematics. On the basis of the HAM model main roles of abstraction in software engineering are explained and a number of fundamental principles for software engineering practice are derived. The cognitive constraints limitations of conventional descriptive means and modeling methodologies as well as the need for more powerful denotational mathematics for software engineering are identified.;
Proceedings of the 2nd International Workshop on The Role of Abstraction in Software Engineering;A sound Decision-Making (DM) process is key to the successful governance of software projects. In many Open Source Software Development (OSSD) communities DM processes lie buried amongst vast amounts of publicly available data. Hidden within this data lie the rationale for decisions that led to the evolution and maintenance of software products. While there have been some efforts to extract DM processes from publicly available data the rationale behind 'how' the decisions are made have seldom been explored. Extracting the rationale for these decisions can facilitate transparency (by making them known) and also promote accountability on the part of decision-makers. This work bridges this gap by means of a large-scale study that unearths the rationale behind decisions from Python development email archives comprising about 1.5 million emails. This paper makes two main contributions. First it makes a knowledge contribution by unearthing and presenting the rationale behind decisions made. Second it makes a methodological contribution by presenting a heuristics-based rationale extraction system called Rationale Miner that employs multiple heuristics and follows a data-driven bottom-up approach to infer the rationale behind specific decisions (e.g. whether a new module is implemented based on core developer consensus or benevolent dictator's pronouncement). Our approach can be applied to extract rationale in other OSSD communities that have similar governance structures.;
Proceedings of the 43rd International Conference on Software Engineering;Background The emergence of the COVID-19 pandemic has impacted all human activity including software development. Early reports seem to indicate that the pandemic may have had a negative effect on software developers socially and personally but that their software development productivity may not have been negatively impacted. Aims: Early reports about the effects of the pandemic on software development focused on software developers' well-being and on their productivity as employees. We are interested in a different aspect of software development: the developers' public contributions as seen in GitHub and Stack Overflow activities. Did the pandemic affect the developers' public contributions and of so in what way? Method: Considering the data from between 2017 and till 2020 we study the trends within GitHub's push create pull request and release events and within Stack Overflow's new users posts votes and comments. We performed linear regressions correlation analyses outlier analyses hypothesis testing and we also contacted individual developers in order to gather qualitative insights about their unusual public contributions. Results: Our study shows that within GitHub and Stack Overflow the onset of the pandemic (March/April 2020) is reflected in a set of outliers in developers' contributions that point to an increase in activity. The distributions of contributions during the entire year of 2020 were in some aspects different but in other aspects similar from the recent past. Additionally we found one noticeably disrupted pattern of contribution in Stack Overflow namely the ratio Questions/Answers which was much higher in 2020 than before. Testimonials from the developers we contacted were mixed: while some developers reported that their increase in activity was due to the pandemic others reported that it was not. Conclusion: In Github there was a noticeable increase in public software development activity in 2020 as well as more abrupt changes in daily activities in Stack Overflow there was a noticeable increase in new users and new questions at the onset of the pandemic and in the ratio of Questions/Answers during 2020. The results may be attributed to the pandemic but other factors could have come into play.;
Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);"The RESER workshop provides a venue in which empirical software engineering researchers can discuss the theoretical foundations and methods of replication as well as present the results of specific replicated studies. In 2011 the workshop co-located with the International Symposium on Empirical Software Engineering and Measurement (ESEM) in Banff Alberta Canada. In addition to several outstanding paper sessions highlights of the 2011 workshop included a keynote address by Dr. Victor R. Basili in which he addressed the question What's so hard about replication of software engineering experiments?"" The workshop also featured a joint replication panel session discussing the first cooperative joint replication ever conducted in empirical software engineering research and a planning session for next year's joint replication project addressing Conway's Law.""";
Towards Effective Technical Debt Decision Making in Software Startups;Context: Technical Debt (TD) is a metaphor used to describe outstanding software maintenance tasks or shortcuts made in the software development to achieve short-term benefits (i.e. time to market) but negatively impact the software quality in the long term. TD is quite common in a software startup which is characterized as a young company with low resources and a small client base aiming to accelerate time to market. Decisions related to TD can be critical for startup success. Objective: I aim to understand the relationship between TD decisions and the success or failure of software startups and explore the best practices related to TD decisions that would better contribute to the startup success. Method: I plan to apply multiple retrospective case studies in different software startups that succeed or failed to pass the startup period and become a mature organization. Semi structured interviews will be used to collect data from the team who was involved in the software development in the startup era. Contribution: The outcome of this study will help software founders/entrepreneurs to make effective TD decisions during the startup timeframe that can better contribute to the startup success and decrease the risk of the startup failure.;
Change-oriented software engineering;We propose a first-class change model for Change-Oriented Software Engineering (COSE). Based on an evolution scenario we identify a lack of support in current Interactive Development Environments (IDEs) to apply COSE. We introduce a set of five extensions to an existing model of first-class changes and describe the desired behaviour of change-oriented IDEs to support COSE. With the help of an evolution scenario we show why those extensions are required. Finally we describe ChEOPS: a prototypical implementation of a change-oriented IDE on top of VisualWorks and illustrate how it supports the extended first-class change model. ChEOPS is finally used to validate COSE as a solution for the shortcomings of existing IDEs.;
Proceedings of the 2007 International Conference on Dynamic Languages: In Conjunction with the 15th International Smalltalk Joint Conference 2007;Identity management refers to authentication sharing of personally identifiable information (PII) and provision of mechanisms protecting the privacy thereof. The most commonly implemented is federated authentication permitting users to maintain a single set of credentials to access many services. Specifications exist for profile exchange between a service provider (SP) and the identity provider (IdP) but are rarely used. Most frequently local storage of profile data is utilised due to security and privacy concerns. Key work in this area includes that of the PRIME project which provides privacy enhancing identity management [1]. Their work utilises local data stores and/or trusted third parties.;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2;Computer science is a rapidly changing field with new tools and products introduced almost daily. The software developer whether beginning student or seasoned professional must not only have a good background on the fundamentals but must also be able to keep up with the latest trends and techniques through research education and practice. This paper addresses this issue in terms of student learning and discusses the issue of currency as it relates to student learning materials such as textbooks.;
Real world experiences in a software engineering course;How can we get students to understand software engineering? This is the basic question we will try to answer in this paper. We describe a course in which students learn about and use software engineering principles to create a software system that will be used in an actual setting. In this paper we describe this course and document our experience across several terms. In addition we describe the software system implemented as this has relevance to the process of accreditation. In the context of continuous improvement the experiences represent lessons learned for ongoing offerings of the course. Our goal is to offer a course where students are engaged in a project where the only way to accomplish the goals for the course are to use the methodologies studied in class. The purpose of this paper is to document how we teach this software engineering course and also to document our experiences with students in the course.;
Proceedings of the 2010 ACM Conference on Information Technology Education;This paper details a computer programming class update for all education levels. As technology has become a more integral part of elementary and secondary education curriculum the skilled programmer has become more commonplace. Students graduating from high school may by that time have been programming for as many as three years. As the IT field develops and spawns sub fields the role of the programmer remains important. However new development methods deal more with creating systems from components. The philosophy change here creates a need for IT professionals who can design and create applications from a user's perspective rather than a computer's perspective [2]. This can be addressed by adding software development principles to the content by going beyond code and helping students visualize the entire process. This change will provide each student with the skills necessary to become successful both in further academic pursuits and in their career. This proposed curriculum will contain Software Engineering processes such as requirements elicitation and management establishing scope and system boundaries modeling test procedures and maintenance activities. The proposed class contains all programming course information while introducing software engineering activities to students in the beginning of their programming education. Instead of simply recreating sample programs a complete problem will be presented. Students decide what processes need to be automated how to go about implementing them how to tell if the problem has been solved (test case) and finally create verify and validate their program. Having students go through these steps will provide them with a better understanding of where computer programming fits in the scope of an IT project and will prepare them for the challenges they will face in a technological environment. This paper will present an overview of course content for this new class as well as strategies and examples for taking current computer programming assignments and infusing Software Engineering principles. It will provide motivation and educational strategy for a solid Software Engineering perspective while introducing programming syntax decision structures and data representations. To not unnecessarily burden a curriculum that in many institutions is already near its credit limits it is critical that programming assignments exemplify SE tenet to reinforce understanding of the material.;
Proceedings of the 10th ACM Conference on SIG-Information Technology Education;Agile methodology as a relatively new approach to software engineering is becoming more popular in both industry and academia. Learning agile software development methodologies will unquestionably increase the marketability of our students as entry-level software engineers. But how agile methods should be taught at the undergraduate level in addition to traditional approaches is still being debated. The authors taught agile methods in their software engineering/senior project course for the first time in the fall of 2010. Students seemed stimulated by fresh perspectives and the lightweight processes offered by agile but implementing agile methodology in an academic environment posed unique challenges. In this paper the authors document their increased understanding of agile methodology through literature reviews the challenges learned by teaching agile methods and some potential areas for improvement.;
The design of Sweden's first 5-year computer science and software engineering program;"In 2013 Link\{o""";
Proceedings of the 45th ACM Technical Symposium on Computer Science Education;As software practitioners we can help society by using our communities of experts to address a software need of a socially-conscious organization. Doing so can benefit society in the locale of a software engineering conference and provides access to international experts for local organizations which may otherwise not have access. Furthermore established Software Engineering (SE) researchers as well as practitioners and students have the opportunity for a unique learning experience. In this paper we argue that the SE community should use SE conferences as the focal points for activities that benefit society at the locations of the conferences and make such activities an integral valued and recognized part of the conference programs. The proposed series of events termed SE Cares can follow and learn from the model of Requirements Engineering (RE) Cares events that took place in 2018 and 2019 and can be a co-located event at all interested SE-related conferences.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Society;Requirement prioritization (RP) is a method for identifying the most critical requirements that should be immediately addressed. The results show how much all parties truly understand the requirements of the project. A trustworthy requirements prioritization process can ensure that the most important requirements are in line with business needs and should be developed first. The process results in the prioritized list of requirements that support decision making in release planning and subsequent activities to maximize software quality and customer satisfaction. This paper identified strengths and weaknesses of existing RP techniques. That leads to identification of factors in selecting the appropriate RP techniques for software projects. The recommendation can lead to improvement of the existing RP techniques. In addition this paper presents the survey results of RP techniques used in participating software companies which developed software in Agile Software Development (ASD) context. The results reveal the challenges faced in their RP processes.;
Proceedings of the 4th International Conference on Computer Science and Software Engineering;Choosing the appropriate Missing Data (MD) imputation technique for a given Software development effort estimation (SDEE) technique is not a trivial task. In fact the impact of the MD imputation on the estimation output depends on the dataset and the SDEE technique used and there is no best imputation technique in all contexts. Thus an attractive solution is to use more than one single imputation technique and combine their results for a final imputation outcome. This concept is called ensemble imputation and can help to significantly improve the estimation accuracy. This paper develops and evaluates a heterogeneous ensemble imputation whose members were the four single imputation techniques: K-Nearest Neighbors (KNN) Expectation Maximization (EM) Support Vector Regression (SVR) and Decision Trees (DT). The impact of the ensemble imputation was evaluated and compared with those of the four single imputation techniques on the accuracy measured in terms of the standardized accuracy criterion of four SDEE techniques: Case Based Reasoning (CBR) Multi-Layers Perceptron (MLP) Support Vector Regression (SVR) and Reduced Error Pruning Tree (REPTree). The Wilcoxon statistical test was also performed in order to assess whether the results are significant. All the empirical evaluations were carried out over the six datasets namely ISBSG China COCOMO81 Desharnais Kemerer and Miyazaki. Results show that the use of heterogeneous ensemble-based imputation instead single imputation significantly improved the accuracy of the four SDEE techniques. Indeed the ensemble imputation technique was ranked either first or second in all contexts.;
Proceedings of the 17th International Conference on Predictive Models and Data Analytics in Software Engineering;Background: The use of Grey Literature (GL) has been investigated in diverse research areas. In Software Engineering (SE) this topic has an increasing interest over the last years. Problem: Even with the increase of GL published in diverse sources the understanding of their use on the SE research community is still controversial. Objective: To understand how Brazilian SE researchers use GL we aimed to become aware of the criteria to assess the credibility of their use as well as the benefits and challenges. Method: We surveyed 76 active SE researchers participants of a flagship SE conference in Brazil using a questionnaire with 11 questions to share their views on the use of GL in the context of SE research. We followed a qualitative approach to analyze open questions. Results: We found that most surveyed researchers use GL mainly to understand new topics. Our work identified new findings including: 1) GL sources used by SE researchers (e.g. blogs community website) 2) motivations to use (e.g. to understand problems and to complement research findings) or reasons to avoid GL (e.g. lack of reliability lack of scientific value) 3) the benefit that is easy to access and read GL and the challenge of GL to have its scientific value recognized and 4) criteria to assess GL credibility showing the importance of the content owner to be renowned (e.g. renowned author and institutions). Conclusions: Our findings contribute to form a body of knowledge on the use of GL by SE researchers by discussing novel (some contradictory) results and providing a set of lessons learned to both SE researchers and practitioners.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;In this paper we present a HOT --- Human Organizational and Technological --- framework for software engineering and describe its application in a full one-semester software engineering course on agile software development. We suggest and illustrate how this framework has the potential to widen and deepen the students' understanding of software engineering processes.;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1;Culture appears to have a greater influence on software-engineering practice than originally envisioned. Many recent studies have reported that cultural factors greatly impact global software-engineering (GSE) practice. However many of these studies characterize culture as a set of dimensions (e.g. Hofstede's) which significantly limits the meaning of culture. In this paper we discuss the limitations of such a dimensional approach to studying culture by highlighting the aspects of culture that such dimensions fail to capture. Next we present the idea of thinking of culture in terms of cultural models (inspired by Shore's work) and illustrate this idea by presenting cultural models adopted by the software-engineering domain. Then based on this idea of cultural models we present a conceptual reference framework for studying the influence of culture in the global software-engineering setting. Finally we present some examples that use this framework which illustrates the benefits of such a framework for studying culture's influence on GSE practice.;
Proceedings of the 4th International Conference on Intercultural Collaboration;A framework for professionalism produced by the International Federation for Information Processing is used to identify progress and challenges with regard to practice and education in Software Engineering. Finally recommendations are made with respect to opportunities that could be relevant in East and Southern Europe;
Proceedings of the 2008 International Workshop on Software Engineering in East and South Europe;Most programs today are written not by professional software developers but by people with expertise in other domains working towards goals for which they need computational support. For example a teacher might write a grading spreadsheet to save time grading or an interaction designer might use an interface builder to test some user interface design ideas. Although these end-user programmers may not have the same goals as professional developers they do face many of the same software engineering challenges including understanding their requirements as well as making decisions about design reuse integration testing and debugging. This article summarizes and classifies research on these activities defining the area of End-User Software Engineering (EUSE) and related terminology. The article then discusses empirical research about end-user software engineering activities and the technologies designed to support them. The article also addresses several crosscutting issues in the design of EUSE tools including the roles of risk reward and domain complexity and self-efficacy in the design of EUSE tools and the potential of educating users about software engineering principles.;
Implicit gender biases in professional software development: an empirical study;It has been well-known that the software development profession lacks gender diversity particularly in the technical leadership positions. Researchers and practitioners have spent tremendous efforts on identifying the problems and finding solutions. However most of the existing software engineering literature focuses on the explicit gender biases but ignores implicit gender biases. To fill this gap the study sought to empirically investigate whether professional software engineers hold implicit gender biases related to women in the software development profession and examine whether these implicit biases predict discriminatory decision-making. Using data from 142 professional software engineers in seven organizations our study yields a rich set of concerning findings. First we find that implicit biases were pervasive-both male and female software engineers implicitly associated software development professions particular technical leadership roles with men not women and also associated women with the home and family. Besides people often cannot resist their implicit gender biases and make decisions in gender-neutral ways while they do well in resisting their explicit gender biases.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Society;Modern complex software systems are being continuously extended and adjusted. The developers responsible for this may come from different teams or organizations and may be distributed over the world. This may make it difficult to keep track of what other developers are doing which may result in multiple developers concurrently editing the same code areas. This in turn may lead to hard-to-merge changes or even merge conflicts logical bugs that are difficult to detect duplication of work and wasted developer productivity. To address this we explore the extent of this problem in the pull-request-based software development model. We study half a year of changes made to six large repositories in Microsoft in which at least 1000 pull requests are created each month. We find that files concurrently edited in different pull requests are more likely to introduce bugs. Motivated by these findings we design implement and deploy a service named Concurrent Edit Detector (ConE) that proactively detects pull requests containing concurrent edits to help mitigate the problems caused by them. ConE has been designed to scale and to minimize false alarms while still flagging relevant concurrently edited files. Key concepts of ConE include the detection of the Extent of Overlap between pull requests and the identification of Rarely Concurrently Edited Files. To evaluate ConE we report on its operational deployment on 234 repositories inside Microsoft. ConE assessed 26000 pull requests and made 775 recommendations about conflicting changes which were rated as useful in over 70% (554) of the cases. From interviews with 48 users we learned that they believed ConE would save time in conflict resolution and avoiding duplicate work and that over 90% intend to keep using the service on a daily basis.;
Structuring variability in the context of embedded systems during software engineering;During the development of embedded software the system context (mechanical electronical business etc.) has to be considered. Typically this context is diverse and highly complex. Moreover the context in which the system is embedded can vary. For example the system can be used in different technical environments or in different countries. This variability in the context influences the software to be developed and typically leads to system variability. This paper systematically analyses the impact of context variability on the system development more precisely on the variability of the system. Related work is discussed and an example from the automotive domain is presented to identify open issues that need to be addressed.;
Proceedings of the 8th International Workshop on Variability Modelling of Software-Intensive Systems;"The Natural Programming"" project at Carnegie Mellon University has been working for more than 10 years to make programming more ""natural"" or closer to the way people think. We have addressed the needs of all kinds of programmers: novices professionals and end-user programmers. Many studies were performed which provided new insights and led to new models of programmers. From these insights and models we created new programming languages and environments. Evaluations of the resulting systems have shown that they are effective and successful. This paper provides an overview of the entire 10-year Natural Programming project but focuses on our new results since WEUSE-III in Dagstuhl.""";
Proceedings of the 4th International Workshop on End-User Software Engineering;The software development process is the software development approach with tasks activities procedures (methods and techniques) and work products. In a world where technology is increasingly needed having the skills to understand the software development process is essential. In a previous consultation with professionals who work in this area based on a survey it was identified that students trained to work in the market do not have all the necessary skills for full professional performance. Therefore this study seeks to promote a syllabus and a teaching plan for the student-centered teaching and learning process in the software process subject. For the development of this research a mapping was carried out in the ACM / IEEE computing teaching curriculum in 2013 and in the reference model for the formation of courses by the SBC in 2017 to understand the necessary skills and content. From that moment the subject was planned with the content divided into three didactic units: Introduction to the software process Software products and job profiles and Models and standards for software process and product. Each teaching unit contains prerequisites guiding questions study plan teaching strategy expected results learning levels. Learning levels were defined based on Bloom's revised taxonomy. The learning strategies were adopted based on a consultation of the literature and teaching professionals in the area based on a survey. For the evaluation of the syllabus and teaching plan an expert panel was held with: (i) two researchers fluent in software process (ii) two professors who are experts in student-centered learning and (iii) one researcher and professor with experience in student-centered learning in the software process subject. The expert panel consisted of a two-part questionnaire in the first part questions were asked about the identification of the expert's specialty and later questions about the teaching and learning process. A total of five experts evaluated the syllabus and its strategies. The proposed revisions were received and the authors gathered and analyzed each item justifying its adoption.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;An inverted classroom is a teaching environment that mixes the use of technology with hands-on activities. In an inverted classroom typical in-class lecture time is replaced with laboratory and in-class activities. Outside class time lectures are delivered over some other medium such as video on-demand. In a three credit hour course for instance contact hours are spent having students actively engaged in learning activities. Outside of class students are focused on viewing 3-6 hours of lectures per week. Additional time outside of class is spent completing learning activities. In this paper we present the inverted classroom model in the context of a software engineering curriculum. The paper motivates the use of the inverted classroom and suggests how different courses from the Software Engineering 2004 Model Curriculum Volume can incorporate the use of the inverted classroom. In addition we present the results of a pilot course that utilized the inverted classroom model at Miami University and describe courses that are currently in process of piloting its use.;
Proceedings of the 30th International Conference on Software Engineering;We present a summary of the 3rd ICSE Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive Progressive Change in this article. The full day workshop is planned to include a keynote speaker panel discussion and paper presentations on game software engineering topics related to requirements specification and verification software engineering education re-use and infrastructure. An overview of the accepted papers is included in this summary.;
Proceedings of the 2013 International Conference on Software Engineering;Providing students with authentic software development experiences is essential to preparing them for careers in industry. To that end many undergraduate courses include a team-based software development experience in which each team works on a different software project. This raises significant challenges for assessing student work and measuring the impact of pedagogical interventions: What do we measure and how when each team is working on a different project? To address this question we present a collection of metrics developed using the Goal-Question-Metric framework from the empirical software engineering literature and an empirical study in which we applied those metrics to assess 23 team software projects involving 94 students at three institutions. Study results suggest that these metrics which gauge commit issue and overall product quality are sensitive to differences in the quality of teams' processes and products. This work contributes a new metric-based approach to evaluating key aspects of software development processes and products in a wide variety of computing courses.;
Proceedings of the 52nd ACM Technical Symposium on Computer Science Education;Information Retrieval (IR) methods and in particular topic models have recently been used to support essential software engineering (SE) tasks by enabling software textual retrieval and analysis. In all these approaches topic models have been used on software artifacts in a similar manner as they were used on natural language documents (e.g. using the same settings and parameters) because the underlying assumption was that source code and natural language documents are similar. However applying topic models on software data using the same settings as for natural language text did not always produce the expected results.  Recent research investigated this assumption and showed that source code is much more repetitive and predictable as compared to the natural language text. Our paper builds on this new fundamental finding and proposes a novel solution to adapt configure and effectively use a topic modeling technique namely Latent Dirichlet Allocation (LDA) to achieve better (acceptable) performance across various SE tasks. Our paper introduces a novel solution called LDA-GA which uses Genetic Algorithms (GA) to determine a near-optimal configuration for LDA in the context of three different SE tasks: (1) traceability link recovery (2) feature location and (3) software artifact labeling. The results of our empirical studies demonstrate that LDA-GA is ableto identify robust LDA configurations which lead to a higher accuracy on all the datasets for these SE tasks as compared to previously published results heuristics and the results of a combinatorial search.;
Proceedings of the 2013 International Conference on Software Engineering;Context: The teaching of software development in computer science courses is distributed over several subjects such as Software Engineering (SE) Human-Computer Interaction (HCI) Database etc. However several studies indicate a deficiency in student training regarding the practical application of concepts and techniques required to develop and evolve of software with quality. Objective: This article presents an approach to teaching software creation as a capstone course to provide a practical and business-oriented experience for students in computer science programs. Method: Based on literature review a theoretical basis is used to establish the proposed approach. This approach brings together concepts from diverse subjects such as SE HCI and entrepreneurship. From a brief introduction the students working in a group employ the concepts of structuring software development projects using the SCRUM agile development process user-centered design (personas) and software evaluation in the development of a hands-on project. The project result will be submitted to an entrepreneurship competition. Questionnaires were used to verify students' perceptions regarding the proposed course and their experience. Results: The proposed approach is detailed with its techniques and operation for a course with an estimated hour load of 72h over a semester. From its application in two classes it was possible to verify that it presents challenges considered significant for the students and allowed them to practice concepts that they believe to be very important about software development. The use of entrepreneurship competition was relevant regarding motivation and development of business-oriented soft skills. Conclusion: The results has shown that the proposed approach can be a successful and desirable educational practice for a computer science course. It allows both to integrate and practice technical skills as well as to develop other desirable soft skills.;
Proceedings of the XXXII Brazilian Symposium on Software Engineering;End-User Programming enables end users to create their own programs. This can be accomplished in different ways where one of them is by appropriation or reconfiguration of existing software. However there is a trade-off between end users' 'situated design' and quality design which is addressed in End-User Software Engineering. This paper investigates how methods and techniques from Model-Based UI Design can contribute to End-User Software Engineering. Applying the concept of Extra-UI the paper describes a Model-Based approach that allows to extend core applications in a way that some of the underlying models and assumptions become manipulable by end users. The approach is discussed through a running example.;
Proceedings of the 4th ACM SIGCHI Symposium on Engineering Interactive Computing Systems;The software development profession suffers from severe gender biases which could be explicit and implicit. However SE literature has not systematically explored and evaluated the methods for reducing gender biases especially for implicit gender biases. This paper reports on a field experiment to examine whether the intergroup contact theory could reduce implicit gender biases in software development. In the field experiment 280 undergraduate students taking a project-centric introductory software engineering course were assigned to 70 teams with different contact configurations. We measured and compared their explicit and implicit gender biases before and after contacts in their teams. The study yields a rich set of findings. First we confirmed the positive effects of intergroup contact theory in reducing gender biases particularly the implicit gender biases in both general and SE-specific contexts. We further revealed that such effects were subjected to different contact configurations. The intergroup contact theory's effects were maximized in teams where the number of females is greater than or equal to the number of males. When the female is the minority group in a team contacts among members contribute to reducing male members' implicit gender biases but fail to result in the same scale of effects on female members' implicit gender biases. The findings provide insights into using intergroup contact theory in reducing implicit gender biases in software development contexts.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Providing opportunities to introduce proper software project management methodologies in undergraduate computer science programs can be difficult. This is especially so for programs experiencing struggles including it in their curriculum due to either the scale of the program (whether the number of faculty or students) or breadth of topics already taught. However it is invaluable for students to be introduced to these concepts in a low stakes environment so they may be better prepared for their careers after graduating. We provide an experience report of a month-long undergraduate course which introduces key topics in project management as a side effect of hands-on experience developing video games. In groups students delivered an educational video game from start to finish for a client (a faculty or staff member outside of the computing fields). Their client had a real need for their proposed video game and students successfully met these needs. We demonstrate an effective environment to reinforce key project management topics and discuss lessons learned providing a free range environment for students to learn about project management.;
Mapping software engineering principles to stages in game development;We discuss the mapping of software engineering principles to various stages of game development and present examples from some of the courses offered by us to illustrate this progression. We demonstrate that software engineering principles can be implicitly and effectively taught not only to a mature audience (college students) but also to K-12 students when game development is used as a tool.;
A comparison of the Essence 1.0 and SPEM 2.0 specifications for software engineering methods;In this paper we present a comparison of the draft Essence 1.0 and SPEM 2.0 specifications for software engineering methods. The comparison is based on results from the REMICS research project where we are defining an agile methodology for model-driven modernization of legacy applications to service clouds.;
Proceedings of the Third Workshop on Process-Based Approaches for Model-Driven Engineering;Companies worldwide have enabled their employees to work remotely as a consequence of the Covid 19 pandemic. Software development is a human-centered discipline and thrives on teamwork. Agile methods are focusing on several social aspects of software development. Software development teams in Germany were mainly co-located before the pandemic. This paper aims to validate the findings of existing studies by expanding on an existing multiple-case study. Therefore we collected data by conducting semi-structured interviews observing agile practices and viewing project documents in three cases. Based on the results we can confirm the following findings: 1) The teams rapidly adapted the agile practices and roles 2) communication is more objective within the teams 3) decreased social exchange between team members 4) the expectation of a combined approach of remote and onsite work after the pandemic 5) stable or increased (perceived) performance and 6) stable or increased well-being of team members.;
Proceedings of the 2022 5th International Conference on Software Engineering and Information Management;"The continuous growth of the use of Information and Communication Technology in different sectors of the market calls out for software professionals with the qualifications needed to solve complex and diverse problems. Innovative teaching methodologies such as the Software Internship"" model and PBL teaching approaches that are learner-centered and focus on bringing market reality to the learning environment have been developed and implemented with a view to meeting this demand. However the effectiveness of these methods cannot always be satisfactorily proved. Prompted by this this paper proposes a model for assessing students based on real market practices while preserving the authenticity of the learning environment. To evaluate this model a case study on skills training for software specialists for the Telecom market is discussed and presents important results that show the applicability of the proposed model for teaching Software Engineering.""";
Proceedings of the 2013 International Conference on Software Engineering;In this paper we identify trends about benefits from and barriers to performing user evaluations in software engineering research. From a corpus of over 3000 papers spanning ten years we report on various subtypes of user evaluations (e.g. coding tasks vs. questionnaires) and relate user evaluations to paper topics (e.g. debugging vs. technology transfer). We identify the external measures of impact such as best paper awards and citation counts that are correlated with the presence of user evaluations. We complement this with a survey of over 100 researchers from over 40 different universities and labs in which we identify a set of perceived barriers to performing user evaluations.;
Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications;OBJECTIVE - to assess the extent and types of techniques used to manage quality within software engineering data sets. We consider this a particularly interesting question in the context of initiatives to promote sharing and secondary analysis of data sets. METHOD - we perform a systematic review of available empirical software engineering studies. RESULTS - only 23 out of the many hundreds of studies assessed explicitly considered data quality. CONCLUSIONS - first the community needs to consider the quality and appropriateness of the data set being utilised not all data sets are equal. Second we need more research into means of identifying and ideally repairing noisy cases. Third it should become routine to use sensitivity analysis to assess conclusion stability with respect to the assumptions that must be made concerning noise levels.;
Proceedings of the 4th International Workshop on Predictor Models in Software Engineering;In recent years a vivid interest in hybrid development methods has been observed as practitioners combine various approaches to software creation to improve productivity product quality and adaptability of the process to react to change. Scientific papers on the subject proliferate however evaluation of the effectiveness of hybrid methods in academic contexts has yet to follow. The work presented investigates if introducing a hybrid approach for student projects brings added value as compared to iterative and sequential development. A controlled experiment was carried out among Bachelor students of a French engineering school to assess the impacts of a given development method on the success of student computing undertakings. Its three dimensions were examined via a set of metrics: product quality team productivity as well as human factors (teamwork quality &amp learning outcomes). Several patterns were observed which can provide a starting point for educators and researchers wishing to tailor or design a software development process for academic needs.;
Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training;Advances in the use of cognitive and machine learning (ML) enabled systems fuel the quest for novel approaches and tools to support software developers in executing their tasks. First as software development is a complex and dynamic activity these tasks are highly dependent on the characteristics of the software project and its context and developers need comprehensive support in terms of information and guidance based on the task context. Second there is a lack of methods based on conversational-guided agents that consider cognitive aspects such as paying attention and remembering. Third there is also a lack of techniques that make use of historical implicit or tacit data to infer new knowledge about the project tasks such as related tasks task experts relevant information needed for task completion and warnings and navigation aspects of the process such as what tasks to perform next and optimal task sequencing. Based on these challenges this paper introduces a novel paradigm for human-machine software support based on context cognitive assistance and machine learning and briefly describes ongoing research activities to realize this paradigm. The research takes advantage of the synergy among emergent methods provided in context-aware software processes cognitive computing such as chatbots and machine learning such as recommendation systems. These novel paradigms have the potential to transform the way software development currently occurs by allowing developers to receive valuable information and guidance in real-time while they are participating in projects.;
Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results;The Unified Modelling Language (UML) is being widely accepted as a modelling notation for visualizing software systems during design and development. UML has thus become part of many software engineering course curricula at universities worldwide providing a recognized tool for practical training of students in understanding and visualizing software design. It is however common that students have difficulties in absorbing UML in its complexity and often repeat the same mistakes that have been observed by course tutors in previous years. Having a catalogue of such mistakes could hence increase the effectiveness of both teaching and learning of UML diagrams.In this paper we introduce such a catalogue consisting of 146 types of mistakes in eight types of diagrams. As the main contribution of this study we use this catalogue to guide the analysis of student projects within a software engineering course. In total over 2700 diagrams submitted over 12 weeks of a semester by 123 students were analysed to identify the frequency of mistakes (from the catalogue) correlations of the mistakes between different diagram types correlation of the quality of student projects to exam results student behaviour in terms of introducing and fixing the mistakes over time and other interesting insights. The analysis is described together with its setup and execution and all datasets and detailed guidebook to the catalogue of all mistakes is made available for download.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training;The software engineering and medical informatics communities have been developing a range of approaches for reasoning about medical processes. To facilitate the comparison of such approaches it would be desirable to have a set of medical examples or benchmarks that are easily available described in considerable detail and characterized in terms of the real-world complexities they capture. This paper presents one such benchmark and discusses a list of desiderata that medical benchmarks can be evaluated against.;
Proceedings of the 2010 ICSE Workshop on Software Engineering in Health Care;We developed a software engineering course that emphasizes code maintenance and evolution by having students reverse engineer and modify open-source projects. To evaluate whether this course had the desired effects on student learning we analyze pre- and post-course survey data using qualitative methods. This analysis in combination with other data suggests that the students gained an appreciation and understanding of software maintenance documentation and tool use.;
Proceedings of the Ninth Annual International Conference on International Computing Education Research;Software engineering bots â€“ automated tools that handle tedious tasks â€“ are increasingly used by industrial and open source projects to improve developer productivity. Current research in this area is held back by a lack of consensus of what software engineering bots (DevBots) actually are what characteristics distinguish them from other tools and what benefits and challenges are associated with DevBot usage. In this paper we report on a mixed-method empirical study of DevBot usage in industrial practice. We report on findings from interviewing 21 and surveying a total of 111 developers. We identify three different personas among DevBot users (focusing on autonomy chat interfaces and â€œsmartnessâ€) each with different definitions of what a DevBot is why developers use them and what they struggle with.We conclude that future DevBot research should situate their work within our framework to clearly identify what type of bot the work targets and what advantages practitioners can expect. Further we find that there currently is a lack of general purpose â€œsmartâ€ bots that go beyond simple automation tools or chat interfaces. This is problematic as we have seen that such bots if available can have a transformative effect on the projects that use them.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;This report summarizes the research works in particular the full and short papers presented at the 4th International Symposium on Empirical Software Engineering and Measurement (ESEM 2010) held the 16th and 17th of September in Bolzano-Bozen Italy. The program provided thirty full papers twenty six short papers and three invited talks held by Bertrand Meyer Steve Fraser and Carlo Ghezzi.;
End user software engineering: chi'2008 special interest group meeting;End users create software whenever they write for instance educational simulations spreadsheets or dynamic e-business web applications. Researchers are working to bring the benefits of rigorous software engineering methodologies to these end users to try to make their software more reliable. Unfortunately errors are pervasive in end-user software and the resulting impact is sometimes enormous. This special interest group meeting has two purposes: to incorporate attendees' and feedback into an emerging survey of the state of this interesting new sub-area and generally to bring together the community of researchers who are addressing this topic with the companies that are creating end-user programming tools.;
CHI '08 Extended Abstracts on Human Factors in Computing Systems;Software engineering courses often include a semester project designed to give students experience with real-world programming challenges and to expose them to phases of the software development cycle not covered in other classes. One means of engaging students in realistic programming challenges is to make participation in open source development a part of the semester project.This paper describes an assignment in which students contribute to an open source project. The project is designed to immerse students in the open source community and expose them to the work flow and design strategies of a large project. Students work in small groups and decide both which open source community to contribute to and which specific contributions they will make. They can choose to focus on implementation of new features over software maintenance or can focus on documentation and design over both. The assignment contains a proposal phase that allows the instructor to ensure that students are exposed to a healthy cross section of the development cycle.;
Proceedings of the 16th Annual Joint Conference on Innovation and Technology in Computer Science Education;Software engineering projects result in experiences that are valuable for continuous improvement. Experience and Knowledge Management (EKM) deals with the proper presentation engineering and reuse of experiences e.g. training new project members or supporting future projects. In globally distributed projects proper EKM is even more important: Communication between project partners is more difficult than in co-located projects and may impair the awareness of knowledge residing at a project partner's location. Project members might hesitate to share experience because of security considerations. We propose a hierarchical experience base with rights management aiming to positively influence their willingness to share. Our concept includes special support for experience engineers to refine local experiences into best practices in globally distributed software projects. In this paper we show how our approach can rise awareness of existing experiences by presenting relevant experiences according to roles. We also argue how this improves the willingness to share experiences in a distributed environment.;
Proceedings of the 11th International Conference on Knowledge Management and Knowledge Technologies;The integration of user centred design activities into software engineering processes is a challenge. This is especially true for next-generation user interfaces that employ interface paradigms like mixed reality. Guidance for designers and developers has to address the integration of software engineering and user centred design on all levels from abstract standards to operational development. We analyze standards in software engineering and usability engineering and derive recommendations for integrated development processes. To support developers we propose the MVCE architecture as an extension of the common model-view-controller pattern to address the specific requirements of mixed reality interfaces through an additional environment component.;
Proceedings of the 2nd Canadian Conference on Computer Science and Software Engineering;Context: During the implementation of issues filed in open source software projects programmers engage and interact in discussions on how to implement them. These discussions provide evidence to investigate emotionally loaded practices embraced by programmers. They interact to explain their point of view regarding the project and the issue under analysis. Objective: Analyze programmers sentiment polarity in an open source software project having releases as a reference for the analysis. Methods: We conducted an exploratory study to characterize the sentiment polarity of comments registered in issues associated with releases of the Moby open source software project. Results: The quantitative analysis identified sentiment polarity variations throughout consecutive releases in line with specific functionalities. Based on a qualitative analysis we identified these functionalities and specific group of programmers that contributed to those results. Conclusions: We identified initial evidence to contribute for the understanding of the causes underlying the influence of the sentiments of the developers in the context of releases of open source software projects.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;The answer to software reliability concerns may lie in formal methods.;
Surfing the net for software engineering notes;Program assessment plays a key role in measuring student learning and improving the program. Assessing programs is an iterative and incremental process that consists of a series of activities conducted by stakeholders such as faculty members students and alumni. These activities include defining learning outcomes developing assessment methods and rubrics conducting assessment analyzing assessment results and recommending actions for change. Over two years we as the software engineering group in the Computer Science Department assessed four student learning outcomes relating software engineering. In this paper we describe our assessment activities for two learning outcomes: 1) Demonstrate an understanding of the principles and practices for software design and development 2) Be able to apply the principles and practices for software design and development to real world problems.;
Experiences in software engineering courses using psychometrics with RAMSET;Lately Programming Psychology has opened up a vast area of study where human social and psychological factors of the programmer are studied in different computational areas. His behavior and how to relate with others are important aspects that influence performance of a developing team. In our daily work in education we have an obligation of shaping human resources to build a society with professionals participating in companies and corporations dedicated to industrial social and economic development. Thus in searching for strategies to shape human resources and improve these group corporations we propose RAMSET a Role Assignment Methodology for Software Engineering Teams where we acknowledge the importance of relating personality with team roles using sociometric techniques and psychometrics to aid in forming high performing teams for software development projects.;
Proceedings of the Fifteenth Annual Conference on Innovation and Technology in Computer Science Education;There is a strong need in new approaches and curricula in different disciplines especially in the domain of software engineering and information systems. The aim of the paper is to discuss the body of knowledge teaching methods and assessment principles in realization of Information System course jointly by staff from two countries. This experience is gained in realization of Information System Development Process (ISDP) course developed under the project Joint MSc Curriculum in Software Engineering which established a regional wide master's software engineering curriculum with international recognition.;
Proceedings of the International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing;Randomized algorithms have been used to successfully address many different types of software engineering problems. This type of algorithms employ a degree of randomness as part of their logic. Randomized algorithms are useful for difficult problems where a precise solution cannot be derived in a deterministic way within reasonable time. However randomized algorithms produce different results on every run when applied to the same problem instance. It is hence important to assess the effectiveness of randomized algorithms by collecting data from a large enough number of runs. The use of rigorous statistical tests is then essential to provide support to the conclusions derived by analyzing such data. In this paper we provide a systematic review of the use of randomized algorithms in selected software engineering venues in 2009. Its goal is not to perform a complete survey but to get a representative snapshot of current practice in software engineering research. We show that randomized algorithms are used in a significant percentage of papers but that in most cases randomness is not properly accounted for.This casts doubts on the validity of most empirical results assessing randomized algorithms. There are numerous statistical tests based on different assumptions and it is not always clear when and how to use these tests. We hence provide practical guidelines to support empirical research on randomized algorithms in software engineering;
Proceedings of the 33rd International Conference on Software Engineering;Software engineering is the disciplined application of theories and techniques from computer science to define develop deliver and maintain on time and within budget software products that meet customers' needs and expectations. Software products include the actual program source code and data structures (q.v.) as well as the documents necessary to produce these and documents and interface programs necessary to use them in the intended environment.;
Encyclopedia of Computer Science;Developing software systems in large organizations requires the cooperation of various organizational units and stakeholders. As software-development processes are distributed among such organizational units and are constantly transformed to fulfill new domain regulations address changing customer requirements or adopt new software-engineering methods it is challenging to ensure measure and steerâ€”essentially monitorâ€”the quality of the resulting systems. One means to facilitate such monitoring throughout whole software-development processes are key performance indicators which provide a consolidated analysis of an organizationsâ€™ performance. However it is also challenging to introduce key performance indicators for the software development of a large organization as they must be implemented at and accepted by all relevant organizational units. In this paper we report our experiences of introducing new key performance indicators for software-development processes at Volkswagen Financial Services AG a large organization in the financial sector. We describe i) our methodology ii) how we customized and use key performance indicators iii) benefits achieved namely improved monitoring and comparability which help to define quality-improving actions iv) and six lessons learned. These insights are helpful for other practitioners providing an overview of a methodology they can adopt to assess the feasibility of key performance indicators as well as their benefits. Moreover we hope to motivate research to investigate methods for introducing and monitoring key performance indicators to facilitate their adoption.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;PLEASE is a new workshop series that focuses on exploring the present and the future of Software Product Line Engineering (SPLE) techniques. The goal of the workshop is to bring together researchers and practitioners with special interest in SPLE in order to discuss ongoing research and new ideas for advancing the field. The workshop's main theme Beyond Product Lines focuses on the adaptation of SPLE to dynamic settings in which neither the goal nor the organizational structure is stable.We seek to foster exchange of ideas techniques and approaches with the broader software engineering community. In a special session of this year's edition we examine how to leverage existing research by discussing synergy opportunities with members of the Software Clones community.The first edition of PLEASE is held in conjunction with the 32st International Conference in Software Engineering (May 2--8 2010. Cape Town South Africa).;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2;This paper reports on the results of a multidisciplinary project involving lawyers and computer scientists with the aim to put forward a set of methods and tools to (1) define software liability in a precise and unambiguous way and (2) establish such liability in case of incident. The overall approach taken in the project is presented through an electronic signature case study. The case study illustrates a situation where in order to reduce legal uncertainties the parties wish to include in the contract specific clauses to define as precisely as possible the share of liabilities between them for the main types of failures of the system.;
Strength of evidence in systematic reviews in software engineering;Systematic reviews are only as good as the evidence they are based on. It is important therefore that users of systematic reviews know how much confidence they can place in the conclusions and recommendations arising from such reviews. In this paper we present an overview of some of the most influential systems for assessing the quality of individual primary studies and for grading the overall strength of a body of evidence. We also present an example of the use of such systems based on a systematic review of empirical studies of agile software development. Our findings suggest that the systems used in other disciplines for grading the strength of evidence for and reporting of systematic reviews especially those that take account of qualitative and observational studies are of particular relevance for software engineering.;
Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;In this paper we consider 20 years of software development at a medium-sized European software company (called adesso). We identify changes and trends in software project management and we name typical risks inherent to fixed price projects (beyond the common sense that unclear requirements missing domain knowledge and breakdown of project communication are permanent risks). Fixed price projects and their related derivatives can have a huge economical upside for companies like adesso which goes along with sometimes even larger risks. The goal of this research is to identify both risk drivers and risk reduction or even elimination strategies. On this basis we introduce the notion of a Project Management Office (PMO) and supporting tools and mechanisms which help to identify project risks early. Experience reported is based on eight years of monitoring software development projects with these tools and mechanisms. We also give some insights how PMO at adesso has changed over time and why these changes were implemented. As key message of this paper we show the correlation between the systematic usage of the PMO tools and a decreasing overspend rate over eight years and more than 320 projects.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice;Specification mining takes execution traces as input and extracts likely program invariants which can be used for comprehension verification and evolution related tasks. In this work we integrate scenario-based specification mining which uses data-mining algorithms to suggest ordering constraints in the form of live sequence charts an inter-object visual modal scenario-based specification language with mining of value-based invariants which detects likely invariants holding at specific program points. The key to the integration is a technique we call scenario-based slicing running on top of the mining algorithms to distinguish the scenario-specific invariants from the general ones. The resulting suggested specifications are rich consisting of modal scenarios annotated with scenario-specific value-based invariants referring to event parameters and participating object properties.An evaluation of our work over a number of case studies shows promising results in extracting expressive specifications from real programs which could not be extracted previously. The more expressive the mined specifications the higher their potential to support program comprehension and testing.;
Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering;Global software development (GSD) done by geographically distributed teams of developers is one of the most common ways of developing software nowadays. Though GSD has various benefits it also introduces challenges that have led to a plethora of research. This paper analyzes research papers published in top software engineering venues in recent years (2009--2018) focusing on team collaboration in order to understand the trend in GSD research. Out of 4292 papers published in these venues we found 33 papers that focused on team collaboration in the context of GSD. We study the kinds of data used in these papers and classify them into primary data (i.e. interview and observation data) and secondary data (i.e. repository and communication data) and found that interview data is the dominant type of data in these papers. We also found that the strength of evidence presented in most papers tends to be moderate.;
Proceedings of the 14th International Conference on Global Software Engineering;Crowdsourcing Software Development (CSD) has existed and developed for many years. Over the years CSD has made new progress and changes. The original intention of CSD is to reduce the cost of software development. However the crowdsourcing approach encountered difficulties in software development so it turned to software testing. Crowdsourcing Software Testing (CST) has had some successful cases. It has many advantages such as reducing the cost and time of software testing. In this paper we analyze the problems that crowdsourcing faces in software development and come to the view that crowdsourcing is more suitable for software testing. We analyzed the Quadrilateral Co-petition Model in the CST platforms and gave the methods for optimization. We also proposed a new software testing program that integrates open source sharing and crowdsourcing methods.;
5th International Conference on Crowd Science and Engineering;The second Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB 2019) intends to pursue the experience of WETSEB 2018 which inherited from the past eight editions of WETSoM (Workshop on Emerging Trends on Software Metrics) the challenges of gathering together researchers interested in emerging topics and trends in software engineering.WETSEB 2018 marked a transition in the workshop interest from the software metrics to the newly emerging fields of research in a software technology whose powerful wide-spreading is disruptively invading academy industry finance and media: the Blockchain software technology.Motivations for this workshop are augmented since last edition given the clear outstanding interest in software communities in the academy in the industry in the finance and in the media on the new emerging software technology of the Blockchain witnessed by the larger and larger amount of publications of start-ups and companies which last year exploited this new technology. We first outline the aims of the workshop followed by a discussion of its keynote speech and technical program.;
Assessing the Impact of the Distributed Software Development Course on the Careers of Young Software Engineers;Various software engineering (SE) curricula in higher education have started including courses on global software engineering (GSE) carried out as internationally distributed project-based courses. These courses known for their closeness to â€œreal-worldâ€ work experience emphasize the importance of involving industry partners as customers and focus on soft skills essential for employment an aspect often neglected in engineering education.However not many such courses are long-lived or consistent in form throughout the years making their impact and relevance hard to assess. The Distributed Software Development course (DSD) currently run among three universities in Croatia Italy and Sweden has now been carried out for 15 years consecutively providing a rich source of in-course and post-graduation data. To evaluate the studentsâ€™ experiences of the course after they graduate and start working a study has been carried out among former DSD students from the University of Zagreb Croatia. Its goal is to understand how useful this course was in studentsâ€™ early careers both in first and current employment as well as related factors at the workplace (magnitude of distributed collaboration company size).The study results show the relevance of such distributed course experiences for future employment as well as the importance of building upon soft skills as part of the software engineering curricula. Higher education institutions are invited to consider including such courses in the software engineering curriculum for the benefit of their students and indirectly studentsâ€™ future employers.;
Software engineering for simulation systems in medical training: some initial experiences;In this paper we describe our experiences of an ongoing project to develop a simulation system for ultrasound training. Ultrasound is a non-invasive technique to scan bodily organs using harmless sound waves. Because of the effectiveness of the ultrasound technology it is widely used by medical practitioners in health care establishments. However gaining expertise in ultrasound technology requires a long time because of the complex hand-eye coordination required to perform ultrasound scans. To this end the goal of this simulation system is to help medical practitioners gain expertise in ultrasound technology in relatively short period of time. In this paper we describe the requirements engineering design and developmental challenges of this simulation system along with some initial evaluations.;
Proceedings of the 2010 ICSE Workshop on Software Engineering in Health Care;The power and the generality of the findings obtained through empirical studies are bounded by the number and type of participating subjects. In software engineering obtaining a large number of adequate subjects to evaluate a technique or tool is often a major challenge. In this work we explore the use of crowdsourcing as a mechanism to address that challenge by assisting in subject recruitment. More specifically through this work we show how we adapted a study to be performed under an infrastructure that not only makes it possible to reach a large base of users but it also provides capabilities to manage those users as the study is being conducted. We discuss the lessons we learned through this experience which illustrate the potential and tradeoffs of crowdsourcing software engineering studies.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;While many computer science students plan to pursue careers as software engineers research shows that most traditional undergraduate CS programs fail to prepare students for the realities of programming in industry. Many misconceptions that are interfering with the transition to industry are belief-oriented not skill-oriented in nature so traditional misconception assessments will not yield a deep understanding of them.In this paper we present a novel methodology that shows interactions among the misconceptions based on a forced choice paradigm and reveals the relative strength of the misconceptions. By analyzing students' repeated responses and response times we construct a model of participants' misconceptions. We used this methodology to assess CS undergraduates at Carnegie Mellon University and compared their results to those from industry practitioners at several highly regarded companies. The results show that the students have misconceptions about process and teamwork. Surprisingly we found that several misconceptions are correlated with elective courses that we expected to weaken misconceptions about software engineering but instead appeared to strengthen them.;
Proceedings of the Sixth International Workshop on Computing Education Research;The article presents ImproSculpt -- a live performance instrument for algorithmic composition and improvised audio manipulation. A custom version of the software has been used within several interactive art installations one of which (i.e. Flyndre) will be described. Besides the software characteristics and usage modes we present and discuss the software engineering challenges problems and lessons learned during the development of ImproSculpt. Several methodologies were used in the case study: observing the project through its life cycle analyzing the software and its documentation questionnaire with the artist who is also the main developer two software engineering interventions. The support of high performance easy modifiability and availability were found to be particularly important. The development of a modular architecture has been identified as a way to satisfy some of the non-functional quality attributes of the software that appeared with the growth of the project. Furthermore ImproSculpt has been published as open source software in order to increase access to wider public and stimulate input from interested community - software developers and artists.;
Proceedings of the 3rd International Conference on Digital Interactive Media in Entertainment and Arts;Outliers have been a constant source of problems in the analysis of Empirical Software Engineering data. In some cases outliers are due to corrupted data while they may be the result of highly unlikely circumstances in others. In either case outliers may unduly greatly bias data analysis as is the case with Ordinary Least Squares (OLS) regression. Robust data analysis techniques have been proposed to address this problem. In this paper we describe an existing robust linear regression technique based on the Least Median of Squares (LMS) and provide a statistical significance test for the associations obtained with it. We also apply LMS and OLS regression to real-life publicly available Empirical Software Engineering data sets to compare the results obtained and investigate commonalities and differences between LMS and OLS from a practical point of view.;
Proceedings of the 5th International Conference on Predictor Models in Software Engineering;The evolution of Science has been supported by complex computerized infrastructures with growing interest in simulation based experiments. This trend can also be observed in Software Engineering. Our capacity of acquiring evidences to describe phenomena of interest in the field allowed the building of in silico models that can virtually replicate feasible software behaviors and improve our capacity of observation. In silico experiments demand additional concerns for its planning. One of them is regarding the scientific workflow conception. This task is not easy and to apply ad-hoc approaches can risky the experiment execution validity and future replications. Regarding this topic this paper presents some initial results from our research towards an approach to support the conception of scientific workflows for in silico experiments in Software Engineering are presented.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;While certification is widely recognized as a means to increase system trustworthiness and reduce uncertainty in decision making it faces severe challenges preventing a wider adoption thereof. Certification is not adequately planned and integrated within the development process leading to suboptimal scenarios where certification introduces the need to further modify the developed system with high costs. We propose a methodology that bridges the gap between software development and certification processes. Our methodology automatically produces the certification requirements driving all steps of the development process and maximizes the strength of certificates while taking costs under control. We formalize the above problem as a multi-objective mathematical program and solve it through a genetic algorithm. The proposed approach is tested in a real-world cloud-based financial scenario at CaixaBank and its performance and quality is evaluated in a simulated scenario.;
Proceedings of the 17th International Conference on Availability Reliability and Security;Formal methods were developed to provide systematic and rigorous techniques for software development and they must be taught in the context of software engineering. In this paper we discuss the importance of such a teaching paradigm and describe several specific techniques for teaching formal methods. These techniques have been tested over the last fifteen years in our formal methods education programs for undergraduate and graduate students at universities as well as practitioners at companies. We also present a curriculum to systematically introduce formal methods to students at university and a successful program of teaching formal methods to industry. Our experience shows that students can gain confidence in formal methods only when they learn their clear benefits in the context of software engineering.;
A model for strengthening the software engineering research capacity;Like all other New Member States (NMS) Bulgaria is experiencing a dramatic change in all areas of its society. These changes reflect very seriously on the research capacity of the country and in particular to Sofia University (SU). The Faculty of Mathematics and Informatics (FMI) has experienced some serious problems closely related to the general socio-economic and the research environment in Bulgaria. This paper describes a model for strengthening the research capacity of FMI especially the one in the area of Software Engineering. The case study of successful industry-university cooperation in the framework of European project is presented.;
Proceedings of the 2008 International Workshop on Software Engineering in East and South Europe;Benefits of collaborative learning are established and gamification methods have been used to motivate students towards achieving course goals in educational settings. However different users prefer different game elements and rewarding approaches. We present an evidence-based method and a case study where interaction analysis and k-means clustering is used to create gamification preference profiles. These profiles can be used with an agent-based simulation to evaluate how computer supported collaboration system users react to the gamification elements and how the collaboration dynamics change.;
Proceedings of the 15th International Conference on Computer Systems and Technologies;How do you select a programming language for your project? Few developers have the luxury of coding the same design in multiple languages to compare language merits. For over twenty years my undergraduate students have implemented the same large (10-15K lines) multi-tasking real-time embedded system. In one 15 week semester student teams specify design and implement software to control a substantial model railroad layout.Students implement everything from device drivers for custom I/O hardware to high-level decision making algorithms. Student teams have implemented the project in both Ada and C. This paper describes the course the laboratory the project and an analysis of the results achieved with each of the implementation languages.;
Proceedings of the 2008 ACM Annual International Conference on SIGAda Annual International Conference;The evaluation of an advanced software engineering (SE) course is a challenging task that should be addressed as part of the course design. In this paper we describe an implementation of the reflective practitioner perspective as part of an advanced SE course and introduce its use for feedback purposes. Reflective feedback goes beyond merely using feedback questionnaires. Furthermore we show using both qualitative and quantitative empirical data that the course on which the perspective was applied meets its objectives and fosters students' awareness to the multidimensional nature of SE.;
Proceedings of the 14th Annual ACM SIGCSE Conference on Innovation and Technology in Computer Science Education;Cognitive biases are hardwired behaviors that influence developer actions and can set them on an incorrect course of action necessitating backtracking. Although researchers have found that cognitive biases occur in development tasks in controlled lab studies we still do not know how these biases affect developers' everyday behavior. Without such an understanding development tools and practices remain inadequate. To close this gap we conducted a two-part field study to examine the extent to which cognitive biases occur the consequences of these biases on developer behavior and the practices and tools that developers use to deal with these biases. We found about 70% of observed actions were associated with at least one cognitive bias. Even though developers recognized that biases frequently occur they are forced to deal with such issues with ad hoc processes and suboptimal tool support. As one participant (IP12) lamented: There is no salvation!;
Characterizing model usage in embedded software engineering: a case study;During development of complex products such as automotive software models -- formal and informal -- are used throughout the development process by different roles and for different purposes -- as requirement as implementation or as documentation. This paper reports results from a case-study of the development of embedded software at a Swedish vehicle manufacturer. We investigated use of models from high-level product planning to low-level requirements specifications for software components. Furthermore we investigated the distribution of effort among the models requirements and other artefacts. The goal was to explore the spectrum of modelling techniques methods and languages used and to establish a baseline for comparison with the state-of-the-art and other companies. The results show that there exist at least 8 different modelling notations. Moreover we found that the majority of effort was spent on behaviour models while static models -- such as high-level design and requirements -- were considered most important.;
Proceedings of the Fourth European Conference on Software Architecture: Companion Volume;The search for diversity and inclusion (D&ampI) in Software Development companies around the world is becoming more common. This change is due both to the understanding of the need to include underrepresented groups but also to the use of diversity as a business tool to improve the image and even increase performance and profit. The process of adapting the work environment to a diverse and inclusive context requires an effort beyond prospecting people from underrepresented groups. Such effort can range from an analysis of who makes up the company and which groups need attention training of leaders and even structural changes in the physical work environment. This paper seeks to bring an analysis of the perception of D&ampI in companies both on the part of developers and management collecting opinions practices and problems through qualitative research. As a result of the present study we see that companies have an interest in improving the work environment and have put an effort to achieve it. However when we contrast the management perspective with the point of view that developers have we realize that some points go unnoticed and do not receive attention. It causes underrepresented groups to end up not having their concerns discussed within the companies. Through this study it is possible to understand some obstacles and failures that some companies are committing in their attempt to improve D&ampI.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Scientific software is defined as an application that supplies data to support decisions in a field of science or engineering. Computational models of climate geographic information systems to study bird habitats analysis software for the safe operation of nuclear generating stations and software to study stresses on concrete structures are only a few thousand examples.;
Proceedings of the 2010 Conference of the Center for Advanced Studies on Collaborative Research;"Modern technologies have the tremendous capacity to unleash the potential of the South Eastern Europe (SEE) countries and to help increase their economic growth and foster their integration in world market. This paper is set forth to analyze the policy impact of eSEE Agenda for the Development of the Information Society"" (eSEE Agenda) as a regional action plan for Information Society development in SEE region implemented from 2002 to 2007 including the policy impact to development of national software engineering industries. As several reviews and reports from recent South Eastern Europe Ministerial Conference on Information Society Development (Sarajevo October 2007) indicate the initial Agenda's aims have in good measure been attained. Development of an enabling framework is largely complete new ICT infrastructure is being introduced in government departments and public institutions a very wide range of e-services for the public and business are either already operational or close to becoming so. Recognition of this fact by the members of the Initiative has led to an extension of the initiative with the agreement of a second phase ""eSEE Agenda Plus for the Development of Information Society in South Eastern Europe 2007-2012"" signed in Sarajevo on 29 October 2007 at the South Eastern Europe Ministerial Conference on Information Society Development. This paper will also look into current trends and perspectives articulated in the second generation of Initiative activities and the Action Plan of the Taskforce for Broadband and their implications for Information Society development in South Eastern Europe as the basic software engineering development environment.""";
Proceedings of the 2008 International Workshop on Software Engineering in East and South Europe;There are software solutions to solve most of the problems related to information management in any company or institutions but still there is a problem for transforming information into knowledge. Technological ecosystems emerge as a solution to combine existing tools and human resources to solve different problems of knowledge management. In particular when the ecosystem is focused on learning processes associated with knowledge are named learning ecosystems. The learning ecosystem metamodel defined in previous works solves several problems related to the definition and implementation of these solutions. However there are still challenges associated with improving the analysis and visualization of information as a way to discover knowledge and support decision making processes. On the other hand there is a metamodel proposal to define customized dashboards for supporting decision-making processes. This proposal aims to integrate both metamodels as a way to improve the definition of learning ecosystems.;
Proceedings of the 2020 European Symposium on Software Engineering;Software developement process modeling with patterns allows to benefit from the advantages of these latter. Indeed this modeling allows to benefit from the proved and reusable knowledge offered by patterns which improves the quality of the models produced and reduces the modeling time and effort. In this article we discuss the main modeling practices of software developement processes with patterns. We focuse on the advantages and difficulties of these practices.;
Proceedings of the 2nd World Symposium on Software Engineering;Background: Testing is one of the main methods for quality assurance in the development of embedded software as well as in software engineering in general. Consequently test results (and how they are reported and visualized) may substantially influence business decisions in software-intensive organizations. Aims: This case study examines the role of test results from automated nightly software testing and the visualizations for decision making they enable at an embedded systems company in Sweden. In particular we want to identify the use of the visualizations for supporting decisions from three aspects: in daily work at feature branch merge and at release time. Method: We conducted an embedded case study with multiple units of analysis by conducting interviews questionnaires using archival data and participant observations. Results: Several visualizations and reports built on top of the test results database are utilized in supporting daily work merging a feature branch to the master and at release time. Some important visualizations are: lists of failing test cases easy access to log files and heatmap trend plots. The industrial practitioners perceived the visualizations and reporting as valuable however they also mentioned several areas of improvement such as better ways of visualizing test coverage in a functional area as well as better navigation between different views. Conclusions: We conclude that visualizations of test results are a vital decision making tool for a variety of roles and tasks in embedded software development however the visualizations need to be continuously improved to keep their value for its stakeholders.;
Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Software Development is a complex and multidimensional task. Often software development faces serious problems of meeting key constraints of cost and time. Big projects which are well planned and analyzed can end up in a disaster because of mismanagement in cost estimation and time allocation. Program slicing has unique importance in addressing the issues of cost and time. It is broadly applicable static program analysis technique which provides mechanism to analyze and understand the program behavior for further restructuring and refinement. In this paper authors investigate the relationship between program slicing and software development phases on the basis of empirical studies conducted in the past and also establish the fact that how program slicing can be helpful in making software system cost and time effective.;
Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology Culture and Human;This paper describes the two-semester capstone courses in Software Engineering offered in the Computer Science Department at Siena College. These courses have been offered for 27 years and they have recently become a graduation requirement for the major. The courses tie-together a variety of educational themes and goals related to Software Engineering professional behavior and preparation for professional careers. Over the years the syllabi content format and teaching-approach has changed substantially. This paper describes the two Software Engineering courses and how the courses have changed and how faculty and students perceive the courses.;
Current and future bots in software development;"Bots that support software development (DevBots"") are seen as a promising approach to deal with the ever-increasing complexity of modern software engineering and development. Existing DevBots are already able to relieve developers from routine tasks such as building project images or keeping dependencies up-to-date. However advances in machine learning and artificial intelligence hold the promise of future significantly more advanced DevBots. In this paper we introduce the terminology of contemporary and ideal DevBots. Contemporary DevBots represent the current state of practice which we characterise using a facet-based taxonomy. We exemplify this taxonomy using 11 existing industrial-strength bots. We further provide a vision and definition of future (ideal) DevBots which are not only autonomous but also adaptive as well as technically and socially competent. These properties may allow ideal DevBots to act more akin to artificial team mates than simple development tools.""";
Proceedings of the 1st International Workshop on Bots in Software Engineering;Any software development company encounters issues that need decision-making. At the same time the use of reliable and proven methods of decision-making does not become a common practice in software companies worldwide. The issues here are the need for extra staff training allocation of additional time and inertia of the software industry. This research studies the problems of adoption of the methods of decision-making in the software development companies of Ukraine and Malaysia. The survey was conducted to evaluate software engineers' attitudes toward the use of the methods of decision-making. Research outcomes can be used to raise the level of adoption of the methods of decision-making in software companies worldwide.;
Proceedings of the 2019 8th International Conference on Software and Computer Applications;The software development industry has been evolving with new development standards and service delivery models. Agile methodologies have reached their completion with DevOps thereby increasing the quality of the software and creating greater speed in delivery. However a gap regarding the formalization of its adoption and implementation doubts became relevant. My hypothesis is that by systematizing the introduction of DevOps into the software development process and defining the function of the members of the DevOps team members may well make it quicker to implement this process thus reducing conflicts between the teams. As part of the investigation of this hypothesis the result of the research will be applied in practical development environments i.e. in a Technology Agency of the State of the Brazilian Government and also at the Brazilian Company Neurotech in order to evaluate its effectiveness from metrics appropriate for DevOps environments.;
Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings;Software Engineering (SE) and Information Technology (IT) jobs are the most sought after career options for Indian youth in the recent times. Indian Software industry is expected to grow at a very healthy rate and each major software company has ambitious plans and growth targets for future. However lack of proper Software Engineering (SE) education may have severe consequences and may negatively affect these growth targets. In this paper we discuss challenges and issues related to software engineering education and training in Indian academia and industry. These are based on our interaction with industry and through our experience as Software engineering educators. These challenges arise from deep rooted issues in Software Engineering educational goals pedagogy and instruction as well as the infrastructure. We will discuss their long term effects on various aspects of software development. We put forth our suggestions that may handle these challenges to an extent. We also discuss the essential and minimal set of software engineering knowledge skills and dispositions that the industry requires from young engineers willing to join the industry. This paper provides course designing guidelines for the academia and learning centers of the industry by focusing on important SE education issues their causes and possible solutions. This in turn would help to make SE Education more effective and inline with requirements of the Indian Software industry;
Proceedings of the 1st India Software Engineering Conference;Component-Based Software Engineering (CBSE) with Open Source Software and Commercial-Off-the-Shelf (COTS) components Open Source Software (OSS) based development and Software Outsourcing (SO) are becoming increasingly important for the Chinese software industry. It is therefore necessary to establish pragmatic and possibly nation-specific guidelines for Chinese software companies regarding the use of CBSE OSS and SO. Such guidelines should be based on insights from actual practice which are in our case obtained through surveys. A European state-of-the-practice survey on COTS- and OSS-oriented CBSE was conducted in Germany Italy and Norway in 2004-2005. We repeated similar surveys in China with an extended survey on OSS and SO. We encountered many difficulties in conducting the surveys but in most cases managed to find working solutions. We report on the lessons learned while conducting these surveys. In particular we address issues relating to sampling contacting respondents data collection and data validation. The main lessons are: 1) it was necessary to cooperate with a third-party organization with close relations to Chinese software companies 2) it was necessary to assign researchers to this third-party organization to facilitate data collection and to control the quality of the data collected and 3) an email survey after an initial telephone call to establish contact was the best method for getting questionnaires completed by Chinese respondents.;
Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;Several years ago I was visiting the National Building Museum in Washington D.C. At the time of my visit there was an exhibit spotlighting the architect C\'{e;
Proceedings of the 2007 Symposium on Science of Design;At present the express industry is developing rapidly and a variety of express companies emerge in endlessly. On this basis the selection of express suppliers is particularly important. In this paper a multi-attribute group decision making (MAGDM) method based on generalized fuzzy soft set (GFSS) is proposed for the selection of express delivery companies. Firstly considering the cognition of decision makers we introduce the adjustment factor to construct GFSS by using fuzzy soft set (FSS) information. Then a similarity measure is used to identify the weight of decision makers (DMs). On this basis we develop the GFSS Bonferroni mean operator (GFSSBM) by Bonferroni mean operator which can be used for aggregating the information of gleaned from the DMs into collective information. The attribute weight is determined by information entropy then calculate and sort the score of each express company using score function. Finally through the case analysis and comparison between GFSS and FSS method it shows that the application of the MAGDM method in the decision making of express companies is scientific and reasonable.;
2022 3rd Asia Service Sciences and Software Engineering Conference;Small software companies have a challenge with utilizing process tools which affects practice with significant quality-related challenges. This affects the software industry significantly because SSCs dominate the industry and most of all over 80 percent of software products are produced by SSCs. This cross-sectional survey was conducted in 3 countries attracting 115 respondents with the primary objective of investigating the software practice concerning the utilization of process tools in SSCs. The study focused on the tools used in requirements engineering and software testing as critical process areas for quality software products. Our findings indicate that the number of personnel intertwines with the complexities arising from lengthy procedures of the tools and processes aggregating into difficulty in tool usage. Due to the constant evolution of practices the volatility in processes also causes slow adoption of other tools for instance testing that must accompany the main engineering tools during a project. These findings are significant in informing theory and communicating to the practitioners what they should do regarding process tools.;
Proceedings of the 2021 European Symposium on Software Engineering;"Adoption of advanced automated SE (ASE) tools would be favored if a business case could be made that these tools are more valuable than alternate methods. In theory software prediction models can be used to make that case. In practice this is complicated by the local tuning"" problem. Normally predictors for software effort and defects and threat use local data to tune their predictions. Such local tuning data is often unavailable.This paper shows that assessing the relative merits of different SE methods need not require precise local tunings. STAR1 is a simulated annealer plus a Bayesian post-processor that explores the space of possible local tunings within software prediction models. STAR1 ranks project decisions by their effects on effort and defects and threats. In experiments with two NASA systems STAR1 found that ASE tools were necessary to minimize effort/ defect/ threats.""";
Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering;Along with the digital economy's growth digital marketing significantly impacts how businesses and customers interact. It steadily permeates the Internet environment and emphasizes the importance of all types of marketing operations. Since 2020 the effect of the Covid-19 epidemic has accelerated the deep integration of social media and the home economy and corporate marketing methods have changed from traditional marketing to digital marketing. However digital marketing is in its infancy for many traditional industries and marketing effectiveness needs to be improved. There is still a long way to go to complete this transformation. Therefore this paper uses the Central Festival catering business in Chiang Mai as a case study and follows a knowledge management process aiming to produce a multiple criteria decision-making model based on the 4C theory. To select digital marketing strategies for the Central Festival catering business in Chiang Mai to recruit and retain long-stay Chinese customers improve market competitiveness and increase brand influence in the face of the Covid-19 epidemic. This study is based on the knowledge management process and used qualitative and quantitative methods to investigate the research questions conducted online surveys and in-depth interviews to collect individual and collective data. AHP and TOPSIS analyses were also used in this work. In the AHP section each influencing factor's importance was counted by calculating the weights of the four criteria and 15 sub-criteria based on the weight of each influencing factor thus providing a more precise measure of the importance of the six alternatives. The result was made that social media marketing is the most suitable digital marketing strategy for Central Festival. The result will help the CF restaurant industry better understand the long-stay Chinese consumer value proposition in Chiang Mai and thus build more robust decision-making models.;
Proceedings of the 4th World Symposium on Software Engineering;"Software engineering is a key discipline in computer science. Its purpose is to develop software products and services of high quality within economic constraints that meet customer requirements and create value. Considerable shares of the societal and industrial infrastructure depend on software and software has become a key driver for innovation. So far so good but who shapes software engineering who defines what the problems to be solved look like and who decides about the importance of certain streams in software engineering research and practice? Furthermore is software engineering in the USA or in Europe the same as e.g. software engineering in Oceania or Africa? In this new column Software Engineering Worldwide we aim to provide an overview of software engineering its importance and its manifestation in different regions worldwide. We wish to take a look behind the scenes to learn about the different environments and the respective key problems to be addressed in local"" software engineering research practice and education. We also aim to open the minds of the community regarding the involvement of new locations not yet on the software engineering map and to stimulate constructive discussion on how to better involve such locations.""";
Predicting code context models for software development tasks;Code context models consist of source code elements and their relations relevant to a development task. Prior research showed that making code context models explicit in software tools can benefit software development practices e.g. code navigation and searching. However little focus has been put on how to proactively form code context models. In this paper we explore the proactive formation of code context models based on the topological patterns of code elements from interaction histories for a project. Specifically we first learn abstract topological patterns based on the stereotype roles of code elements rather than on specific code elements we then leverage the learned patterns to predict the code context models for a given task by graph pattern matching. To determine the effectiveness of this approach we applied the approach to interaction histories stored for the Eclipse Mylyn open source project. We found that our approach achieves maximum F-measures of 0.67 0.33 and 0.21 for 1-step 2-step and 3-step predictions respectively. The most similar approach to ours is Suade which supports 1-step prediction only. In comparison to this existing work our approach predicts code context models with significantly higher F-measure (0.57 over 0.23 on average). The results demonstrate the value of integrating historical and structural approaches to form more accurate code context models.;
Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering;New and emergent computing architectures and software engineering practices provide an opportunity for environmental models to be deployed more efficiently and democratically. In this paper we aim to capture the software engineering practices of environmental scientists highlight opportunities for software engineering and work towards developing a domain specific language for the configuration and deployment of environmental models. We hold a series of interviews with environmental scientists involved in developing and deploying computer based environmental models about the approach taken in engineering models and describe a case study in deploying an environmental model (WRF: Weather Research Forecasting) on a cloud architecture. From these studies we find a number of opportunities for A) software engineering methods and tools such as Domain Specific Languages to play a role in abstracting from underlying computing complexity and for B) new architectures to increase efficiency and availability of deployment. Together we propose they will allow scientists to concentrate on fundamental science rather than specifics of the underlying computing.;
Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Society;In general decomposition methods can facilitate the process of solving sophisticated and heterogonous problems in the area of software development and engineering. These approaches are assisting to decompose problems based on different disciplines characteristics and functionalities that is results into increasing the computational efficiency (e.g. parallel processing/computing) and accelerate the software changing process software modifications and error tracking. Essentially these approaches contribute to the degree of modularity to decompose a complex problem into different sub-problems and to focus on local objectives. There are different approaches that are used to decompose a problem into the smaller ones by keeping/improving the accuracy and efficiency in software engineering. Three major decomposition approaches that have been used in software engineering are decomposition based on aspects objects and views. Each of these has their own characteristics and limitation. This research paper aims to address some of these important issues regarding to the decomposition approaches that are used in the software engineering discipline. In the next step a new decomposition paradigm called multi-level decomposition will be introduced and a proper vision in terms of the key characteristics differences and analogies between this decomposition method and others will be addressed. At the end an example problem will be decomposed based upon the presented approach to show the potential capability of the approach.;
Proceedings of the 49th Annual ACM Southeast Conference;This paper reports our experience developing a product for a real-world client using a software engineering process across multiple semesters with different students each semester. New student teams test debug deploy and critique previous semesters' software and then continue its development. Students are motivated to think critically about and experience real-world software engineering practice. We describe how students in one semester collectively identified the software engineering problems that could be resolved in the current semester how the students proceeded to tackle those problems and the impacts of their actions for future semesters.;
Proceedings of the First International Workshop on Software Engineering Education Based on Real-World Experiences;An Agile development team estimates the effort of a work item to plan a sprint (i.e. an iteration in Scrum). Hence reliable effort estimation would help the team create a reliable sprint plan. Prior studies proposed automated approaches to help the team to estimate the effort accurately. However the effort estimated by the previously proposed approaches may become inaccurate when the related information is changed. Especially when the estimated effort is changed after the sprint has been planned the sprint plan may be invalidated and the team might waste their time and effort spent in planning. This thesis aims to help the Agile development team improve the stability of effort estimation (in the Story Points unit) while aligning with the just-in-time practice of Agile. Hence we first conduct empirical studies using mixed-methods approaches to investigate the potential impact of instability of Story Points. To help an Agile team to achieve reliable effort estimation with optimal effort we will develop approaches to predict the future Story Points changes and the future information changes to help the team cope with uncertainty when finalizing the sprint plan.;
Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Vulnerable software often originates from insufficient attention to security in the software development lifecycle. However current maturity models provide limited support for the teams to assess the security maturity of their software development practices. In this paper we propose a security maturity self-assessment framework for software development lifecycle. The proposed framework is based on three well-known and industry-accepted models that focus on increasing the security maturity of software products: OWASP DevSecOps Maturity Model (DSOMM) OWASP Software assurance Maturity Model (SAMM) and Building Security In Maturity Model (BSIMM). The preliminary validation with software developers suggests that the proposed framework helps teams to understand the security posture of their software products and to identify which security practices need improvements.;
Proceedings of the 17th International Conference on Availability Reliability and Security;Cloud native applications leverage Development and Operation (DevOps) microservice architectures and containerisation for primarily availability resilience and scalability reasons. Small developer teams in low resource settings have unique DevOps needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. We conducted a survey with professional developers students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. In application containerisation an operating system virtualisation method that can significantly optimize the use of computing resources the respondents indicated challenges in the process steps. Particularly small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. Informed by the developer needs we designed and developed a custom automated containerisation pipeline mira for a managed cloud native platform situated in a low-resource setting. We validate mira against 6 major application frameworks tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.;
Proceedings of the Federated Africa and Middle East Conference on Software Engineering;Software Engineering (SE) is a discipline of Computer Science dedicated to teaching topics related to software development. It involves a wide variety of topics so the teaching of SE is a challenge especially to make the discipline attractive to the students. Therefore in the last 10 years the process of teaching SE has been applied and improved continually in the computer science course of the Computer Science Department of the Federal University of Cear\'{a;
Proceedings of the XXXI Brazilian Symposium on Software Engineering;Global software engineering (GSE) courses traditionally require cooperation between at least two universities so as to provide a distributed development environment to the students. In this study we explore an alternative way to organize a global software engineering course where students work on open source software development (OSSD) projects rather than in a multi-university collaboration setting. The results show that the new setup may provide core GSE challenges as well as challenges associated with software development outsourcing and challenges related to working on large open source software. The present article compares the experiences gained from running a combined GSE and OSSD course against the experiences gained from running a traditional GSE course. The two alternatives are compared in terms of studentsâ€™ learning outcomes and course organization. The authors found that a combined GSE and OSSD course provides learning opportunities that are partly overlapping with and partly complementary to a traditional GSE course. The authors also found that the combined OSSD and GSE course was somewhat easier to organize because most of the activities took place in a single university setting. The authors used the extended GSE taxonomy for the comparison and found it to be a useful tool for this although it had some limitations in expressive power. Therefore two additional relationship dimensions are proposed that will further enrich the extended taxonomy in classifying GSE (and OSSD) projects.;
Can we do useful industrial software engineering research in the shadow of lean and agile?;The software industry is rapidly changing from traditional ways of working to lean and agile development methods using self-organized feature development teams that are performing a much larger part of the development process than before. Face to face communication will replace many of the design artifacts used for work-in-progress such as defect reports and feature system design specifications. This type of data will cease to exist when the feature is developed or the problem is solved and will not be readily available to researchers. As a consequence software engineering research in industry will have to rely primarily on participatory and observational methods.;
Proceedings of the 1st International Workshop on Conducting Empirical Studies in Industry;The use of spikes in agile software development (ASD) can enable organizations to produce quality software by employing the required technical expertise planning the entire development cycle and ensuring that the client's requirements are adhered to. This study aims to examine the use of spikes in ASD. It explores the role efficiency and efficacy of spikes in various software development domains through the different agile methods. An exploratory research design is adopted to achieve this purpose whereby mixed methods are used to collect concurrently both qualitative and quantitative data from the experts recruited to the study. Based on the study's findings this paper shows spikes' impact on risk reduction and their role in the estimation process as well as how their use is related to the team's understanding and the consistency and reliability of the story estimate. Through interviews it establishes that the primary role of spikes is risk management through investigations to understand user stories and reveal any uncertainty. Both the efficiency and efficacy of spikes were found to be high. The findings further showed that spikes improve the quality of the end product.;
Proceedings of the 2020 European Symposium on Software Engineering;Many open-source software projects depend on a few core developers who take over both the bulk of coordination and programming tasks. They are supported by peripheral developers who contribute either via discussions or programming tasks often for a limited time. It is unclear what role these peripheral developers play in the programming and communication efforts as well as the temporary task-related sub-groups in the projects. We mine code-repository data and mailing-list discussions to model the relationships and contributions of developers in a social network and devise a method to analyze the temporal collaboration structures in communication and programming learning about the strength and stability of social sub-groups in open-source software projects. Our method uses multi-modal social networks on a series of time windows. Previous work has reduced the network structure representing developer collaboration to networks with only one type of interaction which impedes the simultaneous analysis of more than one type of interaction. We use both communication and version-control data of open-source software projects and model different types of interaction over time. To demonstrate the practicability of our measurement and analysis method we investigate 10&nbspsubstantial and popular open-source software projects and show that if sub-groups evolve modeling these sub-groups helps predict the future evolution of interaction levels of programmers and groups of developers. Our method allows maintainers and other stakeholders of open-source software projects to assess instabilities and organizational changes in developer interaction and can be applied to different use cases in organizational analysis such as understanding the dynamics of a specific incident or discussion.;
Collaboration problems in conducting a group project in a software engineering course;One of the largest problems in conducting a group project is establishing a collaborative environment among the members of the teams that are working on the project. A search was conducted to identify specific tools for the different phases of the software development process that might enable students to work better together collaboratively in hopes of enhancing their performance. In this paper the importance of having a group project in the software engineering course problems related to working together collaboratively and proposed solutions to overcome those problems are discussed.;
When software development meets the shopfloor: the case of industrial fablabs;This paper addresses the question of how software is being developed in industrial fabrication laboratories (fablabs) located in real production environments by the example of a smart factory project conducted by a large company in Europe. Our findings suggest that when developing software in industrial fablabs teams tend to drift away from established software engineering methods and practices and to adapt them impromptu in order to cope with the seemingly arcane sociotechnical environment of the factory.;
Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings;Traditional Software Engineering courses commonly prioritize the teaching of methodologies and concepts in small and controlled environments. This decision is partly justified by the difficulty of bringing real software projects to the classroom. The ubiquity of Open Source Software (OSS) projects contributes to mitigating this problem. Several instructors already make use of contribution to OSS as part of the teaching and evaluation process in their courses. However little is known about how students perceive the approach of contributing to OSS projects in the context of a Software Engineering course. This paper aims to uncover challenges and benefits from the students' perspective. To achieve this we conducted14 semi-structured interviews with students who attended to this kind of courses in five different Brazilian universities resulting in findings not so well known. For example we noticed that although instructors point to the projects that students are required to contribute to students (and the project community) are involved in the process of choosing projects and tasks (issues). We also identified that students' contributions vary in terms of number of lines added and removed in commits as well as the use of different programming languages.;
Proceedings of the XXXII Brazilian Symposium on Software Engineering;Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems we perform a systematic literature review from a software engineering perspective based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding requirement analysis architecture design implementation and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.;
Identifying and mitigating risks of software project management in global software development;Managing global software projects is a difficult task further complicated by the emergence of new risks inherent to the dispersion of stakeholders. Project managers of Global Software Development (GSD) projects deal with challenges related to geographical temporal and socio-cultural distance. The aim of this paper is to identify mitigation strategies intended to counter partially or fully the effects of risk factors related to the management of GSD projects that are available in literature and update the list of risk factors proposed in a previous research. This study proposes a framework for the Software Risk Management (SRM) of GSD projects designed to help practitioners identify risk factors and alleviate their effects through a list of recommended mitigation strategies. Using a systematic literature review (SLR) 39 risk factors and 58 mitigation strategies were identified and classified using a framework inspired from Leavitt's model of organizational change. Results show that the mitigation strategies identified in this SLR target 38 out of 39 risk factors indicating a high academic interest in resolving the challenges of managing GSD projects. Results also reveal that the list of risk factors submitted in this paper and compiled using a different set of selected studies concurs with the list introduced in a previous research.;
Proceedings of the 27th International Workshop on Software Measurement and 12th International Conference on Software Process and Product Measurement;Context: Coordination in large-scale software development is critical yet difficult as it faces the problem of dependency management and resolution. In this work we focus on managing requirement dependencies that in Agile software development (ASD) come in the form of user stories. Objective: This work studies decisions of large-scale Agile teams regarding identification of dependencies between user stories. Our goal is to explain detection of dependencies through usersâ€™ behavior in large-scale distributed projects. Method: We perform empirical evaluation on a large real-world dataset from an Agile software organization provider of a leading software for Agile project management. We mine the usage data of the Agile Lifecycle Management (ALM) tool to extract large-scale development project data for more than 70 teams running over a five-year period. Results: Our results demonstrate that dependencies among user stories are not frequently observed (the problem affects around 10% of user stories) however their implications on large-scale ASD are considerable. Dependencies have impact on software releases and increase work coordination complexity for members of different teams. Conclusion: Requirement dependencies undermine Agile teamsâ€™ autonomy and are difficult to manage at scale. We conclude that leveraging ALM monitoring data to automatically detect dependencies could help Agile teams address work coordination needs and manage risks related to dependencies in a timely manner.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;All large-scale projects contain a degree of risk and uncertainty. Software projects are particularly vulnerable to overruns due to the this uncertainty and the inherent difficulty of software project cost estimation. In this paper we introduce a search based approach to software project robustness. The approach is to formulate this problem as a multi objective Search Based Software Engineering problem in which robustness and completion time are treated as two competing objectives. The paper presents the results of the application of this new approach to four large real-world software projects using two different models of uncertainty.;
Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computation;Software engineers have to cope with uncertainties and changing requirements. Agile methods provide flexibility towards changes and the emergence of continuous delivery has made regular feedback loops possible. The abilities to maintain high code quality through reviews to regularly release software and to collect and prioritize user feedback are necessary for continuous software engineering (CSE). However there exists no software process metamodel that handles the continuous character of software engineering.In this paper we describe an empirical process metamodel for continuous software engineering called CSEPM which treats development activities as parallel running workflows and allows tailoring and customization. CSEPM includes static aspects that describe the relations between specific CSE concepts including reviews releases and feedback. It also describes the dynamic aspect of CSE how development workflows are activated through change events. We show how CSEPM allows to instantiate linear iterative agile and continuous process models and how it enables tailoring and customization.;
Proceedings of the 3rd International Workshop on Rapid Continuous Software Engineering;The teaching system on software engineering in Kaunas University of Technology is investigated. This system lets students to experience the realistic software engineering problems and environments. In the development of an education system one has to take into account new challenges caused by Software Development Globalization. Organizing the software engineering process we implemented some key practices of repeatable level of Capability Maturity Model. Educational issues that showed up in performing Master study programmes are presented.;
Proceedings of the 2007 International Conference on Computer Systems and Technologies;Identifying similar or identical code fragments becomes much more challenging in code theft cases where plagiarizers can use various automated code transformation techniques to hide stolen code from being detected. Previous works in this field are largely limited in that (1) most of them cannot handle advanced obfuscation techniques (2) the methods based on source code analysis are less practical since the source code of suspicious programs is typically not available until strong evidences are collected and (3) those depending on the features of specific operating systems or programming languages have limited applicability.Based on an observation that some critical runtime values are hard to be replaced or eliminated by semantics-preserving transformation techniques we introduce a novel approach to dynamic characterization of executable programs. Leveraging such invariant values our technique is resilient to various control and data obfuscation techniques. We show how the values can be extracted and refined to expose the critical values and how we can apply this runtime property to help solve problems in software plagiarism detection. We have implemented a prototype with a dynamic taint analyzer atop a generic processor emulator. Our experimental results show that the value-based method successfully discriminates 34 plagiarisms obfuscated by SandMark plagiarisms heavily obfuscated by KlassMaster programs obfuscated by Thicket and executables obfuscated by Loco/Diablo.;
Proceedings of the 33rd International Conference on Software Engineering;Problem: developers are increasingly adopting security practices in software projects in response to cyber threats. Despite the additional effort required to perform those practices current cost models either do not consider security as an input or were not properly validated with empirical data. Hypothesis: increasing degrees of application of security practices and security features motivated by security risks lead to growing levels of added software development effort. Such an effort increase can be quantified through a parametric model that takes as input the usage degrees of security practices and requirements and outputs the additional software development effort. Contributions: the accurate prediction of secure software development effort will support the provision of a proper amount of resources to projects. We also expect that the quantification of the security effort will contribute to advance research on the cost-effectiveness of software security.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings;The American Law Institute has recently published principles of software contracts that may have profound impact on changing the software industry. One of the principles implies a nondisclaimable liability of software vendors for any hidden material defects. In this paper we describe the new principle first from a legal and then from a software engineering point of view. We point out potential ramifications and research directions for the software engineering community.;
Proceedings of the 33rd International Conference on Software Engineering;GreenIT has emerged as a discipline concerned with the optimization of software solutions with regards to their energy consumption. In this domain most of state-of-the-art solutions offer limited or constraining approaches to monitor the energy consumption of a device or a process. In this paper we therefore report on a runtime energy monitoring framework we developed to easily report on the energy consumption of system processes. Concretely our approach adopts an OS-level library called PowerAPI which estimates the power consumption of processes according to different dimensions (CPU network etc.). In order to better understand potential energy leaks of legacy software we use this library to study the impact of programming languages and algorithmic choices on the energy consumption. This preliminary study is based on an empirical evaluation of a eight implementations of the Towers of Hanoi problem.;
Proceedings of the First International Workshop on Green and Sustainable Software;Software engineers are plagued by the same troubles as many others in highly skilled jobs and digitized environments: Ever-expanding to-do lists time to market pressure from management deadline-driven development continuous interruption during working tasks and the juggle of balancing that with other areas of life (physical mental and emotional health family household finance friends hobbies and community service). These demands of life in combination with a seemingly ever-increasing pace wear or burn out many people in the long run. Specifically as software engineers this also leads to decreased creativity and less efficiency in problem-solving. Generally offered solutions are reducing screen time and spending more time outdoors both of which are hard to do within the work of a software engineer. On a meta level if the developers of the systems that run most of our world do not develop individual sustainability with a balanced pace of life that imbalance propagates into the systems we develop (similar to Conway's Law). We argue that mindfulness practices like yoga poses (asanas) breathing practices and meditation exercises can help individually and even more effectively in combination. In this exploratory paper we discuss related work that explores the application of these mitigations in other application domains and propose a research agenda to explore their use within software engineering education and practice.Engaging with mindfulness practices in the context of software engineering promises to enhance creativity and cognitive problem-solving skills leading to more efficiency and effectiveness during software development and increased individual sustainability. This in turn leads to better team spirit as well as increased economic profit both in terms of maintaining human capital and customer contract deliverables.;
Proceedings of the 7th International Conference on ICT for Sustainability;Background: Teamwork is central component of any software development organization. Therefore the assessment of teamwork quality is important for team management in practice. TWQ (Teamwork Quality) is a measure of the quality of intra-team interactions developed specifically for software development teams. Aims: To perform a differentiated replication of previous studies on TWQ to expand the contexts in which TWQ has been applied to refine the measurement instrument increasing its reliability and validity and to identify possibilities for future research on software teams. Method: We performed a cross-sectional survey collecting data from all 18 teams in one single software organization and from all members of each team totaling 123 participants. Results: First we refined the measurement instrument achieving a more reliable and parsimonious instrument. Second our results confirmed findings from previous studies when individual level data was used but almost no confirmation was found when data was aggregated at team level. Conclusions: Our results partially supported previous studies but raised questions about the validity of the aggregation of individual data to team level measures of the studied constructs.;
Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);The competitiveness has demanded from the software industry shorter delivery times for its products resulting in optimized life cycles generating a need to increase its performance to maintain competitiveness in the markets where they operate. This context has made productivity study so fundamental that organizations not only evaluate their performance but also provide means to improve it. The main goal of this paper is to investigate which factors affect productivity in software development projects and in open-source projects. In this work a Systematic Literature Review (SLR) was carried out in order to answer the research questions and a survey with practitioners community about their perception in relation to the factors of the productivity of the team. This empirical study led to the discovery of interesting factors that show how the different factors do (or do not) affect productivity. It was also found out that some factors appear to allow independence and responsibility of team while others appear to cause a better distribution of tasks. The results show how factors such as people product organization investment in technology lack of contractual relations and engagement of open-source project contributors influence productivity.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;In the present research I want to examine what trends and current events are taking place in the application of artificial intelligence in the administrative decision-making. At the same time I want to shed light on the limitations and the required level of competence. Besides I would like to point out the limitations of the application of artificial intelligence. I examined the good practices of many OECD countries on the subject. The results show that the prepared human factor is indispensable and at the same time it is always necessary to ensure the transparency legality and fairness of the applications.;
Proceedings of the Central and Eastern European EDem and EGov Days;Background: The application of the blockchain technology has shown promises in various areas such as smart-contracts Internet of Things land registry management identity management etc. Although Github currently hosts more than three thousand active blockchain software (BCS) projects a few software engineering research has been conducted on their software engineering practices. Aims: To bridge this gap we aim to carry out the first formal survey to explore the software engineering practices including requirement analysis task assignment testing and verification of blockchain software projects. Method: We sent an online survey to 1604 active BCS developers identified via mining the Github repositories of 145 popular BCS projects. The survey received 156 responses that met our criteria for analysis. Results: We found that code review and unit testing are the two most effective software development practices among BCS developers. The results suggest that the requirements of BCS projects are mostly identified and selected by community discussion and project owners which is different from requirement collection of general OSS projects. The results also reveal that the development tasks in BCS projects are primarily assigned on voluntary basis which is the usual task assignment practice for OSS projects. Conclusions: Our findings indicate that standard software engineering methods including testing and security best practices need to be adapted with more seriousness to address unique characteristics of blockchain and mitigate potential threats.;
Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;The treatment of economic and social issues in Software Engineering (SE) was pointed out as a challenge for the next years since SE needs to treat issues beyond the technical side which requires observing it in another perspective. In this sense this paper revisits the concept of components in SE through a sociotechnical construction. Based on a ranking of its critical elements a study shows that components are assets in a set of collaborative/local environments more than in global/corporate markets. So an approach called Brech\'{o;
Proceedings of the Fourth European Conference on Software Architecture: Companion Volume;"Software engineering is one of the few disciplines which continue to lack university clinics"" for software (c.f. hospitals in the medical education). There is no facility specifically designed to enable research in software development that is realistic and open and where measurement data can freely be shared for verification or other purposes. We can keep up debating the need for setting up such an infrastructure or just go ahead and start building it. Software Factory is an initiative that we have had in mind for many years. Shortly put the Software Factory is a strategic investment to a new infrastructure supporting software engineering research education and entrepreneurship globally. The reference implementation of the Factory is now in place and it is currently expanding to its targeted global networked capacity of up to 150 software engineers by the end of 2011. Strikingly the Software Factory of today is not intellectually following the earlier undertakings with the same name stemming back in 1980s in Japan or in the US. Rather it represents the software development of the 2010s. Early results are more than promising. A new company is about to be launched fresh and value-oriented research results are quickly emerging and students find it a place to gain valuable experience.""";
Proceedings of the 11th International Conference on Product Focused Software;Scientific software is application software that supplies data to support decisions in a field of science or engineering. Computational models of climate geographic information systems to study bird habitats analysis software for the safe operation of nuclear generating stations and software to study stresses on concrete structures are only a few of the thousands of examples. This scientific software is largely written by scientists not software specialists. In some organizations there may be a team of scientists and software specialists but the complexity of the science requires the participation of the scientist often as the software developer.;
Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research;Governance has been highlighted as a key factor in the success of an Open Source Software (OSS) project. It is generally seen that in a mixed meritocracy and autocracy governance model the decision-making (DM) responsibility regarding what features are included in the OSS is shared among members from select roles prominently the project leader. However less examination has been made whether members from these roles are also prominent in DM discussions and how decisions are made to show they play an integral role in the success of the project. We believe that to establish their influence it is necessary to examine not only discussions of proposals in which the project leader makes the decisions but also those where others make the decisions. Therefore in this study we examine the prominence of members performing different roles in: (i) making decisions (ii) performing certain social roles in DM discussions (e.g. discussion starters) (iii) contributing to the OSS development social network through DM discussions and (iv) how decisions are made under both scenarios. We examine these aspects in the evolution of the well-known Python project. We carried out a data-driven longitudinal study of their email communication spanning 20 years comprising about 1.5 million emails. These emails contain decisions for 466 Python Enhancement Proposals (PEPs) that document the languageâ€™s evolution. Our findings make the influence of different roles transparent to future (new) members other stakeholders and more broadly to the OSS research community.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;Advanced programming and software engineering techniques are challenging to learn due to their inherent complexity. However to the average student they are even more challenging because they have never experienced the context in which the techniques are appropriate. For instance why learn design patterns to increase maintainability when student exercises are never maintained? In this paper we outline the contextual problems that software engineering teaching has to deal with and present a story telling approach for course design as a remedy. We outline the stories that over the last five years have structured lecturing and mandatory exercises for our advanced programming/software engineering course and present benefits liabilities and experiences with the approach comparing it to the normal topic structured course design.;
Proceedings of the 14th Annual ACM SIGCSE Conference on Innovation and Technology in Computer Science Education;An agile approach has become very popular over the last decade which requires good communication and teamwork within teams as well as with outside stakeholders. Therefore social interaction is central for a software development team to be successful. Such social interactions form social identities and social structures in both teams and organizations. This study investigates possible effects that the social identity of individuals may have on the effectiveness of software development through seven in-dept interviews. The qualitative data from interviews were analyzed and summarized using summative content analysis and the seven individuals also answered a questionnaire on social identity taken from social psychology research. The qualitative result shows that aspects of social identity affect software developers' behavior and that we need to build cross-functional stable teams over time also from a pure social identity perspective in addition to the product related aspects to avoid a decreased effectiveness. However we did not see clear connections to our operationalization of effectiveness in this study and the quantitative analysis was also inconclusive but we see value in our suggested method when investigating social identity in software development.;
Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering;This paper describes our approach for conducting a group project in a software engineering course. We organize students into an actual software development company and conduct activities that mimic real-world operations in that company. We have applied this approach to our group projects for the past four years with excellent results.;
CodeWalk: Facilitating Shared Awareness in Mixed-Ability Collaborative Software Development;COVID-19 accelerated the trend toward remote software development increasing the need for tightly-coupled synchronous collaboration. Existing tools and practices impose high coordination overhead on blind or visually impaired (BVI) developers impeding their abilities to collaborate effectively compromising their agency and limiting their contribution. To make remote collaboration more accessible we created CodeWalk a set of features added to Microsoftâ€™s Live Share VS Code extension for synchronous code review and refactoring. We chose design criteria to ease the coordination burden felt by BVI developers by conveying sighted colleaguesâ€™ navigation and edit actions via sound effects and speech. We evaluated our design in a within-subjects experiment with 10 BVI developers. Our results show that CodeWalk streamlines the dialogue required to refer to shared workspace locations enabling participants to spend more time contributing to coding tasks. This design offers a path towards enabling BVI and sighted developers to collaborate on more equal terms.;
Proceedings of the 24th International ACM SIGACCESS Conference on Computers and Accessibility;Traceability is the ability to relate di erent artifacts during the development and operation of a system to each other. It enables program comprehension change impact analysis and facilitates the cooperation of engineers from di erent disciplines. The 10th International Workshop on Software and Systems Traceability (former International Workshop on Traceability in Emerging Forms of Software Engineering TEFSE) explored the role and impact of traceability in modern software and systems development. The event brought together researchers and practitioners to examine the challenges of recovering maintaining and utilizing traceability for the myriad forms of software and systems engineering artifacts. SST'19 was a highly interactive working event focused on discussing the main problems related to software traceability in particular in the context of opportunities and challenges posed by the recent progress in Arti cial Intelligence techniques and proposing possible solutions for such problems.;
Cooperation between developers and operations in software engineering projects;In this paper we discuss how the cooperation between developers and operations staff is practiced. We have analyzed data collected from a focus group of experienced software engineers and project managers as well as interviews from two case studies. Our position is that well performed cooperation between the development team and the operations team is crucial for successful deployment and operations of a new or extensively revised software system. The data shows that cooperation can be improved in several development activities like requirements engineering system design documentation testing training and deployment planning. Likely consequences of poor cooperation in these activities are lower productivity in development and operations as well as unsatisfied users.;
Proceedings of the 2008 International Workshop on Cooperative and Human Aspects of Software Engineering;Modern research in the sciences engineering humanities and other fields depends on software and specifically research software. Much of this research software is developed in universities by faculty postdocs students and staff. In this paper we focus on the role of university staff. We examine three different independently-developed models under which these staff are organized and perform their work and comparatively analyze these models and their consequences on the staff and on the software considering how the different models support software engineering practices and processes. This information can be used by software engineering researchers to understand the practices of such organizations and by universities who want to set up similar organizations and to better produce and maintain research software.;
Proceedings of the 14th International Workshop on Software Engineering for Science;Although computer-aided software engineering (CASE) is one of the most current and interesting subjects within software engineering relatively little has been published on the issue of teaching CASE at the graduate level. This paper reports a case study in teaching a graduate-level course on CASE tools in a span of six years. We explain the structure and contents of the course describe the work the students perform as their term project and summarize the outcome and lessons learned in five course offerings. The issues discussed in this paper might help educational institutions and college professors in designing and implementing software engineering courses at the graduate level.;
Proceedings of the 13th Annual Conference on Innovation and Technology in Computer Science Education;Background: Studies related to human factors in software engineering are providing insightful information on the emotional state of contributors and the impact this has on the code. The open source software development paradigm involves different roles and previous studies about emotions in software development have not taken into account what different roles might play when people express their feelings. Aim: We present an analysis of issues and commits on five GitHub projects distinguishing contributors between users and developers and between one-commit and multi-commit developers. Method: We analyzed more than 650K comments from 130K issues of 64K contributors. We calculated emotions (love joy anger sadness) and politeness of the comments related to the issues of the considered projects and introduced the definition of contributor fan-in and fan-out. Results: Results show that users and developers communicate differently as well as multi-commit developers and one-commit developers do. Conclusions: We provide empirical evidence that one-commit developers are more active and more polite in posting comments. Multi-commit developers are less active in posting comments and while commenting they are less polite than when commented.;
Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering;"Digital technologies represented by the Internet have influenced micro-economic agents' cognitive decisions. We review the effects of Internet technologies on the cognitions and decisions of microeconomic agents systematically. For individuals the Internet has reshaped their cognition with the information shock the Google effect"" and social networks. Individual decisions depend on personal cognitions hence we further clarify the impact of the Internet on individual behavior and decisions such as fertility decisions house purchasing decisions and financial investment decisions. For enterprises we consider Internet Big Data-assisted decision-making. Enterprises can make relevant business decisions such as targeted advertising product improvement and price discrimination by mining big data and using artificial intelligence algorithms. We find that internet technology can directly impact human intelligence (cognition) and influence individual decisions. Internet technology such as artificial intelligence algorithms can also assist individual decisions.""";
5th International Conference on Crowd Science and Engineering;Context: Since software development is a complex socio-technical activity that involves coordinating different disciplines and skill sets it provides ample opportunities for waste to emerge. Waste is any activity that produces no value for the customer or user.Objective: The purpose of this paper is to identify and describe different types of waste in software development.Method: Following Constructivist Grounded Theory we conducted a two-year five-month participant-observation study of eight software development projects at Pivotal a software development consultancy. We also interviewed 33 software engineers interaction designers and product managers and analyzed one year of retrospection topics. We iterated between analysis and theoretical sampling until achieving theoretical saturation.Results: This paper introduces the first empirical waste taxonomy. It identifies nine wastes and explores their causes underlying tensions and overall relationship to the waste taxonomy found in Lean Software Development.Limitations: Grounded Theory does not support statistical generalization. While the proposed taxonomy appears widely applicable organizations with different software development cultures may experience different waste types.Conclusion: Software development projects manifest nine types of waste: building the wrong feature or product mismanaging the backlog rework unnecessarily complex solutions extraneous cognitive load psychological distress waiting/multitasking knowledge loss and ineffective communication.;
Proceedings of the 39th International Conference on Software Engineering;Pushed by market forces software development has become fast-paced. As a consequence modern development projects are assembled from 3rd-party components. Security &amp privacy assurance techniques once designed for large controlled updates over months or years must now cope with small continuous changes taking place within a week and happening in sub-components that are controlled by third-party developers one might not even know they existed. In this paper we aim to provide an overview of the current software security approaches and evaluate their appropriateness in the face of the changed nature in software development. Software security assurance could benefit by switching from a process-based to an artefact-based approach. Further security evaluation might need to be more incremental automated and decentralized. We believe this can be achieved by supporting mechanisms for lightweight and scalable screenings that are applicable to the entire population of software components albeit there might be a price to pay.;
Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results;"Currently professors are using a variety of team assignment techniques to form software engineering teams. This research believes that a contributing factor to the undesired outcomes (i.e. low performing teams and high levels of conflict) of software engineering teams is that the teams were not formed using relevant and salient"" criteria. To address the relevance issue we test the impact of problem solving preferences (a sub-set of the MBTI scale) on group conflict and performance. We then test the extent to which the numerical dominance (i.e. salience) of problem solving styles influences conflict and performance. It was found that dominance of problem solving styles is related to negative team outcomes. We conclude by discussing ways in which instructors and team members may minimize negative team outcomes when there is no choice other than forming a team with one dominant problem solving preference.""";
Code-level model checking in the software development workflow;This experience report describes a style of applying symbolic model checking developed over the course of four years at Amazon Web Services (AWS). Lessons learned are drawn from proving properties of numerous C-based systems e.g. custom hypervisors encryption code boot loaders and an IoT operating system. Using our methodology we find that we can prove the correctness of industrial low-level C-based systems with reasonable effort and predictability. Furthermore AWS developers are increasingly writing their own formal specifications. All proofs discussed in this paper are publicly available on GitHub.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice;This paper argues that conceptual models and more specifically reference models play a key role in the specification and design of information systems. However an effective evaluation strategy of such models is a relatively immature field. The paper presents the key challenges for this evaluation activity and articulates an approach for understanding how to evaluate models based on the information and cognitive theories of structuralism and conversation theory. An example of a reference model developed for the Higher Education domain is used as a case study to illustrate how the approach may be applied.;
Proceedings of the 2nd India Software Engineering Conference;MADMAX is a Haskell-embedded DSL for multi-attribute multi-layered decision making. An important feature of this DSL is the ability to generate explanations of why a computed optimal solution is better than its alternatives.  The functional approach and Haskell's type system support a high-level formulation of decision-making problems which facilitates a number of innovations including the gradual evolution and adaptation of problem representations a more user-friendly form of sensitivity analysis based on problem domain data and fine-grained control over explanations.;
Proceedings of the 20th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences;Academic disruptions are an eventuality that must be anticipated and handled in an efficacious manner. While many schools have general plans especially for hurricane and other weather-related disruptions the COVID-19 pandemic has elevated the issue beyond regional risk mitigation. Team-based software engineering and capstone courses in computer science are especially vulnerable to these types of disruptions and this in turn risks the attainment of key student and program outcomes near the culmination of the academic program. By practicing some of the processes and tools they preach however software engineering courses have a natural advantage and ability to adapt rapidly to changes. This paper recommends specific classroom adaptations for professional software engineering practices and tools provides a sample rubric and assessment instruments recommends instruction approaches that ensure continuity of instruction and concludes with a brief experience report for recent hurricane and COVID-19 disruptions.;
An empirical study of specification by example in a software engineering tool;Meta-CASE tools offer CASE tool specialisation by enabling a designer to specify a tool which is then generated automatically. Constraints are often used in such meta-CASE tools for governing the syntax and semantics of model elements and the values of their attributes. However the constraint definition process is complex time-consuming and error-prone. This paper presents an empirical study of the use of Specification by Example (SBE) based on the well-known notion of Programming by Example (PBE) as a user-computer interactive technique for such constraint specification. Two constraint specification techniques have been implemented in a meta-CASE tool a wizard that represents a conventional form-filling technique and an SBE technique that depends on the user providing one or more examples and the system inferring a list of possible intended constraints. The empirical study compared the wizard and SBE with respect to constraint definition correctness task completion time and user satisfaction. Two common modelling diagrams have been used a State Transition Diagram and a Use Case Diagram. Results suggest that SBE is superior to the wizard in terms of measured criteria described above. Observations on the interaction of users with the system and opinions of participants are also presented.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;Datasets that power machine learning are often used shared and reused with little visibility into the processes of deliberation that led to their creation. As artificial intelligence systems are increasingly used in high-stakes tasks system development and deployment practices must be adapted to address the very real consequences of how model development data is constructed and used in practice. This includes greater transparency about data and accountability for decisions made when developing it. In this paper we introduce a rigorous framework for dataset development transparency that supports decision-making and accountability. The framework uses the cyclical infrastructural and engineering nature of dataset development to draw on best practices from the software development lifecycle. Each stage of the data development lifecycle yields documents that facilitate improved communication and decision-making as well as drawing attention to the value and necessity of careful data work. The proposed framework makes visible the often overlooked work and decisions that go into dataset creation a critical step in closing the accountability gap in artificial intelligence and a critical/necessary resource aligned with recent work on auditing processes.;
Proceedings of the 2021 ACM Conference on Fairness Accountability and Transparency;Open source software represents an important form of digital infrastructure as well as a pathway to technical careers for many developers but women are drastically underrepresented in this setting. Although there is a good body of literature on open source participation there is very little understanding of the participation trajectories and contribution experiences of women developers and how they compare to those of men developers in open source software projects. In order to understand their joining and participation trajectories we conducted interviews with 23 developers (11 men and 12 women) who became core in an open source project. We identify differences in women and men's motivations for initial contributions and joining processes (e.g. women participating in projects that they have been invited to) and sustained involvement in a project. We also describe unique negative experiences faced by women contributors in this setting in each stage of participation. Our results have implications for diversifying participation in open source software and understanding open source as a pathway to technical careers.;
Multi-objective Integer Programming Approaches for Solving the Multi-criteria Test-suite Minimization Problem: Towards Sound and Complete Solutions of a Particular Search-based Software-engineering Problem;Test-suite minimization is one key technique for optimizing the software testing process. Due to the need to balance multiple factors multi-criteria test-suite minimization (MCTSM) becomes a popular research topic in the recent decade. The MCTSM problem is typically modeled as integer linear programming (ILP) problem and solved with weighted-sum single objective approach. However there is no existing approach that can generate sound (i.e. being Pareto-optimal) and complete (i.e. covering the entire Pareto front) Pareto-optimal solution set to the knowledge of the authors. In this work we first prove that the ILP formulation can accurately model the MCTSM problem and then propose the multi-objective integer programming (MOIP) approaches to solve it. We apply our MOIP approaches on three specific MCTSM problems and compare the results with those of the cutting-edge methods namely NonlinearFormulation_LinearSolver (NF_LS) and two Multi-Objective Evolutionary Algorithms (MOEAs). The results show that our MOIP approaches can always find sound and complete solutions on five subject programs using similar or significantly less time than NF_LS and two MOEAs do. The current experimental results are quite promising and our approaches have the potential to be applied for other similar search-based software engineering problems.;
An extended reality approach for creating immersive software project workspaces;Software project workspaces are areas of constant project activities across different phases of the software development lifecycle. Besides being physical spaces to house the team members these are also areas of teamwork creativity and collaboration. It is well established that there are several information and insight needs of software teams (both individual and collective) during the course of any project. Interestingly the use of the project workspaces themselves for assisting in getting those insights has been almost non-existent and there is little technological support for doing so. Here we present our approach that utilizes advances in extended reality to augment the software project bay with important insights which are anchored on and around real objects in the workspace. The approach is based upon mining the data exhaust (disparate sources of data and logs) of the software project and development environment for data important to construct insights relevant to an XR headset wearer and the team. The wearer's location and parts of the workspace (floors furniture ceilings) are detected in the wearer's field of view and thereon spatial mapping is utilized to overlay important representations of the relevant insights onto/around them. The immersive insights are contextual can be continuously updated and leverage affordances of human perception for better comprehension enhanced creativity as well as recall. Along with our approach we also present an early Microsoft Hololens based implementation which allows for different categories of live augmentations for creating a smart immersive workspace.;
Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering;The field of Software Development Software Estimation in Software Engineering is critical due to its practical importance and very challenging due to the lack of a globally best model able to predict accurately the effort (and therefore the cost) of any new software project. After a long research period on different models and their improvements the research interest is directed towards ensemble methods i.e. methods which combine the results of different single models. Furthermore it is desirable to characterise the accuracy of models by different criteria. In this study we develop a methodology based on the Data Envelopment Analysis technique well-known in operation research so as to rank different models based on multiple criteria and then to combine the best of them in order to achieve better prediction performance. The experimentation involves 93 models applied to 10 datasets and provides very promising results regarding the performance of the proposed ensemble approach.;
Proceedings of the 24th Pan-Hellenic Conference on Informatics;Proper calibration of human reliance on AI is fundamental to achieving complementary performance in AI-assisted human decision-making. Most previous works focused on assessing user reliance and more broadly trust retrospectively through user perceptions and task-based measures. In this work we explore the relationship between eye gaze and reliance under varying task difficulties and AI performance levels in a spatial reasoning task. Our results show a strong positive correlation between percent gaze duration on the AI suggestion and user AI task agreement as well as user perceived reliance. Moreover user agency is preserved particularly when the task is easy and when AI performance is low or inconsistent. Our results also reveal nuanced differences between reliance and trust. We discuss the potential of using eye gaze to gauge human reliance on AI in real-time enabling adaptive AI assistance for optimal human-AI team performance.;
How Shortening or Lengthening Design Processes Configure Decision Making;There have been repeated calls for developing time-sensitive discourses in HCI and design research and for re-examining engagement with power. In response we explore the relationship between time and decision making in design processes in order to better understand how this configures power structures. We analyse two design cases: a short-term hackathon and a long-term design process. We argue that the different temporalities of design activities configure decision making â€” and thereby power â€” and that both short- and long-term design processes differ in the ways of engaging people in designing technology: Decisions on values and concepts are prioritised in long-term design processes decisions about implementing the vision are prioritised in short-term design processes decisions requiring negotiations with the outside world are structurally limited in short-term design processes non-decisions in short term design processes are pragmatic and habitual in long-term design processes.;
Nordic Human-Computer Interaction Conference;This paper provides an overview of how software engineering techniques can be applied in decision support systems courses. Specifically this paper describes a systematic course of action for documenting and developing a decision support system for a dynamic application. The course of action is grounded in the software engineering research methodology (SERM) as well as the waterfall software development lifecycle. A case study on the documentation and development of a web-based cost estimator for application for the Al-Sawaf Trading Establishment (ATE) is presented. The paper concludes with lessons learned and recommendations for applying software engineering techniques in other computing courses.;
Lean learning: applying lean techniques to improve software engineering education;"Building a programme of education that reflects and keeps pace with industrial practice is difficult. We often hear of a skills shortage in the software industry and the gap between what people are taught in university and the real world"". This paper is a case study showing how we have developed a programme at Imperial College London that bridges this gap providing students with relevant skills for industrial software engineering careers. We give details of the structure and evolution of the programme which is centred on the tools techniques and issues that feature in the everyday life of a professional developer working in a modern team. We also show how aligning our teaching methods with the principles of lean software delivery has enabled us to provide sustained high quality learning experiences. The contributions of this paper take the form of lessons learnt which may be seen as recommendations for others looking to evolve their own teaching structures and methods.""";
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;Precise estimation of time and effort in the lifecycle of a project plays an important role in delivering a final product on time within an established budget and with expected quality. Inappropriate estimation of effort may lead to overestimation or underestimation of required resources. As people remain to be a constant part of the software development process they should also be considered as an influencing factor in software development estimation process. This work presents the most popular estimation techniques that are used by the survey sample. The questionnaire was completed by 51 participants with industrial experience in Innopolis. The goal was to find differences between roles in software development teams and the techniques that are used to estimate efforts. The result of the survey used to derive main groups of the respondents and map them to estimation techniques. These mappings were analyzed and compared between two main groups to find tendencies differences and similarities. The study is considered to help understand patterns of effort estimation among software engineers and revising existing estimation techniques.;
Proceedings of the 2020 European Symposium on Software Engineering;Software development includes diverse tasks such as implementing new features analyzing requirements and fixing bugs. Being an expert in those tasks requires a certain set of skills knowledge and experience. Several studies investigated individual aspects of software development expertise but what is missing is a comprehensive theory. We present a first conceptual theory of software development expertise that is grounded in data from a mixed-methods survey with 335 software developers and in literature on expertise and expert performance. Our theory currently focuses on programming but already provides valuable insights for researchers developers and employers. The theory describes important properties of software development expertise and which factors foster or hinder its formation including how developers' performance may decline over time. Moreover our quantitative results show that developers' expertise self-assessments are context-dependent and that experience is not necessarily related to expertise.;
Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Decision-making algorithms are being used in important decisions such as who should be enrolled in health care programs and be hired. Even though these systems are currently deployed in high-stakes scenarios many of them cannot explain their decisions. This limitation has prompted the Explainable Artificial Intelligence (XAI) initiative which aims to make algorithms explainable to comply with legal requirements promote trust and maintain accountability. This paper questions whether and to what extent explainability can help solve the responsibility issues posed by autonomous AI systems. We suggest that XAI systems that provide post-hoc explanations could be seen as blameworthy agents obscuring the responsibility of developers in the decision-making process. Furthermore we argue that XAI could result in incorrect attributions of responsibility to vulnerable stakeholders such as those who are subjected to algorithmic decisions (i.e. patients) due to a misguided perception that they have control over explainable algorithms. This conflict between explainability and accountability can be exacerbated if designers choose to use algorithms and patients as moral and legal scapegoats. We conclude with a set of recommendations for how to approach this tension in the socio-technical process of algorithmic decision-making and a defense of hard regulation to prevent designers from escaping responsibility.;
Proceedings of the 2022 ACM Conference on Fairness Accountability and Transparency;With the rise of containerization cloud development and continuous integration and delivery configuration has become an essential aspect not only to tailor software to user requirements but also to configure a software systemâ€™s environment and infrastructure. This heterogeneity of activities domains and processes blurs the term configuration as it is not clear anymore what tasks artifacts or stakeholders are involved and intertwined. However each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit. This makes it difficult to compare findings translate them to practice and to generalize the results. Thus we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella. By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas we derive a model of configuration that provides terminology and context for research studies identifies new research opportunities and allows practitioners to spot possible challenges in their current tasks. Although our interviewees have a clear view about configuration it substantially differs due to their personal experience and role. This indicates that the term configuration might be overloaded. However when taking a closer look we see the interconnections and dependencies among all views arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;"This work presents an approach for realizing Model-Driven software engineering in the distributed and multi-developers context. It particularly focuses on the scalability problems in a complex software project involving a large set of inter-connected models: (1) how to manipulate large data volume with limited computing resources and (2) how to maintain consistency of inter-model links in a large model set facing to concurrent model updates. As a solution we propose the scalable copy-modify-merge mechanism which allows each developer to copy only a model subset from the entire model set to manipulate this subset locally and to merge it back to the repository. This mechanism ensures the global consistency of the model set particularly against dangling links. Our approach is generic: it is applicable to all model types (UML and Domain-Specific Models). Also it offers interoperability with existing heterogeneous CASE tools. Its prototype implementation in the ModelBus environment is now available on the Eclipse project MDDi"".""";
Proceedings of the 2008 ACM Symposium on Applied Computing;In empirical disciplines data sharing leads to verifiable research and facilitates future research studies. Recent efforts of the PROMISE community contributed to data sharing and reproducible research in software engineering. However an important portion of data used in empirical software engineering research still remains classified. This situation is unlikely to change because many companies governments and defense organizations will be always hesitant to share their project data such as effort and defect data due to various confidentiality privacy and security concerns. In this paper we present demonstrate and evaluate a novel tree-based data perturbation approach. This approach does not only preserve privacy effectively but it also preserves the predictive patterns in the original data set. Consequently the empirical software engineering researchers will have access to another category of data sets transformed data sets which will increase the verifiability of research results and facilitate the future research studies in this area. Our approach can be immediately useful to many researchers and organizations who are willing to share their software engineering data but cannot do so due to privacy concerns.;
Proceedings of the 5th International Conference on Predictor Models in Software Engineering;The COVID-19 pandemic has lasted for over 1 year. During the pandemic several software development companies migrated to working from home (WFH). Several studies have recorded an initial moment of adaptation to WFH. This study investigated how Brazilian software development teams dealt with WFH after 1 year of a pandemic and how this change in work was on the software development process. We applied a survey with 67 participants of software development teams and investigated aspects as: work routine collaboration communication productivity financial assistance and software development process. We performed a quantitative and qualitative analysis of the survey results and compared them with previous studies. Our key findings are: (i) 56.71% of the participants said that it has an impact on the work routine related to work overload and exceeds the companyâ€™s standard hours (ii) 92.54% of the participants consider their team to be collaborative (iii) 82.70% are satisfied with the communication at WFH (iv) 86.55% has meetings once or twice a day (v) 59.7% had an improvement in productivity in WFH and 75% are satisfied with their productivity (vi) 79.60% receive some assistance from the company for WFH (vii) 82.1% said that the company intends or probably intends to continue in the WFH and (viii) 55.2% said they had changed in the software development process due to WFH. The main positive changes in the process are related to the practices of: daily meetings agile processes code review pair programming and code versioning.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;Low-quality software products are synonymous with small software companies yet thousands of process tools and methods are available although unfortunately they remain unutilized. The utilization of these process tools are said to be very challenging to small software companies with the difficulty of adaptability tagged to the context in which the companies operate since the process tools are not designed to take care of the operational context of the small software companies. This survey study was undertaken to empirically investigate the implication of the organizational dynamics on using process tools in SSCs. A total of 115 respondents from Tanzania Namibia and Ghana were reached through a structured questionnaire. Our findings reveal that the ad-hoc behaviors and attitude breed a culture that inhibits procedural and process-intensive practices synonymous with most software engineering process tools. This finding is interesting because this area has been underestimated while looking at software practice yet it is significant in understanding practice in relation to software process tools significantly how small software companies can be helped to adopt the different tools and also provide a mechanism to help the designers of process tools make tools that are usable in the context of the practice of SSCs.;
Proceedings of the 10th International Conference on Software and Information Engineering;Aiming at the waste of irrigation water resources caused by inaccurate irrigation in mango orchard a mango accurate irrigation decision-making system based on Lora is designed and developed to improve the yield and quality of mango. The system forms a wireless transmission and remote control network by wireless soil moisture sensor Lora data transmission terminal PLC control center plc4G gateway etc. Soil moisture data is wirelessly transmitted to the cloud platform in real time and then is transmitted to the precision irrigation decision-making system through OPC for analysis processing and storage. The intelligent remote control of the start-stop operation of valves in the irrigation area is realized through the PLC control center. The experiment on system timeliness and accuracy is carried out in mango orchard. According to experimental results the absolute error between the temperature and humidity data collected by soil moisture sensor and the standard value was small the measured temperature and humidity data was more accurate and the accuracy of the data collected by soil moisture sensor was higher the irrigation decision-making system started quickly as a whole the instruction delay was small and the data reporting was relatively rapid the system had good overall timeliness and accuracy. It could realize the precise irrigation of mango and achieve the purpose of water saving.;
Proceedings of the 7th International Conference on Cyber Security and Information Engineering;Context: Quality requirements (QRs) have a significant role in the success of software projects. In agile software development (ASD) where working software is valued over comprehensive documentation QRs are often under-specified or not documented. Consequently they may be handled improperly and result in degraded software quality and increased maintenance costs. Investigating the documentation of QRs in ASD would provide evidence on existing practices tools and aspects considered in ASD that other practitioners might utilize to improve documentation and management of QRs in ASD. Although there are some studies examining documentation in ASD those that specifically investigate the documentation of QRs in depth are lacking.Method: we conducted a multiple case study by interviewing 15 practitioners of four ASD cases to provide empirical evidence on documentation of QRs in ASD. We also run workshops with two of the cases to identify important aspects that ASD practitioners consider when documenting QRs in requirements management repositories.Result and conclusions: ASD companies approach documentation of QRs to fit the needs of their context. They used tools backlogs iterative prototypes and artifacts such as epic and stories to document QRs or utilized face-face communication without documenting QRs. We observed that documentation of QRs in ASD is affected by factors such as context (e.g. product domain and size) and the experience of practitioners. Some tools used to document QRs also enhanced customer collaboration enabling customers report and document QRs. Aspects such as levels of abstraction the traceability of QRs optimal details of information of QRs and verification and validation are deemed important when documenting QRs in ASD requirements management repositories.;
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;"A Real Projects for Real Clients Course (RPRCC) is a course that provides students with the opportunity to develop a solution to a real problem. Students interact directly with a real client and work on solving a problem for that client. RPRCCs are examples of service learning. Within the computing sciences there has been a recent surge in the integration of RPRCCs into the curriculum. They are argued to offer an increased industrial awareness and to help retain computing majors especially among women. In this paper we present our experiences with a senior-level computer science course on software engineering (SE) at a liberal arts institution. We have found that recruiting so-called real clients"" from within the liberal arts college setting is surprisingly easy and that once you have established an initial set of clients is mostly self-sustaining. We demonstrate that an RPRCC enables students to develop their skills in teamwork and applied problem solving. The RPRCC offers the SE course a framework where students gain experience applying a variety of software architectures design patterns and other important SE concepts and simultaneously develop teamwork skills.""";
Software engineering smartphones and health systems and security warnings;The Communications Web site http://cacm.acm.org features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications we'll publish excerpts from selected posts.twitterFollow us on Twitter at http://twitter.com/blogCACMGreg Linden writes about frequent software deployments Ruben Ortega reports on smartphones and health systems research and Jason Hong discusses designing effective security warnings.;
Eagle: a team practices audit framework for agile software development;Agile/XP (Extreme Programming) software teams are expected to follow a number of specific practices in each iteration such as estimating the effort (â€pointsâ€) required to complete user stories properly using branches and pull requests to coordinate merging multiple contributorsâ€™ code having frequent â€standupsâ€ to keep all team members in sync and conducting retrospectives to identify areas of improvement for future iterations. We combine two observations in developing a methodology and tools to help teams monitor their performance on these practices. On the one hand many Agile practices are increasingly supported by web-based tools whose â€data exhaustâ€ can provide insight into how closely the teams are following the practices. On the other hand some of the practices can be expressed in terms similar to those developed for expressing service level objectives (SLO) in software as a service as an example a typical SLO for an interactive Web site might be â€over any 5-minute window 99% of requests to the main page must be delivered within 200msâ€ and analogously a potential Team Practice (TP) for an Agile/XP team might be â€over any 2-week iteration 75% of stories should be â€™1-pointâ€™ storiesâ€. Following this similarity we adapt a system originally developed for monitoring and visualizing service level agreement (SLA) compliance to monitor selected TPs for Agile/XP software teams. Specifically the system consumes and analyzes the data exhaust from widely-used tools such as GitHub and Pivotal Tracker and provides team(s) and coach(es) a â€dashboardâ€ summarizing the teamsâ€™ adherence to various practices. As a qualitative initial investigation of its usefulness we deployed it to twenty student teams in a four-sprint software engineering project course. We find an improvement of the adherence to team practice and a positive studentsâ€™ self-evaluations of their team practices when using the tool compared to previous experiences using an Agile/XP methodology. The demo video is located at &lta&gthttps://youtu.be/A4xwJMEQh9c&lt/a&gt and a landing page with a live demo at &lta&gthttps://isa-group.github.io/2019-05-eagle-demo/&lt/a&gt.;
Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;The economic and strategic gain attracts the software industry to adopt the global software development (GSD) phenomenon. Besides the significant advantages the GSD firms also face certain critical challenges mainly related to security and management perspective. Blockchain is the new revolutionary technology that offers over the globe secure storage via distributed databases. The objective of this study is to investigate how the adoption of blockchain is beneficial for the GSD project. We have conducted interviews with academic researchers and case studies with industry practitioners to identify the impact of blockchain on GSD projects. We have identified ten key critical areas of GSD the effectively addressed by using the blockchain technology in GSD context. A comparative analysis is conducted with the finding of academic researcher and industry practitioners and the results ((W=0.86 p=0.005) shows that there is a strong agreement between the understanding of academic researchers and industry practitioners. Besides we have developed a hypothetical model based on the findings of both studies that shows the positive relationship of blockchain implementation in the GSD domain. We believe that the findings of this study will encourage the practitioners and researchers to develop the new plan and strategies for the adoption of blockchain in GSD.;
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;Recent years have witnessed the growing literature in empirical evaluation of explainable AI (XAI) methods. This study contributes to this ongoing conversation by presenting a comparison on the effects of a set of established XAI methods in AI-assisted decision making. Based on our review of previous literature we highlight three desirable properties that ideal AI explanations should satisfy â€” improve peopleâ€™s understanding of the AI model help people recognize the model uncertainty and support peopleâ€™s calibrated trust in the model. Through three randomized controlled experiments we evaluate whether four types of common model-agnostic explainable AI methods satisfy these properties on two types of AI models of varying levels of complexity and in two kinds of decision making contexts where people perceive themselves as having different levels of domain expertise. Our results demonstrate that many AI explanations do not satisfy any of the desirable properties when used on decision making tasks that people have little domain expertise in. On decision making tasks that people are more knowledgeable the feature contribution explanation is shown to satisfy more desiderata of AI explanations even when the AI model is inherently complex. We conclude by discussing the implications of our study for improving the design of XAI methods to better support human decision making and for advancing more rigorous empirical evaluation of XAI methods.;
Attitudes beliefs and development data concerning agile software development practices;The perceptions and attitudes of developers impact how software projects are run and which development practices are employed in development teams. Recent agile methodologies have taken this into account focusing on collaboration and shared team culture. In this research we investigate the perceptions of agile development practices and their usage in Scrum software development teams. Although perceptions collected through surveys of 42 participating students did not evolve significantly over time our analyses show that the Scrum role significantly impacted participants' views of employed development practices. We find that using the version control system according to agile ideas was consistently rated most related to the values of the Agile Manifesto. Furthermore we investigate how common software development artifacts can be used to gain insights into team behavior and present the development data measurements we employed. We show that we can reliably detect well-defined agile practices such Test-Driven Development in this data and that usage of these practices coincided with participants' self-assessments.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training;Context: Crowdsourcing software development (CSSD) is a form of collective intelligence that is gaining attention in the Information Technology industry as a work alternative for software projects. CSSD represents a paradigm shift in the in-house development approach promising deliveries with quality productivity and innovation. Problem: CSSD is an emerging approach both in research and in practice. Despite the existence of commercial supporting platforms organizations of different sizes still face the challenge of how to organize the collective work and a clear definition of how to perform CSSD is not known yet. Solution: This article presents an analysis of the literature to identify the main processes practices tools and platforms used in CSSD initiatives and to understand the benefits and challenges reported in these initiatives as well. IS theory: Not applicable. Method: Descriptive research based on systematic literature mapping. Summary of Results: CSSD is understood as a democratic alternative with great potential for improving quality productivity and innovation in software projects. However challenges for its realization are many and of different kinds (technical managerial methodological and legal). Results also show not a large amount of CSSD case study reports in real situations. Contributions and Impact on the IS area: This work provides an overview of CSSD application as well as a critical analysis of its advantages and challenges contributing with discussions to the challenge of Information Systems and the Open World. This overview enables reflection on the adoption of CSSD stimulating the research of solutions under development by crowds for companies of different sizes.;
Proceedings of the XVIII Brazilian Symposium on Information Systems;Data science education is a new area in computer science that has attracted increasing attention in recent years. However currently data science educators lack good tools and methodologies. In particular they lack integrated tools through which their students can acquire hands-on software engineering experience. To address these problems we designed and implemented DataLab a web-based tool for data science education that integrates code data and execution management into one system. The goal of DataLab is to provide a hands-on online lab environment to train students to have basic software engineering thinking and habits while maintaining a focus on the core data science contents. In this paper we present the user-experience design and system-level implementation of DataLab. Further we evaluate DataLab's performance through an in-classroom use case. Finally using objective log-based learning behavior analysis and a subjective survey we demonstrate DataLab's effectiveness.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track;We have developed software tools that aim to support the cooperative software engineering tasks and promote an awareness of social dependencies that is essential to successful coordination. The tools share common characteristics that can be traced back to the principles of the Continuous Coordination (CC) paradigm. However the development of each sprung from carrying out a different set of activities during its development process. In this paper we outline the principles of the CC paradigm the tools that implement these principles and focus on the social aspects of software engineering. Finally we discuss the socio-technical and human-centered processes we adopted to develop these tools. Our conclusion is that the cooperative dimension of our tools represents the cooperation between researchers subjects and field sites. Our conclusion suggests that the development processes adopted to develop like-tools need to reflect this cooperative dimension.;
Proceedings of the 2008 International Workshop on Cooperative and Human Aspects of Software Engineering;The objective of the paper is to present generalized approach in design and development of industrial automation systems based on software engineering principles including unified modeling language UML and concept of reusable software and COTS software modules. The said generalization is illustrated on the case example of the design and engineering of the software for one real life project that Faculty software engineering group has completed for local engineering firm. The said project involves monitoring and control system for the refinery oil terminal with truck loading and pipeline shipping of petroleum products. System architecture is based on PLC controllers and can be part of the any larger network-based SCADA/HMI system. In the first part of the paper we present the overall hardware architecture for the system as well as its software structure described with variety of UML diagrams presenting underlying processing logic and communication and human interfaces between systems distributed parts. These formal representations of the system functional requirements are then used in conjunction with the software tools for configuring and programming of the controllers as well as designing and coding its interface modules and drivers and HMI interface screens and underlying functionalities. The modeling of both automatic control sequences (for truck loading applications) and programming units that enable operator input from HMI screens (for pipeline shipping) are presented to demonstrate the idea of reusable software approach further applied in modeling of the user-designed building blocks for the control and monitoring of pumps and MOV's (Motor Operated Valves). Furthermore some of the real-time performance requirements on communication subsystem and protocols are first defined and tested in developed UML RTD diagrams and then implemented and tested in the target hardware and software integration in commissioning and start-up phase of the developed system.;
Proceedings of the 2008 International Workshop on Software Engineering in East and South Europe;Data-driven decision-making allows more resource allocation tasks to be done by programs. Unfortunately real-life training datasets may capture human biases and the learned models can be unfair. To resolve this one could either train a new fair model from scratch or repair an existing unfair model. The former approach is liable for unbounded semantic difference hence is unsuitable for social or legislative decisions. Meanwhile the scalability of state-of-the-art model repair techniques is unsatisfactory.In this paper we aim to automatically repair unfair decision models by converting any decision tree or random forest into a fair one with respect to a specific dataset and sensitive attributes. We built the FairRepair tool inspired by automated program repair techniques for traditional programs. It uses a MaxSMT solver to decide which paths in the decision tree could be flipped or refined with both fairness and semantic difference as hard constraints. Our approach is sound and complete and the output repair always satisfies the desired fairness and semantic difference requirements.FairRepair is able to repair an unfair decision tree on the well-known COMPAS dataset [2] in 1 minute on average achieving 90.3% fairness and only 2.3% semantic difference. We compared FairRepair with 4 state-of-the-art fairness learning algorithms [10 13 16 18]. While achieving similar fairness by training new models they incur 8.9% to 13.5% semantic difference. These results show that FairRepair is capable of repairing an unfair model while maintaining the accuracy and incurring small semantic difference.;
Proceedings of the 2nd International Workshop on Equitable Data and Technology;"Empirical software engineering (SE) research is often criticized for poorly designed and reported studies a lack of replications to build up bodies of knowledge and little practical relevance. In this paper we discuss issues in empirical software architecture research as an illustration of these issues in one subfield of SE and as a step towards better understanding empirical research in SE in general. Based on feedback from software architecture researchers and practitioners we explore why despite persistent discussions in the SE research community there are still disagreements about why and how to conduct empirical research. Then we explore how empirical SE research can progress beyond one-off studies and endless ""new and exciting"" results toward SE research as a mature science. This would allow us to establish foundations for evaluating existing and future empirical research and help researchers design and publish better studies.""";
Proceedings of the 40th International Conference on Software Engineering: New Ideas and Emerging Results;"In this paper we use some common terminology from the computing field to help explain several concepts in the ABET accreditation process that appear to be rather widely misunderstood in the educational computing community. We show how the familiar terms software quality metric"" ""software process metric"" ""quality assurance"" and the ""test-debug cycle"" are used to help explain and clarify several fundamental ABET accreditation activities.""";
Preparing software engineers to develop robot systems;Robotics is a rapidly expanding field that needs software engineers. Most of our undergraduates however are not equipped to manage the unique challenges associated with the development of software for modern robots. In this work we introduce a course we have designed and delivered to better prepare students to develop software for robot systems. The course is unique in that: 1) it emphasizes the distinctive challenges of software development for robots paired with the software engineering techniques that may help manage those challenges 2) it provides many opportunities for experiential learning across the robotics and software engineering interface and 3) it lowers the barriers for learning how to build such systems. We describe the principles and innovations of the course its content and delivery and finish with the lessons we have learned.;
Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Software Engineering Education and Training;"With AI-based decisions playing an increasingly consequential role in our society for example in our financial and criminal justice systems there is a great deal of interest in designing algorithms conforming to application-specific notions of fairness. In this work we ask a complementary question: can AI-based decisions be designed to dynamically influence the evolution of fairness in our society over the long term? To explore this question we propose a framework for sequential decision-making aimed at dynamically influencing long-term societal fairness illustrated via the problem of selecting applicants from a pool consisting of two groups one of which is under-represented. We consider a dynamic model for the composition of the applicant pool in which admission of more applicants from a group in a given selection round positively reinforces more candidates from the group to participate in future selection rounds. Under such a model we show the efficacy of the proposed Fair-Greedy selection policy which systematically trades the sum of the scores of the selected applicants (greedy'') against the deviation of the proportion of selected applicants belonging to a given group from a target proportion (""fair''). In addition to experimenting on synthetic data we adapt static real-world datasets on law school candidates and credit lending to simulate the dynamics of the composition of the applicant pool. We prove that the applicant pool composition converges to a target proportion set by the decision-maker when score distributions across the groups are identical.""";
Proceedings of the 2022 AAAI/ACM Conference on AI Ethics and Society;Slowly but surely statistical practices in the empirical sciences are undergoing a complete makeover. Researchers in empirical software engineering where too statistics is an essential tool must become familiar with these new practices to ensure rigor of their research methods and soundness of their research results.;
Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings;This paper describes an approach for assessing the capability and maturity of undergraduate software engineering projects. The approach is based on a simple adaptation of the Capability Maturity Model Â® Integration and a hybrid version of the Team Software Process (TSPi). The approach was evaluated using 6 capstone project teams comprising 23 undergraduate software engineering students. A capability and maturity baseline was established at the end of first semester. A second capability and maturity assessment was undertaken towards the end of second semester. The approach was shown to focus student attention on process improvement and on the attainment of realistic and measurable project management goals. The approach was also found to contribute to the development of teamwork and leadership skills and to prepare students for professional practice.;
Proceedings of the Tenth Conference on Australasian Computing Education - Volume 78;Through Tri-P-LETS (the Three P Learning Environment for Teachers and Students) the University of Memphis has changed student perceptions about computer science. Graduate students have assisted high school programming teachers by creating and presenting an enhanced curriculum emphasizing three P foundation areas: Process Programming and Problem Solving. This paper describes Tri-P-LETS and its impact on beginning programming classes in the Memphis area. It also discusses a software engineering process and associated forms that were used to provide students with a more realistic view of software development.;
Quality-Driven and Abstraction-Oriented Software Construction Course Design: To Fill the Gap between Programming and Software Engineering Courses;"Traditional Computer Science (CS) and Software Engineering (SE) curricula pay great attention to the training of programming skills and software engineering competence. In practice we find a large gap"" between the two perspectives: even for those students who have good programming skills it is rather difficult for them to transform the programming-oriented thinking into the engineering-oriented thinking. Software construction a key knowledge area (KA) in SWEBOK plays a role for filling such gap in CS and SE education. We design ""four transformations"" in the course Software Construction and use multi-dimensional software artifacts as the index of the course contents so as to train students on the design programming and testing of a software system in terms of five key quality objectives. A set of gradually-deepening labs are designed for students to make practice on various quality-oriented software construction techniques. Two-year practice demonstrates that our course design significantly facilitates the transformation from programming-oriented training to engineering-oriented training and has been widely welcome by undergraduates from CS and SE.""";
Proceedings of the ACM Turing Celebration Conference - China;Global software development (GSD) is a prevalent trend which has fascinated most software companies. However the failure rate of GSD projects reveals the fact that these types of projects are not an easy endeavor. Management of GSD project is a domain where standards are still lacking and companies are still struggling to acquire a win-win situation. Project management body of knowledge (PMBOK) provides a standard framework for managing projects. However the framework does not consider the aspects of GSD. Thus it can't be applied directly for GSD projects. In this paper we have proposed a project management framework for GSD projects. This framework assimilates the knowledge areas of PMBOK with knowledge areas needed for effective management of GSD. It would guide GSD project manager about the aspects to be considered while executing distributed projects. This framework would also act as a baseline to researchers for further investigation in GSD project management domain.;
Country stereotypes initial trust and cooperation in global software development teams;People have to expose to collaborators from different countries in global software engineering (GSE) teams. They often rely on their perceptions of the country stereotypes to form their initial beliefs of the foreign collaborators and to make decisions on how to work with them. In this article we employ the Stereotype Content Model (SCM) to investigate how explicit and implicit country stereotypes influence people' trust towards foreign collaborators and their decisions on cooperative behaviors. We conduct an empirical study with 92 professional software engineers with GSE experience. The results show that both SCM's explicit and implicit warmth as well as the explicit competency have significant impacts on the GSE team members' trust and cooperative behaviors in their initial interactions with unfamiliar foreign collaborators. Our findings indicate that Globally distributed collaboration practitioners may still need to overcome the over-reliance on country-of-origin cues when making attributions on unfamiliar foreign collaborators.;
Proceedings of the 14th International Conference on Global Software Engineering;This paper introduces reviewability as a framework for improving the accountability of automated and algorithmic decisionmaking (ADM) involving machine learning. We draw on an understanding of ADM as a socio-technical process involving both human and technical elements beginning before a decision is made and extending beyond the decision itself. While explanations and other model-centric mechanisms may assist some accountability concerns they often provide insufficient information of these broader ADM processes for regulatory oversight and assessments of legal compliance. Reviewability involves breaking down the ADM process into technical and organisational elements to provide a systematic framework for determining the contextually appropriate record-keeping mechanisms to facilitate meaningful review - both of individual decisions and of the process as a whole. We argue that a reviewability framework drawing on administrative law's approach to reviewing human decision-making offers a practical way forward towards more a more holistic and legally-relevant form of accountability for ADM.;
Proceedings of the 2021 ACM Conference on Fairness Accountability and Transparency;The recent breakthrough of artificial intelligence as well as the wide adoption of the wisdom of the crowd also known as collective intelligence across sectors has received attention and excitement across disciplines. In addition to the scientific breakthrough recent public sector studies recognize AI's potential contributions in public services such as big data for decision making the development of smart cities and social and health care. Studies have also recognized crowdsourcing's potential for service provisions innovation information generation and policymaking. However we have only a limited understanding of the connections between these two types of intelligence and adoption conditions to properly utilize them for the public sector. To understand what roles AI and crowds can play in enhancing public services and policymaking we adopt a bibliometric analysis to identify emerging themes and interconnections between these two streams of literature. Our study provides key themes and significance for each cluster. Our first examination of AI and crowd literature regarding connection to public values complementary in public decision making as well as future potential for joint adoption by governments provides some implications for future considerations.;
Proceedings of the 21st Annual International Conference on Digital Government Research;Background: Agile software projects involve a high degree of coordination between project members to manage complexity and frequent change. There is a need to understand what coordinating mechanisms are valuable for project and team coordination. Coordination mechanisms such as meetings and Slack can foster a smooth workflow but also fragment work by interrupting the focused work of developers. Objective: This study aimed to investigate valuable coordination mechanisms and how they can be balanced against the need for uninterrupted work periods. Method: We conducted 30 interviews and observed 109 meetings in five companies using agile software development methods. We used coordination-dependency mapping to identify valuable coordination mechanisms. Results: Valuable coordination mechanisms included instant messaging tools daily stand-up meetings boards open work area Scrum of Scrums bug crush days BizDev meetings and Make it Happen meetings. Conclusion: We advise companies to identify valuable coordination mechanisms using coordination-dependency mapping and then to bundle schedule and substitute these coordination mechanisms to reduce interruptions to development work.;
Proceedings of the 15th International Conference on Cooperative and Human Aspects of Software Engineering;Everything is possible to structure even the software engineering body of knowledge. In this paper we suggest a conceptual model of the software engineering body of knowledge. The model is a restructured version of SWEBOK and ACM/IEEE Curriculum Guidelines. It constitutes the first attempt to create an underlying structure that is common to most of the software engineering bodies of knowledge.;
Proceedings of the 1st International Workshop on Software Engineering Curricula for Millennials;Context: Requirements Elicitation is an essential part of the software development process. Design Thinking (DT) arises as an alternative approach for supporting the Requirements Elicitation step. Empirical studies have shown that the use of DT in the software development process can be beneficial. The literature offers a wide variety of DT techniques. However there is a lack of studies that mention which information is needed to use the techniques and which results they generate. Objective: Motivated by this need this work aims to assist the software engineers in selecting which DT techniques are more suitable to support the requirements elicitation step. Method: We performed a literature review to identify DT techniques that can be used for the requirements elicitation. Next we analysed and modelled the techniques identified using SADT diagrams. We grouped the DT techniques into ten categories according to their main purpose. Based on the SADT diagrams we elaborated a comparative table for these categories showing for each technique: input control mechanism and output terms. We carried out a feasibility study to verify whether the comparison tables among the DT techniques provide the necessary information for software engineers. Results: Our preliminary results showed that the comparative tables describing the inputs control mechanism and outputs helped software engineers to select the DT technique according to their goals. Conclusion: The results provided evidence that the DT techniques comparison table is promising in the context of requirements elicitation decision making to choose the most appropriate DT techniques.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;Project-Based Learning (PBL) is an active learning method in which students gain knowledge and skills by exploring real-world problems for an extended period of time. Existing studies point out that soft skills related to working in groups such as communication skills teamwork skills and problem-solving skills can be enhanced through PBL. Aspects of the group are fundamental to the success of any software project. In this context this work seeks to investigate the groupâ€™s maturity and its relationship with the effectiveness of Agile Software Development teams in PBL. To do so we conduct a study in the context of a discipline of the Software Engineering graduate course in which PBL is adopted. At the end of the semester a questionnaire was applied to eight teams of graduating students involving a total of 29 students to measure aspects of the groupâ€™s maturity later these aspects were correlated with the effectiveness of the teams. The obtained results point out that group maturity and team effectiveness are directly correlated. The results also show three aspects of group maturity that if improved will possibly improve the effectiveness of teams in software development: mutual trust backup behavior and cohesiveness. Furthermore from this experience we were able to derive some assumptions and directions for supporting instructors to stimulate the improvement of the soft skills relevant to both team effectiveness and software industry when applying PLB in their classes.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Software architecture can be seen as a set of architectural design decisions (ADDs) that shape the resulting software solution. To make an ADD stakeholders follow some organization- or team-specific group decisions making process. In this study we aimed to advance the understanding of how ADDs are made by observing and learning how architects handle uncertainties in real-life settings. We employed a multiple-case studies research method. First we examined the discussions in task management systems of three software engineering projects. Second we conducted interviews with the projects' software architects to investigate (a) uncertainties expressed in the observed discussions and (b) how those uncertainties are comprehended by their respective authors or readers. We systematically analyzed the interviews and derived different types of uncertainties as well as proposed a hypothesis that should be verified in the future work. Results of our qualitative study show how uncertainty is used and perceived by the software architects in the group decision-making process.;
Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings;Recently software startups have been the focus of intense research especially in the Software Engineering community. However we need more empirical evidence that addresses how software startups perform their software development practices. This paper presents a case study of software startups to understand their software development practices. We conducted a multiple case study in ten software startups incubated in industrial environments at All Saints Bay Ecosystem. The case study consisted of questionnaires semi-structured interviews non-participative observations and archiving data analyses covering software development practices. The preliminary results allowed us to build an initial industrial startup model capturing the software startups' practices and the relationship among them. Early-stage startups do not adopt any software development methodology in its completeness. Instead they work focusing on speed-up software development and guide development based on consumers' feedback. The findings of this study is a preliminary result which needs to be tested through other interviews with practitioners that work in other startups to validate the model at its current stage.;
Proceedings of the XVIII Brazilian Symposium on Software Quality;Diversity is a great challenge for software engineers in the social sector context. The objective of this paper is to contribute to the identification of the RE processes and associated challenges in releasing the software in the social sector markets for which an exploratory case study is conducted. The outcome of the case study indicates that the diversity limits the ability to involve the representative samples of user populations using the same set of RE tools and techniques as one size fits all solution for all segments. The diverse user base must be partitioned into different segments with each segment triggered using a suitable set of RE techniques i.e. traditional and crowd-based RE. The diverse perspectives learned as a result of the interaction with each segment must be merged together into a single perspective about the software meant to be used in the social sector. There is a need for a new RE process specially designed for handling the complexities of the social sector which this paper terms as Social Sector Requirement Engineering (SSRE). There is an increased need for collaboration between government social sector institutions and software engineers to get access to diverse customers to improve software quality.;
The carr-benkler wager and its implications for ULS software engineering;In this paper I present the Carr-Benkler wager - a bet over whether free-market/economic or social forces will determine the future of the internet - and discuss its implications for the software engineering practices of Ultra-Large Scale (ULS) systems. As a result of considering the underlying forces behind the wager I discuss three implications for the software engineering of Ultra-large scale systems. From these implications I suggest a set of topics that describe how we need to think about teach and develop software and software-related processes differently.;
Proceedings of the 2nd International Workshop on Ultra-Large-Scale Software-Intensive Systems;Delay one of the challenging topics several corporates have to face in running the complex project such as those implementing a railway system. This article mainly focuses on the development of the Scrum framework with the Objective and Key Results (OKRs) scheme that can assess the performance information at both team and individual levels. The technique manipulates the goals from the team to individual levels to be measurable while aligning them in the same global direction. Here the case study of implementing the OKRs-based Scrum framework in the process occupied by the Computer-Based Interlocking adaptation (CBI) team is reported. The process was evaluated continuously during the project life cycle of the railway software development. From the total of 22 tasks only 27.20% of which were delay from the target deliverable date while 72.80% of which were completed prior to or on the target dates. Therefore the correct implementation of measurable OKRs has shown in providing a collaboration visibility through tracking progress activities with clear priorities of tasks thus providing the improved time deliverable performance.;
Proceedings of the 2021 4th International Conference on Software Engineering and Information Management;It is widely recommended by both academia and industry that today's technology and software engineering students be well prepared for industry before graduation especially given global outsourcing and other trends. Various methods have been developed to ensure student readiness including co-ops and capstone courses. These approaches increasingly use real-world projects for their benefits to industry and often to the community at large. In this paper we argue that students can be prepared to effectively join industry and keep the US technology workforce competitive through a curriculum that includes a theoretical software engineering course with real-world projects and the collaboration of paired teams across two or more universities. We present a case study of a successful teaching experience that features these aspects and describe the outcome along with the unique perspective of a participating student.;
Proceedings of the 40th ACM Technical Symposium on Computer Science Education;Background: Software engineering research articles should make precise claims regarding their contribution so that practitioners can decide when they might be interested and researchers can better recognize (1)&nbspwhether the given research is valid (2)&nbspwhich published works to use as stepping stones for their own research (and which not) and (3) where additional research is required. In particular articles should spell out what assumptions were made at each research step. Question: Can we identify recurring patterns of assumptions that are not spelled out? Method: This is a position paper. It formulates impressions but does not present concrete evidence. Results: Assumptions that are wrong or assumptions that are risky and not explicit threaten the integrity of the scientific record. There are several recurring types of such assumptions. The frequency of these problems is currently unknown. Conclusion: The software engineering research community should become more conscious and more explicit with respect to the assumptions that underlie individual research works.;
Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering;In a junior- or senior-level undergraduate software engineering course that uses real-world projects for real clients different parts of a project are inherently unequal in difficulty time requirements and desirability. A perennial problem is assigning portions of the project to student teams equitably. Fair division is a highly effective strategy for making an equitable proportional and envy-free assignment of tasks and in serving as the basis for fair grading of assignments which vary in difficulty desirability and time requirements.;
Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education;This study is to investigate the impact of high-level generalpurpose programming languages on software development productivity and quality. In particular a comparison is to be made between scripting languages and traditionally compiled system programming ones to examine differences if any. The data obtained for the research is from open source repositories gathered from Github. The results are going to be based on the analysis of possibly the largest open source dataset through examining a population of 15000 projects and by including a sample of 4349 projects where a main language can be identified. The investigation so far has revealed considerable differences in productivity between the two language groups.;
PLD: fast FPGA compilation to make reconfigurable acceleration compatible with modern incremental refinement software development;FPGA-based accelerators are demonstrating significant absolute performance and energy efficiency compared with general-purpose CPUs. While FPGA computations can now be described in standard programming languages like C development for FPGAs accelerators remains tedious and inaccessible to modern software engineers. Slow compiles (potentially taking tens of hours) inhibit the rapid incremental refinement of designs that is the hallmark of modern software engineering. To address this issue we introduce separate compilation and linkage into the FPGA design flow providing faster design turns more familiar to software development. To realize this flow we provide abstractions compiler options and compiler flow that allow the same C source code to be compiled to processor cores in seconds and to FPGA regions in minutes providing the missing -O0 and -O1 options familiar in software development. This raises the FPGA programming level and standardizes the programming experience bringing FPGA-based accelerators into a more familiar software platform ecosystem for software engineers.;
Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems;Computer-aided software engineering (CASE) encompasses computer-based procedures techniques and tools which can be used to develop maintain and reengineer software. CASE is to the software engineer as computer-aided design/computer-aided manufacturing (CAD/CAM) (q.v.) is to the mechanical engineer and computer-aided electrical engineering (CAEE) is to the electrical engineer. Although the variety of technological alternatives can be bewildering the concepts of CASE provide a common-sense approach to engineering quality software more productively.;
Encyclopedia of Computer Science;Productivity research has for the most part examined approaches that are focused on deriving a single measure for Productivity = Output / Input. This can work under specific scenarios and context but cannot be applied universally to a broad range of software development projects. This paper makes the assertion that it is possible to measure productivity in a manner that will help identify opportunities to improve productivity.;
Proceedings of the 2nd International Conference on Software Engineering and Information Management;Phase Change Random Access Memory (PRAM) has great potential as the replacement of DRAM as main memory due to its advantages of high density non-volatility fast read speed and excellent scalability. However poor endurance and high write energy appear to be the challenges to be tackled before PRAM can be adopted as main memory. In order to mitigate these limitations prior research focuses on reducing write intensity at the bit level. In this work we study the data pattern of memory write operations and explore the frequent-value locality in data written back to main memory. Based on the fact that many data are written to memory repeatedly an architecture of frequent-value storage is proposed for PRAM memory. It can significantly reduce the write intensity to PRAM memory so that the lifetime is improved and the write energy is reduced. The trade-off between endurance and capacity of PRAM memory is explored for different configurations. After using the frequent-value storage the endurance of PRAM is improved to about 1.6X on average and the write energy is reduced by 20%.;
Proceedings of the 16th Asia and South Pacific Design Automation Conference;Challenges in implementing Agile Distributed Software Development (ADSD) are well documented. A primary challenge lies in achieving the necessary degree of cooperation and collaboration which are founded on good communication. Agile methodology historically relies on frequent face-to-face communication which is infeasible in distributed development. Recent work suggests that current communication tools can support practices that accommodate ADSD. We present an experience report of a distributed team and describe its interpersonal communication network which is notably more limited when connections are across an eight-hour time difference. As a limited study we provide context to allow better comparisons with other work.;
Proceedings of the 14th International Conference on Global Software Engineering;Software engineering (SE) researchers and research networks from emerging communities are often not visible in already established Software Engineering venues for a multitude of reasons. This limits the opportunities and mutual bene ts that can arise from collaborations between global and emerging Software Engineer- ing networks. This article focuses on a rst attempt to provide a map of the African software engineering research community with focus on the networks of two big East African Universities. We hope that this very initial mapping e ort will help to raise aware- ness in the international community about the variety of software engineering research in Africa. We formulate some suggestions for making our academic Software Engineering community more inclusive.;
Multi-objective optimization in the agile software project scheduling using decomposition;Scrum is an agile software development framework followed nowadays by many software companies worldwide. Since it is an iterative and incremental methodology the software is developed in increments. For each increment the software development team and the customer agree upon a development plan. However the context of the software project may change due to some circumstances that generally arise for example new software requirements or changes in the development team. Consequently these factors force the plan to be adjusted. When the plan is modified it is necessary to consider at least three criteria to minimize the economic and operational impact of these changes. Therefore this activity can be analyzed as a multi-objective problem. In the last two decades multi-objective evolutionary algorithms based on the decomposition principle have become an effective and efficient tool to solve multi-objective problems. In this paper we evaluate the potential of decomposition-based MOEAs when approximating the agile software project scheduling problem. Mainly we focus our investigation on analyzing the performance of emblematic decomposition-based MOEAs in a set of test instances introduced in this study.;
Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion;Replications play an important role in verifying empirical results. In this paper we discuss our experiences performing a literal replication of a human subjects experiment that examined the relationship between a simple test for consistent use of mental models and success in an introductory programming course. We encountered many difficulties in achieving comparability with the original experiment due to a series of apparently minor differences in context. Based on this experience we discuss the relative merits of replication and suggest that for some human subjects studies literal replication may not be the the most effective strategy for validating the results of previous studies.;
Proceedings of the 30th International Conference on Software Engineering;Service Oriented Architecture (SOA) is a way of designing developing deploying and managing enterprise systems where business needs and technical solutions are closely aligned. SOA offers a number of potential benefits such as cost-efficiency and agility. However adopting SOA has considerable challenges. Issues such a security in a SOA-context testing services in a federated environment and leveraging legacy assets when migrating to a SOA-based system all remain important unresolved concerns.;
Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research;Software project management is an essential practice to achieve the goal of success in these projects and a challenging task for the Project Manager (PM). Therefore information about developers' work can be valuable in supporting PM. Several studies have addressed this topic and suggested different strategies for obtaining such information. Given the variety of existing strategies the need arises to know the state of the art regarding the theme. In this paper what relevant information for PM and how that information can support the project management practices are presented especially regarding risk management and people management. So an exploratory study was performed applying Systematic Mapping of Literature technique. Contributions include the identification of 58 metrics 4 sources of information and 7 PM's activities supported by the measurement of developer work. In addition aspects to be explored on the subject are presented inspiring new studies in the field of Software Engineering.;
Proceedings of the XVIII Brazilian Symposium on Software Quality;Targeted and destructive nature of strategies used by attackers to break down the system require mitigation approaches with dynamic awareness. Making a right decision when facing today's sophisticated and dynamic attacks is one of the most challenging aspects of engineering self-protecting software systems. Inspired by game theory in this research work we model the interactions between the attacker and the software system as a two-player game. Using game-theoretic techniques the self-protecting software systems is able to: (i) fuse the strategies of attackers into the decision-making model and (ii) refine the strategies in dynamic attack scenarios by utilizing what has learned from the system's and adversary's interactions. This research introduces a novel decision-making framework with three phases: (i) modeling quality goals aiming at incorporating them into the decision model (ii) designing game-theoretic techniques in order to build the decision model and (iii) realizing the decision-making engine in the adaptation manager. Modeling quality goals provides the adaptation manager with the knowledge-base required in making a systematic adaptation decision. The framework aims at exhibiting a plug-and-play capability to adapt game-theoretic techniques that suite security goals and requirements of the software.;
Proceedings of the 39th International Conference on Software Engineering Companion;As most future automotive innovations will be realized with software the automotive industry is facing a transition from mechanical to software engineering. To achieve successful product launches this is also true for manufacturing engineering.This paper presents an empirical study of the interaction between the organizations for product development and manufacturing specifically focusing on automotive software engineering. It is presented as a multiple case study with a qualitative approach where data were collected from documents and in interviews with practioners at two Swedish automotive companies. To obtain validity of the results multiple information sources were triangulated in within-case analysis and cross-case analysis.It can be concluded that there are challenges in the research area since 18 issues emerged from the data. Furthermore a majority of the findings were supported by data sources from both cases which indicates a possibility to generalize the results to the automotive domain.;
Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;Background: The literature reports that different perspectives (i.e. roles) within an agile software development team (ASD) perceive the impact of teamwork quality (TWQ) on team performance in different ways. However nothing is said about the perspective influence on the assessment TWQ construct itself. Aims: To fill this gap this study provides a more in-depth insight into how the perspective affects the perception of the variables in TWQ construct. Method: We performed a comparative analysis in which we collected TWQ-related data from 21 ASD teams from 2 software development companies. We interviewed 130 professionals from different roles (i.e. developers technical leader and manager). We compared the results for the associated perspectives using the Mean Relative Error (MRE). Results: The leader and manager perspectives show reasonable agreement when evaluating three variables that compose the TWQ (i.e. Cohesion Self-Organizing and Team Orientation). Developers and managers strongly agreed on four variables (i.e. Communication Cohesion Self-Organizing and Collaboration). For developers and leaders only the Coordination variable showed reasonable agreement. Conclusions: We believe that more studies are needed to generalize the results. However the research indicates that different perspectives evaluate the variables that compose the TWQ construct in different ways. Closer discussions and definitions of more objective metrics are advisable to assess these variables aiming to align expectations between perspectives and consensus when measuring efforts to achieve continuous improvement team's.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;Reflective practice is considered to play an important role in transformative learning of educationally critical material but students often respond in other less productive ways. Transformative learning is used here as a lens to investigate reflectiveness: understanding the place of reflectiveness -- and how defensiveness has no place -- in transformative learning illuminates its operation and mechanism. The paper is written as part of an ongoing exploration into how to engender students' reflective response to difficult material preparing a foundation on which to address that question directly. Previous preparation includes phenomenological analysis of reflectiveness and defensiveness and a careful examination of the operation and mechanism of defensiveness both based on Segal's explication of Heidegger's dynamic of rupture. Qualitative data for the investigation comes from an upper-level undergraduate software engineering and design course that students invariably find quite challenging. A grasp of concepts presented here should enable faculty to develop improved pedagogy and institutions to design more effective curricula for engendering students' reflective response to difficult material in computing -- and other -- education.;
Proceedings of the Seventh Baltic Sea Conference on Computing Education Research - Volume 88;Agile Software Development (ASD) has been widely accepted in the software industry as a means to increase customer value despite the few empirical studies related to the subject. A recent systematic review study based on academic works and industry experiences mapped a set of strategies to increase customer value in the ASD. However the factors that drive the adoption of these strategies were not mentioned. Based on a survey of 378 software professionals from 123 software-intensive companies in Brazil we examined the associations of these strategies mapped to six drivers including the team context (product type product owner type and customer type) and the context of the organization (size of unit level of agile adoption and agile experience). The results showed that the organizational context's driving factors are associated with the adoption of a more significant number of strategies than the factors related to the team context focusing mainly on large companies with 100% of the teams using agile methods and with having used ASD for more than five years.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;Success of software development process is defined by its ability to transform the business objectives into requirements and further into features and functionality. In addition to business objectives software development also has security objectives requiring security engineering activities. In contrast to the iterative and incremental software development process software security engineering is defined by sequential life cycle models: security and business objectives are thus implemented using conflicting approaches. To identify the incompatibilities between the methodologies in this study the security engineering activities are mapped into common agile software development practises processes and artifacts. Security engineering activities from Microsoft SDL the ISO Common Criteria and OWASP SAMM security development lifecycle models are mapped into common agile processes practises and artifacts. The organizational and technical aspects of the mapping are considered primarily from the point of view of achieving the security objectives set for the software engineering process: setting security requirements for design their implementation and verification and releasing secure software through efficient software security development process.;
Proceedings of the 19th International Conference on Agile Software Development: Companion;This paper presents a vision of how the Internet of Things will impact the study of software engineering by 2025 and beyond. The following questions guide this inquiry. What will it mean to be able to deploy hundreds of sensors and data collectors running concurrently over months to gather very large and rich datasets of the physical digital and social aspects of software engineering organizations and the products and services those organizations create? How might such datasets change the types of research questions that can be addressed? What sort of tools will be needed to allow interdisciplinary communities of researchers to collaboratively analyse such datasets? How might such datasets help us understand the principles governing the interplay of physical cyber and social aspects of software engineering and its products and automate aspects of such systems?;
Proceedings of the 38th International Conference on Software Engineering Companion;Building more secure software is a recent concern for software engineers due to increasing incidences of data breaches and other types of cyber attacks. However software security through the introduction of specialized practices in the software development life cycle leads to an increase in the development cost. Although there are many studies on software cost models few address the additional costs required to build secure software. We conducted a systematic review in the form of a mapping study to classify and analyze the literature related to the impact of security in software development costs. Our search strategy strove to achieve high completeness by the identification of a quasi-gold-standard set of papers which we then used to establish a search string and retrieve papers from research databases automatically. The application of inclusion/exclusion criteria resulted in a final set of 54 papers which were categorized according to the approach to software security cost analysis. Perform Security Review Apply Threat Modeling and Perform Security Testing were the three most frequent activities related to cost and Common Criteria was the most applied standard. We also identified ten approaches to estimating software security costs for development projects however their validation remains a challenge which could be addressed in future studies.;
Proceedings of the 14th International Conference on Availability Reliability and Security;Often higher educational institutions must purchase software to manage their operations. However the cost to purchase some software is prohibitive particularly for smaller institutions resulting in software that can be difficult to use poorly developed or not fully-featured for the specific needs of the institution. An alternate solution is to hire a team of student developers led by a faculty and minimal staff support to create custom institution-specific software that meets the college's exact needs while providing students with valuable skill-building experience. In its sixth year of operation our team has developed a framework to lead students who create software for an academic institution resulting in nine software systems thus far. This case study details the student software development team framework whose goal is to benefit students by emulating the software engineering industry. Lastly the modifications made to continue pursuing this goal during the COVID-19 crisis is discussed.;
Software development challenges with air-gap isolation;While existing research has explored the trade-off between security and performance these efforts primarily focus on software consumers and often overlook the effectiveness and productivity of software producers. In this paper we highlight an established security practice air-gap isolation and some challenges it uniquely instigates. To better understand and start quantifying the impacts of air-gap isolation on software development productivity we conducted a survey at a commercial software company: Analytical Graphics Inc. Based on our insights of dealing with air-gap isolation daily we suggest some possible directions for future research. Our goal is to bring attention to this neglected area of research and to start a discussion in the SE community about the struggles faced by many commercial and governmental organizations.;
Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Within Computer science and Software engineering the prevalence of students with a diagnosis of autism spectrum disorder is relatively high. Ideally education should be inclusive with which we mean that education must be given in such a way that additional support is needed as little as possible.In this paper we present an overview on what is known about the cognitive style of autistic individuals and compare that cognitive thinking style with computational thinking thinking as an engineer and with academic thinking. We illustrate the cognitive style of autistic students with anecdotes from our students.From the comparison we derive a set of guidelines for inclusive education and we present ideas for future work.;
Proceedings of the 8th Computer Science Education Research Conference;After a seminal article introducing-evidence based software engineering in 2004 systematic reviews (SR) have been increasingly used as a method for conducting secondary studies in software engineering. Our goal is to critically appraise the use of SR in software engineering with respect to the research questions asked and the ways the questions were used in the reviews. We analyzed 53 literature reviews that had been collected in two published tertiary studies. We found that over 65% of the research questions asked in the reviews were exploratory and only 15% investigated causality questions. We concluded that there is a need for a consistent use of terminology to classify secondary studies and that reports of literature reviews should follow reporting guidelines to support assessment and comparison.;
Proceedings of the 2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;How can society understand and hold accountable complex human and algorithmic decision-making systems whose systematic errors are opaque to the public? These systems routinely make decisions on individual rights and well-being and on protecting society and the democratic process. Practical and statistical constraints on external audits--such as dimensional complexity--can lead researchers and regulators to miss important sources of error in these complex decision-making systems. In this paper we design and implement a software-supported approach to audit studies that auto-generates audit materials and coordinates volunteer activity. We implemented this software in the case of political advertising policies enacted by Facebook and Google during the 2018 U.S. election. Guided by this software a team of volunteers posted 477 auto-generated ads and analyzed the companies' actions finding systematic errors in how companies enforced policies. We find that software can overcome some common constraints of audit studies within limitations related to sample size and volunteer capacity.;
Analysis of software project complexity factors;Software projects are among the most complex endeavours today. The increased complexity had led to high numbers of software project failures in terms of time cost quality etc. Software project complexity is one of the main reasons for these failures. Various approaches to measure software complexity have been proposed focusing on the software product complexity but without considering the complexity of the process. In this paper it is presented the results of an extended literature review and of a statistical analysis followed for identifying the main factors that affect software project complexity taking into account both technical and project management aspects of the software development process.;
Proceedings of the 2017 International Conference on Management Engineering Software Engineering and Service Sciences;We present FLEX-SDK: an open-source software development kit that allows creating a social robot from two simple tablet screens. FLEX-SDK involves tools for designing the robot face and its facial expressions creating screens for input/output interactions controlling the robot through a Wizard-of-Oz interface and scripting autonomous interactions through a simple text-based programming interface. We demonstrate how this system can be used to replicate an interaction study and we present nine case studies involving controlled experiments observational studies participatory design sessions and outreach activities in which our tools were used by researchers and participants to create and interact with social robots. We discuss common observations and lessons learned from these case studies. Our work demonstrates the potential of FLEX-SDK to lower the barrier to entry for Human-Robot Interaction research.;
Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology;Security and scalability are core software qualities which as non-functional aspects share certain characteristics and challenges in how they are approached during software development and operation. Based on expert interviews this paper explores interactions and dependencies between security and scalability as well as similarities and differences in their challenges. It concludes that the current understanding of the relationship between security and scalability is not yet mature. Further it points to future research needs to better understand the relationship between these two quality aspects and better support practitioners in addressing security and scalability in a more integrated fashion.;
Proceedings of the 2022 European Interdisciplinary Cybersecurity Conference;Carnegie Mellon's West Coast Campus offers an MS in Software Engineering with technical and development management tracks targeted at working software professionals in Silicon Valley. We believe the program to be unique in that it is entirely team-based and project-centered. Students learn by doing as they are coached just in time by faculty in the context of authentic projects and they are evaluated based on what they produce. Student satisfaction is high: 92% believe that the program has given them a competitive advantage with respect to their professional peers and their promotion and salary histories bear out this belief.;
Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education;Decision-making requirements differ from one decisionmaker to another hence the need to study decision-making requirements personalization. Customization is an effective response to the information overload problem by injecting into queries more restrictive filtering criteria and by possibly reformulating queries to better take into account the interest centers and the decision maker preferences. The decision maker's preferences are obtained at the end of the exhaustive study of the decision-maker profile and taking into account the decision-maker's status with regard to the requested products.We have decided to improve the existent models by adding to the profile a part mentioning the decision-maker belief which allows us to elaborate the needs personalization or to pass to the customized recommendation. To develop our proposed solution we chose the sports articles trade as a study domain.;
Proceedings of the 7th International Conference on Software Engineering and New Technologies;Dynamic strategies used by attackers to break down the software system calls for dynamic countermeasure selection techniques. A significant challenge in engineering self-proctoring software system is selecting a proper countermeasure while the software systems undergoes a well-planned attack. To address this challenge in this research work we model the interactions between the attacker and the software system as a two-player game. Modeling such interaction using game theory enables the decision-making engine to model the strategies of the attackers while considers the effect of possible defense strategies in a dynamic attack scenario. In this research work we aim at engineering a novel decision-making framework that utilizes game theoretic techniques to select the proper mitigation against an attack. The introduced framework consists of three high-level phases including: modeling quality goal designing game-theoretic techniques and realizing the decision-making engine. The first phase models the security goals of the system and maps goal-oriented model to the designed game-theoretic technique. Such goal model makes the decision-making engine capable of tracking the satisfaction of modeled goals before and after applying a mitigation strategy. The framework provides the steps to map the goal-oriented model to any game-theoretic techniques that is suitable to model the countermeasure selection.;
Proceedings of the 39th International Conference on Software Engineering Companion;Multitasking has always been an inherent part of software development and is known as the primary source of interruptions due to task switching in software development teams. Developing software involves a mix of analytical and creative work and requires a significant load on brain functions such as working memory and decision making. Thus task switching in the context of software development imposes a cognitive load that causes software developers to lose focus and concentration while working thereby taking a toll on productivity. To investigate the disruptiveness of task switching and interruptions in software development projects and to understand the reasons for and perceptions of the disruptiveness of task switching we used a mixed-methods approach including a longitudinal data analysis on 4910 recorded tasks of 17 professional software developers and a survey of 132 software developers. We found that compared to task-specific factors (e.g. priority level and temporal stage) contextual factors such as interruption type (e.g. self/external) time of day and task type and context are a more potent determinant of task switching disruptiveness in software development tasks. Furthermore while most survey respondents believe external interruptions are more disruptive than self-interruptions the results of our retrospective analysis reveals otherwise. We found that self-interruptions (i.e. voluntary task switchings) are more disruptive than external interruptions and have a negative effect on the performance of the interrupted tasks. Finally we use the results of both studies to provide a set of comparative vulnerability and interaction patterns which can be used as a mean to guide decision-making and forecasting the consequences of task switching in software development teams.;
Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018;We review design and development decisions and their impact for the open source code Nmag from a software engineering in computational science point of view. We summarise lessons learned and recommendations for future computational science projects. Key lessons include that encapsulating the simulation functionality in a library of a general purpose language here Python provides great flexibility in using the software. The choice of Python for the top-level user interface was very well received by users from the science and engineering community. The from-source installation in which required external libraries and dependencies are compiled from a tarball was remarkably robust. In places the code is a lot more ambitious than necessary which introduces unnecessary complexity and reduces maintainability. Tests distributed with the package are useful although more unit tests and continuous integration would have been desirable. The detailed documentation together with a tutorial for the usage of the system was perceived as one of its main strengths by the community.;
Proceedings of the International Workshop on Software Engineering for Science;Managing and successfully completing software projects can become challenging for project managers due to unforeseen changes in the information technology's business environment. Creating robust software development success criteria for the project and accordingly employing the corresponding development method can greatly help project managers in this regard. Since there is no best methodology that is taken as a software development norm or a best software development process borrowing software development success criteria from each development process and combining these factors into a set of success criteria can be treated as new/better method to apply when possible. In this paper we show through case studies that a combination of success criteria from extreme programming (XP) software project model and waterfall (WF) software development process can be treated as new and potentially better sotware development success criteria. We discuss how blending the success criteria of these two models can be used in developing a new success framework for projects which in turn can help in delivering a successful project within the information technology organizations.;
Proceedings of the 2020 ACM Southeast Conference;The need for greater flexibility autonomy and dynamism in software development has increased the adoption of agile methodologies. In order to support the recommended practices of these methodologies maintaining good communication between team members and promoting a positive work environment that allows the individual growth of employees through autonomous learning and decision making have become key success factors. In this context feedback is an important practice to provide each employee with an analysis of their performance both personal and technical. The objective of this paper is to investigate the impact of feedback on motivational factors from the perspective of developers testers and managers of agile development teams. We conducted a survey with 25 collaborators to assess motivational factors and possible points for improvement in the feedback process adopted by the teams. Among the obtained results job satisfaction and productivity were positively influenced by the practice of feedback. In contrast the periodicity of feedback and the absence of an evaluation among members were considered improvement points. Based on the survey results we provided a set of recommendations to improve the quality of the feedback process in agile teams.;
Proceedings of the XX Brazilian Symposium on Software Quality;Collaboration tools play an important role in the development of software applications. This is especially true as development endeavors are more frequently being conducted in geographically distributed environments. Requiring students to use such tools helps in preparing them for their careers after graduation. This paper describes the experiences of using collaboration tools in a one-semester software engineering course which requires group work throughout the semester. After exploring various open source and closed source solutions Basecamp by 37signals has been used successfully for several semesters as students work collaboratively to develop a real application for a real on-campus client. Basecamp provides an easy way for (1) instructors to keep abreast of group and individual progress (2) on-campus clients to be integrated into the development process and (3) students to embrace a technology which enhances their collaborative efforts.;
The Public Value Creation of eGovernment: An Empirical Study from Citizen Perspective;Due to its inherent benefits governments all over the world have invested huge capital on eGovernment with a view to improving internal efficiency and providing better and quality services to the citizenry. However the success of eGovernment is best measured by the perceptions of citizens who use the services. This paper the second of a two-part study seeks to investigate the types of public value that are desired as outcomes of eGovernment as well as the salient factors that are significant in predicting value creation from the perspective of citizens. To fulfil its objectives the study adopts a theoretical model that integrates two streams of research: (i) the updated DeLone and McLean IS Success Model and (ii) Public Value. Using survey data collected from Nigeria the model is empirically tested and validated through structural equation modelling analysis. Findings identify democracy reflexivity and productivity in order of importance as the three distinct value types desired as outcomes by citizens. Furthermore results show service quality as the most salient factor significant in predicting citizen satisfaction and citizen trust in eGovernment while both service quality and citizen satisfaction are significant in predicting net benefits. This research has both theoretical and practical implications. First it contributes to the advancement of knowledge in the public value creation of eGovernment. Second it provides a practical reference point for improving service delivery in the public sector.;
Proceedings of the 11th International Conference on Theory and Practice of Electronic Governance;Global Software Engineering (GSE) is a reality for even the smallest companies so software engineering students need to learn how to work in a globally distributed development context. Many approaches to teaching GSE have been described in the literature. Since the majority of software development is done by engineers working in small or medium sized enterprises (SMEs) we now ask: Are today's students being trained to work effectively in small distributed companies?We surveyed three GSE SMEs to identify which of 70 Global Teaming Model (GTM) practices were problematic and important to this sample. We then mapped recommendations for GSE educators to those pinpointed GTM practices. Finally we analysed the level to which these needed GTM practices were addressed by the GSE-Education (GSE-Ed) literature and who performed these practices. Nine GTM practices were found important and relevant to all three SMEs. Seven of these were addressed by GSE-Ed recommendations and two were seen to be lacking.A rich set of 63 unique GSE-Ed recommendations were found to support the seven GTM practices but our analysis unearthed a surprising complexity of roles and responsibilities undertaken by the instructor in GSE-Ed courses. As a result student and client involvement in coordination and collaboration activities tended to be weakened or non-existent. In order to ensure graduates are prepared for the reality practitioners of SMEs need to take on a more active role in the education process. Also students need to be given more responsibility so they can learn the broader professional and management skills required when developing software in multi-site SME teams.;
Proceedings of the 12th International Conference on Global Software Engineering;Agile software engineering methods have recently emerged as a new and different way of developing software as compared to the traditional methodologies. Universities already started to teach agile software engineering courses on agile methods at the undergraduate and graduate levels however the correct teaching approach is still under research. This study is addressing the problem of agile teaching its efficiency as perceived by academics and students and finally how the future software developers will acquire the skills required by the software industry. In order to answer to this question a survey was done among current and former computer science students gathering data from 200 students that attended university in the past 5 years. Most of these students have previously attended a course meant to teach agile methods through the completion of a capstone project and they were required to provide feedback regarding their views on the agile methods used as well as the method of teaching.;
Proceedings of the 21st Pan-Hellenic Conference on Informatics;Aiming at the problem of insufficient stability of traditional motor skill training auxiliary decision-making system in dark or dark environment this paper designs a motor skill training auxiliary decision-making support system based on Kinect. In terms of hardware design Kinect is used as the main hardware and TOF technology is used to set the parameters of distance and reachable field of view to obtain motor skill training data. In terms of software design Kinect is used to determine the bone node of human characteristics track human data and smooth it store the smoothed data in the designed data warehouse and connect the scattered databases together as the support of auxiliary decision-making. On this basis priority constraints are set for each module in the system to ensure the normal operation of the system. So far the overall design of the system has been completed. The experimental results show that the motion training aided decision support system based on Kinect designed in this paper has more accurate recognition angle of human motion image and less joint position positioning error in the case of darkness or dark light which proves that the system has good stability.;
Proceedings of the 14th International Conference on Computer Modeling and Simulation;Gamification is the use of game design elements in non-game context platforms such as services and marketing to motivate people to participate in planned activities to increase engagement and loyalty to achieve goals.Gamification has been applied to academic fields including software engineering in recent years. Some studies show that gamification can motivate engineers in Software Engineering (SE) if applied appropriately. However most gamification implementations are lacking well-defined frameworks or models.This paper develops a software gamification model (SGM) with a well-defined framework that provides a robust process for implementing gamification for SE. This model also contains elements from applied psychology Social Software Engineering (SSE) and the Capability Maturity Model (CMM). Having those elements ensures that the model has a solid foundation in gamification and SE disciplines. The model is further tailored for cross-cultural software development teams (CCSDT).CCSDT have been popular in recent years due to the fact that software development has become a global business. However as more and more CCSDT are formed many challenges and issues have been raised in those cross-cultural environments stemming from miscommunication misunderstanding cultural differences and conflicts. This paper uses the SGM to help resolve the issues.;
Proceedings of the 2017 International Conference on Management Engineering Software Engineering and Service Sciences;Majority of the software development organizations are motivated to transform their development activities from collocated development to offshore software development outsourcing (OSDO) environment. The adoption of OSDO is complicated due to geographical distance between development teams. The requirements engineering (RE) in the context of OSDO needs special consideration as it needs more communication and collaboration. The objective of this study is to investigate the RE barriers in the domain of OSDO. This study have two main objectives (i) identification of barriers for RE process in OSDO from the existing literature and (ii) prioritizing the identified barriers by using analytical hierarchy approach (AHP). However in this study a total of 14 barriers of RE process were identified. The investigated barriers were further categorized into three core categories i.e. coordination project administration and human resources management.The results demonstrated that Lack of 3Cs (communication coordination and control) Strict time schedule by customer and Incompatibility with client are the barriers having most priority in RE process in OSDO context. Moreover we noted that the coordination is the most significant category of investigated barriers. We are confident that the findings of this study provide a model which is significant to assess and improve the RE activities in the domain of OSDO.;
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;We describe a synthesis course that provides a hands-on treatment of many hardware and software topics learned in computer science (CS) programs. Using a modular series of twelve projects we walk the students through the gradual construction of a simple hardware platform and a modern software hierarchy yielding a basic yet powerful computer system. In the process of building the computer the students gain a first-hand understanding of how hardware and software systems are designed and how they work together as one enterprise. The course web site contains all the materials necessary to run this course in open source and students and instructors are welcome to use and extend them freely. The course projects are modular and self-contained and any subset of them can be implemented in any order and in any programming language. Therefore they comprise a flexible library of exercises that can be used in many applied CS courses. This paper gives a description of the approach and the course juxtaposed against general educational principles underlying meaningful learning.;
Proceedings of the 40th ACM Technical Symposium on Computer Science Education;Over the past several years crowdsourcing has entered software engineering practice. While most work is still done through traditional development contract development and outsourcing software projects today increasingly use crowdsourcing for a variety of purposes including fixing defects testing their software or gathering alternative designs for a new user interface. Through mechanisms such as competition sites expertise sharing sites bug bounties and online labor markets crowdsourcing has begun to reshape the ways in which developers contribute to software projects. This talk explores the models of crowdsourcing that have been applied to software development to date and outlines some of the opportunities that exist for the future.;
Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice;Chatbots have become commonplace â€“ they can provide customer support take orders collect feedback and even provide (mental) health support. Despite this diversity the opportunities of designing chatbots for more complex decision-making tasks remain largely underexplored. Bearing this in mind leads us to ask: How can chatbots be embedded into software tools used for complex decision-making and designed to scaffold and probe human cognition? The goal of our research was to explore possible uses of such â€œprobing botsâ€. The domain we examined was stock investment where many complex decisions need to be made. In our study different types of investors interacted with a prototype which we called â€œProberBotâ€ and subsequently took part in in-depth interviews. They generally found our ProberBot was effective at supporting their thinking but when this is desirable depends on the type of task and activity. We discuss these and other findings as well as design considerations for developing ProberBots for similar types of decision-making tasks.;
Proceedings of the 4th Conference on Conversational User Interfaces;This paper argues that the essential point of software engineering is not to (semi-automatically) improve the quality of software but rather to help human problem solvers to improve the quality of software. This paper argues that this essential point of software engineering research has been forgotten and that without regaining that perspective significant progress is not likely.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;Worked examples are instructional devices composed of the description of a problem steps to solve the problem and the final result. There is evidence that the use of the worked examples improves the learning process by reducing the learning time reducing the cognitive load and facilitating the construction of cognitive schemes. In addition students who learn from worked examples tend to solve similar problems more quickly and easily. Worked examples are adopted in several areas of knowledge but are not well-explored in Software Engineering (SE) teaching. Thus the goal of this work was to explore the use of worked examples in SE courses. To do so we conducted an exploratory study split into two stages. In the first stage we administered a survey with SE instructors to investigate the use of common examples worked examples and the difficulties find this type of material. In the second stage we applied worked examples in the classroom and collected feedback from students. The second stage was carried out remotely due to the conditions imposed by COVID-19. The results showed that instructors are employing examples in their courses some of them use worked examples even when they do not know the definition. In addition the feedback from the students was positive which may encourage the use of worked examples in SE teaching.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;Teaching Distributed Software Development with real distributed settings is a challenging and rewarding task. Distributed courses are idiosyncratically more challenging than standard local courses. We have experienced this during our distributed course which has been run for 14 consecutive years. In this article we present and analyze the emerging diversities specific to distributed project-based courses. We base our arguments on our experience and we exploit a three-layered distributed course model which we use to analyze several course elements throughout the 14-years lifetime of our distributed project-based course. In particular we focus on the changes that the course underwent throughout the years combining findings obtained from the analyzed data with our own teaching perceptions. Additionally we propose insights on how to manage the various diversity aspects.;
Exponential competence of computer science and software engineering undergraduate students;We live in exceptional times in which the entire world is witnessing the exponential spread of a pandemic which requires to adopt new habits of mind and behaviors. In this paper I introduce the term exponential competence which encompasses these cognitive and social skills and describe a course for computer science and software engineering students in which emphasis is placed on exponential competence. I argue that exponential competence is especially important for computer science and software engineering students since many of them will most likely be required to deal with exponential phenomena in their future professional development.;
Proceedings of the 43rd International Conference on Software Engineering: Joint Track on Software Engineering Education and Training;Interaction design has been consolidated as a practice with the potential to support the improvement of software quality in relation to various aspects of human-computer interaction. On the other hand more and more organizations are developing software with teams distributed geographically. Despite this little is known about how interaction design has been implemented in distributed software development (DSD). In this paper we present the results of an interview study conducted to understand how interaction design has been implemented in DSD projects. For this semi-structured interviews were carried out with profissionais with experience in DSD projects. The data were analyzed based on the thematic analysis method. The results of this study provide a detailed view of how interaction design is implemented in DSD projects. This paper presents an analysis of the main characteristics of interaction design in DSD projects such as the activities and practices of interaction design in DSD projects. This paper contributes to the body of knowledge of interaction design at the frontier of research between HCI and DSD by (i) providing an in-depth view of the practice of interaction design in DSD projects and (ii) identifying interaction design practices in DSD emerging from the study.;
Proceedings of the 21st Brazilian Symposium on Human Factors in Computing Systems;Global software development (GSD) faces several inherent challenges due to temporal organizational socio-cultural and geographical distances. Since GSD operates at different functional levels that include country company and team levels there is a need to understand and categorize GSD challenges at these levels. This paper aims to re-investigate GSD challenges and categorize them at the country company and team level. It will help academia to look into GSD issues with respect to operational levels and allow software companies to improve their processes and management at these levels.;
Proceedings of the 14th International Conference on Global Software Engineering;There is an ongoing debate in the software engineering (SE) community over the usefulness and applicability of classical SE methodologies versus agile methodologies. Based on an investigation of the philosophical origins the history and the technological support of representative classical SE methodologies and agile methodologies a framework is proposed in this paper to help understand the relationship between these different approaches. The framework proposed provides a novel five-dimensional ways in which to consider the concepts historical and technological background of the methodologies the characteristic differences between them the variety of skills and the economic technological and organisational conditions needed to execute them. The framework has been formed by combining five techniques of research analysis: Contextual Historical Analysis by analogy Phenomenological and Linguistic. This framework (CHAPL) helps software engineers understand the nature of SE methodologies more objectively and at a fundamental level in order to select the best practices and suitable SE methodologies for a software project.;
Proceedings of the 2008 International Workshop on Scrutinizing Agile Practices or Shoot-out at the Agile Corral;The goal of Software Engineering (SE) education is to teach theory and practice of software sciences with an ultimate practical goal. Quite surprisingly although standard SE programs include many hands-on courses they do not include practical lab courses in software development and maintenance as common in other engineering disciplines. A capstone project course that is standard in most SE programs cannot function as an instructive SE-lab course since it does not enable effective teaching and cannot replace a planned SE-development experiment.This paper describes an SE-lab course that creates lab conditions where students are faced with a deliberately challenging planned SE development and management tasks and the course staff provides team-based guidance. The paper analyzes the lab ideals principles and goals explains how they are realized in the lab content and presents its evaluation from the students and the instructors' viewpoints.;
Proceedings of the 40th International Conference on Software Engineering: Software Engineering Education and Training;Context: Career abandonment (turnaway) among software developers may be associated with many factors related to the profession. Identifying and understanding how these factors can affect those professionals is essential for organizations to design more effective retention policies and better understand the phenomenon. Objective: This study aims to identify motivators that may be associated with the turnaway phenomenon among software developers in addition to dimensions with which those motivators are associated. Method: A qualitative study was conducted with 15 former software developers from different regions of Brazil. Results: We have identified 49 different motivators among which the most cited were professional stagnation lack of financial recognition lack of professional regulation and work overload among others. We classified those motivators into seven software engineering dimensions mainly: software engineering professional practice management and economics. Conclusion: The results of the study suggest grounded on the collected qualitative data a number of hypotheses to further research relating turnaway to the types of activities of software development. We hope these results contribute to devise effective strategies for organizations to retain developers additionally minimizing the social cost of turnaway to those developers.;
Proceedings of the XXXV Brazilian Symposium on Software Engineering;Software engineering lacks underpinning scientific theories both for the software it produces and the processes by which it does so. We propose that an approach based on information theory can provide such a theory or rather many theories. We envision that such a benefit will be realised primarily through research based on the quantification of information involved and a mathematical study of the limiting laws that arise. However we also argue that less formal but more qualitative uses for information theory will be useful.The main argument in support of our vision is based on the fact that both a program and an engineering process to develop such a program are fundamentally processes that transform information. To illustrate our argument we focus on software testing and develop an initial theory in which a test suite is input/output adequate if it achieves the channel capacity of the program as measured by the mutual information between its inputs and its outputs. We outline a number of problems metrics and concrete strategies for improving software engineering based on information theoretical analyses. We find it likely that similar analyses and subsequent future research to detail them would be generally fruitful for software engineering.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;As one of the most well-known programmer Q&ampA websites Stack Overflow (i.e. SO) is serving tens of thousands of developers every day. Previous work has shown that many developers reuse the code snippets on SO when they find an answer (from SO) that functionally matches the programming problem they encounter in their development activities. To study how programmers reuse code on SO during project development we conduct a comprehensive empirical study. First to capture the development activities of programmers we collect 342148 modified code snippets in commits from 793 open-source Java projects and these modified code can reflect the programming problems encountered during development. We also collect the code snippets from 1355617 posts on SO. Then we employ CCFinder to detect the code clone between the modified code from commits and the code from SO and further analyze the code reuse when programmer solves a programming problem during development. We count the code reuse ratios of the modified code snippets in the commits of each project in different years the results show that the average code reuse ratio is 6.32% and the maximum is 8.38%. The code reuse ratio in project commits has increased year by year and the proportion of code reuse in the newly established project is higher than that of old projects. We also find that some projects reuse the code snippets from many years ago. Additionally we find that experienced developers seem to be more likely to reuse the knowledge on SO. Moreover we find that the code reuse ratio in bug-related commits (6.67%) is slightly higher than that of in non-bug-related commits (6.59%). Furthermore we also find that the code reuse ratio (14.44%) in Java class files that have undergone multiple modifications is more than double the overall code reuse ratio (6.32%).;
Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension;Today most of the moving target defense decision-making methods are based on models of a discrete dynamic game. To more accurately study network attack-defense strategies against continuous confrontations we analyze offensive and defensive behavior from a dynamic perspective. We propose a moving target defense decision-making method based on a model of a dynamic Markov differential game. We implement dynamic analysis and deduction of multi-stage continuous attack and defense confrontations for scenarios of continuous real-time network attack-defense. We take into account the influence of random factors and changes of the network system in the gaming process combine differential gaming with the Markov decision-making method and construct models of attack-defense games. We propose a solution for game equilibrium based on an objective function designed according to the total discounted payoff of the offensive and defensive game and the analysis of the characteristics of multi-staged game equilibrium. On this basis an optimal strategy selection method is designed. We apply and verify the game model and the defense strategy selection algorithm by using the moving target defense technique. We conduct simulations to verify the effectiveness and feasibility of the model and algorithm.;
Proceedings of the 7th ACM Workshop on Moving Target Defense;Context: Managing knowledge is one of the main challenges for software development organizations. Thus the principles of Knowledge Management (KM) are presented as determinant and effective factors for the software product quality. There are several approaches to applying KM in an organization. However for a KM approaches to succeed it is important to conduct a KM diagnostic in order to analyze the KM current state that already exists in the organization. Objective: The objective of this paper is to present the results of a Systematic Literature Review (SLR) conducted to summarize existing research on KM diagnostic in software development organizations. Method: SLR was performed by searching four electronic databases. We also performed backward snowballing from reference lists of selected studies. Results: From the SLR we identified 24 studies addressing investigated differents approaches related to KM diagnostics in software development organizations. Conclusion: Based on our results we conclude that in the software engineering context the KM diagnosis practice still does not seem consolidated.;
Proceedings of the XVII Brazilian Symposium on Software Quality;Network vulnerability management reduces threats posed by weaknesses in software hardware or organizational practices. As networks and related threats grow in size and complexity security analysts face the challenges of analyzing large amounts of data and prioritizing and communicating threats quickly and efficiently. In this paper we report our work-in-progress of developing a vulnerability management dashboard that helps analysts overcome these challenges. The approach uses interviews to identify a typical security analyst workflow and proceeds with an iterative design that relies on real-world data. The vulnerability dashboard development was based on a common security analyst workflow and includes functions to allow vulnerability prioritization according to their age persistence and impact on the system. Future work will look to execute full-scale user studies to evaluate the dashboardâ€™s functionality and decision-making utility.;
Practice and Experience in Advanced Research Computing 2022: Revolutionary: Computing Connections You;Global software development is nowadays becoming a priority for software industry. The actual global software engineering research has mainly focused on challenges and methodologies. Research on the cost attributes and the software development was fundamental to emphasize on the application of these attributes in the overall software development. A major research to explicit how global companies practicing global software development are undertaken to address those cost attributes. In this paper a descriptive survey is conducted to define the position of cost attributes in global software development. This survey is a data collection from an empirical strategy through an online questionnaire targeting 30 practitioners with practical software engineering experience. Moreover results of 26 questions chosen with major care are analyzed and discussed. The results show that interest in cost attributes for global software development projects is a critical topic for distributed software development. The control and the evaluation of cost attributes allow companies principally to save cost and also to remain focused on development of projects.;
Proceedings of the 9th International Conference on Information Management and Engineering;This paper explores softwareâ€™s role in visual art production by examining how artists use and develop software. We conducted interviews with professional artists who were collaborating with software developers learning software development and building and maintaining software. We found artists were motivated to learn software development for intellectual growth and access to technical communities. Artists valued efficient workflows through skilled manual execution and personal software development but avoided high-level forms of software automation. Artists identified conflicts between their priorities and those of professional developers and computational art communities which influenced how they used computational aesthetics in their work. These findings contribute to efforts in systems engineering research to integrate end-user programming and creativity support across software and physical media suggesting opportunities for artists as collaborators. Artistsâ€™ experiences writing software can guide technical implementations of domain-specific representations and their experiences in interdisciplinary production can aid inclusive community building around computational tools.;
Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems;A common approach for introducing computer science to middle school students is to teach them a simple yet engaging programming language A different approach is to teach them some advanced topic independent of any particular language or syntax We describe a 3-hour workshop module designed to do both This module has been piloted with a group of thirty 8th grade girls. It uses the Scratch programming language to develop the advanced software engineering concepts of specifications refinement and composition After this module students were enthusiastic about continuing to program in Scratch independently and also felt they learned something about computer science as a discipline.;
Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education;Digital twin technology has been applied in multiple fields recently by providing modelling platform information of built environment or real-time data. It was created to improve generation process and efficiency of industrial products at first. Today digital twins start to create scenarios of smart cities with information technology and computing. This paper explores the digital twin implementation in design progress of transportation network. A case study of Wellington Digital Twin has been analyzed. This public and accessible model allows for communities and neighborhoodsâ€™ participation in transportation network design progress with components to tag and report comments in urban areas. It is found that compared with conventional transportation simulation the digital twins have the characteristics of accurate implemented and digitalized. Meanwhile digital twins have the capability to present the exact counterpart of physical world and predict how it perform in the future. This research also argues that digital twins are not a panacea although they can assist interactive transportation network simulation to a certain extent.;
Proceedings of the 2022 International Conference on Computational Infrastructure and Urban Planning;Despite considerable efforts to address organizational problems of distributed software development currently available solutions do not seem to be sufficient. They are fragmented into individual patterns either not forming coherent pattern languages to address organizational distributed software development or being incorporated into extensive pattern languages for organizing software development in general. Another problem is their disconnection from the current technological support for collaboration. We attempt at overcoming these problems by providing a set of six organizational patterns for distributed software development. We relate them to each other and to other known patterns and practices practically establishing a pattern language for the organization of distributed software development. The overall idea of how this pattern language can be used is presented using a pattern story of a real company.;
Proceedings of the 26th European Conference on Pattern Languages of Programs;In our earlier research work we developed a conceptual framework that identifies the di?erent types of roles that can exist in contemporary software development projects (including both agile and traditional software development approaches). The purpose of the framework is to assist software project managers when tuning software development project roles to the demands of individual projects with our previous research indicating that there is a need to tailor software development roles to individual projects. In this work we extend the earlier research through the use of a series of semi-structured interviews within seven Turkish software companies. The results which are consistent with previous findings offer further evidence of the usefulness of the framework while also identifying possible areas for future work in this space.;
The Impact of Software Fault Prediction in Real-World Application: An Automated Approach for Software Engineering;Software fault prediction and proneness has long been considered as a critical issue for the tech industry and software professionals. In the traditional techniques it requires previous experience of faults or a faulty module while detecting the software faults inside an application. An automated software fault recovery models enable the software to significantly predict and recover software faults using machine learning techniques. Such ability of the feature makes the software to run more effectively and reduce the faults time and cost. In this paper we proposed a software defect predictive development models using machine learning techniques that can enable the software to continue its projected task. Moreover we used different prominent evaluation benchmark to evaluate the model's performance such as ten-fold cross-validation techniques precision recall specificity f 1 measure and accuracy. This study reports a significant classification performance of 98-100% using SVM on three defect datasets in terms of f1 measure. However software practitioners and researchers can attain independent understanding from this study while selecting automated task for their intended application.;
Proceedings of 2020 6th International Conference on Computing and Data Engineering;Source code search is one of the most important methods to study and reuse software project. Currently natural language based code search mainly faces the following two challenges: 1) More accurate search results are required when software projects evolve to be more heterogeneous and complex. 2) The semantic relationships between code elements (classes methods etc.) need to be illustrated so that developers could better understand their usage scenarios. To deal with these issues we propose a novel approach to searching a software project's source code based on graph embedding. First we build a software project's code graph automatically from its source code and represent each code element in the code graph with graph embedding. Second we search code graph with natural language questions return corresponding subgraph that composed of relevant code elements and their associated relationships as the best answer of the search question. In experiments we select two famous open source projects Apache Lucene and POI as examples to perform source code search tasks. The experimental results show that our approach improves F1-score by 10% than existing shortest path based code graph search approach while reduces average response time about 60 times.;
Proceedings of the 10th Asia-Pacific Symposium on Internetware;The First International Workshop on Quantum Software Engineering (Q-SE 2020) co-located with the 42nd International Conference on Software Engineering (ICSE 2020) was held between July 2 and July 3 2020. The workshop was originally scheduled to be a physical event in May 2020. Due to the SARS-CoV-2 aligned with the main conference the workshop was held virtually instead. This report summarizes the keynote speeches the paper presentations in the workshop and the ensuing discussions. IEEE and ACM publish the proceedings of the workshop as part of the ICSE 2020 Workshops Companion.;
The Stress as Adversarial Factor for Cyber Decision Making;There are several factors that make cyber operations stressful which include their complexity unpredictability and a continuum of decisions involving high risk and fast cost-benefit reasoning. These operations are subject to the reception of a large number of events to which the operator must learn (feedback) and respond appropriately in a timely manner presenting particular cyber stressors able to trigger combat exhaustion battle fatigue. Their consequences will vary and evolve according to changes in the operational context which makes them difficult to prevent detect and mitigate. Among others these attenuate the perception of a lack of self-efficacy reduces the cyber decision-maker ability of distinguishing ally neutral and hostile assets or tend to wrongly perceive the decision cost (effort time self-protection etc.) as much higher than the expected benefits. With the motivation of facilitating the understanding of the impact of the combat and operational stress at cyber operations this paper discusses the related recent insights for cognitive dominance at decision making on the cyberspace.;
Proceedings of the 16th International Conference on Availability Reliability and Security;Combining security engineering and software engineering is shaping the software development processes and shifting the emphasis of information security from the operation environment into the main information asset: the software itself. To protect software and data assets software development is subjected to an increasing amount of external regulation and organizational security requirements. To fulfill these requirements the practitioners producing secure software have plenty of models guidelines standards and security instructions to follow but very little scientific knowledge about effectiveness of the security they take.In this paper we present the current state of security engineering surveys and present results from our industrial survey (n = 62) performed in early 2018. The survey was conducted among selected software and security professionals employed by a selected set of 303 Finnish software companies. Results are compared to a commercial survey the BSIMM version 8 and the similarities and distinct differences are discussed. Also an analysis of the composition of security development life cycle models is presented suggesting regulation to be the driving force behind security engineering in software industry.;
Proceedings of the 13th International Conference on Availability Reliability and Security;The famous COMPAS case has demonstrated the difficulties in identifying and combatting bias and discrimination in AI-based penal decision-making. In this paper I distinguish two kinds of discrimination that need to be addressed in this context. The first is related to the well-known problem of inevitable trade-offs between incompatible accounts of statistical fairness while the second refers to the specific standards of discursive fairness that apply when basing human decisions on empirical evidence. I will sketch the essential requirements of non-discriminatory action within the penal sector for each dimension. Concerning the former we must consider the relevant causes of perceived correlations between race and recidivism in order to assess the moral adequacy of alternative standards of statistical fairness whereas regarding the latter we must analyze the specific reasons owed in penal trials in order to establish what types of information must be provided when justifying court decisions through AI evidence. Both positions are defended against alternative views which try to circumvent discussions of statistical fairness or which tend to downplay the demands of discursive fairness respectively.;
Pains and Gains of Peer Reviewing in Software Engineering: A Journal-Centric Perspective;A young software engineering researcher is invited to be an associate editor (AE) of a major journal in our field. The researcher is very excited. By this point she has amassed a nice career track-record. She has also been recognized via a number of invitations to serve on our conferences' program committees. But this somehow feels different and more important: there are multiple conferences each year and all of them have PCs staffed with dozens of members (not uncommonly over 100 in recent years) while there are comparatively fewer journals and at any point in time the sizes of their editorial boards are a fraction of a typical conference PC. This is a major additional sign of recognition of the young researcher's expertise and stature in the community. So the researcher quickly and enthusiastically accepts the invitation.;
Crystalline: Lowering the Cost for Developers to Collect and Organize Information for Decision Making;Developers perform online sensemaking on a daily basis such as researching and choosing libraries and APIs. Prior research has introduced tools that help developers capture information from various sources and organize it into structures useful for subsequent decision-making. However it remains a laborious process for developers to manually identify and clip content maintaining its provenance and synthesizing it with other content. In this work we introduce a new system called Crystalline that automatically collects and organizes information into tabular structures as the user searches and browses the web. It leverages natural language processing to automatically group similar criteria together to reduce clutter and uses passive behavioral signals such as mouse movement and dwell time to infer what information to collect and how to visualize and prioritize it. Our user study suggests that developers are able to create comparison tables about 20% faster with a 60% reduction in operational cost without sacrificing the quality of the tables.;
Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems;Context: Global software development (GSD) is a well-recognized business model to achieve competitiveness in the current global market. However this model has its own challenges due to the complex nature of its development process. Project management is an area of concern in software development and it has a strong influence in the GSD environment. Mostly companies embrace GSD without prior knowledge of its issues and as a result fail in the management of its process and outcomes of the project. Major reason behind this failure is poor project management practices that do not fit into the GSD context. This research work explores significance of project management and critical success factors (CSF's) in GSD in order to improve processes and facilitate software companies in implementing this developmental model successfully.;
Proceedings of the 14th International Conference on Global Software Engineering;"This paper presents SnappView an open-source software development kit that facilitates end-user review of graphical user interfaces for mobile applications and streamlines their input into a continuous design life cycle. SnappView structures this user interface review process into four cumulative stages: (1) a developer creates a mobile application project with user interface code instrumented by only a few instructions governing SnappView and deploys the resulting application on an application store (2) any tester such as an end-user a designer a reviewer while interacting with the instrumented user interface shakes the mobile device to freeze and capture its screen and to provide insightful multimodal feedback such as textual comments critics suggestions drawings by stroke gestures voice or video records with a level of importance (3) the screenshot is captured with the application browser and status data and sent with the feedback to SnappView server and (4) a designer then reviews collected and aggregated feedback data and passes them to the developer to address raised usability problems. Another cycle then initiates an iterative design. This paper presents the motivations and process for performing mobile application review based on SnappView. Based on this process we deployed on the AppStore WeTwo"" a real-world mobile application to find various personal activities over a one-month period with 420 active users. This application served for a user experience evaluation conducted with N1=14 developers to reveal the advantages and shortcomings of the toolkit from a development point of view. The same application was also used in a usability evaluation conducted with N2=22 participants to reveal the advantages and shortcomings from an end-user viewpoint.""";
A Cross-role and Bi-national Analysis on Security Efforts and Constraints of Software Development Projects;Software security which is often regarded as a non-functional requirement tends to be less prioritized than other explicit requirements in development projects. For designing security measures that can be used in software development we must understand the obstacles that prevent the adoption of secure software development practices. In this study we quantitatively analyzed security efforts and constraints of software development projects through an online survey of software development professionals in the US and Japan (N=664). We revealed how certain characteristics of a development project such as the projectâ€™s contractual relationships or the softwareâ€™s target users influence security efforts and constraints. In addition by comparing the survey results of two groups (developers and managers) we revealed how the gap in their security efforts and constraints influences software security. We believe the results provide insights toward designing usable measures to assist security-related decision-making in software development and conducting appropriate surveys targeting software development professionals.;
Proceedings of the 37th Annual Computer Security Applications Conference;"We propose the use of a new design-first approach called Problem Stereotypes and Solution Frameworks for teaching CS1 and CS2. A problem stereotype is a category of problems that can be solved using similar techniques. A solution framework is a typical solution to a problem parts of which can be reused to solve other problems of this stereotype. Students are introduced to a stereotype through a selection of related problems and common features among these are identified. Homework problems are selected from the same stereotype with students expected to follow the recipe"" provided by the given examples to generate their own solutions. Using this approach reduces the stress level for beginner students and prevents them falling prey to the ""CS is HARD"" myth. We present the results of our experience with this approach in two introductory classes and an upper-division Artificial Intelligence (AI) class at SUNY Brockport.""";
Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education;Development projects in which small teams of learners develop software/digital artefacts are common features of computing-related degree programmes. Within these team projects it can be problematic ensuring students are fairly recognised and rewarded for the contribution they make to the collective team effort and outputs. Peer assessment is a commonly used approach to promote fairness and due recognition. Maintaining parity within assessment processes is also a critical aspect of fairness. This paper presents the processes employed for the operation of one such team project at a UK higher education institution using the Team-Q rubric and analysing the impact of the (self-identified) gender of learner marking and the learner being marked on the scores obtained. The results from this institutional sample (N=121) using the Team-Q metric offers evidence of gender parity in this context. This study also makes the case for continued vigilance to ensure Team-Q and other rubrics are used in a manner that supports gender parity in computing.;
Proceedings of the 6th Conference on Computing Education Practice;Internet is an emerging technology industry worldwide. With the continuous development of computer technology although the Internet can provide convenience for people its security problems are gradually highlighted and are receiving more and more attention. Cyber security issues not only affect personal information but also endanger national information security. At the same time in the cyber environment viruses often threaten the operation of software. There are a number of security risks. How to use software design to enhance virus defense is also a hot issue of current research. Therefore this paper takes the cybersecurity threat characteristics of software in the big data environment as the basic basis and proposes a software design framework based on cybersecurity system to improve software security in the cyber environment so as to ensure internal data security.;
Proceedings of the 2022 7th International Conference on Cloud Computing and Internet of Things;Software development effort estimation is one of the most crucial activities in software engineering. Effort estimation permits managers and software engineers to anticipate forecast and precisely quote the schedule budget and manpower requirements. By accurately estimating the effort software projects can be saved from under run or over run. In this paper we have summarized and then analyzed the past work of software effort estimation in a systematic way. 10 researches were surveyed and explained briefly that how they are contributing towards solving the effort estimation problem in terms of time cost or test. It also emphasizes that various effort estimation models have different pros and cons and can be used in different context on basis of different types of historical data. The survey discovered the most popular models used for effort prediction are supervised learning algorithms. The trends identified through this survey can help in exploring the potential research areas.;
Proceedings of the 2018 7th International Conference on Software and Computer Applications;The explicit documentation of the rationale of design decisions is a practice generally encouraged but rarely implemented in industry because of a variety of inhibitors. Known methods for Design Decisions Rationale Documentation (DDRD) are aimed to maximize the benefits for practitioners who should utilize the DDRD by imposing the burden on the developers of documenting all the potentially useful information. In our view the adoption of a tailored DDRD consisting only of the required set of information would mitigate the effects of DDRD inhibitors. This paper focuses on confirming empirically the feasibility of a value-based approach for documenting the rationale behind design decisions and the importance of different DDRD information categories. In this context this work describes a replicated experiment carried out at the University Rey Juan Carlos of Madrid (Spain) aimed to validate previous results from an analogous study conducted at the University of Roma Tor Vergata (Italy). Results confirm that the level of utility related to the same category of DDRD information significantly changes depending on its purpose.;
Proceedings of the 3rd International Workshop on Sharing and Reusing Architectural Knowledge;Team-based student projects in beginning software engineering courses are often the first place that students have tried working on a team to develop a shared software product. For this reason team coordination and communication skills are probably very important to their team success. We have access and experience with a research training game named TeC developed to improve team coordination in disaster response teams and hypothesized that it might help student software teams.We ran a course experiment where we used the training game as a treatment and a generic board game as a control. With only 8 teams in the course available to participate and 6 ultimately completing the experiment statistical results are inconclusive. Nevertheless interesting outcomes were obtained that indicate potential benefit of such a training game and we believe this argues for more research in the area.;
Proceedings of the 9th International Workshop on Cooperative and Human Aspects of Software Engineering;DevOps and continuous development are getting popular in the software industry. Adopting these modern approaches in regulatory environments such as medical device software is not straightforward because of the demand for regulatory compliance. While DevOps relies on continuous deployment and integration regulated environments require strict audits and approvals before releases. Therefore the use of modern development approaches in regulatory environments is rare as is the research on the topic. However as software is more and more predominant in medical devices modern software development approaches become attractive. This paper discusses the fit of DevOps for regulated medical device software development. We examine two related standards IEC 62304 and IEC 82304-1 for obstacles and benefits of using DevOps for medical device software development. We found these standards to set obstacles for continuous delivery and integration. Respectively development tools can help fulfilling the requirements of traceability and documentation of these standards.;
Proceedings of the 39th International Conference on Software Engineering: New Ideas and Emerging Results Track;Nowadays the majority of cloud applications are developed based on the Service-Oriented Architecture (SOA) paradigm. Large-scale applications are structured as a collection of well-integrated services that are deployed in public private or hybrid cloud. Despite the inherent benefits that service-based cloud development provides the process is far from trivial in the sense that it requires the software engineer to be (at least) comfortable with the use of various technologies in the long cloud development toolchain: programming in various languages testing tools build / CI tools repositories deployment mechanisms etc. In this paper we propose an approach and corresponding toolkit (termed SmartCLIDEâ€”as part of the results of an EU-funded research project) for facilitating SOA-based software development for the cloud by extending a well-known cloud IDE from Eclipse. The approach aims at shortening the toolchain for cloud development hiding the process complexity and lowering the required level of knowledge from software engineers. The approach and tool underwent an initial validation from professional cloud software developers. The results underline the potential of such an automation approach as well as the usability of the research prototype opening further research opportunities and providing benefits for practitioners.;
Proceedings of the 25th Pan-Hellenic Conference on Informatics;This purpose of this study is find empirically The effect of management accounting information systems and decision making on managerial performance. The research method used is quantitative research methods with primary data obtained from questionnaire data which is measured using a likert scale. The result found that management accounting information system and decision making influence managerial performance. The results showed that the smaller the management accounting information system and decision making owned by the company the smaller the percentage of managerial performance carried out in the company. The higher the management accounting information system the higher the company's managerial performance.;
Proceedings of the 2021 5th International Conference on Software and E-Business;Multi-attribute decision making (MADM) is one of important issues in make-decision have been conducted many research in recent years. Indeed the main objective of this research is developing an extended Fuzzy rule based method based on TOPSIS conventional technique. This paper aids to solve a MADM problem by means of fuzzy environment under a group decision making. To do so fuzzy rule based system (FRBS) is used to obtain final score of alternatives toward each individual expert's opinions. And also TOPSIS technique is used in order to final aggregation of expert's results and makes a unique decision. This study makes an investigation on data about a supplier selection problem (SSP) as a case-based problem has been taken from a valid research. Robustness and validity of the proposed method is indicated with a numerical example and compare the output of results with another validated approach.;
Proceedings of the 3rd International Conference on Software Engineering and Information Management;"The principles behind the Agile Manifesto begin with Our highest priority is to satisfy the customer..."". It also states that Agile projects should be build around motivated and self-organized teams which might also lead to more satisfied developers. Several studies indeed report an increased job satisfaction by anecdotal evidence. In this paper we address the topic of satisfaction by in-depth analysis of the results of a nationwide survey about software development in Switzerland. We wanted to find out if satisfaction depends on the applied development method and more concrete how satisfaction relates to other elements in the development process including the use of various practices and the influences on business team and software issues. We found that higher satisfaction is reported more by those using Agile development than with plan-driven processes. We explored the different perspectives of developers and those with a management role and found a high consistency of satisfaction between Agile developers and Agile management and big differences with using working plan-driven methods. We found that certain practices and influences have high correlations to satisfaction and that collaborative processes are closely related to satisfaction especially when combined with technical practices. Applying recursive partitioning we found which elements were most important for satisfaction and gained insight about how practices and influences work in combination. We also explored the relationship between satisfaction and personal experience with Agile development. Our results in this analysis are principally descriptive but we think they can be a relevant contribution to understand the challenges for everyone involved in Agile development and can help in the transformation to Agile.""";
Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018;Software architecture focuses on the structure of a software system how such structure is organized into components how components are related to each other and what are the external visible properties of these components. In addition to satisfying the functional requirements software architecture attempts to fulfill the non-functional requirements such as performance efficiency reliability portability scalability and interoperability. Software architecture is an important part of software engineering and more so when developing complex software systems [2].;
Benchmarking and Comparison of Software Project Human Resource Allocation Optimization Approaches;For the Staffing and Scheduling a Software Project (SSSP) one has to find an allocation of resources to tasks while considering parameters such skills and availability to identify the optimal delivery of the project. Many approaches have been proposed that solve SSSP tasks by representing them as optimization problems and applying optimization techniques and heuristics. However these approaches tend to vary in the parameters they consider such as skill and availability as well as the optimization techniques which means their accuracy performance and applicability can vastly differ making it difficult to select the most suitable approach for the problem at hand. The fundamental reason for this lack of comparative material lies in the absence of a systematic evaluation method that uses a validation dataset to benchmark SSSP approaches. We introduce an evaluation process for SSSP approaches together with benchmark data to address this problem. In addition we present the initial evaluation of five SSSP approaches. The results show that SSSP approaches solving identical challenges can differ in their computational time preciseness of results and that our approach is capable of quantifying these differences. In addition the results highlight that focused approaches generally outperform more sophisticated approaches for identical SSSP problems;
LPI Radar Signal Processing Method Based on Software Development Mode;In order to improve the performance of modern Low Probability of Intercept (LPI) radar this paper designs several typical LPI radar signals and furthermore performs simulation experiments to verify the LPI performance of these signals. Meanwhile combining with open architecture of radar information processing an LPI radar signal processing method based on software development mode is put forward. This method overcomes the defect of existing design method of radar signal processing system which can realize the flexible configuration of LPI radar parameters. Using this method LPI radar can achieve adaptive expansion capability which can adapt future more complex electromagnetic interference and the environment.;
Proceedings of the 4th International Conference on Computer Science and Application Engineering;Empirical software research could be improved if there was a systematic way to identify the types of software for which empirical evidence applies. This is because results are unlikely to be globally applicable but are more likely to apply only in certain contexts such as the type of software on which the evidence has been tested. We present a software taxonomy that should help researchers to apply their research systematically to particular types of software. The taxonomy was generated using existing partial taxonomies and input from survey participants. If a taxonomy such as ours gains acceptance it will facilitate comparison and appropriate application of research. In the paper we present the benefits of such a taxonomy the process we used to develop it and the taxonomy itself.;
Proceedings of the 2008 Conference of the Center for Advanced Studies on Collaborative Research: Meeting of Minds;Emotion analysis in text has drawn recent interests in the software engineering (SE) community. Existing domain-independent techniques for automated emotion/sentiment analysis perform poorly when operated on SE text. Thus a few SE domain-specific tools are recently developed for detecting sentimental polarities (e.g. positivity negativity). But for capturing individual emotional states such as excitation stress depression and relaxation there is only one recent tool named DEVA which uses a lexicon-based approach.We have developed MarValous the first Machine Learning based tool for improved detection of the aforementioned emotional states in software engineering text. We evaluate MarValous using a dataset containing 5122 comments collected from JIRA and Stack Overflow. From a quantitative evaluation MarValous is found to have substantially outperformed DEVA achieving more than 83% precision and more than 79% recall.;
Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing;For the multiple attribute decision-making problem the decision-making approach which considers hesitant fuzzy decision information and unknown attribute weights is investigated. Primarily the formed vectors of alternative positive and negative ideal direction are defined. Subsequently a bidirectional projection based on hesitant fuzzy information is established. Simultaneously the improved closeness degree equation is proposed. Further an attribute weight determination model which maximizes the closeness degree and entropy is constructed. In the last an illustrative example is provided to demonstrate the validity and feasibility of the proposed approach.;
Proceedings of the 2020 2nd International Conference on Management Science and Industrial Engineering;For the success of automated vehicles in addition to legal safety and technical aspects user acceptance and trust in automation systems are considered to have a significant impact. The driving style can decisively influence these factors. Besides driving dynamics such as velocity and accelerations tactical decisions (e.g. for lane changes) also define the driving style on highways. In order to get a better understanding of lane change behavior expected by passengers during automated driving participants (N=35) determined and initiated the desired point in time to perform lane changes in a study under real highway driving conditions. Subsequently a logistic regression analysis could determine the probability of a lane change considering different environmental variables as predictors. Thus the most important factors influencing lane change decisions could be identified. The results indicate that for lane changes from the right to the middle lane as well as from the middle to the right lane the preceding and approaching vehicle on the target lane as well as the preceding vehicle on the current lane have a significant influence on the lane change decision. In addition vehicles entering the highway and presence of more than one preceding vehicle on the right lane were revealed as significant predictors for the lane change decision to the right. Contrarily for the lane change decision to the left the relative velocity to the preceding vehicle as well as a speed limit equal to the target velocity have decisive influence. The results give a first important insight for a user-centered automated lane change behavior. Following individual aspects of these results can be considered to be evaluated more specifically.;
Proceedings of the 2021 ACM/IEEE International Conference on Human-Robot Interaction;Existing tools for automated sentiment analysis in software engineering text suffer from either or both of two limitations. First they are developed for non-technical domain and perform poorly when operated on software engineering text. Second those tools attempt to detect valence only and cannot capture arousal or individual emotional states such as excitement stress depression and relaxation.In this paper we present the first sentiment analysis tool DEVA which is especially designed for software engineering text and also capable of capturing the aforementioned emotional states through the detection of both arousal and valence. We also create a ground-truth dataset containing 1795 JIRA issue comments. From a quantitative evaluation using this dataset DEVA is found to have more than 82% precision and more than 78% recall.;
Proceedings of the 33rd Annual ACM Symposium on Applied Computing;Deciding what constitutes a single module what classes belong to which module or the right set of modules for a specific software system has always been a challenging task. The problem is even harder in large-scale software systems composed of thousands of classes and hundreds of modules. Over the years researchers have been proposing different techniques to support developers in re-modularizing their software systems. In particular the search-based software re-modularization is an active research topic within the software engineering community for more than 20 years.This paper describes our efforts in applying search-based software re-modularization approaches at Adyen a large-scale payment company. Adyen's code base has 5.5M+ lines of code split into around hundreds of modules. We leveraged the existing body of knowledge in the field to devise our own search algorithm and applied it to our code base. Our results show that search-based approaches scale to large code bases as ours. Our algorithm can find solutions that improve the code base according to the metrics we optimize for and developers see value in the recommendations. Based on our experiences we then list a set of challenges and opportunities for future researchers aiming at making search-based software re-modularization more efficient for large-scale software companies.;
Proceedings of the 43rd International Conference on Software Engineering: Software Engineering in Practice;Founded in 2017 as an information technology company ABC-CORP engaged in several projects. Not all projects finished by the deadline. This is caused by the software development process is undisciplined. So there are opportunities to enable the use of software development methodology in the organization. But not any methodology can fit to the company. Unsuitable methodology may cause more problems than before. The researcher decided to use the quality function deployment with multicriteria approach using fuzzy number. Acting as the decision maker in this study is all ABC-CORP staff. The data collection tool used in this research is questionnaire. Data processing is done using two phase QFD with fuzzy number. The result of this research Dynamic System Development Method is a suitable development method to be applied in ABC-CORP with a value of 0.64535 in the ranking.;
Proceedings of the 2nd International Conference on Software Engineering and Information Management;Modern static-analysis tools provide powerful and specific insights into codebases. The Linux kernel team for example developed Coccinelle a powerful tool for searching analyzing and rewriting C source code because the Linux kernel contains more than 27 million lines of code a static-analysis tool is essential both for finding bugs and for making automated changes across its many libraries and modules. Another tool targeted at the C family of languages is Clang scan-build which comes with many useful analyses and provides an API for programmers to write their own analyses. Like so many things in computer science the utility of static analysis is self-referential: To write reliable programs we must also write programs for our programs. But this is no paradox. Static-analysis tools complex though their theory and practice may be are what will enable us and engineers of the future to overcome this challenge and yield the knowledge and insights that we practitioners deserve.;
Software development design and implementation of management system for characteristic B &amp B;The regional comprehensive economic partnership has been officially signed and released. It is the construction of economic integration in East Asia which will promote regional economic integration and world economic development. It can be expected that the following 15 countries will soon release relevant supporting policies such as visa free landing visa and supporting tourism catering and other consumer preferences which will also make it more convenient and affordable for individuals to travel abroad. Now is a good time to experience foreign culture. Personal planning starts with the three categories of world cultural heritage advocated by UNESCO. The choice of conditions should start with the accommodation service of characteristic B &amp B around the tourism area so as to be able to experience the foreign characteristics festival atmosphere and learn the characteristics of multi culture.Because Covid-19 is still under continuous influence. Large group transnational travel groups have been temporarily frozen or disappeared. A new state of small bourgeois groups short-term and deep tourism has emerged. Expensive hotels have also reduced their prices to survive the epidemic. However in order to avoid cluster infection people who want to micro travel have changed to stay in low-cost and characteristic B &amp B which are close to the scenic spots and cheap in price The main consideration of accommodation is that B &amp B has the characteristics of local characteristics to attract free travelers and backpackers to stay.The existing website and software of characteristic B &amp B are relatively simple and easy. Most websites can provide information services of passenger reservation and online payment. The construction of characteristic B &amp B online management system is the performance requirement of modular management system. According to the software engineering development process find out the system requirements feasibility system analysis conceive system design mainly including the front-end HTML CSS and JavaScript. The server is Apache the framework is Django and the integrated compiler tool is PyCharm. Using Python language to separate the front-end and back-end of the system combining Django framework with MySQL database technology can improve the stability of system performance run system test acceptance test and system security and successfully construct the characteristic B &amp B management system.;
Proceedings of the 2021 4th International Conference on Computers in Management and Business;Software engineering researchers and their industrial counterparts have emphasized that research is essential for innovation. In practice rather than ending up in a win-win situation most of the times both the parties lose because of differences in expectations between the two sides. In this report we briefly summarize the key insights from 1st International Workshop on Software Engineering Research and Industrial Practices (SER&ampIPs 2014) co-located with 36th International Conference on Software Engineering (ICSE 2014). The core lesson that stems out of this workshop is a definite need to have multiple approaches to deal with software engineering research-industrial practices partnership. Specifically the workshop presented two keynotes: one from an industrial researcher explaining the need for academic expertise and an academic researcher on how their research added value to industry. An invited seminar unveiled short-term and long-term funding opportunities followed by a list of presentations from peerreviewed submissions from both software engineering research and industry partners. Finally the workshop ended with group discussions brainstorming of potential topics that can lead to fruitful collaboration between software engineering researchers and industrial practitioners. A major lesson from the workshop is the choice of a topic that fosters a win-win situation for both parties in short-term and long-term collaborations.;
Improving the decision-making process of self-adaptive systems by accounting for tactic volatility;When self-adaptive systems encounter changes within their surrounding environments they enact tactics to perform necessary adaptations. For example a self-adaptive cloud-based system may have a tactic that initiates additional computing resources when response time thresholds are surpassed or there may be a tactic to activate a specific security measure when an intrusion is detected. In real-world environments these tactics frequently experience tactic volatility which is variable behavior during the execution of the tactic.Unfortunately current self-adaptive approaches do not account for tactic volatility in their decision-making processes and merely assume that tactics do not experience volatility. This limitation creates uncertainty in the decision-making process and may adversely impact the system's ability to effectively and efficiently adapt. Additionally many processes do not properly account for volatility that may effect the system's Service Level Agreement (SLA). This can limit the system's ability to act proactively especially when utilizing tactics that contain latency.To address the challenge of sufficiently accounting for tactic volatility we propose a Tactic Volatility Aware (TVA) solution. Using Multiple Regression Analysis (MRA) TVA enables self-adaptive systems to accurately estimate the cost and time required to execute tactics. TVA also utilizes Autoregressive Integrated Moving Average (ARIMA) for time series forecasting allowing the system to proactively maintain specifications.;
Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering;Scheduling tasks is one of the critical duties of software project managers. The main objective of the scheduling is typically reducing the project's cost and duration. However the numerous possible assignments of tasks to the team members and the dependencies between tasks make task scheduling an NP-hard problem. In the context of Global Software Development (GSD) projects specifically reducing the development time is one of the cornerstones. However some of the GSD characteristics such as having people from different locations working in different time zones and perhaps involved in the same software tasks (Follow the Sun approach) make the scheduling even more difficult for the manager. Recently several techniques based on evolutionary search algorithms have been proposed to automatically optimize the task scheduling in traditional software development projects. In this paper we apply the same concepts in the context of GSD projects. We have implemented a Genetic algorithm-based assignment technique that uses a queue-based GSD simulator for fitness function evaluation. Our technique has been evaluated based on three project's datasets from two large-scale organizations that practice GSD. The results show that the search-based approach can in some cases improve the assignments compared to the actual assignments by the managers in terms of reducing the projects duration. We also report the actual project managers' feedback on the automatic assignments.;
Proceedings of the 39th International Conference on Software Engineering: Software Engineering in Practice Track;"This is a position paper of research related to usability and software engineering. Important problem to develop software with high usability is that it is difficult to apply human centered design process to software development process. To solve this we propose three issues they are 1) clarification of demand"" and evaluation process about user requirements 2) how to fill gaps between software engineers and usability experts about HCD 3) solution of twin peaks problem (gap between requirements and architecture). For these issues it is necessary to discuss detail targets.""";
Proceedings of the 1st International Workshop on Design and Innovation in Software Engineering;Emotions have an effect on developers' progress during software development tasks. The purpose of this position paper is to investigate the effects of emotional awareness specifically type clarity on developers' progress. A proposal for this investigation and a discussion of the current work implicating the effects of emotion in software development are presented.;
Proceedings of the 2nd International Workshop on Emotion Awareness in Software Engineering;Research in HCI and CSCW has consistently shown how software design approaches are an abstract idealisation of work practices raising questions regarding the appropriateness and applicability of what might be considered as â€˜best practiceâ€™ or â€˜doable practiceâ€™ in project work. Such issues have magnified the fundamental need for examining exactly how conventional (and generally Western) constructs approaches and methods widely adopted in the process of producing and deploying technologies actually work. The paper reports findings from a study that seeks to understand the implications for adopting â€˜well-knownâ€™ practices for framing undertaking and analysis distributed and collaborative software project in the context of Nigeria. Findings show that documenting and analysing what is often considered as â€˜best practiceâ€™ supposedly prescriptive maps and scripts for accomplishing work necessitates considering how they get adopted interpreted and extended as â€˜orderlyâ€™ and occasionally â€˜messyâ€™ alternatives offering some sensitivities for understanding the translocal features and transitional meaning of agile project work.;
Proceedings of the 32nd Australian Conference on Human-Computer Interaction;In this paper we present patterns for building customer relationships in a pattern language for value-creation marketing. This pattern language is a collection of practical knowledge to realize successful business and commerce that offers new value proposes a deeply wonderful life and shares excitement with customers through products and services with mutual respect so that sales will naturally increase as an extension of pleasure. This practical knowledge has been nurtured in Japan for about 20 years in a community of practice comprised of approximately 1500 participating shops and companies. This pattern language consists of a total of 40 patterns this paper covers 10 patterns related to building customer relationships namely Special Existence Connect at First Meetings Approach Just Right Small Self-Presentation Behave Naturally Unforgettable Experiences Connect to Business Grow Own Style Keep Enchanting and Fan Community. These patterns can be categorized into three groups: BEGIN BONDING (beginner level) OFFER EXPERIENCES TO GROW CLOSE (intermediate level) and MOVE FORWARD TOGETHER (advanced level).;
Proceedings of the European Conference on Pattern Languages of Programs 2020;Software quality sits at the core of software engineering as a discipline. Yet although each university software-engineering and the software-development course covers software quality to some extent practitioners still lament on graduatesâ€™ readiness for practise for this very reasonâ€”poor quality of their code. As a result we have engaged university industrial partners in designing a master-degree Software Quality course that puts the key software quality topics in one place. In this paper we report on the effects of the course on the quality of studentsâ€™ coding projects. To this end we have analysed a total of 54 project submissions from 27 students with both manual and automated quality assessment methods. We have employed 30 manual and 22 automated quality characteristics related to coding style architecture design and general development practices. In particular we examine which characteristics of the code have improved the most and what were the most common issues. Additionally we investigate how the code quality improvement is related to external aspects such as studentsâ€™ prior coding experience interest and their time spent on the assignments. We use the results to formulate a set of lessons learned in order to improve the design of the course and to inspire educators who consider introducing a similar type of course.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;We review practical advice on decision-making during computer security incident response. Scope includes standards from the IETF ISO FIRST and the US intelligence community. To focus on human decision-making the scope is the evidence collection analysis and reporting phases of response which includes human decision-making within and connecting these phases. The results indicate both strengths and gaps. A strength is available advice on how to accomplish many specific tasks. However there is little guidance on how to prioritize tasks in limited time or how to interpret generalize and convincingly report results. Future work should focus on these gaps in explication and specification of decision-making during incident analysis.;
Environmental factors influencing individual decision-making behavior in software projects: a systematic literature review;As one of the crucial human aspects individual decision-making behavior may affect the quality of a software project and it is adaptive to the environment in which an individual is practicing. However no comprehensive reference framework of the environmental factors influencing individual decision-making behavior in software projects is presently available. This paper undertakes a systematic literature review (SLR) to gain insight into existing studies on this topic. After a careful SLR process 40 studies were targeted to solve this question. Based on these extracted studies we first provided a taxonomy of environmental factors comprising eight categories. Then a total of 237 factors are identified and classified using these eight categories and major environmental factors of each category are listed in the paper. The environmental factors listing and the taxonomy can help researchers and practitioners to better understand and predict the behavior of individuals during decision making and to design more effective solutions to improve people management in software projects.;
Proceedings of the 9th International Workshop on Cooperative and Human Aspects of Software Engineering;The cooperative bandit problem is a multi-agent decision problem involving a group of agents that interact simultaneously with a multi-armed bandit while communicating over a network with delays. The central idea in this problem is to design algorithms that can efficiently leverage communication to obtain improvements over acting in isolation. In this paper we investigate the stochastic bandit problem under two settings - (a) when the agents wish to make their communication private with respect to the action sequence and (b) when the agents can be byzantine i.e. they provide (stochastically) incorrect information. For both these problem settings we provide upper-confidence bound algorithms that obtain optimal regret while being (a) differentially-private and (b) tolerant to byzantine agents. Our decentralized algorithms require no information about the network of connectivity between agents making them scalable to large dynamic systems. We test our algorithms on a competitive benchmark of random graphs and demonstrate their superior performance with respect to existing robust algorithms. We hope that our work serves as an important step towards creating distributed decision-making systems that maintain privacy.;
Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems;Regardless of numerous collision avoidance regulations to prevent collisions of vessels accidents still happen. The collision avoidance decision system is an important part of intelligent ship applications as it can provide decision support to avoid collision accidents. In this paper using the encounter samples extracted from Automatic Identification System (AIS) data a vessel collision avoidance decision-making model is developed by the Support Vector Regression (SVR) approach. During the model training and validation tests the SVR model has high prediction accuracy and solves the nonlinear problem with the multiple motion parameters and vessel collision avoidance behavior in different encounter situations. However due to the sensitivity of the model to the magnitude of collision avoidance behavior prediction errors are inevitable. These findings can improve the real-time performance of the collision avoidance decision-making and illustrate the necessity of collision avoidance behavior in real situations. It provides a reference to collision avoidance action and decision guidance of vessel autonomous driving systems.;
2021 2nd International Conference on Artificial Intelligence and Information Systems;Startups are on the rise every day. They contribute to global economies by creating innovative products and services yet the phenomenon of software development skills for start-ups is not fully researched. A key challenge startup companies face is recruiting software development professionals with the right skills. Current software development skill studies largely focus on a broader level with very little focus on startup companies which operate differently to well-established companies. In this study the Delphi method was employed to create a skills profile of software development professionals for startups. Four of the top five skills identified pertain to soft skills i.e. problem-solving working well as a team player being self-motivated and having learning agility. The only technical skill ranked in the top five pertained to the core development task of building new software.;
Conference of the South African Institute of Computer Scientists and Information Technologists 2020;The software engineering industry has witnessed an increasing number of innovative methods and practices in the last decade at different levels ranging from development processes to software projects and from testing to verification software products. Extensive studies have been conducted empirically to investigate and discuss the impact of using agile principles in the testing process on distributed teams across geographical boundaries. This empirical study has a similar focus using a real case study in a distributed domain and applying agile testing to a selected team compares their outcome with another three teams to determine the impact of involving a client in a testing process to overcome distributed development challenges. The findings indicate a highly positive impact on team productivity when using agile tests as compared with other groups using central distributed team testing. All teams met a 90% testing requirement. However the group applying agile testing verified more than 99% of all requests entered into the testing process a notable difference supporting the productivity of any development project.;
Proceedings of the 2020 3rd International Conference on Geoinformatics and Data Analysis;"Team projects in software engineering courses can contextualize practical software development experience and help students transition into related careers. However the traditional academic environment is not particularly conducive to realistic software development. Consequently we developed a model for collaboration between students in Computer Science and Entrepreneurship programs to cultivate development of real software products. This paper describes our partnership and illustrates how courses teaching agile software development and lean startup methodologies complement each other to foster realistic interdisciplinary Tech Startup"" team projects.""";
An empirical study on female participation in software project courses;Gender issues in software engineering education are gaining research attention due to the desire to promote female participation in the field. The objective of this work is to enhance the understanding of female students' participation in software engineering projects to support gender-aware course optimization. Since 2015 we have investigated the participation of female students in terms of software engineering activities and team dynamics in a software project course that involves a real customer. We found that female students are more active with project management and requirement engineering while they remain under-represented in highly complex or specific tasks i.e. architecture work and user experience design. We found no statistically significant difference in perceived team dynamics between male and female students. Insights on female project activities would facilitate the arrangement of project teams so that learning can be distributed equally across genders.;
Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings;"During the last few years many researchers have attempted to find a way to implement gamified systems that are adaptively personalized based on user types. Gamification which is the use of game elements in a non-game context in a way that makes it like a game helps in increasing users' engagement. Thus software engineers cannot follow the approach of One size fit all"" anymore as in the traditional software design. That is because different people are motivated with different ways and with different mechanics and dynamics based on their needs and personalities. This paper focuses on devising means to develop personalized gamified systems based on user types. We suggest achieving that by changing the gamification elements themselves and not to only adapt the game mechanics and dynamics values based on user types to get the most users' engagement satisfaction and performance while using the developed software. We propose a method that provides a systematic process that guides the software engineers in designing adaptive gamified systems based on user types by mapping them to gamification elements. Moreover to formalize the proposed method we develop an ontology that implements the mappings between game elements and user types by defining rules that govern their usage. The method also provides a systematic means to modify the system at runtime (i.e. while the system is in use) based on the users' preference and behavior by changing the existing elements based on the usage of each user.""";
Proceedings of the 2020 3rd International Conference on Geoinformatics and Data Analysis;Data quality is an essential aspect in any empirical study because the validity of models and/or analysis results derived from an empirical data is inherently influenced by its quality. In this empirical study we focus on data consistency as a critical factor influencing the accuracy of prediction models in software engineering. We propose a software metric called Cases Inconsistency Level (CIL) for analyzing conflicts within software engineering data sets by leveraging probability statistics on project cases and counting the number of conflicting pairs. The result demonstrated that CIL is able to be used as a metric to identify either consistent data sets or inconsistent data sets which are valuable for building robust prediction models. In addition to measuring the level of consistency CIL is proved to be applicable to predict whether or not an effort model built from data set can achieve higher accuracy an important indicator for empirical experiments in software engineering.;
Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering;We describe how CSP-OZ a formal method combining the process algebra CSP with the specification language Object-Z can be integrated into an object-oriented software engineering process employing the UML as a modelling and Java as an implementation language. The benefit of this integration lies in the rigour of the formal method which improves the precision of the constructed models and opens up the possibility of (1) verifying properties of models in the early design phases and (2) checking adherence of implementations to models.The envisaged application area of our approach is the design of distributed reactive systems. To this end we propose a specific UML profile for reactive systems. The profile contains facilities for modelling components their interfaces and interconnections via synchronous/broadcast communication and the overall architecture of a system. The integration with the formal method proceeds by generating a significant part of the CSP-OZ specification from the initially developed UML model. The formal specification is on the one hand the starting point for verifying properties of the model for instance by using the FDR model checker. On the other hand it is the basis for generating contracts for the final implementation. Contracts are written in the Java Modeling Language (JML) complemented by CSPjassda an assertion language for specifying orderings between method invocations. A set of tools for runtime checking can be used to supervise the adherence of the final Java implementation to the generated contracts.;
How to Evaluate Trust in AI-Assisted Decision Making? A Survey of Empirical Methodologies;The spread of AI-embedded systems involved in human decision making makes studying human trust in these systems critical. However empirically investigating trust is challenging. One reason is the lack of standard protocols to design trust experiments. In this paper we present a survey of existing methods to empirically investigate trust in AI-assisted decision making and analyse the corpus along the constitutive elements of an experimental protocol. We find that the definition of trust is not commonly integrated in experimental protocols which can lead to findings that are overclaimed or are hard to interpret and compare across studies. Drawing from empirical practices in social and cognitive studies on human-human trust we provide practical guidelines to improve the methodology of studying Human-AI trust in decision-making contexts. In addition we bring forward research opportunities of two types: one focusing on further investigation regarding trust methodologies and the other on factors that impact Human-AI trust.;
Distance-Measurement-Decision-Making Backend System Using NodeJS;A potential start-up business in the catering industry called Kunyahku which aims to source food products from micro-catering businesses while offering customers many options of ordering food products for their events. Because customers do not initially know from which vendors their order comes from and only consider Kunyahku as the brand representing the vendors Kunyahku has a unique business process which no current existing e-commerce platforms is able to accommodate. A custom backend system with the ability of calculating the most suitable vendor based on the closest distance between the vendor and the customer is required to support the e-commerce business process. Because the state of the business is still a startup financial resources are limited and therefore minimizing expenses is. the ultimate goal therefore the usage of cost minimalized platforms such as NodeJS programming language self-created codes to run algorithms etc.;
Proceedings of the 2020 International Conference on Engineering and Information Technology for Sustainable Industry;Evidence-Based Software Engineering (EBSE) focuses on understanding and delivering software engineering practices tools and techniques that qualitatively and quantitatively provide value. The principles of EBSE underpin safety critical software engineering practices: when we build a safety critical software system we must in parallel deliver evidence that the steps we have taken and the artefacts that we build will lead to an acceptably safe system. In safety critical software engineering traceability plays a vital role. This talk will explore some of the different applications and uses of traceability in this context and will suggest ways in which Model-Driven Engineering can provide solutions (e.g. through standardised approaches for describing safety arguments and evidence) as well as new challenges.;
Why Google stores billions of lines of code in a single repository;Google's monolithic repository provides a common source of truth for tens of thousands of developers around the world.;
The SPACE of Developer Productivity: There's more to it than you think.;Developer productivity is about more than an individual's activity levels or the efficiency of the engineering systems relied on to ship software and it cannot be measured by a single metric or dimension. The SPACE framework captures different dimensions of productivity and here we demonstrate how this framework can be used to understand productivity in practice and why using it will help teams better understand developer productivity and create better measures to inform their work and teams.;
C Is Not a Low-level Language: Your computer is not a fast PDP-11.;In the wake of the recent Meltdown and Spectre vulnerabilities itâ€™s worth spending some time looking at root causes. Both of these vulnerabilities involved processors speculatively executing instructions past some kind of access check and allowing the attacker to observe the results via a side channel. The features that led to these vulnerabilities along with several others were added to let C programmers continue to believe they were programming in a low-level language when this hasnâ€™t been the case for decades.;
A view of cloud computing;Clearing the clouds away from the true potential and obstacles posed by this computing capability.;
Borg Omega and Kubernetes: Lessons learned from three container-management systems over a decade;Though widespread interest in software containers is a relatively recent phenomenon at Google we have been managing Linux containers at scale for more than ten years and built three different container-management systems in that time. Each system was heavily influenced by its predecessors even though they were developed for different reasons. This article describes the lessons weâ€™ve learned from developing and operating them.;
A Tour through the Visualization Zoo: A survey of powerful visualization techniques from the obvious to the obscure;Thanks to advances in sensing networking and data management our society is producing digital information at an astonishing rate. According to one estimate in 2010 alone we will generate 1200 exabytes -- 60 million times the content of the Library of Congress. Within this deluge of data lies a wealth of valuable information on how we conduct our businesses governments and personal lives. To put the information to good use we must find ways to explore relate and communicate the data meaningfully.;
Bitcoinâ€™s Academic Pedigree: The concept of cryptocurrencies is built from forgotten ideas in research literature.;Weâ€™ve seen repeatedly that ideas in the research literature can be gradually forgotten or lie unappreciated especially if they are ahead of their time even in popular areas of research. Both practitioners and academics would do well to revisit old ideas to glean insights for present systems. Bitcoin was unusual and successful not because it was on the cutting edge of research on any of its components but because it combined old ideas from many previously unrelated fields. This is not easy to do as it requires bridging disparate terminology assumptions etc. but it is a valuable blueprint for innovation.;
The status of the P versus NP problem;It's one of the fundamental mathematical problems of our time and its importance grows with the rise of powerful computers.;
BASE: An Acid Alternative: In partitioned databases trading some consistency for availability can lead to dramatic improvements in scalability.;Web applications have grown in popularity over the past decade. Whether you are building an application for end users or application developers (i.e. services) your hope is most likely that your application will find broad adoption and with broad adoption will come transactional growth. If your application relies upon persistence then data storage will probably become your bottleneck.;
A few billion lines of code later: using static analysis to find bugs in the real world;How Coverity built a bug-finding tool and a business around the unlimited supply of bugs in software systems.;
Crossing the software education chasm;An Agile approach that exploits cloud computing.;
The Pathologies of Big Data: Scale up your datasets enough and all your apps will come undone. What are the typical problems and where do the bottlenecks generally surface?;"What is big data"" anyway? Gigabytes? Terabytes? Petabytes? A brief personal memory may provide some perspective. In the late 1980s at Columbia University I had the chance to play around with what at the time was a truly enormous ""disk"": the IBM 3850 MSS (Mass Storage System). The MSS was actually a fully automatic robotic tape library and associated staging disks to make random access if not exactly instantaneous at least fully transparent. In Columbiaâ€™s configuration it stored a total of around 100 GB. It was already on its way out by the time I got my hands on it but in its heyday the early to mid-1980s it had been used to support access by social scientists to what was unquestionably ""big data"" at the time: the entire 1980 U.S. Census database.""";
The Curse of the Excluded Middle: Mostly functional programming does not work.;"There is a trend in the software industry to sell mostly functional"" programming as the silver bullet for solving problems developers face with concurrency parallelism (manycore) and of course Big Data. Contemporary imperative languages could continue the ongoing trend embrace closures and try to limit mutation and other side effects. Unfortunately just as ""mostly secure"" does not work ""mostly functional"" does not work either. Instead developers should seriously consider a completely fundamentalist option as well: embrace pure lazy functional programming with all effects explicitly surfaced in the type system using monads.""";
Google's hybrid approach to research;By closely connecting research and development Google is able to conduct experiments on an unprecedented scale often resulting in new capabilities for the company.;
OCaml for the Masses: Why the next language you learn should be functional;Functional programming is an old idea with a distinguished history. Lisp a functional language inspired by Alonzo Churchâ€™s lambda calculus was one of the first programming languages developed at the dawn of the computing age. Statically typed functional languages such as OCaml and Haskell are newer but their roots go deep.;
Unikernels: Rise of the Virtual Library Operating System: What if all the software layers in a virtual appliance were compiled within the same safe high-level language framework?;Cloud computing has been pioneering the business of renting computing resources in large data centers to multiple (and possibly competing) tenants. The basic enabling technology for the cloud is operating-system virtualization such as Xen1 or VMWare which allows customers to multiplex VMs (virtual machines) on a shared cluster of physical machines. Each VM presents as a self-contained computer booting a standard operating-system kernel and running unmodified applications just as if it were executing on a physical machine.;
BBR: Congestion-Based Congestion Control: Measuring bottleneck bandwidth and round-trip propagation time;When bottleneck buffers are large loss-based congestion control keeps them full causing bufferbloat. When bottleneck buffers are small loss-based congestion control misinterprets loss as a signal of congestion leading to low throughput. Fixing these problems requires an alternative to loss-based congestion control. Finding this alternative requires an understanding of where and how network congestion originates.;
Barbarians at the Gateways: High-frequency Trading and Exchange Technology;I am a former high-frequency trader. For a few wonderful years I led a group of brilliant engineers and mathematicians and together we traded in the electronic marketplaces and pushed systems to the edge of their capability.;
Why Writing Your Own Search Engine Is Hard: Big or small proprietary or open source Web or intranet itâ€™s a tough job.;There must be 4000 programmers typing away in their basements trying to build the next â€œworldâ€™s most scalableâ€ search engine. It has been done only a few times. It has never been done by a big group always one to four people did the core work and the big team came on to build the elaborations and the production infrastructure. Why is it so hard? We are going to delve a bit into the various issues to consider when writing a search engine. This article is aimed at those individuals or small groups that are considering this endeavor for their Web site or intranet. It is fun but a word of caution: not only is it difficult but you need two commodities in short supply: time and patience.;
There is No Now: Problems with simultaneity in distributed systems;"Now. The time elapsed between when I wrote that word and when you read it was at least a couple of weeks. That kind of delay is one that we take for granted and donâ€™t even think about in written media. Now."" If we were in the same room and instead I spoke aloud you might have a greater sense of immediacy. You might intuitively feel as if you were hearing the word at exactly the same time that I spoke it. That intuition would be wrong. If instead of trusting your intuition you thought about the physics of sound you would know that time must have elapsed between my speaking and your hearing. The motion of the air carrying my word would take time to get from my mouth to your ear.""";
NUMA (Non-Uniform Memory Access): An Overview: NUMA becomes more common because memory controllers get close to execution units on microprocessors.;NUMA (non-uniform memory access) is the phenomenon that memory at various points in the address space of a processor have different performance characteristics. At current processor speeds the signal path length from the processor to memory plays a significant role. Increased signal path length not only increases latency to memory but also quickly becomes a throughput bottleneck if the signal path is shared by multiple processors. The performance differences to memory were noticeable first on large-scale systems where data paths were spanning motherboards or chassis. These systems required modified operating-system kernels with NUMA support that explicitly understood the topological properties of the systemâ€™s memory (such as the chassis in which a region of memory was located) in order to avoid excessively long signal path lengths. (Altix and UV SGIâ€™s large address space systems are examples. The designers of these products had to modify the Linux kernel to support NUMA in these machines processors in multiple chassis are linked via a proprietary interconnect called NUMALINK.);
Legal issues involved in E-commerce;The exponential growth of the Internet and online activity raise a number of new regulatory issues and legal questions.;
A new golden age for computer architecture;Innovations like domain-specific hardware enhanced security open instruction sets and agile chip development will lead the way.;
Your Mouse is a Database: Web and mobile applications are increasingly composed of asynchronous and realtime streaming services and push notifications.;"Among the hottest buzzwords in the IT industry these days is big data"" but the ""big"" is something of a misnomer: big data is not just about volume but also about velocity and variety. The volume of data ranges from a small number of items stored in the closed world of a conventional RDMS (relational database management system) to a large number of items spread out over a large cluster of machines or across the entire World Wide Web.""";
Thereâ€™s Just No Getting around It: Youâ€™re Building a Distributed System: Building a distributed system requires a methodical approach to requirements.;"Distributed systems are difficult to understand design build and operate. They introduce exponentially more variables into a design than a single machine does making the root cause of an application problem much harder to discover. It should be said that if an application does not have meaningful SLAs (service-level agreements) and can tolerate extended downtime and/or performance degradation then the barrier to entry is greatly reduced. Most modern applications however have an expectation of resiliency from their users and SLAs are typically measured by the number of nines"" (e.g. 99.9 or 99.99 percent availability per month). Each additional 9 becomes harder and harder to achieve.""";
Embedded systems in real time applications design &amp architecture;Tree boosting is a highly effective and widely used machine learning method. In this paper we describe a scalable end-to-end tree boosting system called XGBoost which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly we provide insights on cache access patterns data compression and sharding to build a scalable tree boosting system. By combining these insights XGBoost scales beyond billions of examples using far fewer resources than existing systems.;
Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;For the entire careers of most practicing computer scientists a fundamental observation has consistently held true: CPUs are significantly more performant and more expensive than I/O devices. The fact that CPUs can process data at extremely high rates while simultaneously servicing multiple I/O devices has had a sweeping impact on the design of both hardware and software for systems of all sizes for pretty much as long as weâ€™ve been building them.;
The Network is Reliable: An informal survey of real-world communications failures;"The network is reliable tops Peter Deutschâ€™s classic list Eight fallacies of distributed computing"" ""all [of which] prove to be false in the long run and all [of which] cause big trouble and painful learning experiences."" Accounting for and understanding the implications of network behavior is key to designing robust distributed programs in fact six of Deutschâ€™s ""fallacies"" directly pertain to limitations on networked communications. This should be unsurprising: the ability (and often requirement) to communicate over a shared channel is a defining characteristic of distributed programs and many of the key results in the field pertain to the possibility and impossibility of performing distributed computations under particular sets of network conditions.""";
A co-Relational Model of Data for Large Shared Data Banks: Contrary to popular belief SQL and noSQL are really just two sides of the same coin.;Fueled by their promise to solve the problem of distilling valuable information and business insight from big data in a scalable and programmer-friendly way noSQL databases have been one of the hottest topics in our field recently. With a plethora of open source and commercial offerings and a surrounding cacophony of technical terms however it is hard for businesses and practitioners to see the forest for the trees.;
Visualizing System Latency: Heat maps are a unique and powerful way to visualize latency data. Explaining the results however is an ongoing challenge.;When I/O latency is presented as a visual heat map some intriguing and beautiful patterns can emerge. These patterns provide insight into how a system is actually performing and what kinds of latency end-user applications experience. Many characteristics seen in these patterns are still not understood but so far their analysis is revealing systemic behaviors that were previously unknown.;
Apache Spark: a unified engine for big data processing;This open source computing framework unifies streaming batch and interactive big data workloads to unlock new applications.;
An overview of business intelligence technology;BI technologies are essential to running today's businesses and this technology is going through sea changes.;
The Rise and Fall of CORBA: Thereâ€™s a lot we can learn from CORBAâ€™s mistakes.;Depending on exactly when one starts counting CORBA is about 10-15 years old. During its lifetime CORBA has moved from being a bleeding-edge technology for early adopters to being a popular middleware to being a niche technology that exists in relative obscurity. It is instructive to examine why CORBAâ€”despite once being heralded as the â€œnext-generation technology for e-commerceâ€â€”suffered this fate. CORBAâ€™s history is one that the computing industry has seen many times and it seems likely that current middleware efforts specifically Web services will reenact a similar history.;
A large-scale study of programming languages and code quality in GitHub;What is the effect of programming languages on software quality? This question has been a topic of much debate for a very long time. In this study we gather a very large data set from GitHub (728 projects 63 million SLOC 29000 authors 1.5 million commits in 17 languages) in an attempt to shed some empirical light on this question. This reasonably large sample size allows us to use a mixed-methods approach combining multiple regression modeling with visualization and text analytics to study the effect of language features such as static versus dynamic typing and allowing versus disallowing type confusion on software quality. By triangulating findings from different methods and controlling for confounding effects such as team size project size and project history we report that language design does have a significant but modest effect on software quality. Most notably it does appear that disallowing type confusion is modestly better than allowing it and among functional languages static typing is also somewhat better than dynamic typing. We also find that functional languages are somewhat better than procedural languages. It is worth noting that these modest effects arising from language design are overwhelmingly dominated by the process factors such as project size team size and commit size. However we caution the reader that even these modest effects might quite possibly be due to other intangible process factors for example the preference of certain personality types for functional static languages that disallow type confusion.;
Probabilistic topic models;Surveying a suite of algorithms that offer a solution to managing large document archives.;
Anatomy of a Solid-state Drive: While the ubiquitous SSD shares many features with the hard-disk drive under the surface they are completely different.;Over the past several years a new type of storage device has entered laptops and data centers fundamentally changing expectations regarding the power size and performance dynamics of storage. The SSD (solid-state drive) is a technology that has been around for more than 30 years but remained too expensive for broad adoption.;
The Road to SDN: An intellectual history of programmable networks;Designing and managing networks has become more innovative over the past few years with the aid of SDN (software-defined networking). This technology seems to have appeared suddenly but it is actually part of a long history of trying to make computer networks more programmable.;
What DNS Is Not: DNS is many things to many people - perhaps too many things to too many people.;DNS (Domain Name System) is a hierarchical distributed autonomous reliable database. The first and only of its kind it offers realtime performance levels to a global audience with global contributors. Every TCP/IP traffic flow including every World Wide Web page view begins with at least one DNS transaction. DNS is in a word glorious.;
Nonblocking Algorithms and Scalable Multicore Programming: Exploring some alternatives to lock-based synchronization;Real-world systems with complicated quality-of-service guarantees may require a delicate balance between throughput and latency to meet operating requirements in a cost-efficient manner. The increasing availability and decreasing cost of commodity multicore and many-core systems make concurrency and parallelism increasingly necessary for meeting demanding performance requirements. Unfortunately the design and implementation of correct efficient and scalable concurrent software is often a daunting task.;
Splinternet Behind the Great Firewall of China: Once China opened its door to the world it could not close it again.;What if you could not access YouTube Facebook Twitter and Wikipedia? How would you feel if Google informed you that your connection had been reset during a search? What if Gmail was only periodically available and Google Docs which was used to compose this article was completely unreachable? What a mess!;
Bufferbloat: Dark Buffers in the Internet: Networks without effective AQM may again be vulnerable to congestion collapse.;Todayâ€™s networks are suffering from unnecessary latency and poor system performance. The culprit is bufferbloat the existence of excessively large and frequently full buffers inside the network. Large buffers have been inserted all over the Internet without sufficient thought or testing. They damage or defeat the fundamental congestion-avoidance algorithms of the Internetâ€™s most common transport protocol. Long delays from bufferbloat are frequently attributed incorrectly to network congestion and this misinterpretation of the problem leads to the wrong solutions being proposed.;
The Calculus of Service Availability: Youâ€™re only as available as the sum of your dependencies.;"Most services offered by Google aim to offer 99.99 percent (sometimes referred to as the four 9s"") availability to users. Some services contractually commit to a lower figure externally but set a 99.99 percent target internally. This more stringent target accounts for situations in which users become unhappy with service performance well before a contract violation occurs as the number one aim of an SRE team is to keep users happy. For many services a 99.99 percent internal target represents the sweet spot that balances cost complexity and availability. For some services notably global cloud services the internal target is 99.999 percent.""";
Algorithmic trading review;The competitive nature of AT the scarcity of expertise and the vast profits potential makes for a secretive community where implementation details are difficult to find.;
JavaScript and the Netflix User Interface: Conditional dependency resolution;In the two decades since its introduction JavaScript has become the de facto official language of the Web. JavaScript trumps every other language when it comes to the number of runtime environments in the wild. Nearly every consumer hardware device on the market today supports the language in some way. While this is done most commonly through the integration of a Web browser application many devices now also support Web views natively as part of the operating system UI (user interface). Across most platforms (phones tablets TVs and game consoles) the Netflix UI for example is written almost entirely in JavaScript.;
Eventual Consistency Today: Limitations Extensions and Beyond: How can applications be built on eventually consistent infrastructure given no guarantee of safety?;"In a July 2000 conference keynote Eric Brewer now VP of engineering at Google and a professor at the University of California Berkeley publicly postulated the CAP (consistency availability and partition tolerance) theorem which would change the landscape of how distributed storage systems were architected. Brewerâ€™s conjecture--based on his experiences building infrastructure for some of the first Internet search engines at Inktomi--states that distributed systems requiring always-on highly available operation cannot guarantee the illusion of coherent consistent single-system operation in the presence of network partitions which cut communication between active servers. Brewerâ€™s conjecture proved prescient: in the following decade with the continued rise of large-scale Internet services distributed-system architects frequently dropped strong"" guarantees in favor of weaker models--the most notable being eventual consistency.""";
Scratch: programming for all;"Digital fluency"" should mean designing creating and remixing not just browsing chatting and interacting.""";
CPU DB: Recording Microprocessor History: With this open database you can mine microprocessor trends over the past 40 years.;In November 1971 Intel introduced the worldâ€™s first single-chip microprocessor the Intel 4004. It had 2300 transistors ran at a clock speed of up to 740 KHz and delivered 60000 instructions per second while dissipating 0.5 watts. The following four decades witnessed exponential growth in compute power a trend that has enabled applications as diverse as climate modeling protein folding and computing real-time ballistic trajectories of angry birds. Todayâ€™s microprocessor chips employ billions of transistors include multiple processor cores on a single silicon die run at clock speeds measured in gigahertz and deliver more than 4 million times the performance of the original 4004.;
The tail at scale;Software techniques that tolerate latency variability are vital to building responsive large-scale Web services.;
Usablity Testing for the Web: Todayâ€™s sophisticated Web applications make tracking and listening to users more important than ever.;Todayâ€™s Internet user has more choices than ever before with many competing sites offering similar services. This proliferation of options provides ample opportunity for users to explore different sites and find out which one best suits their needs for any particular service. Users are further served by the latest generation of Web technologies and services commonly dubbed Web 2.0 which enables a better more personalized user experience and encourages user-generated content. Although there is considerable debate over the definition of Web 2.0 the term is useful in distinguishing key innovations such as weblogs social bookmarking tagging wikis RSS feeds Ajax Web APIs and online Web services that have significantly altered the Web user experience since the 1990s.;
MapReduce: a flexible data processing tool;MapReduce advantages over parallel databases include storage-system independence and fine-grain fault tolerance for large jobs.;
The Responsive Enterprise: Embracing the Hacker Way: Soon every company will be a software company.;As of July 2014 Facebook founded in 2004 is in the top 20 of the most valuable companies in the S&ampP 500 putting the 10-year-old software company in the same league as IBM Oracle and Coca-Cola. Of the top five fastest-growing companies with regard to market capitalization in 2014 (table 1) three are software companies: Apple Google and Microsoft (in fact one could argue that Intel is also driven by software making it four out of five).;
The Debugging Mindset: Understanding the psychology of learning strategies leads to effective problem-solving skills.;Software developers spend 35-50 percent of their time validating and debugging software. The cost of debugging testing and verification is estimated to account for 50-75 percent of the total budget of software development projects amounting to more than $100 billion annually. While tools languages and environments have reduced the time spent on individual debugging tasks they have not significantly reduced the total time spent debugging nor the cost of doing so. Therefore a hyperfocus on elimination of bugs during development is counterproductive programmers should instead embrace debugging as an exercise in problem solving.;
Disks from the Perspective of a File System: Disks lie. And the controllers that run them are partners in crime.;Most applications do not deal with disks directly instead storing their data in files in a file system which protects us from those scoundrel disks. After all a key task of the file system is to ensure that the file system can always be recovered to a consistent state after an unplanned system crash (for example a power failure). While a good file system will be able to beat the disks into submission the required effort can be great and the reduced performance annoying. This article examines the shortcuts that disks take and the hoops that file systems must jump through to get the desired reliability.;
The future of microprocessors;Energy efficiency is the new fundamental limiter of processor performance way beyond numbers of processors.;
Rate-limiting State: The edge of the Internet is an unruly place;"By design the Internet core is dumb and the edge is smart. This design decision has enabled the Internetâ€™s wildcat growth since without complexity the core can grow at the speed of demand. On the downside the decision to put all smartness at the edge means weâ€™re at the mercy of scale when it comes to the quality of the Internetâ€™s aggregate traffic load. Not all device and software builders have the skills and the quality assurance budgets that something the size of the Internet deserves. Furthermore the resiliency of the Internet means that a device or program that gets something importantly wrong about Internet communication stands a pretty good chance of working well enough"" in spite of this.""";
Creating Languages in Racket: Sometimes you just have to make a better mousetrap.;Choosing the right tool for a simple job is easy: a screwdriver is usually the best option when you need to change the battery in a toy and grep is the obvious choice to check for a word in a text document. For more complex tasks the choice of tool is rarely so straightforward--all the more so for a programming task where programmers have an unparalleled ability to construct their own tools. Programmers frequently solve programming problems by creating new tool programs such as scripts that generate source code from tables of data.;
FPGA Programming for the Masses: The programmability of FPGAs must improve if they are to be part of mainstream computing.;When looking at how hardware influences computing performance we have GPPs (general-purpose processors) on one end of the spectrum and ASICs (application-specific integrated circuits) on the other. Processors are highly programmable but often inefficient in terms of power and performance. ASICs implement a dedicated and fixed function and provide the best power and performance characteristics but any functional change requires a complete (and extremely expensive) re-spinning of the circuits.;
Generative adversarial networks;Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.;
Fail at Scale: Reliability in the face of rapid change;"Failure is part of engineering any large-scale system. One of Facebookâ€™s cultural values is embracing failure. This can be seen in the posters hung around the walls of our Menlo Park headquarters: What Would You Do If You Werenâ€™t Afraid?"" and ""Fortune Favors the Bold.""""";
Data science and prediction;Big data promises automated actionable knowledge creation and predictive models for use by both humans and computers.;
Hidden in Plain Sight: Improvements in the observability of software can help you diagnose your most crippling performance problems.;In December 1997 Sun Microsystems had just announced its new flagship machine: a 64-processor symmetric multiprocessor supporting up to 64 gigabytes of memory and thousands of I/O devices. As with any new machine launch Sun was working feverishly on benchmarks to prove the machineâ€™s performance. While the benchmarks were generally impressive there was one in particular that was exhibiting unexpectedly low performance. The benchmark machine would occasionally become mysteriously distracted: Benchmark activity would practically cease but the operating system kernel remained furiously busy. After some number of minutes spent on unknown work the operating system would suddenly right itself: Benchmark activity would resume at full throttle and run to completion. Those running the benchmark could see that the machine was on course to break the world record but these minutes-long periods of unknown kernel activity were enough to be the difference between first and worst.;
The Web Wonâ€™t Be Safe or Secure until We Break It: Unless youâ€™ve taken very particular precautions assume every Web site you visit knows exactly who you are.;The Internet was designed to deliver information but few people envisioned the vast amounts of information that would be involved or the personal nature of that information. Similarly few could have foreseen the potential flaws in the design of the Internet that would expose this personal information compromising the data of individuals and companies.;
The Flame Graph: This visualization of software execution is a new necessity for performance profiling and debugging.;An everyday problem in our industry is understanding how software is consuming resources particularly CPUs. What exactly is consuming how much and how did this change since the last software version? These questions can be answered using software profilers tools that help direct developers to optimize their code and operators to tune their environment. The output of profilers can be verbose however making it laborious to study and comprehend. The flame graph provides a new visualization for profiler output and can make for much faster comprehension reducing the time for root cause analysis.;
An interview with Edsger W. Dijkstra;The computer science luminary in one of his last interviews before his death in 2002 reflects on a programmer's life.;
A File System All Its Own: Flash memory has come a long way. Now itâ€™s time for software to catch up.;In the past five years flash memory has progressed from a promising accelerator whose place in the data center was still uncertain to an established enterprise component for storing performance-critical data. Itâ€™s rise to prominence followed its proliferation in the consumer world and the volume economics that followed (see figure 1). With SSDs (solid-state devices) flash arrived in a form optimized for compatibility - just replace a hard drive with an SSD for radically better performance. But the properties of the NAND flash memory used by SSDs differ significantly from those of the magnetic media in the hard drives they often displace. While SSDs have become more pervasive in a variety of uses the industry has only just started to design storage systems that embrace the nuances of flash memory. As it escapes the confines of compatibility significant improvements in performance reliability and cost are possible.;
The Antifragile Organization: Embracing Failure to Improve Resilience and Maximize Availability;Failure is inevitable. Disks fail. Software bugs lie dormant waiting for just the right conditions to bite. People make mistakes. Data centers are built on farms of unreliable commodity hardware. If youâ€™re running in a cloud environment then many of these factors are outside of your control. To compound the problem failure is not predictable and doesnâ€™t occur with uniform probability and frequency. The lack of a uniform frequency increases uncertainty and risk in the system. In the face of such inevitable and unpredictable failure how can you build a reliable service that provides the high level of availability your users can depend on?;
Mars code;Redundant software (and hardware) ensured Curiosity reached its destination and functioned as its designers intended.;
Passing a Language through the Eye of a Needle: How the embeddability of Lua impacted its design;Scripting languages are an important element in the current landscape of programming languages. A key feature of a scripting language is its ability to integrate with a system language. This integration takes two main forms: extending and embedding. In the first form you extend the scripting language with libraries and functions written in the system language and write your main program in the scripting language. In the second form you embed the scripting language in a host program (written in the system language) so that the host can run scripts and call functions defined in the scripts the main program is the host program. In this setting the system language is usually called the host language.;
Containers Will Not Fix Your Broken Culture (and Other Hard Truths): Complex socio-technical systems are hard film at 11.;We focus so often on technical anti-patterns neglecting similar problems inside our social structures. Spoiler alert: the solutions to many difficulties that seem technical can be found by examining our interactions with others. Letâ€™s talk about five things youâ€™ll want to know when working with those pesky creatures known as humans.;
A tour through the visualization zoo;A survey of powerful visualization techniques from the obvious to the obscure.;
Making Sense of Revision-control Systems: Whether distributed or centralized all revision-control systems come with complicated sets of tradeoffs. How do you find the best match between tool and team?;Modern software is tremendously complicated and the methods that teams use to manage its development reflect this complexity. Though many organizations use revision-control software to track and manage the complexity of a project as it evolves the topic of how to make an informed choice of revision-control tools has received scant attention. Until fairly recently the world of revision control was moribund so there was simply not much to say on this subject.;
Algorithmic composition: computational thinking in music;The composer still composes but also gets to take a programming-enabled journey of musical discovery.;
Coding Guidelines: Finding the Art in the Science: What separates good code from great code?;Computer science is both a science and an art. Its scientific aspects range from the theory of computation and algorithmic studies to code design and program architecture. Yet when it comes time for implementation there is a combination of artistic flare nuanced style and technical prowess that separates good code from great code.;
A look at the design of Lua;Simplicity small size portability and embeddability set Lua apart from other scripting languages.;
Social Bookmarking in the Enterprise: Can your organization benefit from social bookmarking tools?;One of the greatest challenges facing people who use large information spaces is to remember and retrieve items that they have previously found and thought to be interesting. One approach to this problem is to allow individuals to save particular search strings to re-create the search in the future. Another approach has been to allow people to create personal collections of material. Collections of citations can be created manually by readers or through execution of (and alerting to) a saved search.;
Computing technologies for reflective creative care of people with dementia;Mobile apps manage data on individual residents to help carers deliver more person-centered care.;
You don't know jack about software maintenance;Long considered an afterthought software maintenance is easiest and most effective when built into a system from the ground up.;
Optimizations in C++ Compilers: A practical journey;Thereâ€™s a tradeoff to be made in giving the compiler more information: it can make compilation slower. Technologies such as link time optimization can give you the best of both worlds. Optimizations in compilers continue to improve and upcoming improvements in indirect calls and virtual function dispatch might soon lead to even faster polymorphism.;
A New Software Engineering: What happened to the promise of rigorous disciplined professional practices for software development?;"What happened to software engineering? What happened to the promise of rigorous disciplined professional practices for software development like those observed in other engineering disciplines? What has been adopted under the rubric of software engineering"" is a set of practices largely adapted from other engineering disciplines: project management design and blueprinting process control and so forth. The basic analogy was to treat software as a manufactured product with all the real ""engineering"" going on upstream of that - in requirements analysis design modeling etc.""";
Cloud Computing: An Overview: A summary of important cloud-computing issues distilled from ACM CTO Roundtables;Probably more than anything weâ€™ve seen in IT since the invention of timesharing or the introduction of the PC cloud computing represents a paradigm shift in the delivery architecture of information services. This overview presents some of the key topics discussed during the ACM Cloud Computing and Virtualization CTO Roundtables of 2008. While not intended to replace the in-depth roundtable discussions the overview summarizes the fundamental issues generally agreed upon by the panels and should help readers to assess the applicability of cloud computing to their application areas.;
Who Must You Trust? You must have some trust if you want to get anything done.;In his novel The Diamond Age author Neal Stephenson describes a constructed society (called a phyle) based on extreme trust in oneâ€™s fellow members. Part of the membership requirements is that from time to time each member is called upon to undertake certain tasks to reinforce that trust. For example a phyle member might be told to go to a particular location at the top of a cliff at a specific time where he will find bungee cords with ankle harnesses attached. The other ends of the cords trail off into the bushes. At the appointed time he is to fasten the harnesses to his ankles and jump off the cliff. He has to trust that the unseen fellow phyle member who was assigned the job of securing the other end of the bungee to a stout tree actually did his job otherwise he will plummet to his death. A third member secretly watches to make sure the first two donâ€™t communicate in any way relying only on trust to keep tragedy at bay. Whom you trust what you trust them with and how much you trust them are at the center of the Internet today as well as every other aspect of your technological life.;
Eventually Consistent: Building reliable distributed systems at a worldwide scale demands trade-offs?between consistency and availability.;At the foundation of Amazonâ€™s cloud computing are infrastructure services such as Amazonâ€™s S3 (Simple Storage Service) SimpleDB and EC2 (Elastic Compute Cloud) that provide the resources for constructing Internet-scale computing platforms and a great variety of applications. The requirements placed on these infrastructure services are very strict they need to score high marks in the areas of security scalability availability performance and cost effectiveness and they need to meet these requirements while serving millions of customers around the globe continuously.;
Thinking Methodically about Performance: The USE method addresses shortcomings in other commonly used methodologies.;Performance issues can be complex and mysterious providing little or no clue to their origin. In the absence of a starting point performance issues are often analyzed randomly: guessing where the problem may be and then changing things until it goes away. While this can deliver results it can also be time-consuming disruptive and may ultimately overlook certain issues. This article describes system-performance issues and the methodologies in use today for analyzing them and it proposes a new methodology for approaching and solving a class of issues.;
Revisiting Network I/O APIs: The netmap Framework: It is possible to achieve huge performance improvements in the way packet processing is done on modern operating systems.;Today 10-gigabit interfaces are used more and more in datacenters and servers. On these links packets flow as fast as one every 67.2 nanoseconds yet modern operating systems can take 10-20 times longer just to move one packet between the wire and the application. We can do much better not with more powerful hardware but by revising architectural decisions made long ago regarding the design of device drivers and network stacks.;
Trends in steganography;Methods for embedding secret data are more sophisticated than their ancient predecessors but the basic principles remain unchanged.;
Mobile application development: web vs. native;Web apps are cheaper to develop and deploy than native apps but can they match the native user experience?;
The Essence of Software Engineering: The SEMAT Kernel: A thinking framework in the form of an actionable kernel;Everyone who develops software knows that it is a complex and risky business and its participants are always on the lookout for new ideas that will lead to better software. Fortunately software engineering is still a young and growing profession that sees innovations and improvements in best practices every year. Just look for example at the improvements and benefits that lean and agile thinking have brought to software-development teams.;
Thinking Clearly about Performance: Improving the performance of complex software is difficult but understanding some fundamental principles can make it easier.;"When I joined Oracle Corporation in 1989 performance was difficult. Only a few people claimed they could do it very well and those people commanded high consulting rates. When circumstances thrust me into the Oracle tuning"" arena I was quite unprepared. Recently Iâ€™ve been introduced to the world of ""MySQL tuning"" and the situation seems very similar to what I saw in Oracle more than 20 years ago.""";
Bufferbloat: dark buffers in the internet;Networks without effective AQM may again be vulnerable to congestion collapse.;
The Go programming language and environment;Released as open source in November 2009 Go has become the foundation for critical infrastructure at every major cloud provider. Its creators look back on how Go got here and why it has stuck around.;
Death by UML Fever: Self-diagnosis and early treatment are crucial in the fight against UML Fever.;A potentially deadly illness clinically referred to as UML (Unified Modeling Language) fever is plaguing many software-engineering efforts today. This fever has many different strains that vary in levels of lethality and contagion. A number of these strains are symptomatically related however. Rigorous laboratory analysis has revealed that each is unique in origin and makeup. A particularly insidious characteristic of UML fever common to most of its assorted strains is the difficulty individuals and organizations have in self-diagnosing the affliction. A consequence is that many cases of the fever go untreated and often evolve into more complex and lethal strains.;
Scalable Parallel Programming with CUDA: Is CUDA the parallel programming model that application developers have been waiting for?;The advent of multicore CPUs and manycore GPUs means that mainstream processor chips are now parallel systems. Furthermore their parallelism continues to scale with Mooreâ€™s law. The challenge is to develop mainstream application software that transparently scales its parallelism to leverage the increasing number of processor cores much as 3D graphics applications transparently scale their parallelism to manycore GPUs with widely varying numbers of cores.;
Scaling static analyses at Facebook;Key lessons for designing static analyses tools deployed to find bugs in hundreds of millions of lines of code.;
Real-World Concurrency: In this look at how concurrency affects practitioners in the real world Cantrill and Bonwick argue that much of the anxiety over concurrency is unwarranted.;Software practitioners today could be forgiven if recent microprocessor developments have given them some trepidation about the future of software. While Mooreâ€™s law continues to hold (that is transistor density continues to double roughly every 18 months) as a result of both intractable physical limitations and practical engineering considerations that increasing density is no longer being spent on boosting clock rate. Instead it is being used to put multiple CPU cores on a single CPU die. From the software perspective this is not a revolutionary shift but rather an evolutionary one: multicore CPUs are not the birthing of a new paradigm but rather the progression of an old one (multiprocessing) into more widespread deployment.;
Game Development: Harder Than You Think: Ten or twenty years ago it was all fun and games. Now itâ€™s blood sweat and code.;The hardest part of making a game has always been the engineering. In times past game engineering was mainly about low-level optimizationâ€”writing code that would run quickly on the target computer leveraging clever little tricks whenever possible. But in the past ten years games have ballooned in complexity. Now the primary technical challenge is simply getting the code to work to produce an end result that bears some semblance to the desired functionality. To the extent that we optimize we are usually concerned with high-level algorithmic choices. Thereâ€™s such a wide variety of algorithms to know about so much experience required to implement them in a useful way and so much work overall that just needs to be done that we have a perpetual shortage of qualified people in the industry.;
The five-minute rule 20 years later (and how flash memory changes the rules);Revisiting Gray and Putzolu's famous rule in the age of Flash.;
Design principles for visual communication;How to identify instantiate and evaluate domain-specific design principles for creating more effective visualizations.;
Crowdsourcing systems on the World-Wide Web;The practice of crowdsourcing is transforming the Web and giving rise to a new field.;
Cognitive computing;Unite neuroscience supercomputing and nanotechnology to discover demonstrate and deliver the brain's core algorithms.;
Statistics for Engineers: Applying statistical techniques to operations data;Modern IT systems collect an increasing wealth of data from network gear operating systems applications and other components. This data needs to be analyzed to derive vital information about the user experience and business performance. For instance faults need to be detected service quality needs to be measured and resource usage of the next days and month needs to be forecast.;
MapReduce: simplified data processing on large clusters;MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines handles machine failures and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day processing a total of more than twenty petabytes of data per day.;
Seven principles for selecting software packages;Everything you always wanted to know but were afraid to ask about the decision-making process.;
How Amazon web services uses formal methods;Engineers use TLA+ to prevent serious but subtle bugs from reaching production.;
The NSA and Snowden: securing the all-seeing eye;How good security at the NSA could have stopped him.;
The data on diversity;It's not just about being fair.;
Evolution of the Product Manager: Better education needed to develop the discipline;Software practitioners know that product management is a key piece of software development. Product managers talk to users to help figure out what to build define requirements and write functional specifications. They work closely with engineers throughout the process of building software. They serve as a sounding board for ideas help balance the schedule when technical challenges occur - and push back to executive teams when technical revisions are needed. Product managers are involved from before the first code is written until after it goes out the door.;
The Seven Deadly Sins of Linux Security: Avoid these common security risks like the devil.;The problem with security advice is that there is too much of it and that those responsible for security certainly have too little time to implement all of it. The challenge is to determine what the biggest risks are and to worry about those first and about others as time permits. Presented here are the seven common problems - the seven deadly sins of security - most likely to allow major damage to occur to your system or bank account. If any of these are a problem on any of your systems you will want to take care of them immediately.;
Discrimination in Online Ad Delivery: Google ads black names and white names racial discrimination and click advertising;Do online ads suggestive of arrest records appear more often with searches of black-sounding names than white-sounding names? What is a black-sounding name or white-sounding name anyway? How many more times would an ad have to appear adversely affecting one racial group for it to be considered discrimination? Is online activity so ubiquitous that computer scientists have to think about societal consequences such as structural racism in technology design? If so how is this technology to be built? Letâ€™s take a scientific dive into online ad delivery to find answers.;
The one-second war;Finding a lasting solution to the leap seconds problem has become increasingly urgent.;
Why Logical Clocks are Easy: Sometimes all you need is the right language.;Any computing system can be described as executing sequences of actions with an action being any relevant change in the state of the system. For example reading a file to memory modifying the contents of the file in memory or writing the new contents to the file are relevant actions for a text editor. In a distributed system actions execute in multiple locations in this context actions are often called events. Examples of events in distributed systems include sending or receiving messages or changing some state in a node. Not all events are related but some events can cause and influence how other later events occur. For example a reply to a received mail message is influenced by that message and maybe by prior messages received.;
Attack of the killer microseconds;Microsecond-scale I/O means tension between performance and productivity that will need new latency-mitigating ideas including in hardware.;
Why SRE Documents Matter: How documentation enables SRE teams to manage new and existing services;SRE (site reliability engineering) is a job function a mindset and a set of engineering approaches for making web products and services run reliably. SREs operate at the intersection of software development and systems engineering to solve operational problems and engineer solutions to design build and run large-scale distributed systems scalably reliably and efficiently. A mature SRE team likely has well-defined bodies of documentation associated with many SRE functions. If you manage an SRE team or intend to start one this article will help you understand the types of documents your team needs to write and why each type is needed allowing you to plan for and prioritize documentation work along with other team projects.;
The Long Road to 64 Bits: Double double toil and trouble;Shakespeareâ€™s words often cover circumstances beyond his wildest dreams. Toil and trouble accompany major computing transitions even when people plan ahead. To calibrate â€œtomorrowâ€™s legacy todayâ€ we should study â€œtomorrowâ€™s legacy yesterday.â€ Much of tomorrowâ€™s software will still be driven by decades-old decisions. Past decisions have unanticipated side effects that last decades and can be difficult to undo.;
The Case Against Data Lock-in: Want to keep your users? Just make it easy for them to leave.;Engineers employ many different tactics to focus on the user when writing software: for example listening to user feedback fixing bugs and adding features that their users are clamoring for. Since Web-based services have made it easier for users to move to new applications itâ€™s becoming even more important to focus on building and retaining user trust. Weâ€™ve found that an incredibly effective way to earn and maintain user trust is to make it easy for users to leave your product with their data in tow. This not only prevents lock-in and engenders trust but also forces your team to innovate and compete on technical merit. We call this data liberation.;
Security and privacy for augmented reality systems;AR systems pose potential security concerns that should be addressed before the systems become widespread.;
Passively Measuring TCP Round-trip Times: A close look at RTT measurements with TCP;Measuring and monitoring network RTT (round-trip time) is important for multiple reasons: it allows network operators and end users to understand their network performance and help optimize their environment and it helps businesses understand the responsiveness of their services to sections of their user base.;
A co-relational model of data for large shared data banks;Contrary to popular belief SQL and noSQL are really just two sides of the same coin.;
Software and the Concurrency Revolution: Leveraging the full power of multicore processors demands new tools and new  thinking from the software industry.;"Concurrency has long been touted as the next big thing"" and ""the way of the future"" but for the past 30 years mainstream software development has been able to ignore it. Our parallel future has finally arrived: new machines will be parallel machines and this will require major changes in the way we develop software. The introductory article in this issue describes the hardware imperatives behind this shift in computer architecture from uniprocessors to multicore processors also known as CMPs.""";
Finding More Than One Worm in the Apple: If you see something say something.;In February Apple revealed and fixed an SSL (Secure Sockets Layer) vulnerability that had gone undiscovered since the release of iOS 6.0 in September 2012. It left users vulnerable to man-in-the-middle attacks thanks to a short circuit in the SSL/TLS (Transport Layer Security) handshake algorithm introduced by the duplication of a goto statement. Since the discovery of this very serious bug many people have written about potential causes. A close inspection of the code however reveals not only how a unit test could have been written to catch the bug but also how to refactor the existing code to make the algorithm testable - as well as more clues to the nature of the error and the environment that produced it.;
The NSA and Snowden: Securing the All-Seeing Eye: How good security at the NSA could have stopped him;Edward Snowden while an NSA (National Security Agency) contractor at Booz Allen Hamilton in Hawaii copied up to 1.7 million top-secret and above documents smuggling copies on a thumb drive out of the secure facility in which he worked and later released many to the press. This has altered the relationship of the U.S. government with the American people as well as with other countries. This article examines the computer security aspects of how the NSA could have prevented this perhaps the most damaging breach of secrets in U.S. history. The accompanying sidebar looks at the Constitutional legal and moral issues.;
Anomaly detection: A survey;Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category we provide a basic anomaly detection technique and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further for each category we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic and how techniques developed in one area can be applied in domains for which they were not intended to begin with.;
Testing a Distributed System: Testing a distributed system can be trying even under the best of circumstances.;Distributed systems can be especially difficult to program for a variety of reasons. They can be difficult to design difficult to manage and above all difficult to test. Testing a normal system can be trying even under the best of circumstances and no matter how diligent the tester is bugs can still get through. Now take all of the standard issues and multiply them by multiple processes written in multiple languages running on multiple boxes that could potentially all be on different operating systems and there is potential for a real disaster.;
Online Event Processing: Achieving consistency where distributed transactions have failed;Support for distributed transactions across heterogeneous storage technologies is either nonexistent or suffers from poor operational and performance characteristics. In contrast OLEP is increasingly used to provide good performance and strong consistency guarantees in such settings. In data systems it is very common for logs to be used as internal implementation details. The OLEP approach is different: it uses event logs rather than transactions as the primary application programming model for data management. Traditional databases are still used but their writes come from a log rather than directly from the application. The use of OLEP is not simply pragmatism on the part of developers but rather it offers a number of advantages. Consequently OLEP is expected to be increasingly used to provide strong consistency in large-scale systems that use heterogeneous storage technologies.;
Fault Injection in Production: Making the case for resilience testing;When we build Web infrastructures at Etsy we aim to make them resilient. This means designing them carefully so that they can sustain their (increasingly critical) operations in the face of failure. Thankfully there have been a couple of decades and reams of paper spent on researching how fault tolerance and graceful degradation can be brought to computer systems. That helps the cause.;
A Decade of OS Access-control Extensibility: Open source security foundations for mobile and embedded devices;To discuss operating system security is to marvel at the diversity of deployed access-control models: Unix and Windows NT multiuser security Type Enforcement in SELinux anti-malware products app sandboxing in Apple OS X Apple iOS and Google Android and application-facing systems such as Capsicum in FreeBSD. This diversity is the result of a stunning transition from the narrow 1990s Unix and NT status quo to â€™security localizationâ€™ - the adaptation of operating-system security models to site-local or product-specific requirements.;
Mobile Application Development: Web vs. Native: Web apps are cheaper to develop and deploy than native apps but can they match the native user experience?;"A few short years ago most mobile devices were for want of a better word dumb."" Sure there were some early smartphones but they were either entirely e-mail focused or lacked sophisticated touch screens that could be used without a stylus. Even fewer shipped with a decent mobile browser capable of displaying anything more than simple text links and maybe an image. This meant if you had one of these devices you were either a businessperson addicted to e-mail or an alpha geek hoping that this would be the year of the smartphone. Then Apple changed everything with the release of the iPhone and our expectations for mobile experiences were completely reset.""";
Disambiguating Databases: Use the database built for your access model.;The topic of data storage is one that doesnâ€™t need to be well understood until something goes wrong (data disappears) or something goes really right (too many customers). Because databases can be treated as black boxes with an API their inner workings are often overlooked. Theyâ€™re often treated as magic things that just take data when offered and supply it when asked. Since these two operations are the only understood activities of the technology they are often the only features presented when comparing different technologies.;
Dark Patterns: Past Present and Future: The evolution of tricky user interfaces;Dark patterns are an abuse of the tremendous power that designers hold in their hands. As public awareness of dark patterns grows so does the potential fallout. Journalists and academics have been scrutinizing dark patterns and the backlash from these exposures can destroy brand reputations and bring companies under the lenses of regulators. Design is power. In the past decade software engineers have had to confront the fact that the power they hold comes with responsibilities to users and to society. In this decade it is time for designers to learn this lesson as well.;
Thereâ€™s No Such Thing as a General-purpose Processor: And the belief in such a device is harmful;"There is an increasing trend in computer architecture to categorize processors and accelerators as general purpose."" Of the papers published at this yearâ€™s International Symposium on Computer Architecture (ISCA 2014) nine out of 45 explicitly referred to general-purpose processors one additionally referred to general-purpose FPGAs (field-programmable gate arrays) and another referred to general-purpose MIMD (multiple instruction multiple data) supercomputers stretching the definition to the breaking point. This article presents the argument that there is no such thing as a truly general-purpose processor and that the belief in such a device is harmful.""";
A Guided Tour through Data-center Networking: A good user experience depends on predictable performance within the data-center network.;"The magic of the cloud is that it is always on and always available from anywhere. Users have come to expect that services are there when they need them. A data center (or warehouse-scale computer) is the nexus from which all the services flow. It is often housed in a nondescript warehouse-sized building bearing no indication of what lies inside. Amidst the whirring fans and refrigerator-sized computer racks is a tapestry of electrical cables and fiber optics weaving everything together -- the data-center network. This article provides a guided tour"" through the principles and central ideas surrounding the network at the heart of a data center -- the modern-day loom that weaves the digital fabric of the Internet.""";
Browser Security: Lessons from Google Chrome: Google Chrome developers focused on three key problems to shield the browser from attacks.;The Web has become one of the primary ways people interact with their computers connecting people with a diverse landscape of content services and applications. Users can find new and interesting content on the Web easily but this presents a security challenge: malicious Web-site operators can attack users through their Web browsers. Browsers face the challenge of keeping their users safe while providing a rich platform for Web applications.;
"From game design elements to gamefulness: defining gamification""""";"Recent years have seen a rapid proliferation of mass-market consumer software that takes inspiration from video games. Usually summarized as gamification"" this trend connects to a sizeable body of existing concepts and research in human-computer interaction and game studies such as serious games pervasive games alternate reality games or playful design. However it is not clear how ""gamification"" relates to these whether it denotes a novel phenomenon and how to define it. Thus in this paper we investigate ""gamification"" and the historical origins of the term in relation to precursors and similar concepts. It is suggested that ""gamified"" applications provide insight into novel gameful phenomena complementary to playful phenomena. Based on our research we propose a definition of ""gamification"" as the use of game design elements in non-game contexts.""";
Proceedings of the 15th International Academic MindTrek Conference: Envisioning Future Media Environments;We believe our approach has enabled Netflix to quickly adopt and benefit from containers. Though the details may be Netflix-specific the approach of providing low-friction container adoption by integrating with existing infrastructure and working with the right early adopters can be a successful strategy for any organization looking to adopt containers.;
Reliable Cron across the Planet: ...or How I stopped worrying and learned to love time;This article describes Googleâ€™s implementation of a distributed Cron service serving the vast majority of internal teams that need periodic scheduling of compute jobs. During its existence we have learned many lessons on how to design and implement what might seem like a basic service. Here we discuss the problems that distributed Crons face and outline some potential solutions.;
Idempotence Is Not a Medical Condition: An essential property for reliable systems;The definition of distributed computing can be confusing. Sometimes it refers to a tightly coupled cluster of computers working together to look like one larger computer. More often however it refers to a bunch of loosely related applications chattering together without a lot of system-level support. This lack of support in distributed computing environments makes it difficult to write applications that work together. Messages sent between systems do not have crisp guarantees for delivery. They can get lost and so after a timeout they are retried. The application on the other side of the communication may see multiple messages arrive where one was intended. These messages may be reordered and interleaved with different messages. Ensuring that the application behaves as intended can be very hard to design and implement. It is even harder to test.;
Memory models: a case for rethinking parallel languages and hardware;Solving the memory model problem will require an ambitious and cross-disciplinary research direction.;
Oops! Coping with Human Error in IT Systems: Errors Happen. How to Deal.;Human operator error is one of the most insidious sources of failure and data loss in todayâ€™s IT environments. In early 2001 Microsoft suffered a nearly 24-hour outage in its Web properties as a result of a human error made while configuring a name resolution system. Later that year an hour of trading on the Nasdaq stock exchange was disrupted because of a technicians mistake while testing a development system. More recently human error has been blamed for outages in instant messaging networks for security and privacy breaches and for banking system failures.;
BBR: congestion-based congestion control;Measuring bottleneck bandwidth and round-trip propagation time.;
Domain-specific Languages and Code Synthesis Using Haskell: Looking at embedded DSLs;There are many ways to give instructions to a computer: an electrical engineer might write a MATLAB program a database administrator might write an SQL script a hardware engineer might write in Verilog and an accountant might write a spreadsheet with embedded formulas. Aside from the difference in language used in each of these examples there is an important difference in form and idiom. Each uses a language customized to the job at hand and each builds computational requests in a form both familiar and productive for programmers (although accountants may not think of themselves as programmers). In short each of these examples uses a DSL (domain-specific language).;
Computing without Processors: Heterogeneous systems allow us to target our programming to the appropriate environment.;From the programmerâ€™s perspective the distinction between hardware and software is being blurred. As programmers struggle to meet the performance requirements of todayâ€™s systems they will face an ever increasing need to exploit alternative computing elements such as GPUs (graphics processing units) which are graphics cards subverted for data-parallel computing and FPGAs (field-programmable gate arrays) or soft hardware.;
API design matters;Bad application programming interfaces plague software engineering. How do we get things right?;
Mobile Devices in the Enterprise: CTO Roundtable Overview: An overview of the key points discussed in the ACM Roundtable on Mobile Devices in the Enterprise;The CTO Roundtable on Mobile Devices in the Enterprise focuses on the implications of the widespread use of mobile devices such as smartphones in the enterprise computing environment. These new personal devices have presented great challenges and opportunities for the protection of valuable information assets and creation of business value. What follows are the key points from that broader conversation.;
You Donâ€™t Know Jack about Shared Variables or Memory Models: Data races are evil.;"A Google search for Threads are evil"" generates 18000 hits but threads are ubiquitous. Almost all of the processes running on a modern Windows PC use them. Software threads are typically how programmers get machines with multiple cores to work together to solve problems faster. And often they are what allow user interfaces to remain responsive while the application performs a background calculation.""";
The Ideal HPC Programming Language: Maybe itâ€™s Fortran. Or maybe it just doesnâ€™t matter.;The DARPA HPCS program sought a tenfold productivity improvement in trans-petaflop systems for HPC. This article describes programmability studies undertaken by Sun Microsystems in its HPCS participation. These studies were distinct from Sunâ€™s ongoing development of a new HPC programming language (Fortress) and the companyâ€™s broader HPCS productivity studies though there was certainly overlap with both activities.;
Creating languages in Racket;Sometimes you just have to make a better mousetrap.;
How Fast is Your Web Site? Web site performance data has never been more readily available.;The overwhelming evidence indicates that a Web siteâ€™s performance (speed) correlates directly to its success across industries and business metrics. With such a clear correlation (and even proven causation) it is important to monitor how your Web site performs. So how fast is your Web site?;
Performance Anti-Patterns: Want your apps to run faster? Hereâ€™s what not to do.;Performance pathologies can be found in almost any software from user to kernel applications drivers etc. At Sun weâ€™ve spent the last several years applying state-of-the-art tools to a Unix kernel system libraries and user applications and have found that many apparently disparate performance problems in fact have the same underlying causes. Since software patterns are considered abstractions of positive experience we can talk about the various approaches that led to these performance problems as anti-patterns: something to be avoided rather than emulated.;
Lessons from building static analysis tools at Google;For a static analysis project to succeed developers must feel they benefit from and enjoy using it.;
Surviving Software Dependencies: Software reuse is finally here but comes with risks.;Software reuse is finally here and its benefits should not be understated but weâ€™ve accepted this transformation without completely thinking through the potential consequences. The Copay and Equifax attacks are clear warnings of real problems in the way software dependencies are consumed today. Thereâ€™s a lot of good software out there. Letâ€™s work together to find out how to reuse it safely.;
Realtime GPU Audio: Finite difference-based sound synthesis using graphics processors;Todayâ€™s CPUs are capable of supporting realtime audio for many popular applications but some compute-intensive audio applications require hardware acceleration. This article looks at some realtime sound-synthesis applications and shares the authorsâ€™ experiences implementing them on GPUs (graphics processing units).;
ACM CTO Roundtable on Mobile Devices in the Enterprise: Finding solutions as growth and fragmentation complicate mobile device support;BlackBerry? iPhone? Android? Other? Thin client or fat client? Browser or Wi-Fi? Developers of mobile applications have many variables to consider in a rapidly changing environment. The mobile device market is growing quickly and fragmenting as it does so. Supporting mobile devices in the enterprise is getting much more complicated because of both this rapid growth worldwide and the diverse set of devices and networks.;
MapReduce and parallel DBMSs: friends or foes?;MapReduce complements DBMSs since databases are not designed for extract-transform-load tasks a MapReduce specialty.;
The Rise of Fully Homomorphic Encryption: Often called the Holy Grail of cryptography commercial FHE is near.;Once commercial FHE is achieved data access will become completely separated from unrestricted data processing and provably secure storage and computation on untrusted platforms will become both relatively inexpensive and widely accessible. In ways similar to the impact of the database cloud computing PKE and AI FHE will invoke a sea change in how confidential information is protected processed and shared and will fundamentally change the course of computing at a foundational level.;
The Future of WLAN: Overcoming the Top Ten Challenges in wireless networking--will it allow wide-area mesh networks to become ubiquitous?;Since James Clerk Maxwell first mathematically described electromagnetic waves almost a century and a half ago the world has seen steady progress toward using them in better and more varied ways. Voice has been the killer application for wireless for the past century. As performance in all areas of engineering has improved wireless voice has migrated from a mass broadcast medium to a peer-to-peer medium. The ability to talk to anyone on the planet from anywhere on the planet has fundamentally altered the way society works and the speed with which it changes.;
The Challenge of Cross-language Interoperability: Interfacing between languages is increasingly important.;Interoperability between languages has been a problem since the second programming language was invented. Solutions have ranged from language-independent object models such as COM (Component Object Model) and CORBA (Common Object Request Broker Architecture) to VMs (virtual machines) designed to integrate languages such as JVM (Java Virtual Machine) and CLR (Common Language Runtime). With software becoming ever more complex and hardware less homogeneous the likelihood of a single language being the correct tool for an entire program is lower than ever. As modern compilers become more modular there is potential for a new generation of interesting solutions.;
Fifty years of P vs. NP and the possibility of the impossible;Advances in algorithms machine learning and hardware can help tackle many NP-hard problems once thought impossible.;
Efficient maximum flow algorithms;Though maximum flow algorithms have a long history revolutionary progress is still being made.;
You're doing it wrong;Think you've mastered the art of server performance? Think again.;
The Robustness Principle Reconsidered: Seeking a middle ground;In 1981 Jon Postel formulated the Robustness Principle also known as Postelâ€™s Law as a fundamental implementation guideline for the then-new TCP. The intent of the Robustness Principle was to maximize interoperability between network service implementations particularly in the face of ambiguous or incomplete specifications. If every implementation of some service that generates some piece of protocol did so using the most conservative interpretation of the specification and every implementation that accepted that piece of protocol interpreted it using the most generous interpretation then the chance that the two services would be able to talk with each other would be maximized. Experience with the Arpanet had shown that getting independently developed implementations to interoperate was difficult and since the Internet was expected to be much larger than the Arpanet the old ad-hoc methods needed to be enhanced.;
"Time is an Illusion.: Lunchtime doubly so. - Ford Prefect to Arthur Dent in The Hitchhikerâ€™s Guide to the Galaxy"" by Douglas Adams""";"One of the more surprising things about digital systems - and in particular modern computers - is how poorly they keep time. When most programs ran on a single system this was not a significant issue for the majority of software developers but once software moved into the distributed-systems realm this inaccuracy became a significant challenge. Few programmers have read the most important paper in this area Leslie Lamportâ€™s Time Clocks and the Ordering of Events in a Distributed System"" (1978) and only a few more have come to appreciate the problems they face once they move into the world of distributed systems.""";
API: Design Matters: Why changing APIs might become a criminal offense.;After more than 25 years as a software engineer I still find myself underestimating the time it will take to complete a particular programming task. Sometimes the resulting schedule slip is caused by my own shortcomings: as I dig into a problem I simply discover that it is a lot harder than I initially thought so the problem takes longer to solveâ€”such is life as a programmer. Just as often I know exactly what I want to achieve and how to achieve it but it still takes far longer than anticipated. When that happens it is usually because I am struggling with an API that seems to do its level best to throw rocks in my path and make my life difficult. What I find telling is that after 25 years of progress in software engineering this still happens. Worse recent APIs implemented in modern programming languages make the same mistakes as their two-decade-old counterparts written in C. There seems to be something elusive about API design that despite many years of progress we have yet to master.;
DNS Complexity: Although it contains just a few simple rules DNS has grown into an enormously complex system.;DNS is a distributed coherent reliable autonomous hierarchical database the first and only one of its kind. Created in the 1980s when the Internet was still young but overrunning its original system for translating host names into IP addresses DNS is one of the foundation technologies that made the worldwide Internet possible. Yet this did not all happen smoothly and DNS technology has been periodically refreshed and refined. Though itâ€™s still possible to describe DNS in simple terms the underlying details are by now quite sublime. This article explores the supposed and true definitions of DNS and shows some of the tension between these two definitions through the lens of the Internet protocol development philosophy.;
Continuous Delivery Sounds Great but Will It Work Here? Itâ€™s not magic it just requires continuous daily improvement at all levels.;Continuous delivery is a set of principles patterns and practices designed to make deployments predictable routine affairs that can be performed on demand at any time. This article introduces continuous delivery presents both common objections and actual obstacles to implementing it and describes how to overcome them using real-life examples. Continuous delivery is not magic. Itâ€™s about continuous daily improvement at all levels of the organization.;
I/O Virtualization: Decoupling a logical device from its physical implementation offers many compelling advantages.;The term virtual is heavily overloaded evoking everything from virtual machines running in the cloud to avatars running across virtual worlds. Even within the narrowfigureer context of computer I/O virtualization has a long diverse history exemplified by logical devices that are deliberately separate from their physical instantiations.;
Touchless interaction in surgery;Touchless interaction with medical images lets surgeons maintain sterility during surgical procedures.;
The Future of Human-Computer Interaction: Is an HCI revolution just around the corner?;Personal computing launched with the IBM PC. But popular computingâ€”computing for the massesâ€”launched with the modern WIMP (windows icons mouse pointer) interface which made computers usable by ordinary people. As popular computing has grown the role of HCI (human-computer interaction) has increased. Most software today is interactive and code related to the interface is more than half of all code. HCI also has a key role in application design. In a consumer market a productâ€™s success depends on each userâ€™s experience with it. Unfortunately great engineering on the back end will be undone by a poor interface and a good UI can carry a product in spite of weaknesses inside.;
Web science: an interdisciplinary approach to understanding the web;The Web must be studied as an entity in its own right to ensure it keeps flourishing and prevent unanticipated social effects.;
Brain-computer interfaces for communication and control;The brain's electrical signals enable people without muscle control to physically interact with the world.;
Business impact of Web 2.0 technologies;What do wikis blogs podcasts social networks virtual worlds and the rest do for corporate productivity and management?;
Data Sketching: The approximate approach is often faster and more efficient.;Do you ever feel overwhelmed by an unending stream of information? It can seem like a barrage of new email and text messages demands constant attention and there are also phone calls to pick up articles to read and knocks on the door to answer. Putting these pieces together to keep track of whatâ€™s important can be a real challenge. In response to this challenge the model of streaming data processing has grown in popularity. The aim is no longer to capture store and index every minute event but rather to process each observation quickly in order to create a summary of the current state. Following its processing an event is dropped and is no longer accessible. The summary that is retained is often referred to as a sketch of the data. This article introduces the ideas behind sketching with a focus on algorithmic innovations. It describes some algorithmic developments in the abstract followed by the steps needed to put them into practice with examples. The article also looks at four novel algorithmic ideas and discusses some emerging areas.;
The state of phishing attacks;Looking past the systems people use they target the people using the systems.;
Reinventing Backend Subsetting at Google: Designing an algorithm with reduced connection churn that could replace deterministic subsetting;Backend subsetting is useful for reducing costs and may even be necessary for operating within the system limits. For more than a decade Google used deterministic subsetting as its default backend subsetting algorithm but although this algorithm balances the number of connections per backend task deterministic subsetting has a high level of connection churn. Our goal at Google was to design an algorithm with reduced connection churn that could replace deterministic subsetting as the default backend subsetting algorithm.;
Managing Technical Debt: Shortcuts that save money and time today can cost you down the road.;"In 1992 Ward Cunningham published a report at OOPSLA (Object-oriented Programming Systems Languages and Applications) in which he proposed the concept of technical debt. He defines it in terms of immature code: Shipping first-time code is like going into debt."" Technical debt isnâ€™t limited to first-time code however. There are many ways and reasons (not all bad) to take on technical debt.""";
Erlang;The same component isolation that made it effective for large distributed telecom systems makes it effective for multicore CPUs and networked applications.;
Principles of Robust Timing over the Internet: The key to synchronizing clocks over networks is taming delay variability.;Everyone and most everything needs a clock and computers are no exception. Clocks tend to drift off if left to themselves however so it is necessary to bring them to heel periodically through synchronizing to some other reference clock of higher accuracy. An inexpensive and convenient way to do this is over a computer network.;
Eventually Consistent: Not What You Were Expecting? Methods of quantifying consistency (or lack thereof) in eventually consistent storage systems;Storage systems continue to lay the foundation for modern Internet services such as Web search e-commerce and social networking. Pressures caused by rapidly growing user bases and data sets have driven system designs away from conventional centralized databases and toward more scalable distributed solutions including simple NoSQL key-value storage systems as well as more elaborate NewSQL databases that support transactions at scale.;
Wikidata: a free collaborative knowledgebase;This collaboratively edited knowledgebase provides a common source of data for Wikipedia and everyone else.;
The robustness principle reconsidered;Seeking a middle ground.;
AI in Computer Games: Smarter games are making for a better user experience. What does the future hold?;"If youâ€™ve been following the game development scene youâ€™ve probably heard many remarks such as: The main role of graphics in computer games will soon be over artificial intelligence is the next big thing!"" Although you should hardly buy into such statements there is some truth in them. The quality of AI (artificial intelligence) is a high-ranking feature for game fans in making their purchase decisions and an area with incredible potential to increase playersâ€™ immersion and fun.""";
Multitier Programming in Hop: A first step toward programming 21st-century applications;The Web is becoming the richest platform on which to create computer applications. Its power comes from three elements: (1) modern Web browsers enable highly sophisticated GUIs with 3D multimedia fancy typesetting etc. (2) calling existing services through Web APIs makes it possible to develop sophisticated applications from independently available components and (3) open data availability allows applications to access a wide set of information that was unreachable or that simply did not exist before. The combination of these three elements has already given birth to revolutionary applications such as Google Maps radio podcasts and social networks.;
Debugging Distributed Systems: Challenges and options for validation and debugging;Distributed systems pose unique challenges for software developers. Reasoning about concurrent activities of system nodes and even understanding the systemâ€™s communication topology can be difficult. A standard approach to gaining insight into system activity is to analyze system logs. Unfortunately this can be a tedious and complex process. This article looks at several key features and debugging challenges that differentiate distributed systems from other kinds of software. The article presents several promising tools and ongoing research to help resolve these challenges.;
If you have too much data then 'good enough' is good enough;In today's humongous database systems clarity may be relaxed but business needs can still be met.;
Bringing Arbitrary Compute to Authoritative Data: Many disparate use cases can be satisfied with a single storage system.;While the term â€™big dataâ€™ is vague enough to have lost much of its meaning todayâ€™s storage systems are growing more quickly and managing more data than ever before. Consumer devices generate large numbers of photos videos and other large digital assets. Machines are rapidly catching up to humans in data generation through extensive recording of system logs and metrics as well as applications such as video capture and genome sequencing. Large data sets are now commonplace and people increasingly want to run sophisticated analyses on the data. In this article â€™big dataâ€™ refers to a corpus of data large enough to benefit significantly from parallel computation across a fleet of systems where the efficient orchestration of the computation is itself a considerable challenge.;
Bitcoin's academic pedigree;The concept of cryptocurrencies is built from forgotten ideas in research literature.;
20 Obstacles to Scalability: Watch out for these pitfalls that can prevent Web application scaling.;Web applications can grow in fits and starts. Customer numbers can increase rapidly and application usage patterns can vary seasonally. This unpredictability necessitates an application that is scalable. What is the best way of achieving scalability?;
The Verification of a Distributed System: A practitionerâ€™s guide to increasing confidence in system correctness;"Leslie Lamport known for his seminal work in distributed systems famously said A distributed system is one in which the failure of a computer you didnâ€™t even know existed can render your own computer unusable."" Given this bleak outlook and the large set of possible failures how do you even begin to verify and validate that the distributed systems you build are doing the right thing?""";
A domain-specific supercomputer for training deep neural networks;Google's TPU supercomputers train deep neural networks 50x faster than general-purpose supercomputers running a high-performance computing benchmark.;
Why computing belongs within the social sciences;Fully appreciating the overarching scope of CS requires weaving more than ethics into the reigning curricula.;
Beyond Relational Databases: There is more to data access than SQL.;The number and variety of computing devices in the environment are increasing rapidly. Real computers are no longer tethered to desktops or locked in server rooms. PDAs highly mobile tablet and laptop devices palmtop computers and mobile telephony handsets now offer powerful platforms for the delivery of new applications and services. These devices are however only the tip of the iceberg. Hidden from sight are the many computing and network elements required to support the infrastructure that makes ubiquitous computing possible.;
Certificate Transparency: Public verifiable append-only logs;On August 28 2011 a mis-issued wildcard HTTPS certificate for google.com was used to conduct a man-in-the-middle attack against multiple users in Iran. The certificate had been issued by a Dutch CA (certificate authority) known as DigiNotar a subsidiary of VASCO Data Security International. Later analysis showed that DigiNotar had been aware of the breach in its systems for more than a month - since at least July 19. It also showed that at least 531 fraudulent certificates had been issued. The final count may never be known since DigiNotar did not have records of all the mis-issued certificates. On September 20 2011 DigiNotar was declared bankrupt.;
Physical key extraction attacks on PCs;Computers broadcast their secrets via inadvertent physical emanations that are easily measured and exploited.;
Languages Levels Libraries and Longevity: New programming languages are born every day. Why do some succeed and some fail?;In 50 years weâ€™ve already seen numerous programming systems come and (mostly) go although some have remained a long time and will probably do so for: decades? centuries? millennia? The questions about language designs levels of abstraction libraries and resulting longevity are numerous. Why do new languages arise? Why is it sometimes easier to write new software than to adapt old software that works? How many different levels of languages make sense? Why do some languages last in the face of â€œbetterâ€ ones?;
The Five-Minute Rule 20 Years Later: and How Flash Memory Changes the Rules: The old rule continues to evolve while flash memory adds two new rules.;In 1987 Jim Gray and Gianfranco Putzolu published their now-famous five-minute rule for trading off memory and I/O capacity. Their calculation compares the cost of holding a record (or page) permanently in memory with the cost of performing disk I/O each time the record (or page) is accessed using appropriate fractions of prices for RAM chips and disk drives. The name of their rule refers to the break-even interval between accesses. If a record (or page) is accessed more often it should be kept in memory otherwise it should remain on disk and read when needed.;
SAGE: Whitebox Fuzzing for Security Testing: SAGE has had a remarkable impact at Microsoft.;"Most ACM Queue readers might think of program verification research"" as mostly theoretical with little impact on the world at large. Think again. If you are reading these lines on a PC running some form of Windows (like 93-plus percent of PC users--that is more than a billion people) then you have been affected by this line of work--without knowing it which is precisely the way we want it to be.""";
Code Spelunking Redux: Is this subject important enough to warrant two articles in five years? I believe it is.;It has been five years since I first wrote about code spelunking and though systems continue to grow in size and scope the tools we use to understand those systems are not growing at the same rate. In fact I believe we are steadily losing ground. So why should we go over the same ground again? Is this subject important enough to warrant two articles in five years? I believe it is.;
GFS: evolution on fast-forward;Kirk McKusick and Sean Quinlan discuss the origin and evolution of the Google File System.;
Extending the Semantics of Scheduling Priorities: Increasing parallelism demands new paradigms.;Application performance is directly affected by the hardware resources that the application requires the degree to which such resources are available and how the operating system addresses its requirements with regard to the other processes in the system. Ideally an application would have access to all the resources it could use and be allowed to complete its work without competing with any other activity in the system. In a world of highly shared hardware resources and generalpurpose time-share-based operating systems however no guarantees can be made as to how well resourced an application will be.;
Here we go again: why is it difficult for developers to learn another programming language?;Once a programmer knows one language they can leverage concepts and knowledge already learned and easily pick up another programming language. But is that always the case? To understand if programmers have difficulty learning additional programming languages we conducted an empirical study of Stack Overflow questions across 18 different programming languages. We hypothesized that previous knowledge could potentially interfere with learning a new programming language. From our inspection of 450 Stack Overflow questions we found 276 instances of interference that occurred due to faulty assumptions originating from knowledge about a different language. To understand why these difficulties occurred we conducted semistructured interviews with 16 professional programmers. The interviews revealed that programmers make failed attempts to relate a new programming language with what they already know. Our findings inform design implications for technical authors toolsmiths and language designers such as designing documentation and automated tools that reduce interference anticipating uncommon language transitions during language design and welcoming programmers not just into a language but its entire ecosystem.;
10 rules for scalable performance in 'simple operation' datastores;Partition data and operations keep administration simple do not assume one size fits all.;
Hyperledger fabric: a distributed operating system for permissioned blockchains;"Fabric is a modular and extensible open-source system for deploying and operating permissioned blockchains and one of the Hyperledger projects hosted by the Linux Foundation (www.hyperledger.org).Fabric is the first truly extensible blockchain system for running distributed applications. It supports modular consensus protocols which allows the system to be tailored to particular use cases and trust models. Fabric is also the first blockchain system that runs distributed applications written in standard general-purpose programming languages without systemic dependency on a native cryptocurrency. This stands in sharp contrast to existing block-chain platforms that require smart-contracts"" to be written in domain-specific languages or rely on a cryptocurrency. Fabric realizes the permissioned model using a portable notion of membership which may be integrated with industry-standard identity management. To support such flexibility Fabric introduces an entirely novel blockchain design and revamps the way blockchains cope with non-determinism resource exhaustion and performance attacks.This paper describes Fabric its architecture the rationale behind various design decisions its most prominent implementation aspects as well as its distributed application programming model. We further evaluate Fabric by implementing and benchmarking a Bitcoin-inspired digital currency. We show that Fabric achieves end-to-end throughput of more than 3500 transactions per second in certain popular deployment configurations with sub-second latency scaling well to over 100 peers.""";
Proceedings of the Thirteenth EuroSys Conference;What is nonblocking progress? Consider the simple example of incrementing a counter C shared among multiple threads. One way to do so is by protecting the steps of incrementing C by a mutual exclusion lock L (i.e. acquire(L) oldâ€¯:= Câ€¯ Câ€¯:= old+1 release(L)). If a thread P is holding L then a different thread Q must wait for P to release L before Q can proceed to operate on C. That is Q is blocked by P.;
Advances and Challenges in Log Analysis: Logs contain a wealth of information for help in managing systems.;Computer-system logs provide a glimpse into the states of a running system. Instrumentation occasionally generates short messages that are collected in a system-specific log. The content and format of logs can vary widely from one system to another and even among components within a system. A printer driver might generate messages indicating that it had trouble communicating with the printer while a Web server might record which pages were requested and when.;
A Call to Arms: Long anticipated the arrival of radically restructured database architectures is now finally at hand.;We live in a time of extreme change much of it precipitated by an avalanche of information that otherwise threatens to swallow us whole. Under the mounting onslaught our traditional relational database constructsâ€”always cumbersome at bestâ€”are now clearly at risk of collapsing altogether. In fact rarely do you find a DBMS anymore that doesnâ€™t make provisions for online analytic processing. Decision trees Bayes nets clustering and time-series analysis have also become part of the standard package with allowances for additional algorithms yet to come. Also text temporal and spatial data access methods have been addedâ€”along with associated probabilistic logic since a growing number of applications call for approximated results. Column stores which store data column-wise rather than record-wise have enjoyed a rebirth mostly to accommodate sparse tables as well as to optimize bandwidth.;
Simulators: Virtual Machines of the Past (and Future): Has the time come to kiss that old iron goodbye?;Simulators are a form of â€œvirtual machineâ€ intended to address a simple problem: the absence of real hardware. Simulators for past systems address the loss of real hardware and preserve the usability of software after real hardware has vanished. Simulators for future systems address the variability of future hardware designs and facilitate the development of software before real hardware exists.;
Debugging Incidents in Googleâ€™s Distributed Systems: How experts debug production issues in complex distributed systems;This article covers the outcomes of research performed in 2019 on how engineers at Google debug production issues including the types of tools high-level strategies and low-level tasks that engineers use in varying combinations to debug effectively. It examines the research approach used to capture data summarizing the common engineering journeys for production investigations and sharing examples of how experts debug complex distributed systems. Finally the article extends the Google specifics of this research to provide some practical strategies that you can apply in your organization.;
A Systematic Analysis of the Capital One Data Breach: Critical Lessons Learned;The 2019 Capital One data breach was one of the largest data breaches impacting the privacy and security of personal information of over a 100 million individuals. In most reports about a cyberattack you will often hear that it succeeded because a single employee clicked on a link in a phishing email or forgot to patch some software making it seem like an isolated one-off trivial problem involving maybe one person committing a mistake or being negligent. But that is usually not the complete story. By ignoring the related managerial and organizational failures you are leaving in place the conditions for the next breach. Using our Cybersafety analysis methodology we identified control failures spanning control levels going from rather technical issues up to top management the Board of Directors and Government regulators. In this analysis we reconstruct the Capital One hierarchical cyber safety control structure identify what parts failed and why and provide recommendations for improvements. This work demonstrates how to discover the true causes of security failures in complex information systems and derive systematic cybersecurity improvements that likely apply to many other organizations. It also provides an approach that individuals can use to evaluate and better secure their organizations.;
Exponential laws of computing growth;Moore's Law is one small component in an exponentially growing planetary computing ecosystem.;
The pathologies of big data;Scale up your datasets enough and your apps come undone. What are the typical problems and where do the bottlenecks surface?;
Peer-to-peer systems;Within a decade P2P has proven to be a technology that enables innovative new services and is used by millions of people every day.;
Structured Deferral: Synchronization via Procrastination: We simply do not have a synchronization mechanism that can enforce mutual exclusion.;Developers often take a proactive approach to software design especially those from cultures valuing industriousness over procrastination. Lazy approaches however have proven their value with examples including reference counting garbage collection and lazy evaluation. This structured deferral takes the form of synchronization via procrastination specifically reference counting hazard pointers and RCU (read-copy-update).;
Unifying functional and object-oriented programming with Scala;Scala unifies traditionally disparate programming-language philosophies to develop new components and component systems.;
Learning from the Web: The Web has taught us many lessons about distributed computing but some of  the most important ones have yet to fully take hold.;In the past decade we have seen a revolution in computing that transcends anything seen to date in terms of scope and reach but also in terms of how we think about what makes up â€œgoodâ€ and â€œbadâ€ computing.;
The Hidden Dividends of Microservices: Microservices arenâ€™t for every company and the journey isnâ€™t easy.;Microservices are an approach to building distributed systems in which services are exposed only through hardened APIs the services themselves have a high degree of internal cohesion around a specific and well-bounded context or area of responsibility and the coupling between them is loose. Such services are typically simple yet they can be composed into very rich and elaborate applications. The effort required to adopt a microservices-based approach is considerable particularly in cases that involve migration from more monolithic architectures. The explicit benefits of microservices are well known and numerous however and can include increased agility resilience scalability and developer productivity. This article identifies some of the hidden dividends of microservices that implementers should make a conscious effort to reap.;
Evolution and Practice: Low-latency Distributed Applications in Finance: The finance industry has unique demands for low-latency distributed systems.;Virtually all systems have some requirements for latency defined here as the time required for a system to respond to input. Latency requirements appear in problem domains as diverse as aircraft flight controls voice communications multiplayer gaming online advertising and scientific experiments. Distributed systems present special latency considerations. In recent years the automation of financial trading has driven requirements for distributed systems with challenging latency requirements and global geographic distribution. Automated trading provides a window into the engineering challenges of ever-shrinking latency requirements which may be useful to software engineers in other fields.;
You Donâ€™t Know Jack about Disks: Whatever happened to cylinders and tracks?;Traditionally the programmerâ€™s working model of disk storage has consisted of a set of uniform cylinders each with a set of uniform tracks which in turn hold a fixed number of 512-byte sectors each with a unique address. The cylinder is made up of concentric circles (or tracks) on each disk platter in a multiplatter drive. Each track is divided up like pie slices into sectors. Because any location in this three-dimensional storage space could be uniquely identified by the cylinder number head (surface) number and sector number this formed the basis for the original programming model for disk drives: cylinder-head-sector access.;
Software Transactional Memory: Why Is It Only a Research Toy? The promise of STM may likely be undermined by its overheads and workload applicabilities.;TM (transactional memory) is a concurrency control paradigm that provides atomic and isolated execution for regions of code. TM is considered by many researchers to be one of the most promising solutions to address the problem of programming multicore processors. Its most appealing feature is that most programmers only need to reason locally about shared data accesses mark the code region to be executed transactionally and let the underlying system ensure the correct concurrent execution. This model promises to provide the scalability of fine-grain locking while avoiding common pitfalls of lock composition such as deadlock. In this article we explore the performance of a highly optimized STM and observe that the overall performance of TM is significantly worse at low levels of parallelism which is likely to limit the adoption of this programming paradigm.;
Toward a Commodity Enterprise Middleware: Can AMQP enable a new era in messaging middleware? A look inside standards-based messaging with AMQP;AMQP was born out of my own experience and frustrations in developing front- and back-office processing systems at investment banks. It seemed to me that we were living in integration Groundhog Day - the same problems of connecting systems together would crop up with depressing regularity. Each time the same discussions about which products to use would happen and each time the architecture of some system would be curtailed to allow for the fact that the chosen middleware was reassuringly expensive. From 1996 through to 2003 I was waiting for the solution to this obvious requirement to materialize as a standard and thereby become a commodity. But that failed to happen and I grew tired of waiting.;
Biases in AI Systems: A survey for practitioners;This article provides an organization of various kinds of biases that can occur in the AI pipeline starting from dataset creation and problem formulation to data analysis and evaluation. It highlights the challenges associated with the design of bias-mitigation strategies and it outlines some best practices suggested by researchers. Finally a set of guidelines is presented that could aid ML developers in identifying potential sources of bias as well as avoiding the introduction of unwanted biases. The work is meant to serve as an educational resource for ML developers in handling and addressing issues related to bias in AI systems.;
Hard-disk drives: the good the bad and the ugly;New drive technologies and increased capacities create new categories of failure modes that will influence system designs.;
Building Nutch: Open Source Search: A case study in writing an open source search engine;Search engines are as critical to Internet use as any other part of the network infrastructure but they differ from other components in two important ways. First their internal workings are secret unlike say the workings of the DNS (domain name system). Second they hold political and cultural power as users increasingly rely on them to navigate online content.;
DSL for the uninitiated;Domain-specific languages bridge the semantic gap in programming.;
Adopting DevOps Practices in Quality Assurance: Merging the art and science of software development;Software life-cycle management was for a very long time a controlled exercise. The duration of product design development and support was predictable enough that companies and their employees scheduled their finances vacations surgeries and mergers around product releases. When developers were busy QA (quality assurance) had it easy. As the coding portion of a release cycle came to a close QA took over while support ramped up. Then when the product released the development staff exhaled rested and started the loop again while the support staff transitioned to busily supporting the new product.;
Computational journalism;How computer scientists can empower journalists democracy's watchdogs in the production of news in the public interest.;
Tracking and Controlling Microservice Dependencies: Dependency management is a crucial part of system and software design.;Dependency cycles will be familiar to you if you have ever locked your keys inside your house or car. You canâ€™t open the lock without the key but you canâ€™t get the key without opening the lock. Some cycles are obvious but more complex dependency cycles can be challenging to find before they lead to outages. Strategies for tracking and controlling dependencies are necessary for maintaining reliable systems.;
Cybercrime 2.0: When the Cloud Turns Dark: Web-based malware attacks are more insidious than ever. What can be done to stem the tide?;As the Web has become vital for day-to-day transactions it has also become an attractive avenue for cybercrime. Financially motivated the crime we see on the Web today is quite different from the more traditional network attacks. A few years ago Internet attackers relied heavily on remotely exploiting servers identified by scanning the Internet for vulnerable network services. Autonomously spreading computer worms such as Code Red and SQLSlammer were examples of such scanning attacks. Their huge scale put even the Internet at large at risk for example SQLSlammer generated traffic sufficient to melt down backbones.;
Industry-scale Knowledge Graphs: Lessons and Challenges: Five diverse technology companies show how itâ€™s done;This article looks at the knowledge graphs of five diverse tech companies comparing the similarities and differences in their respective experiences of building and using the graphs and discussing the challenges that all knowledge-driven enterprises face today. The collection of knowledge graphs discussed here covers the breadth of applications from search to product descriptions to social networks.;
The growth and evolution of India's software industry;Modern multicore systems are designed to allow clusters of cores to share various hardware structures such as LLCs (last-level caches for example L2 or L3) memory controllers and interconnects as well as prefetching hardware. We refer to these resource-sharing clusters as memory domains because the shared resources mostly have to do with the memory hierarchy.;
Computational sustainability: computing for a better world and a sustainable future;Computer and information scientists join forces with other fields to help solve societal and environmental challenges facing humanity in pursuit of a sustainable future.;
A second conversation with Werner Vogels;The Amazon CTO sits with Tom Killalea to discuss designing for evolution at scale.;
OpenFlow: A Radical New Idea in Networking: An open standard that enables software-defined networking;Computer networks have historically evolved box by box with individual network elements occupying specific ecological niches as routers switches load balancers NATs (network address translations) or firewalls. Software-defined networking proposes to overturn that ecology turning the network as a whole into a platform and the individual network elements into programmable entities. The apps running on the network platform can optimize traffic flows to take the shortest path just as the current distributed protocols do but they can also optimize the network to maximize link utilization create different reachability domains for different users or make device mobility seamless.;
Scaling Existing Lock-based Applications with Lock Elision: Lock elision enables existing lock-based programs to achieve the performance benefits of nonblocking synchronization and fine-grain locking with minor software engineering effort.;Multithreaded applications take advantage of increasing core counts to achieve high performance. Such programs however typically require programmers to reason about data shared among multiple threads. Programmers use synchronization mechanisms such as mutual-exclusion locks to ensure correct updates to shared data in the presence of accesses from multiple threads. Unfortunately these mechanisms serialize thread accesses to the data and limit scalability.;
Bitcoinâ€™s Underlying Incentives: The unseen economic forces that govern the Bitcoin protocol;Incentives are crucial for the Bitcoin protocolâ€™s security and effectively drive its daily operation. Miners go to extreme lengths to maximize their revenue and often find creative ways to do so that are sometimes at odds with the protocol. Cryptocurrency protocols should be placed on stronger foundations of incentives. There are many areas left to improve ranging from the very basics of mining rewards and how they interact with the consensus mechanism through the rewards in mining pools and all the way to the transaction fee market itself.;
Hazy: Making it Easier to Build and Maintain Big-data Analytics: Racing to unleash the full potential of big data with the latest statistical and machine-learning techniques.;"The rise of big data presents both big opportunities and big challenges in domains ranging from enterprises to sciences. The opportunities include better-informed business decisions more efficient supply-chain management and resource allocation more effective targeting of products and advertisements better ways to organize the worldâ€™s information"" faster turnaround of scientific discoveries etc.""";
Commercializing Open Source Software: Many have tried a few are succeeding but challenges abound.;The use of open source software has become increasingly popular in production environments as well as in research and software development. One obvious attraction is the low cost of acquisition. Commercial software has a higher initial cost though it usually has advantages such as support and training. A number of business models designed by users and vendors combine open source and commercial software they use open source as much as possible adding commercial software as needed. They may use open source software as a central component of a product or service but use other components to add value which can then induce customers to pay for the offering (obviously it is hard to compete with free software on price).;
What serverless computing is and should become: the next phase of cloud computing;The evolution that serverless computing represents the economic forces that shape it why it could fail and how it might fulfill its potential.;
Autopilot: workload autoscaling at Google;In many public and private Cloud systems users need to specify a limit for the amount of resources (CPU cores and RAM) to provision for their workloads. A job that exceeds its limits might be throttled or killed resulting in delaying or dropping end-user requests so human operators naturally err on the side of caution and request a larger limit than the job needs. At scale this results in massive aggregate resource wastage.To address this Google uses Autopilot to configure resources automatically adjusting both the number of concurrent tasks in a job (horizontal scaling) and the CPU/memory limits for individual tasks (vertical scaling). Autopilot walks the same fine line as human operators: its primary goal is to reduce slack - the difference between the limit and the actual resource usage - while minimizing the risk that a task is killed with an out-of-memory (OOM) error or its performance degraded because of CPU throttling. Autopilot uses machine learning algorithms applied to historical data about prior executions of a job plus a set of finely-tuned heuristics to walk this line. In practice Autopiloted jobs have a slack of just 23% compared with 46% for manually-managed jobs. Additionally Autopilot reduces the number of jobs severely impacted by OOMs by a factor of 10.Despite its advantages ensuring that Autopilot was widely adopted took significant effort including making potential recommendations easily visible to customers who had yet to opt in automatically migrating certain categories of jobs and adding support for custom recommenders. At the time of writing Autopiloted jobs account for over 48% of Google's fleet-wide resource usage.;
Proceedings of the Fifteenth European Conference on Computer Systems;Some people do living history -- reviving older skills and material culture by reenacting Waterloo or knapping flint knives. One pleasant rainy weekend in 2012 I set my sights a little more recently and settled in for a little meditative retro-computing ca. 1962 following the ancient mode of transmission of knowledge: lecture and recitation -- or rather grace of living in historical times lecture (here in the French sense reading) and transcription (or even more specifically grace of living post-Post lecture and reimplementation).;
Intermediate Representation: The increasing significance of intermediate representations in compilers;Program compilation is a complicated process. A compiler is a software program that translates a high-level source language program into a form ready to execute on a computer. Early in the evolution of compilers designers introduced IRs (intermediate representations also commonly called intermediate languages) to manage the complexity of the compilation process. The use of an IR as the compilerâ€™s internal representation of the program enables the compiler to be broken up into multiple phases and components thus benefiting from modularity.;
The Pain of Implementing LINQ Providers: Itâ€™s no easy task for NoSQL;I remember sitting on the edge of my seat watching the 2005 PDC (Professional Developers Conference) videos that first showed LINQ (Language Integrated Query). I wanted LINQ: it offered just about everything that I could hope for to make working with data easy. The impetus for building queries into the language is quite simple it is something that is used all the time and the promise of a unified querying model is good enough even before you add all the language goodies that were dropped on us. Being able to write in C# and have the database magically understand what I am doing? Awesome! Getting compilation errors from Visual Studio rather than runtime errors at testing (or worse production)? Wonderful! Getting rid of most SQL injection issues? Amazing!;
The History Status and Future of FPGAs: Hitting a nerve with field-programmable gate arrays;This article is a summary of a three-hour discussion at Stanford University in September 2019 among the authors. It has been written with combined experiences at and with organizations such as Zilog Altera Xilinx Achronix Intel IBM Stanford MIT Berkeley University of Wisconsin the Technion Fairchild Bell Labs Bigstream Google DIGITAL (DEC) SUN Nokia SRI Hitachi Silicom Maxeler Technologies VMware Xerox PARC Cisco and many others. These organizations are not responsible for the content but may have inspired the authors in some ways to arrive at the colorful ride through FPGA space described above.;
Scaling Synchronization in Multicore Programs: Advanced synchronization methods can boost the performance of multicore software.;Designing software for modern multicore processors poses a dilemma. Traditional software designs in which threads manipulate shared data have limited scalability because synchronization of updates to shared data serializes threads and limits parallelism. Alternative distributed software designs in which threads do not share mutable data eliminate synchronization and offer better scalability. But distributed designs make it challenging to implement features that shared data structures naturally provide such as dynamic load balancing and strong consistency guarantees and are simply not a good fit for every program. Often however the performance of shared mutable data structures is limited by the synchronization methods in use today whether lock-based or lock-free. To help readers make informed design decisions this article describes advanced (and practical) synchronization methods that can push the performance of designs using shared mutable data to levels that are acceptable to many applications.;
I/O virtualization;Decoupling a logical device from its physical implementation offers many compelling advantages.;
Canary Analysis Service: Automated canarying quickens development improves production safety and helps prevent outages.;It is unreasonable to expect engineers working on product development or reliability to have statistical knowledge removing this hurdle led to widespread CAS adoption. CAS has proven useful even for basic cases that donâ€™t need configuration and has significantly improved Googleâ€™s rollout reliability. Impact analysis shows that CAS has likely prevented hundreds of postmortem-worthy outages and the rate of postmortems among groups that do not use CAS is noticeably higher.;
 'Natural' search user interfaces;Users will speak rather than type watch video rather than read and use technology socially rather than alone.;
Extensible Programming for the 21st Century: Is an open more flexible programming environment just around the corner?;In his keynote address at OOPSLA â€™98 Sun Microsystems Fellow Guy L. Steele Jr. said â€œFrom now on a main goal in designing a language should be to plan for growth.â€ Functions user-defined types operator overloading and generics (such as C++ templates) are no longer enough: tomorrowâ€™s languages must allow programmers to add entirely new kinds of information to programs and control how it is processed. This article argues that next-generation programming systems can accomplish this by combining three specific technologies.;
Why cryptocurrencies use so much energy: and what to do about it;The electricity consumption of mining for cryptocurrencies is becoming a real concern. Here's what to do about it.;
A Hitchhikerâ€™s Guide to the Blockchain Universe: Blockchain remains a mystery despite its growing acceptance.;It is difficult these days to avoid hearing about blockchain. Despite the significant potential of blockchain it is also difficult to find a consistent description of what it really is. This article looks at the basics of blockchain: the individual components how those components fit together and what changes might be made to solve some of the problems with blockchain technology.;
Keeping Bits Safe: How Hard Can It Be? As storage systems grow larger and larger protecting their data for long-term storage is becoming more and more challenging.;These days we are all data pack rats. Storage is cheap so if thereâ€™s a chance the data could possibly be useful we keep it. We know that storage isnâ€™t completely reliable so we keep backup copies as well. But the more data we keep and the longer we keep it the greater the chance that some of it will be unrecoverable when we need it.;
Scalability Techniques for Practical Synchronization Primitives: Designing locking primitives with performance in mind;In an ideal world applications are expected to scale automatically when executed on increasingly larger systems. In practice however not only does this scaling not occur but it is common to see performance actually worsen on those larger systems.;
Culture Surprises in Remote Software Development Teams: When in Rome doesnâ€™t help when your team crosses time zones and your deadline doesnâ€™t.;"Technology has made it possible for organizations to construct teams of people who are not in the same location adopting what one company calls virtual collocation."" Worldwide groups of software developers financial analysts automobile designers consultants pricing analysts and researchers are examples of teams that work together from disparate locations using a variety of collaboration technologies that allow communication across space and time.""";
Undergraduate Software Engineering: Addressing the Needs of Professional Software Development: Addressing the Needs of Professional Software Development;In the fall semester of 1996 RIT (Rochester Institute of Technology) launched the first undergraduate software engineering program in the United States. The culmination of five years of planning development and review the program was designed from the outset to prepare graduates for professional positions in commercial and industrial software development.;
DSPs: Back to the Future: To understand where DSPs are headed we must look at where theyâ€™ve come from.;"From the dawn of the DSP (digital signal processor) an old quote still echoes: Oh no! Weâ€™ll have to use state-of-the-art 5Âµm NMOS!"" The speakerâ€™s name is lost in the fog of history as are many things from the ancient days of 5Âµm chip design. This quote refers to the first Bell Labs DSP whose mask set in fact underwent a 10 percent linear lithographic shrink to 4.5Âµm NMOS (N-channel metal oxide semiconductor) channel length and taped out in late 1979 with an aggressive full-custom circuit design. The designer I quoted had realized that the best technology of the time would be required to meet the performance demands of the then cutting-edge digital Touch-Tone receiver.""";
Static analysis at GitHub;An experience report.;
Can automated agents proficiently negotiate with humans?;Exciting research in the design of automated negotiators is making great progress.;
The Price of Performance: An Economic Case for Chip Multiprocessing;In the late 1990s our research group at DEC was one of a growing number of teams advocating the CMP (chip multiprocessor) as an alternative to highly complex single-threaded CPUs. We were designing the Piranha system1 which was a radical point in the CMP design space in that we used very simple cores (similar to the early RISC designs of the late â€™80s) to provide a higher level of thread-level parallelism. Our main goal was to achieve the best commercial workload performance for a given silicon budget. Today in developing Googleâ€™s computing infrastructure our focus is broader than performance alone. The merits of a particular architecture are measured by answering the following question: Are you able to afford the computational capacity you need? The high-computational demands that are inherent in most of Googleâ€™s services have led us to develop a deep understanding of the overall cost of computing and continually to look for hardware/software designs that optimize performance per unit of cost.;
Metrics That Matter: Critical but oft-neglected service metrics that every SRE and product owner should care about;Measure your site reliability metrics set the right targets and go through the work to measure the metrics accurately. Then youâ€™ll find that your service runs better with fewer outages and much more user adoption.;
Toward Higher Precision: An introduction to PTP and its significance to NTP practitioners;"It is difficult to overstate the importance of synchronized time to modern computer systems. Our lives today depend on the financial transactions telecommunications power generation and delivery high-speed manufacturing and discoveries in big physics"" among many other things that are driven by fast powerful computing devices coordinated in time with each other.""";
In-Datacenter Performance Analysis of a Tensor Processing Unit;Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU) --- deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs that help average throughput more than guaranteed latency. The lack of such features helps explain why despite having myriad MACs and a big memory the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU which are contemporaries deployed in the same datacenters. Our workload written in the high-level TensorFlow framework uses production NN applications (MLPs CNNs and LSTMs) that represent 95% of our datacenters' NN inference demand. Despite low utilization for some applications the TPU is on average about 15X -- 30X faster than its contemporary GPU or CPU with TOPS/Watt about 30X -- 80X higher. Moreover using the CPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU.;
Proceedings of the 44th Annual International Symposium on Computer Architecture;End-to-end testing of Web applications typically involves tricky interactions with Web pages by means of a framework such as Selenium WebDriver. The recommended method for hiding such Web-page intricacies is to use page objects but there are questions to answer first: Which page objects should you create when testing Web applications? What actions should you include in a page object? Which test scenarios should you specify given your page objects?;
Proving the Correctness of Nonblocking Data Structures: So youâ€™ve decided to use a nonblocking data structure and now you need to be certain of its correctness. How can this be achieved?;Nonblocking synchronization can yield astonishing results in terms of scalability and realtime response but at the expense of verification state space.;
Weapons of mass assignment;A Ruby on Rails app highlights some serious yet easily avoided security vulnerabilities.;
Blockchain beyond bitcoin;Blockchain technology has the potential to revolutionize applications and redefine the digital economy.;
The Software Inferno: Danteâ€™s tale as experienced by a software architect;"The Software Inferno is a tale that parallels The Inferno Part One of The Divine Comedy written by Dante Alighieri in the early 1300s. That literary masterpiece describes the condemnation and punishment faced by a variety of sinners in their hell-spent afterlives as recompense for atrocities committed during their earthly existences. The Software Inferno is a similar account describing a journey where sinners against software"" are encountered amidst their torment within their assigned areas of eternal condemnation and paying their penance.""";
Whither Sockets? High bandwidth low latency and multihoming challenge the sockets API.;One of the most pervasive and longest-lasting interfaces in software is the sockets API. Developed by the Computer Systems Research Group at the University of California at Berkeley the sockets API was first released as part of the 4.1c BSD operating system in 1982. While there are longer-lived APIs it is quite impressive for an API to have remained in use and largely unchanged for 27 years. The only major update to the sockets API has been the extension of ancillary routines to accommodate the larger addresses used by IPv6.;
Long Live Software Easter Eggs!;It's a period of unrest. Rebel developers striking from continuous deployment servers have won their first victory. During the battle rebel spies managed to push an epic commit in the HTML code of https://pro.sony. Pursued by sinister agents the rebels are hiding in commits buttons tooltips API HTTP headers and configuration screens.;
Making Money Using Math: Modern applications are increasingly using probabilistic machine-learned models.;A big difference between human-written code and learned models is that the latter are usually not represented by text and hence are not understandable by human developers or manipulable by existing tools. The consequence is that none of the traditional software engineering techniques for conventional programs (such as code reviews source control and debugging) are applicable anymore. Since incomprehensibility is not unique to learned code these aspects are not of concern here.;
APL since 1978;The Evolution of APL the HOPL I paper by Falkoff and Iverson on APL recounted the fundamental design principles which shaped the implementation of the APL language in 1966 and the early uses and other influences which shaped its first decade of enhancements.In the 40 years that have elapsed since HOPL I several dozen APL implementations have come and gone. In the first decade or two interpreters were typically born and buried along with the hardware or operating system that they were created for. More recently the use of C as an implementation language provided APL interpreters with greater longevity and portability.APL started its life on IBM mainframes which were time-shared by multiple users. As the demand for computing resources grew and costs dropped APL first moved in-house to mainframes then to mini- and micro-computers. Today APL runs on PCs and tablets Apples and Raspberry Pis smartphones and watches.The operating systems and the software application platforms that APL runs on have evolved beyond recognition. Tools like database systems have taken over many of the tasks that were initially implemented in APL or provided by the APL system and new capabilities like parallel hardware have also changed the focus of design and implementation efforts through the years.The first wave of significant language enhancements occurred shortly after HOPL I resulting in so-called second-generation APL systems. The most important feature of the second generation is the addition of general arraysâ€”in which any item of an array can be another arrayâ€”and a number of new functions and operators aligned with if not always motivated by the new data structures.The majority of implementations followed IBMâ€™s path with APL2 â€œfloatingâ€ arrays others aligned themselves with SHARP APL and â€œgroundedâ€ arrays. While the APL2 style of APL interpreters came to dominate the mainstream of the APL community two new cousins of APL descended from the SHARP APL family tree: J (created by Iverson and Hui) and k (created by Arthur Whitney).We attempt to follow a reasonable number of threads through the last 40 years to identify the most important factors that have shaped the evolution of APL. We will discuss the details of what we believe are the most significant language features that made it through the occasionally unnatural selection imposed by the loss of habitats that disappeared with hardware software platforms and business models.The history of APL now spans six decades. It is still the case as Falkoff and Iverson remarked at the end of the HOPL I paper that:Although this is not the place to discuss the future it should be remarked that the evolution of APL is far from finished.;
Searching for Jim Gray: a technical overview;The volunteer search for Jim Gray lost at sea in 2007 highlights the challenges of computer-aided emergency response.;
Community sense and response systems: your phone as quake detector;The Caltech CSN project collects sensor data from thousands of personal devices for real-time response to dangerous earthquakes.;
Should You Upload or Ship Big Data to the Cloud? The accepted wisdom does not always hold true.;"It is accepted wisdom that when the data you wish to move into the cloud is at terabyte scale and beyond you are better off shipping it to the cloud provider rather than uploading it. This article takes an analytical look at how shipping and uploading strategies compare the various factors on which they depend and under what circumstances you are better off shipping rather than uploading data and vice versa. Such an analytical determination is important to make given the increasing availability of gigabit-speed Internet connections along with the explosive growth in data-transfer speeds supported by newer editions of drive interfaces such as SAS and PCI Express. As this article reveals the aforementioned accepted wisdom"" does not always hold true and there are well-reasoned practical recommendations for uploading versus shipping data to the cloud.""";
Industry-scale knowledge graphs: lessons and challenges;Five diverse technology companies show how it's done.;
Internet voting in the U.S.;Internet voting is unachievable for the foreseeable future and therefore not inevitable.;
Erlang for Concurrent Programming: What role can programming languages play in dealing with concurrency? One answer can be found in Erlang a language designed for concurrency from the ground up.;Erlang is a language developed to let mere mortals write test deploy and debug fault-tolerant concurrent software. Developed at the Swedish telecom company Ericsson in the late 1980s it started as a platform for developing soft realtime software for managing phone switches. It has since been open-sourced and ported to several common platforms finding a natural fit not only in distributed Internet server applications but also in graphical user interfaces and ordinary batch applications.;
Cloud security: a gathering storm;Users' trust in cloud systems is undermined by the lack of transparency in existing security policies.;
Why cloud computing will never be free;The competition among cloud providers may drive prices downward but at what cost?;
The Future of Microprocessors: Chip multiprocessorsâ€™ promise of huge performance gains is now a reality.;The performance of microprocessors that power modern computers has continued to increase exponentially over the years for two main reasons. First the transistors that are the heart of the circuits in all processors and memory chips have simply become faster over time on a course described by Mooreâ€™s law and this directly affects the performance of processors built with those transistors. Moreover actual processor performance has increased faster than Mooreâ€™s law would predict because processor designers have been able to harness the increasing numbers of transistors available on modern chips to extract more parallelism from software.;
Could artificial intelligence create an unemployment crisis?;Advances in artificial intelligence and robotics will have significant implications for evolving economic systems.;
BufferBloat: what's wrong with the internet?;A discussion with Vint Cerf Van Jacobson Nick Weaver and Jim Gettys.;
Componentizing the Web: We may be on the cusp of a new revolution in web development.;There is no task in software engineering today quite as herculean as web development. A typical specification for a web application might read: The app must work across a wide variety of browsers. It must run animations at 60 fps. It must be immediately responsive to touch. It must conform to a specific set of design principles and specs. It must work on just about every screen size imaginable from TVs and 30-inch monitors to mobile phones and watch faces. It must be well-engineered and maintainable in the long term.;
Global IT management: structuring for scale responsiveness and innovation;To succeed on a global scale businesses should focus on a trio of key elements.;
Twitter Heron: Stream Processing at Scale;Storm has long served as the main platform for real-time analytics at Twitter. However as the scale of data being processed in real-time at Twitter has increased along with an increase in the diversity and the number of use cases many limitations of Storm have become apparent. We need a system that scales better has better debug-ability has better performance and is easier to manage -- all while working in a shared cluster infrastructure. We considered various alternatives to meet these needs and in the end concluded that we needed to build a new real-time stream data processing system. This paper presents the design and implementation of this new system called Heron. Heron is now the de facto stream data processing engine inside Twitter and in this paper we also share our experiences from running Heron in production. In this paper we also provide empirical evidence demonstrating the efficiency and scalability of Heron.;
Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data;Just as open standards and open software rocked the networking and computing industry open spectrum is poised to be a disruptive force in the use of radio spectrum for communications. At the same time open spectrum will be a major element that helps continue the Internetâ€™s march to integrate and facilitate all electronic communications with open standards and commodity hardware.;
Postmortem Debugging in Dynamic Environments: Modern dynamic languages lack tools for understanding software failures.;"Despite the best efforts of software engineers to produce high-quality software inevitably some bugs escape even the most rigorous testing process and are first encountered by end users. When this happens such failures must be understood quickly the underlying bugs fixed and deployments patched to avoid another user (or the same one) running into the same problem again. As far back as 1951 the dawn of modern computing Stanley Gill wrote that some attention has therefore been given to the problem of dealing with mistakes after the programme has been tried and found to fail."" Gill went on to describe the first use of ""the post-mortem technique"" in software whereby the running program was modified to record important system state as it ran so that the programmer could later understand what happened and why the software failed.""";
How Will Astronomy Archives Survive the Data Tsunami? Astronomers are collecting more data than ever. What practices can keep them ahead of the flood?;Astronomy is already awash with data: currently 1 PB of public data is electronically accessible and this volume is growing at 0.5 PB per year. The availability of this data has already transformed research in astronomy and the STScI now reports that more papers are published with archived data sets than with newly acquired data. This growth in data size and anticipated usage will accelerate in the coming few years as new projects such as the LSST ALMA and SKA move into operation. These new projects will use much larger arrays of telescopes and detectors or much higher data acquisition rates than are now used. Projections indicate that by 2020 more than 60 PB of archived data will be accessible to astronomers.;
A domain-specific architecture for deep neural networks;Tensor processing units improve performance per watt of neural networks in Google datacenters by roughly 50x.;
Sound index: charts for the people by the people;Mining the wisdom of the online crowds generates music business intelligence identifying what's hot and what's not.;
Towards Individuated Reading Experiences: Different Fonts Increase Reading Speed for Different Individuals;In our age of ubiquitous digital displays adults often read in short opportunistic interludes. In this context of Interlude Reading we consider if manipulating font choice can improve adult readersâ€™ reading outcomes. Our studies normalize font size by human perception and use hundreds of crowdsourced participants to provide a foundation for understanding which fonts people prefer and which fonts make them more effective readers. Participantsâ€™ reading speeds (measured in words-per-minute (WPM)) increased by 35% when comparing fastest and slowest fonts without affecting reading comprehension. High WPM variability across fonts suggests that one font does not fit all. We provide font recommendations related to higher reading speed and discuss the need for individuation allowing digital devices to match their readersâ€™ needs in the moment. We provide recommendations from one of the most significant online reading efforts to date. To complement this we release our materials and tools with this article.;
You Donâ€™t Know Jack about Network Performance: Bandwidth is only part of the problem.;Why does an application that works just fine over a LAN come to a grinding halt across the wide-area network? You may have experienced this firsthand when trying to open a document from a remote file share or remotely logging in over a VPN to an application running in headquarters. Why is it that an application that works fine in your office can become virtually useless over the WAN? If you think itâ€™s simply because thereâ€™s not enough bandwidth in the WAN then you donâ€™t know jack about network performance.;
Software Development with Code Maps: Could those ubiquitous hand-drawn code diagrams become a thing of the past?;To better understand how professional software developers use visual representations of their code we interviewed nine developers at Microsoft to identify common scenarios and then surveyed more than 400 developers to understand the scenarios more deeply.;
Human-level intelligence or animal-like abilities?;What just happened in artificial intelligence and how it is being misunderstood.;
Human mobility characterization from cellular network data;Anonymous location data from cellular phone networks sheds light on how people move around on a large scale.;
Never-ending learning;Whereas people learn many different types of knowledge from diverse experiences over many years and become better learners over time most current machine learning systems are much more narrow learning just a single function or data model based on statistical analysis of a single data set. We suggest that people learn better than computers precisely because of this difference and we suggest a key direction for machine learning research is to develop software architectures that enable intelligent agents to also learn many types of knowledge continuously over many years and to become better learners over time. In this paper we define more precisely this never-ending learning paradigm for machine learning and we present one case study: the Never-Ending Language Learner (NELL) which achieves a number of the desired properties of a never-ending learner. NELL has been learning to read the Web 24hrs/day since January 2010 and so far has acquired a knowledge base with 120mn diverse confidence-weighted beliefs (e.g. servedWith(teabiscuits)) while learning thousands of interrelated functions that continually improve its reading competence over time. NELL has also learned to reason over its knowledge base to infer new beliefs it has not yet read from those it has and NELL is inventing new relational predicates to extend the ontology it uses to represent beliefs. We describe the design of NELL experimental results illustrating its behavior and discuss both its successes and shortcomings as a case study in never-ending learning. NELL can be tracked online at http://rtw.ml.cmu.edu and followed on Twitter at @CMUNELL.;
Crash Consistency: Rethinking the Fundamental Abstractions of the File System;The reading and writing of data one of the most fundamental aspects of any Von Neumann computer is surprisingly subtle and full of nuance. For example consider access to a shared memory in a system with multiple processors. While a simple and intuitive approach known as strong consistency is easiest for programmers to understand many weaker models are in widespread use (e.g. x86 total store ordering) such approaches improve system performance but at the cost of making reasoning about system behavior more complex and error-prone. Fortunately a great deal of time and effort has gone into thinking about such memory models and as a result most multiprocessor applications are not caught unaware.;
Does deterrence work in reducing information security policy abuse by employees?;Methods for evaluating and effectively managing the security behavior of employees.;
Spicing Up Dart with Side Effects: A set of extensions to the Dart programming language designed to support asynchrony and generator functions;The Dart programming language has recently incorporated a set of extensions designed to support asynchrony and generator functions. Because Dart is a language for Web programming latency is an important concern. To avoid blocking developers must make methods asynchronous when computing their results requires nontrivial time. Generator functions ease the task of computing iterable sequences.;
Leaking Space: Eliminating memory hogs;A space leak occurs when a computer program uses more memory than necessary. In contrast to memory leaks where the leaked memory is never released the memory consumed by a space leak is released but later than expected. This article presents example space leaks and how to spot and eliminate them.;
Halide: decoupling algorithms from schedules for high-performance image processing;Writing high-performance code on modern machines requires not just locally optimizing inner loops but globally reorganizing computations to exploit parallelism and locality---doing things such as tiling and blocking whole pipelines to fit in cache. This is especially true for image processing pipelines where individual stages do much too little work to amortize the cost of loading and storing results to and from off-chip memory. As a result the performance difference between a naive implementation of a pipeline and one globally optimized for parallelism and locality is often an order of magnitude. However using existing programming tools writing high-performance image processing code requires sacrificing simplicity portability and modularity. We argue that this is because traditional programming models conflate the computations defining the algorithm with decisions about intermediate storage and the order of computation which we call the schedule.We propose a new programming language for image processing pipelines called Halide that separates the algorithm from its schedule. Programmers can change the schedule to express many possible organizations of a single algorithm. The Halide compiler then synthesizes a globally combined loop nest for an entire algorithm given a schedule. Halide models a space of schedules which is expressive enough to describe organizations that match or outperform state-of-the-art hand-written implementations of many computational photography and computer vision algorithms. Its model is simple enough to do so often in only a few lines of code and small changes generate efficient implementations for x86 ARM Graphics Processors (GPUs) and specialized image processors all from a single algorithm.Halide has been public and open source for over four years during which it has been used by hundreds of programmers to deploy code to tens of thousands of servers and hundreds of millions of phones processing billions of images every day.;
A conversation with David E. Shaw;Stanford professor Pat Hanrahan sits down with the noted hedge fund founder computational biochemist and (above all) computer scientist.;
Designing games with a purpose;Data generated as a side effect of game play also solves computational problems and trains AI algorithms.;
Future Internet architecture: clean-slate versus evolutionary research;Should researchers focus on designing new network architectures or improving the current Internet?;
Lamboozling Attackers: A New Generation of Deception: Software engineering teams can exploit attackers' human nature by building deception environments.;The goal of this article is to educate software leaders engineers and architects on the potential of deception for systems resilience and the practical considerations for building deception environments. By examining the inadequacy and stagnancy of historical deception efforts by the information security community the article also demonstrates why engineering teams are now poised to become significantly more successful owners of deception systems.;
LIBSVM: A library for support vector machines;LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.;
Uninitialized Reads: Understanding the proposed revisions to the C language;Most developers understand that reading uninitialized variables in C is a defect but some do it anyway. What happens when you read uninitialized objects is unsettled in the current version of the C standard (C11).3 Various proposals have been made to resolve these issues in the planned C2X revision of the standard. Consequently this is a good time to understand existing behaviors as well as proposed revisions to the standard to influence the evolution of the C language. Given that the behavior of uninitialized reads is unsettled in C11 prudence dictates eliminating uninitialized reads from your code.;
A view of the parallel computing landscape;Writing programs that scale with increasing numbers of cores should be as easy as writing programs for sequential computers.;
Toward Software-defined SLAs: Enterprise computing in the public cloud;The public cloud has introduced new technology and architectures that could reshape enterprise computing. In particular the public cloud is a new design center for enterprise applications platform software and services. API-driven orchestration of large-scale on-demand resources is an important new design attribute which differentiates public-cloud from conventional enterprise data-center infrastructure. Enterprise applications must adapt to the new public-cloud design center but at the same time new software and system design patterns can add enterprise attributes and service levels to public-cloud services.;
Use-Case 2.0: The Hub of Software Development;Use cases have been around for almost 30 years as a requirements approach and have been part of the inspiration for more-recent techniques such as user stories. Now the inspiration has flown in the other direction. Use-Case 2.0 is the new generation of use-case-driven development-light agile and lean-inspired by user stories and the agile methodologies Scrum and Kanban.;
UX design and agile: a natural fit?;Talking with Julian Gosper Jean-Luc Agathos Richard Rutter and Terry Coatta.;
Making the Mobile Web Faster: Mobile performance issues? Fix the back end not just the client.;Mobile clients have been on the rise and will only continue to grow. This means that if you are serving clients over the Internet you cannot ignore the customer experience on a mobile device. There are many informative articles on mobile performance and just as many on general API design but youâ€™ll find few discussing the design considerations needed to optimize the back-end systems for mobile clients. Whether you have an app mobile Web site or both it is likely that these clients are consuming APIs from your back-end systems. Certainly optimizing the on-mobile performance of the application is critical but software engineers can do a lot to ensure that mobile clients are remotely served both data and application resources reliably and efficiently.;
Formally verified software in the real world;Verified software secures the Unmanned Little Bird autonomous helicopter against mid-flight cyber attacks.;
Spotify guilds;When the value increases engagement engagement increases the value.;
Domain-specific hardware accelerators;DSAs gain efficiency from specialization and performance from parallelism.;
Testable System Administration: Models of indeterminism are changing IT management.;The methods of system administration have changed little in the past 20 years. While core IT technologies have improved in a multitude of ways for many if not most organizations system administration is still based on production-line build logistics (aka provisioning) and reactive incident handling. As we progress into an information age humans will need to work less like the machines they use and embrace knowledge-based approaches. That means exploiting simple (hands-free) automation that leaves us unencumbered to discover patterns and make decisions. This goal is reachable if IT itself opens up to a core challenge of automation that is long overdue: namely how to abandon the myth of determinism and expect the unexpected.;
Stream Processors: Progammability and Efficiency: Will this new kid on the block muscle out ASIC and DSP?;Many signal processing applications require both efficiency and programmability. Baseband signal processing in 3G cellular base stations for example requires hundreds of GOPS (giga or billions of operations per second) with a power budget of a few watts an efficiency of about 100 GOPS/W (GOPS per watt) or 10 pJ/op (picoJoules per operation). At the same time programmability is needed to follow evolving standards to support multiple air interfaces and to dynamically provision processing resources over different air interfaces. Digital television surveillance video processing automated optical inspection and mobile cameras camcorders and 3G cellular handsets have similar needs.;
Machine Learning in Mental Health: A Systematic Review of the HCI Literature to Support the Development of Effective and Implementable ML Systems;High prevalence of mental illness and the need for effective mental health care combined with recent advances in AI has led to an increase in explorations of how the field of machine learning (ML) can assist in the detection diagnosis and treatment of mental health problems. ML techniques can potentially offer new routes for learning patterns of human behavior identifying mental health symptoms and risk factors developing predictions about disease progression and personalizing and optimizing therapies. Despite the potential opportunities for using ML within mental health this is an emerging research area and the development of effective ML-enabled applications that are implementable in practice is bound up with an array of complex interwoven challenges. Aiming to guide future research and identify new directions for advancing development in this important domain this article presents an introduction to and a systematic review of current ML work regarding psycho-socially based mental health conditions from the computing and HCI literature. A quantitative synthesis and qualitative narrative review of 54 papers that were included in the analysis surfaced common trends gaps and challenges in this space. Discussing our findings we (i) reflect on the current state-of-the-art of ML work for mental health (ii) provide concrete suggestions for a stronger integration of human-centered and multi-disciplinary approaches in research and development and (iii) invite more consideration of the potentially far-reaching personal social and ethical implications that ML models and interventions can have if they are to find widespread successful adoption in real-world mental health contexts.;
Why Cloud Computing Will Never Be Free: The competition among cloud providers may drive prices downward but at what cost?;The last time the IT industry delivered outsourced shared-resource computing to the enterprise was with timesharing in the 1980s when it evolved to a high art delivering the reliability performance and service the enterprise demanded. Today cloud computing is poised to address the needs of the same market based on a revolution of new technologies significant unused computing capacity in corporate data centers and the development of a highly capable Internet data communications infrastructure. The economies of scale of delivering computing from a centralized shared infrastructure have set the expectation among customers that cloud-computing costs will be significantly lower than those incurred from providing their own computing. Together with the reduced deployment costs of open source software and the perfect competition characteristics of remote computing these expectations set the stage for fierce pressure on cloud providers to continuously lower prices.;
(Computer) vision without sight;Computer vision holds the key for the blind or visually impaired to explore the visual world.;
Hard Disk Drives: The Good the Bad and the Ugly! HDDs are like the bread in a peanut butter and jelly sandwich.;HDDs are like the bread in a peanut butter and jelly sandwichâ€”sort of an unexciting piece of hardware necessary to hold the â€œsoftware.â€ They are simply a means to an end. HDD reliability however has always been a significant weak link perhaps the weak link in data storage. In the late 1980s people recognized that HDD reliability was inadequate for large data storage systems so redundancy was added at the system level with some brilliant software algorithms and RAID (redundant array of inexpensive disks) became a reality. RAID moved the reliability requirements from the HDD itself to the system of data disks. Commercial implementations of RAID range from n+1 configurations (mirroring) to the more common RAID-4 and RAID-5 and recently to RAID-6 the n+2 configuration that increases storage system reliability using two redundant disks (dual parity). Additionally reliability at the RAID group level has been favorably enhanced because HDD reliability has been improving as well.;
Hadoop Superlinear Scalability: The perpetual motion of parallel performance;We often see more than 100 percent speedup efficiency! came the rejoinder to the innocent reminder that you canâ€™t have more than 100 percent of anything. But this was just the first volley from software engineers during a presentation on how to quantify computer system scalability in terms of the speedup metric. In different venues on subsequent occasions that retort seemed to grow into a veritable chorus that not only was superlinear speedup commonly observed but also the model used to quantify scalability for the past 20 years failed when applied to superlinear speedup data.;
Scene understanding by labeling pixels;Pixels labeled with a scene's semantics and geometry let computers describe what they see.;
Computing without processors;Heterogeneous systems allow us to target our programming to the appropriate environment.;
Thriving in a crowded and changing world: C++ 2006â€“2020;By 2006 C++ had been in widespread industrial use for 20 years. It contained parts that had survived unchanged since introduced into C in the early 1970s as well as features that were novel in the early 2000s. From 2006 to 2020 the C++ developer community grew from about 3 million to about 4.5 million. It was a period where new programming models emerged hardware architectures evolved new application domains gained massive importance and quite a few well-financed and professionally marketed languages fought for dominance. How did C++ -- an older language without serious commercial backing -- manage to thrive in the face of all that?  This paper focuses on the major changes to the ISO C++ standard for the 2011 2014 2017 and 2020 revisions. The standard library is about 3/4 of the C++20 standard but this paper's primary focus is on language features and the programming techniques they support.  The paper contains long lists of features documenting the growth of C++. Significant technical points are discussed and illustrated with short code fragments. In addition it presents some failed proposals and the discussions that led to their failure. It offers a perspective on the bewildering flow of facts and features across the years. The emphasis is on the ideas people and processes that shaped the language.  Themes include efforts to preserve the essence of C++ through evolutionary changes to simplify its use to improve support for generic programming to better support compile-time programming to extend support for concurrency and parallel programming and to maintain stable support for decades' old code.  The ISO C++ standard evolves through a consensus process. Inevitably there is competition among proposals and clashes (usually polite ones) over direction design philosophies and principles. The committee is now larger and more active than ever with as many as 250 people turning up to week-long meetings three times a year and many more taking part electronically. We try (not always successfully) to mitigate the effects of design by committee bureaucratic paralysis and excessive enthusiasm for a variety of language fashions.  Specific language-technical topics include the memory model concurrency and parallelism compile-time computation move-semantics exceptions lambda expressions and modules. Designing a mechanism for specifying a template's requirements on its arguments that is sufficiently flexible and precise yet doesn't impose run-time costs turned out to be hard. The repeated attempts to design ``concepts'' to do that have their roots back in the 1980s and touch upon many key design issues for C++ and for generic programming.  The description is based on personal participation in the key events and design decisions backed by the thousands of papers and hundreds of meeting minutes in the ISO C++ standards committee's archives.;
Data-Parallel Computing: Data parallelism is a key concept in leveraging the power of todayâ€™s manycore GPUs.;Users always care about performance. Although often itâ€™s just a matter of making sure the software is doing only what it should there are many cases where it is vital to get down to the metal and leverage the fundamental characteristics of the processor.;
DevOps Metrics: Your biggest mistake might be collecting the wrong data.;Delivering value to the business through software requires processes and coordination that often span multiple teams across complex systems and involves developing and delivering software with both quality and resiliency. As practitioners and professionals we know that software development and delivery is an increasingly difficult art and practice and that managing and improving any process or system requires insights into that system. Therefore measurement is paramount to creating an effective software value stream. Yet accurate measurement is no easy feat.;
The Seattle report on database research;Every five years a group of the leading database researchers meet to reflect on their community's impact on the computing industry as well as examine current research challenges.;
Simplicity Betrayed: Emulating a video system shows how even a simple interface can be more complexâ€”and capableâ€”than it appears.;"An emulator is a program that runs programs built for different computer architectures from the host platform that supports the emulator. Approaches differ but most emulators simulate the original hardware in some way. At a minimum the emulator interprets the original CPU instructions and provides simulated hardware-level devices for input and output. For example keyboard input is taken from the host platform and translated into the original hardware format resulting in the emulated program seeing"" the same sequence of keystrokes. Conversely the emulator will translate the original hardware screen format into an equivalent form on the host machine.""";
A Survey on Bias and Fairness in Machine Learning;With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions thus it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey we investigated different real-world applications that have shown biases in various ways and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.;
Why Your Data Wonâ€™t Mix: New tools and techniques can help ease the pain of reconciling schemas.;When independent parties develop database schemas for the same domain they will almost always be quite different from each other. These differences are referred to as semantic heterogeneity which also appears in the presence of multiple XML documents Web services and ontologiesâ€”or more broadly whenever there is more than one way to structure a body of data. The presence of semi-structured data exacerbates semantic heterogeneity because semi-structured schemas are much more flexible to start with. For multiple data systems to cooperate with each other they must understand each otherâ€™s schemas. Without such understanding the multitude of data sources amounts to a digital version of the Tower of Babel.;
A Primer on Provenance: Better understanding of data requires tracking its history and context.;Assessing the quality or validity of a piece of data is not usually done in isolation. You typically examine the context in which the data appears and try to determine its original sources or review the process through which it was created. This is not so straightforward when dealing with digital data however: the result of a computation might have been derived from numerous sources and by applying complex successive transformations possibly over long periods of time.;
Synthesis of trustable ICs using untrusted CAD tools;We have developed the first technique for synthesis of trustable ICs using untrusted CAD tools. The approach enables the use of CAD tools for difficult synthesis tasks and very simple trusted tools developed by the designer for checking results and modifying specifications. The main idea is to specify the pertinent design in such a way that there is no room for the untrusted tool to add any malicious circuitry.;
Proceedings of the 47th Design Automation Conference;"The obvious advantage to wireless communication over wired is as they say in the real estate business location location location. Individuals and industries choose wireless because it allows flexibility of location--whether that means mobility portability or just ease of installation at a fixed point. The challenge of wireless communication is that unlike the mostly error-free transmission environments provided by cables the environment that wireless communications travel through is unpredictable. Environmental radio-frequency (RF) noise"" produced by powerful motors other wireless devices microwaves--and even the moisture content in the air--can make wireless communication unreliable.""";
Provenance in Sensor Data Management: A cohesive independent solution for bringing provenance to scientific research;In todayâ€™s information-driven workplaces data is constantly being moved around and undergoing transformation. The typical business-as-usual approach is to use e-mail attachments shared network locations databases and more recently the cloud. More often than not there are multiple versions of the data sitting in different locations and users of this data are confounded by the lack of metadata describing its provenance or in other words its lineage. The ProvDMS project at the Oak Ridge National Laboratory (ORNL) described in this article aims to solve this issue in the context of sensor data.;
Making machine learning robust against adversarial inputs;Such inputs distort how machine-learning-based systems are able to function in the world as it is.;
On Plug-ins and Extensible Architectures: Extensible application architectures such as Eclipse offer many advantages but one must be careful to avoid â€œplug-in hell.â€;In a world of increasingly complex computing requirements we as software developers are continually searching for that ultimate universal architecture that allows us to productively develop high-quality applications. This quest has led to the adoption of many new abstractions and tools. Some of the most promising recent developments are the new pure plug-in architectures. What began as a callback mechanism to extend an application has become the very foundation of applications themselves. Plug-ins are no longer just add-ons to applications todayâ€™s applications are made entirely of plug-ins. This field has matured quite a bit in the past few years with significant contributions from a number of successful projects.;
Eulerian video magnification and analysis;The world is filled with important but visually subtle signals. A person's pulse the breathing of an infant the sag and sway of a bridge---these all create visual patterns which are too difficult to see with the naked eye. We present Eulerian Video Magnification a computational technique for visualizing subtle color and motion variations in ordinary videos by making the variations larger. It is a microscope for small changes that are hard or impossible for us to see by ourselves. In addition these small changes can be quantitatively analyzed and used to recover sounds from vibrations in distant objects characterize material properties and remotely measure a person's pulse.;
Who does what in a massive open online course?;Student-participation data from the inaugural MITx (now edX) course---6.002x: Circuits and Electronics---unpacks MOOC student behavior.;
System Administration Soft Skills: How can system administrators reduce stress and conflict in the workplace?;System administration can be both stressful and rewarding. Stress generally comes from outside factors such as conflict between SAs (system administrators) and their colleagues a lack of resources a high-interrupt environment conflicting priorities and SAs being held responsible for failures outside their control. What can SAs and their managers do to alleviate the stress? There are some well-known interpersonal and time-management techniques that can help but these can be forgotten in times of crisis or just through force of habit. The purpose of this article is to restate these maxims and remind readers of these important soft skills particularly as they apply to SAs.;
The pushback effects of race ethnicity gender and age in code review;Research shows that White male and younger engineers receive less pushback than those in other demographics.;
Unlocking Concurrency: Multicore programming with transactional memory;Multicore architectures are an inflection point in mainstream software development because they force developers to write parallel programs. In a previous article in Queue Herb Sutter and James Larus pointed out â€œThe concurrency revolution is primarily a software revolution. The difficult problem is not building multicore hardware but programming it in a way that lets mainstream applications benefit from the continued exponential growth in CPU performance.â€ In this new multicore world developers must write explicitly parallel applications that can take advantage of the increasing number of cores that each successive multicore generation will provide.;
Big Games Small Screens: Developing 3D games for mobile devices is full of challenges but the rich evolving toolset enables some stunning results.;One thing that becomes immediately apparent when creating and distributing mobile 3D games is that there are fundamental differences between the cellphone market and the more traditional games markets such as consoles and handheld gaming devices. The most striking of these are the number of delivery platforms the severe constraints of the devices including small screens whose orientation can be changed limited input controls the need to deal with other tasks the nonphysical delivery mechanism and the variations in handset performance and input capability.;
Improving performance on the internet;Given the Internet's bottlenecks how can we build fast scalable content-delivery systems?;
GPUs: A Closer Look: As the line between GPUs and CPUs begins to blur itâ€™s important to understand what makes GPUs tick.;A gamer wanders through a virtual world rendered in near- cinematic detail. Seconds later the screen fills with a 3D explosion the result of unseen enemies hiding in physically accurate shadows. Disappointed the user exits the game and returns to a computer desktop that exhibits the stylish 3D look-and-feel of a modern window manager. Both of these visual experiences require hundreds of gigaflops of computing performance a demand met by the GPU (graphics processing unit) present in every consumer PC.;
Understanding throughput-oriented architectures;For workloads with abundant parallelism GPUs deliver higher peak computational throughput than latency-oriented CPUs.;
Best Practice: Application Frameworks: While powerful frameworks are not for everyone.;While frameworks can be a powerful tool they have some disadvantages and may not make sense for all organizations. Framework maintainers need to provide standardization and well-defined behavior while not being overly prescriptive. When frameworks strike the right balance however they can offer large developer productivity gains. The consistency provided by widespread use of frameworks is a boon for other teams such as SRE and security that have a vested interest in the quality of applications. Additionally the structure of frameworks provides a foundation for building higher-level abstractions such as microservices platforms which unlock new opportunities for system architecture and automation. At Google such frameworks and platforms have seen broad organic adoption and have had a significant positive impact.;
Identity management and privacy: a rare opportunity to get it right;The National Strategy for Trusted Identities in Cyberspace represents a shift in the way the U.S. government is approaching identity management privacy and the Internet.;
Network Virtualization: Breaking the Performance Barrier: Shared I/O in virtualization platforms has come a long way but performance concerns remain.;The recent resurgence in popularity of virtualization has led to its use in a growing number of contexts many of which require high-performance networking. Consider server consolidation for example. The efficiency of network virtualization directly impacts the number of network servers that can effectively be consolidated onto a single physical machine. Unfortunately modern network virtualization techniques incur significant overhead which limits the achievable network performance. We need new network virtualization techniques to realize the full benefits of virtualization in network-intensive domains.;
Abstraction in Hardware System Design: Applying lessons from software languages to hardware languages using Bluespec SystemVerilog;The history of software engineering is one of continuing development of abstraction mechanisms designed to tackle ever-increasing complexity. Hardware design however is not as current. For example the two most commonly used HDLs date back to the 1980s. Updates to the standards lag behind modern programming languages in structural abstractions such as types encapsulation and parameterization. Their behavioral semantics lag even further. They are specified in terms of event-driven simulators running on uniprocessor von Neumann machines.;
Securing the Tangled Web: Preventing script injection vulnerabilities through software design;Script injection vulnerabilities are a bane of Web application development: deceptively simple in cause and remedy they are nevertheless surprisingly difficult to prevent in large-scale Web development.;
OCaml for the masses;Why the next language you learn should be functional.;
Reading news with maps by exploiting spatial synonyms;Use this map query interface to search the world even when not sure what information you seek.;
Beyond total capture: a constructive critique of lifelogging;Rather than try to capture everything system design should focus on the psychological basis of human memory.;
The impact of information technology on energy consumption and carbon emissions;In this article the authors evaluate the impact of different sectors of information and communication technologies (ICT) on energy consumption and CO2 emissions. ICT is understood to cover computer and peripheral equipment including local area networks telecommunication equipment and networks and data centers.;
Designing Cluster Schedulers for Internet-Scale Services: Embracing failures for improving availability;Engineers looking to build scheduling systems should consider all failure modes of the underlying infrastructure they use and consider how operators of scheduling systems can configure remediation strategies while aiding in keeping tenant systems as stable as possible during periods of troubleshooting by the owners of the tenant systems.;
Code Spelunking: Exploring Cavernous Code Bases: Code diving through unfamiliar source bases is something we do far more often than write new code from scratch--make sure you have the right gear for the job.;Try to remember your first day at your first software job. Do you recall what you were asked to do after the human resources people were done with you? Were you asked to write a piece of fresh code? Probably not. It is far more likely that you were asked to fix a bug or several and to try to understand a large poorly documented collection of source code. Of course this doesnâ€™t just happen to new graduates it happens to all of us whenever we start a new job or look at a new piece of code. With experience we all develop a set of techniques for working with large unfamiliar source bases. This is what I call code spelunking.;
Security Analysis of SMS as a Second Factor of Authentication: The challenges of multifactor authentication based on SMS including cellular security deficiencies SS7 exploits and SIM swapping;Despite their popularity and ease of use SMS-based authentication tokens are arguably one of the least secure forms of two-factor authentication. This does not imply however that it is an invalid method for securing an online account. The current security landscape is very different from that of two decades ago. Regardless of the critical nature of an online account or the individual who owns it using a second form of authentication should always be the default option regardless of the method chosen. In the wake of a large number of leaks and other intrusions there are many username and password combinations out there in the wrong hands that make password spraying attacks cheap and easy to accomplish.;
Blockchain Technology: What Is It Good for? Industryâ€™s dreams and fears for this new technology;Business executives government leaders investors and researchers frequently ask the following three questions: (1) What exactly is blockchain technology? (2) What capabilities does it provide? (3) What are good applications? Here we answer these questions thoroughly provide a holistic overview of blockchain technology that separates hype from reality and propose a useful lexicon for discussing the specifics of blockchain technology in the future.;
Visualizing system latency;Heat maps are a unique and powerful way to visualize latency data. Explaining the results however is an ongoing challenge.;
Monitoring in a DevOps World: Perfect should never be the enemy of better.;Monitoring can seem quite overwhelming. The most important thing to remember is that perfect should never be the enemy of better. DevOps enables highly iterative improvement within organizations. If you have no monitoring get something get anything. Something is better than nothing and if youâ€™ve embraced DevOps youâ€™ve already signed up for making it better over time.;
Beyond Server Consolidation: Server consolidation helps companies improve resource utilization but virtualization can help in other ways too.;Virtualization technology was developed in the late 1960s to make more efficient use of hardware. Hardware was expensive and there was not that much available. Processing was largely outsourced to the few places that did have computers. On a single IBM System/360 one could run in parallel several environments that maintained full isolation and gave each of its customers the illusion of owning the hardware. Virtualization was time sharing implemented at a coarse-grained level and isolation was the key achievement of the technology. It also provided the ability to manage resources efficiently as they would be assigned to virtual machines such that deadlines could be met and a certain quality of service could be achieved.;
Challenges of Memory Management on Modern NUMA System: Optimizing NUMA systems applications with Carrefour;Modern server-class systems are typically built as several multicore chips put together in a single system. Each chip has a local DRAM (dynamic random-access memory) module together they are referred to as a node. Nodes are connected via a high-speed interconnect and the system is fully coherent. This means that transparently to the programmer a core can issue requests to its nodeâ€™s local memory as well as to the memories of other nodes. The key distinction is that remote requests will take longer because they are subject to longer wire delays and may have to jump several hops as they traverse the interconnect. The latency of memory-access times is hence non-uniform because it depends on where the request originates and where it is destined to go. Such systems are referred to as NUMA (non-uniform memory access).;
Idle-Time Garbage-Collection Scheduling: Taking advantage of idleness to reduce dropped frames and memory consumption;Googleâ€™s Chrome web browser strives to deliver a smooth user experience. An animation will update the screen at 60 FPS (frames per second) giving Chrome around 16.6 milliseconds to perform the update. Within these 16.6 ms all input events have to be processed all animations have to be performed and finally the frame has to be rendered. A missed deadline will result in dropped frames. These are visible to the user and degrade the user experience. Such sporadic animation artifacts are referred to here as jank. This article describes an approach implemented in the JavaScript engine V8 used by Chrome to schedule garbage-collection pauses during times when Chrome is idle. This approach can reduce user-visible jank on real-world web pages and results in fewer dropped frames.;
Is Open Source Right for You? A fictional case study of open source in a commercial software shop;The media often present open source software as a direct competitor to commercial software. This depiction usually pitting David (Linux) against Goliath (Microsoft) makes for fun reading in the weekend paper. However it mostly misses the point of what open source means to a development organization. In this article I use the experiences of GizmoSoft (a fictitious software company) to present some perspectives on the impact of open source software usage in a software development shop.;
Improving Performance on the Internet: Given the Internetâ€™s bottlenecks how can we build fast scalable content-delivery systems?;When it comes to achieving performance reliability and scalability for commercial-grade Web applications where is the biggest bottleneck? In many cases today we see that the limiting bottleneck is the middle mile or the time data spends traveling back and forth across the Internet between origin server and end user.;
Heterogeneous Graph Neural Network;"Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction personalized recommendation node classification etc. This task however is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges but also due to the need for considering heterogeneous attributes or contents (e.g. text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding attributed graph embedding as well as graph neural networks few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper we propose HetGNN a heterogeneous graph neural network model to resolve this issue. Specifically we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes deep"" feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks i.e. link prediction recommendation node classification &amp clustering and inductive node classification &amp clustering.""";
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Giant monolithic source-code repositories are one of the fundamental pillars of the back end infrastructure in large and fast-paced software companies. The sheer volume of everyday code changes demands a reliable and efficient change management system with three uncompromisable key requirements --- always green master high throughput and low commit turnaround time. Green refers to a master branch that always successfully compiles and passes all build steps the opposite being red. A broken master (red) leads to delayed feature rollouts because a faulty code commit needs to be detected and rolled backed. Additionally a red master has a cascading effect that hampers developer productivity--- developers might face local test/build failures or might end up working on a codebase that will eventually be rolled back.This paper presents the design and implementation of SubmitQueue. It guarantees an always green master branch at scale: all build steps (e.g. compilation unit tests UI tests) successfully execute for every commit point. SubmitQueue has been in production for over a year and can scale to thousands of daily commits to giant monolithic repositories.;
Proceedings of the Fourteenth EuroSys Conference 2019;"Compose dream tools"" from continuously evolving bundles of software to make sense of complex scientific data sets.""";
Anton a special-purpose machine for molecular dynamics simulation;The ability to perform long accurate molecular dynamics (MD) simulations involving proteins and other biological macro-molecules could in principle provide answers to some of the most important currently outstanding questions in the fields of biology chemistry and medicine. A wide range of biologically interesting phenomena however occur over timescales on the order of a millisecond---several orders of magnitude beyond the duration of the longest current MD simulations.We describe a massively parallel machine called Anton which should be capable of executing millisecond-scale classical MD simulations of such biomolecular systems. The machine which is scheduled for completion by the end of 2008 is based on 512 identical MD-specific ASICs that interact in a tightly coupled manner using a specialized highspeed communication network. Anton has been designed to use both novel parallel algorithms and special-purpose logic to dramatically accelerate those calculations that dominate the time required for a typical MD simulation. The remainder of the simulation algorithm is executed by a programmable portion of each chip that achieves a substantial degree of parallelism while preserving the flexibility necessary to accommodate anticipated advances in physical models and simulation methods.;
TCP Offload to the Rescue: Getting a toehold on TCP offload enginesâ€”and why we need them;In recent years TCP/IP offload engines known as TOEs have attracted a good deal of industry attention and a sizable share of venture capital dollars. A TOE is a specialized network device that implements a significant portion of the TCP/IP protocol in hardware thereby offloading TCP/IP processing from software running on a general-purpose CPU. This article examines the reasons behind the interest in TOEs and looks at challenges involved in their implementation and deployment.;
"Benchmarking Hello World!"": Six different views of the execution of ""Hello World!"" show what is often missing in todayâ€™s tools""";As more and more software moves off the desktop and into data centers and more and more cell phones use server requests as the other half of apps observation tools for large-scale distributed transaction systems are not keeping up. This makes it tempting to look under the lamppost using simpler tools. You will waste a lot of high-pressure time following that path when you have a sudden complex performance crisis. Instead know what each tool you use is blind to know what information you need to understand a performance problem and then look for tools that can actually observe that information directly.;
Cybercrime: An Epidemic: Who commits these crimes and what are their motivations?;Painted in the broadest of strokes cybercrime essentially is the leveraging of information systems and technology to commit larceny extortion identity theft fraud and in some cases corporate espionage. Who are the miscreants who commit these crimes and what are their motivations? One might imagine they are not the same individuals committing crimes in the physical world. Bank robbers and scam artists garner a certain public notoriety after only a few occurrences of their crimes yet cybercriminals largely remain invisible and unheralded. Based on sketchy news accounts and a few public arrests such as Mafiaboy accused of paralyzing Amazon CNN and other Web sites the public may infer these miscreants are merely a subculture of teenagers. In this article we provide insight into the root causes of cybercrime its participants and their motivations and we identify some of the issues inherent in dealing with this crime wave.;
System administration soft skills;How can system administrators reduce stress and conflict in the workplace?;
Open-source Firmware: Step into the world behind the kernel.;Open-source firmware can help bring computing to a more secure place by making the actions of firmware more visible and less likely to do harm. This articleâ€™s goal is to make readers feel empowered to demand more from vendors who can help drive this change.;
The rise of serverless computing;The server is dead long live the server.;
Building Systems to Be Shared Securely: Want to securely partition VMs? One option is to put â€™em in Jail.;The history of computing has been characterized by continuous transformation resulting from the dramatic increases in performance and drops in price described by Mooreâ€™s law. Computing power has migrated from centralized mainframes/servers to distributed systems and the commodity desktop. Despite these changes system sharing remains an important tool for computing. From the multitasking file-sharing and virtual machines of the desktop environment to the large-scale sharing of server-class ISP hardware in collocation centers safely sharing hardware between mutually untrusting parties requires addressing critical concerns of accidental and malicious damage.;
Data science: challenges and directions;While it may not be possible to build a data brain identical to a human data science can still aspire to imaginative machine thinking.;
The Snowflake Elastic Data Warehouse;"We live in the golden age of distributed computing. Public cloud platforms now offer virtually unlimited compute and storage resources on demand. At the same time the Software-as-a-Service (SaaS) model brings enterprise-class systems to users who previously could not afford such systems due to their cost and complexity. Alas traditional data warehousing systems are struggling to fit into this new environment. For one thing they have been designed for fixed resources and are thus unable to leverage the cloud's elasticity. For another thing their dependence on complex ETL pipelines and physical tuning is at odds with the flexibility and freshness requirements of the cloud's new types of semi-structured data and rapidly evolving workloads. We decided a fundamental redesign was in order. Our mission was to build an enterprise-ready data warehousing solution for the cloud. The result is the Snowflake Elastic Data Warehouse or Snowflake"" for short. Snowflake is a multi-tenant transactional secure highly scalable and elastic system with full SQL support and built-in extensions for semi-structured and schema-less data. The system is offered as a pay-as-you-go service in the Amazon cloud. Users upload their data to the cloud and can immediately manage and query it using familiar tools and interfaces. Implementation began in late 2012 and Snowflake has been generally available since June 2015. Today Snowflake is used in production by a growing number of small and large organizations alike. The system runs several million queries per day over multiple petabytes of data.In this paper we describe the design of Snowflake and its novel multi-cluster shared-data architecture. The paper highlights some of the key features of Snowflake: extreme elasticity and availability semi-structured and schema-less data time travel and end-to-end security. It concludes with lessons learned and an outlook on ongoing work.""";
Proceedings of the 2016 International Conference on Management of Data;The digital transformation is turning archives both old and new into data. As a consequence automation in the form of artificial intelligence techniques is increasingly applied both to scale traditional recordkeeping activities and to experiment with novel ways to capture organise and access records. We survey recent developments at the intersection of Artificial Intelligence and archival thinking and practice. Our overview of this growing body of literature is organised through the lenses of the Records Continuum model. We find four broad themes in the literature on archives and artificial intelligence: theoretical and professional considerations the automation of recordkeeping processes organising and accessing archives and novel forms of digital archives. We conclude by underlining emerging trends and directions for future work which include the application of recordkeeping principles to the very data and processes that power modern artificial intelligence and a more structuralâ€”yet critically awareâ€”integration of artificial intelligence into archival systems and practice.;
The most expensive one-byte mistake;Did Ken Dennis and Brian choose wrong with NUL-terminated text strings?;
What college could be like;Imagining an optimized education model.;
Getting What You Measure: Four common pitfalls in using software metrics for project management;Software metrics - helpful tools or a waste of time? For every developer who treasures these mathematical abstractions of software systems there is a developer who thinks software metrics are invented just to keep project managers busy. Software metrics can be very powerful tools that help achieve your goals but it is important to use them correctly as they also have the power to demotivate project teams and steer development in the wrong direction.;
Spanner: Googleâ€™s Globally Distributed Database;Spanner is Googleâ€™s scalable multiversion globally distributed and synchronously replicated database. It is the first system to distribute data at global scale and support externally-consistent distributed transactions. This article describes how Spanner is structured its feature set the rationale underlying various design decisions and a novel time API that exposes clock uncertainty. This API and its implementation are critical to supporting external consistency and a variety of powerful features: nonblocking reads in the past lock-free snapshot transactions and atomic schema changes across all of Spanner.;
Mind Your State for Your State of Mind: The interactions between storage and applications can be complex and subtle.;Applications have had an interesting evolution as they have moved into the distributed and scalable world. Similarly storage and its cousin databases have changed side by side with applications. Many times the semantics performance and failure models of storage and applications do a subtle dance as they change in support of changing business requirements and environmental challenges. Adding scale to the mix has really stirred things up. This article looks at some of these issues and their impact on systems.;
Making sense of revision-control systems;All revision-control systems come with complicated sets of trade-offs. How do you find the best match between tool and team?;
Voyage in the Agile Memeplex: In the world of agile development context is key.;Agile processes are not a technology not a science not a product. They constitute a space somewhat hard to define. Agile methods or more precisely agile software development methods or processes are a family of approaches and practices for developing software systems. Any attempt to define them runs into egos and marketing posturing. For our purposes here we can define this space in two ways: By enumeration. Pointing to recognizable members of the set: XP scrum lean development DSDM Crystal FDD Agile RUP or OpenUP etc.;
The Magic of RFID: Just how do those little things work anyway?;Many modern technologies give the impression they work by magic particularly when they operate automatically and their mechanisms are invisible. A technology called RFID (radio frequency identification) which is relatively new to the mass market has exactly this characteristic and for many people seems a lot like magic. RFID is an electronic tagging technology that allows an object place or person to be automatically identified at a distance without a direct line-of-sight using an electromagnetic challenge/response exchange. Typical applications include labeling products for rapid checkout at a point-of-sale terminal inventory tracking animal tagging timing marathon runners secure automobile keys and access control for secure facilities.;
The Evolution of Security: What can nature tell us about how best to manage our risks?;Security people are never in charge unless an acute embarrassment has occurred. Otherwise their advice is tempered by â€œeconomic realityâ€ which is to say that security is a means not an end. This is as it should be. Since means are about tradeoffs security is about trade-offs but you knew all that. Our tradeoff decisions can be hard to make and these hard-to-make decisions come in two varieties. One type occurs when the uncertainty of the alternatives is so great that they canâ€™t be sorted in terms of probable effect. As such other factors such as familiarity or convenience will drive the decision. This too is as it should be.;
A purpose-built global network: Google's move to SDN;A discussion with Amin Vahdat David Clark and Jennifer Rexford.;
Knowledge Graphs;In this article we provide a comprehensive introduction to knowledge graphs which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse dynamic large-scale collections of data. After some opening remarks we motivate and contrast various graph-based data models as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs.;
You Donâ€™t Know Jack About VoIP: The Communications they are a-changinâ€™.;Telecommunications worldwide has experienced a significant revolution over recent years. The long-held promise of network convergence is occurring at an increasing pace. This convergence of data voice and video using IP-based networks is delivering advanced services at lower cost across the spectrum including residential users business customers of varying sizes and service providers.;
Weapons of Mass Assignment: A Ruby on Rails app highlights some serious yet easily avoided security vulnerabilities.;In May 2010 during a news cycle dominated by usersâ€™ widespread disgust with Facebook privacy policies a team of four students from New York University published a request for $10000 in donations to build a privacy-aware Facebook alternative. The software Diaspora would allow users to host their own social networks and own their own data. The team promised to open-source all the code they wrote guaranteeing the privacy and security of usersâ€™ data by exposing the code to public scrutiny. With the help of front-page coverage from the New York Times the team ended up raising more than $200000. They anticipated launching the service to end users in October 2010.;
Toward Confidential Cloud Computing: Extending hardware-enforced cryptographic protection to data while in use;Although largely driven by economies of scale the development of the modern cloud also enables increased security. Large data centers provide aggregate availability reliability and security assurances. The operational cost of ensuring that operating systems databases and other services have secure configurations can be amortized among all tenants allowing the cloud provider to employ experts who are responsible for security this is often unfeasible for smaller businesses where the role of systems administrator is often conflated with many others.;
The API Performance Contract: How can the expected interactions between caller and implementation be guaranteed?;When you call functions in an API you expect them to work correctly sometimes this expectation is called a contract between the caller and the implementation. Callers also have performance expectations about these functions and often the success of a software system depends on the API meeting these expectations. So thereâ€™s a performance contract as well as a correctness contract. The performance contract is usually implicit often vague and sometimes breached (by caller or implementation). How can this aspect of API design and documentation be improved?;
Interactive intent modeling: information discovery beyond search;The system should let users incrementally direct their search toward relevant though not initially obvious information.;
Putting the 'smarts' into the smart grid: a grand challenge for artificial intelligence;A research agenda for making the smart grid a reality.;
Coding guidelines: finding the art in the science;What separates good code from great code?;
Formally verified mathematics;With the help of computational proof assistants formal verification could become the new standard for rigor in mathematics.;
Bigtable: A Distributed Storage System for Structured Data;Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable including web indexing Google Earth and Google Finance. These applications place very different demands on Bigtable both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands Bigtable has successfully provided a flexible high-performance solution for all of these Google products. In this article we describe the simple data model provided by Bigtable which gives clients dynamic control over data layout and format and we describe the design and implementation of Bigtable.;
XML &ltand Semi-Structured Data&gt: XML provides a natural representation for hierarchical structures and repeating fields or structures.;Vocabulary designers can require XML data to be perfectly regular or they can allow a little variation or a lot. In the extreme case an XML vocabulary can effectively say that there are no rules at all beyond those required of all well-formed XML. Because XML syntax records only what is present not everything that might be present sparse data does not make the XML representation awkward XML storage systems are typically built to handle sparse data gracefully.;
Open vs. Closed: Which source is more secure?;"There is no better way to start an argument among a group of developers than proclaiming Operating System A to be more secure"" than Operating System B. I know this from first-hand experience as previous papers I have published on this topic have led to reams of heated e-mails directed at me - including some that were quite literally physically threatening. Despite the heat (not light!) generated from attempting to investigate the relative security of different software projects investigate we must.""";
Why we twitter: understanding microblogging usage and communities;Microblogging is a new form of communication in which users can describe their current status in short posts distributed by instant messages mobile phones email or the Web. Twitter a popular microblogging tool has seen a lot of growth since it launched in October 2006. In this paper we present our observations of the microblogging phenomena by studying the topological and geographical properties of Twitter's social network. We find that people use microblogging to talk about their daily activities and to seek or share information. Finally we analyze the user intentions associated at a community level and show how users with similar intentions connect with each other.;
Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 Workshop on Web Mining and Social Network Analysis;To move forward with programming languages we must first break free from the tyranny of ASCII.;
Simplicity betrayed;Emulating a video system shows how even a simple interface can be more complex---and capable---than it appears.;
CTO Roundtable: Cloud Computing;The age of cloud computing has begun. How can companies take advantage of the new opportunities it provides?;
AI Gets a Brain: New technology allows software to tap real human intelligence.;In the 50 years since John McCarthy coined the term artificial intelligence much progress has been made toward identifying understanding and automating many classes of symbolic and computational problems that were once the exclusive domain of human intelligence. Much work remains in the field because humans still significantly outperform the most powerful computers at completing such simple tasks as identifying objects in photographs - something children can do even before they learn to speak.;
Federated Learning and Privacy: Building privacy-preserving systems for machine learning and data science on decentralized data;Centralized data collection can expose individuals to privacy risks and organizations to legal risks if data is not properly managed. Federated learning is a machine learning setting where multiple entities collaborate in solving a machine learning problem under the coordination of a central server or service provider. Each client's raw data is stored locally and not exchanged or transferred instead focused updates intended for immediate aggregation are used to achieve the learning objective. This article provides a brief introduction to key concepts in federated learning and analytics with an emphasis on how privacy technologies may be combined in real-world systems and how their use charts a path toward societal benefit from aggregate statistics in new domains and with minimized risk to individuals and to the organizations who are custodians of the data.;
Software model checking takes off;A translator framework enables the use of model checking in complex avionics systems and other industrial settings.;
JavaScript: the first 20 years;How a sidekick scripting language for Java created at Netscape in a ten-day hack ships first as a de facto Web standard and eventually becomes the world's most widely used programming language. This paper tells the story of the creation design evolution and standardization of the JavaScript language over the period of 1995--2015. But the story is not only about the technical details of the language. It is also the story of how people and organizations competed and collaborated to shape the JavaScript language which dominates the Web of 2020.;
Finding usability bugs with automated tests;Automated usability tests can be valuable companions to in-person tests.;
Why LINQ Matters: Cloud Composability Guaranteed: The benefits of composability are becoming clear in software engineering.;"In this article we use LINQ (Language-integrated Query) as the guiding example of composability. LINQ is a specification of higher-order operators designed specifically to be composable. This specification is broadly applicable over anything that fits a loose definition of collection"" from objects in memory to asynchronous data streams to resources distributed in the cloud. With such a design developers build up complexity by chaining together transforms and filters in various orders and by nesting the chains--that is by building expression trees of operators.""";
Finding Usability Bugs with Automated Tests: Automated usability tests can be valuable companions to in-person tests.;Ideally all software should be easy to use and accessible for a wide range of people however even software that appears to be modern and intuitive often falls short of the most basic usability and accessibility goals. Why does this happen? One reason is that sometimes our designs look appealing so we skip the step of testing their usability and accessibility all in the interest of speed reducing costs and competitive advantage.;
The Die is Cast: Hardware Security is Not Assured;The future of hardware security will evolve with hardware. As packaging advances and focus moves to beyond Moore's law technologies hardware security experts will need to keep ahead of changing security paradigms including system and process vulnerabilities. Research focused on quantum hacking is emblematic of the translation of principles of security on the physical attack plane for emerging communications and computing technologies. Perhaps the commercial market will evolve such that the GAO will run a study on compromised quantum technologies in the not-too-distant future.;
Exposing the ORM Cache: Familiarity with ORM caching issues can help prevent performance problems and bugs.;In the early 1990s when object-oriented languages emerged into the mainstream of software development a noticeable surge in productivity occurred as developers saw new and better ways to create software programs. Although the new and efficient object programming paradigm was hailed and accepted by a growing number of organizations relational database management systems remained the preferred technology for managing enterprise data. Thus was born ORM (object-relational mapping) out of necessity and the complex challenge of saving the persistent state of an object environment in a relational database subsequently became known as the object-relational impedance mismatch.;
Modern Performance Monitoring: Todayâ€™s diverse and decentralized computer world demands new thinking about performance monitoring and analysis.;"The modern Unix server floor can be a diverse universe of hardware from several vendors and software from several sources. Often the personnel needed to resolve server floor performance issues are not available or for security reasons not allowed to be present at the very moment of occurrence. Even when as luck might have it the right personnel are actually present to witness a performance event"" the tools to measure and analyze the performance of the hardware and software have traditionally been sparse and vendor-specific. Because few real Unix cross-platform toolkits exist there is no standard method for administrators to accurately view an event record it for later analysis or share it with additional qualified personnel for an efficient resolution.""";
Taxonomy of Risks posed by Language Models;Responsible innovation on large-scale Language Models (LMs) requires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxonomy of ethical and social risks associated with LMs. We identify twenty-one risks drawing on expertise and literature from computer science linguistics and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination Hate speech and Exclusion II. Information Hazards III. Misinformation Harms IV. Malicious Uses V. Human-Computer Interaction Harms and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs the causal mechanism leading to harm evidence of the risk and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.;
Proceedings of the 2022 ACM Conference on Fairness Accountability and Transparency;To shield the browser from attacks Google Chrome developers eyed three key problems.;
Big data and its technical challenges;Exploring the inherent technical challenges in realizing the potential of Big Data.;
A differential approach to undefined behavior detection;Remember the halcyon days when development required only a text editor a compiler and some sort of debugger (in cases where the odd printf() or two alone didnâ€™t serve)? During the early days of computing these were independent tools used iteratively in developmentâ€™s golden circle. Somewhere along the way we realized that a closer integration of these tools could expedite the development process. Thus was born the integrated development environment (IDE) a framework and user environment for software development thatâ€™s actually a toolkit of instruments essential to software creation. At first IDEs simply connected the big three (editor compiler and debugger) but nowadays most go well beyond those minimum requirements. In fact in recent years we have witnessed an explosion in the constituent functionality of IDEs.;
TFX: A TensorFlow-Based Production-Scale Machine Learning Platform;Creating and maintaining a platform for reliably producing and deploying machine learning models requires careful orchestration of many components---a learner for generating models based on training data modules for analyzing and validating both data as well as models and finally infrastructure for serving models in production. This becomes particularly challenging when data changes over time and fresh models need to be produced continuously. Unfortunately such orchestration is often done ad hoc using glue code and custom scripts developed by individual teams for specific use cases leading to duplicated effort and fragile systems with high technical debt.We present TensorFlow Extended (TFX) a TensorFlow-based general-purpose machine learning platform implemented at Google. By integrating the aforementioned components into one platform we were able to standardize the components simplify the platform configuration and reduce the time to production from the order of months to weeks while providing platform stability that minimizes disruptions.We present the case study of one deployment of TFX in the Google Play app store where the machine learning models are refreshed continuously as new data arrive. Deploying TFX led to reduced custom code faster experiment cycles and a 2% increase in app installs resulting from improved data and model analysis.;
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;A searchable meta-graph can connect even troublesome house elves and other supernatural beings to scholarly folk categories.;
Beyond relational databases;There is more to data access than SQL.;
Building Scalable Web Services: Build only what you really need.;In the early days of the Web we severely lacked tools and frameworks and in retrospect it seems noteworthy that those early Web services scaled at all. Nowadays while the tools have progressed so too have expectations with respect to richness of interaction performance and scalability. In view of these raised expectations it is advisable to build only what you really need relying on other peopleâ€™s work where possible. Above all be cautious in choosing when what and how to optimize.;
Software Needs Seatbelts and Airbags: Finding and fixing bugs in deployed software is difficult and time-consuming. Here are some alternatives.;Like death and taxes buggy code is an unfortunate fact of life. Nearly every program ships with known bugs and probably all of them end up with bugs that are discovered only post-deployment. There are many reasons for this sad state of affairs.;
The QUIC Transport Protocol: Design and Internet-Scale Deployment;We present our experience with QUIC an encrypted multiplexed and low-latency transport protocol designed from the ground up to improve transport performance for HTTPS traffic and to enable rapid deployment and continued evolution of transport mechanisms. QUIC has been globally deployed at Google on thousands of servers and is used to serve traffic to a range of clients including a widely-used web browser (Chrome) and a popular mobile video streaming app (YouTube). We estimate that 7% of Internet traffic is now QUIC. We describe our motivations for developing a new transport the principles that guided our design the Internet-scale process that we used to perform iterative experiments on QUIC performance improvements seen by our various services and our experience deploying QUIC globally. We also share lessons about transport design and the Internet ecosystem that we learned from our deployment.;
Proceedings of the Conference of the ACM Special Interest Group on Data Communication;The Quipper language offers a unified general-purpose programming framework for quantum computation.;
Thread Scheduling in FreeBSD 5.2: To help get a better handle on thread scheduling we take a look at how FreeBSD 5.2 handles it.;A busy system makes thousands of scheduling decisions per second so the speed with which scheduling decisions are made is critical to the performance of the system as a whole. This article - excerpted from the forthcoming book â€œThe Design and Implementation of the FreeBSD Operating Systemâ€œ - uses the example of the open source FreeBSD system to help us understand thread scheduling. The original FreeBSD scheduler was designed in the 1980s for large uniprocessor systems. Although it continues to work well in that environment today the new ULE scheduler was designed specifically to optimize multiprocessor and multithread environments. This article first studies the original FreeBSD scheduler then describes the new ULE scheduler. The article does not describe the realtime scheduler that is also available in FreeBSD.;
A closer look at GPUs;As the line between GPUs and CPUs begins to blur it's important to understand what makes GPUs tick.;
Playing for Keeps: Will security threats bring an end to general-purpose computing?;Inflection points come at you without warning and quickly recede out of reach. We may be nearing one now. If so we are now about to play for keeps and â€œweâ€ doesnâ€™t mean just us security geeks. If anything itâ€™s because we security geeks have not worked the necessary miracles already that an inflection point seems to be approaching at high velocity.;
Using Free and Open Source Tools to Manage Software Quality: An agile process implementation;The principles of agile software development place more emphasis on individuals and interactions than on processes and tools. They steer us away from heavy documentation requirements and guide us along a path of reacting efficiently to change rather than sticking rigidly to a pre-defined plan. To support this flexible method of operation it is important to have suitable applications to manage the teamâ€™s activities. It is also essential to implement effective frameworks to ensure quality is being built into the product early and at all levels. With these concerns in mind and coming from a budget-conscious perspective this article will explore the free and open source applications and tools used by one organization in its quest to build process and quality around its projects and products.;
Open source firmware;Step into the world behind the kernel.;
Phishing Forbidden: Current anti-phishing technologies prevent users from taking the bait.;Phishing is a significant risk facing Internet users today. Through e-mails or instant messages users are led to counterfeit Web sites designed to trick them into divulging usernames passwords account numbers and personal information. It is up to the user to ensure the authenticity of the Web site. Browsers provide some tools but these are limited by at least three issues.;
The early history of F#;"This paper describes the genesis and early history of the F# programming language. I start with the origins of strongly-typed functional programming (FP) in the 1970s 80s and 90s. During the same period Microsoft was founded and grew to dominate the software industry. In 1997 as a response to Java Microsoft initiated internal projects which eventually became the .NET programming framework and the C# language. From 1997 the worlds of academic functional programming and industry combined at Microsoft Research Cambridge. The researchers engaged with the company through Project 7 the initial effort to bring multiple languages to .NET leading to the initiation of .NET Generics in 1998 and F# in 2002. F# was one of several responses by advocates of strongly-typed functional programming to the object-oriented tidal wave"" of the mid-1990s. The development of the core features of F# 1.0 happened from 2004-2007 and I describe the decision-making process that led to the ""productization"" of F# by Microsoft in 2007-10 and the release of F# 2.0. The origins of F#'s characteristic features are covered: object programming quotations statically resolved type parameters active patterns computation expressions async units-of-measure and type providers. I describe key developments in F# since 2010 including F# 3.0-4.5 and its evolution as an open source cross-platform language with multiple delivery channels. I conclude by examining some uses of F# and the influence F# has had on other languages so far.""";
Databases of Discovery: Open-ended database ecosystems promote new discoveries in biotech. Can they help your organization too?;The National Center for Biotechnology Information is responsible for massive amounts of data. A partial list includes the largest public bibliographic database in biomedicine the U.S. national DNA sequence database an online free full text research article database assembly annotation and distribution of a reference set of genes genomes and chromosomes online text search and retrieval systems and specialized molecular biology data search engines. At this writing NCBI receives about 50 million Web hits per day at peak rates of about 1900 hits per second and about 400000 BLAST searches per day from about 2.5 million users. The Web site transfers about 0.6 terabytes per day and people interested in local copies of bulk data FTP about 1.2 terabytes per day.;
Java Security Architecture Revisited: Hard technical problems and tough business challenges;This article looks back at a few of the hardest technical problems from a design and engineering perspective as well as some tough business challenges for which research scientists are rarely trained. Li Gong offers a retrospective here culled from four previous occasions when he had the opportunity to dig into old notes and refresh his memory.;
Cybersecurity is not very important;"There is a rising tide of security breaches. There is an even faster rising tide of hysteria over the ostensible reason for these breaches namely the deficient state of our information infrastructure. Yet the world is doing remarkably well overall and has not suffered any of the oft-threatened giant digital catastrophes. This continuing general progress of society suggests that cyber security is not very important. Adaptations to cyberspace of techniques that worked to protect the traditional physical world have been the main means of mitigating the problems that occurred. This chewing gum and baling wire"" approach is likely to continue to be the basic method of handling problems that arise and to provide adequate levels of security.""";
Instant inkjet circuits: lab-based inkjet printing to support rapid prototyping of UbiComp devices;This paper introduces a low cost fast and accessible technology to support the rapid prototyping of functional electronic devices. Central to this approach of 'instant inkjet circuits' is the ability to print highly conductive traces and patterns onto flexible substrates such as paper and plastic films cheaply and quickly. In addition to providing an alternative to breadboarding and conventional printed circuits we demonstrate how this technique readily supports large area sensors and high frequency applications such as antennas. Unlike existing methods for printing conductive patterns conductivity emerges within a few seconds without the need for special equipment. We demonstrate that this technique is feasible using commodity inkjet printers and commercially available ink for an initial investment of around US$300. Having presented this exciting new technology we explain the tools and techniques we have found useful for the first time. Our main research contribution is to characterize the performance of instant inkjet circuits and illustrate a range of possibilities that are enabled by way of several example applications which we have built. We believe that this technology will be of immediate appeal to researchers in the ubiquitous computing domain since it supports the fabrication of a variety of functional electronic device prototypes.;
Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing;This paper presents a new model for understanding human behavior. In this model (FBM) behavior is a product of three factors: motivation ability and triggers each of which has subcomponents. The FBM asserts that for a person to perform a target behavior he or she must (1) be sufficiently motivated (2) have the ability to perform the behavior and (3) be triggered to perform the behavior. These three factors must occur at the same moment else the behavior will not happen. The FBM is useful in analysis and design of persuasive technologies. The FBM also helps teams work together efficiently because this model gives people a shared way of thinking about behavior change.;
Proceedings of the 4th International Conference on Persuasive Technology;The video game industry earned $8.85 billion in revenue in 2007 almost as much as movies made at the box office. Much of this revenue was generated by blockbuster titles created by large groups of people. Though large development teams are not unheard of in the software industry game studios tend to have unique collections of developers. Software engineers make up a relatively small portion of the game development team while the majority of the team consists of content creators such as artists musicians and designers.;
Re-examining Whether Why and How Human-AI Interaction Is Uniquely Difficult to Design;Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example AI systems can make unpredictable errors and these errors damage UX and even lead to undesired societal impact. However HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research our own design and research experience and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities 2) AI's output complexity spanning from simple to adaptive complex. We identify four levels of AI systems. On each level designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers researchers and design tool makers in productively addressing the challenges of human-AI interaction going forward.;
Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;As MongoDB becomes more feature-rich and complex with time the need to develop more sophisticated methods for finding bugs grows as well. Three years ago MongDB added a home-grown JavaScript fuzzer to its toolkit and it is now our most prolific bug-finding tool responsible for detecting almost 200 bugs over the course of two release cycles. These bugs span a range of MongoDB components from sharding to the storage engine with symptoms ranging from deadlocks to data inconsistency. The fuzzer runs as part of the CI (continuous integration) system where it frequently catches bugs in newly committed code.;
Large-scale cluster management at Google with Borg;Google's Borg system is a cluster manager that runs hundreds of thousands of jobs from many thousands of different applications across a number of clusters each with up to tens of thousands of machines.It achieves high utilization by combining admission control efficient task-packing over-commitment and machine sharing with process-level performance isolation. It supports high-availability applications with runtime features that minimize fault-recovery time and scheduling policies that reduce the probability of correlated failures. Borg simplifies life for its users by offering a declarative job specification language name service integration real-time job monitoring and tools to analyze and simulate system behavior.We present a summary of the Borg system architecture and features important design decisions a quantitative analysis of some of its policy decisions and a qualitative examination of lessons learned from a decade of operational experience with it.;
Proceedings of the Tenth European Conference on Computer Systems;This paper was first published online by the Internet Society in December 20031 and is being re-published in ACM SIGCOMM Computer Communication Review because of its historic import. It was written at the urging of its primary editor the late Barry Leiner. He felt that a factual rendering of the events and activities associated with the development of the early Internet would be a valuable contribution. The contributing authors did their best to incorporate only factual material into this document. There are sure to be many details that have not been captured in the body of the document but it remains one of the most accurate renderings of the early period of development available.;
Open Source to the Core: Using open source in real-world software products: The good the bad and the ugly;The open source development model is not exactly new. Individual engineers have been using open source as a collaborative development methodology for decades. Now that it has come to the attention of upper and middle management however itâ€™s finally being openly acknowledged as a commercial engineering force-multiplier and important option for avoiding significant software development costs.;
From Server Room to Living Room: How open source and TiVo became a perfect match;The open source movement exemplified by the growing acceptance of Linux is finding its way not only into corporate environments but also into a home near you. For some time now high-end applications such as software development computer-aided design and manufacturing and heavy computational applications have been implemented using Linux and generic PC hardware.;
Parallel Processing with Promises: A simple method of writing a collaborative system;In todayâ€™s world there are many reasons to write concurrent software. The desire to improve performance and increase throughput has led to many different asynchronous techniques. The techniques involved however are generally complex and the source of many subtle bugs especially if they require shared mutable state. If shared state is not required then these problems can be solved with a better abstraction called promises. These allow programmers to hook asynchronous function calls together waiting for each to return success or failure before running the next appropriate function in the chain.;
Condos and Clouds: Constraints in an environment empower the services.;Living in a condominium has its constraints and its services. By defining the lifestyle and limits on usage patterns it is possible to pack many homes close together and to provide the residents with many conveniences. Condo living can offer a great value to those interested and willing to live within its constraints and enjoy the sharing of common services.;
The rise and fall of CORBA;There's a lot we can learn from CORBA's mistakes.;
Where did I leave my keys? lessons from the Juniper Dual EC incident;"In December 2015 Juniper Networks announced multiple security vulnerabilities stemming from unauthorized code in ScreenOS the operating system for their NetScreen Virtual Private Network (VPN) routers. The more sophisticated of these vulnerabilities was a passive VPN decryption capability enabled by a change to one of the parameters used by the Dual Elliptic Curve (EC) pseudorandom number generator.In this paper we described the results of a full independent analysis of the ScreenOS randomness and VPN key establishment protocol subsystems which we carried out in response to this incident. While Dual EC is known to be insecure against an attacker who can choose the elliptic curve parameters Juniper had claimed in 2013 that ScreenOS included countermeasures against this type of attack. We find that contrary to Juniper's public statements the ScreenOS VPN implementation has been vulnerable to passive exploitation by an attacker who selects the Dual EC curve point since 2008. This vulnerability arises due to flaws in Juniper's countermeasures as well as a cluster of changes that were all introduced concurrently with the inclusion of Dual EC in a single 2008 release. We demonstrate the vulnerability on a real NetScreen device by modifying the firmware to install our own parameters and we show that it is possible to passively decrypt an individual VPN session in isolation without observing any other network traffic. This incident is an important example of how guidelines for random number generation engineering and validation can fail in practice. Additionally it casts further doubt on the practicality of designing a safe exceptional access"" or ""key escrow"" scheme of the type contemplated by law enforcement agencies in the United States and elsewhere.""";
Computationally modeling human emotion;Computer models of emotion inform theories of human intelligence and advance human-centric applications.;
Metrics that matter;Critical but oft-neglected service metrics that every SRE and product owner should care about.;
My VM is Lighter (and Safer) than your Container;Containers are in great demand because they are lightweight when compared to virtual machines. On the downside containers offer weaker isolation than VMs to the point where people run containers in virtual machines to achieve proper isolation. In this paper we examine whether there is indeed a strict tradeoff between isolation (VMs) and efficiency (containers). We find that VMs can be as nimble as containers as long as they are small and the toolstack is fast enough.We achieve lightweight VMs by using unikernels for specialized applications and with Tinyx a tool that enables creating tailor-made trimmed-down Linux virtual machines. By themselves lightweight virtual machines are not enough to ensure good performance since the virtualization control plane (the toolstack) becomes the performance bottleneck. We present LightVM a new virtualization solution based on Xen that is optimized to offer fast boot-times regardless of the number of active VMs. LightVM features a complete redesign of Xen's control plane transforming its centralized operation to a distributed one where interactions with the hypervisor are reduced to a minimum. LightVM can boot a VM in 2.3ms comparable to fork/exec on Linux (1ms) and two orders of magnitude faster than Docker. LightVM can pack thousands of LightVM guests on modest hardware with memory and CPU usage comparable to that of processes.;
Proceedings of the 26th Symposium on Operating Systems Principles;Exploring the similarities and differences between distributed computations in biological and computational systems.;
A High-Performance Team: From design to production performance should be part of the process.;You work in the product development group of a software company where the product is often compared with the competition on performance grounds. Performance is an important part of your business but so is adding new functionality fixing bugs and working on new projects. So how do you lead your team to develop high-performance software as well as doing everything else? And how do you keep that performance high throughout cycles of maintenance and enhancement?;
Best Practice (BPM): In business process management finding the right tool suite is just the beginning.;"Just as BPM (business process management) technology is markedly different from conventional approaches to application support the methodology of BPM development is markedly different from traditional software implementation techniques. With CPI (continuous process improvement) as the core discipline of BPM the models that drive work through the company evolve constantly. Indeed recent studies suggest that companies fine-tune their BPM-based applications at least once a quarter (and sometimes as often as eight times per year). The point is that there is no such thing as a finished"" process it takes multiple iterations to produce highly effective solutions. Every working BPM-based process is just a starting point for the future. Moreover with multiple processes that could benefit from BPM-style automated support the issue becomes how to support dozens or even hundreds of engagements per year.""";
The hardware lottery;After decades of incentivizing the isolation of hardware software and algorithm development the catalysts for closer collaboration are changing the paradigm.;
Analysis of SSL certificate reissues and revocations in the wake of heartbleed;A properly managed public key infrastructure (PKI) is critical to ensure secure communication on the Internet. Surprisingly some of the most important administrative steps---in particular reissuing new X.509 certificates and revoking old ones---are manual and remained unstudied largely because it is difficult to measure these manual processes at scale.We use Heartbleed a widespread OpenSSL vulnerability from 2014 as a natural experiment to determine whether administrators are properly managing their certificates. All domains affected by Heartbleed should have patched their software revoked their old (possibly compromised) certificates and reissued new ones all as quickly as possible. We find the reality to be far from the ideal: over 73% of vulnerable certificates were not reissued and over 87% were not revoked three weeks after Heartbleed was disclosed. Our results also show a drastic decline in revocations on the weekends even immediately following the Heartbleed announcement. These results are an important step in understanding the manual processes on which users rely for secure authenticated communication.;
Abstractions their algorithms and their compilers;Jeffrey D. Ullman and Alfred V. Aho are recipients of the 2020 ACM A.M. Turing award. They were recognized for creating fundamental algorithms and theory underlying programming language implementation and for synthesizing these results and those of others in their highly influential books which educated generations of computer scientists.;
Closing the AI accountability gap: defining an end-to-end framework for internal algorithmic auditing;Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment and once deployed emergent issues can become difficult or impossible to trace back to their source.In this paper we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end to be applied throughout the internal organization development life-cycle. Each stage of the audit yields a set of documents that together form an overall audit report drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing framework is intended to contribute to closing the accountability gap in the development and deployment of large-scale artificial intelligence systems by embedding a robust process to ensure audit integrity.;
Proceedings of the 2020 Conference on Fairness Accountability and Transparency;Why can't we all use standard libraries for commonly needed algorithms?;
Cache Me If You Can: Building a decentralized web-delivery model;The world is more connected than it ever has been before and with our pocket supercomputers and IoT (Internet of Things) future the next generation of the web might just be delivered in a peer-to-peer model. Itâ€™s a giant problem space but the necessary tools and technology are here today. We just need to define the problem a little better.;
How will astronomy archives survive the data tsunami?;Astronomers are collecting more data than ever. What practices can keep them ahead of the flood?;
Artificial intelligence for synthetic biology;The opportunities and challenges of adapting and applying AI principles to synbio.;
The power of social media analytics;How to use and influence consumer social communications to improve business performance reputation and profit.;
The future of data storage;Research into next-generation storage techniques marches forward yet tape remains the most viable dependable medium.;
Extreme Software Scaling: Chip multiprocessors have introduced a new dimension in scaling for application developers operating system designers and deployment specialists.;The advent of SMP (symmetric multiprocessing) added a new degree of scalability to computer systems. Rather than deriving additional performance from an incrementally faster microprocessor an SMP system leverages multiple processors to obtain large gains in total system performance. Parallelism in software allows multiple jobs to execute concurrently on the system increasing system throughput accordingly. Given sufficient software parallelism these systems have proved to scale to several hundred processors.;
An interview with Frances E. Allen;Frances E. Allen recipient of the 2006 ACM A.M. Turing Award reflects on her career.;
Passing a language through the eye of a needle;How the embeddability of Lua impacted its design.;
CTO Roundtable: Cloud Computing: Our panel of experts discuss cloud computing and how companies can make the best use of it.;Many people reading about cloud computing in the trade journals will think itâ€™s a panacea for all their IT problems. It is not. In this CTO Roundtable discussion we hope to give practitioners useful advice on how to evaluate cloud computing for their organizations. Our focus will be on the SMB (small- to medium-size business) IT managers who are underfunded overworked and have lots of assets tied up in out-of-date hardware and software. To what extent can cloud computing solve their problems? With the help of five current thought leaders in this quickly evolving field we offer some answers to that question. We explore some of the basic principles behind cloud computing and highlight some of the key issues and opportunities that arise when computing moves from in-house to the cloud. Our sincere thanks to all who participated and to the ACM Professions Board for making this possible.;
Incremental iterative data processing with timely dataflow;We describe the timely dataflow model for distributed computation and its implementation in the Naiad system. The model supports stateful iterative and incremental computations. It enables both low-latency stream processing and high-throughput batch processing using a new approach to coordination that combines asynchronous and fine-grained synchronous execution. We describe two of the programming frameworks built on Naiad: GraphLINQ for parallel graph processing and differential dataflow for nested iterative and incremental computations. We show that a general-purpose system can achieve performance that matches and sometimes exceeds that of specialized systems.;
A year in lockdown: how the waves of COVID-19 impact internet traffic;"In March 2020 the World Health Organization declared the Corona Virus 2019 (COVID-19) outbreak a global pandemic. As a result billions of people were either encouraged or forced by their governments to stay home to reduce the spread of the virus. This caused many to turn to the Internet for work education social interaction and entertainment. With the Internet demand rising at an unprecedented rate the question of whether the Internet could sustain this additional load emerged. To answer this question this paper will review the impact of the first year of the COVID-19 pandemic on Internet traffic in order to analyze its performance. In order to keep our study broad we collect and analyze Internet traffic data from multiple locations at the core and edge of the Internet. From this we characterize how traffic and application demands change to describe the new normal"" and explain how the Internet reacted during these unprecedented times.""";
Arrogance in Business Planning: Technology business plans that assume no competition (ever);"In the Internet addressing and naming market thereâ€™s a lot of competition margins are thin and the premiums on good planning and good execution are nowhere higher. To survive investors and entrepreneurs have to be bold. Some entrepreneurs however go beyond bold"" and enter the territory of ""arrogant"" by making the wild assumption that they will have no competitors if they create a new and profitable niche. So it is with those who would unilaterally supplant or redraw the existing Internet resource governance or allocation systems. Because alternative DNS (Domain Name System) roots provide such a well-proved and well-understood example of this kind of arrogance this article begins with a short slog through that swamp before discussing the more current and topical matter of alternative numbering Whois.""";
Software development with code maps;Could ubiquitous hand-drawn code map diagrams become a thing of the past?;
You Donâ€™t Know Jack About Software Maintenance: Long considered an afterthought software maintenance is easiest and most effective when built into a system from the ground up.;"Everyone knows maintenance is hard and boring and avoids doing it. Besides their pointy-haired bosses say things like: No one needs to do maintenance - thatâ€™s a waste of time.""""";
Internal Access Controls: Trust but Verify;Every day seems to bring news of another dramatic and high-profile security incident whether it is the discovery of longstanding vulnerabilities in widely used software such as OpenSSL or Bash or celebrity photographs stolen and publicized. There seems to be an infinite supply of zero-day vulnerabilities and powerful state-sponsored attackers. In the face of such threats is it even worth trying to protect your systems and data? What can systems security designers and administrators do?;
Deep Learning with Differential Privacy;Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often the training of models requires large representative datasets which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives under a modest privacy budget and at a manageable cost in software complexity training efficiency and model quality.;
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;Contention for caches memory controllers and interconnects can be eased by contention-aware scheduling algorithms.;
Software engineering and formal methods;The answer to software reliability concerns may lie in formal methods.;
From designing to co-designing to collective dreaming: three slices in time;The time has come for software liability laws.;
Incremental research vs. paradigm-shift mania;The Communications Web site http://cacm.acm.org features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications we'll publish selected posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMhttp://cacm.acm.org/blogs/blog-cacmBertrand Meyer asks why too many research agencies seem obsessed with funding only groundbreaking projects.;
Exascale computing and big data;Scientific discovery and engineering innovation requires unifying traditionally separated high-performance computing and big data analytics.;
Design Exploration through Code-generating DSLs: High-level DSLs for low-level programming;DSLs (domain-specific languages) make programs shorter and easier to write. They can be stand-alone - for example LaTeX Makefiles and SQL - or they can be embedded in a host language. You might think that DSLs embedded in high-level languages would be abstract or mathematically oriented far from the nitty-gritty of low-level programming. This is not the case. This article demonstrates how high-level EDSLs (embedded DSLs) really can ease low-level programming. There is no contradiction.;
How do app vendors respond to subject access requests?  A longitudinal privacy study on iOS and Android Apps;EU data protection laws grant consumers the right to access the personal data that companies hold about them. In a first-of-its-kind longitudinal study we examine how service providers have complied with subject access requests over four years. In three iterations between 2015 and 2019 we sent subject access requests to vendors of 225 mobile apps popular in Germany. Throughout the iterations 19 to 26% of the vendors were unreachable or did not reply at all. Our subject access requests were fulfilled in 15 to 53% of the cases with an unexpected decline between the GDPR enforcement date and the end of our study. The remaining responses exhibit a long list of shortcomings including severe violations of information security and data protection principles. Some responses even contained deceptive and misleading statements (7 to 13%). Further 9% of the apps were discontinued and 27% of the user accounts vanished during our study mostly without proper notification about the consequences for our personal data. While we observe improvements for selected aspects over time the results indicate that subject access request handling will be unsatisfactory as long as vendors accept such requests via email and process them manually.;
Proceedings of the 15th International Conference on Availability Reliability and Security;The promise of STM may likely be undermined by its overheads and workload applicabilities.;
Collaboration in system administration;For sysadmins solving problems usually involves collaborating with others. How can we make it more effective?;
Enterprise Search: Tough Stuff: Why is it that searching an intranet is so much harder than searching the Web?;The last decade has witnessed the growth of information retrieval from a boutique discipline in information and library science to an everyday experience for billions of people around the world. This revolution has been driven in large measure by the Internet with vendors focused on search and navigation of Web resources and Web content management. Simultaneously enterprises have invested in networking all of their information together to the point where it is increasingly possible for employees to have a single window into the enterprise. Although these employees seek Web-like experiences in the enterprise the Internet and enterprise domains differ fundamentally in the nature of the content user behavior and economic motivations.;
Gamification: designing for motivation;Social Mediator is a forum exploring the ways that HCI research and principles interact---or might interact---with practices in the social media world.Joe McCarthy Editor;
Flash storage memory;Can flash memory become the foundation for a new tier in the storage hierarchy?;
Guidelines for Human-AI Interaction;Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge highlighting opportunities for further research. Based on the evaluations we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies and to researchers interested in the further development of human-AI interaction design principles.;
Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;This paper aims to provide the view of what means IoT (Internet of Things) in energy efficiency applications of its technical and business impacts of its opportunities and risks for the different market players. It is concluded by the author's long term vision about the use of IoT in energy efficiency applications.;
The world according to LINQ;Big data is about more than size and LINQ is more than up to the task.;
Pregel: a system for large-scale graph processing;Many practical computing problems concern large graphs. Standard examples include the Web graph and various social networks. The scale of these graphs - in some cases billions of vertices trillions of edges - poses challenges to their efficient processing. In this paper we present a computational model suitable for this task. Programs are expressed as a sequence of iterations in each of which a vertex can receive messages sent in the previous iteration send messages to other vertices and modify its own state and that of its outgoing edges or mutate graph topology. This vertex-centric approach is flexible enough to express a broad set of algorithms. The model has been designed for efficient scalable and fault-tolerant implementation on clusters of thousands of commodity computers and its implied synchronicity makes reasoning about programs easier. Distribution-related details are hidden behind an abstract API. The result is a framework for processing large graphs that is expressive and easy to program.;
Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data;The exponential growth in PVT corners due to Moore's law scaling and the increasing demand for consumer applications and longer battery life in mobile devices has ushered in significant cost and power-related challenges for designing and productizing mobile chips within a predictable schedule. Two main reasons for this are the reliance on human decision-making to achieve the desired performance within the target area and power budget and significant increases in complexity of the human decision-making space. The problem is that to-date human design experience has not been replaced by design automation tools and tasks requiring experience of past designs are still being performed manually.In this paper we investigate how machine learning may be applied to develop tools that learn from experience just like human designers thus automating tasks that still require human intervention. The potential advantage of the machine learning approach is the ability to scale with increasing complexity and therefore hold the design-time constant with same manpower.Reinforcement Learning (RL) is a machine learning technique that allows us to mimic a human designers' ability to learn from experience and automate human decision-making without loss in quality of the design while making the design time independent of the complexity. In this paper we show how manual design tasks can be abstracted as RL problems. Based on the experience with applying RL to one of these problems we show that RL can automatically achieve results similar to human designs but in a predictable schedule. However a major drawback is that the RL solution can require a prohibitively large number of iterations for training. If efficient training techniques can be developed for RL it holds great promise to automate tasks requiring human experience. In this paper we present a Bayesian Optimization technique for reducing the RL training time.;
Proceedings of the 55th Annual Design Automation Conference;In computing systems a CPU is usually one of the largest consumers of energy. For this reason reducing CPU power consumption has been a hot topic in the past few years in both the academic community and the industry. In the quest to create more power-efficient CPUs several researchers have proposed an asymmetric multicore architecture that promises to save a significant amount of power while delivering similar performance to conventional symmetric multicore processors.;
Corp to Cloud: Googleâ€™s Virtual Desktops: How Google moved its virtual desktops to the cloud;Over one-fourth of Googlers use internal data-center-hosted virtual desktops. This on-premises offering sits in the corporate network and allows users to develop code access internal resources and use GUI tools remotely from anywhere in the world. Among its most notable features a virtual desktop instance can be sized according to the task at hand has persistent user storage and can be moved between corporate data centers to follow traveling Googlers. Until recently our virtual desktops were hosted on commercially available hardware on Googleâ€™s corporate network using a homegrown open-source virtual cluster-management system called Ganeti. Today this substantial and Google-critical workload runs on GCP (Google Compute Platform). This article discusses the reasons for the move to GCP and how the migration was accomplished.;
Network Forensics: Good detective work means paying attention before during and after the attack.;The dictionary defines forensics as â€œthe use of science and technology to investigate and establish facts in criminal or civil courts of law.â€ I am more interested however in the usage common in the computer world: using evidence remaining after an attack on a computer to determine how the attack was carried out and what the attacker did. The standard approach to forensics is to see what can be retrieved after an attack has been made but this leaves a lot to be desired. The first and most obvious problem is that successful attackers often go to great lengths to ensure that they cover their trails. The second is that unsuccessful attacks often go unnoticed and even when they are noticed little information is available to assist with diagnosis.;
Beyond Instant Messaging: Platforms and standards for these services must anticipate and accommodate future developments.;The recent rise in popularity of IM (instant messaging) has driven the development of platforms and the emergence of standards to support IM. Especially as the use of IM has migrated from online socializing at home to business settings there is a need to provide robust platforms with the interfaces that business customers use to integrate with other work applications. Yet in the rush to develop a mature IM infrastructure it is also important to recognize that IM features and uses are still evolving. For example popular press stories1 have raised the concern that IM interactions may be too distracting in the workplace. This concern suggests that we still need to fine-tune the interface design for IM so the benefits of quick lightweight communication can be gained without creating a distracting burden for users. How can the industry meet the demand for robust platforms and standards for IM without locking out innovation and development?;
Toward Energy-Efficient Computing: What will it take to make server-side computing more energy efficient?;By now most everyone is aware of the energy problem at its highest level: our primary sources of energy are running out while the demand for energy in both commercial and domestic environments is increasing and the side effects of energy use have important global environmental considerations. The emission of greenhouse gases such as CO now seen by most climatologists to be linked to global warming is only one issue.;
Declarative Machine Learning Systems: The future of machine learning will depend on it being in the hands of the rest of us.;The people training and using ML models now are typically experienced developers with years of study working within large organizations but the next wave of ML systems should allow a substantially larger number of people potentially without any coding skills to perform the same tasks. These new ML systems will not require users to fully understand all the details of how models are trained and used for obtaining predictions but will provide them a more abstract interface that is less demanding and more familiar. Declarative interfaces are well-suited for this goal by hiding complexity and favoring separation of interest and ultimately leading to increased productivity.;
How Do I Model State? Let Me Count the Ways: A study of the technology and sociology of Web services specifications;There is nothing like a disagreement concerning an arcane technical matter to bring out the best (and worst) in software architects and developers. As every reader knows from experience it can be hard to get to the bottom of what exactly is being debated. One reason for this lack of clarity is often that different people care about different aspects of the problem. In the absence of agreement concerning the problem it can be difficult to reach an agreement about the solutions.;
Fairness and Abstraction in Sociotechnical Systems;"A key goal of the fair-ML community is to develop machine-learning based systems that once introduced into a social context can achieve social and legal outcomes such as fairness justice and due process. Bedrock concepts in computer science---such as abstraction and modular design---are used to define notions of fairness and discrimination to produce fairness-aware learning algorithms and to intervene at different stages of a decision-making pipeline to produce fair"" outcomes. In this paper however we contend that these concepts render technical interventions ineffective inaccurate and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five ""traps"" that fair-ML work can fall into even as it attempts to be more context-aware in comparison to traditional data science. We draw on studies of sociotechnical systems in Science and Technology Studies to explain why such traps occur and how to avoid them. Finally we suggest ways in which technical designers can mitigate the traps through a refocusing of design in terms of process rather than solutions and by drawing abstraction boundaries to include social actors rather than purely technical ones.""";
Proceedings of the Conference on Fairness Accountability and Transparency;Software patching is an increasingly important aspect of todayâ€™s computing environment as the volume complexity and number of configurations under which a piece of software runs have grown considerably. Software architects and developers do everything they can to build secure bug-free software products. To ensure quality development teams leverage all the tools and techniques at their disposal. For example software architects incorporate security threat models into their designs and QA engineers develop automated test suites that include sophisticated code-defect analysis tools.;
Bringing the web up to speed with WebAssembly;The maturation of the Web platform has given rise to sophisticated and demanding Web applications such as interactive 3D visualization audio and video software and games. With that efficiency and security of code on the Web has become more important than ever. Yet JavaScript as the only built-in language of the Web is not well-equipped to meet these requirements especially as a compilation target.  Engineers from the four major browser vendors have risen to the challenge and collaboratively designed a portable low-level bytecode called WebAssembly. It offers compact representation efficient validation and compilation and safe low to no-overhead execution. Rather than committing to a specific programming model WebAssembly is an abstraction over modern hardware making it language- hardware- and platform-independent with use cases beyond just the Web. WebAssembly has been designed with a formal semantics from the start. We describe the motivation design and formal semantics of WebAssembly and provide some preliminary experience with implementations.;
Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation;Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices making medical diagnoses and facial recognition. In a model inversion attack recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al. adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs however is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and in the other context show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.;
Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security;Lessons learned from three container-management systems over a decade.;
The pain of implementing LINQ providers;It's no easy task for NoSQL.;
Fighting Spam with Reputation Systems: User-submitted spam fingerprints;Spam is everywhere clogging the inboxes of e-mail users worldwide. Not only is it an annoyance it erodes the productivity gains afforded by the advent of information technology. Workers plowing through hours of legitimate e-mail every day also must contend with removing a significant amount of illegitimate e-mail. Automated spam filters have dramatically reduced the amount of spam seen by the end users who employ them but the amount of training required rivals the amount of time needed simply to delete the spam without the assistance of a filter.;
The Reliability of Enterprise Applications: Understanding enterprise reliability;Enterprise reliability is a discipline that ensures applications will deliver the required business functionality in a consistent predictable and cost-effective manner without compromising core aspects such as availability performance and maintainability. This article describes a core set of principles and engineering methodologies that enterprises can apply to help them navigate the complex environment of enterprise reliability and deliver highly reliable and cost-efficient applications.;
High-performance web sites;Want to make your Web site fly? Focus on frontend performance.;
The emergence of a networking primitive in wireless sensor networks;"The wireless sensor network community approached networking abstractions as an open question allowing answers to emerge with time and experience. The Trickle algorithm has become a basic mechanism used in numerous protocols and systems. Trickle brings nodes to eventual consistency quickly and efficiently while remaining remarkably robust to variations in network density topology and dynamics. Instead of flooding a network with packets Trickle uses a polite gossip"" policy to control send rates so each node hears just enough packets to stay consistent. This simple mechanism enables Trickle to scale to 1000-fold changes in network density reach consistency in seconds and require only a few bytes of state yet impose a maintenance cost of a few sends an hour. Originally designed for disseminating new code experience has shown Trickle to have much broader applicability including route maintenance and neighbor discovery. This paper provides an overview of the research challenges wireless sensor networks face describes the Trickle algorithm and outlines several ways it is used today.""";
Unifying Biological Image Formats with HDF5: The biosciences need an image format capable of high performance and long-term maintenance. Is HDF5 the answer?;The biological sciences need a generic image format suitable for long-term storage and capable of handling very large images. Images convey profound ideas in biology bridging across disciplines. Digital imagery began 50 years ago as an obscure technical phenomenon. Now it is an indispensable computational tool. It has produced a variety of incompatible image file formats most of which are already obsolete.;
Too Much Information: Two applications reveal the key challenges in making context-aware computing a reality.;As mobile computing devices and a variety of sensors become ubiquitous new resources for applications and services - often collectively referred to under the rubric of context-aware computing - are becoming available to designers and developers. In this article we consider the potential benefits and issues that arise from leveraging context awareness in new communication services that include the convergence of VoIP (voice over IP) and traditional information technology.;
Thinking clearly about performance part 1;Improving the performance of complex software is difficult but understanding some fundamental principles can make it easier.;
Static Analysis: An Introduction: The fundamental challenge of software engineering is one of complexity.;Modern static-analysis tools provide powerful and specific insights into codebases. The Linux kernel team for example developed Coccinelle a powerful tool for searching analyzing and rewriting C source code because the Linux kernel contains more than 27 million lines of code a static-analysis tool is essential both for finding bugs and for making automated changes across its many libraries and modules. Another tool targeted at the C family of languages is Clang scan-build which comes with many useful analyses and provides an API for programmers to write their own analyses. Like so many things in computer science the utility of static analysis is self-referential: To write reliable programs we must also write programs for our programs. But this is no paradox. Static-analysis tools complex though their theory and practice may be are what will enable us and engineers of the future to overcome this challenge and yield the knowledge and insights that we practitioners deserve.;
Cybercrime 2.0: when the cloud turns dark;Web-based malware attacks are more insidious than ever. What can be done to stem the tide?;
Small-data computing: correct calculator arithmetic;Rounding errors are usually avoidable and sometimes we can afford to avoid them.;
CockroachDB: The Resilient Geo-Distributed SQL Database;We live in an increasingly interconnected world with many organizations operating across countries or even continents. To serve their global user base organizations are replacing their legacy DBMSs with cloud-based systems capable of scaling OLTP workloads to millions of users. CockroachDB is a scalable SQL DBMS that was built from the ground up to support these global OLTP workloads while maintaining high availability and strong consistency. Just like its namesake CockroachDB is resilient to disasters through replication and automatic recovery mechanisms. This paper presents the design of CockroachDB and its novel transaction model that supports consistent geo-distributed transactions on commodity hardware. We describe how CockroachDB replicates and distributes data to achieve fault tolerance and high performance as well as how its distributed SQL layer automatically scales with the size of the database cluster while providing the standard SQL interface that users expect. Finally we present a comprehensive performance evaluation and share a couple of case studies of CockroachDB users. We conclude by describing lessons learned while building CockroachDB over the last five years.;
Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data;GPU acceleration and other computer performance increases will offer critical benefits to biomedical science.;
Debunking the 100X GPU vs. CPU myth: an evaluation of throughput computing on CPU and GPU;Recent advances in computing have led to an explosion in the amount of data being generated. Processing the ever-growing data in a timely manner has made throughput computing an important aspect for emerging applications. Our analysis of a set of important throughput computing kernels shows that there is an ample amount of parallelism in these kernels which makes them suitable for today's multi-core CPUs and GPUs. In the past few years there have been many studies claiming GPUs deliver substantial speedups (between 10X and 1000X) over multi-core CPUs on these kernels. To understand where such large performance difference comes from we perform a rigorous performance analysis and find that after applying optimizations appropriate for both CPUs and GPUs the performance gap between an Nvidia GTX280 processor and the Intel Core i7-960 processor narrows to only 2.5x on average. In this paper we discuss optimization techniques for both CPU and GPU analyze what architecture features contributed to performance differences between the two architectures and recommend a set of architectural features which provide significant improvement in architectural efficiency for throughput kernels.;
Proceedings of the 37th Annual International Symposium on Computer Architecture;The Semantic Code team at GitHub builds and operates a suite of technologies that power symbolic code navigation on github.com. We learned that scale is about adoption user behavior incremental improvement and utility. Static analysis in particular is difficult to scale with respect to human behavior we often think of complex analysis tools working to find potentially problematic patterns in code and then trying to convince the humans to fix them. Our approach took a different tack: use basic analysis techniques to quickly put information that augments our ability to understand programs in front of everyone reading code on GitHub with zero configuration required and almost immediate availability after code changes.;
The Hitchhikerâ€™s Guide to Biomorphic Software: The natural world may be the inspiration we need for solving our computer problems.;"The natural world may be the inspiration we need for solving our computer problems. While it is certainly true that the map is not the territory"" most visitors to a foreign country do prefer to take with them at least a guidebook to help locate themselves as they begin their explorations. That is the intent of this article. Although there will not be enough time to visit all the major tourist sites with a little effort and using the information in the article as signposts the intrepid explorer can easily find numerous other interesting paths to explore.""";
Productivity in Parallel Programming: A Decade of Progress: Looking at the design and benefits of X10;In 2002 DARPA (Defense Advanced Research Projects Agency) launched a major initiative in HPCS (high-productivity computing systems). The program was motivated by the belief that the utilization of the coming generation of parallel machines was gated by the difficulty of writing debugging tuning and maintaining software at peta scale.;
Designing Portable Collaborative Networks: A middleware solution to keep pace with the ever-changing ways in which mobile workers collaborate.;"Peer-to-peer technology and wireless networking offer great potential for working together away from the desk - but they also introduce unique software and infrastructure challenges. The traditional idea of the work environment is anchored to a central location - the desk and office - where the resources needed for the job are located. Even in the many professions where the practitioners move among different field locations such as professional consulting health care or resource exploration the full set of information and technology resources has been available only in fixed locations where the workers check in"" periodically to integrate their field results back into the larger picture.""";
Software-defined cooking using a microwave oven;Despite widespread popularity today's microwave ovens are limited in their cooking capabilities given that they heat food blindly resulting in a nonuniform and unpredictable heating distribution. We present software-defined cooking (SDC) a low-cost closed-loop microwave oven system that aims to heat food in a software-defined thermal trajectory. SDC achieves this through a novel high-resolution heat sensing and actuation system that uses microwave-safe components to augment existing microwaves. SDC first senses the thermal gradient by using arrays of neon lamps that are charged by the electromagnetic (EM) field a microwave produces. SDC then modifies the EM-field strength to desired levels by accurately moving food on a programmable turntable toward sensed hot and cold spots. To create a more skewed arbitrary thermal pattern SDC further introduces two types of programmable accessories: A microwave shield and a susceptor. We design and implement one experimental test bed by modifying a commercial off-the-shelf microwave oven. Our evaluation shows that SDC can programmatically create temperature deltas at a resolution of 21Â°C with a spatial resolution of 3 cm without the programmable accessories and 183Â°C with them. We further demonstrate how an SDC-enabled microwave can be enlisted to perform unexpected cooking tasks: Cooking meat and fat in bacon discriminatively and heating milk uniformly.;
Velocity in Software Engineering: From tectonic plate to F-16;Software engineering occupies an increasingly critical role in companies across all sectors but too many software initiatives end up both off target and over budget. A surer path is optimized for speed open to experimentation and learning agile and subject to regular course correcting. Good ideas tend to be abundant though execution at high velocity is elusive. The good news is that velocity is controllable companies can invest systematically to increase it.;
The case for RAMCloud;With scalable high-performance storage entirely in DRAM RAMCloud will enable a new breed of data-intensive applications.;
Untangling Enterprise Java: A new breed of framework helps eliminate crosscutting concerns.;Separation of concerns is one of the oldest concepts in computer science. The term was coined by Dijkstra in 1974.1 It is important because it simplifies software making it easier to develop and maintain. Separation of concerns is commonly achieved by decomposing an application into components. There are however crosscutting concerns which span (or cut across) multiple components. These kinds of concerns cannot be handled by traditional forms of modularization and can make the application more complex and difficult to maintain.;
Boolean satisfiability: theory and engineering;I would like to start out this article with an odd yet surprisingly uncontroversial assertion which is this: programmers are human. I wish to use this as a premise to explore how to improve the programmerâ€™s lot. So please no matter your opinion on the subject grant me this assumption for the sake of argument.;
The SPACE of developer productivity;There's more to it than you think.;
"Purpose-Built Languages: While often breaking the rules of traditional language design the growing ecosystem of purpose-built little"" languages is an essential part of systems development.""";"In my college computer science lab two eternal debates flourished during breaks from long nights of coding and debugging: emacs versus vi?"" and ""what is the best programming language?"" Later as I began my career in industry I noticed that the debate over programming languages was also going on in the hallways of Silicon Valley campuses. It was the â€™90s and at Sun many of us were watching Java claim significant mindshare among developers particularly those previously developing in C or C++.""";
Metaphors We Compute By: Code is a story that explains how to solve a particular problem.;Programmers must be able to tell a story with their code explaining how they solved a particular problem. Like writers programmers must know their metaphors. Many metaphors will be able to explain a concept but you must have enough skill to choose the right one thatâ€™s able to convey your ideas to future programmers who will read the code. Thus you cannot use every metaphor you know. You must master the art of metaphor selection of meaning amplification. You must know when to add and when to subtract. You will learn to revise and rewrite code as a writer does. Once thereâ€™s nothing else to add or remove you have finished your work. The problem you started with is now the solution. Is that the meaning you intended to convey in the first place?;
DSL for the Uninitiated: Domain-specific languages bridge the semantic gap in programming.;One of the main reasons why software projects fail is the lack of communication between the business users who actually know the problem domain and the developers who design and implement the software model. Business users understand the domain terminology and they speak a vocabulary that may be quite alien to the software people itâ€™s no wonder that the communication model can break down right at the beginning of the project life cycle.;
Bias on the web;Bias in Web data and use taints the algorithms behind Web-based applications delivering equally biased results.;
Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks;Convolutional neural network (CNN) has been widely employed for image recognition because it can achieve high accuracy by emulating behavior of optic nerves in living creatures. Recently rapid growth of modern applications based on deep learning algorithms has further improved research and implementations. Especially various accelerators for deep CNN have been proposed based on FPGA platform because it has advantages of high performance reconfigurability and fast development round etc. Although current FPGA accelerators have demonstrated better performance over generic processors the accelerator design space has not been well exploited. One critical problem is that the computation throughput may not well match the memory bandwidth provided an FPGA platform. Consequently existing approaches cannot achieve best performance due to under-utilization of either logic resource or memory bandwidth. At the same time the increasing complexity and scalability of deep learning applications aggravate this problem. In order to overcome this problem we propose an analytical design scheme using the roofline model. For any solution of a CNN design we quantitatively analyze its computing throughput and required memory bandwidth using various optimization techniques such as loop tiling and transformation. Then with the help of rooine model we can identify the solution with best performance and lowest FPGA resource requirement. As a case study we implement a CNN accelerator on a VC707 FPGA board and compare it to previous approaches. Our implementation achieves a peak performance of 61.62 GFLOPS under 100MHz working frequency which outperform previous approaches significantly.;
Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays;Algorand is a new cryptocurrency that confirms transactions with latency on the order of a minute while scaling to many users. Algorand ensures that users never have divergent views of confirmed transactions even if some of the users are malicious and the network is temporarily partitioned. In contrast existing cryptocurrencies allow for temporary forks and therefore require a long time on the order of an hour to confirm transactions with high confidence.Algorand uses a new Byzantine Agreement (BA) protocol to reach consensus among users on the next set of transactions. To scale the consensus to many users Algorand uses a novel mechanism based on Verifiable Random Functions that allows users to privately check whether they are selected to participate in the BA to agree on the next set of transactions and to include a proof of their selection in their network messages. In Algorand's BA protocol users do not keep any private state except for their private keys which allows Algorand to replace participants immediately after they send a message. This mitigates targeted attacks on chosen participants after their identity is revealed.We implement Algorand and evaluate its performance on 1000 EC2 virtual machines simulating up to 500000 users. Experimental results show that Algorand confirms transactions in under a minute achieves 125x Bitcoin's throughput and incurs almost no penalty for scaling to more users.;
Proceedings of the 26th Symposium on Operating Systems Principles;Graphics architectures are in the midst of a major transition. In the past these were specialized architectures designed to support a single rendering algorithm: the standard Z buffer. Realtime 3D graphics has now advanced to the point where the Z-buffer algorithm has serious shortcomings for generating the next generation of higher-quality visual effects demanded by games and other interactive 3D applications. There is also a desire to use the high computational capability of graphics architectures to support collision detection approximate physics simulations scene management and simple artificial intelligence. In response to these forces graphics architectures are evolving toward a general-purpose parallel-programming model that will support a variety of image-synthesis algorithms as well as nongraphics tasks.;
Coding for the Code: Can models provide the DNA for software development?;Despite the considerable effort invested by industry and academia in modeling standards such as UML (Unified Modeling Language) software modeling has long played a subordinate role in commercial software development. Although modeling is generally perceived as state of the art and thus as something that ought to be done its appreciation seems to pale along with the progression from the early more conceptual phases of a software project to those where the actual handcrafting is done. As a matter of fact while models have been found useful for documentation purposes and as rough sketches of implementations their ultimate value has been severely limited by their ambiguity and tendency to get out of sync with the final code.;
Injecting Errors for Fun and Profit: Error-detection and correction features are only as good as our ability to test them.;It is an unfortunate fact of life that anything with moving parts eventually wears out and malfunctions and electronic circuitry is no exception. In this case of course the moving parts are electrons. In addition to the wear-out mechanisms of electromigration (the moving electrons gradually push the metal atoms out of position causing wires to thin thus increasing their resistance and eventually producing open circuits) and dendritic growth (the voltage difference between adjacent wires causes the displaced metal atoms to migrate toward each other just as magnets will attract each other eventually causing shorts) electronic circuits are also vulnerable to background radiation. These fast-moving charged particles knock electrons out of their orbits leaving ionized trails in their wake. Until those electrons find their way back home a conductive path exists where there once was none.;
How OSGi Changed My Life: The promises of the Lego hypothesis have yet to materialize fully but they remain a goal worth pursuing.;In the early 1980s I discovered OOP (object-oriented programming) and fell in love with it head over heels. As usual this kind of love meant convincing management to invest in this new technology and most important of all send me to cool conferences. So I pitched the technology to my manager. I sketched him the rosy future how one day we would create applications from ready-made classes. We would get those classes from a repository put them together and voila a new application would be born. Today we take objects more or less for granted but if I am honest the pitch I gave to my manager in 1985 never really materialized. The reuse of objects never achieved the levels foreseen by people such as Brad Cox with his software-IC model and many others including myself. Still this Lego hypothesis remains a grail worth pursuing.;
Behavioral programming;A novel paradigm for programming reactive systems centered on naturally specified modular behavior.;
Toward verified artificial intelligence;Making AI more trustworthy with a formal methods-based approach to AI system verification and validation.;
Enterprise SSDs: Solid-state drives are finally ready for the enterprise. But beware not all SSDs are created alike.;For designers of enterprise systems ensuring that hardware performance keeps pace with application demands is a mind-boggling exercise. The most troubling performance challenge is storage I/O. Spinning media while exceptional in scaling areal density will unfortunately never keep pace with I/O requirements. The most cost-effective way to break through these storage I/O limitations is by incorporating high-performance SSDs (solid-state drives) into the systems.;
Caching XML Web Services for Mobility: In the face of unreliable connections and low bandwidth caching may offer reliable wireless access to Web services.;Web services are emerging as the dominant application on the Internet. The Web is no longer just a repository of information but has evolved into an active medium for providers and consumers of services: Individuals provide peer-to-peer services to access personal contact information or photo albums for other individuals individuals provide services to businesses for accessing personal preferences or tax information Web-based businesses provide consumer services such as travel arrangement (Orbitz) shopping (eBay) and e-mail (Hotmail) and several business-to-business (B2B) services such as supply chain management form important applications of the Internet.;
Collaboration in System Administration: For sysadmins solving problems usually involves collaborating with others. How can we make it more effective?;George was in trouble. A seemingly simple deployment was taking all morning and there seemed no end in sight. His manager kept coming in to check on his progress as the customer was anxious to have the deployment done. He was supposed to be leaving for a goodbye lunch for a departing co-worker adding to the stress. He had called in all kinds of help including colleagues an application architect technical support and even one of the system developers. He used e-mail instant messaging face-to-face contacts his phone and even his office mateâ€™s phone to communicate with everyone. And George was no novice. He had been working as a Web-hosting administrator for three years and he had a bachelorâ€™s degree in computer science. But it seemed that all the expertise being brought to bear was simply not enough. Why was George in trouble? Weâ€™ll find out.;
ACM CTO roundtable on mobile devices in the enterprise;Finding solutions as growth and fragmentation complicate mobile device support.;
Power-Efficient Software: Power-manageable hardware can help save energy but what can software developers do to address the problem?;"The rate at which power-management features have evolved is nothing short of amazing. Today almost every size and class of computer system from the smallest sensors and handheld devices to the big iron"" servers in data centers offers a myriad of features for reducing metering and capping power consumption. Without these features fan noise would dominate the office ambience and untethered laptops would remain usable for only a few short hours (and then only if one could handle the heat) while data-center power and cooling costs and capacity would become unmanageable.""";
Enterprise Grid Computing: Grid computing holds great promise for the enterprise data center but many technical and operational hurdles remain.;I have to admit a great measure of sympathy for the IT populace at large when it is confronted by the barrage of hype around grid technology particularly within the enterprise. Individual vendors have attempted to plant their flags in the notionally virgin technological territory and proclaim it as their own using terms such as grid autonomic self-healing self-managing adaptive utility and so forth. Analysts well analyze and try to make sense of it all and in the process each independently creates his or her own map of this terra incognita naming it policy-based computing organic computing and so on. Unfortunately this serves only to further muddy the waters for most people. All of these terms capture some aspect of the big pictureâ€”they all describe parts of solutions that seek to address essentially the same problems in similar waysâ€”but theyâ€™re never quite synonymous.;
Outsourcing: Devising a Game Plan: What types of projects make good candidates for outsourcing?;Your CIO just summoned you to duty by handing off the decision-making power about whether to outsource next years big development project to rewrite the internal billing system. Thatâ€™s quite a daunting task! How can you possibly begin to decide if outsourcing is the right option for your company? There are a few strategies that you can follow to help you avoid the pitfalls of outsourcing and make informed decisions. Outsourcing is not exclusively a technical issue but it is a decision that architects or development managers are often best qualified to make because they are in the best position to know what technologies make sense to keep in-house. Deciding what should and should not be outsourced is key to a successful game plan.;
Debugging AJAX in production;Lacking proper browser support what steps can we take to debug production AJAX code?;
Realtime Garbage Collection: Itâ€™s now possible to develop realtime systems using Java.;Traditional computer science deals with the computation of correct results. Realtime systems interact with the physical world so they have a second correctness criterion: they have to compute the correct result within a bounded amount of time. Simply building functionally correct software is hard enough. When timing is added to the requirements the cost and complexity of building the software increase enormously.;
Sentient Data Access via a Diverse Society of Devices: Todayâ€™s ubiquitous computing environment cannot benefit from the traditional understanding of a hierarchical file system.;"It has been more than ten years since such information appliances"" as ATMs and grocery store UPC checkout counters were introduced. For the office environment Mark Weiser began to articulate the notion of UbiComp and identified some of the salient features of the trends in 1991. Embedded computation is also becoming widespread. Microprocessors for example are finding themselves embedded into seemingly conventional pens that remember what they have written. Anti-lock brake systems in cars are controlled by fuzzy logic. And as a result of wireless computing miniaturization and new economies of scale such technologies as PDAs IM and mobile access to the Internet are almost taken for granted.""";
E-mail Authentication: What Why How? Perhaps we should have figured out what was going to happen when Usenet started  to go bad.;Internet e-mail was conceived in a different world than we live in today. It was a small tightly knit community and we didnâ€™t really have to worry too much about miscreants. Generally if someone did something wrong the problem could be dealt with through social means â€œshunningâ€ is very effective in small communities. Perhaps we should have figured out what was going to happen when Usenet started to go bad. Usenet was based on an inexpensive network called UUCP which was fairly easy to join so it gave us a taste of what happens when the community becomes larger and more distributedâ€”and harder to manage. Even the worst flame wars seemed fairly innocuous in the grand scheme of things and kill files were really enough but there was a seed of something ominous that was going to germinate all too soon.;
Will massive open online courses change how we teach?;Sharing recent experiences with an online course.;
The Singularity system;Safe modern programming languages let Microsoft rethink the architectural trade-offs in its experimental operating system.;
Jupiter rising: a decade of clos topologies and centralized control in Google's datacenter network;We present our approach for overcoming the cost operational complexity and limited scale endemic to datacenter networks a decade ago. Three themes unify the five generations of datacenter networks detailed in this paper. First multi-stage Clos topologies built from commodity switch silicon can support cost-effective deployment of building-scale networks. Second much of the general but complex decentralized network routing and management protocols supporting arbitrary deployment scenarios were overkill for single-operator pre-planned datacenter networks. We built a centralized control mechanism based on a global configuration pushed to all datacenter switches. Third modular hardware design coupled with simple robust software allowed our design to also support inter-cluster and wide-area networks. Our datacenter networks run at dozens of sites across the planet scaling in capacity by 100x over 10 years to more than 1 Pbps of bisection bandwidth. A more detailed version of this paper is available at Ref.;
Understanding scoping and defining user experience: a survey approach;Despite the growing interest in user experience (UX) it has been hard to gain a common agreement on the nature and scope of UX. In this paper we report a survey that gathered the views on UX of 275 researchers and practitioners from academia and industry. Most respondents agree that UX is dynamic context-dependent and subjective. With respect to the more controversial issues the authors propose to delineate UX as something individual (instead of social) that emerges from interacting with a product system service or an object. The draft ISO definition on UX seems to be in line with the survey findings although the issues of experiencing anticipated use and the object of UX will require further explication. The outcome of this survey lays ground for understanding scoping and defining the concept of user experience.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;We present an inexpensive tabletop loom that offers fully computational patterning while maintaining the flexibility of handweaving. Our loom can be assembled for under US$200 with 3D printed parts and it can be controlled straightforwardly over USB. Our loom is explicitly a hand loom: that is a weaver is required to operate the weaving process and may mediate row-by-row patterning and material specifics like yarn tension. Our approach combines the flexibility of fully analog handweaving with the computational affordances of digital fabrication: it enables the incorporation of special techniques and materials as well as allowing for the possibility of computational and creative interventions in the weaving process itself. In taking this approach we aim to serve a range of end users including artisans and researchers whether for skill-building for rapid prototyping or for creative reflection. We describe the mechanical and electronic implementation of our loom and show examples of its use for personal fabrication.;
Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems;Naiad is a distributed system for executing data parallel cyclic dataflow programs. It offers the high throughput of batch processors the low latency of stream processors and the ability to perform iterative and incremental computations. Although existing systems offer some of these features applications that require all three have relied on multiple platforms at the expense of efficiency maintainability and simplicity. Naiad resolves the complexities of combining these features in one framework.A new computational model timely dataflow underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataflow computation with timestamps that represent logical points in the computation and provide the basis for an efficient lightweight coordination mechanism.We show that many powerful high-level programming models can be built on Naiad's low-level primitives enabling such diverse tasks as streaming data analysis iterative machine learning and interactive graph mining. Naiad outperforms specialized systems in their target application domains and its unique features enable the development of new high-performance applications.;
Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles;The HEP (high energy physics) group at the California Institute of Technology started developing the MonALISA (Monitoring Agents using a Large Integrated Services Architecture) framework in 2002 aiming to provide a distributed service system capable of controlling and optimizing large-scale data-intensive applications. Its initial target field of applications is the grid systems and the networks supporting data processing and analysis for HEP collaborations. Our strategy in trying to satisfy the demands of data-intensive applications was to move to more synergetic relationships between the applications computing and storage facilities and the network infrastructure.;
Functional at Scale: Applying functional programming principles to distributed computing projects;Modern server software is demanding to develop and operate: it must be available at all times and in all locations it must reply within milliseconds to user requests it must respond quickly to capacity demands it must process a lot of data and even more traffic it must adapt quickly to changing product needs and in many cases it must accommodate a large engineering organization its many engineers the proverbial cooks in a big messy kitchen.;
CTO Roundtable: Virtualization Part I;Virtualization technology is hot again but for the right reasons?;
Verification of Safety-critical Software: Avionics software safety certification is achieved through objective-based standards.;Avionics software has become a keystone in todayâ€™s aircraft design. Advances in avionics systems have reduced aircraft weight thereby reducing fuel consumption enabled precision navigation improved engine performance and provided a host of other benefits. These advances have turned modern aircraft into flying data centers with computers controlling or monitoring many of the critical systems onboard. The software that runs these aircraft systems must be as safe as we can make it.;
The calculus of service availability;You're only as available as the sum of your dependencies.;
Finding high-quality content in social media;The quality of user-generated content varies drastically from excellent to abuse and spam. As the availability of such content increases the task of identifying high-quality content sites based on user contributions --social media sites -- becomes increasingly important. Social media in general exhibit a rich variety of information sources: in addition to the content itself there is a wide array of non-content information available such as links between items and explicit quality ratings from members of the community. In this paper we investigate methods for exploiting such community feedback to automatically identify high quality content. As a test case we focus on Yahoo! Answers a large community question/answering portal that is particularly rich in the amount and types of content and social interactions available in it. We introduce a general classification framework for combining the evidence from different sources of information that can be tuned automatically for a given social media type and quality definition. In particular for the community question/answering domain we show that our system is able to separate high-quality items from the rest with an accuracy close to that of humans;
Proceedings of the 2008 International Conference on Web Search and Data Mining;You have probably heard about MBT (model-based testing) but like many software-engineering professionals who have not used MBT you might be curious about othersâ€™ experience with this test-design method. From mid-June 2014 to early August 2014 we conducted a survey to learn how MBT users view its efficiency and effectiveness. The 2014 MBT User Survey a follow-up to a similar 2012 survey was open to all those who have evaluated or used any MBT approach. Its 32 questions included some from a survey distributed at the 2013 User Conference on Advanced Automated Testing. Some questions focused on the efficiency and effectiveness of MBT providing the figures that managers are most interested in. Other questions were more technical and sought to validate a common MBT classification scheme. A common classification scheme could help users understand both the general diversity and specific approaches. The 2014 survey provides a realistic picture of the current state of MBT practice. This article presents some highlights of the survey findings.;
Recipe for efficiency: principles of power-aware computing;Prior work on power management reflects recurring themes that can be leveraged to make future systems more energy efficient.;
Rebooting the CS publication process;A proposal for a new cost-free open-access publication model for computer science papers.;
Why SRE documents matter;How documentation enables SRE teams to manage new and existing services.;
Erlang for concurrent programming;Designed for concurrency from the ground up the Erlang language can be a valuable tool to help solve concurrent problems.;
Boolean satisfiability from theoretical hardness to practical success;Satisfiability solvers can now be effectively deployed in practical applications.;
Major-league SEMAT: Why Should an Executive Care? Becoming better faster cheaper and happier;"In todayâ€™s ever more competitive world boards of directors and executives demand that CIOs and their teams deliver more with less."" Studies show without any real surprise that there is no one-size-fits-all method to suit all software initiatives and that a practice-based approach with some light but effective degree of order and governance is the goal of most software-development departments.""";
How to Live in a Post-Meltdown and -Spectre World: Learn from the past to prepare for the next battle.;Spectre and Meltdown create a risk landscape that has more questions than answers. This article addresses how these vulnerabilities were triaged when they were announced and the practical defenses that are available. Ultimately these vulnerabilities present a unique set of circumstances but for the vulnerability management program at Goldman Sachs the response was just another day at the office.;
Ph.D. students must break away from undergraduate mentality;The Communications Web site http://cacm.acm.org features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications we'll publish selected posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMhttp://cacm.acm.org/blogs/blog-cacmJason Hong considers how students working on their doctorates in computer science must adapt and evolve to succeed.;
Reliability and Inter-rater Reliability in Qualitative Research: Norms and Guidelines for CSCW and HCI Practice;"What does reliability mean for building a grounded theory? What about when writing an auto-ethnography? When is it appropriate to use measures like inter-rater reliability (IRR)? Reliability is a familiar concept in traditional scientific practice but how and even whether to establish reliability in qualitative research is an oft-debated question. For researchers in highly interdisciplinary fields like computer-supported cooperative work (CSCW) and human-computer interaction (HCI) the question is particularly complex as collaborators bring diverse epistemologies and training to their research. In this article we use two approaches to understand reliability in qualitative research. We first investigate and describe local norms in the CSCW and HCI literature then we combine examples from these findings with guidelines from methods literature to help researchers answer questions like: should I calculate IRR?"" Drawing on a meta-analysis of a representative sample of CSCW and HCI papers from 2016-2018 we find that authors use a variety of approaches to communicate reliability notably IRR is rare occurring in around 1/9 of qualitative papers. We reflect on current practices and propose guidelines for reporting on reliability in qualitative research using IRR as a central example of a form of agreement. The guidelines are designed to generate discussion and orient new CSCW and HCI scholars and reviewers to reliability in qualitative research.""";
Agile and SEMAT - Perfect Partners: Combining agile and SEMAT yields more advantages than either one alone;Today as always many different initiatives are under way to improve the ways in which software is developed. The most popular and prevalent of these is the agile movement. One of the newer kids on the block is the SEMAT (Software Engineering Method and Theory) initiative. As with any new initiative people are struggling to see how it fits into the world and relates to all the other things going on. For example does it improve or replace their current ways of working? Is it like lean which supports and furthers the aims of the agile movement or is it more like waterfall planning which is in opposition to an agile approach?;
Arrogance in business planning;Technology business plans that assume no competition---ever.;
Uncomfortable user experience;How to create and resolve discomfort for a thrilling and memorable experience.;
SMPL: a skinned multi-person linear model;We present a learned model of human body shape and pose-dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines. Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex-based model that accurately represents a wide variety of body shapes in natural human poses. The parameters of the model are learned from data including the rest pose template blend weights pose-dependent blend shapes identity-dependent blend shapes and a regressor from vertices to joint locations. Unlike previous models the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices. This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses. We quantitatively evaluate variants of SMPL using linear or dual-quaternion blend skinning and show that both are more accurate than a Blend-SCAPE model trained on the same data. We also extend SMPL to realistically model dynamic soft-tissue deformations. Because it is based on blend skinning SMPL is compatible with existing rendering engines and we make it available for research purposes.;
Using remote cache service for bazel;Save time by sharing and reusing build and test output.;
SATURN: an introduction to the internet of materials;We envision a new generation of computation devices computational materials which are self-sustainable cheaply manufactured at scale and exhibit form factors that are easily incorporated into everyday environments. These materials can enable ordinary objects such as walls carpet furniture jewelry and cups to do computational things without looking like today's computational devices. Self-powered Audio Triboelectric Ultra-thin Rollable Nanogenerator (SATURN) is an early example of a computational material that can sense vibration such as sound. SATURN can be manufactured from inexpensive components is flexible so that it can be integrated into many different surfaces and powers itself through the sound or vibration it is sensing. Using radio backscatter we demonstrate that SATURN's sensed data is passively transmitted to remote computers alleviating the need for batteries or any wired power for the material itself. The proliferation of these types of computational materials ushers an era of Internet of Materials further blurring the distinction between the physical and digital worlds.;
Enterprise Software as Service: Online services are changing the nature of software.;While the practice of outsourcing business functions such as payroll has been around for decades its realization as online software services has only recently become popular. In the online service model a provider develops an application and operates the servers that host it. Customers access the application over the Internet using industry-standard browsers or Web services clients. A wide range of online applications including e-mail human resources business analytics CRM (customer relationship management) and ERP (enterprise resource planning) are available.;
Java security architecture revisited;Difficult technical problems and tough business challenges.;
Bridging the Object-Relational Divide: ORM technologies can simplify data access but be aware of the challenges that come with introducing this new layer of abstraction.;Modern applications are built using two very different technologies: object-oriented programming for business logic and relational databases for data storage. Object-oriented programming is a key technology for implementing complex systems providing benefits of reusability robustness and maintainability. Relational databases are repositories for persistent data. ORM (object-relational mapping) is a bridge between the two that allows applications to access relational data in an object-oriented way.;
Thinking clearly about performance part 2;More important principles to keep in mind when designing high-performance software.;
Too Darned Big to Test: Testing large systems is a daunting task but there are steps we can take to ease the pain.;The increasing size and complexity of software coupled with concurrency and distributed systems has made apparent the ineffectiveness of using only handcrafted tests. The misuse of code coverage and avoidance of random testing has exacerbated the problem. We must start again beginning with good design (including dependency analysis) good static checking (including model property checking) and good unit testing (including good input selection). Code coverage can help select and prioritize tests to make you more efficient as can the all-pairs technique for controlling the number of configurations. Finally testers can use models to generate test coverage and good stochastic tests and to act as test oracles.;
The Science of Managing Data Science: Lessons learned managing a data science research team;"What are they doing all day? When I first took over as VP of Engineering at a startup doing data mining and machine learning research this was what the other executives wanted to know. They knew the team was super smart and they seemed like they were working really hard but the executives had lots of questions about the work itself. How did they know that the work they were doing was the right"" work? Were there other projects they could be doing instead? And how could we get this research into the hands of our customers faster?""";
Verification of safety-critical software;Avionics software safety certification is achieved through objective-based standards.;
Biology as reactivity;Exploring the connection of biology with reactive systems to better understand living systems.;
Toward energy-efficient computing;What will it take to make server-side computing more energy efficient?;
Social Perception: Modeling human interaction for the next generation of communication services;Bob manages a team that designs and builds widgets. Life would be sweet except that Bobâ€™s team is distributed over three sites located in three different time zones. Bob used to collect lots of frequent flyer miles traveling to attend meetings. Lately however business travel has evolved into a humanly degrading wasteful ordeal. So Bob has invested in a high-bandwidth video communications system to cut down on business travel. Counting direct costs the system was supposed to pay for itself within three months. There is a problem however.;
Time but Faster: A computing adventure about time through the looking glass;"The first premise was summed up perfectly by the late Douglas Adams in The Hitchhikerâ€™s Guide to the Galaxy: Time is an illusion. Lunchtime doubly so."" The concept of time when colliding with decoupled networks of computers that run at billions of operations per second is... well the truth of the matter is that you simply never really know what time it is. That is why Leslie Lamportâ€™s seminal paper on Lamport timestamps was so important to the industry but this article is actually about wall-clock time or a reasonably useful estimation of it.""";
The WEKA data mining software: an update;More than twelve years have elapsed since the first public release of WEKA. In that time the software has been rewritten entirely from scratch evolved substantially and now accompanies a text on data mining [35]. These days WEKA enjoys widespread acceptance in both academia and business has an active community and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench reviews the history of the project and in light of the recent 3.6 stable release briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.;
Is Moore's Party over?;Exploring the many distinctive elements that make securing HPC systems much different than securing traditional systems.;
Enhanced Debugging with Traces: An essential technique used in emulator development is a useful addition to any programmerâ€™s toolbox.;Creating an emulator to run old programs is a difficult task. You need a thorough understanding of the target hardware and the correct functioning of the original programs that the emulator is to execute. In addition to being functionally correct the emulator must hit a performance target of running the programs at their original realtime speed. Reaching these goals inevitably requires a considerable amount of debugging. The bugs are often subtle errors in the emulator itself but could also be a misunderstanding of the target hardware or an actual known bug in the original program. (It is also possible the binary data for the original program has become subtly corrupted or is not the version expected.) Solving these problems requires some unusual debugging techniques.;
Coding Smart: People vs. Tools: Tools can help developers be more productive but theyâ€™re no replacement for thinking.;Cool tools are seductive. When we think about software productivity tools naturally come to mind. When we see pretty new tools we tend to believe that their amazing features will help us get our work done much faster. Because every software engineer uses software productivity tools daily and all team managers have to decide which tools their members will use the latest and greatest look appealing.;
A Tale of Two Cities: Software Developers Working from Home during the COVID-19 Pandemic;The COVID-19 pandemic has shaken the world to its core and has provoked an overnight exodus of developers who normally worked in an office setting to working from home. The magnitude of this shift and the factors that have accompanied this new unplanned work setting go beyond what the software engineering community has previously understood to be remote work. To find out how developers and their productivity were affected we distributed two surveys (with a combined total of 3634 responses that answered all required questions) weeks apart to understand the presence and prevalence of the benefits challenges and opportunities to improve this special circumstance of remote work. From our thematic qualitative analysis and statistical quantitative analysis we find that there is a dichotomy of developer experiences influenced by many different factors (that for some are a benefit while for others a challenge). For example a benefit for some was being close to family members but for others having family members share their working space and interrupting their focus was a challenge. Our surveys led to powerful narratives from respondents and revealed the scale at which these experiences exist to provide insights as to how the future of (pandemic) remote work can evolve.;
Slimium: Debloating the Chromium Browser with Feature Subsetting;Today a web browser plays a crucial role in offering a broad spectrum of web experiences. The most popular browser Chromium has become an extremely complex application to meet ever-increasing user demands exposing unavoidably large attack vectors due to its large code base. Code debloating attracts attention as a means of reducing such a potential attack surface by eliminating unused code. However it is very challenging to perform sophisticated code removal without breaking needed functionalities because Chromium operates on a large number of closely connected and complex components such as a renderer and JavaScript engine. In this paper we present Slimium a debloating framework for a browser (i.e. Chromium) that harnesses a hybrid approach for a fast and reliable binary instrumentation. The main idea behind Slimium is to determine a set of features as a debloating unit on top of a hybrid (i.e. static dynamic heuristic) analysis and then leverage feature subsetting to code debloating. It aids in i) focusing on security-oriented features ii) discarding unneeded code simply without complications and iii)~reasonably addressing a non-deterministic path problem raised from code complexity. To this end we generate a feature-code map with a relation vector technique and prompt webpage profiling results. Our experimental results demonstrate the practicality and feasibility of Slimium for 40 popular websites as on average it removes 94 CVEs (61.4%) by cutting down 23.85 MB code (53.1%) from defined features (21.7% of the whole) in Chromium.;
Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security;Deployed AI systems often do not work. They can be constructed haphazardly deployed indiscriminately and promoted deceptively. However despite this reality scholars the press and policymakers pay too little attention to functionality. This leads to technical and policy solutions focused on â€œethicalâ€ or value-aligned deployments often skipping over the prior question of whether a given system functions or provides any benefits at all. To describe the harms of various types of functionality failures we analyze a set of case studies to create a taxonomy of known AI functionality issues. We then point to policy and organizational responses that are often overlooked and become more readily available once functionality is drawn into focus. We argue that functionality is a meaningful AI policy challenge operating as a necessary first step towards protecting affected communities from algorithmic harm.;
Proceedings of the 2022 ACM Conference on Fairness Accountability and Transparency;Performance measurements often go wrong reporting surface-level results that are more marketing than science.;
Using Remote Cache Service for Bazel: Save time by sharing and reusing build and test output;Remote cache service is a new development that significantly saves time in running builds and tests. It is particularly useful for a large code base and any size of development team. Bazel is an actively developed open-source build and test system that aims to increase productivity in software development. It has a growing number of optimizations to improve the performance of daily development tasks.;
Getting Gigascale Chips: Challenges and Opportunities in Continuing Mooreâ€™s Law;Processor performance has increased by five orders of magnitude in the last three decades made possible by following Mooreâ€™s law - that is continued technology scaling improved transistor performance to increase frequency additional (to avoid repetition) integration capacity to realize complex architectures and reduced energy consumed per logic operation to keep power dissipation within limits. Advances in software technology such as rich multimedia applications and runtime systems exploited this performance explosion delivering to end users higher productivity seamless Internet connectivity and even multimedia and entertainment.;
Swift: Delay is Simple and Effective for Congestion Control in the Datacenter;We report on experiences with Swift congestion control in Google datacenters. Swift targets an end-to-end delay by using AIMD control with pacing under extreme congestion. With accurate RTT measurement and care in reasoning about delay targets we find this design is a foundation for excellent performance when network distances are well-known. Importantly its simplicity helps us to meet operational challenges. Delay is easy to decompose into fabric and host components to separate concerns and effortless to deploy and maintain as a congestion signal while the datacenter evolves. In large-scale testbed experiments Swift delivers a tail latency of &lt50Î¼s for short RPCs with near-zero packet drops while sustaining ~100Gbps throughput per server. This is a tail of &lt3x the minimal latency at a load close to 100%. In production use in many different clusters Swift achieves consistently low tail completion times for short RPCs while providing high throughput for long RPCs. It has loss rates that are at least 10x lower than a DCTCP protocol and handles O(10k) incasts that sharply degrade with DCTCP.;
Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications Technologies Architectures and Protocols for Computer Communication;Applying lessons from software languages to hardware languages using Bluespec SystemVerilog.;
Real-world String Comparison: How to handle Unicode sequences correctly;In many languages a string comparison is a pitfall for beginners. With any Unicode string as input a comparison often causes problems even for advanced users. The semantic equivalence of different characters in Unicode requires a normalization of the strings before comparing them. This article shows how to handle Unicode sequences correctly. The comparison of two strings for equality often raises questions concerning the difference between comparison by value comparison of object references strict equality and loose equality. The most important aspect is semantic equivalence.;
Orchestrating an Automated Test Lab: Composing a score can help us manage the complexity of testing distributed apps.;Networking and the Internet are encouraging increasing levels of interaction and collaboration between people and their software. Whether users are playing games or composing legal documents their applications need to manage the complex interleaving of actions from multiple machines over potentially unreliable connections. As an example Silicon Chalk is a distributed application designed to enhance the in-class experience of instructors and students. Its distributed nature requires that we test with multiple machines. Manual testing is too tedious expensive and inconsistent to be effective. While automating our testing however we have found it very labor intensive to maintain a set of scripts describing each machineâ€™s portion of a given test. Maintainability suffers because the test description is spread over several files.;
Where did my 256 GB go? A Measurement Analysis of Storage Consumption on Smart Mobile Devices;This work presents the first-ever detailed and large-scale measurement analysis of storage consumption behavior of applications (apps) on smart mobile devices. We start by carrying out a five-year longitudinal static analysis of millions of Android apps to study the increase in their sizes over time and identify various sources of app storage consumption. Our study reveals that mobile apps have evolved as large monolithic packages that are packed with features to monetize/engage users and optimized for performance at the cost of redundant storage consumption.We also carry out a mobile storage usage study with 140 Android participants. We built and deployed a lightweight context-aware storage tracing tool called cosmos on each participant's device. Leveraging the traces from our user study we show that only a small fraction of apps/features are actively used and usage is correlated to user context. Our findings suggest a high degree of app feature bloat and unused functionality which leads to inefficient use of storage. Furthermore we found that apps are not constrained by storage quota limits and developers freely abuse persistent storage by frequently caching data creating debug logs user analytics and downloading advertisements as needed.Finally drawing upon our findings we discuss the need for efficient mobile storage management and propose an elastic storage design to reclaim storage space when unused. We further identify research challenges and quantify expected storage savings from such a design. We believe our findings will be valuable to the storage research community as well as mobile app developers.;
Federated learning and privacy;Building privacy-preserving systems for machine learning and data science on decentralized data.;
The IDAR Graph: An improvement over UML;"UML is the de facto standard for representing object-oriented designs. It does a fine job of recording designs but it has a severe problem: its diagrams donâ€™t convey what humans need to know making them hard to understand. This is why most software developers use UML only when forced to. People understand an organization such as a corporation in terms of a control hierarchy. When faced with an organization of people or objects the first question usually is Whatâ€™s controlling all this?"" Surprisingly UML has no concept of one object controlling another. Consequently in every type of UML diagram no object appears to have greater or lesser control than its neighbors. These problems mean designs tend to become messy during both initial implementation and maintenance resulting in more bugs and delays.""";
Methodologies for data quality assessment and improvement;The literature provides a wide range of techniques to assess and improve the quality of data. Due to the diversity and complexity of these techniques research has recently focused on defining methodologies that help the selection customization and application of data quality assessment and improvement techniques. The goal of this article is to provide a systematic and comparative description of such methodologies. Methodologies are compared along several dimensions including the methodological phases and steps the strategies and techniques the data quality dimensions the types of data and finally the types of information systems addressed by each methodology. The article concludes with a summary description of each methodology.;
Too Big NOT to Fail: Embrace failure so it doesnâ€™t embrace you.;Web-scale infrastructure implies LOTS of servers working together often tens or hundreds of thousands of servers all working toward the same goal. How can the complexity of these environments be managed? How can commonality and simplicity be introduced?;
Is There a Single Method for the Internet of Things? Essence can keep software development for the IoT from becoming unwieldy.;The Industrial Internet Consortium predicts the IoT (Internet of Things) will become the third technological revolution after the Industrial Revolution and the Internet Revolution. Its impact across all industries and businesses can hardly be imagined. Existing software (business telecom aerospace defense etc.) is expected to be modified or redesigned and a huge amount of new software solving new problems will have to be developed. As a consequence the software industry should welcome new and better methods.;
Massively Multiplayer Middleware: Building scaleable middleware for ultra-massive online games teaches a lesson we all can use: Big project simple design.;Wish is a multiplayer online fantasy role-playing game being developed by Mutable Realms. It differs from similar online games in that it allows tens of thousands of players to participate in a single game world. Allowing such a large number of players requires distributing the processing load over a number of machines and raises the problem of choosing an appropriate distribution technology.;
From IR to Search and Beyond: Searching has come a long way since the 60s but have we only just begun?;Itâ€™s been nearly 60 years since Vannevar Bushâ€™s seminal article â€™As We May Thinkâ€™ portrayed the image of a scholar aided by a machine â€œa device in which an individual stores all his books records and communications and which is mechanized so that it may be consulted with exceeding speed and flexibility.â€;
Surviving software dependencies;Software reuse is finally here but comes with risks.;
Proving program termination;In contrast to popular belief proving termination is not always impossible.;
CTO Roundtable: Virtualization Part II;When it comes to virtualization platforms experts say focus first on the services to be delivered.;
From COM to Common: Component softwareâ€™s 10-year journey toward ubiquity;Ten years ago the term component software meant something relatively specific and concrete. A small number of software component frameworks more or less defined the concept for most people. Today few terms in the software industry are less precise than component software. There are now many different forms of software componentry for many different purposes. The technologies and methodologies of 10 years ago have evolved in fundamental ways and have been joined by an explosion of new technologies and approaches that have redefined our previously held notions of component software.;
Image retrieval: Ideas influences and trends of the new age;We have witnessed great interest and a wealth of promise in content-based image retrieval as an emerging technology. While the last decade laid foundation to such promise it also paved the way for a large number of new techniques and systems got many new people involved and triggered stronger association of weakly related fields. In this article we survey almost 300 key theoretical and empirical contributions in the current decade related to image retrieval and automatic image annotation and in the process discuss the spawning of related subfields. We also discuss significant challenges involved in the adaptation of existing image retrieval techniques to build systems that can be useful in the real world. In retrospect of what has been achieved so far we also conjecture what the future may hold for image retrieval research.;
Global Pandemic and Rapid New Product Development of Medical Products;New product development is a strenuous and long process for companies. When the COVID-19 disease turned into a global pandemic governments announced the need for various medical products that were scarce and at the same time imposed lockdowns and trade restrictions. During this period rapid new product development of medical products was attempted by many companies worldwide using their existing supply chains. Data of 240 companies from non-medical product-segment background launching new medical products were collected and analyzed. Two case studies of Indian companies responding to shortages of ventilators and PPE are presented. A critical reflection of a new way of new product development and cooperation across firms is discussed.;
Now that we can write simultaneously how do we use that to our advantage?;Word processors now make it possible for many authors to work on the same document concurrently. But what can they actually do?;
Gaming Graphics: The Road to Revolution: From laggard to leader game graphics are taking us in new directions.;It has been a long journey from the days of multicolored sprites on tiled block backgrounds to the immersive 3D environments of modern games. What used to be a job for a single game creator is now a multifaceted production involving staff from every creative discipline. The next generation of console and home computer hardware is going to bring a revolutionary leap in available computing power a teraflop (trillion floating-point operations per second) or more will be on tap from commodity hardware. This leap in power will bring with it a leap in expectations both on the part of the consumer and the creative professional.;
Roofline: an insightful visual performance model for multicore architectures;The Roofline model offers insight on how to improve the performance of software and hardware.;
The ideal HPC programming language;Maybe it's Fortran. Or maybe it just doesn't matter.;
eBP: an ear-worn device for frequent and comfortable blood pressure monitoring;Frequent blood pressure monitoring is the key to diagnosis and treatments of many severe diseases. However the conventional ambulatory methods require patients to carry a blood pressure (BP) monitoring device for 24 h and conduct the measurement every 10--15 min. Despite their extensive usage wearing the wrist/arm-based BP monitoring device for a long time has a significant impact on users' daily activities. To address the problem we developed eBP to measure blood pressure (BP) from inside user's ear aiming to minimize the measurement's impact on users' normal activities although maximizing its comfort level.The key novelty of eBP includes (1) a light-based inflatable pulse sensor which goes inside the ear (2) a digital air pump with a fine controller and (3) BP estimation algorithms that eliminate the need of blocking the blood flow inside the ear.Through the comparative study of 35 subjects eBP can achieve the average error of 1.8 mmHg for systolic (high-pressure value) and -3.1 mmHg for diastolic (low-pressure value) with the standard deviation error of 7.2 mmHg and 7.9 mmHg respectively. These results satisfy the FDA's AAMI standard which requires a mean error of less than 5 mmHg and a standard deviation of less than 8 mmHg.;
DNS Cache Poisoning Attack Reloaded: Revolutions with Side Channels;"In this paper we report a series of flaws in the software stack that leads to a strong revival of DNS cache poisoning --- a classic attack which is mitigated in practice with simple and effective randomization-based defenses such as randomized source port. To successfully poison a DNS cache on a typical server an off-path adversary would need to send an impractical number of $2^32 $ spoofed responses simultaneously guessing the correct source port (16-bit) and transaction ID (16-bit). Surprisingly we discover weaknesses that allow an adversary to divide and conquer'' the space by guessing the source port first and then the transaction ID (leading to only $2^16 +2^16 $ spoofed responses). Even worse we demonstrate a number of ways an adversary can extend the attack window which drastically improves the odds of success. The attack affects all layers of caches in the DNS infrastructure such as DNS forwarder and resolver caches and a wide range of DNS software stacks including the most popular BIND Unbound and dnsmasq running on top of Linux and potentially other operating systems. The major condition for a victim being vulnerable is that an OS and its network is configured to allow ICMP error replies. From our measurement we find over 34% of the open resolver population on the Internet are vulnerable (and in particular 85% of the popular DNS services including Google's 8.8.8.8). Furthermore we comprehensively validate the proposed attack with positive results against a variety of server configurations and network conditions that can affect the success of the attack in both controlled experiments and a production DNS resolver (with authorization).""";
Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security;As storage systems grow larger and larger protecting their data for long-term storage is becoming ever more challenging.;
Document &amp Media Exploitation: The DOMEX challenge is to turn digital bits into actionable intelligence.;A computer used by Al Qaeda ends up in the hands of a Wall Street Journal reporter. A laptop from Iran is discovered that contains details of that countryâ€™s nuclear weapons program. Photographs and videos are downloaded from terrorist Web sites. As evidenced by these and countless other cases digital documents and storage devices hold the key to many ongoing military and criminal investigations. The most straightforward approach to using these media and documents is to explore them with ordinary toolsâ€”open the word files with Microsoft Word view the Web pages with Internet Explorer and so on.;
Automating data science;Given the complexity of data science projects and related demand for human expertise automation has the potential to transform the data science process.;
The worsening state of ransomware;Sophisticated dangerous ransomware is the new normal â€¦ and there is no simple fix.;
Making a Case for Efficient Supercomputing: It is time for the computing community to use alternative metrics for evaluating performance.;A supercomputer evokes images of â€œbig ironâ€œ and speed it is the Formula 1 racecar of computing. As we venture forth into the new millennium however I argue that efficiency reliability and availability will become the dominant issues by the end of this decade not only for supercomputing but also for computing in general.;
WebRTC - Realtime Communication for the Open Web Platform: What was once a way to bring audio and video to the web has expanded into more use cases we could ever imagine.;In this time of pandemic the world has turned to Internet-based RTC (realtime communication) as never before. The number of RTC products has over the past decade exploded in large part because of cheaper high-speed network access and more powerful devices but also because of an open royalty-free platform called WebRTC. WebRTC is growing from enabling useful experiences to being essential in allowing billions to continue their work and education and keep vital human contact during a pandemic. The opportunities and impact that lie ahead for WebRTC are intriguing indeed.;
UML Fever: Diagnosis and Recovery: Acknowledgment is only the first step toward recovery from this potentially devastating affliction.;The Institute of Infectious Diseases has recently published research confirming that the many and varied strains of UML Fever1 continue to spread worldwide indiscriminately infecting software analysts engineers and managers alike. One of the feverâ€™s most serious side effects has been observed to be a significant increase in both the cost and duration of developing software products. This increase is largely attributable to a decrease in productivity resulting from fever-stricken individuals investing time and effort in activities that are of little or no value to producing deliverable products. For example afflictees of Open Loop Fever continue to create UML (Unified Modeling Language) diagrams for unknown stakeholders. Victims of Comfort Zone Fever remain glued in the modeling space postponing the development of software. And those suffering from Gnatâ€™s Eyebrow Fever continue creating models that glorify each and every Boolean value of prospective software implementations.;
A programmable programming language;As the software industry enters the era of language-oriented programming it needs programmable programming languages.;
From the EDVAC to WEBVACs: Cloud computing for computer scientists;By now everyone has heard of cloud computing and realized that it is changing how both traditional enterprise IT and emerging startups are building solutions for the future. Is this trend toward the cloud just a shift in the complicated economics of the hardware and software industry or is it a fundamentally different way of thinking about computing? Having worked in the industry I can confidently say it is both.;
What DNS is not;DNS is many things to many people---perhaps too many things to too many people.;
Building certified concurrent OS kernels;Operating system (OS) kernels form the backbone of system software. They can have a significant impact on the resilience and security of today's computers. Recent efforts have demonstrated the feasibility of formally verifying simple general-purpose kernels but they have ignored the important issues of concurrency which include not just user and I/O concurrency on a single core but also multi-core parallelism with fine-grained locking. In this work we present CertiKOS a novel compositional framework for building verified concurrent OS kernels. Concurrency allows interleaved execution of programs belonging to different abstraction layers and running on different CPUs/threads. Each such layer can have a different set of observable events. In CertiKOS these layers and their observable events can be formally specified and each module can then be verified at the abstraction level it belongs to. To link all the verified pieces together CertiKOS enforces a so-called contextual refinement property for every such piece which states that the implementation will behave like its specification under any concurrent context with any valid interleaving. Using CertiKOS we have successfully developed a practical concurrent OS kernel called mC2 and built the formal proofs of its correctness in Coq. The mC2 kernel is written in 6500 lines of C and x86 assembly and runs on stock x86 multicore machines. To our knowledge this is the first correctness proof of a general-purpose concurrent OS kernel with fine-grained locking.;
SIP: Basics and Beyond: More than just a simple telephony application protocol SIP is a framework for developing communications systems.;Chances are youâ€™re already using SIP (Session Initiation Protocol). It is one of the key innovations driving the current evolution of communications systems. Its first major use has been signaling in Internet telephony. Large carriers have been using SIP inside their networks for interconnect and trunking across long distances for several years. If youâ€™ve made a long-distance call part of that call probably used SIP.;
The long road to 64 bits;Double double toil and trouble ---Shakespeare Macbeth Act 4 Scene 1;
Moving to the edge: a CTO roundtable on network virtualization;Leading experts debate how virtualization and clouds impact network service architectures.;
Mobile Media: Making It a Reality: Two prototype apps reveal the challenges in delivering mobile media services.;"Many future mobile applications are predicated on the existence of rich interactive media services. The promise and challenge of such services is to provide applications under the most hostile conditions - and at low cost to a user community that has high expectations. Context-aware services require information about who where when and what a user is doing and must be delivered in a timely manner with minimum latency. This article reveals some of the current state-of-the-art magic"" and the research challenges.""";
Blockchain technology: what is it good for?;Industry's dreams and fears for this new technology.;
Soli: ubiquitous gesture sensing with millimeter wave radar;This paper presents Soli a new robust high-resolution low-power miniature gesture sensing technology for human-computer interaction based on millimeter-wave radar. We describe a new approach to developing a radar-based sensor optimized for human-computer interaction building the sensor architecture from the ground up with the inclusion of radar design principles high temporal resolution gesture tracking a hardware abstraction layer (HAL) a solid-state radar chip and system architecture interaction models and gesture vocabularies and gesture recognition. We demonstrate that Soli can be used for robust gesture recognition and can track gestures with sub-millimeter accuracy running at over 10000 frames per second on embedded hardware.;
Hardware Trojan horse detection using gate-level characterization;Hardware Trojan horses (HTHs) are the malicious altering of hardware specification or implementation in such a way that its functionality is altered under a set of conditions defined by the attacker. There are numerous HTHs sources including untrusted foundries synthesis tools and libraries testing and verification tools and configuration scripts. HTH attacks can greatly comprise security and privacy of hardware users either directly or through interaction with pertinent systems and application software or with data. However while there has been a huge research and development effort for detecting software Trojan horses surprisingly HTHs are rarely addressed. HTH detection is a particularly difficult task in modern and pending deep submicron technologies due to intrinsic manufacturing variability.Our goal is to provide an impetus for HTH research by creating a generic and easily applicable set of techniques and tools for HTH detection. We start by introducing a technique for recovery of characteristics of gates in terms of leakage current switching power and delay which utilizes linear programming to solve a system of equations created using non-destructive measurements of power or delays. This technique is combined with constraint manipulation techniques to detect embedded HTHs. The effectiveness of the approach is demonstrated on a number of standard benchmarks.;
Proceedings of the 46th Annual Design Automation Conference;Machine learning is enabling a myriad innovations including new algorithms for cancer diagnosis and self-driving cars. The broad use of machine learning makes it important to understand the extent to which machine-learning algorithms are subject to attack particularly when used in applications where physical security or safety is at risk.In this paper we focus on facial biometric systems which are widely used in surveillance and access control. We define and investigate a novel class of attacks: attacks that are physically realizable and inconspicuous and allow an attacker to evade recognition or impersonate another individual. We develop a systematic method to automatically generate such attacks which are realized through printing a pair of eyeglass frames. When worn by the attacker whose image is supplied to a state-of-the-art face-recognition algorithm the eyeglasses allow her to evade being recognized or to impersonate another individual. Our investigation focuses on white-box face-recognition systems but we also demonstrate how similar techniques can be used in black-box scenarios as well as to avoid face detection.;
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;ECLIPSE is both an open extensible development environment for building software and an open extensible application framework upon which software can be built. Considered the most popular Java IDE it provides a common UI model for working with tools and promotes rapid development of modular features based on a plug-in component model. The Eclipse Foundation designed the platform to run natively on multiple operating systems including Macintosh Windows and Linux providing robust integration with each and providing rich clients that support the GUI interactions everyone is familiar with: drag and drop cut and paste (clipboard) navigation and customization. You can think of Eclipse as a â€œdesign centerâ€ supported by a development team of 300 or more developers whom you can leverage when developing your own software.;
Accountability in Algorithmic Decision-making: A view from computational journalism;Every fiscal quarter automated writing algorithms churn out thousands of corporate earnings articles for the AP (Associated Press) based on little more than structured data. Companies such as Automated Insights which produces the articles for AP and Narrative Science can now write straight news articles in almost any domain that has clean and well-structured data: finance sure but also sports weather and education among others. The articles arenâ€™t cardboard either they have variability tone and style and in some cases readers even have difficulty distinguishing the machine-produced articles from human-written ones.;
The (Im)possibility of fairness: different value systems require different mechanisms for fair decision making;What does it mean to be fair?;
Certifying a file system using crash hoare logic: correctness in the presence of crashes;FSCQ is the first file system with a machine-checkable proof that its implementation meets a specification even in the presence of fail-stop crashes. FSCQ provably avoids bugs that have plagued previous file systems such as performing disk writes without sufficient barriers or forgetting to zero out directory blocks. If a crash happens at an inopportune time these bugs can lead to data loss. FSCQ's theorems prove that under any sequence of crashes followed by reboots FSCQ will recover its state correctly without losing data.To state FSCQ's theorems this paper introduces the Crash Hoare logic (CHL) which extends traditional Hoare logic with a crash condition a recovery procedure and logical address spaces for specifying disk states at different abstraction levels. CHL also reduces the proof effort for developers through proof automation. Using CHL we developed specified and proved the correctness of the FSCQ file system. Although FSCQ's design is relatively simple experiments with FSCQ as a user-level file system show that it is sufficient to run Unix applications with usable performance. FSCQ's specifications and proofs required significantly more work than the implementation but the work was manageable even for a small team of a few researchers.&lt!-- END_PAGE_1 --&gt;
Digitally Assisted Analog Integrated Circuits: Closing the gap between analog and digital;In past decades â€œMooreâ€™s lawâ€1 has governed the revolution in microelectronics. Through continuous advancements in device and fabrication technology the industry has maintained exponential progress rates in transistor miniaturization and integration density. As a result microchips have become cheaper faster more complex and more power efficient.;
Model checking: algorithmic verification and debugging;Turing Lecture from the winners of the 2007 ACM A.M. Turing Award.In 1981 Edmund M. Clarke and E. Allen Emerson working in the USA and Joseph Sifakis working independently in France authored seminal papers that founded what has become the highly successful field of model checking. This verification technology provides an algorithmic means of determining whether an abstract model---representing for example a hardware or software design---satisfies a formal specification expressed as a temporal logic (TL) formula. Moreover if the property does not hold the method identifies a counterexample execution that shows the source of the problem.The progression of model checking to the point where it can be successfully used for complex systems has required the development of sophisticated means of coping with what is known as the state explosion problem. Great strides have been made on this problem over the past 28 years by what is now a very large international research community. As a result many major hardware and software companies are beginning to use model checking in practice. Examples of its use include the verification of VLSI circuits communication protocols software device drivers real-time embedded systems and security algorithms.The work of Clarke Emerson and Sifakis continues to be central to the success of this research area. Their work over the years has led to the creation of new logics for specification new verification algorithms and surprising theoretical results. Model checking tools created by both academic and industrial teams have resulted in an entirely novel approach to verification and test case generation. This approach for example often enables engineers in the electronics industry to design complex systems with considerable assurance regarding the correctness of their initial designs. Model checking promises to have an even greater impact on the hardware and software industries in the future.&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp---Moshe Y. Vardi Editor-in-Chief;
Fuzzy Boundaries: Objects Components and Web Services: Itâ€™s easy to transform objects into components and Web services but how do we know which is right for the job?;If you are an object-oriented programmer you will understand the code snippet even if you are not familiar with the language (C# not that it matters). You will not be surprised to learn that this program will print out the following line to the console: woof.;
Simba: scaling deep-learning inference with chiplet-based architecture;Package-level integration using multi-chip-modules (MCMs) is a promising approach for building large-scale systems. Compared to a large monolithic die an MCM combines many smaller chiplets into a larger system substantially reducing fabrication and design costs. Current MCMs typically only contain a handful of coarse-grained large chiplets due to the high area performance and energy overheads associated with inter-chiplet communication. This work investigates and quantifies the costs and benefits of using MCMs with finegrained chiplets for deep learning inference an application domain with large compute and on-chip storage requirements. To evaluate the approach we architected implemented fabricated and tested Simba a 36-chiplet prototype MCM system for deep-learning inference. Each chiplet achieves 4 TOPS peak performance and the 36-chiplet MCM package achieves up to 128 TOPS and up to 6.1 TOPS/W. The MCM is configurable to support a flexible mapping of DNN layers to the distributed compute and storage units. To mitigate inter-chiplet communication overheads we introduce three tiling optimizations that improve data locality. These optimizations achieve up to 16% speedup compared to the baseline layer mapping. Our evaluation shows that Simba can process 1988 images/s running ResNet-50 with a batch size of one delivering an inference latency of 0.50 ms.;
Probing Biomolecular Machines with Graphics Processors: The evolution of GPU processors and programming tools is making advanced simulation and analysis techniques accessible to a growing community of biomedical scientists.;"Computer simulation has become an integral part of the study of the structure and function of biological molecules. For years parallel computers have been used to conduct these computationally demanding simulations and to analyze their results. These simulations function as a computational microscope"" allowing the scientist to observe details of molecular processes too small fast or delicate to capture with traditional instruments. Over time commodity GPUs (graphics processing units) have evolved into massively parallel computing devices and more recently it has become possible to program them in dialects of the popular C/C++ programming languages.""";
Seeking anonymity in an internet panopticon;The Dissent system aims for a quantifiably secure collective approach to anonymous communication online.;
3D Virtual worlds and the metaverse: Current status and future possibilities;Moving from a set of independent virtual worlds to an integrated network of 3D virtual worlds or Metaverse rests on progress in four areas: immersive realism ubiquity of access and identity interoperability and scalability. For each area the current status and needed developments in order to achieve a functional Metaverse are described. Factors that support the formation of a viable Metaverse such as institutional and popular interest and ongoing improvements in hardware performance and factors that constrain the achievement of this goal including limits in computational methods and unrealized collaboration among virtual world stakeholders and developers are also considered.;
RocksDB: Evolution of Development Priorities in a Key-value Store Serving Large-scale Applications;This article is an eight-year retrospective on development priorities for RocksDB a key-value store developed at Facebook that targets large-scale distributed systems and that is optimized for Solid State Drives (SSDs). We describe how the priorities evolved over time as a result of hardware trends and extensive experiences running RocksDB at scale in production at a number of organizations: from optimizing write amplification to space amplification to CPU utilization. We describe lessons from running large-scale applications including that resource allocation needs to be managed across different RocksDB instances that data formats need to remain backward- and forward-compatible to allow incremental software rollouts and that appropriate support for database replication and backups are needed. Lessons from failure handling taught us that data corruption errors needed to be detected earlier and that data integrity protection mechanisms are needed at every layer of the system. We describe improvements to the key-value interface. We describe a number of efforts that in retrospect proved to be misguided. Finally we describe a number of open problems that could benefit from future research.;
VoIP Security: Not an Afterthought: DDOS takes on a whole new meaning.;Voice over IP (VoIP) promises to up-end a century-old model of voice telephony by breaking the traditional monolithic service model of the public switched telephone network (PSTN) and changing the point of control and provision from the central office switch to the end userâ€™s device. Placing intelligence at the edge in the Internet tradition has a number of consequences: a wider community of developers - in particular the large community of Web service developers - can work on voice applications open interfaces and decomposable functionality facilitate multi-vendor and homegrown solutions and open source and nonproprietary software development can facilitate innovation and experimentation.;
Reading Writing and Code: The key to writing readable code is developing good coding style.;Forty years ago when computer programming was an individual experience the need for easily readable code wasnâ€™t on any priority list. Today however programming usually is a team-based activity and writing code that others can easily decipher has become a necessity. Creating and developing readable code is not as easy as it sounds.;
Using simple abstraction to reinvent computing for parallelism;The ICE abstraction may take CS from serial (single-core) computing to effective parallel (many-core) computing.;
Security - Problem Solved? Solutions to many of our security problems already exist so why are we still so vulnerable?;There are plenty of security problems that have solutions. Yet our security problems donâ€™t seem to be going away. Whatâ€™s wrong here? Are consumers being offered snake oil and rejecting it? Are they not adopting solutions they should be adopting? Or is there something else at work entirely? Weâ€™ll look at a few places where the world could easily be a better place but isnâ€™t and build some insight as to why.;
No Source Code? No Problem! What if you have to port a program but all you have is a binary?;Typical software development involves one of two processes: the creation of new software to fit particular requirements or the modification (maintenance) of old software to fix problems or fit new requirements. These transformations happen at the source-code level. But what if the problem is not the maintenance of old software but the need to create a functional duplicate of the original? And what if the source code is no longer available?;
Fun and Games: Multi-Language Development: Game development can teach us much about the common practice of combining multiple languages in a single project.;"Computer games (or electronic games"" if you encompass those games played on console-class hardware) comprise one of the fastest-growing application markets in the world. Within the development community that creates these entertaining marvels multi-language development is becoming more commonplace as games become more and more complex. Today asking a development team to construct a database-enabled Web site with the requirement that it be written entirely in C++ would earn scornful looks and rolled eyes but not long ago the idea that multiple languages were needed to accomplish a given task was scoffed at.""";
The Age of Corporate Open Source Enlightenment: Like it or not zealots and heretics are finding common ground in the open source holy war.;Itâ€™s a bad idea mixing politics and religion. Conventional wisdom tells us to keep them separate - and to discuss neither at a dinner party. The same has been said about the world of software. When it comes to mixing the open source church with the proprietary state (or is it the other way around?) only one rule applies: Donâ€™t do it.;
The Hawthorne studies and their relevance to HCI research;High bandwidth low latency and multihoming challenge the sockets API.;
Threads without the Pain: Multithreaded programming need not be so angst-ridden.;Much of todayâ€™s software deals with multiple concurrent tasks. Web browsers support multiple concurrent HTTP connections graphical user interfaces deal with multiple windows and input devices and Web and DNS servers handle concurrent connections or transactions from large numbers of clients. The number of concurrent tasks that needs to be handled increases while software grows more complex. Structuring concurrent software in a way that meets the increasing scalability requirements while remaining simple structured and safe enough to allow mortal programmers to construct ever-more complex systems is a major engineering challenge.;
Why computer talents become computer hackers;Start with talent and skills driven by curiosity and hormones constrained only by moral values and judgment.;
The Invisible Assistant: One labâ€™s experiment with ubiquitous computing;Ubiquitous computing seeks to place computers everywhere around usâ€”into the very fabric of everyday life1â€”so that our lives are made better. Whether it is improving our job productivity our ability to stay connected with family and friends or our entertainment the goal is to find ways to put technology to work for us by getting all those computersâ€”large and small visible and invisibleâ€”to work together. Since Mark Weiser presented the ubiquitous computing vision in 1991 we have made significant progress in creating faster smaller and lower-power computing devices.We have just barely begun however to tackle the problem of how we get these devices to interact effectively with us and with each other.;
Sherman: A Write-Optimized Distributed B+Tree Index on Disaggregated Memory;Memory disaggregation architecture physically separates CPU and memory into independent components which are connected via high-speed RDMA networks greatly improving resource utilization of databases. However such an architecture poses unique challenges to data indexing due to limited RDMA semantics and near-zero computation power at memory-side. Existing indexes supporting disaggregated memory either suffer from low write performance or require hardware modification. This paper presents Sherman a write-optimized distributed B+Tree index on disaggregated memory that delivers high performance with commodity RDMA NICs. Sherman combines RDMA hardware features and RDMA-friendly software techniques to boost index write performance from three angles. First to reduce round trips Sherman coalesces dependent RDMA commands by leveraging in-order delivery property of RDMA. Second to accelerate concurrent accesses Sherman introduces a hierarchical lock that exploits on-chip memory of RDMA NICs. Finally to mitigate write amplification Sherman tailors the data structure layout of B+Tree with a two-level version mechanism. Our evaluation shows that Sherman is one order of magnitude faster in terms of both throughput and 99th percentile latency on typical write-intensive workloads compared with state-of-the-art designs.;
Proceedings of the 2022 International Conference on Management of Data;"The history of the NFE (network front-end) processor currently best known as a TOE (TCP offload engine) extends all the way back to the Arpanet IMP (interface message processor) and possibly before. The notion is beguilingly simple: partition the work of executing communications protocols from the work of executing the applications"" that require the services of those protocols. That way the applications and the network machinery can achieve maximum performance and efficiency possibly taking advantage of special hardware performance assistance. While this looks utterly compelling on the whiteboard architectural and implementation realities intrude often with considerable force.""";
Integrating RFID: Data management and inventory control are about to get a whole lot more interesting.;RFID (radio frequency identification) has received a great deal of attention in the commercial world over the past couple of years. The excitement stems from a confluence of events. First through the efforts of the former Auto-ID Center and its sponsor companies the prospects of low-cost RFID tags and a networked supply chain have come within reach of a number of companies. Second several commercial companies and government bodies such as Wal-Mart and Target in the United States Tesco in Europe and the U.S. Department of Defense have announced RFID initiatives in response to technology improvements.;
Cluster-level Logging of Containers with Containers: Logging Challenges of Container-Based Cloud Deployments;This article shows how cluster-level logging infrastructure can be implemented using open source tools and deployed using the very same abstractions that are used to compose and manage the software systems being logged. Collecting and analyzing log information is an essential aspect of running production systems to ensure their reliability and to provide important auditing information. Many tools have been developed to help with the aggregation and collection of logs for specific software components (e.g. an Apache web server) running on specific servers (e.g. Fluentd and Logstash.) They are accompanied by tools such as Elasticsearch for ingesting log information into persistent storage and tools such as Kibana7 for querying log information.;
Scrum Essentials Cards: Experiences of Scrum Teams Improving with Essence;This article presents a series of examples and case studies on how people have used the Scrum Essentials cards to benefit their teams and improve how they work. Scrum is one of the most popular agile frameworks used successfully all over the world. It has been taught and used for 15-plus years. It is by far the most-used practice when developing software and it has been generalized to be applicable for not just software but all kinds of products. It has been taught to millions of developers all based on the Scrum Guide. Today all our Scrum training is accompanied by a set of cards designed using the Essence standard which has given us a better Scrum.;
Above the Line Below the Line: The resilience of Internet-facing systems relies on what is above the line of representation.;Knowledge and understanding of below-the-line structure and function are continuously in flux. Near-constant effort is required to calibrate and refresh the understanding of the workings dependencies limitations and capabilities of what is present there. In this dynamic situation no individual or group can ever know the system state. Instead individuals and groups must be content with partial fragmented mental models that require more or less constant updating and adjustment if they are to be useful.;
Security of IoT systems: design challenges and opportunities;Computer-aided design (CAD) in its quest to facilitate new design revolutions is again on the brink of changing its scope. Following both historical and recent technological and application trends one can identify several emerging research and development directions in which CAD approaches and techniques may have major impacts. Among them due to the potential to fundamentally alter everyday life as well as how science and engineering systems are designed and operated the Internet of Things (IoT) stands out. IoT also poses an extraordinary system replete with conceptual and technical challenges. For instance greatly reduced quantitative bounds on acceptable area and energy metrics require qualitative breakthroughs in design and optimization techniques.Most likely the most demanding of requirements for the widespread realization of many IoT visions is security. IoT security has an exceptionally wide scope in at least four dimensions. In terms of security scope it includes rarely addressed tasks such as trusted sensing computation communication privacy and digital forgetting. It also asks for new and better techniques for the protection of hardware software and data that considers the possibility of physical access to IoT devices. Sensors and actuators are common components of IoT devices and pose several unique security challenges including the integrity of physical signals and actuating events. Finally during processing of collected data one can envision many semantic attacks.Our strategic objective is to provide an impetus for the development of IoT CAD security techniques. We start by presenting a brief survey of IoT challenges and opportunities with an emphasis on security issues. Next we discuss the potential of hardware-based IoT security approaches. Finally we conclude with several case studies that advocate the use of stable PUFs and digital PPUFs for several IoT security protocols.;
Proceedings of the 2014 IEEE/ACM International Conference on Computer-Aided Design;Chips designed specifically to model the neurons and synapses in the human brain are poised to change computing in profound ways.;
Implementing distributed shared memory for dynamic networks;Atomically consistent memory services provide resiliency in dynamic settings.;
TiVo-lution: The challenges of delivering a reliable easy-to-use DVR service to the masses;"One of the greatest challenges of designing a computer system is in making sure the system itself is invisible"" to the user. The system should simply be a conduit to the desired result. There are many examples of such purpose-built systems ranging from modern automobiles to mobile phones.""";
CTO roundtable: malware defense;The battle is bigger than most of us realize.;
Industrial Scale Agile - from Craft to Engineering: Essence is instrumental in moving software development toward a true engineering discipline.;There are many many ways to illustrate how fragile IT investments can be. You just have to look at the way that even after huge investments in education and coaching many organizations are struggling to broaden their agile adoption to the whole of their organization - or at the way other organizations are struggling to maintain the momentum of their agile adoptions as their teams change and their systems mature.;
Network Applications Are Interactive: The network era requires new models with interactions instead of algorithms.;The miniaturization of devices and the prolific interconnectedness of these devices over high-speed wireless networks is completely changing how commerce is conducted. These changes (a.k.a. digital) will profoundly change how enterprises operate. Software is at the heart of this digital world but the software toolsets and languages were conceived for the host-based era. The issues that already plague software practice (such as high defects poor software productivity information vulnerability poor software project success rates etc.) will be more profound with such an approach. It is time for software to be made simpler secure and reliable.;
Challenges and opportunities with big data;"The promise of data-driven decision-making is now being recognized broadly and there is growing enthusiasm for the notion of Big Data"" including the recent announcement from the White House about new funding initiatives across different agencies that target research for Big Data. While the promise of Big Data is real -- for example it is estimated that Google alone contributed 54 billion dollars to the US economy in 2009 -- there is no clear consensus on what is Big Data. In fact there have been many controversial statements about Big Data such as ""Size is the only thing that matters."" In this panel we will try to explore the controversies and debunk the myths surrounding Big Data.""";
Information hiding: Challenges for forensic experts;The practice of hiding ill-gotten data in digital objects is rising among cyber thieves. New initiatives serve to educate train and thwart these activities.;
Accountability in algorithmic decision making;A view from computational journalism.;
Breaking the Major Release Habit: Can agile development make your team more productive?;Keeping up with the rapid pace of change can be a daunting task. Just as you finally get your software working with a new technology to meet yesterdayâ€™s requirements a newer technology is introduced or a new business trend comes along to upset the apple cart. Whether your new challenge is Web services SOA (service-oriented architecture) ESB (enterprise service bus) AJAX Linux the Sarbanes-Oxley Act distributed development outsourcing or competitive pressure there is an increasing need for development methodologies that help to shorten the development cycle time respond to user needs faster and increase quality all at the same time.;
Caffe: Convolutional Architecture for Fast Feature Embedding;Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects large-scale industrial applications and startup prototypes in vision speech and multimedia.;
Proceedings of the 22nd ACM International Conference on Multimedia;Recent advances in artificial intelligence have been driven by an exponential growth in digitised data. Natural language processing in particular has been transformed by machine learning models such as OpenAIâ€™s GPT-3 which generates human-like text so realistic that its developers have warned of the dangers of its misuse. In recent months OpenAI released Codex a new deep learning model trained on Python code from more than 50 million GitHub repositories. Provided with a natural language description of a programming problem as input Codex generates solution code as output. It can also explain (in English) input code translate code between programming languages and more. In this work we explore how Codex performs on typical introductory programming problems. We report its performance on real questions taken from introductory programming exams and compare it to results from students who took these same exams under normal conditions demonstrating that Codex outscores most students. We then explore how Codex handles subtle variations in problem wording using several published variants of the well-known â€œRainfall Problemâ€ along with one unpublished variant we have used in our teaching. We find the model passes many test cases for all variants. We also explore how much variation there is in the Codex generated solutions observing that an identical input prompt frequently leads to very different solutions in terms of algorithmic approach and code length. Finally we discuss the implications that such technology will have for computing education as it continues to evolve including both challenges and opportunities.;
Proceedings of the 24th Australasian Computing Education Conference;We have instantaneous access to petabytes of stored data through Web searches. With respect to messaging we have an unprecedented number of communication tools that provide both synchronous and asynchronous access to people. E-mail message boards newsgroups IRC (Internet relay chat) and IM (instant messaging) are just a few examples. These tools are all particularly significant because they have become essential productivity entitlements. They have caused a fundamental shift in the way we communicate. Many readers can attest to feeling disconnected when a mail server goes down or when access to IM is unavailable. For some of us network outages are now as inconvenient as a blackout.;
Cognitive biases in software development;Cognitive biases are hardwired behaviors that influence developer actions and can set them on an incorrect course of action necessitating backtracking. Although researchers have found that cognitive biases occur in development tasks in controlled lab studies we still do not know how these biases affect developers' everyday behavior. Without such an understanding development tools and practices remain inadequate. To close this gap we conducted a two-part field study to examine the extent to which cognitive biases occur the consequences of these biases on developer behavior and the practices and tools that developers use to deal with these biases. We found about 70% of observed actions were associated with at least one cognitive bias. Even though developers recognized that biases frequently occur they are forced to deal with such issues with ad hoc processes and suboptimal tool support. As one participant (IP12) lamented: There is no salvation!;
Research for practice: security for the modern age;Securely running processes that require the entire syscall interface.;
Flash Storage Today: Can flash memory become the foundation for a new tier in the storage hierarchy?;The past few years have been an exciting time for flash memory. The cost has fallen dramatically as fabrication has become more efficient and the market has grown the density has improved with the advent of better processes and additional bits per cell and flash has been adopted in a wide array of applications. The flash ecosystem has expanded and continues to expand especially for thumb drives cameras ruggedized laptops and phones in the consumer space.;
Middleware 101: What to know now and for the future;Whether segregating a sophisticated software component into smaller services transferring data between computers or creating a general gateway for seamless communication you can rely on middleware to achieve communication between different devices applications and software layers. Following the increasing agile movement the tech industry has adopted the use of fast waterfall models to create stacks of layers for each structural need including integration communication data and security. Given this scope emphasis must now be on endpoint connection and agile development. This means that middleware should not serve solely as an object-oriented solution to execute simple request-response commands. Middleware can incorporate pull-push events and streams via multiple gateways by combining microservices architectures to develop a holistic decentralized ecosystem.;
The case against data lock-in;Want to keep your users? Just make it easy for them to leave.;
CTO Roundtable: Malware Defense: The battle is bigger than most of us realize.;As all manner of information assets migrate online malware has kept on track to become a huge source of individual threats. In a continuously evolving game of cat and mouse as security professionals close off points of access attackers develop more sophisticated attacks. Today profit models from malware are comparable to any seen in the legitimate world.;
Teaching programming the way it works outside the classroom;The Communications Web site http://cacm.acm.org features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications we'll publish selected posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMhttp://cacm.acm.org/blogs/blog-cacmPhilip Guo offers programmers 'Opportunistic Programming' tips that typically are not shared in school.;
CTO Roundtable: Malware Defense Overview: Key points from ACMâ€™s CTO Roundtable on malware defense;The Internet has enabled malware to progress to a much broader distribution model and is experiencing a huge explosion of individual threats. There are automated tools that find vulnerable sites attack them and turn them into distribution sites. As commerce and the business of daily living migrate online attacks to leverage information assets for ill-gotten benefit have increased dramatically. Security professionals are seeing more sophisticated and innovative profit models on par with business models seen in the legitimate world.;
Debugging distributed systems;ShiViz is a new distributed system debugging visualization tool.;
Biases in AI systems;A survey for practitioners.;
DeepDive: declarative knowledge base construction;The dark data extraction or knowledge base construction (KBC) problem is to populate a relational database with information from unstructured data sources such as emails webpages and PDFs. KBC is a long-standing problem in industry and research that encompasses problems of data extraction cleaning and integration. We describe DeepDive a system that combines database and machine learning ideas to help to develop KBC systems. The key idea in DeepDive is to frame traditional extract-transform-load (ETL) style data management problems as a single large statistical inference task that is declaratively defined by the user. DeepDive leverages the effectiveness and efficiency of statistical inference and machine learning for difficult extraction tasks whereas not requiring users to directly write any probabilistic inference algorithms. Instead domain experts interact with DeepDive by defining features or rules about the domain. DeepDive has been successfully applied to domains such as pharmacogenomics paleobiology and antihuman trafficking enforcement achieving human-caliber quality at machine-caliber scale. We present the applications abstractions and techniques used in DeepDive to accelerate the construction of such dark data extraction systems.;
Managing Semi-Structured Data: I vividly remember during my first college class my fascination with the relational database.;In that class I learned how to build a schema for my information and I learned that to obtain an accurate schema there must be a priori knowledge of the structure and properties of the information to be modeled. I also learned the ER (entity-relationship) model as a basic tool for all further data modeling as well as the need for an a priori agreement on both the general structure of the information and the vocabularies used by all communities producing processing or consuming this information.;
Document design matters;How do we apply the concept of resource orientation by designing representations to support interactions?;
Real-world concurrency;What does the proliferation of concurrency mean for the software you develop?;
Describing the Elephant: The Different Faces of IT as Service: Terms such as grid on-demand and service-oriented architecture are mired in confusion but there is an overarching trend behind them all.;In a well-known fable a group of blind men are asked to describe an elephant. Each encounters a different part of the animal and not surprisingly provides a different description. We see a similar degree of confusion in the IT industry today as terms such as service-oriented architecture grid utility computing on-demand adaptive enterprise data center automation and virtualization are bandied about. As when listening to the blind men it can be difficult to know what reality lies behind the words whether and how the different pieces fit together and what we should be doing about the animal(s) that are being described. (Of course in the case of the blind men we did not also have marketing departments in the mix!);
The Keys to the Kingdom: A deleted private key a looming deadline and a last chance to patch a new static root of trust into the bootloader;An unlucky fat-fingering precipitated the current crisis: The client had accidentally deleted the private key needed to sign new firmware updates. They had some exciting new features to ship along with the usual host of reliability improvements. Their customers were growing impatient but my client had to stall when asked for a release date. How could they come up with a meaningful date? They had lost the ability to sign a new firmware release.;
Other Peopleâ€™s Data: Companies have access to more types of external data than ever before. How can they integrate it most effectively?;Every organization bases some of its critical decisions on external data sources. In addition to traditional flat file data feeds Web services and Web pages are playing an increasingly important role in data warehousing. The growth of Web services has made data feeds easily consumable at the departmental and even end-user levels. There are now more than 1500 publicly available Web services and thousands of data mashups ranging from retail sales data to weather information to United States census data. These mashups are evidence that when users need information they will find a way to get it. An effective enterprise information management strategy needs to take into account both internal and external data.;
An Overview of the Action Space for Deep Reinforcement Learning;In recent years deep reinforcement learning has been applied to tasks in the real world gradually. Especially in the field of control reinforcement learning has shown unprecedented popularity such as robot control autonomous driving and so on. Different algorithms may be suitable for different problems so we investigate and analyze the existing advanced deep reinforcement learning algorithms from the perspective of action space. At the same time we analyze the differences and connections between discrete action space continuous action space and discrete-continuous hybrid action space and elaborate various reinforcement learning algorithms suitable for different action spaces. Applying reinforcement learning to the control problem in the real world still presents huge challenges. Finally we summarize these challenges and discuss how reinforcement learning can be appropriately applied to satellite attitude control tasks.;
Proceedings of the 2021 4th International Conference on Algorithms Computing and Artificial Intelligence;Changing network landscapes and rising security threats have imparted a sense of urgency for new approaches to security. Zero trust has been proposed as a solution to these problems but some regard it as a marketing tool to sell existing best practice while others praise it as a new cybersecurity standard. This article discusses the history and development of zero trust and why the changing threat landscape has led to a new discourse in cybersecurity. Drivers barriers and business implications of zero trust provide a backdrop for a brief overview of key logical components of a zero trust architecture and implementation challenges.;
The Challenges of IoT TLS and Random Number Generators in the Real World: Bad random numbers are still with us and are proliferating in modern systems.;Many in the cryptographic community scoff at the mistakes made in implementing RNGs. Many cryptographers and members of the IETF resist the call to make TLS more resilient to this class of failures. This article discusses the history current state and fragility of the TLS protocol and it closes with an example of how to improve the protocol. The goal is not to suggest a solution but to start a dialog to make TLS more resilient by proving that the security of TLS without the assumption of perfect random numbers is possible.;
Spectre attacks: exploiting speculative execution;Modern processors use branch prediction and speculative execution to maximize performance. For example if the destination of a branch depends on a memory value that is in the process of being read CPUs will try to guess the destination and attempt to execute ahead. When the memory value finally arrives the CPU either discards or commits the speculative computation. Speculative logic is unfaithful in how it executes can access the victim's memory and registers and can perform operations with measurable side effects.Spectre attacks involve inducing a victim to speculatively perform operations that would not occur during correct program execution and which leak the victim's confidential information via a side channel to the adversary. This paper describes practical attacks that combine methodology from side-channel attacks fault attacks and return-oriented programming that can read arbitrary memory from the victim's process. More broadly the paper shows that speculative execution implementations violate the security assumptions underpinning numerous software security mechanisms such as operating system process separation containerization just-in-time (JIT) compilation and countermeasures to cache timing and side-channel attacks. These attacks represent a serious threat to actual systems because vulnerable speculative execution capabilities are found in microprocessors from Intel AMD and ARM that are used in billions of devices.Although makeshift processor-specific countermeasures are possible in some cases sound solutions will require fixes to processor designs as well as updates to instruction set architectures (ISAs) to give hardware architects and software developers a common understanding as to what computation state CPU implementations are (and are not) permitted to leak.;
Survey of graph database models;Graph database models can be defined as those in which data structures for the schema and instances are modeled as graphs or generalizations of them and data manipulation is expressed by graph-oriented operations and type constructors. These models took off in the eighties and early nineties alongside object-oriented models. Their influence gradually died out with the emergence of other database models in particular geographical spatial semistructured and XML. Recently the need to manage information with graph-like nature has reestablished the relevance of this area. The main objective of this survey is to present the work that has been conducted in the area of graph database modeling concentrating on data structures query languages and integrity constraints.;
A Requirements Primer: A short primer that provides background on four  of the most important compliance challenges that organizations face today.;Many software engineers and architects are exposed to compliance through the growing number of rules regulations and standards with which their employers must comply. Some of these requirements such as HIPAA focus primarily on one industry whereas others such as SOX span many industries. Some apply to only one country while others cross national boundaries.;
Better scripts better games;Smarter more powerful scripting languages will improve game performance while making gameplay development more efficient.;
Dark patterns: past present and future;The evolution of tricky user interfaces.;
ORM in Dynamic Languages: O/R mapping frameworks for dynamic languages such as Groovy provide a different flavor of ORM that can greatly simplify application code.;A major component of most enterprise applications is the code that transfers objects in and out of a relational database. The easiest solution is often to use an ORM (object-relational mapping) framework which allows the developer to declaratively define the mapping between the object model and database schema and express database-access operations in terms of objects. This high-level approach significantly reduces the amount of database-access code that needs to be written and boosts developer productivity.;
Safe to the last instruction: automated verification of a type-safe operating system;While millions of students worldwide have enjoyed coding experiences over the last decade the next challenge is spreading educational values and approaches.;
A history of Clojure;Clojure was designed to be a general-purpose practical functional language suitable for use by professionals wherever its host language e.g. Java would be. Initially designed in 2005 and released in 2007 Clojure is a dialect of Lisp but is not a direct descendant of any prior Lisp. It complements programming with pure functions of immutable data with concurrency-safe state management constructs that support writing correct multithreaded programs without the complexity of mutex locks.  Clojure is intentionally hosted in that it compiles to and runs on the runtime of another language such as the JVM. This is more than an implementation strategy numerous features ensure that programs written in Clojure can leverage and interoperate with the libraries of the host language directly and efficiently.  In spite of combining two (at the time) rather unpopular ideas functional programming and Lisp Clojure has since seen adoption in industries as diverse as finance climate science retail databases analytics publishing healthcare advertising and genomics and by consultancies and startups worldwide much to the career-altering surprise of its author.  Most of the ideas in Clojure were not novel but their combination puts Clojure in a unique spot in language design (functional hosted Lisp). This paper recounts the motivation behind the initial development of Clojure and the rationale for various design decisions and language constructs. It then covers its evolution subsequent to release and adoption.;
Distributed Latency Profiling through Critical Path Tracing: CPT can provide actionable and precise latency analysis.;Low latency is an important feature for many Google applications such as Search and latency-analysis tools play a critical role in sustaining low latency at scale. For complex distributed systems that include services that constantly evolve in functionality and data keeping overall latency to a minimum is a challenging task. In large real-world distributed systems existing tools such as RPC telemetry CPU profiling and distributed tracing are valuable to understand the subcomponents of the overall system but are insufficient to perform end-to-end latency analyses in practice. Scalable and accurate fine-grain tracing has made Critical Path Tracing the standard approach for distributed latency analysis for many Google applications including Google Search.;
Triple-parity RAID and beyond;As hard-drive capacities continue to outpace their throughput the time has come for a new level of RAID.;
Liquid testing with your smartphone;Surface tension is an important property of liquids. It has diverse uses such as testing water contamination measuring alcohol concentration in drinks and identifying the presence of protein in urine to detect the onset of kidney failure. Today measurements of surface tension are done in a lab environment using costly instruments making it hard to leverage this property in ubiquitous applications. In contrast we show how to measure surface tension using only a smartphone. We introduce a new algorithm that uses the small waves on the liquid surface as a series of lenses that focus light and generate a characteristic pattern. We then use the phone camera to capture this pattern and measure the surface tension. Our approach is simple accurate and available to anyone with a smartphone. Empirical evaluations show that our mobile app can detect water contamination and measure alcohol concentration. Furthermore it can track protein concentration in the urine providing an initial at-home test for proteinuria a dangerous complication that can lead to kidney failure.;
Conceptualizing smart city with dimensions of technology people and institutions;This conceptual paper discusses how we can consider a particular city as a smart one drawing on recent practices to make cities smart. A set of the common multidimensional components underlying the smart city concept and the core factors for a successful smart city initiative is identified by exploring current working definitions of smart city and a diversity of various conceptual relatives similar to smart city. The paper offers strategic principles aligning to the three main dimensions (technology people and institutions) of smart city: integration of infrastructures and technology-mediated services social learning for strengthening human infrastructure and governance for institutional improvement and citizen engagement.;
Proceedings of the 12th Annual International Digital Government Research Conference: Digital Government Innovation in Challenging Times;Modern cell phones are required to receive and display alerts via the Wireless Emergency Alert (WEA) program under the mandate of the Warning Alert and Response Act of 2006. These alerts include AMBER alerts severe weather alerts and (unblockable) Presidential Alerts intended to inform the public of imminent threats. Recently a test Presidential Alert was sent to all capable phones in the U.S. prompting concerns about how the underlying WEA protocol could be misused or attacked. In this paper we investigate the details of this system and develop and demonstrate the first practical spoofing attack on Presidential Alerts using commercially available hardware and modified open source software. Our attack can be performed using a commercially available software-defined radio and our modifications to the open source software libraries. We find that with only four malicious portable base stations of a single Watt of transmit power each almost all of a 50000-seat stadium can be attacked with a 90% success rate. The real impact of such an attack would of course depend on the density of cellphones in range fake alerts in crowded cities or stadiums could potentially result in cascades of panic. Fixing this problem will require a large collaborative effort between carriers government stakeholders and cellphone manufacturers. To seed this effort we also propose three mitigation solutions to address this threat.;
Building Rome in a day;We present a system that can reconstruct 3D geometry from large unorganized collections of photographs such as those found by searching for a given city (e.g. Rome) on Internet photo-sharing sites. Our system is built on a set of new distributed computer vision algorithms for image matching and 3D reconstruction designed to maximize parallelism at each stage of the pipeline and to scale gracefully with both the size of the problem and the amount of available computation. Our experimental results demonstrate that it is now possible to reconstruct city-scale image collections with more than a hundred thousand images in less than a day.;
Modern System Power Management: Increasing demands for more power and increased efficiency are pressuring software and hardware developers to ask questions and look for answers.;The Advanced Configuration and Power Interface (ACPI) is the most widely used power and configuration interface for laptops desktops and server systems. It is also very complex and its current specification weighs in at more than 500 pages. Needless to say operating systems that choose to support ACPI require significant additional software support up to and including fundamental OS architecture changes. The effort that ACPIâ€™s definition and implementation has entailed is worth the trouble because of how much flexibility it gives to the OS (and ultimately the user) to control power management policy and implementation.;
Clustering high-dimensional data: A survey on subspace clustering pattern-based clustering and correlation clustering;"As a prolific research area in data mining subspace clustering and related problems induced a vast quantity of proposed solutions. However many publications compare a new propositionâ€”if at allâ€”with one or two competitors or even with a so-called â€œna\{\i""";
Methods included: standardizing computational reuse and portability with the Common Workflow Language;Standardizing computational reuse and portability with the Common Workflow Language.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;KinectFusion enables a user holding and moving a standard Kinect camera to rapidly create detailed 3D reconstructions of an indoor scene. Only the depth data from Kinect is used to track the 3D pose of the sensor and reconstruct geometrically precise 3D models of the physical scene in real-time. The capabilities of KinectFusion as well as the novel GPU-based pipeline are described in full. Uses of the core system for low-cost handheld scanning and geometry-aware augmented reality and physics-based interactions are shown. Novel extensions to the core GPU pipeline demonstrate object segmentation and user interaction directly in front of the sensor without degrading camera tracking or reconstruction. These extensions are used to enable real-time multi-touch interactions anywhere allowing any planar or non-planar reconstructed physical surface to be appropriated for touch.;
Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology;Organizations using ASPs and third-party vendors that provide value-added products to ASPs need to integrate with them. ASPs enable this integration by providing Web service-based APIs. There are significant differences between integrating with ASPs over the Internet and integrating with a local application. When integrating with ASPs users have to consider a number of issues including latency unavailability upgrades performance load limiting and lack of transaction support.;
When social networks cross boundaries: a case study of workplace use of facebook and linkedin;The use of social networking software by professionals is increasing dramatically. How it is used whether it enhances or reduces productivity and how enterprise-friendly design and use might evolve are open questions. We examine attitudes and behaviors in a large technologically-savvy organization through a broad survey and thirty focused interviews. We find extensive social and work uses with complex patterns that differ with software system and networker age. Tensions arise when use spans social groups and the organization's firewall. Although use is predominantly to support weak ties whose contribution to productivity can be difficult to prove we anticipate rapid uptake of social networking technology by organizations.;
Proceedings of the 2009 ACM International Conference on Supporting Group Work;The Laplacian pyramid is ubiquitous for decomposing images into multiple scales and is widely used for image analysis. However because it is constructed with spatially invariant Gaussian kernels the Laplacian pyramid is widely believed to be ill-suited for representing edges as well as for edge-aware operations such as edge-preserving smoothing and tone mapping. To tackle these tasks a wealth of alternative techniques and representations have been proposed for example anisotropic diffusion neighborhood filtering and specialized wavelet bases. While these methods have demonstrated successful results they come at the price of additional complexity often accompanied by higher computational cost or the need to postprocess the generated results. In this paper we show state-of-the-art edge-aware processing using standard Laplacian pyramids. We characterize edges with a simple threshold on pixel values that allow us to differentiate large-scale edges from small-scale details. Building upon this result we propose a set of image filters to achieve edge-preserving smoothing detail enhancement tone mapping and inverse tone mapping. The advantage of our approach is its simplicity and flexibility relying only on simple point-wise nonlinearities and small Gaussian convolutions no optimization or postprocessing is required. As we demonstrate our method produces consistently high-quality results without degrading edges or introducing halos.;
Monitoring at Your Service: Automated monitoring can increase the reliability and scalability of todayâ€™s online software services.;Internet services are becoming more and more a part of our daily lives. We derive value from them depend on them and are now beginning to assume their ubiquity as we do the phone system and electricity grid. The implementation of Internet services though is an unsolved problem and Internet services remain far from fulfilling their potential in our world.;
MadMax: analyzing the out-of-gas world of smart contracts;"Ethereum is a distributed blockchain platform serving as an ecosystem for smart contracts: full-fledged intercommunicating programs that capture the transaction logic of an account. A gas limit caps the execution of an Ethereum smart contract: instructions when executed consume gas and the execution proceeds as long as gas is available.Gas-focused vulnerabilities permit an attacker to force key contract functionality to run out of gas---effectively performing a permanent denial-of-service attack on the contract. Such vulnerabilities are among the hardest for programmers to protect against as out-of-gas behavior may be uncommon in nonattack scenarios and reasoning about these vulnerabilities is nontrivial.In this paper we identify gas-focused vulnerabilities and present MadMax: a static program analysis technique that automatically detects gas-focused vulnerabilities with very high confidence. MadMax combines a smart contract decompiler and semantic queries in Datalog. Our approach captures high-level program modeling concepts (such as dynamic data structure storage"" and ""safely resumable loops"") and delivers high precision and scalability. MadMax analyzes the entirety of smart contracts in the Ethereum blockchain in just 10 hours and flags vulnerabilities in contracts with a monetary value in billions of dollars. Manual inspection of a sample of flagged contracts shows that 81% of the sampled warnings do indeed lead to vulnerabilities.""";
The theft of business innovation: an ACM-BCS roundtable on threats to global competitiveness;These days cybercriminals are looking to steal more than just banking information.;
Spam Spam Spam Spam Spam the FTC and Spam: A forum sponsored by the FTC highlights just how bad spam is and how itâ€™s only going to get worse without some intervention.;The Federal Trade Commission held a forum on spam in Washington D.C. April 30 to May 2. Rather to my surprise it was a really good content-full event. The FTC folks had done their homework and had assembled panelists that ran the gamut from ardent anti-spammers all the way to hard-core spammers and everyone in between: lawyers legitimate marketers and representatives from vendor groups.;
Parallel Programming with Transactional Memory: While sometimes even writing regular single-threaded programs can be quite challenging trying to split a program into multiple pieces that can be executed in parallel adds a whole dimension of additional problems. Drawing upon the transaction concept familiar to most programmers transactional memory was designed to solve some of these problems and make parallel programming easier. Ulrich Drepper from Red Hat shows us how itâ€™s done.;With the speed of individual cores no longer increasing at the rate we came to love over the past decades programmers have to look for other ways to increase the speed of our ever-more-complicated applications. The functionality provided by the CPU manufacturers is an increased number of execution units or CPU cores.;
Enterprise-Grade Wireless: Wireless technology has come a long way but is it robust enough for todayâ€™s enterprise?;We have been working in the wireless space in one form or another in excess of 10 years and have participated in every phase of its maturation process. We saw wireless progress from a toy technology before the dot-com boom to something truly promising during the boom only to be left wanting after the bubble when the technology was found to be not ready for prime time. Fortunately it appears that we have finally reached the point where the technology and the enterpriseâ€™s expectations have finally converged.;
A Passage to India: Pitfalls that the outsourcing vendor forgot to mention;Most American IT employees take a dim view of offshore outsourcing. Itâ€™s considered unpatriotic and it drains valuable intellectual capital and jobs from the United States to destinations such as India or China. Online discussion forums on sites such as isyourjobgoingoffshore.com are headlined with titles such as â€œHow will you cope?â€ and â€œIs your career in danger?â€ A cover story in BusinessWeek magazine a couple of years ago summed up the angst most people suffer when faced with offshoring: â€œIs your job next?â€;
Learning topic models -- provably and efficiently;While still primarily a research project transactional memory shows promise for making parallel programming easier.;
On Mapping Alogrithms to DSP Architectures: Knowledge of both the algorithm and target architecture is crucial.;Our complex world is characterized by representation transmission and storage of information - and information is mostly processed in digital form. With the advent of DSPs (digital signal processors) engineers are able to implement complex algorithms with relative ease. Today we find DSPs all around us - in cars digital cameras MP3 and DVD players modems and so forth. Their widespread use and deployment in complex systems has triggered a revolution in DSP architectures which in turn has enabled engineers to implement algorithms of ever-increasing complexity. A DSP programmer today must be proficient in not only digital signal processing but also computer architecture and software engineering.;
Achieving Digital Permanence: The many challenges to maintaining stored information and ways to overcome them;Todayâ€™s Information Age is creating new uses for and new ways to steward the data that the world depends on. The world is moving away from familiar physical artifacts to new means of representation that are closer to information in its essence. We need processes to ensure both the integrity and accessibility of knowledge in order to guarantee that history will be known and true.;
Myths and mythconceptions: what does it mean to be a programming language anyhow?;Modern software does not stand alone it is embedded in complex physical and sociotechnical systems. It relies on computational support from interdependent subsystems as well as non-code resources such as data communications sensors and interactions with humans. Both general-purpose programming languages and mainstream programming language research focus on symbolic notations with well-defined abstractions that are intended for use by professionals to write programs that solve precisely specified problems. There is a strong emphasis on correctness of the resulting programs preferably by formal reasoning. However these languages despite their careful design and formal foundations address only a modest portion of modern software and only a minority of software developers.  Several persistent myths reinforce this focus. These myths express an idealized model of software and software development. They provide a lens for examining modern software and software development practice: highly trained professionals are outnumbered by vernacular developers. Writing new code is dominated by composition of ill-specified software and non-software components. General-purpose languages may be less appropriate for a task than domain-specific languages and functional correctness is often a less appropriate goal than overall fitness for task. Support for programming to meet a specification is of little help to people who are programming in order to understand their problems. Reasoning about software is challenged by uncertainty and nondeterminism in the execution environment and by the increasingly dominant role of data especially with the advent of systems that rely on machine learning. The lens of our persistent myths illuminates the dissonance between our idealized view of software development and common practice which enables us to identify emerging opportunities and challenges for programming language research.;
Black Box Debugging: Itâ€™s all about what takes place at the boundary of an application.;Modern software development practices build applications as a collection of collaborating components. Unlike older practices that linked compiled components into a single monolithic application modern executables are made up of any number of executable components that exist as separate binary files. This design means that as an application component needs resources from another component calls are made to transfer control or data from one component to another. Thus we can observe externally visible application behaviors by watching the activity that occurs across the boundaries of the applicationâ€™s constituent components.;
Enclaves in the Clouds: Legal considerations and broader implications;With organizational data practices coming under increasing scrutiny demand is growing for mechanisms that can assist organizations in meeting their data-management obligations. TEEs (trusted execution environments) provide hardware-based mechanisms with various security properties for assisting computation and data management. TEEs are concerned with the confidentiality and integrity of data code and the corresponding computation. Because the main security properties come from hardware certain protections and guarantees can be offered even if the host privileged software stack is vulnerable.;
Alloy: a language and tool for exploring software designs;Exploiting a simple expressive logic based on relations to describe designs and automate their analysis.;
Understanding DRM: Recognizing the tradeoffs associated with different DRM systems can pave the way for a more flexible and capable DRM.;The explosive growth of the Internet and digital media has created both tremendous opportunities and new threats for content creators. Advances in digital technology offer new ways of marketing disseminating interacting with and monetizing creative works giving rise to expanding markets that did not exist just a few years ago. At the same time however the technologies have created major challenges for copyright holders seeking to control the distribution of their works and protect against piracy.;
The complex path to quantum resistance;Is your organization prepared?;
Building Secure Web Applications: Believe it or not itâ€™s not a lost cause.;In these days of phishing and near-daily announcements of identity theft via large-scale data losses it seems almost ridiculous to talk about securing the Web. At this point most people seem ready to throw up their hands at the idea or to lock down one small component that they can control in order to keep the perceived chaos at bay.;
Meaning and Context in Computer Programs: Sharing domain knowledge among programmers using the source code as the medium;When you look at a function program's source code how do you know what it means? Is the meaning found in the return values of the function or is it located inside the function body? What about the function name? Answering these questions is important to understanding how to share domain knowledge among programmers using the source code as the medium. The program is the medium of communication among programmers to share their solutions.;
Metamorphosis: the Coming Transformation of Translational Systems Biology: In the future computers will mine patient data to deliver faster cheaper healthcare but how will we design them to give informative causal explanations? Ideas from philosophy model checking and statistical testing can pave the way for the needed translational systems biology.;"One morning as Gregorina Samsa was waking up from anxious dreams she discovered that she had become afflicted with certain mysterious flu-like symptoms that appeared without any warning. Equally irritating this capricious metamorphosis seemed impervious to a rational explanation in terms of causes and effects. Whatâ€™s happened to me?"" she thought. Before seeing a doctor she decided to find out more about what might ail her. She logged on to a Web site where she annotated a timeline with what she could remember. Since March sheâ€™d had more headaches than usual and then in April she had begun to experience more fatigue after exercise and as of July she had also experienced occasional lapses in memory. ""Why donâ€™t I go back to sleep for a little while longer and forget all this foolishness"" she thought. As she was about to abandon this errand the system came back to life with a barrage of questions: Is she female? Had she experienced any significant stress in the past few months? Had she noticed any joint or muscle pain? It also obtained her permission to download her genomic profile.""";
BPM: The Promise and the Challenge: Itâ€™s all about closing the loop from conception to execution and back.;Over the last decade businesses and governments have been giving increasing attention to business processes - to their description automation and management. This interest grows out of the need to streamline business operations consolidate organizations and save costs reflecting the fact that the process is the basic unit of business value within an organization.;
Efficient parallelization using rank convergence in dynamic programming algorithms;This paper proposes an efficient parallel algorithm for an important class of dynamic programming problems that includes Viterbi Needleman--Wunsch Smith--Waterman and Longest Common Subsequence. In dynamic programming the subproblems that do not depend on each other and thus can be computed in parallel form stages or wavefronts. The algorithm presented in this paper provides additional parallelism allowing multiple stages to be computed in parallel despite dependences among them. The correctness and the performance of the algorithm relies on rank convergence properties of matrix multiplication in the tropical semiring formed with plus as the multiplicative operation and max as the additive operation.This paper demonstrates the efficiency of the parallel algorithm by showing significant speedups on a variety of important dynamic programming problems. In particular the parallel Viterbi decoder is up to 24\texttimes{;
Why did your project fail?;IntroductionWe have been developing software since the 1960s but still have not learned enough to ensure that our software development projects are successful. Boehm2 suggested that realistic schedule and budgets together with a continuing steam of requirements changes are high risk factors. The Standish Group in 1994 noted that approximately 31% of corporate software development projects were cancelled before completion and 53% were challenged and cost 180% above their original estimate.13 Glass discussed 16 project disasters.5 He found that the failed projects he reviewed were mostly huge and that the failure factors were not just management factors but also included technical factors. Linberg in 1999 found that 20% of software projects failed and that 46% experienced cost and schedule overruns or significantly reduced functionality.8 Later Glass revisited failed projects and found that poor estimation was high on his list of failure factors.6In 2007 the Standish Group reported that 35% of software projects started in 2006 were successful compared with only 16% in the corresponding 1994 report however the 2007 CHAOS report still identifies 46% (53% in 1994) of software projects as challenged (having cost or time overruns or not fully meeting user's requirements) and 19% (31% in 1994) as outright failures.12 The validity of the Standish Group findings has been questioned as not consistent with cost overrun results of other surveys.7 J\o{;
Cooling the data center;What can be done to make cooling systems in data centers more energy efficient?;
Unifying biological image formats with HDF5;The biosciences need an image format capable of high performance and long-term maintenance. Is HDF5 the answer?;
Responsible data management;Perspectives on the role and responsibility of the data-management research community in designing developing using and overseeing automated decision systems.;
On the hourglass model;Used in the design of the Internet and Unix the layered services of the hourglass model have enabled viral adoption and deployment scalability.;
Energy Management on Handheld Devices: Whatever their origin all handheld devices share the same Achilles heel: the battery.;Handheld devices are becoming ubiquitous and as their capabilities increase they are starting to displace laptop computers - much as laptop computers have displaced desktop computers in many roles. Handheld devices are evolving from todayâ€™s PDAs organizers cellular phones and game machines into a variety of new forms. Although partially offset by improvements in low-power electronics this increased functionality carries a corresponding increase in energy consumption. Second as a consequence of displacing other pieces of equipment handheld devices are seeing more use between battery charges. Finally battery technology is not improving at the same pace as the energy requirements of handheld electronics. Therefore energy management once in the realm of desired features has become an important design requirement and one of the greatest challenges in portable computing and it will remain so for a long time to come.;
Money models for MOOCs;Considering new business models for massive open online courses.;
The Complex Path to Quantum Resistance: Is your organization prepared?;There is a new technology on the horizon that will forever change the information security and privacy industry landscape. Quantum computing together with quantum communication will have many beneficial applications but will also be capable of breaking many of today's most popular cryptographic techniques that help ensure data protection?in particular confidentiality and integrity of sensitive information. These techniques are ubiquitously embedded in today's digital fabric and implemented by many industries such as finance health care utilities and the broader information communication technology (ICT) community. It is therefore imperative for ICT executives to prepare for the transition from quantum-vulnerable to quantum-resistant technologies.;
AutoMan: a platform for integrating human-based and digital computation;Knowing where you are in space and time promises a deeper understanding of neighbors ecosystems and the environment.;
Dismantling the Barriers to Entry: We have to choose to build a web that is accessible to everyone.;"A war is being waged in the world of web development. On one side is a vanguard of toolmakers and tool users who thrive on the destruction of bad old ideas (old"" in this milieu meaning anything that debuted on Hacker News more than a month ago) and raucous debates about transpilers and suchlike. On the other side is an increasingly vocal contingent of developers who claim that the head-spinning rate of innovation makes it impossible to stay up to date and that the web is disintegrating into a jumble of hacks upon opinions most of which are wrong and all of which will have changed by the time hot-new-thing.js reaches version 1.0.0.""";
DAML: the contract language of distributed ledgers;A discussion between Shaul Kfir and Camille Fournier.;
Battling algorithmic bias: how do we ensure algorithms treat us fairly?;ZGC is a modern non-generational region-based mostly concurrent parallel mark-evacuate collector recently added to OpenJDK. It aims at having GC pauses that do not grow as the heap size increases offering low latency even with large heap sizes. The ZGC C++ source code is readily accessible in the OpenJDK repository but reading it (25 KLOC) can be very intimidating and one might easily get lost in low-level implementation details obscuring the key concepts. To make the ZGC algorithm more approachable this work provides a thorough description on a high-level focusing on the overall design with moderate implementation details. To explain the concurrency aspects we provide a SPIN model that allows studying races between mutators and GC threads and how they are resolved in ZGC. Such a model is not only useful for learning the current design (offering a deterministic and interactive experience) but also beneficial for prototyping new ideas and extensions. Our hope is that our detailed description and the SPIN model will enable the use of ZGC as a building block for future GC research and research ideas implemented on top of it could even be adopted in the industry more readily bridging the gap between academia and industry in the context of GC research.;
Information seeking: convergence of search recommendations and advertising;How to address user information needs amidst a preponderance of data.;
Big-data applications in the government sector;In the same way businesses use big data to pursue profits governments use it to promote the public good.;
Cluster-GCN: An Efficient Algorithm for Training Deep and Large Graph Convolutional Networks;Graph convolutional network (GCN) has been successfully applied to many graph-based applications however training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper we propose Cluster-GCN a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm we create a new Amazon2M data with 2 million nodes and 61 million edges which is more than 5 times larger than the previous largest publicly available dataset (Reddit). For training a 3-layer GCN on this data Cluster-GCN is faster than the previous state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB vs 11.2GB). Furthermore for training 4 layer GCN on this data our algorithm can finish in around 36 minutes while all the existing GCN training algorithms fail to train due to the out-of-memory issue. Furthermore Cluster-GCN allows us to train much deeper GCN without much time and memory overhead which leads to improved prediction accuracy---using a 5-layer Cluster-GCN we achieve state-of-the-art test F1 score 99.36 on the PPI dataset while the previous best result was 98.71 by~citezhang2018gaan.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Leaders in the storage world offer valuable advice for making more effective architecture and technology decisions.;
The science in computer science;Computer science is in a period of renaissance as it rediscovers its science roots.;
Verifying quantitative reliability for programs that execute on unreliable hardware;A growing number of low-cost (and free!) solutions aim to open the Internet to developing regions.;
UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception;A Dark Pattern (DP) is an interface maliciously crafted to deceive users into performing actions they did not mean to do. In this work we analyze Dark Patterns in 240 popular mobile apps and conduct an online experiment with 589 users on how they perceive Dark Patterns in such apps. The results of the analysis show that 95% of the analyzed apps contain one or more forms of Dark Patterns and on average popular applications include at least seven different types of deceiving interfaces. The online experiment shows that most users do not recognize Dark Patterns but can perform better in recognizing malicious designs if informed on the issue. We discuss the impact of our work and what measures could be applied to alleviate the issue.;
Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;Companies have access to more types of external data than ever before. How can they integrate it most effectively?;
What is AI Literacy? Competencies and Design Considerations;Artificial intelligence (AI) is becoming increasingly integrated in user-facing technology but public understanding of these technologies is often limited. There is a need for additional HCI research investigating a) what competencies users need in order to effectively interact with and critically evaluate AI and b) how to design learner-centered AI technologies that foster increased user understanding of AI. This paper takes a step towards realizing both of these goals by providing a concrete definition of AI literacy based on existing research. We synthesize a variety of interdisciplinary literature into a set of core competencies of AI literacy and suggest several design considerations to support AI developers and educators in creating learner-centered AI. These competencies and design considerations are organized in a conceptual framework thematically derived from the literature. This paper's contributions can be used to start a conversation about and guide future research on AI literacy within the HCI community.;
Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;A full-body virtual autopsy of an ancient Egyptian mummy showed visitors he was likely murdered.;
The anatomy of prototypes: Prototypes as filters prototypes as manifestations of design ideas;The role of prototypes is well established in the field of HCI and Design. A lack of knowledge however about the fundamental nature of prototypes still exists. Researchers have attempted to identify different types of prototypes such as low- vs. high-fidelity prototypes but these attempts have centered on evaluation rather than support of design exploration. There have also been efforts to provide new ways of thinking about the activity of using prototypes such as experience prototyping and paper prototyping but these efforts do not provide a discourse for understanding fundamental characteristics of prototypes. In this article we propose an anatomy of prototypes as a framework for prototype conceptualization. We view prototypes not only in their role in evaluation but also in their generative role in enabling designers to reflect on their design activities in exploring a design space. We base this framework on the findings of two case studies that reveal two key dimensions: prototypes as filters and prototypes as manifestations. We explain why these two dimensions are important and how this conceptual framework can benefit our field by establishing more solid and systematic knowledge about prototypes and prototyping.;
A scalable commodity data center network architecture;Today's data centers may contain tens of thousands of computers with significant aggregate bandwidth requirements. The network architecture typically consists of a tree of routing and switching elements with progressively more specialized and expensive equipment moving up the network hierarchy. Unfortunately even when deploying the highest-end IP switches/routers resulting topologies may only support 50% of the aggregate bandwidth available at the edge of the network while still incurring tremendous cost. Non-uniform bandwidth among data center nodes complicates application design and limits overall system performance.In this paper we show how to leverage largely commodity Ethernet switches to support the full aggregate bandwidth of clusters consisting of tens of thousands of elements. Similar to how clusters of commodity computers have largely replaced more specialized SMPs and MPPs we argue that appropriately architected and interconnected commodity switches may deliver more performance at less cost than available from today's higher-end solutions. Our approach requires no modifications to the end host network interface operating system or applications critically it is fully backward compatible with Ethernet IP and TCP.;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;This paper proposes a new type system for concurrent programs allowing threads to exchange complex object graphs  without risking destructive data races. While this goal is  shared by a rich history of past work existing solutions either rely on strictly enforced heap invariants that prohibit  natural programming patterns or demand pervasive annotations even for simple programming tasks. As a result past  systems cannot express intuitively simple code without unnatural rewrites or substantial annotation burdens. Our work  avoids these pitfalls through a novel type system that provides sound reasoning about separation in the heap while  remaining flexible enough to support a wide range of desirable heap manipulations. This new sweet spot is attained  by enforcing a heap domination invariant similarly to prior  work but tempering it by allowing complex exceptions that  add little annotation burden. Our results include: (1) code  examples showing that common data structure manipulations which are difficult or impossible to express in prior  work are natural and direct in our system (2) a formal proof  of correctness demonstrating that well-typed programs cannot encounter destructive data races at run time and (3) an  efficient type checker implemented in Gallina and OCaml.;
Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation;The January monthly service quality meeting started normally. Around the table were representatives from development operations marketing and product management and the agenda focused on the prior monthâ€™s performance. As usual customer-impacting incidents and quality of service were key topics and I was armed with the numbers showing the average uptime for the part of the service that I represent: MSN the Microsoft family of services that includes e-mail Instant Messenger news weather and sports etc.;
Heterogeneous Von Neumann/dataflow microprocessors;General-purpose processors (GPPs) which traditionally rely on a Von Neumann-based execution model incur burdensome power overheads largely due to the need to dynamically extract parallelism and maintain precise state. Further it is extremely difficult to improve their performance without increasing energy usage. Decades-old explicit-dataflow architectures eliminate many Von Neumann overheads but have not been successful as stand-alone alternatives because of poor performance on certain workloads due to insufficient control speculation and communication overheads.We observe a synergy between out-of-order (OOO) and explicit-dataflow processors whereby dynamically switching between them according to the behavior of program phases can greatly improve performance and energy efficiency. This work studies the potential of such a paradigm of heterogeneous execution models by developing a specialization engine for explicit-dataflow (SEED) and integrating it with a standard out-of-order (OOO) core. When integrated with a dual-issue OOO it becomes both faster (1.33x) and dramatically more energy efficient (1.70x). Integrated with an in-order core it becomes faster than even a dual-issue OOO with twice the energy efficiency.;
Compliance Deconstructed: When you break it down compliance is largely about ensuring that business processes are executed as expected.;The topic of compliance becomes increasingly complex each year. Dozens of regulatory requirements can affect a companyâ€™s business processes. Moreover these requirements are often vague and confusing. When those in charge of compliance are asked if their business processes are in compliance it is understandably difficult for them to respond succinctly and with confidence. This article looks at how companies can deconstruct compliance dealing with it in a systematic fashion and applying technology to automate compliance-related business processes. It also looks specifically at how Microsoft approaches compliance to SOX.;
Instant Messaging or Instant Headache? IM has found a home within the enterprise but itâ€™s far from secure.;Itâ€™s a reality. You have IM (instant messaging) clients in your environment. You have already recognized that it is eating up more and more of your network bandwidth and with Microsoft building IM capability into its XP operating system and applications you know this will only get worse. Management is also voicing concerns over the lost user productivity caused by personal conversations over this medium. You have tried blocking these conduits for conversation but it is a constant battle. Tools are now available to make this blocking job easier such as those from Akonix FaceTime Communications and NetIQ but IM is maturing and your users are starting to depend on it as an essential business tool.;
Language models: past present and future;A language modeling overview highlighting basic concepts intuitive explanations technical achievements and fundamental challenges.;
SoC: Software Hardware Nightmare Bliss: System-on-a-chip design offers great promise by shrinking an entire computer to a single chip. But with the promise come challenges that need to be overcome before SoC reaches its full potential.;System-on-a-chip (SoC) design methodology allows a designer to create complex silicon systems from smaller working blocks or systems. By providing a method for easily supporting proprietary functionality in a larger context that includes many existing design pieces SoC design opens the craft of silicon design to a much broader audience.;
Computing in the clouds;"Powerful services and applications are being integrated and packaged on the Web in what the industry now calls cloud computing""""";
Speculative taint tracking (STT): a comprehensive protection for speculatively accessed data;Speculative execution attacks present an enormous security threat capable of reading arbitrary program data under malicious speculation and later exfiltrating that data over microarchitectural covert channels. This paper proposes speculative taint tracking (STT) a high security and high performance hardware mechanism to block these attacks. The main idea is that it is safe to execute and selectively forward the results of speculative instructions that read secrets as long as we can prove that the forwarded results do not reach potential covert channels. The technical core of the paper is a new abstraction to help identify all micro-architectural covert channels and an architecture to quickly identify when a covert channel is no longer a threat. We further conduct a detailed formal analysis on the scheme in a companion document. When evaluated on SPEC06 workloads STT incurs 8.5% or 14.5% performance overhead relative to an insecure machine.;
Embedded EthiCS: integrating ethics across CS education;A Harvard-based pilot program integrates class sessions on ethical reasoning into courses throughout its computer science curriculum.;
hXDP: Efficient software packet processing on FPGA NICs;The network interface cards (NICs) of modern computers are changing to adapt to faster data rates and to help with the scaling issues of general-purpose CPU technologies. Among the ongoing innovations the inclusion of programmable accelerators on the NIC's data path is particularly interesting since it provides the opportunity to offload some of the CPU's network packet processing tasks to the accelerator. Given the strict latency constraints of packet processing tasks accelerators are often implemented leveraging platforms such as Field-Programmable Gate Arrays (FPGAs). FPGAs can be re-programmed after deployment to adapt to changing application requirements and can achieve both high throughput and low latency when implementing packet processing tasks. However they have limited resources that may need to be shared among diverse applications and programming them is difficult and requires hardware design expertise.We present hXDP a solution to run on FPGAs software packet processing tasks described with the eBPF technology and targeting the Linux's eXpress Data Path. hXDP uses only a fraction of the available FPGA resources while matching the performance of high-end CPUs. The iterative execution model of eBPF is not a good fit for FPGA accelerators. Nonetheless we show that many of the instructions of an eBPF program can be compressed parallelized or completely removed when targeting a purpose-built FPGA design thereby significantly improving performance.We implement hXDP on an FPGA NIC and evaluate it running real-world unmodified eBPF programs. Our implementation runs at 156.25MHz and uses about 15% of the FPGA resources. Despite these modest requirements it can run dynamically loaded programs achieves the packet processing throughput of a high-end CPU core and provides a 10X lower packet forwarding latency.;
How video production affects student engagement: an empirical study of MOOC videos;Videos are a widely-used kind of resource for online learning. This paper presents an empirical study of how video production decisions affect student engagement in online educational videos. To our knowledge ours is the largest-scale study of video engagement to date using data from 6.9 million video watching sessions across four courses on the edX MOOC platform. We measure engagement by how long students are watching each video and whether they attempt to answer post-video assessment problems.Our main findings are that shorter videos are much more engaging that informal talking-head videos are more engaging that Khan-style tablet drawings are more engaging that even high-quality pre-recorded classroom lectures might not make for engaging online videos and that students engage differently with lecture and tutorial videos.Based upon these quantitative findings and qualitative insights from interviews with edX staff we developed a set of recommendations to help instructors and video producers take better advantage of the online video format. Finally to enable researchers to reproduce and build upon our findings we have made our anonymized video watching data set and analysis scripts public. To our knowledge ours is one of the first public data sets on MOOC resource usage.;
Proceedings of the First ACM Conference on Learning @ Scale Conference;Although essential to revealing biased performance well intentioned attempts at algorithmic auditing can have effects that may harm the very populations these measures are meant to protect. This concern is even more salient while auditing biometric systems such as facial recognition where the data is sensitive and the technology is often used in ethically questionable manners. We demonstrate a set of fiveethical concerns in the particular case of auditing commercial facial processing technology highlighting additional design considerations and ethical tensions the auditor needs to be aware of so as not exacerbate or complement the harms propagated by the audited system. We go further to provide tangible illustrations of these concerns and conclude by reflecting on what these concerns mean for the role of the algorithmic audit and the fundamental product limitations they reveal.;
Proceedings of the AAAI/ACM Conference on AI Ethics and Society;Industry is building larger more complex manycore processors on the back of strong institutional knowledge but academic projects face difficulties in replicating that scale. To alleviate these difficulties and to develop and share knowledge the community needs open architecture frameworks for simulation chip design and software exploration that support extensibility scalability and configurability alongside an established base of verification tools and supported software. In this article we present OpenPiton an open source framework for building scalable architecture research prototypes from one core to 500 million cores. OpenPiton is the world's first open source general-purpose multithreaded manycore processor and framework. OpenPiton is highly configurable providing a rich design space spanning a variety of hardware parameters that researchers can change. OpenPiton designs can be emulated on FPGAs where they can run full-stack multiuser Debian Linux. OpenPiton is designed to scale to very large core fabrics enabling researchers to measure operating system compiler and software scalability. The mature code-base reflects the complexity of an industrial-grade design and provides the necessary scripts to build new chips making OpenPiton a natural choice for computer-aided design (CAD) research. OpenPiton has been validated with a 25-core chip prototype named Piton and is bolstered by a validation suite that has thousands of tests providing an environment to test new hardware designs while verifying the correctness of the whole system. OpenPiton is being actively used in research both internally to Princeton and in the wider community as well as being adopted in education industry and government settings.;
Network front-end processors yet again;The history of NFE processors sheds light on the trade-offs involved in designing network stack software.;
Maximizing power efficiency with asymmetric multicore systems;How do we develop software to make the most of the promise that asymmetric multicore systems use a lot less energy?;
A history of MATLAB;The first MATLAB (the name is short for â€œMatrix Laboratoryâ€) was not a programming language. Written in Fortran in the late 1970s it was a simple interactive matrix calculator built on top of about a dozen subroutines from the LINPACK and EISPACK matrix software libraries. There were only 71 reserved words and built-in functions. It could be extended only by modifying the Fortran source code and recompiling it. The programming language appeared in 1984 when MATLAB became a commercial product. The calculator was reimplemented in C and significantly enhanced with the addition of user functions toolboxes and graphics. It was available initially on the IBM PC and clones versions for Unix workstations and the Apple Macintosh soon followed. In addition to the matrix functions from the calculator the 1984 MATLAB included fast Fourier transforms (FFT). The Control System Toolbox appeared in 1985 and the Signal Processing Toolbox in 1987. Built-in support for the numerical solution of ordinary differential equations also appeared in 1987. The first significant new data structure the sparse matrix was introduced in 1992. The Image Processing Toolbox and the Symbolic Math Toolbox were both introduced in 1993. Several new data types and data structures including single precision floating point various integer and logical types cell arrays structures and objects were introduced in the late 1990s. Enhancements to the MATLAB computing environment have dominated development in recent years. Included are extensions to the desktop major enhancements to the object and graphics systems support for parallel computing and GPUs and the â€œLive Editorâ€ which combines programs descriptive text output and graphics into a single interactive formatted document. Today there are over 60 Toolboxes many programmed in the MATLAB language providing extended capabilities in specialized technical fields.;
Leveraging Application Frameworks: Why frameworks are important and how to apply them effectively;In todayâ€™s competitive fast-paced computing industry successful software must increasingly be: (1) extensible to support successions of quick updates and additions to address new requirements and take advantage of emerging markets (2) flexible to support a growing range of multimedia data types traffic flows and end-to-end QoS (quality of service) requirements (3) portable to reduce the effort required to support applications on heterogeneous operating-system platforms and compilers (4) reliable to ensure that applications are robust and tolerant to faults (5) scalable to enable applications to handle larger numbers of clients simultaneously and (6) affordable to ensure that the total ownership costs of software acquisition and evolution are not prohibitively high.;
The future of artificial intelligence in China;"In this paper we examine a number of SQL and socalled NoSQL"" data stores designed to scale simple OLTP-style application loads over many servers. Originally motivated by Web 2.0 applications these systems are designed to scale to thousands or millions of users doing updates as well as reads in contrast to traditional DBMSs and data warehouses. We contrast the new systems on their data model consistency mechanisms storage mechanisms durability guarantees availability query support and other dimensions. These systems typically sacrifice some of these dimensions e.g. database-wide transaction consistency in order to achieve others e.g. higher availability and scalability.""";
A historical perspective of speech recognition;What do we know now that we did not know 40 years ago?;
Web Services: Promises and Compromises: Much of web servicesâ€™ initial promise will be realized via integration within the enterprise.;Much of web servicesâ€™ initial promise will be realized via integration within the enterprise either with legacy applications or new business processes that span organizational silos. Enterprises need organizational structures that support this new paradigm.;
AI judges and juries;Artificial intelligence is changing the legal industry.;
Streams and Standards: Delivering Mobile Video: The era of video served up to mobile phones has arrived and threatens to be the next â€œkiller appâ€ after wireless calling itself.;Donâ€™t believe me? Follow alongâ€¦ Mobile phones are everywhere. Everybody has one. Think about the last time you were on an airplane and the flight was delayed on the ground. Immediately after the dreaded announcement you heard everyone reach for their phones and start dialing.;
Power-efficient software;Power-manageable hardware can help save energy but what can software developers do to address the problem?;
Monitoring and control of large systems with MonALISA;MonALISA developers describe how it works the key design principles behind it and the biggest technical challenges in building it.;
The Android Platform Security Model;Android is the most widely deployed end-user focused operating system. With its growing set of use cases encompassing communication navigation media consumption entertainment finance health and access to sensors actuators cameras or microphones its underlying security model needs to address a host of practical threats in a wide variety of scenarios while being useful to non-security experts. The model needs to strike a difficult balance between security privacy and usability for end users assurances for app developers and system performance under tight hardware constraints. While many of the underlying design principles have implicitly informed the overall system architecture access control mechanisms and mitigation techniques the Android security model has previously not been formally published. This article aims to both document the abstract model and discuss its implications. Based on a definition of the threat model and Android ecosystem context in which it operates we analyze how the different security measures in past and current Android implementations work together to mitigate these threats. There are some special cases in applying the security model and we discuss such deliberate deviations from the abstract model.;
Accelerating GPU betweenness centrality;Graphs that model social networks numerical simulations and the structure of the Internet are enormous and cannot be manually inspected. A popular metric used to analyze these networks is Betweenness Centrality (BC) which has applications in community detection power grid contingency analysis and the study of the human brain. However these analyses come with a high computational cost that prevents the examination of large graphs of interest.Recently the use of Graphics Processing Units (GPUs) has been promising for efficient processing of unstructured data sets. Prior GPU implementations of BC suffer from large local data structures and inefficient graph traversals that limit scalability and performance. Here we present a hybrid GPU implementation that provides good performance on graphs of arbitrary structure rather than just scale-free graphs as was done previously. Our methods achieve up to 13\texttimes{;
How to live in a post-meltdown and -spectre world;Learn from the past to prepare for the next battle.;
Larrabee: a many-core x86 architecture for visual computing;This paper presents a many-core visual computing architecture code named Larrabee a new software rendering pipeline a manycore programming model and performance analysis for several applications. Larrabee uses multiple in-order x86 CPU cores that are augmented by a wide vector processor unit as well as some fixed function logic blocks. This provides dramatically higher performance per watt and per unit of area than out-of-order CPUs on highly parallel workloads. It also greatly increases the flexibility and programmability of the architecture as compared to standard GPUs. A coherent on-die 2nd level cache allows efficient inter-processor communication and high-bandwidth local data access by CPU cores. Task scheduling is performed entirely with software in Larrabee rather than in fixed function logic. The customizable software graphics rendering pipeline for this architecture uses binning in order to reduce required memory bandwidth minimize lock contention and increase opportunities for parallelism relative to standard GPUs. The Larrabee native programming model supports a variety of highly parallel applications that use irregular data structures. Performance analysis on those applications demonstrates Larrabee's potential for a broad range of parallel computation.;
Principles of robust timing over the internet;The key to synchronizing clocks over networks is taming delay variability.;
Digging into big provenance (with SPADE);A user interface for querying provenance.;
Moving to the Edge: An ACM CTO Roundtable on Network Virtualization: How will virtualization technologies affect network service architectures?;The general IT community is just beginning to digest how the advent of virtual machines and cloud computing is changing their world. These new technologies promise to make applications more portable and increase the opportunity for more flexibility and efficiency in both on-premises and outsourced support infrastructures. However virtualization can break long-standing linkages between applications and their supporting physical devices. Before data-center managers can take advantage of these new opportunities they must have a better understanding of service infrastructure requirements and their linkages to applications.;
The scalable commutativity rule: designing scalable software for multicore processors;Developing software that scales on multicore processors is an inexact science dominated by guesswork measurement and expensive cycles of redesign and reimplementation. Current approaches are workload-driven and hence can reveal scalability bottlenecks only for known workloads and available software and hardware. This paper introduces an interface-driven approach to building scalable software. This approach is based on the scalable commutativity rule which informally stated says that whenever interface operations commute they can be implemented in a way that scales. We formalize this rule and prove it correct for any machine on which conflict-free operations scale such as current cache-coherent multicore machines. The rule also enables a better design process for scalable software: programmers can now reason about scalability from the earliest stages of interface definition through software design implementation and evaluation.;
Debugging in an Asynchronous World: Hard-to-track bugs can emerge when you canâ€™t guarantee sequential execution. The right tools and the right techniques can help.;Pagers cellular phones smart appliances and Web services - these products and services are almost omnipresent in our world and are stimulating the creation of a new breed of software: applications that must deal with inputs from a variety of sources provide real-time responses deliver strong security - and do all this while providing a positive user experience. In response a new style of application programming is taking hold one that is based on multiple threads of control and the asynchronous exchange of data and results in fundamentally more complex applications.;
Trials and Tribulations of Debugging Concurrency: You can run but you canâ€™t hide.;We now sit firmly in the 21st century where the grand challenge to the modern-day programmer is neither memory leaks nor type issues (both of those problems are now effectively solved) but rather issues of concurrency. How does one write increasingly complex programs where concurrency is a first-class concern. Or even more treacherous how does one debug such a beast? These questions bring fear into the hearts of even the best programmers.;
150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com;Booking.com is the world's largest online travel agent where millions of guests find their accommodation and millions of accommodation providers list their properties including hotels apartments bed and breakfasts guest houses and more. During the last years we have applied Machine Learning to improve the experience of our customers and our business. While most of the Machine Learning literature focuses on the algorithmic or mathematical aspects of the field not much has been published about how Machine Learning can deliver meaningful impact in an industrial environment where commercial gains are paramount. We conducted an analysis on about 150 successful customer facing applications of Machine Learning developed by dozens of teams in Booking.com exposed to hundreds of millions of users worldwide and validated through rigorous Randomized Controlled Trials. Following the phases of a Machine Learning project we describe our approach the many challenges we found and the lessons we learned while scaling up such a complex technology across our organization. Our main conclusion is that an iterative hypothesis driven process integrated with other disciplines was fundamental to build 150 successful products enabled by Machine Learning.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Modern datacenter networks provide very high capacity via redundant Clos topologies and low switch latency but transport protocols rarely deliver matching performance. We present NDP a novel data-center transport architecture that achieves near-optimal completion times for short transfers and high flow throughput in a wide range of scenarios including incast. NDP switch buffers are very shallow and when they fill the switches trim packets to headers and priority forward the headers. This gives receivers a full view of instantaneous demand from all senders and is the basis for our novel high-performance multipath-aware transport protocol that can deal gracefully with massive incast events and prioritize traffic from different senders on RTT timescales. We implemented NDP in Linux hosts with DPDK in a software switch in a NetFPGA-based hardware switch and in P4. We evaluate NDP's performance in our implementations and in large-scale simulations simultaneously demonstrating support for very low-latency and high throughput.;
Proceedings of the Conference of the ACM Special Interest Group on Data Communication;Software development is rarely a solo coding effort. More often it is a collaborative process with teams of developers working together to design solutions and produce quality code. The members of these close-knit teams often look at one anotherâ€™s code collectively make plans about how to proceed and even fix each otherâ€™s bugs when necessary. Teamwork does not stop there however. An extended team may include project managers testers architects designers writers and other specialists as well as other programming teams. Programmers also interact with the community of developers outside their organization to obtain advice code snippets and a general understanding of what works and what doesnâ€™t.;
Vision-based hand-gesture applications;Body posture and finger pointing are a natural modality for human-machine interaction but first the system must know what it's seeing.;
Bioinformaticsâ€”an introduction for computer scientists;The article aims to introduce computer scientists to the new field of bioinformatics. This area has arisen from the needs of biologists to utilize and help interpret the vast amounts of data that are constantly being gathered in genomic research---and its more recent counterparts proteomics and functional genomics. The ultimate goal of bioinformatics is to develop in silico models that will complement in vitro and in vivo biological experiments. The article provides a bird's eye view of the basic concepts in molecular cell biology outlines the nature of the existing data and describes the kind of computer algorithms and techniques that are necessary to understand cell behavior. The underlying motivation for many of the bioinformatics approaches is the evolution of organisms and the complexity of working with incomplete and noisy data. The topics covered include: descriptions of the current software especially developed for biologists computer and mathematical cell models and areas of computer science that play an important role in bioinformatics.;
In-sensor classification with boosted race trees;When extremely low-energy processing is required the choice of data representation makes a tremendous difference. Each representation (e.g. frequency domain residue coded and log-scale) embodies a different set of tradeoffs based on the algebraic operations that are either easy or hard to perform in that domain. We demonstrate the potential of a novel form of encoding race logic in which information is represented as the delay in the arrival of a signal. Under this encoding the ways in which signal delays interact and interfere with one another define the operation of the system. Observations of the relative delays (for example the outcome of races between signals) define the output of the computation. Interestingly completely standard hardware logic elements can be repurposed to this end and the resulting embedded systems have the potential to be extremely energy efficient. To realize this potential in a practical design we demonstrate two different approaches to the creation of programmable tree-based ensemble classifiers in an extended set of race logic primitives we explore the trade-offs inherent to their operation across sensor hardware architecture and algorithm and we compare the resulting designs against traditional state-of-the-art hardware techniques.;
Usability evaluation considered harmful (some of the time);Current practice in Human Computer Interaction as encouraged by educational institutes academic review processes and institutions with usability groups advocate usability evaluation as a critical part of every design process. This is for good reason: usability evaluation has a significant role to play when conditions warrant it. Yet evaluation can be ineffective and even harmful if naively done 'by rule' rather than 'by thought'. If done during early stage design it can mute creative ideas that do not conform to current interface norms. If done to test radical innovations the many interface issues that would likely arise from an immature technology can quash what could have been an inspired vision. If done to validate an academic prototype it may incorrectly suggest a design's scientific worthiness rather than offer a meaningful critique of how it would be adopted and used in everyday practice. If done without regard to how cultures adopt technology over time then today's reluctant reactions by users will forestall tomorrow's eager acceptance. The choice of evaluation methodology - if any - must arise from and be appropriate for the actual problem or research question under consideration.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;With the increasing growth and impact of machine learning and other math-intensive fields it is more important than ever to broaden access to mathematical notation. Can new visual and interactive displays help a wider readership successfully engage with notation? This paper provides the first detailed qualitative analysis of math augmentationâ€”the practice of embellishing notation with novel visual design patterns to improve its readability. We present two qualitative studies of the practice of math augmentation. First is an analysis of 1.1k augmentations to 281 formulas in 47 blogs textbooks and other documents containing mathematical expressions. Second is an interview study with 12 authors who had previously designed custom math augmentations (â€œmaugsâ€). This paper contributes a comprehensive inventory of the kinds of maugs that appear in math documents and a detailed account of how authorsâ€™ tools ought to be redesigned to support efficient creation of math augmentations. These studies open a critical new design space for HCI researchers and interface designers.;
Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems;The ability to predict student performance in a course or program creates opportunities to improve educational outcomes. With effective performance prediction approaches instructors can allocate resources and instruction more accurately. Research in this area seeks to identify features that can be used to make predictions to identify algorithms that can improve predictions and to quantify aspects of student performance. Moreover research in predicting student performance seeks to determine interrelated features and to identify the underlying reasons why certain features work better than others. This working group report presents a systematic literature review of work in the area of predicting student performance. Our analysis shows a clearly increasing amount of research in this area as well as an increasing variety of techniques used. At the same time the review uncovered a number of issues with research quality that drives a need for the community to provide more detailed reporting of methods and results and to increase efforts to validate and replicate work.;
Proceedings Companion of the 23rd Annual ACM Conference on Innovation and Technology in Computer Science Education;Digital signal processing is a stealth technology. It is the core enabling technology in everything from your cellphone to the Mars Rover. It goes much further than just enabling a one-time breakthrough product. It provides ever-increasing capability compare the performance gains made by dial-up modems with the recent performance gains of DSL and cable modems. Remarkably digital signal processing has become ubiquitous with little fanfare and most of its users are not even aware of what it is. Therefore it is worthwhile to look at the development history of DSP an explanation of what the technology is and a review of the many technologies that are used to implement modern digital signal processing systems.;
Experiences With and Lessons Learned on Deadlines and Submission Behavior;Course exercises are typically given so that the time it takes to finish them fits in the time constraints of the academic system. Exercises come with deadlines that are considered to help students plan their schedules and consequently help get the exercises done. Without deadlines exercises that need to be done may easily slide away to make room for other tasks that are seemingly more important. Even with deadlines however some students procrastinate and leave their tasks without attention until the very last moment. In this article we study computer science course exercise deadlines by analyzing data from a course that had different deadline placements over the years. The deadline placements of the course were varied to identify a deadline that would be suitable for the majorityâ€”if not allâ€”of students. Our analyses from six different deadlines demonstrate that some deadlines seem to reduce last-minute work on exercises. Our findings highlight that not all deadlines are the same and serves as a call for more research into deadline placement and their potential impacts on student time management and performance.;
Proceedings of the 22nd Koli Calling International Conference on Computing Education Research;Trusted Execution Environments ('TEEs') or 'secure enclaves' aim at enabling more secure computation and data management. There is much enthusiasm for this technology not least as we see increasing legal and regulatory attention on issues of security privacy and data management and use. With cloud providing the infrastructure for underpinning applications data processing and analytics/ML access to enclaves and enclave-backed technologies are increasingly being offered by service (cloud) providers - with the technology described as enabling confidential computing. This paper provides a high-level overview of the common security properties provided by enclaves and considers how such technology in being offered by cloud providers relates to organizational legal and regulatory concerns. Focusing on data protection regulations we explore the aspects of TEEs that might assist compliance and who stands to benefit from the deployment of such technology in a service provision context.;
Blaster Revisited: A second look at the cost of Blaster sheds new light on todayâ€™s blended threats.;What lessons can we learn from the carnage the Blaster worm created? The following tale is based upon actual circumstances from corporate enterprises that were faced with confronting and eradicating the Blaster worm which hit in August 2003. The story provides views from many perspectives illustrating the complexity and sophistication needed to combat new blended threats.;
ORM in dynamic languages;Dynamic languages offer a taste of object-relational mapping that eases application code.;
Coz: finding code that counts with causal profiling;"Improving performance is a central concern for software developers. To locate optimization opportunities developers rely on software profilers. However these profilers only report where programs spend their time: optimizing that code may have no impact on performance. Past profilers thus both waste developer time and make it difficult for them to uncover significant optimization opportunities.This paper introduces causal profiling. Unlike past profiling approaches causal profiling indicates exactly where programmers should focus their optimization efforts and quantifies their potential impact. Causal profiling works by running performance experiments during program execution. Each experiment calculates the impact of any potential optimization by virtually speeding up code: inserting pauses that slow down all other code running concurrently. The key insight is that this slowdown has the same relative effect as running that line faster thus virtually"" speeding it up.We present Coz a causal profiler which we evaluate on a range of highly-tuned applications such as Memcached SQLite and the PARSEC benchmark suite. Coz identifies previously unknown optimization opportunities that are both significant and targeted. Guided by Coz we improve the performance of Memcached by 9% SQLite by 25% and accelerate six PARSEC applications by as much as 68% in most cases these optimizations involve modifying under 10 lines of code.""";
The gem5 simulator;The gem5 simulation infrastructure is the merger of the best aspects of the M5 [4] and GEMS [9] simulators. M5 provides a highly configurable simulation framework multiple ISAs and diverse CPU models. GEMS complements these features with a detailed and exible memory system including support for multiple cache coherence protocols and interconnect models. Currently gem5 supports most commercial ISAs (ARM ALPHA MIPS Power SPARC and x86) including booting Linux on three of them (ARM ALPHA and x86).The project is the result of the combined efforts of many academic and industrial institutions including AMD ARM HP MIPS Princeton MIT and the Universities of Michigan Texas and Wisconsin. Over the past ten years M5 and GEMS have been used in hundreds of publications and have been downloaded tens of thousands of times. The high level of collaboration on the gem5 project combined with the previous success of the component parts and a liberal BSD-like license make gem5 a valuable full-system simulation tool.;
Enhanced debugging with traces;An essential technique used in emulator development is a useful addition to any programmer's toolbox.;
Code spelunking redux;Is it getting any easier to understand other people's code?;
Garbage collection as a joint venture;A collaborative approach to reclaiming memory in heterogeneous software systems.;
Teaching and learning human-computer interaction: past present and future;As data analytics has become an important application for modern data management systems a new category of data management system has appeared recently: the scalable linear algebra system. We argue that a parallel or distributed database system is actually an excellent platform upon which to build such functionality. Most relational systems already have support for cost-based optimization---which is vital to scaling linear algebra computations---and it is well known how to make relational systems scalable.We show that by making just a few changes to a parallel/distributed relational database system such a system can become a competitive platform for scalable linear algebra. Taken together our results should at least raise the possibility that brand new systems designed from the ground up to support scalable linear algebra are not absolutely necessary and that such systems could instead be built on top of existing relational technology.;
ACM SIGGRAPH 2008 Papers;Companies have always been challenged with integrating systems across organizational boundaries. With the advent of Internet-native systems this integration has become essential for modern organizations but it has also become more and more complex especially as next-generation business systems depend on agile flexible interoperable reliable and secure cross-enterprise systems.;
Powering the next Billion devices with wi-fi;We present the first power over Wi-Fi system that delivers power to low-power sensors and devices and works with existing Wi-Fi chipsets. We show that a ubiquitous part of wireless communication infrastructure the Wi-Fi router can provide far field wireless power without significantly compromising the network's communication performance. Building on our design we prototype battery-free temperature and camera sensors that we power with Wi-Fi at ranges of 20 and 17 ft respectively. We also demonstrate the ability to wirelessly trickle-charge nickel--metal hydride and lithium-ion coin-cell batteries at distances of up to 28 ft. We deploy our system in six homes in a metropolitan area and show that it can successfully deliver power via Wi-Fi under real-world network conditions without significantly degrading network performance.;
How to teach computer ethics through science fiction;Science fiction in particular offers students a way to cultivate their capacity for moral imagination.;
FPGA HLS Today: Successes Challenges and Opportunities;The year 2011 marked an important transition for FPGA high-level synthesis (HLS) as it went from prototyping to deployment. A decade later in this article we assess the progress of the deployment of HLS technology and highlight the successes in several application domains including deep learning video transcoding graph processing and genome sequencing. We also discuss the challenges faced by todayâ€™s HLS technology and the opportunities for further research and development especially in the areas of achieving high clock frequency coping with complex pragmas and system integration legacy code transformation building on open source HLS infrastructures supporting domain-specific languages and standardization. It is our hope that this article will inspire more research on FPGA HLS and bring it to a new height.;
Heads-up limit hold'em poker is solved;Poker is a family of games that exhibit imperfect information where players do not have full knowledge of past events. While many perfect information games have been solved (e.g. Connect-Four and checkers) no nontrivial imperfect information game played competitively by humans has previously been solved. In this paper we announce that the smallest variant of poker in-play heads-up limit Texas hold'em is now essentially weakly solved. Furthermore this computation formally proves the common wisdom that the dealer in the game holds a significant advantage. This result was enabled by a new algorithm CFR+ which is capable of solving extensive-form games three orders of magnitude larger than previously possible. This paper is an extended version of the original 2015 Science article with additional results showing Cepheus' in-game performance against computer and human opponents.;
The algorithm that changed quantum machine learning;A college student discovered a classical computing algorithm that experts overlooked. It promises to change both classical and quantum machine learning.;
Improving gender composition in computing;Combining academic and industry representation the NCWIT Pacesetters program works to increase the participation of girls and women in computing.;
The Answer is 42 of Course: If we want our networks to be sufficiently difficult to penetrate weâ€™ve got to ask the right questions.;Why is security so hard? As a security consultant Iâ€™m glad that people feel that way because that perception pays my mortgage. But is it really so difficult to build systems that are impenetrable to the bad guys?;
Online deception in social media;The unknown and the invisible exploit the unwary and the uninformed for illicit financial gain and reputation damage.;
Investigating Explainability of Generative AI for Code through Scenario-based Design;What does it mean for a generative AI model to be explainable? The emergent discipline of explainable AI (XAI) has made great strides in helping people understand discriminative models. Less attention has been paid to generative models that produce artifacts rather than decisions as output. Meanwhile generative AI (GenAI) technologies are maturing and being applied to application domains such as software engineering. Using scenario-based design and question-driven XAI design approaches we explore usersâ€™ explainability needs for GenAI in three software engineering use cases: natural language to code code translation and code auto-completion. We conducted 9 workshops with 43 software engineers in which real examples from state-of-the-art generative AI models were used to elicit usersâ€™ explainability needs. Drawing from prior work we also propose 4 types of XAI features for GenAI for code and gathered additional design ideas from participants. Our work explores explainability needs for GenAI for code and demonstrates how human-centered approaches can drive the technical development of XAI in novel domains.;
Proceedings of the 27th International Conference on Intelligent User Interfaces;Optimizing programs to run efficiently on modern parallel hardware is hard but crucial for many applications. The predominantly used imperative languages - like C or OpenCL - force the programmer to intertwine the code describing functionality and optimizations. This results in a portability nightmare that is particularly problematic given the accelerating trend towards specialized hardware devices to further increase efficiency.  Many emerging DSLs used in performance demanding domains such as deep learning or high-performance image processing attempt to simplify or even fully automate the optimization process. Using a high-level - often functional - language programmers focus on describing functionality in a declarative way. In some systems such as Halide or TVM a separate schedule specifies how the program should be optimized. Unfortunately these schedules are not written in well-defined programming languages. Instead they are implemented as a set of ad-hoc predefined APIs that the compiler writers have exposed.  In this functional pearl we show how to employ functional programming techniques to solve this challenge with elegance. We present two functional languages that work together - each addressing a separate concern. RISE is a functional language for expressing computations using well known functional data-parallel patterns. ELEVATE is a functional language for describing optimization strategies. A high-level RISE program is transformed into a low-level form using optimization strategies written in ELEVATE . From the rewritten low-level program high-performance parallel code is automatically generated. In contrast to existing high-performance domain-specific systems with scheduling APIs in our approach programmers are not restricted to a set of built-in operations and optimizations but freely define their own computational patterns in RISE and optimization strategies in ELEVATE in a composable and reusable way. We show how our holistic functional approach achieves competitive performance with the state-of-the-art imperative systems Halide and TVM.;
Injecting errors for fun and profit;Error-detection and correction features are only as good as our ability to test them.;
Persistent Memory Programming on Conventional Hardware: The persistent memory style of programming can dramatically simplify application software.;Driven by the advent of byte-addressable non-volatile memory the persistent memory style of programming will gain traction among developers taking its rightful place alongside existing paradigms for managing persistent application state. Until NVM becomes available on all computers developers can use the techniques presented in this article to enjoy the benefits of persistent memory programming on conventional hardware.;
Are Deepfakes Concerning? Analyzing Conversations of Deepfakes on Reddit and Exploring Societal Implications;Deepfakes are synthetic content generated using advanced deep learning and AI technologies. The advancement of technology has created opportunities for anyone to create and share deepfakes much easier. This may lead to societal concerns based on how communities engage with it. However there is limited research available to understand how communities perceive deepfakes. We examined deepfake conversations on Reddit from 2018 to 2021â€”including major topics and their temporal changes as well as implications of these conversations. Using a mixed-method approachâ€”topic modeling and qualitative coding we found 6638 posts and 86425 comments discussing concerns of the believable nature of deepfakes and how platforms moderate them. We also found Reddit conversations to be pro-deepfake and building a community that supports creating and sharing deepfake artifacts and building a marketplace regardless of the consequences. Possible implications derived from qualitative codes indicate that deepfake conversations raise societal concerns. We propose that there are implications for Human Computer Interaction (HCI) to mitigate the harm created from deepfakes.;
Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems;The introduction of the microprocessor in 1971 marked the beginning of a 30-year stall in design methods for electronic systems. The industry is coming out of the stall by shifting from programmed to reconfigurable systems. In programmed systems a linear sequence of configuration bits organized into blocks called instructions configures fixed hardware to mimic custom hardware. In reconfigurable systems the physical connections among logic elements change with time to mimic custom hardware. The transition to reconfigurable systems will be wrenching but this is inevitable as the design emphasis shifts from cost performance to cost performance per watt. Hereâ€™s the story.;
Making decisions based on the preferences of multiple agents;Computer scientists have made great strides in how decision-making mechanisms are used.;
The Effects of Mixing Machine Learning and Human Judgment: Collaboration between humans and machines does not necessarily lead to better outcomes.;Based on the theoretical findings from the existing literature some policymakers and software engineers contend that algorithmic risk assessments such as the COMPAS software can alleviate the incarceration epidemic and the occurrence of violent crimes by informing and improving decisions about policing treatment and sentencing. Considered in tandem these findings indicate that collaboration between humans and machines does not necessarily lead to better outcomes and human supervision does not sufficiently address problems when algorithms err or demonstrate concerning biases. If machines are to improve outcomes in the criminal justice system and beyond future research must further investigate their practical role: an input to human decision makers.;
Neurosurgeon: Collaborative Intelligence Between the Cloud and Mobile Edge;The computation for today's intelligent personal assistants such as Apple Siri Google Now and Microsoft Cortana is performed in the cloud. This cloud-only approach requires significant amounts of data to be sent to the cloud over the wireless network and puts significant computational pressure on the datacenter. However as the computational resources in mobile devices become more powerful and energy efficient questions arise as to whether this cloud-only processing is desirable moving forward and what are the implications of pushing some or all of this compute to the mobile devices on the edge.In this paper we examine the status quo approach of cloud-only processing and investigate computation partitioning strategies that effectively leverage both the cycles in the cloud and on the mobile device to achieve low latency low energy consumption and high datacenter throughput for this class of intelligent applications. Our study uses 8 intelligent applications spanning computer vision speech and natural language domains all employing state-of-the-art Deep Neural Networks (DNNs) as the core machine learning technique. We find that given the characteristics of DNN algorithms a fine-grained layer-level computation partitioning strategy based on the data and computation variations of each layer within a DNN has significant latency and energy advantages over the status quo approach.Using this insight we design Neurosurgeon a lightweight scheduler to automatically partition DNN computation between mobile devices and datacenters at the granularity of neural network layers. Neurosurgeon does not require per-application profiling. It adapts to various DNN architectures hardware platforms wireless networks and server load levels intelligently partitioning computation for best latency or best mobile energy. We evaluate Neurosurgeon on a state-of-the-art mobile development platform and show that it improves end-to-end latency by 3.1X on average and up to 40.7X reduces mobile energy consumption by 59.5% on average and up to 94.7% and improves datacenter throughput by 1.5X on average and up to 6.7X.;
Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems;Integrating computer games into existing CS courses may help attract students to the field but there are guidelines to be considered.;
Managing the Hidden Costs of Coordination: Controlling coordination costs when multiple distributed perspectives are essential;Some initial considerations to control cognitive costs for incident responders include: (1) assessing coordination strategies relative to the cognitive demands of the incident (2) recognizing when adaptations represent a tension between multiple competing demands (coordination and cognitive work) and seeking to understand them better rather than unilaterally eliminating them (3) widening the lens to study the joint cognition system (integration of human-machine capabilities) as the unit of analysis and (4) viewing joint activity as an opportunity for enabling reciprocity across inter- and intra-organizational boundaries.;
Data Cards: Purposeful and Transparent Dataset Documentation for Responsible AI;As research and industry moves towards large-scale models capable of numerous downstream tasks the complexity of understanding multi-modal datasets that give nuance to models rapidly increases. A clear and thorough understanding of a datasetâ€™s origins development intent ethical considerations and evolution becomes a necessary step for the responsible and informed deployment of models especially those in people-facing contexts and high-risk domains. However the burden of this understanding often falls on the intelligibility conciseness and comprehensiveness of the documentation. It requires consistency and comparability across the documentation of all datasets involved and as such documentation must be treated as a user-centric product in and of itself. In this paper we propose Data Cards for fostering transparent purposeful and human-centered documentation of datasets within the practical contexts of industry and research. Data Cards are structured summaries of essential facts about various aspects of ML datasets needed by stakeholders across a datasetâ€™s lifecycle for responsible AI development. These summaries provide explanations of processes and rationales that shape the data and consequently the modelsâ€”such as upstream sources data collection and annotation methods training and evaluation methods intended use or decisions affecting model performance. We also present frameworks that ground Data Cards in real-world utility and human-centricity. Using two case studies we report on desirable characteristics that support adoption across domains organizational structures and audience groups. Finally we present lessons learned from deploying over 20 Data Cards.x;
Proceedings of the 2022 ACM Conference on Fairness Accountability and Transparency;Thanks to modern SCM (software configuration management) systems when developers work on a codeline they leave behind a trail of clues that can reveal what parts of the code have been modified when how and by whom. From the perspective of QA (quality assurance) and test engineers is this all just â€œdataâ€ or is there useful information that can improve the test coverage and overall quality of a product?;
CTO Roundtable: Storage Part II;Leaders in the storage industry ponder upcoming technologies and trends.;
Information cartography;A metro map can tell a story as well as provide good directions.;
How and why people Twitter: the role that micro-blogging plays in informal communication at work;Micro-blogs a relatively new phenomenon provide a new communication channel for people to broadcast information that they likely would not share otherwise using existing channels (e.g. email phone IM or weblogs). Micro-blogging has become popu-lar quite quickly raising its potential for serving as a new informal communication medium at work providing a variety of impacts on collaborative work (e.g. enhancing information sharing building common ground and sustaining a feeling of connectedness among colleagues). This exploratory research project is aimed at gaining an in-depth understanding of how and why people use Twitter - a popular micro-blogging tool - and exploring micro-blog's poten-tial impacts on informal communication at work.;
Proceedings of the 2009 ACM International Conference on Supporting Group Work;"Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly in the wild"" contexts and understand how practices evolve over long-term naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings which both support and contrast with those of previous research paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Complex and opaque systems do not scale easily. A human-centered approach for evolving tools and practices is essential to ensuring that software is scaled safely and securely. Static analysis can unveil information about program behavior but the goal of deriving this information should not be to accumulate hairsplitting detail. HCI can help direct static-analysis techniques into developer-facing systems that structure information and embody relationships in representations that closely mirror a programmer's thought. The survival of great software depends on programming languages that support rather than inhibit communicating reasoning and abstract thinking.;
Evolve or Die: High-Availability Design Principles Drawn from Googles Network Infrastructure;Maintaining the highest levels of availability for content providers is challenging in the face of scale network evolution and complexity. Little however is known about failures large content providers are susceptible to and what mechanisms they employ to ensure high availability. From a detailed analysis of over 100 high-impact failure events in a global-scale content provider encompassing several data centers and two WANs we quantify several dimensions of availability failures. We find that failures are evenly distributed across different network types and planes but that a large number of failures happen when a management operation is in progress within the network. We discuss some of these failures in detail and also describe our design principles for high availability motivated by these failures including using defense in depth maintaining consistency across planes failing open on large failures carefully preventing and avoiding failures and assessing root cause quickly. Our findings suggest that as networks become more complicated failures lurk everywhere and counter-intuitively continuous incremental evolution of the network can when applied together with our design principles result in a more robust network.;
Proceedings of the 2016 ACM SIGCOMM Conference;This paper introduces BioScript a domain-specific language (DSL) for programmable biochemistry that executes on emerging microfluidic platforms. The goal of this research is to provide a simple intuitive and type-safe DSL that is accessible to life science practitioners. The novel feature of the language is its syntax which aims to optimize human readability the technical contribution of the paper is the BioScript type system. The type system ensures that certain types of errors specific to biochemistry do not occur such as the interaction of chemicals that may be unsafe. Results are obtained using a custom-built compiler that implements the BioScript language and type system.;
Scalable signal reconstruction for a broad range of applications;Signal reconstruction problem (SRP) is an important optimization problem where the objective is to identify a solution to an underdetermined system of linear equations that is closest to a given prior. It has a substantial number of applications in diverse areas such as network traffic engineering medical image reconstruction acoustics astronomy and many more. Unfortunately most of the common approaches for solving SRP do not scale to large problem sizes. We propose a novel and scalable algorithm for solving this critical problem. Specifically we make four major contributions. First we propose a dual formulation of the problem and develop the DIRECT algorithm that is significantly more efficient than the state of the art. Second we show how adapting database techniques developed for scalable similarity joins provides a substantial speedup over DIRECT. Third we describe several practical techniques that allow our algorithm to scale---on a single machine---to settings that are orders of magnitude larger than previously studied. Finally we use the database techniques of materialization and reuse to extend our result to dynamic settings where the input to the SRP changes. Extensive experiments on real-world and synthetic data confirm the efficiency effectiveness and scalability of our proposal.;
Patching the Enterprise: Organizations of all sizes are spending considerable efforts on getting patch management right - their businesses depend on it.;Software patch management has grown to be a business-critical issueâ€”from both a risk and a financial management perspective. According to a recent Aberdeen Group study corporations spent more than $2 billion in 2002 on patch management for operating systems.1 Gartner research further notes the cost of operating a well-managed PC was approximately $2000 less annually than that of an unmanaged PC.2 You might think that with critical mass and more sophisticated tools the management cost per endpoint in large organizations would be lower though in reality this may not be the case. The objective of this article is to provide some rationaleâ€”drawn from enterprise experienceâ€”to put these observations into context and present some approaches that could be useful to combat that trend.;
Concurrent Hash Tables: Fast and General(?)!;Concurrent hash tables are one of the most important concurrent data structures which are used in numerous applications. For some applications it is common that hash table accesses dominate the execution time. To efficiently solve these problems in parallel we need implementations that achieve speedups in highly concurrent scenarios. Unfortunately currently available concurrent hashing libraries are far away from this requirement in particular when adaptively sized tables are necessary or contention on some elements occurs.Our starting point for better performing data structures is a fast and simple lock-free concurrent hash table based on linear probing that is however limited to word-sized key-value types and does not support dynamic size adaptation. We explain how to lift these limitations in a provably scalable way and demonstrate that dynamic growing has a performance overhead comparable to the same generalization in sequential hash tables.We perform extensive experiments comparing the performance of our implementations with six of the most widely used concurrent hash tables. Ours are considerably faster than the best algorithms with similar restrictions and an order of magnitude faster than the best more general tables. In some extreme cases the difference even approaches four orders of magnitude.All our implementations discussed in this publication can be found on github [17].;
How do I model state? Let me count the ways;A study of the technology and sociology of Web service specifications.;
CTO Roundtable: Virtualization Part II: When it comes to virtualization platforms experts say focus first on the services to be delivered.;Last month we published Part I of a CTO Roundtable forum on virtualization. Sponsored by the ACM Professions Board the roundtable features five experts on virtualization discussing the current state of the technology and how companies can use it most effectively. In this second and final installment the participants address key issues such as choosing the most appropriate virtual machine platform using virtualization to streamline desktop delivery and using virtualization as an effective disaster-recovery mechanism.;
Scribe: deep integration of human and machine intelligence to caption speech in real time;Quickly converting speech to text allows deaf and hard of hearing people to interactively follow along with live speech. Doing so reliably requires a combination of perception understanding and speed that neither humans nor machines possess alone. In this article we discuss how our Scribe system combines human labor and machine intelligence in real time to reliably convert speech to text with less than 4s latency. To achieve this speed while maintaining high accuracy Scribe integrates automated assistance in two ways. First its user interface directs workers to different portions of the audio stream slows down the portion they are asked to type and adaptively determines segment length based on typing speed. Second it automatically merges the partial input of multiple workers into a single transcript using a custom version of multiple-sequence alignment. Scribe illustrates the broad potential for deeply interleaving human labor and machine intelligence to provide intelligent interactive services that neither can currently achieve alone.;
"Design as learning---or knowledge creation""---the SECI model""";Models help bridge the gap between observing and making---especially when systems are involved (as in designing for interaction service and evolution). This forum introduces new models links them to existing models and describes their history and why they matter.&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbspHugh Dubberly Editor | hugh@dubberly.com;
Under New Management: Autonomic computing is revolutionizing the way we manage complex systems.;In an increasingly competitive global environment enterprises are under extreme pressure to reduce operating costs. At the same time they must have the agility to respond to business opportunities offered by volatile markets.;
Impulse Buying: Design Practices and Consumer Needs;"E-commerce sites have an incentive to encourage impulse buying even when not in the consumer's best interest. This study investigates what features e-commerce sites use to encourage impulse buying and what tools consumers desire to curb their online spending. We present two studies: (1) a systematic content analysis of 200 top e-commerce websites in the U.S. and (2) a survey of online impulse buyers (N=151). From Study 1 we find that e-commerce sites contain multiple features that encourage impulsive buying including those that lower perceived risks leverage social influence and enhance perceived proximity to the product. Conversely from Study 2 we find that online impulse buyers want tools that (a) encourage deliberation and avoidance (b) enforce spending limits and postponement (c) increase checkout effort (d) make costs more salient and (e) reduce product desire. These findings inform the design of friction'' technologies that help users make more deliberative consumer choices.""";
Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;Steve Furber designer of the seminal BBC Microcomputer System and the widely used ARM microprocessor reflects on his career.;
Pivot tracing: dynamic causal monitoring for distributed systems;Monitoring and troubleshooting distributed systems are notoriously difficult potential problems are complex varied and unpredictable. The monitoring and diagnosis tools commonly used today---logs counters and metrics---have two important limitations: what gets recorded is defined a priori and the information is recorded in a component- or machine-centric way making it extremely hard to correlate events that cross these boundaries. This paper presents Pivot Tracing a monitoring framework for distributed systems that addresses both limitations by combining dynamic instrumentation with a novel relational operator: the happened-before join. Pivot Tracing gives users at runtime the ability to define arbitrary metrics at one point of the system while being able to select filter and group by events meaningful at other parts of the system even when crossing component or machine boundaries. Pivot Tracing does not correlate cross-component events using expensive global aggregations nor does it perform offline analysis. Instead Pivot Tracing directly correlates events as they happen by piggybacking metadata alongside requests as they execute. This gives Pivot Tracing low runtime overhead---less than 1% for many cross-component monitoring queries.;
One laptop per child: vision vs. reality;The vision is being overwhelmed by the reality of business politics logistics and competing interests worldwide.;
Complying with Compliance: Blowing it off is not an option.;â€œHey compliance is boring. Really really boring. And besides I work neither in the financial industry nor in health care. Why should I care about SOX and HIPAA?â€ Yep youâ€™re absolutely right. You write payroll applications or operating systems or user interfaces or (heaven forbid) e-mail servers. Why should you worry about compliance issues?;
A comparative study of cyberattacks;Attackers base themselves in countries of convenience virtually.;
The Many Faces of Resilience;A review of network science and complexity theory as they apply to the ability of systems to resist stress and recover from faults.;
Spanner: Becoming a SQL System;Spanner is a globally-distributed data management system that backs hundreds of mission-critical services at Google. Spanner is built on ideas from both the systems and database communities. The first Spanner paper published at OSDI'12 focused on the systems aspects such as scalability automatic sharding fault tolerance consistent replication external consistency and wide-area distribution. This paper highlights the database DNA of Spanner. We describe distributed query execution in the presence of resharding query restarts upon transient failures range extraction that drives query routing and index seeks and the improved blockwise-columnar storage format. We touch upon migrating Spanner to the common SQL dialect shared with other systems at Google.;
Proceedings of the 2017 ACM International Conference on Management of Data;Smart power management is all about doing more with the resources we have.;
C is not a low-level language;Your computer is not a fast PDP-11.;
Big data and cloud computing: current state and future opportunities;Scalable database management systems (DBMS)---both for update intensive application workloads as well as decision support systems for descriptive and deep analytics---are a critical part of the cloud infrastructure and play an important role in ensuring the smooth transition of applications from the traditional enterprise infrastructures to next generation cloud infrastructures. Though scalable data management has been a vision for more than three decades and much research has focussed on large scale data management in traditional enterprise setting cloud computing brings its own set of novel challenges that must be addressed to ensure the success of data management solutions in the cloud environment. This tutorial presents an organized picture of the challenges faced by application developers and DBMS designers in developing and deploying internet scale applications. Our background study encompasses both classes of systems: (i) for supporting update heavy applications and (ii) for ad-hoc analytics and decision support. We then focus on providing an in-depth analysis of systems for supporting update intensive web-applications and provide a survey of the state-of-the-art in this domain. We crystallize the design choices made by some successful systems large scale database management systems analyze the application demands and access patterns and enumerate the desiderata for a cloud-bound DBMS.;
Proceedings of the 14th International Conference on Extending Database Technology;Optical character recognition (OCR) is one of the most popular techniques used for converting printed documents into machine-readable ones. While OCR engines can do well with modern text their performance is unfortunately significantly reduced on historical materials. Additionally many texts have already been processed by various out-of-date digitisation techniques. As a consequence digitised texts are noisy and need to be post-corrected. This article clarifies the importance of enhancing quality of OCR results by studying their effects on information retrieval and natural language processing applications. We then define the post-OCR processing problem illustrate its typical pipeline and review the state-of-the-art post-OCR processing approaches. Evaluation metrics accessible datasets language resources and useful toolkits are also reported. Furthermore the work identifies the current trend and outlines some research directions of this field.;
Technical PerspectiveThe physical side of computing;Three trends are driving the rapid growth of wireless LAN (WLAN): The increased use of laptops and personal digital assistants (PDAs) rapid advances in WLAN data rates (from 2 megabits per second to 108 Mbps in the past four years) and precipitous drops in WLAN prices (currently under $50 for a client and under $100 for an access point).;
Purpose-built languages;The ecosystem of purpose-built languages is a key part of systems development.;
HPCC: high precision congestion control;Congestion control (CC) is the key to achieving ultra-low latency high bandwidth and network stability in high-speed networks. From years of experience operating large-scale and high-speed RDMA networks we find the existing high-speed CC schemes have inherent limitations for reaching these goals. In this paper we present HPCC (High Precision Congestion Control) a new high-speed CC mechanism which achieves the three goals simultaneously. HPCC leverages in-network telemetry (INT) to obtain precise link load information and controls traffic precisely. By addressing challenges such as delayed INT information during congestion and overreac-tion to INT information HPCC can quickly converge to utilize free bandwidth while avoiding congestion and can maintain near-zero in-network queues for ultra-low latency. HPCC is also fair and easy to deploy in hardware. We implement HPCC with commodity programmable NICs and switches. In our evaluation compared to DCQCN and TIMELY HPCC shortens flow completion times by up to 95% causing little congestion even under large-scale incasts.;
Proceedings of the ACM Special Interest Group on Data Communication;Reflecting on the career and contributions of the Apple cofounder.;
Garbage Collection as a Joint Venture: A collaborative approach to reclaiming memory in heterogeneous software systems;Cross-component tracing is a way to solve the problem of reference cycles across component boundaries. This problem appears as soon as components can form arbitrary object graphs with nontrivial ownership across API boundaries. An incremental version of CCT is implemented in V8 and Blink enabling effective and efficient reclamation of memory in a safe manner.;
Putting It All Together: Component integration is one of the tough challenges in embedded system design. Designers search for conservative design styles and reliable techniques for interfacing and verification.;With the growing complexity of embedded systems more and more parts of a system are reused or supplied often from external sources. These parts range from single hardware components or software processes to hardware-software (HW-SW) subsystems. They must cooperate and share resources with newly developed parts such that all of the design constraints are met. This simply speaking is the integration task which ideally should be a plug-and-play procedure. This does not happen in practice however not only because of incompatible interfaces and communication standards but also because of specialization.;
Software as a service for data scientists;Globus Online manages fire-and-forget file transfers for big-data high-performance scientific collaborations.;
Machine Learning Systems are Stuck in a Rut;In this paper we argue that systems for numerical computing are stuck in a local basin of performance and programmability. Systems researchers are doing an excellent job improving the performance of 5-year-old benchmarks but gradually making it harder to explore innovative machine learning research ideas.We explain how the evolution of hardware accelerators favors compiler back ends that hyper-optimize large monolithic kernels show how this reliance on high-performance but inflexible kernels reinforces the dominant style of programming model and argue these programming abstractions lack expressiveness maintainability and modularity all of which hinders research progress.We conclude by noting promising directions in the field and advocate steps to advance progress towards high-performance general purpose numerical computing systems on modern accelerators.;
Proceedings of the Workshop on Hot Topics in Operating Systems;Autopilot systems are typically composed of an â€œinner loopâ€ providing stability and control whereas an â€œouter loopâ€ is responsible for mission-level objectives such as way-point navigation. Autopilot systems for unmanned aerial vehicles are predominately implemented using Proportional-Integral-Derivative&nbsp(PID) control systems which have demonstrated exceptional performance in stable environments. However more sophisticated control is required to operate in unpredictable and harsh environments. Intelligent flight control systems is an active area of research addressing limitations of PID control most recently through the use of reinforcement learning&nbsp(RL) which has had success in other applications such as robotics. Yet previous work has focused primarily on using RL at the mission-level controller. In this work we investigate the performance and accuracy of the inner control loop providing attitude control when using intelligent flight control systems trained with state-of-the-art RL algorithmsâ€”Deep Deterministic Policy Gradient Trust Region Policy Optimization and Proximal Policy Optimization. To investigate these unknowns we first developed an open source high-fidelity simulation environment to train a flight controller attitude control of a quadrotor through RL. We then used our environment to compare their performance to that of a PID controller to identify if using RL is appropriate in high-precision time-critical flight control.;
Research for practice: the DevOps phenomenon;An executive crash course.;
Workload Frequency Scaling Law - Derivation and Verification: Workload scalability has a cascade relation via the scale factor.;This article presents equations that relate to workload utilization scaling at a per-DVFS subsystem level. A relation between frequency utilization and scale factor (which itself varies with frequency) is established. The verification of these equations turns out to be tricky since inherent to workload the utilization also varies seemingly in an unspecified manner at the granularity of governance samples. Thus a novel approach called histogram ridge trace is applied. Quantifying the scaling impact is critical when treating DVFS as a building block. Typical application includes DVFS governors and or other layers that influence utilization power and performance of the system. The scope here though is limited to demonstrating well-quantified and verified scaling equations.;
Deconstructing the bakery to build a distributed state machine;A rigorous journey from the bakery algorithm to a distributed state machine.;
DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning;Machine-Learning tasks are becoming pervasive in a broad range of domains and in a broad range of systems (from embedded systems to data centers). At the same time a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks i.e. CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve towards heterogeneous multi-cores composed of a mix of cores and accelerators a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope.Until now most machine-learning accelerator designs have focused on efficiently implementing the computational part of the algorithms. However recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study we design an accelerator for large-scale CNNs and DNNs with a special emphasis on the impact of memory on accelerator design performance and energy.We show that it is possible to design an accelerator with a high throughput capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm2 and 485 mW compared to a 128-bit 2GHz SIMD processor the accelerator is 117.87x faster and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65 nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications.;
Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems;Although large language models (LLMs) have demonstrated impressive potential on simple tasks their breadth of scope lack of transparency and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response we introduce the concept of Chaining LLM steps together where the output of one step becomes the input for the next thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction then present an interactive system where users can modify these Chains along with their intermediate results in a modular way. In a 20-person user study we found that Chaining not only improved the quality of task outcomes but also significantly enhanced system transparency controllability and sense of collaboration. Additionally we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations compared and contrasted alternative strategies by observing parallel downstream effects and debugged unexpected model outputs by â€œunit-testingâ€ sub-components of a Chain. In two case studies we further explore how LLM Chains may be used in future applications.;
Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems;Concept drift primarily refers to an online supervised learning scenario when the relation between the input data and the target variable changes over time. Assuming a general knowledge of supervised learning in this article we characterize adaptive learning processes categorize existing strategies for handling concept drift overview the most representative distinct and popular techniques and algorithms discuss evaluation methodology of adaptive algorithms and present a set of illustrative applications. The survey covers the different facets of concept drift in an integrated way to reflect on the existing scattered state of the art. Thus it aims at providing a comprehensive introduction to the concept drift adaptation for researchers industry analysts and practitioners.;
Algorithmic game theory;A new era of theoretical computer science addresses fundamental problems about auctions networks and human behavior.;
Research for practice: edge computing;Scaling resources within multiple administrative domains.;
Exploiting the analog properties of digital circuits for malicious hardware;While the move to smaller transistors has been a boon for performance it has dramatically increased the cost to fabricate chips using those smaller transistors. This forces the vast majority of chip design companies to trust a third party---often overseas---to fabricate their design. To guard against shipping chips with errors (intentional or otherwise) chip design companies rely on post-fabrication testing. Unfortunately this type of testing leaves the door open to malicious modifications since attackers can craft attack triggers requiring a sequence of unlikely events which will never be encountered by even the most diligent tester. In this paper we show how a fabrication-time attacker can leverage analog circuits to create a hardware attack that is small (i.e. requires as little as one gate) and stealthy (i.e. requires an unlikely trigger sequence before affecting a chip's functionality). In the open spaces of an already placed and routed design we construct a circuit that uses capacitors to siphon charge from nearby wires as they transit between digital values. When the capacitors are fully charged they deploy an attack that forces a victim flip-flop to a desired value. We weaponize this attack into a remotely controllable privilege escalation by attaching the capacitor to a controllable wire and by selecting a victim flip-flop that holds the privilege bit for our processor. We implement this attack in an OR1200 processor and fabricate a chip. Experimental results show that the purposed attack works. It eludes activation by a diverse set of benchmarks and evades known defenses.;
Powering Down: Smart power management is all about doing more with the resources we have.;Power management is a topic of interest to everyone. In the beginning there was the desktop computer. It ran at a fixed speed and consumed less power than the monitor it was plugged into. Where computers were portable their sheer size and weight meant that you were more likely to be limited by physical strength than battery life. It was not a great time for power management. Now consider the present. Laptops have increased in speed by more than 5000 times. Battery capacity sadly has not. With hardware becoming increasingly mobile however users are demanding that battery life start matching the way they work. People want to work from cafes. Long-haul flights are now perceived as the ideal opportunity to finish a presentation. Two hours of battery life just isnâ€™t going to cut it users are looking for upwards of eight hours. Whatâ€™s drawing that power and more importantly how can we manage it better?;
Diversity in smartphone usage;Using detailed traces from 255 users we conduct a comprehensive study of smartphone use. We characterize intentional user activities -- interactions with the device and the applications used -- and the impact of those activities on network and energy usage. We find immense diversity among users. Along all aspects that we study users differ by one or more orders of magnitude. For instance the average number of interactions per day varies from 10 to 200 and the average amount of data received per day varies from 1 to 1000 MB. This level of diversity suggests that mechanisms to improve user experience or energy consumption will be more effective if they learn and adapt to user behavior. We find that qualitative similarities exist among users that facilitate the task of learning user behavior. For instance the relative application popularity for can be modeled using an exponential distribution with different distribution parameters for different users. We demonstrate the value of adapting to user behavior in the context of a mechanism to predict future energy drain. The 90th percentile error with adaptation is less than half compared to predictions based on average behavior across users.;
Proceedings of the 8th International Conference on Mobile Systems Applications and Services;HACs offer a new science for exploring the computational and human aspects of society.;
Why data citation is a computational problem;Using database views to define citable units is the key to specifying and generating citations to data.;
Meltdown: reading kernel memory from user space;Lessons learned from Meltdown's exploitation of the weaknesses in today's processors.;
Citus: Distributed PostgreSQL for Data-Intensive Applications;Citus is an open source distributed database engine for PostgreSQL that is implemented as an extension. Citus gives users the ability to distribute data queries and transactions in PostgreSQL across a cluster of PostgreSQL servers to handle the needs of data-intensive applications. The development of Citus has largely been driven by conversations with companies looking to scale PostgreSQL beyond a single server and their workload requirements. This paper describes the requirements of four common workload patterns and how Citus addresses those requirements. It also shares benchmark results demonstrating the performance and scalability of Citus in each of the workload patterns and describes how Microsoft uses Citus to address one of its most challenging data problems.;
Proceedings of the 2021 International Conference on Management of Data;The challenges---and great promise---of modern symbolic execution techniques and the tools to help implement them.;
GPU ray tracing;The NVIDIAÂ® OptiXâ„¢ ray tracing engine is a programmable system designed for NVIDIA GPUs and other highly parallel architectures. The OptiX engine builds on the key observation that most ray tracing algorithms can be implemented using a small set of programmable operations. Consequently the core of OptiX is a domain-specific just-in-time compiler that generates custom ray tracing kernels by combining user-supplied programs for ray generation material shading object intersection and scene traversal. This enables the implementation of a highly diverse set of ray tracing-based algorithms and applications including interactive rendering offline rendering collision detection systems artificial intelligence queries and scientific simulations such as sound propagation. OptiX achieves high performance through a compact object model and application of several ray tracing-specific compiler optimizations. For ease of use it exposes a single-ray programming model with full support for recursion and a dynamic dispatch mechanism similar to virtual function calls.;
User Perceptions of Smart Home IoT Privacy;Smart home Internet of Things (IoT) devices are rapidly increasing in popularity with more households including Internet-connected devices that continuously monitor user activities. In this study we conduct eleven semi-structured interviews with smart home owners investigating their reasons for purchasing IoT devices perceptions of smart home privacy risks and actions taken to protect their privacy from those external to the home who create manage track or regulate IoT devices and/or their data. We note several recurring themes. First users' desires for convenience and connectedness dictate their privacy-related behaviors for dealing with external entities such as device manufacturers Internet Service Providers governments and advertisers. Second user opinions about external entities collecting smart home data depend on perceived benefit from these entities. Third users trust IoT device manufacturers to protect their privacy but do not verify that these protections are in place. Fourth users are unaware of privacy risks from inference algorithms operating on data from non-audio/visual devices. These findings motivate several recommendations for device designers researchers and industry standards to better match device privacy features to the expectations and preferences of smart home owners.;
Measuring security practices;"Users are encouraged to adopt a wide array of technologies and behaviors to reduce their security risk. However the adoption of these best practices"" ranging from the use of antivirus products to keeping software updated is not well understood nor is their practical impact on security risk well established. To explore these issues we conducted a large-scale measurement of 15000 computers over six months. We use passive monitoring to infer and characterize the prevalence of various security practices as well as a range of other potentially security-relevant behaviors. We then explore the extent to which differences in key security behaviors impact the real-world outcomes (i.e. that a device shows clear evidence of having been compromised).""";
Robust Anomaly Detection for Multivariate Time Series through Stochastic Recurrent Neural Network;Industry devices (i.e. entities) such as server machines spacecrafts engines etc. are typically monitored with multivariate time series whose anomaly detection is critical for an entity's service quality management. However due to the complex temporal dependence and stochasticity of multivariate time series their anomaly detection remains a big challenge. This paper proposes OmniAnomaly a stochastic recurrent neural network for multivariate time series anomaly detection that works well robustly for various devices. Its core idea is to capture the normal patterns of multivariate time series by learning their robust representations with key techniques such as stochastic variable connection and planar normalizing flow reconstruct input data by the representations and use the reconstruction probabilities to determine anomalies. Moreover for a detected entity anomaly OmniAnomaly can provide interpretations based on the reconstruction probabilities of its constituent univariate time series. The evaluation experiments are conducted on two public datasets from aerospace and a new server machine dataset (collected and released by us) from an Internet company. OmniAnomaly achieves an overall F1-Score of 0.86 in three real-world datasets signicantly outperforming the best performing baseline method by 0.09. The interpretation accuracy for OmniAnomaly is up to 0.89.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Using real event data to X-ray business processes helps ensure conformance between design and reality.;
When software engineering meets quantum computing;The Session Initiation Protocol (SIP) is used to set up realtime sessions in IP-based networks. These sessions might be for audio video or IM communications or they might be used to relay presence information. SIP service providers are mainly focused on providing a service that copies that provided by the PSTN (public switched telephone network) or the PLMN (public land mobile network) to the Internet-based environment.;
Better Faster More Secure: Whoâ€™s in charge of the Internetâ€™s future?;Since I started a stint as chair of the IETF in March 2005 I have frequently been asked â€œWhatâ€™s coming next?â€ but I have usually declined to answer. Nobody is in charge of the Internet which is a good thing but it makes predictions difficult. The reason the lack of central control is a good thing is that it has allowed the Internet to be a laboratory for innovation throughout its lifeâ€”and itâ€™s a rare thing for a major operational system to serve as its own development lab. As the old metaphor goes we frequently change some of the Internetâ€™s engines in flight.;
What do agile lean and ITIL mean to DevOps?;The value of learning skillsets within a trio of disciplines and the role each plays in DevOps.;
Toward systematic architectural design of near-term trapped ion quantum computers;Trapped ions (TIs) are a leading candidate for building Noisy Intermediate-Scale Quantum (NISQ) hardware. TI qubits have fundamental advantages over other technologies featuring high qubit quality coherence time and qubit connectivity. However current TI systems are small in size and typically use a single trap architecture which has fundamental scalability limitations. To progress toward the next major milestone of 50--100 qubit TI devices a modular architecture termed the Quantum Charge Coupled Device (QCCD) has been proposed. In a QCCD-based TI device small traps are connected through ion shuttling. While the basic hardware components for such devices have been demonstrated building a 50--100 qubit system is challenging because of a wide range of design possibilities for trap sizing communication topology and gate implementations and the need to match diverse application resource requirements.Toward realizing QCCD-based TI systems with 50--100 qubits we perform an extensive application-driven architectural study evaluating the key design choices of trap sizing communication topology and operation implementation methods. To enable our study we built a design toolflow which takes a QCCD architecture's parameters as input along with a set of applications and realistic hardware performance models. Our toolflow maps the applications onto the target device and simulates their execution to compute metrics such as application run time reliability and device noise rates. Using six applications and several hardware design points we show that trap sizing and communication topology choices can impact application reliability by up to three orders of magnitude. Microarchitectural gate implementation choices influence reliability by another order of magnitude. From these studies we provide concrete recommendations to tune these choices to achieve highly reliable and performant application executions. With industry and academic efforts underway to build TI devices with 50-100 qubits our insights have the potential to influence QC hardware in the near future and accelerate the progress toward practical QC systems.;
Privacy-preserving data publishing: A survey of recent developments;The collection of digital information by governments corporations and individuals has created tremendous opportunities for knowledge- and information-based decision making. Driven by mutual benefits or by regulations that require certain data to be published there is a demand for the exchange and publication of data among various parties. Data in its original form however typically contains sensitive information about individuals and publishing such data will violate individual privacy. The current practice in data publishing relies mainly on policies and guidelines as to what types of data can be published and on agreements on the use of published data. This approach alone may lead to excessive data distortion or insufficient protection. Privacy-preserving data publishing (PPDP) provides methods and tools for publishing useful information while preserving data privacy. Recently PPDP has received considerable attention in research communities and many approaches have been proposed for different data publishing scenarios. In this survey we will systematically summarize and evaluate different approaches to PPDP study the challenges in practical data publishing clarify the differences and requirements that distinguish PPDP from other related problems and propose future research directions.;
Making Smart Contracts Smarter;Cryptocurrencies record transactions in a decentralized data structure called a blockchain. Two of the most popular cryptocurrencies Bitcoin and Ethereum support the feature to encode rules or scripts for processing transactions. This feature has evolved to give practical shape to the ideas of smart contracts or full-fledged programs that are run on blockchains. Recently Ethereum's smart contract system has seen steady adoption supporting tens of thousands of contracts holding millions dollars worth of virtual coins.In this paper we investigate the security of running smart contracts based on Ethereum in an open distributed network like those of cryptocurrencies. We introduce several new security problems in which an adversary can manipulate smart contract execution to gain profit. These bugs suggest subtle gaps in the understanding of the distributed semantics of the underlying platform. As a refinement we propose ways to enhance the operational semantics of Ethereum to make contracts less vulnerable. For developers writing contracts for the existing Ethereum system we build a symbolic execution tool called Oyente to find potential security bugs. Among 19 336 existing Ethereum contracts Oyente flags 8 833 of them as vulnerable including the TheDAO bug which led to a 60 million US dollar loss in June 2016. We also discuss the severity of other attacks for several case studies which have source code available and confirm the attacks (which target only our accounts) in the main Ethereum network.;
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;We present the design implementation and evaluation of B4 a private WAN connecting Google's data centers across the planet. B4 has a number of unique characteristics: i) massive bandwidth requirements deployed to a modest number of sites ii) elastic traffic demand that seeks to maximize average bandwidth and iii) full control over the edge servers and network which enables rate limiting and demand measurement at the edge.These characteristics led to a Software Defined Networking architecture using OpenFlow to control relatively simple switches built from merchant silicon. B4's centralized traffic engineering service drives links to near 100% utilization while splitting application flows among multiple paths to balance capacity against application priority/demands. We describe experience with three years of B4 production deployment lessons learned and areas for future work.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;Static-analysis tools suffer from usability issues such as a high rate of false positives lack of responsiveness and unclear warning descriptions and classifications. Here we explore the effect of applying user-centered approach and design guidelines to SWAN a security-focused static-analysis tool for the Swift programming language. SWAN is an interesting case study for exploring static-analysis tool usability because of its large target audience its potential to integrate easily into developers' workflows and its independence from existing analysis platforms.;
Cassandra: a decentralized structured storage system;Cassandra is a distributed storage system for managing very large amounts of structured data spread out across many commodity servers while providing highly available service with no single point of failure. Cassandra aims to run on top of an infrastructure of hundreds of nodes (possibly spread across different data centers). At this scale small and large components fail continuously. The way Cassandra manages the persistent state in the face of these failures drives the reliability and scalability of the software systems relying on this service. While in many ways Cassandra resembles a database and shares many design and implementation strategies therewith Cassandra does not support a full relational data model instead it provides clients with a simple data model that supports dynamic control over data layout and format. Cassandra system was designed to run on cheap commodity hardware and handle high write throughput while not sacrificing read efficiency.;
dEFEND: Explainable Fake News Detection;In recent years to mitigate the problem of fake news computational detection of fake news has been studied producing some promising early results. While important however we argue that a critical missing piece of the study be the explainability of such detection i.e. why a particular piece of news is detected as fake. In this paper therefore we study the explainable detection of fake news. We develop a sentence-comment co-attention sub-network to exploit both news contents and user comments to jointly capture explainable top-k check-worthy sentences and user comments for fake news detection. We conduct extensive experiments on real-world datasets and demonstrate that the proposed method not only significantly outperforms 7 state-of-the-art fake news detection methods by at least 5.33% in F1-score but also (concurrently) identifies top-k user comments that explain why a news piece is fake better than baselines by 28.2% in NDCG and 30.7% in Precision.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Delphi study sets out to identify essential cognitive interpersonal and intrapersonal competencies needed for success in data analytics.;
Computer security and the modern home;A framework for evaluating security risks associated with technologies used at home.;
Computer and information science and engineering: one discipline many specialties;Mathematics is no longer the only foundation for computing and information research and education in academia.;
Tear Down the Method Prisons! Set Free the Practices! Essence: a new way of thinking that promises to liberate the practices and enable true learning organizations;This article explains why we need to break out of this repetitive dysfunctional behavior and it introduces Essence a new way of thinking that promises to free the practices from their method prisons and thus enable true learning organizations.;
The Insider Naivety and Hostility: Security Perfect Storm? Keeping nasties out if only half the battle.;Every year corporations and government installations spend millions of dollars fortifying their network infrastructures. Firewalls intrusion detection systems and antivirus products stand guard at network boundaries and individuals monitor countless logs and sensors for even the subtlest hints of network penetration. Vendors and IT managers have focused on keeping the wily hacker outside the network perimeter but very few technological measures exist to guard against insiders - those entities that operate inside the fortified network boundary. The 2002 CSI/FBI survey estimates that 70 percent of successful attacks come from the inside. Several other estimates place those numbers even higher.;
A Review on Outlier/Anomaly Detection in Time Series Data;Recent advances in technology have brought major breakthroughs in data collection enabling a large amount of data to be gathered over time and thus generating time series. Mining this data has become an important task for researchers and practitioners in the past few years including the detection of outliers or anomalies that may represent errors or events of interest. This review aims to provide a structured and comprehensive state-of-the-art on unsupervised outlier detection techniques in the context of time series. To this end a taxonomy is presented based on the main aspects that characterize an outlier detection technique.;
AuraRing: precise electromagnetic finger tracking;Wearable computing platforms such as smartwatches and head-mounted mixed reality displays demand new input devices for high-fidelity interaction. We present AuraRing a wearable magnetic tracking system designed for tracking fine-grained finger movement. The hardware consists of a ring with an embedded electromagnetic transmitter coil and a wristband with multiple sensor coils. By measuring the magnetic fields at different points around the wrist AuraRing estimates the five degree-of-freedom pose of the ring. AuraRing is trained only on simulated data and requires no runtime supervised training ensuring user and session independence. It has a dynamic accuracy of 4.4 mm as measured through a user evaluation with optical ground truth. The ring is completely self-contained and consumes just 2.3 mW of power.;
Mindsets Matter: How Beliefs About Facebook Moderate the Association Between Time Spent and Well-Being;â€œTime spent on platformâ€ is a widely used measure in many studies examining social media use and well-being yet the current literature presents unresolved findings about the relationship between time on platform and well-being. In this paper we consider the moderating effect of peopleâ€™s mindsets about social media â€” whether they think a platform is good or bad for themselves and for society more generally. Combining survey responses from 29284 participants in 15 countries with server-logged data of Facebook use we found that when people thought that Facebook was good for them and for society time spent on the platform was not significantly associated with well-being. Conversely when they thought Facebook was bad greater time spent was associated with lower well-being. On average there was a small negative correlation between time spent and well-being and the causal direction is not known. Beliefs had a stronger moderating relationship when time-spent measures were self-reported rather than coming from server logs. We discuss potential mechanisms for these results and implications for future research on well-being and social media use.;
Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems;Newer phones use security features in many different ways and combinations. As with any security technology however using a feature incorrectly can create a false sense of security. As such many app developers and service providers today do not use any of the secure identity-management facilities that modern phones offer. For those of you who fall into this camp this article is meant to leave you with ideas about how to bring a hardware-backed and biometrics-based concept of user identity into your ecosystem.;
Six reasons why virtual reality is a game-changing computing and communication platform for organizations;Beyond the pandemic organizations need to recognize what digital assets interactions and communication processes reap the most benefits from virtual reality.;
Order from Chaos: Will ontologies help you structure your semi-structured data?;There is probably little argument that the past decade has brought the â€œbig bangâ€ in the amount of online information available for processing by humans and machines. Two of the trends that it spurred (among many others) are: first there has been a move to more flexible and fluid (semi-structured) models than the traditional centralized relational databases that stored most of the electronic data before second today there is simply too much information available to be processed by humans and we really need help from machines. On todayâ€™s Web however most of the information is still for human consumption in one way or another.;
Are the costs of 'free' too high in online education?;Considering the economic implications as educational institutions expand online learning initiatives.;
Success factors for deploying cloud computing;Trust between client organization and cloud provider is a strong predictor of successful cloud deployment.;
Ry\={u;We present Ry\={u;
Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation;A positive image would inspire the capable but underrepresented who might otherwise give up on computing.;
Is there a single method for the internet of things?;Essence can keep software development for the IoT from becoming unwieldy.;
Toward robotic cars;This article advocates self-driving robotic technology for cars. Recent challenges organized by DARPA have induced a significant advance in technology for autopilots for cars similar to those already used in aircraft and marine vessels. This article reviews this technology and argues that enormous societal benefits can be reaped by deploying this emerging technology in the marketplace. It lays out a vision for deployment and discusses some of the key remaining technology obstacles.;
Securing the tangled web;Preventing script injection vulnerabilities through software design.;
Distributed strategies for computational sprints;Computational sprinting is a class of mechanisms that boost performance but dissipate additional power. We describe a sprinting architecture in which many independent chip multiprocessors share a power supply and sprints are constrained by the chips' thermal limits and the rack's power limits. Moreover we present the computational sprinting game a multi-agent perspective on managing sprints. Strategic agents decide whether to sprint based on application phases and system conditions. The game produces an equilibrium that improves task throughput for data analytics workloads by 4--6x over prior greedy heuristics and performs within 90% of an upper bound on throughput from a globally optimized policy.;
Illuminati: the game of conspiracy: a close reading;Illuminati is a humorous game of conspiracy and political intrigue. Designed by Steve Jackson in 1981 it has proven to be enduringly popular through many years of revision and republication. In this paper we examine its latest incarnation Deluxe Illuminati and closely analyse its operation in terms of the MDA framework of Hunicke LeBlanc and Zubek [8]. Five general-purpose game-dynamic patterns are discovered that might serve in the understanding and design of other games.;
Proceedings of the Sixth Australasian Conference on Interactive Entertainment;To become an industry platform vendors must open their infrastructure technology to other product companies.;
The Scalability Problem: The coexistence of high-end systems and value PCs can make life hell for game developers.;Back in the mid-1990s I worked for a company that developed multimedia kiosk demos. Our biggest client was Intel and we often created demos that appeared in new PCs on the end-caps of major computer retailers such as CompUSA. At that time performance was in demand for all application classes from business to consumer. We created demos that showed for example how much faster a spreadsheet would recalculate (you had to do that manually back then) on a new processor as compared with the previous yearâ€™s processor. The differences were immediately noticeable to even a casual observer - and it mattered. Having to wait only 10 seconds for something that previously took 20 or more was a major improvement and led many consumers and businesses to upgrade their PCs.;
Optimizations in C++ compilers;A practical journey.;
Security is Harder than You Think: Itâ€™s not just about the buffer overflow.;"Many developers see buffer overflows as the biggest security threat to software and believe that there is a simple two-step process to secure software: switch from C or C++ to Java then start using SSL (Secure Sockets Layer) to protect data communications. It turns out that this na\{\i""";
An Energy-Efficient PUF Design: Computing While Racing;Physical unclonable functions (PUFs) take advantage of the effect of process variation on hardware to obtain their unclonability. Traditional PUF design only focuses on the analog signals of circuits. An arbiter PUF for example generates responses by racing delay signals. Implementations of such PUFs usually employ large area and power consumption while providing very low throughput.To address this problem we propose an energy efficient PUF design in such a way that it races analog signals and computes digital logic simultaneously. More importantly the analog portion of the circuit (racing) shares a large amount of hardware resources with the digital portion of the circuit (computing) by introducing only small overhead in terms of area and power. Our test results on Spartan-6 field-programmable gate array (FPGA) platforms indicate that by combining the two outputs our design enables much larger PUF output throughput better randomness and less power consumption compared to traditional PUFs.;
Proceedings of the 2016 International Symposium on Low Power Electronics and Design;Overcoming the inherent challenges.;
"Constructing Authenticity on TikTok: Social Norms and Social Support on the Fun"" Platform""";"Authenticity generally regarded as coherence between one's inner self and outward behavior is associated with myriad social values (e.g. integrity) and beneficial outcomes such as psychological well-being. Scholarship suggests however that behaving authentically online is complicated by self-presentation norms that make it difficult to present a complex self as well as encourage sharing positive emotions and facets of self and discourage sharing difficult emotions. In this paper we position authenticity as a self-presentation norm and identify the sociomaterial factors that contribute to the learning enactment and enforcement of authenticity on the short-video sharing platform TikTok. We draw on interviews with 15 U.S. TikTok users to argue that normative authenticity and understanding of TikTok as a fun"" platform are mutually constitutive in supporting a ""just be you"" attitude on TikTok that in turn normalizes expressions of both positive and difficult emotions and experiences. We consider the social context of TikTok and use an affordance lens to identify anonymity of oneself and one's audience association between content and the ""For You"" landing page and video modality of TikTok as factors informing authenticity as a self-presentation norm. We argue that these factors similarly contribute to TikTok's viability as a space for social support exchange and address the utility of the comments section as a site for both supportive communication and norm judgment and enforcement. We conclude by considering the limitations of authenticity as social norm and present implications for designing online spaces for social support and connection.""";
Realizing the potential of data science;Data science promises new insights helping transform information into knowledge that can drive science and industry.;
User experience evaluation methods: current state and development needs;The recent shift of emphasis to user experience (UX) has rendered it a central focus of product design and evaluation. A multitude of methods for UX design and evaluation exist but a clear overview of the current state of the available UX evaluation methods is missing. This is partly due to a lack of agreement on the essential characteristics of UX. In this paper we present the results of our multi-year effort of collecting UX evaluation methods from academia and industry with different approaches such as literature review workshops Special Interest Groups sessions and an online survey. We have collected 96 methods and analyzed them among other criteria based on the product development phase and the studied period of experience. Our analysis reveals development needs for UX evaluation methods such as early-stage methods methods for social and collaborative UX evaluation establishing practicability and scientific quality and a deeper understanding of UX.;
Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries;Let's bring friction back into computing.;
An interview with Ed Feigenbaum;ACM Fellow and A.M. Turing Award recipient Edward A. Feigenbaum a pioneer in the field of expert systems reflects on his career.;
Nine IM Accounts and Counting: The key word with instant messaging today is interoperability.;Instant messaging has become nearly as ubiquitous as e-mail in some cases far surpassing e-mail in popularity. But it has gone far beyond teenagersâ€™ insular world to business where it is becoming a useful communication tool. The problem unlike e-mail is that no common standard exists for IM so users feel compelled to maintain multiple accounts for example AOL Jabber Yahoo and MSN.;
The origins of Objective-C at PPI/Stepstone and its evolution at NeXT;"The roots of Objective-C began at ITT in the early 1980s in a research group led by Tom Love investigating improving programmer productivity by an order of magnitude a concern motivated by the perceived software crisis"" articulated in the late 1960s. In 1981 Brad Cox a member of this group began to investigate Smalltalk and object-oriented programming for this purpose but needed a language compatible with the Unix and C environments used by ITT. That year Cox quickly wrote up the Object-Oriented Pre-Compiler (OOPC) that would translate a Smalltalk-like syntax into C.  Love felt there was a market for object-oriented solutions that could coexist with legacy languages and platforms and after a brief stint at Schlumberger-Doll co-founded with Cox Productivity Products International (PPI) later renamed as Stepstone to pursue this. At PPI Cox developed OOPC into Objective-C. Cox saw Objective-C as a crucial link in his larger vision of creating a market for ""pre-fabricated"" software components (""software-ICs"") which could be bought off the shelf and which Cox believed would unleash a ""software industrial revolution.""  Steve Naroff joined Stepstone in 1986 as Steve Jobs' NeXT Computer became an important customer for Objective-C as it was being used in its NeXTSTEP operating system. Naroff became the primary Stepstone developer addressing NeXT's issues with Objective-C solving a key fragility problem preventing NeXT from deploying forwards-compatible object libraries. Impressed with NeXT Naroff left Stepstone for NeXT in 1988 and once there added Objective-C support to Richard Stallman's GNU GCC compiler which NeXT was using as its C compiler removing the need to use Stepstone's ObjC to C translator. Over the next several years Naroff and others would add significant new features to Objective-C such as ""categories"" ""protocols"" and the ability to mix in C++ code. When Stepstone folded in 1994 all rights to Objective-C were acquired by NeXT. This eventually transferred to Apple when NeXT was acquired by Apple in 1997. Objective-C became the basis for Apple's Mac OS X and then iOS platforms and Naroff and others at Apple added additional features to the language in the late 2000s as the iPhone App Store greatly expanded Objective-C's user base.""";
Bridging the Gap Between Ethics and Practice: Guidelines for Reliable Safe and Trustworthy Human-centered AI Systems;This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures I propose 15 recommendations at three levels of governance: team organization and industry. The recommendations are intended to increase the reliability safety and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices (2) safety culture through business management strategies and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures software engineering workflows verification and validation testing bias testing to enhance fairness and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety hiring and training oriented to safety extensive reporting of failures and near misses internal review boards for problems and future plans and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation accounting firms conducting external audits insurance companies compensating for failures non-governmental and civil society organizations advancing design principles and professional organizations and research institutes developing standards policies and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals organizations and society.;
Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models;Large deep learning models have shown great potential with state-of-the-art results in many tasks. However running these large models is quite challenging on an accelerator (GPU or TPU) because the on-device memory is too limited for the size of these models. Intra-layer model parallelism is an approach to address the issues by partitioning individual layers or operators across multiple devices in a distributed accelerator cluster. But the data communications generated by intra-layer model parallelism can contribute to a significant proportion of the overall execution time and severely hurt the computational efficiency. As intra-layer model parallelism is critical to enable large deep learning models this paper proposes a novel technique to effectively reduce its data communication overheads by overlapping communication with computation. With the proposed technique an identified original communication collective is decomposed along with the dependent computation operation into a sequence of finer-grained operations. By creating more overlapping opportunities and executing the newly created finer-grained communication and computation operations in parallel it effectively hides the data transfer latency and achieves a better system utilization. Evaluated on TPU v4 Pods using different types of large models that have 10 billion to 1 trillion parameters the proposed technique improves system throughput by 1.14 - 1.38x. The achieved highest peak FLOPS utilization is 72% on 1024 TPU chips with a large language model that has 500 billion parameters.;
Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems Volume 1;Large language models (LMs) of code have recently shown tremendous promise in completing code and synthesizing code from natural language descriptions. However the current state-of-the-art code LMs (e.g. Codex) are not publicly available leaving many questions about their model and data design decisions. We aim to fill in some of these blanks through a systematic evaluation of the largest existing models: Codex GPT-J GPT-Neo GPT-NeoX-20B and CodeParrot across various programming languages. Although Codex itself is not open-source we find that existing opensource models do achieve close results in some programming languages although targeted mainly for natural language  modeling. We further identify an important missing piece in the form of a large open-source model trained exclusively on a multi-lingual corpus of code. We release a new model PolyCoder with 2.7B parameters based on the GPT-2 architecture that was trained on 249GB of code across 12 programming  languages on a single machine. In the C programming language PolyCoder outperforms all models including Codex. Our trained models are open-source and publicly available at https://github.com/VHellendoorn/Code-LMs which enables future research and application in this area.  We have an online appendix at https://arxiv.org/abs/2202.13169.;
Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming;We present a neural model for representing snippets of code as continuous distributed vectors (``code embeddings''). The main idea is to represent a code snippet as a single fixed-length code vector which can be used to predict semantic properties of the snippet. To this end code is first decomposed to a collection of paths in its abstract syntax tree. Then the network learns the atomic representation of each path while simultaneously learning how to aggregate a set of them.  We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 12M methods. We show that code vectors trained on this dataset can predict method names from files that were unobserved during training. Furthermore we show that our model learns useful method name vectors that capture semantic similarities combinations and analogies.  A comparison of our approach to previous techniques over the same dataset shows an improvement of more than 75% making it the first to successfully predict method names based on a large cross-project corpus. Our trained model visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code data and trained models are available at https://github.com/tech-srl/code2vec.;
A Time and a Place for Standards: History shows how abuses of the standards process have impeded progress.;Over the next decade we will encounter at least three major opportunities where success will hinge largely on our ability to define appropriate standards. Thatâ€™s because intelligently crafted standards that surface at just the right time can do much to nurture nascent industries and encourage product development simply by creating a trusted and reliable basis for interoperability. From where I stand the three specific areas I see as particularly promising are: (1) all telecommunications and computing capabilities that work together to facilitate collaborative work (2) hybrid computing/home entertainment products providing for the online distribution of audio and/or video content and (3) wireless sensor and network platforms (the sort that some hope the 802.15.4 and ZigBee Alliance standards will ultimately enable). No doubt there will be others but for the purposes of this discussion these should suffice.;
Reflections on Stanford's MOOCs;New possibilities in online education create new challenges.;
Robots Enact Malignant Stereotypes;Stereotypes bias and discrimination have been extensively documented in Machine Learning (ML) methods such as Computer Vision (CV)&nbsp[18 80] Natural Language Processing (NLP)&nbsp[6] or both in the case of large image and caption models such as OpenAI CLIP&nbsp[14]. In this paper we evaluate how ML bias manifests in robots that physically and autonomously act within the world. We audit one of several recently published CLIP-powered robotic manipulation methods presenting it with objects that have pictures of human faces on the surface which vary across race and gender alongside task descriptions that contain terms associated with common stereotypes. Our experiments definitively show robots acting out toxic stereotypes with respect to gender race and scientifically-discredited physiognomy at scale. Furthermore the audited methods are less likely to recognize Women and People of Color. Our interdisciplinary sociotechnical analysis synthesizes across fields and applications such as Science Technology and Society (STS) Critical Studies History Safety Robotics and AI. We find that robots powered by large datasets and Dissolution Models (sometimes called â€œfoundation modelsâ€ e.g. CLIP) that contain humans risk physically amplifying malignant stereotypes in general and that merely correcting disparities will be insufficient for the complexity and scale of the problem. Instead we recommend that robot learning methods that physically manifest stereotypes or other harmful outcomes be paused reworked or even wound down when appropriate until outcomes can be proven safe effective and just. Finally we discuss comprehensive policy changes and the potential of new interdisciplinary research on topics like Identity Safety Assessment Frameworks and Design Justice to better understand and address these harms.;
Proceedings of the 2022 ACM Conference on Fairness Accountability and Transparency;"The Internet of Everything (IoE) is more than a $19 trillion opportunity over 10 years. Fifty billions of devices will be connected to various networks in 2020. This is bringing new technical challenges in all domains and specifically in the data processing. Distributed intelligence is one of the key technological answers. We call it fog computing."" Fog can provide intelligent connection of people processes data and things in hierarchical Internet of Things networks. By supplementing the cloud and providing intermediate layers of computation networking and storage fog nodes can optimize IoE deployments---greatly enhancing latency bandwidth reliability security and overall IoE network performance. The article will analyze the architecture and main design choices of this technology.""";
DeepTest: automated testing of deep-neural-network-driven autonomous cars;Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that using sensors like camera LiDAR etc. can drive without any human intervention. Most major manufacturers including Tesla GM Ford BMW and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California Texas and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads.However despite their spectacular progress DNNs just like traditional software often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases.In this paper we design implement and evaluate DeepTest a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain fog lighting conditions etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g. blurring rain fog etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.;
Proceedings of the 40th International Conference on Software Engineering;Middleware for robotics development must meet demanding requirements in real-time distributed embedded systems. The Robot Operating System (ROS) open-source middleware has been widely used for robotics applications. However the ROS is not suitable for real-time embedded systems because it does not satisfy real-time requirements and only runs on a few OSs. To address this problem ROS1 will undergo a significant upgrade to ROS2 by utilizing the Data Distribution Service (DDS). DDS is suitable for real-time distributed embedded systems due to its various transport configurations (e.g. deadline and fault-tolerance) and scalability. ROS2 must convert data for DDS and abstract DDS from its users however this incurs additional overhead which is examined in this study. Transport latencies between ROS2 nodes vary depending on the use cases data size configurations and DDS vendors. We conduct proof of concept for DDS approach to ROS and arrange DDS characteristic and guidelines from various evaluations. By highlighting the DDS capabilities we explore and evaluate the potential and constraints of DDS and ROS2.;
Proceedings of the 13th International Conference on Embedded Software;When posts are removed on a social media platform users may or may not receive an explanation. What kinds of explanations are provided? Do those explanations matter? Using a sample of 32 million Reddit posts we characterize the removal explanations that are provided to Redditors and link them to measures of subsequent user behaviors---including future post submissions and future post removals. Adopting a topic modeling approach we show that removal explanations often provide information that educate users about the social norms of the community thereby (theoretically) preparing them to become a productive member. We build regression models that show evidence of removal explanations playing a role in future user activity. Most importantly we show that offering explanations for content moderation reduces the odds of future post removals. Additionally explanations provided by human moderators did not have a significant advantage over explanations provided by bots for reducing future post removals. We propose design solutions that can promote the efficient use of explanation mechanisms reflecting on how automated moderation tools can contribute to this space. Overall our findings suggest that removal explanations may be under-utilized in moderation practices and it is potentially worthwhile for community managers to invest time and resources into providing them.;
Jupiter evolving: transforming google's datacenter network via optical circuit switches and software-defined networking;We present a decade of evolution and production experience with Jupiter datacenter network fabrics. In this period Jupiter has delivered 5x higher speed and capacity 30% reduction in capex 41% reduction in power incremental deployment and technology refresh all while serving live production traffic. A key enabler for these improvements is evolving Jupiter from a Clos to a direct-connect topology among the machine aggregation blocks. Critical architectural changes for this include: A datacenter interconnection layer employing Micro-Electro-Mechanical Systems (MEMS) based Optical Circuit Switches (OCSes) to enable dynamic topology reconfiguration centralized Software-Defined Networking (SDN) control for traffic engineering and automated network operations for incremental capacity delivery and topology engineering. We show that the combination of traffic and topology engineering on direct-connect fabrics achieves similar throughput as Clos fabrics for our production traffic patterns. We also optimize for path lengths: 60% of the traffic takes direct path from source to destination aggregation blocks while the remaining transits one additional block achieving an average block-level path length of 1.4 in our fleet today. OCS also achieves 3x faster fabric reconfiguration compared to pre-evolution Clos fabrics that used a patch panel based interconnect.;
Proceedings of the ACM SIGCOMM 2022 Conference;Autonomous computing is a pattern for business work using collaborations to connect fiefdoms and their emissaries. This pattern based on paper forms has been used for centuries. Here we explain fiefdoms collaborations and emissaries. We examine how emissaries work outside the autonomous boundary and are convenient while remaining an outsider. And we examine how work across different fiefdoms can be initiated run for long periods of time and eventually be completed.;
Analyzing and Securing SOME/IP Automotive Services with Formal and Practical Methods;Automotive Ethernet is increasingly used in modern vehicles and complements or replaces legacy bus systems such as CAN. Ethernet also enables service-oriented communication with the Scalable service-Oriented MiddlewarE over IP (SOME/IP) middleware. In this paper we present a formal and practical security analysis of Scalable service-Oriented MiddlewarE over IP (SOME/IP) the identified Man-in-the-Middle (MITM) attacks and propose two security extensions. The attacks are possible even if SOME/IP is used in combination with link layer security mechanisms. The attacker can impersonate a service offering server and a service consuming client. The two most common communication methods request/response and publish/subscribe are both vulnerable. In most communication scenarios we are able to route all messages over the attacker. Our security extensions for authentication and authorization of service provisioning and usage protect against these attacks. We formally analyze the security and evaluate the overhead with practical implementations.;
Proceedings of the 16th International Conference on Availability Reliability and Security;"How to find a thing"" in the Internet of Things (IoT) haystack? The answer to this question will be the key challenge that IoT users and developers are facing now and will face in the future. Current models for IoT are focused heavily on developing vertical solutions limited by hardware and software platforms and support. With the estimated explosion of IoT in the coming years as predicted by Cisco IBM and Gartner there is a need to rethink how IoT can deliver value to the end-user. A paradigm shift is required in the underlying fundamentals of current IoT developments to enable a wider notion of ""thing"" discovery as well as discovery of relevant data and context on the IoT. Discovery will allow users to build IoT apps services and applications using ""smart things"" without the need for a priori knowledge of things. In this article we look at the current state of IoT and argue for paradigm shift addressing why and how discovery can make a significant impact for the future of IoT and moreover become a necessary component for IoT success story.""";
Demystifying Stablecoins: Cryptography meets monetary policy;Self-sovereign stablecoins are interesting and probably here to stay however they face numerous regulatory hurdles from banking financial tracking and securities laws. For stablecoins backed by a governmental currency the ultimate expression would be a CBDC. Since paper currency has been in steady decline (and disproportionately for legitimate transactions) a CBDC could reintroduce cash with technological advantages and efficient settlement while minimizing user fees.;
The data science life cycle: a disciplined approach to advancing data science as a science;A cycle that traces ways to define the landscape of data science.;
Motivations for social networking at work;The introduction of a social networking site inside of a large enterprise enables a new method of communication between colleagues encouraging both personal and professional sharing inside the protected walls of a company intranet. Our analysis of user behavior and interviews presents the case that professionals use internal social networking to build stronger bonds with their weak ties and to reach out to employees they do not know. Their motivations in doing this include connecting on a personal level with coworkers advancing their career with the company and campaigning for their projects.;
Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work;Although algorithmic auditing has emerged as a key strategy to expose systematic biases embedded in software platforms we struggle to understand the real-world impact of these audits and continue to find it difficult to translate such independent assessments into meaningful corporate accountability. To analyze the impact of publicly naming and disclosing performance results of biased AI systems we investigate the commercial impact of Gender Shades the first algorithmic audit of gender- and skin-type performance disparities in commercial facial analysis models. This paper (1) outlines the audit design and structured disclosure procedure used in the Gender Shades study (2) presents new performance metrics from targeted companies such as IBM Microsoft and Megvii (Face++) on the Pilot Parliaments Benchmark (PPB) as of August 2018 (3) provides performance results on PPB by non-target companies such as Amazon and Kairos and (4) explores differences in company responses as shared through corporate communications that contextualize differences in performance on PPB. Within 7 months of the original audit we find that all three targets released new application program interface (API) versions. All targets reduced accuracy disparities between males and females and darker- and lighter-skinned subgroups with the most significant update occurring for the darker-skinned female subgroup that underwent a 17.7--30.4% reduction in error between audit periods. Minimizing these disparities led to a 5.72--8.3% reduction in overall error on the Pilot Parliaments Benchmark (PPB) for target corporation APIs. The overall performance of non-targets Amazon and Kairos lags significantly behind that of the targets with error rates of 8.66% and 6.60% overall and error rates of 31.37% and 22.50% for the darker female subgroup respectively. This is an expanded version of an earlier publication of these results revised for a more general audience and updated to include commentary on further developments.;
Decentralized blockchain-based electronic marketplaces;In a decentralized marketplace buyers and sellers transact directly without manipulation by intermediary platforms.;
Barriers to refactoring;Developers know refactoring improves their software but many find themselves unable to do so when they want to.;
Managing scientific data;Needed are generic rather than one-off DBMS solutions automating storage and analysis of data from scientific collaborations.;
An Empirical Analysis of the Commercial VPN Ecosystem;Global Internet users increasingly rely on virtual private network (VPN) services to preserve their privacy circumvent censorship and access geo-filtered content. Due to their own lack of technical sophistication and the opaque nature of VPN clients however the vast majority of users have limited means to verify a given VPN service's claims along any of these dimensions. We design an active measurement system to test various infrastructural and privacy aspects of VPN services and evaluate 62 commercial providers. Our results suggest that while commercial VPN services seem on the whole less likely to intercept or tamper with user traffic than other previously studied forms of traffic proxying many VPNs do leak user traffic---perhaps inadvertently---through a variety of means. We also find that a non-trivial fraction of VPN providers transparently proxy traffic and many misrepresent the physical location of their vantage points: 5--30% of the vantage points associated with 10% of the providers we study appear to be hosted on servers located in countries other than those advertised to users.;
Proceedings of the Internet Measurement Conference 2018;Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains such as self-driving cars and malware detection where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs.We design implement and evaluate DeepXplore the first white-box framework for systematically testing real-world DL systems. First we introduce neuron coverage for measuring the parts of a DL system exercised by test inputs. Next we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques.DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g. self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets such as ImageNet and Udacity self-driving challenge data. For all tested DL models on average DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model's accuracy by up to 3%.;
Controlling data in the cloud: outsourcing computation without outsourcing control;Cloud computing is clearly one of today's most enticing technology areas due at least in part to its cost-efficiency and flexibility. However despite the surge in activity and interest there are significant persistent concerns about cloud computing that are impeding momentum and will eventually compromise the vision of cloud computing as a new IT procurement model. In this paper we characterize the problems and their impact on adoption. In addition and equally importantly we describe how the combination of existing research thrusts has the potential to alleviate many of the concerns impeding adoption. In particular we argue that with continued research advances in trusted computing and computation-supporting encryption life in the cloud can be advantageous from a business intelligence standpoint over the isolated alternative that is more common today.;
Proceedings of the 2009 ACM Workshop on Cloud Computing Security;Most modern routers consist of several line cards that perform packet lookup and forwarding all controlled by a control plane that acts as the brain of the router performing essential tasks such as management functions error reporting control functions including route calculations and adjacency maintenance. This control plane has many names in this article it is the route processor or RP. The route processor calculates the forwarding table and downloads it to the line cards using a control-plane bus. The line cards perform the actual packet lookup and forwarding. Although individual vendors or models may differ slightly in implementation the salient points remain the same.;
A decade of software model checking with SLAM;SLAM is a program-analysis engine used to check if clients of an API follow the API's stateful usage rules.;
Burst photography for high dynamic range and low-light imaging on mobile cameras;Cell phone cameras have small apertures which limits the number of photons they can gather leading to noisy images in low light. They also have small sensor pixels which limits the number of electrons each pixel can store leading to limited dynamic range. We describe a computational photography pipeline that captures aligns and merges a burst of frames to reduce noise and increase dynamic range. Our system has several key features that help make it robust and efficient. First we do not use bracketed exposures. Instead we capture frames of constant exposure which makes alignment more robust and we set this exposure low enough to avoid blowing out highlights. The resulting merged image has clean shadows and high bit depth allowing us to apply standard HDR tone mapping methods. Second we begin from Bayer raw frames rather than the demosaicked RGB (or YUV) frames produced by hardware Image Signal Processors (ISPs) common on mobile platforms. This gives us more bits per pixel and allows us to circumvent the ISP's unwanted tone mapping and spatial denoising. Third we use a novel FFT-based alignment algorithm and a hybrid 2D/3D Wiener filter to denoise and merge the frames in a burst. Our implementation is built atop Android's Camera2 API which provides per-frame camera control and access to raw imagery and is written in the Halide domain-specific language (DSL). It runs in 4 seconds on device (for a 12 Mpix image) requires no user intervention and ships on several mass-produced cell phones.;
How UX Practitioners Produce Findings in Usability Testing;Usability testing has long been a core interest of HCI research and forms a key element of industry practice. Yet our knowledge of it harbours striking absences. There are few if any detailed accounts of the contingent material ways in which usability testing is actually practiced. Further it is rare that industry practitionersâ€™ testing work is treated as indigenous and particular (instead subordinated as a â€˜compromisedâ€™ version). To service these problems this article presents an ethnomethodological study of usability testing practices in a design consultancy. It unpacks how findings are produced in and as the work of observers analysing the test as it unfolds between moderators taking participants through relevant tasks. The study nuances conventional views of usability findings as straightforwardly â€˜there to be foundâ€™ or â€˜read offâ€™ by competent evaluators. It explores how evaluators/observers collaboratively work to locate relevant troubles in the test's unfolding. However in the course of doing this work potential candidate troubles may also routinely be dissipated and effectively â€˜ignoredâ€™ in one way or another. The implications of the study suggest refinements to current understandings of usability evaluations and affirm the value to HCI in studying industry practitioners more deeply.;
XGBoost: A Scalable Tree Boosting System;Tree boosting is a highly effective and widely used machine learning method. In this paper we describe a scalable end-to-end tree boosting system called XGBoost which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly we provide insights on cache access patterns data compression and sharding to build a scalable tree boosting system. By combining these insights XGBoost scales beyond billions of examples using far fewer resources than existing systems.;
Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;More than twelve years have elapsed since the first public release of WEKA. In that time the software has been rewritten entirely from scratch evolved substantially and now accompanies a text on data mining [35]. These days WEKA enjoys widespread acceptance in both academia and business has an active community and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench reviews the history of the project and in light of the recent 3.6 stable release briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.;
Proceedings of the 22nd ACM International Conference on Multimedia;Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category we provide a basic anomaly detection technique and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further for each category we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic and how techniques developed in one area can be applied in domains for which they were not intended to begin with.;
Proceedings of the 15th International Academic MindTrek Conference: Envisioning Future Media Environments;The gem5 simulation infrastructure is the merger of the best aspects of the M5 [4] and GEMS [9] simulators. M5 provides a highly configurable simulation framework multiple ISAs and diverse CPU models. GEMS complements these features with a detailed and exible memory system including support for multiple cache coherence protocols and interconnect models. Currently gem5 supports most commercial ISAs (ARM ALPHA MIPS Power SPARC and x86) including booting Linux on three of them (ARM ALPHA and x86).The project is the result of the combined efforts of many academic and industrial institutions including AMD ARM HP MIPS Princeton MIT and the Universities of Michigan Texas and Wisconsin. Over the past ten years M5 and GEMS have been used in hundreds of publications and have been downloaded tens of thousands of times. The high level of collaboration on the gem5 project combined with the previous success of the component parts and a liberal BSD-like license make gem5 a valuable full-system simulation tool.;
Networking named content;Network use has evolved to be dominated by content distribution and retrieval while networking technology still speaks only of connections between hosts. Accessing content and services requires mapping from the what that users care about to the network's where. We present Content-Centric Networking (CCN) which treats content as a primitive - decoupling location from identity security and access and retrieving content by name. Using new approaches to routing named content derived heavily from IP we can simultaneously achieve scalability security and performance. We implemented our architecture's basic features and demonstrate resilience and performance with secure file downloads and VoIP calls.;
Proceedings of the 5th International Conference on Emerging Networking Experiments and Technologies;Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often the training of models requires large representative datasets which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives under a modest privacy budget and at a manageable cost in software complexity training efficiency and model quality.;
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;This paper presents and characterizes the Princeton Application Repository for Shared-Memory Computers (PARSEC) a benchmark suite for studies of Chip-Multiprocessors (CMPs). Previous available benchmarks for multiprocessors have focused on high-performance computing applications and used a limited number of synchronization methods. PARSEC includes emerging applications in recognition mining and synthesis (RMS) as well as systems applications which mimic large-scale multithreaded commercial programs. Our characterization shows that the benchmark suite covers a wide spectrum of working sets locality data sharing synchronization and off-chip traffic. The benchmark suite has been made available to the public.;
Proceedings of the 17th International Conference on Parallel Architectures and Compilation Techniques;Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU) --- deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs that help average throughput more than guaranteed latency. The lack of such features helps explain why despite having myriad MACs and a big memory the TPU is relatively small and low power. We compare the TPU to a server-class Intel Haswell CPU and an Nvidia K80 GPU which are contemporaries deployed in the same datacenters. Our workload written in the high-level TensorFlow framework uses production NN applications (MLPs CNNs and LSTMs) that represent 95% of our datacenters' NN inference demand. Despite low utilization for some applications the TPU is on average about 15X -- 30X faster than its contemporary GPU or CPU with TOPS/Watt about 30X -- 80X higher. Moreover using the CPU's GDDR5 memory in the TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and 200X the CPU.;
Proceedings of the 44th Annual International Symposium on Computer Architecture;Today's data centers may contain tens of thousands of computers with significant aggregate bandwidth requirements. The network architecture typically consists of a tree of routing and switching elements with progressively more specialized and expensive equipment moving up the network hierarchy. Unfortunately even when deploying the highest-end IP switches/routers resulting topologies may only support 50% of the aggregate bandwidth available at the edge of the network while still incurring tremendous cost. Non-uniform bandwidth among data center nodes complicates application design and limits overall system performance.In this paper we show how to leverage largely commodity Ethernet switches to support the full aggregate bandwidth of clusters consisting of tens of thousands of elements. Similar to how clusters of commodity computers have largely replaced more specialized SMPs and MPPs we argue that appropriately architected and interconnected commodity switches may deliver more performance at less cost than available from today's higher-end solutions. Our approach requires no modifications to the end host network interface operating system or applications critically it is fully backward compatible with Ethernet IP and TCP.;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;"While the use of MapReduce systems (such as Hadoop) for large scale data analysis has been widely recognized and studied we have recently seen an explosion in the number of systems developed for cloud data serving. These newer systems address cloud OLTP"" applications though they typically do not support ACID transactions. Examples of systems proposed for cloud serving use include BigTable PNUTS Cassandra HBase Azure CouchDB SimpleDB Voldemort and many others. Further they are being applied to a diverse range of applications that differ considerably from traditional (e.g. TPC-C like) serving workloads. The number of emerging cloud serving systems and the wide range of proposed applications coupled with a lack of apples-to-apples performance comparisons makes it difficult to understand the tradeoffs between systems and the workloads for which they are suited. We present the ""Yahoo! Cloud Serving Benchmark"" (YCSB) framework with the goal of facilitating performance comparisons of the new generation of cloud data serving systems. We define a core set of benchmarks and report results for four widely used systems: Cassandra HBase Yahoo!'s PNUTS and a simple sharded MySQL implementation. We also hope to foster the development of additional cloud benchmark suites that represent other classes of applications by making our benchmark tool available via open source. In this regard a key feature of the YCSB framework/tool is that it is extensible--it supports easy definition of new workloads in addition to making it easy to benchmark new systems.""";
Proceedings of the 1st ACM Symposium on Cloud Computing;"Fabric is a modular and extensible open-source system for deploying and operating permissioned blockchains and one of the Hyperledger projects hosted by the Linux Foundation (www.hyperledger.org).Fabric is the first truly extensible blockchain system for running distributed applications. It supports modular consensus protocols which allows the system to be tailored to particular use cases and trust models. Fabric is also the first blockchain system that runs distributed applications written in standard general-purpose programming languages without systemic dependency on a native cryptocurrency. This stands in sharp contrast to existing block-chain platforms that require smart-contracts"" to be written in domain-specific languages or rely on a cryptocurrency. Fabric realizes the permissioned model using a portable notion of membership which may be integrated with industry-standard identity management. To support such flexibility Fabric introduces an entirely novel blockchain design and revamps the way blockchains cope with non-determinism resource exhaustion and performance attacks.This paper describes Fabric its architecture the rationale behind various design decisions its most prominent implementation aspects as well as its distributed application programming model. We further evaluate Fabric by implementing and benchmarking a Bitcoin-inspired digital currency. We show that Fabric achieves end-to-end throughput of more than 3500 transactions per second in certain popular deployment configurations with sub-second latency scaling well to over 100 peers.""";
Proceedings of the Thirteenth EuroSys Conference;The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically (2) efficient implementation of both searching and pruning strategies and (3) easy-to-setup versatile architecture that can be deployed for various purposes ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point we will introduce Optuna an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;We present a learned model of human body shape and pose-dependent shape variation that is more accurate than previous models and is compatible with existing graphics pipelines. Our Skinned Multi-Person Linear model (SMPL) is a skinned vertex-based model that accurately represents a wide variety of body shapes in natural human poses. The parameters of the model are learned from data including the rest pose template blend weights pose-dependent blend shapes identity-dependent blend shapes and a regressor from vertices to joint locations. Unlike previous models the pose-dependent blend shapes are a linear function of the elements of the pose rotation matrices. This simple formulation enables training the entire model from a relatively large number of aligned 3D meshes of different people in different poses. We quantitatively evaluate variants of SMPL using linear or dual-quaternion blend skinning and show that both are more accurate than a Blend-SCAPE model trained on the same data. We also extend SMPL to realistically model dynamic soft-tissue deformations. Because it is based on blend skinning SMPL is compatible with existing rendering engines and we make it available for research purposes.;
Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data;We have witnessed great interest and a wealth of promise in content-based image retrieval as an emerging technology. While the last decade laid foundation to such promise it also paved the way for a large number of new techniques and systems got many new people involved and triggered stronger association of weakly related fields. In this article we survey almost 300 key theoretical and empirical contributions in the current decade related to image retrieval and automatic image annotation and in the process discuss the spawning of related subfields. We also discuss significant challenges involved in the adaptation of existing image retrieval techniques to build systems that can be useful in the real world. In retrospect of what has been achieved so far we also conjecture what the future may hold for image retrieval research.;
The MovieLens Datasets: History and Context;The MovieLens datasets are widely used in education research and industry. They are downloaded hundreds of thousands of times each year reflecting their use in popular press programming books traditional and online courses and software. These datasets are a product of member activity in the MovieLens movie recommendation system an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research.;
P4: programming protocol-independent packet processors;P4 is a high-level language for programming protocol-independent packet processors. P4 works in conjunction with SDN control protocols like OpenFlow. In its current form OpenFlow explicitly specifies protocol headers on which it operates. This set has grown from 12 to 41 fields in a few years increasing the complexity of the specification while still not providing the flexibility to add new headers. In this paper we propose P4 as a strawman proposal for how OpenFlow should evolve in the future. We have three goals: (1) Reconfigurability in the field: Programmers should be able to change the way switches process packets once they are deployed. (2) Protocol independence: Switches should not be tied to any specific network protocols. (3) Target independence: Programmers should be able to describe packet-processing functionality independently of the specifics of the underlying hardware. As an example we describe how to use P4 to configure a switch to add a new hierarchical label.;
A survey on concept drift adaptation;Concept drift primarily refers to an online supervised learning scenario when the relation between the input data and the target variable changes over time. Assuming a general knowledge of supervised learning in this article we characterize adaptive learning processes categorize existing strategies for handling concept drift overview the most representative distinct and popular techniques and algorithms discuss evaluation methodology of adaptive algorithms and present a set of illustrative applications. The survey covers the different facets of concept drift in an integrated way to reflect on the existing scattered state of the art. Thus it aims at providing a comprehensive introduction to the concept drift adaptation for researchers industry analysts and practitioners.;
B4: experience with a globally-deployed software defined wan;We present the design implementation and evaluation of B4 a private WAN connecting Google's data centers across the planet. B4 has a number of unique characteristics: i) massive bandwidth requirements deployed to a modest number of sites ii) elastic traffic demand that seeks to maximize average bandwidth and iii) full control over the edge servers and network which enables rate limiting and demand measurement at the edge.These characteristics led to a Software Defined Networking architecture using OpenFlow to control relatively simple switches built from merchant silicon. B4's centralized traffic engineering service drives links to near 100% utilization while splitting application flows among multiple paths to balance capacity against application priority/demands. We describe experience with three years of B4 production deployment lessons learned and areas for future work.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;Mobile devices are becoming increasingly sophisticated and the latest generation of smart cell phones now incorporates many diverse and powerful sensors. These sensors include GPS sensors vision sensors (i.e. cameras) audio sensors (i.e. microphones) light sensors temperature sensors direction sensors (i.e. magnetic compasses) and acceleration sensors (i.e. accelerometers). The availability of these sensors in mass-marketed communication devices creates exciting new opportunities for data mining and data mining applications. In this paper we describe and evaluate a system that uses phone-based accelerometers to perform activity recognition a task which involves identifying the physical activity a user is performing. To implement our system we collected labeled accelerometer data from twenty-nine users as they performed daily activities such as walking jogging climbing stairs sitting and standing and then aggregated this time series data into examples that summarize the user activity over 10- second intervals. We then used the resulting training data to induce a predictive model for activity recognition. This work is significant because the activity recognition model permits us to gain useful knowledge about the habits of millions of users passively---just by having them carry cell phones in their pockets. Our work has a wide range of applications including automatic customization of the mobile device's behavior based upon a user's activity (e.g. sending calls directly to voicemail if a user is jogging) and generating a daily/weekly activity profile to determine if a user (perhaps an obese child) is performing a healthy amount of exercise.;
Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering;This collaboratively edited knowledgebase provides a common source of data for Wikipedia and everyone else.;
The university of Florida sparse matrix collection;We describe the University of Florida Sparse Matrix Collection a large and actively growing set of sparse matrices that arise in real applications. The Collection is widely used by the numerical linear algebra community for the development and performance evaluation of sparse matrix algorithms. It allows for robust and repeatable experiments: robust because performance results with artificially generated matrices can be misleading and repeatable because matrices are curated and made publicly available in many formats. Its matrices cover a wide spectrum of domains include those arising from problems with underlying 2D or 3D geometry (as structural engineering computational fluid dynamics model reduction electromagnetics semiconductor devices thermodynamics materials acoustics computer graphics/vision robotics/kinematics and other discretizations) and those that typically do not have such geometry (optimization circuit simulation economic and financial modeling theoretical and quantum chemistry chemical process simulation mathematics and statistics power networks and other networks and graphs). We provide software for accessing and managing the Collection from MATLABâ„¢ Mathematicaâ„¢ Fortran and C as well as an online search capability. Graph visualization of the matrices is provided and a new multilevel coarsening scheme is proposed to facilitate this task.;
MAUI: making smartphones last longer with code offload;This paper presents MAUI a system that enables fine-grained energy-aware offload of mobile code to the infrastructure. Previous approaches to these problems either relied heavily on programmer support to partition an application or they were coarse-grained requiring full process (or full VM) migration. MAUI uses the benefits of a managed code environment to offer the best of both worlds: it supports fine-grained code offload to maximize energy savings with minimal burden on the programmer. MAUI decides at run-time which methods should be remotely executed driven by an optimization engine that achieves the best energy savings possible under the mobile device's current connectivity constrains. In our evaluation we show that MAUI enables: 1) a resource-intensive face recognition application that consumes an order of magnitude less energy 2) a latency-sensitive arcade game application that doubles its refresh rate and 3) a voice-based language translation application that bypasses the limitations of the smartphone environment by executing unsupported components remotely.;
Proceedings of the 8th International Conference on Mobile Systems Applications and Services;This paper presents the design and implementation of the first in-band full duplex WiFi radios that can simultaneously transmit and receive on the same channel using standard WiFi 802.11ac PHYs and achieves close to the theoretical doubling of throughput in all practical deployment scenarios. Our design uses a single antenna for simultaneous TX/RX (i.e. the same resources as a standard half duplex system). We also propose novel analog and digital cancellation techniques that cancel the self interference to the receiver noise floor and therefore ensure that there is no degradation to the received signal. We prototype our design by building our own analog circuit boards and integrating them with a fully WiFi-PHY compatible software radio implementation. We show experimentally that our design works robustly in noisy indoor environments and provides close to the expected theoretical doubling of throughput in practice.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;Named Data Networking (NDN) is one of five projects funded by the U.S. National Science Foundation under its Future Internet Architecture Program. NDN has its roots in an earlier project Content-Centric Networking (CCN) which Van Jacobson first publicly presented in 2006. The NDN project investigates Jacobson's proposed evolution from today's host-centric network architecture (IP) to a data-centric network architecture (NDN). This conceptually simple shift has far-reaching implications for how we design develop deploy and use networks and applications. We describe the motivation and vision of this new architecture and its basic components and operations. We also provide a snapshot of its current design development status and research challenges. More information about the project including prototype implementations publications and annual reports is available on named-data.net.;
Proceedings of the 9th WebKDD and 1st SNA-KDD 2007 Workshop on Web Mining and Social Network Analysis;MatConvNet is an open source implementation of Convolutional Neural Networks (CNNs) with a deep integration in the MATLAB environment. The toolbox is designed with an emphasis on simplicity and flexibility. It exposes the building blocks of CNNs as easy-to-use MATLAB functions providing routines for computing convolutions with filter banks feature pooling normalisation and much more. MatConvNet can be easily extended often using only MATLAB code allowing fast prototyping of new CNN architectures. At the same time it supports efficient computation on CPU and GPU allowing to train complex models on large datasets such as ImageNet ILSVRC containing millions of training examples;
Proceedings of the 23rd ACM International Conference on Multimedia;Today's smartphones are a ubiquitous source of private and confidential data. At the same time smartphone users are plagued by carelessly programmed apps that leak important data by accident and by malicious apps that exploit their given privileges to copy such data intentionally. While existing static taint-analysis approaches have the potential of detecting such data leaks ahead of time all approaches for Android use a number of coarse-grain approximations that can yield high numbers of missed leaks and false alarms.In this work we thus present FlowDroid a novel and highly precise static taint analysis for Android applications. A precise model of Android's lifecycle allows the analysis to properly handle callbacks invoked by the Android framework while context flow field and object-sensitivity allows the analysis to reduce the number of false alarms. Novel on-demand algorithms help FlowDroid maintain high efficiency and precision at the same time.We also propose DroidBench an open test suite for evaluating the effectiveness and accuracy of taint-analysis tools specifically for Android apps. As we show through a set of experiments using SecuriBench Micro DroidBench and a set of well-known Android test applications FlowDroid finds a very high fraction of data leaks while keeping the rate of false positives low. On DroidBench FlowDroid achieves 93% recall and 86% precision greatly outperforming the commercial tools IBM AppScan Source and Fortify SCA. FlowDroid successfully finds leaks in a subset of 500 apps from Google Play and about 1000 malware apps from the VirusShare project.;
Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation;The Roofline model offers insight on how to improve the performance of software and hardware.;
False data injection attacks against state estimation in electric power grids;A power grid is a complex system connecting electric power generators to consumers through power transmission and distribution networks across a large geographical area. System monitoring is necessary to ensure the reliable operation of power grids and state estimation is used in system monitoring to best estimate the power grid state through analysis of meter measurements and power system models. Various techniques have been developed to detect and identify bad measurements including interacting bad measurements introduced by arbitrary nonrandom causes. At first glance it seems that these techniques can also defeat malicious measurements injected by attackers.In this article we expose an unknown vulnerability of existing bad measurement detection algorithms by presenting and analyzing a new class of attacks called false data injection attacks against state estimation in electric power grids. Under the assumption that the attacker can access the current power system configuration information and manipulate the measurements of meters at physically protected locations such as substations such attacks can introduce arbitrary errors into certain state variables without being detected by existing algorithms. Moreover we look at two scenarios where the attacker is either constrained to specific meters or limited in the resources required to compromise meters. We show that the attacker can systematically and efficiently construct attack vectors in both scenarios to change the results of state estimation in arbitrary ways. We also extend these attacks to generalized false data injection attacks which can further increase the impact by exploiting measurement errors typically tolerated in state estimation. We demonstrate the success of these attacks through simulation using IEEE test systems and also discuss the practicality of these attacks and the real-world constraints that limit their effectiveness.;
EIE: efficient inference engine on compressed deep neural network;State-of-the-art deep neural networks (DNNs) have hundreds of millions of connections and are both computationally and memory intensive making them difficult to deploy on embedded systems with limited hardware resources and power budgets. While custom hardware helps the computation fetching weights from DRAM is two orders of magnitude more expensive than ALU operations and dominates the required power.Previously proposed 'Deep Compression' makes it possible to fit large DNNs (AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by pruning the redundant connections and having multiple connections share the same weight. We propose an energy efficient inference engine (EIE) that performs inference on this compressed network model and accelerates the resulting sparse matrix-vector multiplication with weight sharing. Going from DRAM to SRAM gives EIE 120\texttimes{;
Proceedings of the 43rd International Symposium on Computer Architecture;KinectFusion enables a user holding and moving a standard Kinect camera to rapidly create detailed 3D reconstructions of an indoor scene. Only the depth data from Kinect is used to track the 3D pose of the sensor and reconstruct geometrically precise 3D models of the physical scene in real-time. The capabilities of KinectFusion as well as the novel GPU-based pipeline are described in full. Uses of the core system for low-cost handheld scanning and geometry-aware augmented reality and physics-based interactions are shown. Novel extensions to the core GPU pipeline demonstrate object segmentation and user interaction directly in front of the sensor without degrading camera tracking or reconstruction. These extensions are used to enable real-time multi-touch interactions anywhere allowing any planar or non-planar reconstructed physical surface to be appropriated for touch.;
Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology;Mobile applications are becoming increasingly ubiquitous and provide ever richer functionality on mobile devices. At the same time such devices often enjoy strong connectivity with more powerful machines ranging from laptops and desktops to commercial clouds. This paper presents the design and implementation of CloneCloud a system that automatically transforms mobile applications to benefit from the cloud. The system is a flexible application partitioner and execution runtime that enables unmodified mobile applications running in an application-level virtual machine to seamlessly off-load part of their execution from mobile devices onto device clones operating in a computational cloud. CloneCloud uses a combination of static analysis and dynamic profiling to partition applications automatically at a fine granularity while optimizing execution time and energy use for a target computation and communication environment. At runtime the application partitioning is effected by migrating a thread from the mobile device at a chosen point to the clone in the cloud executing there for the remainder of the partition and re-integrating the migrated thread back to the mobile device. Our evaluation shows that CloneCloud can adapt application partitioning to different environments and can help some applications achieve as much as a 20x execution speed-up and a 20-fold decrease of energy spent on the mobile device.;
Proceedings of the Sixth Conference on Computer Systems;CUBIC is a congestion control protocol for TCP (transmission control protocol) and the current default TCP algorithm in Linux. The protocol modifies the linear window growth function of existing TCP standards to be a cubic function in order to improve the scalability of TCP over fast and long distance networks. It also achieves more equitable bandwidth allocations among flows with different RTTs (round trip times) by making the window growth to be independent of RTT -- thus those flows grow their congestion window at the same rate. During steady state CUBIC increases the window size aggressively when the window is far from the saturation point and the slowly when it is close to the saturation point. This feature allows CUBIC to be very scalable when the bandwidth and delay product of the network is large and at the same time be highly stable and also fair to standard TCP flows. The implementation of CUBIC in Linux has gone through several upgrades. This paper documents its design implementation performance and evolution as the default TCP algorithm of Linux.;
Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures;Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices making medical diagnoses and facial recognition. In a model inversion attack recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al. adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs however is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and in the other context show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.;
Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security;With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions thus it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey we investigated different real-world applications that have shown biases in various ways and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.;
Proceedings of the 12th Annual International Digital Government Research Conference: Digital Government Innovation in Challenging Times;In this paper we present a new method for estimating the optical transmission in hazy scenes given a single input image. Based on this estimation the scattered light is eliminated to increase scene visibility and recover haze-free scene contrasts. In this new approach we formulate a refined image formation model that accounts for surface shading in addition to the transmission function. This allows us to resolve ambiguities in the data by searching for a solution in which the resulting shading and transmission functions are locally statistically uncorrelated. A similar principle is used to estimate the color of the haze. Results demonstrate the new method abilities to remove the haze layer as well as provide a reliable transmission estimate which can be used for additional applications such as image refocusing and novel view synthesis.;
The aligned rank transform for nonparametric factorial analyses using only anova procedures;"Nonparametric data from multi-factor experiments arise often in human-computer interaction (HCI). Examples may include error counts Likert responses and preference tallies. But because multiple factors are involved common nonparametric tests (e.g. Friedman) are inadequate as they are unable to examine interaction effects. While some statistical techniques exist to handle such data these techniques are not widely available and are complex. To address these concerns we present the Aligned Rank Transform (ART) for nonparametric factorial data analysis in HCI. The ART relies on a preprocessing step that aligns"" data before applying averaged ranks after which point common ANOVA procedures can be used making the ART accessible to anyone familiar with the F-test. Unlike most articles on the ART which only address two factors we generalize the ART to N factors. We also provide ARTool and ARTweb desktop and Web-based programs for aligning and ranking data. Our re-examination of some published HCI results exhibits advantages of the ART.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Machine-Learning tasks are becoming pervasive in a broad range of domains and in a broad range of systems (from embedded systems to data centers). At the same time a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks i.e. CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve towards heterogeneous multi-cores composed of a mix of cores and accelerators a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope.Until now most machine-learning accelerator designs have focused on efficiently implementing the computational part of the algorithms. However recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study we design an accelerator for large-scale CNNs and DNNs with a special emphasis on the impact of memory on accelerator design performance and energy.We show that it is possible to design an accelerator with a high throughput capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm2 and 485 mW compared to a 128-bit 2GHz SIMD processor the accelerator is 117.87x faster and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65 nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications.;
Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems;Mininet is a system for rapidly prototyping large networks on the constrained resources of a single laptop. The lightweight approach of using OS-level virtualization features including processes and network namespaces allows it to scale to hundreds of nodes. Experiences with our initial implementation suggest that the ability to run poke and debug in real time represents a qualitative change in workflow. We share supporting case studies culled from over 100 users at 18 institutions who have developed Software-Defined Networks (SDN). Ultimately we think the greatest value of Mininet will be supporting collaborative network research by enabling self-contained SDN prototypes which anyone with a PC can download run evaluate explore tweak and build upon.;
Proceedings of the 9th ACM SIGCOMM Workshop on Hot Topics in Networks;Convolutional neural network (CNN) has been widely employed for image recognition because it can achieve high accuracy by emulating behavior of optic nerves in living creatures. Recently rapid growth of modern applications based on deep learning algorithms has further improved research and implementations. Especially various accelerators for deep CNN have been proposed based on FPGA platform because it has advantages of high performance reconfigurability and fast development round etc. Although current FPGA accelerators have demonstrated better performance over generic processors the accelerator design space has not been well exploited. One critical problem is that the computation throughput may not well match the memory bandwidth provided an FPGA platform. Consequently existing approaches cannot achieve best performance due to under-utilization of either logic resource or memory bandwidth. At the same time the increasing complexity and scalability of deep learning applications aggravate this problem. In order to overcome this problem we propose an analytical design scheme using the roofline model. For any solution of a CNN design we quantitatively analyze its computing throughput and required memory bandwidth using various optimization techniques such as loop tiling and transformation. Then with the help of rooine model we can identify the solution with best performance and lowest FPGA resource requirement. As a case study we implement a CNN accelerator on a VC707 FPGA board and compare it to previous approaches. Our implementation achieves a peak performance of 61.62 GFLOPS under 100MHz working frequency which outperform previous approaches significantly.;
Proceedings of the 2015 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays;The determination of upper bounds on execution times commonly called worst-case execution times (WCETs) is a necessary step in the development and validation process for hard real-time systems. This problem is hard if the underlying processor architecture has components such as caches pipelines branch prediction and other speculative components. This article describes different approaches to this problem and surveys several commercially available tools1 and research prototypes.;
Hey you get off of my cloud: exploring information leakage in third-party compute clouds;Third-party cloud computing represents the promise of outsourcing as applied to computation. Services such as Microsoft's Azure and Amazon's EC2 allow users to instantiate virtual machines (VMs) on demand and thus purchase precisely the capacity they require when they require it. In turn the use of virtualization allows third-party cloud providers to maximize the utilization of their sunk capital costs by multiplexing many customer VMs across a shared physical infrastructure. However in this paper we show that this approach can also introduce new vulnerabilities. Using the Amazon EC2 service as a case study we show that it is possible to map the internal cloud infrastructure identify where a particular target VM is likely to reside and then instantiate new VMs until one is placed co-resident with the target. We explore how such placement can then be used to mount cross-VM side-channel attacks to extract information from a target VM on the same machine.;
Proceedings of the 16th ACM Conference on Computer and Communications Security;Memory scaling is in jeopardy as charge storage and sensing mechanisms become less reliable for prevalent memory technologies such as DRAM. In contrast phase change memory (PCM) storage relies on scalable current and thermal mechanisms. To exploit PCM's scalability as a DRAM alternative PCM must be architected to address relatively long latencies high energy writes and finite endurance.We propose crafted from a fundamental understanding of PCM technology parameters area-neutral architectural enhancements that address these limitations and make PCM competitive with DRAM. A baseline PCM system is 1.6x slower and requires 2.2x more energy than a DRAM system. Buffer reorganizations reduce this delay and energy gap to 1.2x and 1.0x using narrow rows to mitigate write energy and multiple rows to improve locality and write coalescing. Partial writes enhance memory endurance providing 5.6 years of lifetime. Process scaling will further reduce PCM energy costs and improve endurance.;
Proceedings of the 36th Annual International Symposium on Computer Architecture;The initial design of Apache Hadoop [1] was tightly focused on running massive MapReduce jobs to process a web crawl. For increasingly diverse companies Hadoop has become the data and computational agor\'{a;
Proceedings of the 4th Annual Symposium on Cloud Computing;Cryptocurrencies record transactions in a decentralized data structure called a blockchain. Two of the most popular cryptocurrencies Bitcoin and Ethereum support the feature to encode rules or scripts for processing transactions. This feature has evolved to give practical shape to the ideas of smart contracts or full-fledged programs that are run on blockchains. Recently Ethereum's smart contract system has seen steady adoption supporting tens of thousands of contracts holding millions dollars worth of virtual coins.In this paper we investigate the security of running smart contracts based on Ethereum in an open distributed network like those of cryptocurrencies. We introduce several new security problems in which an adversary can manipulate smart contract execution to gain profit. These bugs suggest subtle gaps in the understanding of the distributed semantics of the underlying platform. As a refinement we propose ways to enhance the operational semantics of Ethereum to make contracts less vulnerable. For developers writing contracts for the existing Ethereum system we build a symbolic execution tool called Oyente to find potential security bugs. Among 19 336 existing Ethereum contracts Oyente flags 8 833 of them as vulnerable including the TheDAO bug which led to a 60 million US dollar loss in June 2016. We also discuss the severity of other attacks for several case studies which have source code available and confirm the attacks (which target only our accounts) in the main Ethereum network.;
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;Our main result is a reduction from worst-case lattice problems such as GapSVP and SIVP to a certain learning problem. This learning problem is a natural extension of the â€œlearning from parity with errorâ€ problem to higher moduli. It can also be viewed as the problem of decoding from a random linear code. This we believe gives a strong indication that these problems are hard. Our reduction however is quantum. Hence an efficient solution to the learning problem implies a quantum algorithm for GapSVP and SIVP. A main open question is whether this reduction can be made classical (i.e. nonquantum).We also present a (classical) public-key cryptosystem whose security is based on the hardness of the learning problem. By the main result its security is also based on the worst-case quantum hardness of GapSVP and SIVP. The new cryptosystem is much more efficient than previous lattice-based cryptosystems: the public key is of size \~{O;
ISAAC: a convolutional neural network accelerator with in-situ analog arithmetic in crossbars;A number of recent efforts have attempted to design accelerators for popular machine learning algorithms such as those involving convolutional and deep neural networks (CNNs and DNNs). These algorithms typically involve a large number of multiply-accumulate (dot-product) operations. A recent project DaDianNao adopts a near data processing approach where a specialized neural functional unit performs all the digital arithmetic operations and receives input weights from adjacent eDRAM banks.This work explores an in-situ processing approach where memristor crossbar arrays not only store input weights but are also used to perform dot-product operations in an analog manner. While the use of crossbar memory as an analog dot-product engine is well known no prior work has designed or characterized a full-fledged accelerator based on crossbars. In particular our work makes the following contributions: (i) We design a pipelined architecture with some crossbars dedicated for each neural network layer and eDRAM buffers that aggregate data between pipeline stages. (ii) We define new data encoding techniques that are amenable to analog computations and that can reduce the high overheads of analog-to-digital conversion (ADC). (iii) We define the many supporting digital components required in an analog CNN accelerator and carry out a design space exploration to identify the best balance of memristor storage/compute ADCs and eDRAM storage on a chip. On a suite of CNN and DNN workloads the proposed ISAAC architecture yields improvements of 14.8\texttimes{;
Proceedings of the 43rd International Symposium on Computer Architecture;This paper presents BCube a new network architecture specifically designed for shipping-container based modular data centers. At the core of the BCube architecture is its server-centric network structure where servers with multiple network ports connect to multiple layers of COTS (commodity off-the-shelf) mini-switches. Servers act as not only end hosts but also relay nodes for each other. BCube supports various bandwidth-intensive applications by speeding-up one-to-one one-to-several and one-to-all traffic patterns and by providing high network capacity for all-to-all traffic.BCube exhibits graceful performance degradation as the server and/or switch failure rate increases. This property is of special importance for shipping-container data centers since once the container is sealed and operational it becomes very difficult to repair or replace its components.Our implementation experiences show that BCube can be seamlessly integrated with the TCP/IP protocol stack and BCube packet forwarding can be efficiently implemented in both hardware and software. Experiments in our testbed demonstrate that BCube is fault tolerant and load balancing and it significantly accelerates representative bandwidth-intensive applications.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;Anomalies are data points that are few and different. As a result of these properties we show that anomalies are susceptible to a mechanism called isolation. This article proposes a method called Isolation Forest (iForest) which detects anomalies purely based on the concept of isolation without employing any distance or density measure---fundamentally different from all existing methods.As a result iForest is able to exploit subsampling (i) to achieve a low linear time-complexity and a small memory-requirement and (ii) to deal with the effects of swamping and masking effectively. Our empirical evaluation shows that iForest outperforms ORCA one-class SVM LOF and Random Forests in terms of AUC processing time and it is robust against masking and swamping effects. iForest also works well in high dimensional problems containing a large number of irrelevant attributes and when anomalies are not available in training sample.;
Ambient backscatter: wireless communication out of thin air;We present the design of a communication system that enables two devices to communicate using ambient RF as the only source of power. Our approach leverages existing TV and cellular transmissions to eliminate the need for wires and batteries thus enabling ubiquitous communication where devices can communicate among themselves at unprecedented scales and in locations that were previously inaccessible.To achieve this we introduce ambient backscatter a new communication primitive where devices communicate by backscattering ambient RF signals. Our design avoids the expensive process of generating radio waves backscatter communication is orders of magnitude more power-efficient than traditional radio communication. Further since it leverages the ambient RF signals that are already around us it does not require a dedicated power infrastructure as in traditional backscatter communication. To show the feasibility of our design we prototype ambient backscatter devices in hardware and achieve information rates of 1 kbps over distances of 2.5 feet and 1.5 feet while operating outdoors and indoors respectively. We use our hardware prototype to implement proof-of-concepts for two previously infeasible ubiquitous communication applications.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;The collection of digital information by governments corporations and individuals has created tremendous opportunities for knowledge- and information-based decision making. Driven by mutual benefits or by regulations that require certain data to be published there is a demand for the exchange and publication of data among various parties. Data in its original form however typically contains sensitive information about individuals and publishing such data will violate individual privacy. The current practice in data publishing relies mainly on policies and guidelines as to what types of data can be published and on agreements on the use of published data. This approach alone may lead to excessive data distortion or insufficient protection. Privacy-preserving data publishing (PPDP) provides methods and tools for publishing useful information while preserving data privacy. Recently PPDP has received considerable attention in research communities and many approaches have been proposed for different data publishing scenarios. In this survey we will systematically summarize and evaluate different approaches to PPDP study the challenges in practical data publishing clarify the differences and requirements that distinguish PPDP from other related problems and propose future research directions.;
seL4: formal verification of an OS kernel;Complete formal verification is the only known way to guarantee that a system is free of programming errors.We present our experience in performing the formal machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler assembly code and hardware and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge this is the first formal proof of functional correctness of a complete general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation.seL4 a third-generation microkernel of L4 provenance comprises 8700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;This paper presents a new model for understanding human behavior. In this model (FBM) behavior is a product of three factors: motivation ability and triggers each of which has subcomponents. The FBM asserts that for a person to perform a target behavior he or she must (1) be sufficiently motivated (2) have the ability to perform the behavior and (3) be triggered to perform the behavior. These three factors must occur at the same moment else the behavior will not happen. The FBM is useful in analysis and design of persuasive technologies. The FBM also helps teams work together efficiently because this model gives people a shared way of thinking about behavior change.;
Proceedings of the 4th International Conference on Persuasive Technology;Cyber-physical systems (CPS) are physical and engineered systems whose operations are monitored coordinated controlled and integrated by a computing and communication core. Just as the internet transformed how humans interact with one another cyber-physical systems will transform how we interact with the physical world around us. Many grand challenges await in the economically vital domains of transportation health-care manufacturing agriculture energy defense aerospace and buildings. The design construction and verification of cyber-physical systems pose a multitude of technical challenges that must be addressed by a cross-disciplinary community of researchers and educators.;
Proceedings of the 47th Design Automation Conference;In most well known image retrieval test sets the imagery typically cannot be freely distributed or is not representative of a large community of users. In this paper we present a collection for the MIR community comprising 25000 images from the Flickr website which are redistributable for research purposes and represent a real community of users both in the image content and image tags. We have extracted the tags and EXIF image metadata and also make all of these publicly available. In addition we discuss several challenges for benchmarking retrieval and classification methods.;
Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval;This paper discusses the design of a single channel full-duplex wireless transceiver. The design uses a combination of RF and baseband techniques to achieve full-duplexing with minimal effect on link reliability. Experiments on real nodes show the full-duplex prototype achieves median performance that is within 8% of an ideal full-duplexing system.This paper presents Antenna Cancellation a novel technique for self-interference cancellation. In conjunction with existing RF interference cancellation and digital baseband interference cancellation antenna cancellation achieves the amount of self-interference cancellation required for full-duplex operation.The paper also discusses potential MAC and network gains with full-duplexing. It suggests ways in which a full-duplex system can solve some important problems with existing wireless systems including hidden terminals loss of throughput due to congestion and large end-to-end delays.;
Proceedings of the Sixteenth Annual International Conference on Mobile Computing and Networking;The last 20 years have seen ever-increasing research activity in the field of human activity recognition. With activity recognition having considerably matured so has the number of challenges in designing implementing and evaluating activity recognition systems. This tutorial aims to provide a comprehensive hands-on introduction for newcomers to the field of human activity recognition. It specifically focuses on activity recognition using on-body inertial sensors. We first discuss the key research challenges that human activity recognition shares with general pattern recognition and identify those challenges that are specific to human activity recognition. We then describe the concept of an Activity Recognition Chain (ARC) as a general-purpose framework for designing and evaluating activity recognition systems. We detail each component of the framework provide references to related research and introduce the best practice methods developed by the activity recognition research community. We conclude with the educational example problem of recognizing different hand gestures from inertial sensors attached to the upper and lower arm. We illustrate how each component of this framework can be implemented for this specific activity recognition problem and demonstrate how different implementations compare and how they impact overall recognition performance.;
RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response;Randomized Aggregatable Privacy-Preserving Ordinal Response or RAPPOR is a technology for crowdsourcing statistics from end-user client software anonymously with strong privacy guarantees. In short RAPPORs allow the forest of client data to be studied without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner RAPPOR provides the mechanisms for such collection as well as for efficient high-utility analysis of the collected data. In particular RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client and without linkability of their reports. This paper describes and motivates RAPPOR details its differential-privacy and utility guarantees discusses its practical deployment and properties in the face of different attack models and finally gives results of its application to both synthetic and real-world data.;
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security;This paper presents the design and implementation of SpotFi an accurate indoor localization system that can be deployed on commodity WiFi infrastructure. SpotFi only uses information that is already exposed by WiFi chips and does not require any hardware or firmware changes yet achieves the same accuracy as state-of-the-art localization systems. SpotFi makes two key technical contributions. First SpotFi incorporates super-resolution algorithms that can accurately compute the angle of arrival (AoA) of multipath components even when the access point (AP) has only three antennas. Second it incorporates novel filtering and estimation techniques to identify AoA of direct path between the localization target and AP by assigning values for each path depending on how likely the particular path is the direct path. Our experiments in a multipath rich indoor environment show that SpotFi achieves a median accuracy of 40 cm and is robust to indoor hindrances such as obstacles and multipath.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;This paper presents a full duplex radio design using signal inversion and adaptive cancellation. Signal inversion uses a simple design based on a balanced/unbalanced (Balun) transformer. This new design unlike prior work supports wideband and high power systems. In theory this new design has no limitation on bandwidth or power. In practice we find that the signal inversion technique alone can cancel at least 45dB across a 40MHz bandwidth. Further combining signal inversion cancellation with cancellation in the digital domain can reduce self-interference by up to 73dB for a 10MHz OFDM signal. This paper also presents a full duplex medium access control (MAC) design and evaluates it using a testbed of 5 prototype full duplex nodes. Full duplex reduces packet losses due to hidden terminals by up to 88%. Full duplex also mitigates unfair channel allocation in AP-based networks increasing fairness from 0.85 to 0.98 while improving downlink throughput by 110% and uplink throughput by 15%. These experimental results show that a re- design of the wireless network stack to exploit full duplex capability can result in significant improvements in network performance.;
Proceedings of the 17th Annual International Conference on Mobile Computing and Networking;TetGen is a C++ program for generating good quality tetrahedral meshes aimed to support numerical methods and scientific computing. The problem of quality tetrahedral mesh generation is challenged by many theoretical and practical issues. TetGen uses Delaunay-based algorithms which have theoretical guarantee of correctness. It can robustly handle arbitrary complex 3D geometries and is fast in practice. The source code of TetGen is freely available.This article presents the essential algorithms and techniques used to develop TetGen. The intended audience are researchers or developers in mesh generation or other related areas. It describes the key software components of TetGen including an efficient tetrahedral mesh data structure a set of enhanced local mesh operations (combination of flips and edge removal) and filtered exact geometric predicates. The essential algorithms include incremental Delaunay algorithms for inserting vertices constrained Delaunay algorithms for inserting constraints (edges and triangles) a new edge recovery algorithm for recovering constraints and a new constrained Delaunay refinement algorithm for adaptive quality tetrahedral mesh generation. Experimental examples as well as comparisons with other softwares are presented.;
DevoFlow: scaling flow management for high-performance networks;OpenFlow is a great concept but its original design imposes excessive overheads. It can simplify network and traffic management in enterprise and data center environments because it enables flow-level control over Ethernet switching and provides global visibility of the flows in the network. However such fine-grained control and visibility comes with costs: the switch-implementation costs of involving the switch's control-plane too often and the distributed-system costs of involving the OpenFlow controller too frequently both on flow setups and especially for statistics-gathering.In this paper we analyze these overheads and show that OpenFlow's current design cannot meet the needs of high-performance networks. We design and evaluate DevoFlow a modification of the OpenFlow model which gently breaks the coupling between control and global visibility in a way that maintains a useful amount of visibility without imposing unnecessary costs. We evaluate DevoFlow through simulations and find that it can load-balance data center traffic as well as fine-grained solutions without as much overhead: DevoFlow uses 10--53 times fewer flow table entries at an average switch and uses 10--42 times fewer control messages.;
Proceedings of the ACM SIGCOMM 2011 Conference;MapReduce advantages over parallel databases include storage-system independence and fine-grain fault tolerance for large jobs.;
PRIME: a novel processing-in-memory architecture for neural network computation in ReRAM-based main memory;"Processing-in-memory (PIM) is a promising solution to address the memory wall"" challenges for future computer systems. Prior proposed PIM architectures put additional computation logic in or near memory. The emerging metal-oxide resistive random access memory (ReRAM) has showed its potential to be used for main memory. Moreover with its crossbar array structure ReRAM can perform matrix-vector multiplication efficiently and has been widely studied to accelerate neural network (NN) applications. In this work we propose a novel PIM architecture called PRIME to accelerate NN applications in ReRAM based main memory. In PRIME a portion of ReRAM crossbar arrays can be configured as accelerators for NN applications or as normal memory for a larger memory space. We provide microarchitecture and circuit designs to enable the morphable functions with an insignificant area overhead. We also design a software/hardware interface for software developers to implement various NNs on PRIME. Benefiting from both the PIM architecture and the efficiency of using ReRAM for NN computation PRIME distinguishes itself from prior work on NN acceleration with significant performance improvement and energy saving. Our experimental results show that compared with a state-of-the-art neural processing unit design PRIME improves the performance by ~2360\texttimes{""";
Proceedings of the 43rd International Symposium on Computer Architecture;The process of increasing student exposure to computational thinking in K-12 is complex requiring systemic change teacher engagement and development of signifi cant resources. Collaboration with the computer science education community is vital to this effort.;
(Leveled) fully homomorphic encryption without bootstrapping;We present a novel approach to fully homomorphic encryption (FHE) that dramatically improves performance and bases security on weaker assumptions. A central conceptual contribution in our work is a new way of constructing leveled fully homomorphic encryption schemes (capable of evaluating arbitrary polynomial-size circuits) without Gentry's bootstrapping procedure.Specifically we offer a choice of FHE schemes based on the learning with error (LWE) or ring-LWE (RLWE) problems that have 2Î» security against known attacks. For RLWE we have:â€¢ A leveled FHE scheme that can evaluate L-level arithmetic circuits with \~{O;
Proceedings of the 3rd Innovations in Theoretical Computer Science Conference;Network virtualization is a powerful way to run multiple architectures or experiments simultaneously on a shared infrastructure. However making efficient use of the underlying resources requires effective techniques for virtual network embedding--mapping each virtual network to specific nodes and links in the substrate network. Since the general embedding problem is computationally intractable past research restricted the problem space to allow efficient solutions or focused on designing heuristic algorithms. In this paper we advocate a different approach: rethinking the design of the substrate network to enable simpler embedding algorithms and more efficient use of resources without restricting the problem space. In particular we simplify virtual link embedding by: i) allowing the substrate network to split a virtual link over multiple substrate paths and ii) employing path migration to periodically re-optimize the utilization of the substrate network. We also explore node-mapping algorithms that are customized to common classes of virtual-network topologies. Our simulation experiments show that path splitting path migrationand customized embedding algorithms enable a substrate network to satisfy a much larger mix of virtual networks;
Privacy-Preserving Deep Learning;Deep learning based on artificial neural networks is a very popular approach to modeling classifying and recognizing complex data such as images speech and text. The unprecedented accuracy of deep learning methods has turned them into the foundation of new AI-based services on the Internet. Commercial companies that collect user data on a large scale have been the main beneficiaries of this trend since the success of deep learning techniques is directly proportional to the amount of data available for training. Massive data collection required for deep learning presents obvious privacy issues. Users' personal highly sensitive data such as photos and voice recordings is kept indefinitely by the companies that collect it. Users can neither delete it nor restrict the purposes for which it is used. Furthermore centrally kept data is subject to legal subpoenas and extra-judicial surveillance. Many data owners--for example medical institutions that may want to apply deep learning methods to clinical records--are prevented by privacy and confidentiality concerns from sharing the data and thus benefitting from large-scale deep learning.In this paper we design implement and evaluate a practical system that enables multiple parties to jointly learn an accurate neural-network model for a given objective without sharing their input datasets. We exploit the fact that the optimization algorithms used in modern deep learning namely those based on stochastic gradient descent can be parallelized and executed asynchronously. Our system lets participants train independently on their own datasets and selectively share small subsets of their models' key parameters during training. This offers an attractive point in the utility/privacy tradeoff space: participants preserve the privacy of their respective data while still benefitting from other participants' models and thus boosting their learning accuracy beyond what is achievable solely on their own inputs. We demonstrate the accuracy of our privacy-preserving deep learning on benchmark datasets.;
Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security;In order to recommend products to users we must ultimately predict how a user will respond to a new product. To do so we must uncover the implicit tastes of each user as well as the properties of each product. For example in order to predict whether a user will enjoy Harry Potter it helps to identify that the book is about wizards as well as the user's level of interest in wizardry. User feedback is required to discover these latent product and user dimensions. Such feedback often comes in the form of a numeric rating accompanied by review text. However traditional methods often discard review text which makes user and product latent dimensions difficult to interpret since they ignore the very text that justifies a user's rating. In this paper we aim to combine latent rating dimensions (such as those of latent-factor recommender systems) with latent review topics (such as those learned by topic models like LDA). Our approach has several advantages. Firstly we obtain highly interpretable textual labels for latent rating dimensions which helps us to `justify' ratings with text. Secondly our approach more accurately predicts product ratings by harnessing the information present in review text this is especially true for new products and users who may have too few ratings to model their latent factors yet may still provide substantial information from the text of even a single review. Thirdly our discovered topics can be used to facilitate other tasks such as automated genre discovery and to identify useful and representative reviews.;
Proceedings of the 7th ACM Conference on Recommender Systems;Videos are a widely-used kind of resource for online learning. This paper presents an empirical study of how video production decisions affect student engagement in online educational videos. To our knowledge ours is the largest-scale study of video engagement to date using data from 6.9 million video watching sessions across four courses on the edX MOOC platform. We measure engagement by how long students are watching each video and whether they attempt to answer post-video assessment problems.Our main findings are that shorter videos are much more engaging that informal talking-head videos are more engaging that Khan-style tablet drawings are more engaging that even high-quality pre-recorded classroom lectures might not make for engaging online videos and that students engage differently with lecture and tutorial videos.Based upon these quantitative findings and qualitative insights from interviews with edX staff we developed a set of recommendations to help instructors and video producers take better advantage of the online video format. Finally to enable researchers to reproduce and build upon our findings we have made our anonymized video watching data set and analysis scripts public. To our knowledge ours is one of the first public data sets on MOOC resource usage.;
Proceedings of the First ACM Conference on Learning @ Scale Conference;As organizations start to use data-intensive cluster computing systems like Hadoop and Dryad for more applications there is a growing need to share clusters between users. However there is a conflict between fairness in scheduling and data locality (placing tasks on nodes that contain their input data). We illustrate this problem through our experience designing a fair scheduler for a 600-node Hadoop cluster at Facebook. To address the conflict between locality and fairness we propose a simple algorithm called delay scheduling: when the job that should be scheduled next according to fairness cannot launch a local task it waits for a small amount of time letting other jobs launch tasks instead. We find that delay scheduling achieves nearly optimal data locality in a variety of workloads and can increase throughput by up to 2x while preserving fairness. In addition the simplicity of delay scheduling makes it applicable under a wide variety of scheduling policies beyond fair sharing.;
Proceedings of the 5th European Conference on Computer Systems;Online social networks have become extremely popular numerous sites allow users to interact and share content using social links. Users of these networks often establish hundreds to even thousands of social links with other users. Recently researchers have suggested examining the activity network - a network that is based on the actual interaction between users rather than mere friendship - to distinguish between strong and weak links. While initial studies have led to insights on how an activity network is structurally different from the social network itself a natural and important aspect of the activity network has been disregarded: the fact that over time social links can grow stronger or weaker. In this paper we study the evolution of activity between users in the Facebook social network to capture this notion. We find that links in the activity network tend to come and go rapidly over time and the strength of ties exhibits a general decreasing trend of activity as the social network link ages. For example only 30% of Facebook user pairs interact consistently from one month to the next. Interestingly we also find that even though the links of the activity network change rapidly over time many graph-theoretic properties of the activity network remain unchanged.;
Proceedings of the 2nd ACM Workshop on Online Social Networks;Deep neural networks (DNNs) are one of the most prominent technologies of our time as they achieve state-of-the-art performance in many machine learning tasks including but not limited to image classification text mining and speech processing. However recent research on DNNs has indicated ever-increasing concern on the robustness to adversarial examples especially for security-critical tasks such as traffic sign identification for autonomous driving. Studies have unveiled the vulnerability of a well-trained DNN by demonstrating the ability of generating barely noticeable (to both human and machines) adversarial images that lead to misclassification. Furthermore researchers have shown that these adversarial images are highly transferable by simply training and attacking a substitute model built upon the target model known as a black-box attack to DNNs.Similar to the setting of training substitute models in this paper we propose an effective black-box attack that also only has access to the input (images) and the output (confidence scores) of a targeted DNN. However different from leveraging attack transferability from substitute models we propose zeroth order optimization (ZOO) based attacks to directly estimate the gradients of the targeted DNN for generating adversarial examples. We use zeroth order stochastic coordinate descent along with dimension reduction hierarchical attack and importance sampling techniques to efficiently attack black-box models. By exploiting zeroth order optimization improved attacks to the targeted DNN can be accomplished sparing the need for training substitute models and avoiding the loss in attack transferability. Experimental results on MNIST CIFAR10 and ImageNet show that the proposed ZOO attack is as effective as the state-of-the-art white-box attack (e.g. Carlini and Wagner's attack) and significantly outperforms existing black-box attacks via substitute models.;
Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security;Machine learning is enabling a myriad innovations including new algorithms for cancer diagnosis and self-driving cars. The broad use of machine learning makes it important to understand the extent to which machine-learning algorithms are subject to attack particularly when used in applications where physical security or safety is at risk.In this paper we focus on facial biometric systems which are widely used in surveillance and access control. We define and investigate a novel class of attacks: attacks that are physically realizable and inconspicuous and allow an attacker to evade recognition or impersonate another individual. We develop a systematic method to automatically generate such attacks which are realized through printing a pair of eyeglass frames. When worn by the attacker whose image is supplied to a state-of-the-art face-recognition algorithm the eyeglasses allow her to evade being recognized or to impersonate another individual. Our investigation focuses on white-box face-recognition systems but we also demonstrate how similar techniques can be used in black-box scenarios as well as to avoid face detection.;
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;Todayâ€™s smartphone operating systems frequently fail to provide users with visibility into how third-party applications collect and share their private data. We address these shortcomings with TaintDroid an efficient system-wide dynamic taint tracking and analysis system capable of simultaneously tracking multiple sources of sensitive data. TaintDroid enables realtime analysis by leveraging Androidâ€™s virtualized execution environment. TaintDroid incurs only 32% performance overhead on a CPU-bound microbenchmark and imposes negligible overhead on interactive third-party applications. Using TaintDroid to monitor the behavior of 30 popular third-party Android applications in our 2010 study we found 20 applications potentially misused usersâ€™ private information so did a similar fraction of the tested applications in our 2012 study. Monitoring the flow of privacy-sensitive data with TaintDroid provides valuable input for smartphone users and security service firms seeking to identify misbehaving applications.;
Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems;The practice of crowdsourcing is transforming the Web and giving rise to a new field.;
Algorand: Scaling Byzantine Agreements for Cryptocurrencies;Algorand is a new cryptocurrency that confirms transactions with latency on the order of a minute while scaling to many users. Algorand ensures that users never have divergent views of confirmed transactions even if some of the users are malicious and the network is temporarily partitioned. In contrast existing cryptocurrencies allow for temporary forks and therefore require a long time on the order of an hour to confirm transactions with high confidence.Algorand uses a new Byzantine Agreement (BA) protocol to reach consensus among users on the next set of transactions. To scale the consensus to many users Algorand uses a novel mechanism based on Verifiable Random Functions that allows users to privately check whether they are selected to participate in the BA to agree on the next set of transactions and to include a proof of their selection in their network messages. In Algorand's BA protocol users do not keep any private state except for their private keys which allows Algorand to replace participants immediately after they send a message. This mitigates targeted attacks on chosen participants after their identity is revealed.We implement Algorand and evaluate its performance on 1000 EC2 virtual machines simulating up to 500000 users. Experimental results show that Algorand confirms transactions in under a minute achieves 125x Bitcoin's throughput and incurs almost no penalty for scaling to more users.;
Proceedings of the 26th Symposium on Operating Systems Principles;Urbanization's rapid progress has modernized many people's lives but also engendered big issues such as traffic congestion energy consumption and pollution. Urban computing aims to tackle these issues by using the data that has been generated in cities (e.g. traffic flow human mobility and geographical data). Urban computing connects urban sensing data management data analytics and service providing into a recurrent process for an unobtrusive and continuous improvement of people's lives city operation systems and the environment. Urban computing is an interdisciplinary field where computer sciences meet conventional city-related fields like transportation civil engineering environment economy ecology and sociology in the context of urban spaces. This article first introduces the concept of urban computing discussing its general framework and key challenges from the perspective of computer sciences. Second we classify the applications of urban computing into seven categories consisting of urban planning transportation the environment energy social economy and public safety and security presenting representative scenarios in each category. Third we summarize the typical technologies that are needed in urban computing into four folds which are about urban sensing urban data management knowledge fusion across heterogeneous data and urban data visualization. Finally we give an outlook on the future of urban computing suggesting a few research topics that are somehow missing in the community.;
Dcell: a scalable and fault-tolerant network structure for data centers;A fundamental challenge in data center networking is how to efficiently interconnect an exponentially increasing number of servers. This paper presents DCell a novel network structure that has many desirable features for data center networking. DCell is a recursively defined structure in which a high-level DCell is constructed from many low-level DCells and DCells at the same level are fully connected with one another. DCell scales doubly exponentially as the node degree increases. DCell is fault tolerant since it does not have single point of failure and its distributed fault-tolerant routing protocol performs near shortest-path routing even in the presence of severe link or node failures. DCell also provides higher network capacity than the traditional tree-based structure for various types of services. Furthermore DCell can be incrementally expanded and a partial DCell provides the same appealing features. Results from theoretical analysis simulations and experiments show that DCell is a viable interconnection structure for data centers.;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;Many surface computing prototypes have employed gestures created by system designers. Although such gestures are appropriate for early investigations they are not necessarily reflective of user behavior. We present an approach to designing tabletop gestures that relies on eliciting gestures from non-technical users by first portraying the effect of a gesture and then asking users to perform its cause. In all 1080 gestures from 20 participants were logged analyzed and paired with think-aloud data for 27 commands performed with 1 and 2 hands. Our findings indicate that users rarely care about the number of fingers they employ that one hand is preferred to two that desktop idioms strongly influence users' mental models and that some commands elicit little gestural agreement suggesting the need for on-screen widgets. We also present a complete user-defined gesture set quantitative agreement scores implications for surface technology and a taxonomy of surface gestures. Our results will help designers create better gesture sets informed by user behavior.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;We present SWAN a system that boosts the utilization of inter-datacenter networks by centrally controlling when and how much traffic each service sends and frequently re-configuring the network's data plane to match current traffic demand. But done simplistically these re-configurations can also cause severe transient congestion because different switches may apply updates at different times. We develop a novel technique that leverages a small amount of scratch capacity on links to apply updates in a provably congestion-free manner without making any assumptions about the order and timing of updates at individual switches. Further to scale to large networks in the face of limited forwarding table capacity SWAN greedily selects a small set of entries that can best satisfy current demand. It updates this set without disrupting traffic by leveraging a small amount of scratch capacity in forwarding tables. Experiments using a testbed prototype and data-driven simulations of two production networks show that SWAN carries 60% more traffic than the current practice.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;In many commercial systems the 'best bet' recommendations are shown but the predicted rating values are not. This is usually referred to as a top-N recommendation task where the goal of the recommender system is to find a few specific items which are supposed to be most appealing to the user. Common methodologies based on error metrics (such as RMSE) are not a natural fit for evaluating the top-N recommendation task. Rather top-N performance can be directly measured by alternative methodologies based on accuracy metrics (such as precision/recall).An extensive evaluation of several state-of-the art recommender algorithms suggests that algorithms optimized for minimizing RMSE do not necessarily perform as expected in terms of top-N recommendation task. Results show that improvements in RMSE often do not translate into accuracy improvements. In particular a naive non-personalized algorithm can outperform some common recommendation approaches and almost match the accuracy of sophisticated algorithms. Another finding is that the very few top popular items can skew the top-N performance. The analysis points out that when evaluating a recommender algorithm on the top-N recommendation task the test set should be chosen carefully in order to not bias accuracy metrics towards non-personalized solutions. Finally we offer practitioners new variants of two collaborative filtering algorithms that regardless of their RMSE significantly outperform other recommender algorithms in pursuing the top-N recommendation task with offering additional practical advantages. This comes at surprise given the simplicity of these two methods.;
Proceedings of the Fourth ACM Conference on Recommender Systems;Factorization approaches provide high accuracy in several important prediction problems for example recommender systems. However applying factorization approaches to a new prediction problem is a nontrivial task and requires a lot of expert knowledge. Typically a new model is developed a learning algorithm is derived and the approach has to be implemented.Factorization machines (FM) are a generic approach since they can mimic most factorization models just by feature engineering. This way factorization machines combine the generality of feature engineering with the superiority of factorization models in estimating interactions between categorical variables of large domain. libFM is a software implementation for factorization machines that features stochastic gradient descent (SGD) and alternating least-squares (ALS) optimization as well as Bayesian inference using Markov Chain Monto Carlo (MCMC). This article summarizes the recent research on factorization machines both in terms of modeling and learning provides extensions for the ALS and MCMC algorithms and describes the software tool libFM.;
From RSSI to CSI: Indoor localization via channel response;The spatial features of emitted wireless signals are the basis of location distinction and determination for wireless indoor localization. Available in mainstream wireless signal measurements the Received Signal Strength Indicator (RSSI) has been adopted in vast indoor localization systems. However it suffers from dramatic performance degradation in complex situations due to multipath fading and temporal dynamics.Break-through techniques resort to finer-grained wireless channel measurement than RSSI. Different from RSSI the PHY layer power feature channel response is able to discriminate multipath characteristics and thus holds the potential for the convergence of accurate and pervasive indoor localization. Channel State Information (CSI reflecting channel response in 802.11 a/g/n) has attracted many research efforts and some pioneer works have demonstrated submeter or even centimeter-level accuracy. In this article we survey this new trend of channel response in localization. The differences between CSI and RSSI are highlighted with respect to network layering time resolution frequency resolution stability and accessibility. Furthermore we investigate a large body of recent works and classify them overall into three categories according to how to use CSI. For each category we emphasize the basic principles and address future directions of research in this new and largely open area.;
Workload analysis of a large-scale key-value store;Key-value stores are a vital component in many scale-out enterprises including social networks online retail and risk analysis. Accordingly they are receiving increased attention from the research community in an effort to improve their performance scalability reliability cost and power consumption. To be effective such efforts require a detailed understanding of realistic key-value workloads. And yet little is known about these workloads outside of the companies that operate them. This paper aims to address this gap.To this end we have collected detailed traces from Facebook's Memcached deployment arguably the world's largest. The traces capture over 284 billion requests from five different Memcached use cases over several days. We analyze the workloads from multiple angles including: request composition size and rate cache efficacy temporal patterns and application use cases. We also propose a simple model of the most representative trace to enable the generation of more realistic synthetic workloads by the community.Our analysis details many characteristics of the caching workload. It also reveals a number of surprises: a GET/SET ratio of 30:1 that is higher than assumed in the literature some applications of Memcached behave more like persistent storage than a cache strong locality metrics such as keys accessed many millions of times a day do not always suffice for a high hit rate and there is still room for efficiency and hit rate improvements in Memcached's implementation. Toward the last point we make several suggestions that address the exposed deficiencies.;
Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE Joint International Conference on Measurement and Modeling of Computer Systems;Software systems dealing with distributed applications in changing environments normally require human supervision to continue operation in all conditions. These (re-)configuring troubleshooting and in general maintenance tasks lead to costly and time-consuming procedures during the operating phase. These problems are primarily due to the open-loop structure often followed in software development. Therefore there is a high demand for management complexity reduction management automation robustness and achieving all of the desired quality requirements within a reasonable cost and time range during operation. Self-adaptive software is a response to these demands it is a closed-loop system with a feedback loop aiming to adjust itself to changes during its operation. These changes may stem from the software system's self (internal causes e.g. failure) or context (external events e.g. increasing requests from users). Such a system is required to monitor itself and its context detect significant changes decide how to react and act to execute such decisions. These processes depend on adaptation properties (called self-* properties) domain characteristics (context information or models) and preferences of stakeholders. Noting these requirements it is widely believed that new models and frameworks are needed to design self-adaptive software. This survey article presents a taxonomy based on concerns of adaptation that is how what when and where towards providing a unified view of this emerging area. Moreover as adaptive systems are encountered in many disciplines it is imperative to learn from the theories and models developed in these other areas. This survey article presents a landscape of research in self-adaptive software by highlighting relevant disciplines and some prominent research projects. This landscape helps to identify the underlying research gaps and elaborates on the corresponding challenges.;
Finding your Way in the Fog: Towards a Comprehensive Definition of Fog Computing;"The cloud is migrating to the edge of the network where routers themselves may become the virtualisation infrastructure in an evolution labelled as the fog"". However many other complementary technologies are reaching a high level of maturity. Their interplay may dramatically shift the information and communication technology landscape in the following years bringing separate technologies into a common ground. This paper offers a comprehensive definition of the fog comprehending technologies as diverse as cloud sensor networks peer-to-peer networks network virtualisation functions or configuration management techniques. We highlight the main challenges faced by this potentially breakthrough technology amalgamation.""";
Model Cards for Model Reporting;Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement medicine education and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper we propose a framework that we call model cards to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions such as across different cultural demographic or phenotypic groups (e.g. race geographic location sex Fitzpatrick skin type [15]) and intersectional groups (e.g. age and race or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used details of the performance evaluation procedures and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing this framework can be used to document any trained machine learning model. To solidify the concept we provide cards for two supervised models: One trained to detect smiling faces in images and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.;
Proceedings of the Conference on Fairness Accountability and Transparency;Radio Frequency (RF) fingerprinting based onWiFi or cellular signals has been a popular approach to indoor localization. However its adoption in the real world has been stymied by the need for sitespecific calibration i.e. the creation of a training data set comprising WiFi measurements at known locations in the space of interest. While efforts have been made to reduce this calibration effort using modeling the need for measurements from known locations still remains a bottleneck. In this paper we present Zee -- a system that makes the calibration zero-effort by enabling training data to be crowdsourced without any explicit effort on the part of users. Zee leverages the inertial sensors (e.g. accelerometer compass gyroscope) present in the mobile devices such as smartphones carried by users to track them as they traverse an indoor environment while simultaneously performing WiFi scans. Zee is designed to run in the background on a device without requiring any explicit user participation. The only site-specific input that Zee depends on is a map showing the pathways (e.g. hallways) and barriers (e.g. walls). A significant challenge that Zee surmounts is to track users without any a priori user-specific knowledge such as the user's initial location stride-length or phone placement. Zee employs a suite of novel techniques to infer location over time: (a) placement-independent step counting and orientation estimation (b) augmented particle filtering to simultaneously estimate location and user-specific walk characteristics such as the stride length(c) back propagation to go back and improve the accuracy of ocalization in the past and (d) WiFi-based particle initialization to enable faster convergence. We present an evaluation of Zee in a large office building.;
Proceedings of the 18th Annual International Conference on Mobile Computing and Networking;Image processing pipelines combine the challenges of stencil computations and stream programs. They are composed of large graphs of different stencil stages as well as complex reductions and stages with global or data-dependent access patterns. Because of their complex structure the performance difference between a naive implementation of a pipeline and an optimized one is often an order of magnitude. Efficient implementations require optimization of both parallelism and locality but due to the nature of stencils there is a fundamental tension between parallelism locality and introducing redundant recomputation of shared values.We present a systematic model of the tradeoff space fundamental to stencil pipelines a schedule representation which describes concrete points in this space for each stage in an image processing pipeline and an optimizing compiler for the Halide image processing language that synthesizes high performance implementations from a Halide algorithm and a schedule. Combining this compiler with stochastic search over the space of schedules enables terse composable programs to achieve state-of-the-art performance on a wide range of real image processing pipelines and across different hardware architectures including multicores with SIMD and heterogeneous CPU+GPU execution. From simple Halide programs written in a few hours we demonstrate performance up to 5x faster than hand-tuned C intrinsics and CUDA implementations optimized by experts over weeks or months for image processing applications beyond the reach of past automatic compilers.;
Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation;Existing ABR algorithms face a significant challenge in estimating future capacity: capacity can vary widely over time a phenomenon commonly observed in commercial services. In this work we suggest an alternative approach: rather than presuming that capacity estimation is required it is perhaps better to begin by using only the buffer and then ask when capacity estimation is needed. We test the viability of this approach through a series of experiments spanning millions of real users in a commercial service. We start with a simple design which directly chooses the video rate based on the current buffer occupancy. Our own investigation reveals that capacity estimation is unnecessary in steady state however using simple capacity estimation (based on immediate past throughput) is important during the startup phase when the buffer itself is growing from empty. This approach allows us to reduce the rebuffer rate by 10-20% compared to Netflix's then-default ABR algorithm while delivering a similar average video rate and a higher video rate in steady state.;
Proceedings of the 2014 ACM Conference on SIGCOMM;A power grid is a complex system connecting electric power generators to consumers through power transmission and distribution networks across a large geographical area. System monitoring is necessary to ensure the reliable operation of power grids and state estimation is used in system monitoring to best estimate the power grid state through analysis of meter measurements and power system models. Various techniques have been developed to detect and identify bad measurements including the interacting bad measurements introduced by arbitrary non-random causes. At first glance it seems that these techniques can also defeat malicious measurements injected by attackers.In this paper we present a new class of attacks called false data injection attacks against state estimation in electric power grids. We show that an attacker can exploit the configuration of a power system to launch such attacks to successfully introduce arbitrary errors into certain state variables while bypassing existing techniques for bad measurement detection. Moreover we look at two realistic attack scenarios in which the attacker is either constrained to some specific meters (due to the physical protection of the meters) or limited in the resources required to compromise meters. We show that the attacker can systematically and efficiently construct attack vectors in both scenarios which can not only change the results of state estimation but also modify the results in arbitrary ways. We demonstrate the success of these attacks through simulation using IEEE test systems. Our results indicate that security protection of the electric power grid must be revisited when there are potentially malicious attacks.;
Proceedings of the 16th ACM Conference on Computer and Communications Security;"In this paper we examine a number of SQL and socalled NoSQL"" data stores designed to scale simple OLTP-style application loads over many servers. Originally motivated by Web 2.0 applications these systems are designed to scale to thousands or millions of users doing updates as well as reads in contrast to traditional DBMSs and data warehouses. We contrast the new systems on their data model consistency mechanisms storage mechanisms durability guarantees availability query support and other dimensions. These systems typically sacrifice some of these dimensions e.g. database-wide transaction consistency in order to achieve others e.g. higher availability and scalability.""";
Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;This paper reports on the development and formal verification (proof of semantic preservation) of CompCert a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.;
Going Deeper with Embedded FPGA Platform for Convolutional Neural Network;In recent years convolutional neural network (CNN) based methods have achieved great success in a large number of applications and have been among the most powerful and widely used techniques in computer vision. However CNN-based methods are com-putational-intensive and resource-consuming and thus are hard to be integrated into embedded systems such as smart phones smart glasses and robots. FPGA is one of the most promising platforms for accelerating CNN but the limited bandwidth and on-chip memory size limit the performance of FPGA accelerator for CNN.In this paper we go deeper with the embedded FPGA platform on accelerating CNNs and propose a CNN accelerator design on embedded FPGA for Image-Net large-scale image classification. We first present an in-depth analysis of state-of-the-art CNN models and show that Convolutional layers are computational-centric and Fully-Connected layers are memory-centric.Then the dynamic-precision data quantization method and a convolver design that is efficient for all layer types in CNN are proposed to improve the bandwidth and resource utilization. Results show that only 0.4% accuracy loss is introduced by our data quantization flow for the very deep VGG16 model when 8/4-bit quantization is used. A data arrangement method is proposed to further ensure a high utilization of the external memory bandwidth. Finally a state-of-the-art CNN VGG16-SVD is implemented on an embedded FPGA platform as a case study. VGG16-SVD is the largest and most accurate network that has been implemented on FPGA end-to-end so far. The system on Xilinx Zynq ZC706 board achieves a frame rate at 4.45 fps with the top-5 accuracy of 86.66% using 16-bit quantization. The average performance of convolutional layers and the full CNN is 187.8 GOP/s and 137.0 GOP/s under 150MHz working frequency which outperform previous approaches significantly.;
Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays;This article reviews the state-of-the-art in overlapping community detection algorithms quality measures and benchmarks. A thorough comparison of different algorithms (a total of fourteen) is provided. In addition to community-level evaluation we propose a framework for evaluating algorithms' ability to detect overlapping nodes which helps to assess overdetection and underdetection. After considering community-level detection performance measured by normalized mutual information the Omega index and node-level detection performance measured by F-score we reached the following conclusions. For low overlapping density networks SLPA OSLOM Game and COPRA offer better performance than the other tested algorithms. For networks with high overlapping density and high overlapping diversity both SLPA and Game provide relatively stable performance. However test results also suggest that the detection in such networks is still not yet fully resolved. A common feature observed by various algorithms in real-world networks is the relatively small fraction of overlapping nodes (typically less than 30%) each of which belongs to only 2 or 3 communities.;
Android permissions demystified;Android provides third-party applications with an extensive API that includes access to phone hardware settings and user data. Access to privacy- and security-relevant parts of the API is controlled with an install-time application permission system. We study Android applications to determine whether Android developers follow least privilege with their permission requests. We built Stowaway a tool that detects overprivilege in compiled Android applications. Stowaway determines the set of API calls that an application uses and then maps those API calls to permissions. We used automated testing tools on the Android API in order to build the permission map that is necessary for detecting overprivilege. We apply Stowaway to a set of 940 applications and find that about one-third are overprivileged. We investigate the causes of overprivilege and find evidence that developers are trying to follow least privilege but sometimes fail due to insufficient API documentation.;
Proceedings of the 18th ACM Conference on Computer and Communications Security;We present the design and implementation of an automatic polyhedral source-to-source transformation framework that can optimize regular programs (sequences of possibly imperfectly nested loops) for parallelism and locality simultaneously. Through this work we show the practicality of analytical model-driven automatic transformation in the polyhedral model -- far beyond what is possible by current production compilers. Unlike previous works our approach is an end-to-end fully automatic one driven by an integer linear optimization framework that takes an explicit view of finding good ways of tiling for parallelism and locality using affine transformations. The framework has been implemented into a tool to automatically generate OpenMP parallel code from C program sections. Experimental results from the tool show very high speedups for local and parallel execution on multi-cores over state-of-the-art compiler frameworks from the research community as well as the best native production compilers. The system also enables the easy use of powerful empirical/iterative optimization for general arbitrarily nested loop sequences.;
Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation;In this paper we present a measurement study of the energy consumption characteristics of three widespread mobile networking technologies: 3G GSM and WiFi. We find that 3G and GSM incur a high tail energy overhead because of lingering in high power states after completing a transfer. Based on these measurements we develop a model for the energy consumed by network activity for each technology.Using this model we develop TailEnder a protocol that reduces energy consumption of common mobile applications. For applications that can tolerate a small delay such as e-mail TailEnder schedules transfers so as to minimize the cumulative energy consumed meeting user-specified deadlines. We show that the TailEnder scheduling algorithm is within a factor 2x of the optimal and show that any online algorithm can at best be within a factor 1.62x of the optimal. For applications like web search that can benefit from prefetching TailEnder aggressively prefetches several times more data and improves user-specified response times while consuming less energy. We evaluate the benefits of TailEnder for three different case study applications - email news feeds and web search - based on real user logs and show significant reduction in energy consumption in each case. Experiments conducted on the mobile phone show that TailEnder can download 60% more news feed updates and download search results for more than 50% of web queries compared to using the default policy.;
Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement;Online applications are vulnerable to theft of sensitive information because adversaries can exploit software bugs to gain access to private data and because curious or malicious administrators may capture and leak data. CryptDB is a system that provides practical and provable confidentiality in the face of these attacks for applications backed by SQL databases. It works by executing SQL queries over encrypted data using a collection of efficient SQL-aware encryption schemes. CryptDB can also chain encryption keys to user passwords so that a data item can be decrypted only by using the password of one of the users with access to that data. As a result a database administrator never gets access to decrypted data and even if all servers are compromised an adversary cannot decrypt the data of any user who is not logged in. An analysis of a trace of 126 million SQL queries from a production MySQL server shows that CryptDB can support operations over encrypted data for 99.5% of the 128840 columns seen in the trace. Our evaluation shows that CryptDB has low overhead reducing throughput by 14.5% for phpBB a web forum application and by 26% for queries from TPC-C compared to unmodified MySQL. Chaining encryption keys to user passwords requires 11--13 unique schema annotations to secure more than 20 sensitive fields and 2--7 lines of source code changes for three multi-user web applications.;
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles;"We analyze microblog posts generated during two recent concurrent emergency events in North America via Twitter a popular microblogging service. We focus on communications broadcast by people who were on the ground"" during the Oklahoma Grassfires of April 2009 and the Red River Floods that occurred in March and April 2009 and identify information that may contribute to enhancing situational awareness (SA). This work aims to inform next steps for extracting useful relevant information during emergencies using information extraction (IE) techniques.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;User-perceived quality-of-experience (QoE) is critical in Internet video applications as it impacts revenues for content providers and delivery systems. Given that there is little support in the network for optimizing such measures bottlenecks could occur anywhere in the delivery system. Consequently a robust bitrate adaptation algorithm in client-side players is critical to ensure good user experience. Previous studies have shown key limitations of state-of-art commercial solutions and proposed a range of heuristic fixes. Despite the emergence of several proposals there is still a distinct lack of consensus on: (1) How best to design this client-side bitrate adaptation logic (e.g. use rate estimates vs. buffer occupancy) (2) How well specific classes of approaches will perform under diverse operating regimes (e.g. high throughput variability) or (3) How do they actually balance different QoE objectives (e.g. startup delay vs. rebuffering). To this end this paper makes three key technical contributions. First to bring some rigor to this space we develop a principled control-theoretic model to reason about a broad spectrum of strategies. Second we propose a novel model predictive control algorithm that can optimally combine throughput and buffer occupancy information to outperform traditional approaches. Third we present a practical implementation in a reference video player to validate our approach using realistic trace-driven emulations.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;We consider the problem of monitoring road and traffic conditions in a city. Prior work in this area has required the deployment of dedicated sensors on vehicles and/or on the roadside or the tracking of mobile phones by service providers. Furthermore prior work has largely focused on the developed world with its relatively simple traffic flow patterns. In fact traffic flow in cities of the developing regions which comprise much of the world tends to be much more complex owing to varied road conditions (e.g. potholed roads) chaotic traffic (e.g. a lot of braking and honking) and a heterogeneous mix of vehicles (2-wheelers 3-wheelers cars buses etc.).To monitor road and traffic conditions in such a setting we present Nericell a system that performs rich sensing by piggybacking on smartphones that users carry with them in normal course. In this paper we focus specifically on the sensing component which uses the accelerometer microphone GSM radio and/or GPS sensors in these phones to detect potholes bumps braking and honking. Nericell addresses several challenges including virtually reorienting the accelerometer on a phone that is at an arbitrary orientation and performing honk detection and localization in an energy efficient manner. We also touch upon the idea of triggered sensing where dissimilar sensors are used in tandem to conserve energy. We evaluate the effectiveness of the sensing functions in Nericell based on experiments conducted on the roads of Bangalore with promising results.;
Proceedings of the 6th ACM Conference on Embedded Network Sensor Systems;Emerging scale-out workloads require extensive amounts of computational resources. However data centers using modern server hardware face physical constraints in space and power limiting further expansion and calling for improvements in the computational density per server and in the per-operation energy. Continuing to improve the computational resources of the cloud while staying within physical constraints mandates optimizing server efficiency to ensure that server hardware closely matches the needs of scale-out workloads.In this work we introduce CloudSuite a benchmark suite of emerging scale-out workloads. We use performance counters on modern servers to study scale-out workloads finding that today's predominant processor micro-architecture is inefficient for running these workloads. We find that inefficiency comes from the mismatch between the workload needs and modern processors particularly in the organization of instruction and data memory systems and the processor core micro-architecture. Moreover while today's predominant micro-architecture is inefficient when executing scale-out workloads we find that continuing the current trends will further exacerbate the inefficiency in the future. In this work we identify the key micro-architectural needs of scale-out workloads calling for a change in the trajectory of server processors that would lead to improved computational density and power efficiency in data centers.;
Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems;Surprisingly console logs rarely help operators detect problems in large-scale datacenter services for they often consist of the voluminous intermixing of messages from many software components written by independent developers. We propose a general methodology to mine this rich source of information to automatically detect system runtime problems. We first parse console logs by combining source code analysis with information retrieval to create composite features. We then analyze these features using machine learning to detect operational problems. We show that our method enables analyses that are impossible with previous methods because of its superior ability to create sophisticated features. We also show how to distill the results of our analysis to an operator-friendly one-page decision tree showing the critical messages associated with the detected problems. We validate our approach using the Darkstar online game server and the Hadoop File System where we detect numerous real problems with high accuracy and few false positives. In the Hadoop case we are able to analyze 24 million lines of console logs in 3 minutes. Our methodology works on textual console logs of any size and requires no changes to the service software no human input and no knowledge of the software's internals.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;We explore the nature of traffic in data centers designed to support the mining of massive data sets. We instrument the servers to collect socket-level logs with negligible performance impact. In a 1500 server operational cluster we thus amass roughly a petabyte of measurements over two months from which we obtain and report detailed views of traffic and congestion conditions and patterns. We further consider whether traffic matrices in the cluster might be obtained instead via tomographic inference from coarser-grained counter data.;
Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement;Recent advances in Deep Neural Networks (DNNs) have led to the development of DNN-driven autonomous cars that using sensors like camera LiDAR etc. can drive without any human intervention. Most major manufacturers including Tesla GM Ford BMW and Waymo/Google are working on building and testing different types of autonomous vehicles. The lawmakers of several US states including California Texas and New York have passed new legislation to fast-track the process of testing and deployment of autonomous vehicles on their roads.However despite their spectacular progress DNNs just like traditional software often demonstrate incorrect or unexpected corner-case behaviors that can lead to potentially fatal collisions. Several such real-world accidents involving autonomous cars have already happened including one which resulted in a fatality. Most existing testing techniques for DNN-driven vehicles are heavily dependent on the manual collection of test data under different driving conditions which become prohibitively expensive as the number of test conditions increases.In this paper we design implement and evaluate DeepTest a systematic testing tool for automatically detecting erroneous behaviors of DNN-driven vehicles that can potentially lead to fatal crashes. First our tool is designed to automatically generated test cases leveraging real-world changes in driving conditions like rain fog lighting conditions etc. DeepTest systematically explore different parts of the DNN logic by generating test inputs that maximize the numbers of activated neurons. DeepTest found thousands of erroneous behaviors under different realistic driving conditions (e.g. blurring rain fog etc.) many of which lead to potentially fatal crashes in three top performing DNNs in the Udacity self-driving car challenge.;
Proceedings of the 40th International Conference on Software Engineering;With the recent advent of 4G LTE networks there has been increasing interest to better understand the performance and power characteristics compared with 3G/WiFi networks. In this paper we take one of the first steps in this direction.Using a publicly deployed tool we designed for Android called 4GTest attracting more than 3000 users within 2 months and extensive local experiments we study the network performance of LTE networks and compare with other types of mobile networks. We observe LTE generally has significantly higher downlink and uplink throughput than 3G and even WiFi with a median value of 13Mbps and 6Mbps respectively. We develop the first empirically derived comprehensive power model of a commercial LTE network with less than 6% error rate and state transitions matching the specifications. Using a comprehensive data set consisting of 5-month traces of 20 smartphone users we carefully investigate the energy usage in 3G LTE and WiFi networks and evaluate the impact of configuring LTE-related parameters. Despite several new power saving improvements we find that LTE is as much as 23 times less power efficient compared with WiFi and even less power efficient than 3G based on the user traces and the long high power tail is found to be a key contributor. In addition we perform case studies of several popular applications on Android in LTE and identify that the performance bottleneck for web-based applications lies less in the network compared to our previous study in 3G [24]. Instead the device's processing power despite the significant improvement compared to our analysis two years ago becomes more of a bottleneck.;
Proceedings of the 10th International Conference on Mobile Systems Applications and Services;Deep Learning has recently become hugely popular in machine learning for its ability to solve end-to-end learning systems in which the features and the classifiers are learned simultaneously providing significant improvements in classification accuracy in the presence of highly-structured and large databases.Its success is due to a combination of recent algorithmic breakthroughs increasingly powerful computers and access to significant amounts of data.Researchers have also considered privacy implications of deep learning. Models are typically trained in a centralized manner with all the data being processed by the same training algorithm. If the data is a collection of users' private data including habits personal pictures geographical positions interests and more the centralized server will have access to sensitive information that could potentially be mishandled. To tackle this problem collaborative deep learning models have recently been proposed where parties locally train their deep learning structures and only share a subset of the parameters in the attempt to keep their respective training sets private. Parameters can also be obfuscated via differential privacy (DP) to make information extraction even more challenging as proposed by Shokri and Shmatikov at CCS'15.Unfortunately we show that any privacy-preserving collaborative deep learning is susceptible to a powerful attack that we devise in this paper. In particular we show that a distributed federated or decentralized deep learning approach is fundamentally broken and does not protect the training sets of honest participants. The attack we developed exploits the real-time nature of the learning process that allows the adversary to train a Generative Adversarial Network (GAN) that generates prototypical samples of the targeted training set that was meant to be private (the samples generated by the GAN are intended to come from the same distribution as the training data). Interestingly we show that record-level differential privacy applied to the shared parameters of the model as suggested in previous work is ineffective (i.e. record-level DP is not designed to address our attack).;
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security;Both recognizing human behavior and understanding a user's mobility from sensor data are critical issues in ubiquitous computing systems. As a kind of user behavior the transportation modes such as walking driving etc. that a user takes can enrich the user's mobility with informative knowledge and provide pervasive computing systems with more context information. In this paper we propose an approach based on supervised learning to infer people's motion modes from their GPS logs. The contribution of this work lies in the following two aspects. On one hand we identify a set of sophisticated features which are more robust to traffic condition than those other researchers ever used. On the other hand we propose a graph-based post-processing algorithm to further improve the inference performance. This algorithm considers both the commonsense constraint of real world and typical user behavior based on location in a probabilistic manner. Using the GPS logs collected by 65 people over a period of 10 months we evaluated our approach via a set of experiments. As a result based on the change point-based segmentation method and Decision Tree-based inference model the new features brought an eight percent improvement in inference accuracy over previous result and the graph-based post-processing achieve a further four percent enhancement.;
Proceedings of the 10th International Conference on Ubiquitous Computing;Blockchain technology has the potential to revolutionize applications and redefine the digital economy.;
DeepXplore: Automated Whitebox Testing of Deep Learning Systems;Deep learning (DL) systems are increasingly deployed in safety- and security-critical domains including self-driving cars and malware detection where the correctness and predictability of a system's behavior for corner case inputs are of great importance. Existing DL testing depends heavily on manually labeled data and therefore often fails to expose erroneous behaviors for rare inputs.We design implement and evaluate DeepXplore the first whitebox framework for systematically testing real-world DL systems. First we introduce neuron coverage for systematically measuring the parts of a DL system exercised by test inputs. Next we leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. Finally we demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient-based search techniques.DeepXplore efficiently finds thousands of incorrect corner case behaviors (e.g. self-driving cars crashing into guard rails and malware masquerading as benign software) in state-of-the-art DL models with thousands of neurons trained on five popular datasets including ImageNet and Udacity self-driving challenge data. For all tested DL models on average DeepXplore generated one test input demonstrating incorrect behavior within one second while running only on a commodity laptop. We further show that the test inputs generated by DeepXplore can also be used to retrain the corresponding DL model to improve the model's accuracy by up to 3%.;
Proceedings of the 26th Symposium on Operating Systems Principles;Recent advances in small inexpensive sensors low-power processing and activity modeling have enabled applications that use on-body sensing and machine learning to infer people's activities throughout everyday life. To address the growing rate of sedentary lifestyles we have developed a system UbiFit Garden which uses these technologies and a personal mobile display to encourage physical activity. We conducted a 3-week field trial in which 12 participants used the system and report findings focusing on their experiences with the sensing and activity inference. We discuss key implications for systems that use on-body sensing and activity inference to encourage physical activity.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;This paper describes PowerBooter an automated power model construction technique that uses built-in battery voltage sensors and knowledge of battery discharge behavior to monitor power consumption while explicitly controlling the power management and activity states of individual components. It requires no external measurement equipment. We also describe PowerTutor a component power management and activity state introspection based tool that uses the model generated by PowerBooter for online power estimation. PowerBooter is intended to make it quick and easy for application developers and end users to generate power models for new smartphone variants which each have different power consumption properties and therefore require different power models. PowerTutor is intended to ease the design and selection of power efficient software for embedded systems. Combined PowerBooter and PowerTutor have the goal of opening power modeling and analysis for more smartphone variants and their users.;
Proceedings of the Eighth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis;This paper investigates an application of mobile sensing: detecting and reporting the surface conditions of roads. We describe a system and associated algorithms to monitor this important civil infrastructure using a collection of sensor-equipped vehicles. This system which we call the Pothole Patrol (P2) uses the inherent mobility of the participating vehicles opportunistically gathering data from vibration and GPS sensors and processing the data to assess road surface conditions. We have deployed P2 on 7 taxis running in the Boston area. Using a simple machine-learning approach we show that we are able to identify potholes and other severe road surface anomalies from accelerometer data. Via careful selection of training data and signal features we have been able to build a detector that misidentifies good road segments as having potholes less than 0.2% of the time. We evaluate our system on data from thousands of kilometers of taxi drives and show that it can successfully detect a number of real potholes in and around the Boston area. After clustering to further reduce spurious detections manual inspection of reported potholes shows that over 90% contain road anomalies in need of repair.;
Proceedings of the 6th International Conference on Mobile Systems Applications and Services;In Software Defined Networking (SDN) the control plane is physically separate from the forwarding plane. Control software programs the forwarding plane (e.g. switches and routers) using an open interface such as OpenFlow. This paper aims to overcomes two limitations in current switching chips and the OpenFlow protocol: i) current hardware switches are quite rigid allowing ``Match-Action'' processing on only a fixed set of fields and ii) the OpenFlow specification only defines a limited repertoire of packet processing actions. We propose the RMT (reconfigurable match tables) model a new RISC-inspired pipelined architecture for switching chips and we identify the essential minimal set of action primitives to specify how headers are processed in hardware. RMT allows the forwarding plane to be changed in the field without modifying hardware. As in OpenFlow the programmer can specify multiple match tables of arbitrary width and depth subject only to an overall resource limit with each table configurable for matching on arbitrary fields. However RMT allows the programmer to modify all header fields much more comprehensively than in OpenFlow. Our paper describes the design of a 64 port by 10 Gb/s switch chip implementing the RMT model. Our concrete design demonstrates contrary to concerns within the community that flexible OpenFlow hardware switch implementations are feasible at almost no additional cost or power.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;Neural networks are known to be vulnerable to adversarial examples: inputs that are close to natural inputs but classified incorrectly. In order to better understand the space of adversarial examples we survey ten recent proposals that are designed for detection and compare their efficacy. We show that all can be defeated by constructing new loss functions. We conclude that adversarial examples are significantly harder to detect than previously appreciated and the properties believed to be intrinsic to adversarial examples are in fact not. Finally we propose several simple guidelines for evaluating future proposed defenses.;
Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security;"Representation learning in heterogeneous graphs aims to pursue a meaningful vector representation for each node so as to facilitate downstream applications such as link prediction personalized recommendation node classification etc. This task however is challenging not only because of the demand to incorporate heterogeneous structural (graph) information consisting of multiple types of nodes and edges but also due to the need for considering heterogeneous attributes or contents (e.g. text or image) associated with each node. Despite a substantial amount of effort has been made to homogeneous (or heterogeneous) graph embedding attributed graph embedding as well as graph neural networks few of them can jointly consider heterogeneous structural (graph) information as well as heterogeneous contents information of each node effectively. In this paper we propose HetGNN a heterogeneous graph neural network model to resolve this issue. Specifically we first introduce a random walk with restart strategy to sample a fixed size of strongly correlated heterogeneous neighbors for each node and group them based upon node types. Next we design a neural network architecture with two modules to aggregate feature information of those sampled neighboring nodes. The first module encodes deep"" feature interactions of heterogeneous contents and generates content embedding for each node. The second module aggregates content (attribute) embeddings of different neighboring groups (types) and further combines them by considering the impacts of different groups to obtain the ultimate node embedding. Finally we leverage a graph context loss and a mini-batch gradient descent procedure to train the model in an end-to-end manner. Extensive experiments on several datasets demonstrate that HetGNN can outperform state-of-the-art baselines in various graph mining tasks i.e. link prediction recommendation node classification &amp clustering and inductive node classification &amp clustering.""";
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Empirical studies in software testing research may not be comparable reproducible or characteristic of practice. One reason is that real bugs are too infrequently used in software testing research. Extracting and reproducing real bugs is challenging and as a result hand-seeded faults or mutants are commonly used as a substitute. This paper presents Defects4J a database and extensible framework providing real bugs to enable reproducible studies in software testing research. The initial version of Defects4J contains 357 real bugs from 5 real-world open source pro- grams. Each real bug is accompanied by a comprehensive test suite that can expose (demonstrate) that bug. Defects4J is extensible and builds on top of each programâ€™s version con- trol system. Once a program is configured in Defects4J new bugs can be added to the database with little or no effort. Defects4J features a framework to easily access faulty and fixed program versions and corresponding test suites. This framework also provides a high-level interface to common tasks in software testing research making it easy to con- duct and reproduce empirical studies. Defects4J is publicly available at http://defects4j.org.;
Proceedings of the 2014 International Symposium on Software Testing and Analysis;Data center power consumption is growing to unprecedented levels: the EPA estimates U.S. data centers will consume 100 billion kilowatt hours annually by 2011. Much of this energy is wasted in idle systems: in typical deployments server utilization is below 30% but idle servers still consume 60% of their peak power draw. Typical idle periods though frequent--last seconds or less confounding simple energy-conservation approaches.In this paper we propose PowerNap an energy-conservation approach where the entire system transitions rapidly between a high-performance active state and a near-zero-power idle state in response to instantaneous load. Rather than requiring fine-grained power-performance states and complex load-proportional operation from each system component PowerNap instead calls for minimizing idle power and transition time which are simpler optimization goals. Based on the PowerNap concept we develop requirements and outline mechanisms to eliminate idle power waste in enterprise blade servers. Because PowerNap operates in low-efficiency regions of current blade center power supplies we introduce the Redundant Array for Inexpensive Load Sharing (RAILS) a power provisioning approach that provides high conversion efficiency across the entire range of PowerNap's power demands. Using utilization traces collected from enterprise-scale commercial deployments we demonstrate that together PowerNap and RAILS reduce average server power consumption by 74%.;
Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems;"As a prolific research area in data mining subspace clustering and related problems induced a vast quantity of proposed solutions. However many publications compare a new propositionâ€”if at allâ€”with one or two competitors or even with a so-called â€œna\{\i""";
Better I/O through byte-addressable persistent memory;Modern computer systems have been built around the assumption that persistent storage is accessed via a slow block-based interface. However new byte-addressable persistent memory technologies such as phase change memory (PCM) offer fast fine-grained access to persistent storage.In this paper we present a file system and a hardware architecture that are designed around the properties of persistent byteaddressable memory. Our file system BPFS uses a new technique called short-circuit shadow paging to provide atomic fine-grained updates to persistent storage. As a result BPFS provides strong reliability guarantees and offers better performance than traditional file systems even when both are run on top of byte-addressable persistent memory. Our hardware architecture enforces atomicity and ordering guarantees required by BPFS while still providing the performance benefits of the L1 and L2 caches.Since these memory technologies are not yet widely available we evaluate BPFS on DRAM against NTFS on both a RAM disk and a traditional disk. Then we use microarchitectural simulations to estimate the performance of BPFS on PCM. Despite providing strong safety and consistency guarantees BPFS on DRAM is typically twice as fast as NTFS on a RAM disk and 4-10 times faster than NTFS on disk. We also show that BPFS on PCM should be significantly faster than a traditional disk-based file system.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;Google's Borg system is a cluster manager that runs hundreds of thousands of jobs from many thousands of different applications across a number of clusters each with up to tens of thousands of machines.It achieves high utilization by combining admission control efficient task-packing over-commitment and machine sharing with process-level performance isolation. It supports high-availability applications with runtime features that minimize fault-recovery time and scheduling policies that reduce the probability of correlated failures. Borg simplifies life for its users by offering a declarative job specification language name service integration real-time job monitoring and tools to analyze and simulate system behavior.We present a summary of the Borg system architecture and features important design decisions a quantitative analysis of some of its policy decisions and a qualitative examination of lessons learned from a decade of operational experience with it.;
Proceedings of the Tenth European Conference on Computer Systems;We present the design implementation evaluation and user ex periences of theCenceMe application which represents the first system that combines the inference of the presence of individuals using off-the-shelf sensor-enabled mobile phones with sharing of this information through social networking applications such as Facebook and MySpace. We discuss the system challenges for the development of software on the Nokia N95 mobile phone. We present the design and tradeoffs of split-level classification whereby personal sensing presence (e.g. walking in conversation at the gym) is derived from classifiers which execute in part on the phones and in part on the backend servers to achieve scalable inference. We report performance measurements that characterize the computational requirements of the software and the energy consumption of the CenceMe phone client. We validate the system through a user study where twenty two people including undergraduates graduates and faculty used CenceMe continuously over a three week period in a campus town. From this user study we learn how the system performs in a production environment and what uses people find for a personal sensing system.;
Proceedings of the 6th ACM Conference on Embedded Network Sensor Systems;One of the important types of information on the Web is the opinions expressed in the user generated content e.g. customer reviews of products forum posts and blogs. In this paper we focus on customer reviews of products. In particular we study the problem of determining the semantic orientations (positive negative or neutral) of opinions expressed on product features in reviews. This problem has many applications e.g. opinion mining summarization and search. Most existing techniques utilize a list of opinion (bearing) words (also called opinion lexicon) for the purpose. Opinion words are words that express desirable (e.g. great amazing etc.) or undesirable (e.g. bad poor etc) states. These approaches however all have some major shortcomings. In this paper we propose a holistic lexicon-based approach to solving the problem by exploiting external evidences and linguistic conventions of natural language expressions. This approach allows the system to handle opinion words that are context dependent which cause major difficulties for existing algorithms. It also deals with many special words phrases and language constructs which have impacts on opinions based on their linguistic patterns. It also has an effective function for aggregating multiple conflicting opinion words in a sentence. A system called Opinion Observer based on the proposed technique has been implemented. Experimental results using a benchmark product review data set and some additional reviews show that the proposed technique is highly effective. It outperforms existing methods significantly;
Proceedings of the 2008 International Conference on Web Search and Data Mining;We present our experiences to date building ONOS (Open Network Operating System) an experimental distributed SDN control platform motivated by the performance scalability and availability requirements of large operator networks. We describe and evaluate two ONOS prototypes. The first version implemented core features: a distributed but logically centralized global network view scale-out and fault tolerance. The second version focused on improving performance. Based on experience with these prototypes we identify additional steps that will be required for ONOS to support use cases such as core network traffic engineering and scheduling and to become a usable open source distributed network OS platform that the SDN community can build upon.;
Proceedings of the Third Workshop on Hot Topics in Software Defined Networking;The basic building block of ever larger data centers has shifted from a rack to a modular container with hundreds or even thousands of servers. Delivering scalable bandwidth among such containers is a challenge. A number of recent efforts promise full bisection bandwidth between all servers though with significant cost complexity and power consumption. We present Helios a hybrid electrical/optical switch architecture that can deliver significant reductions in the number of switching elements cabling cost and power consumption relative to recently proposed data center network architectures. We explore architectural trade offs and challenges associated with realizing these benefits through the evaluation of a fully functional Helios prototype.;
Proceedings of the ACM SIGCOMM 2010 Conference;The Konstanz Information Miner is a modular environment which enables easy visual assembly and interactive execution of a data pipeline. It is designed as a teaching research and collaboration platform which enables simple integration of new algorithms and tools as well as data manipulation or visualization methods in the form of new modules or nodes. In this paper we describe some of the design aspects of the underlying architecture briey sketch how new nodes can be incorporated and highlight some of the new features of version 2.0.;
Tanks and temples: benchmarking large-scale scene reconstruction;We present a benchmark for image-based 3D reconstruction. The benchmark sequences were acquired outside the lab in realistic conditions. Ground-truth data was captured using an industrial laser scanner. The benchmark includes both outdoor scenes and indoor environments. High-resolution video sequences are provided as input supporting the development of novel pipelines that take advantage of video input to increase reconstruction fidelity. We report the performance of many image-based 3D reconstruction pipelines on the new benchmark. The results point to exciting challenges and opportunities for future work.;
Finding and understanding bugs in C compilers;Compilers should be correct. To improve the quality of C compilers we created Csmith a randomized test-case generation tool and spent three years using it to find compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our first contribution is to advance the state of the art in compiler testing. Unlike previous tools Csmith generates programs that cover a large subset of C while avoiding the undefined and unspecified behaviors that would destroy its ability to automatically find wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.;
Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation;The quality of user-generated content varies drastically from excellent to abuse and spam. As the availability of such content increases the task of identifying high-quality content sites based on user contributions --social media sites -- becomes increasingly important. Social media in general exhibit a rich variety of information sources: in addition to the content itself there is a wide array of non-content information available such as links between items and explicit quality ratings from members of the community. In this paper we investigate methods for exploiting such community feedback to automatically identify high quality content. As a test case we focus on Yahoo! Answers a large community question/answering portal that is particularly rich in the amount and types of content and social interactions available in it. We introduce a general classification framework for combining the evidence from different sources of information that can be tuned automatically for a given social media type and quality definition. In particular for the community question/answering domain we show that our system is able to separate high-quality items from the rest with an accuracy close to that of humans;
Proceedings of the 2008 International Conference on Web Search and Data Mining;This paper describes the use of Storm at Twitter. Storm is a real-time fault-tolerant and distributed stream data processing system. Storm is currently being used to run various critical computations in Twitter at scale and in real-time. This paper describes the architecture of Storm and its methods for distributed scale-out and fault-tolerance. This paper also describes how queries (aka. topologies) are executed in Storm and presents some operational stories based on running Storm at Twitter. We also present results from an empirical evaluation demonstrating the resilience of Storm in dealing with machine failures. Storm is under active development at Twitter and we also present some potential directions for future work.;
Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data;Some pioneer WiFi signal based human activity recognition systems have been proposed. Their key limitation lies in the lack of a model that can quantitatively correlate CSI dynamics and human activities. In this paper we propose CARM a CSI based human Activity Recognition and Monitoring system. CARM has two theoretical underpinnings: a CSI-speed model which quantifies the correlation between CSI value dynamics and human movement speeds and a CSI-activity model which quantifies the correlation between the movement speeds of different human body parts and a specific human activity. By these two models we quantitatively build the correlation between CSI value dynamics and a specific human activity. CARM uses this correlation as the profiling mechanism and recognizes a given activity by matching it to the best-fit profile. We implemented CARM using commercial WiFi devices and evaluated it in several different environments. Our results show that CARM achieves an average accuracy of greater than 96%.;
Proceedings of the 21st Annual International Conference on Mobile Computing and Networking;"This paper considers the requirements for a scalable easily manageable fault-tolerant and efficient data center network fabric. Trends in multi-core processors end-host virtualization and commodities of scale are pointing to future single-site data centers with millions of virtual end points. Existing layer 2 and layer 3 network protocols face some combination of limitations in such a setting: lack of scalability difficult management inflexible communication or limited support for virtual machine migration. To some extent these limitations may be inherent for Ethernet/IP style protocols when trying to support arbitrary topologies. We observe that data center networks are often managed as a single logical network fabric with a known baseline topology and growth model. We leverage this observation in the design and implementation of PortLand a scalable fault tolerant layer 2 routing and forwarding protocol for data center environments. Through our implementation and evaluation we show that PortLand holds promise for supporting a ``plug-and-play large-scale data center network.""";
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;The reality of multi-core hardware has made concurrent programs pervasive. Unfortunately writing correct concurrent programs is difficult. Addressing this challenge requires advances in multiple directions including concurrency bug detection concurrent program testing concurrent programming model design etc. Designing effective techniques in all these directions will significantly benefit from a deep understanding of real world concurrency bug characteristics.This paper provides the first (to the best of our knowledge) comprehensive real world concurrency bug characteristic study. Specifically we have carefully examined concurrency bug patterns manifestation and fix strategies of 105 randomly selected real world concurrency bugs from 4 representative server and client open-source applications (MySQL Apache Mozilla and OpenOffice). Our study reveals several interesting findings and provides useful guidance for concurrency bug detection testing and concurrent programming language design.Some of our findings are as follows: (1) Around one third of the examined non-deadlock concurrency bugs are caused by violation to programmers' order intentions which may not be easily expressed via synchronization primitives like locks and transactional memories (2) Around 34% of the examined non-deadlock concurrency bugs involve multiple variables which are not well addressed by existing bug detection tools (3) About 92% of the examined concurrency bugs canbe reliably triggered by enforcing certain orders among no more than 4 memory accesses. This indicates that testing concurrent programs can target at exploring possible orders among every small groups of memory accesses instead of among all memory accesses (4) About 73% of the examinednon-deadlock concurrency bugs were not fixed by simply adding or changing locks and many of the fixes were not correct at the first try indicating the difficulty of reasoning concurrent execution by programmers.;
Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems;People strive to obtain self-knowledge. A class of systems called personal informatics is appearing that help people collect and reflect on personal information. However there is no comprehensive list of problems that users experience using these systems and no guidance for making these systems more effective. To address this we conducted surveys and interviews with people who collect and reflect on personal information. We derived a stage-based model of personal informatics systems composed of five stages (preparation collection integration reflection and action) and identified barriers in each of the stages. These stages have four essential properties: barriers cascade to later stages they are iterative they are user-driven and/or system-driven and they are uni-faceted or multi-faceted. From these properties we recommend that personal informatics systems should 1) be designed in a holistic manner across the stages 2) allow iteration between stages 3) apply an appropriate balance of automated technology and user control within each stage to facilitate the user experience and 4) explore support for associating multiple facets of people's lives to enrich the value of systems.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;While WiFi-based indoor localization is attractive the need for a significant degree of pre-deployment effort is a key challenge. In this paper we ask the question: can we perform indoor localization with no pre-deployment effort? Our setting is an indoor space such as an office building or a mall with WiFi coverage but where we do not assume knowledge of the physical layout including the placement of the APs. Users carrying WiFi-enabled devices such as smartphones traverse this space in normal course. The mobile devices record Received Signal Strength (RSS) measurements corresponding to APs in their view at various (unknown) locations and report these to a localization server. Occasionally a mobile device will also obtain and report a location fix say by obtaining a GPS lock at the entrance or near a window. The centerpiece of our work is the EZ Localization algorithm which runs on the localization server. The key intuition is that all of the observations reported to the server even the many from unknown locations are constrained by the physics of wireless propagation. EZ models these constraints and then uses a genetic algorithm to solve them. The results from our deployment in two different buildings are promising. Despite the absence of any explicit pre-deployment calibration EZ yields a median localization error of 2m and 7m respectively in a small building and a large building which is only somewhat worse than the 0.7m and 4m yielded by the best-performing but calibration-intensive Horus scheme [29] from prior work.;
Proceedings of the Sixteenth Annual International Conference on Mobile Computing and Networking;Cloud computing promises flexibility and high performance for users and high cost-efficiency for operators. Nevertheless most cloud facilities operate at very low utilization hurting both cost effectiveness and future scalability.We present Quasar a cluster management system that increases resource utilization while providing consistently high application performance. Quasar employs three techniques. First it does not rely on resource reservations which lead to underutilization as users do not necessarily understand workload dynamics and physical resource requirements of complex codebases. Instead users express performance constraints for each workload letting Quasar determine the right amount of resources to meet these constraints at any point. Second Quasar uses classification techniques to quickly and accurately determine the impact of the amount of resources (scale-out and scale-up) type of resources and interference on performance for each workload and dataset. Third it uses the classification results to jointly perform resource allocation and assignment quickly exploring the large space of options for an efficient way to pack workloads on available resources. Quasar monitors workload performance and adjusts resource allocation and assignment when needed. We evaluate Quasar over a wide range of workload scenarios including combinations of distributed analytics frameworks and low-latency stateful services both on a local cluster and a cluster of dedicated EC2 servers. At steady state Quasar improves resource utilization by 47% in the 200-server EC2 cluster while meeting performance constraints for workloads of all types.;
Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems;We propose a simple yet effective method for visualizing and classifying malware using image processing techniques. Malware binaries are visualized as gray-scale images with the observation that for many malware families the images belonging to the same family appear very similar in layout and texture. Motivated by this visual similarity a classification method using standard image features is proposed. Neither disassembly nor code execution is required for classification. Preliminary experimental results are quite promising with 98% classification accuracy on a malware database of 9458 samples with 25 different malware families. Our technique also exhibits interesting resilience to popular obfuscation techniques such as section encryption.;
Proceedings of the 8th International Symposium on Visualization for Cyber Security;As spacecraft send back increasing amounts of telemetry data improved anomaly detection systems are needed to lessen the monitoring burden placed on operations engineers and reduce operational risk. Current spacecraft monitoring systems only target a subset of anomaly types and often require costly expert knowledge to develop and maintain due to challenges involving scale and complexity. We demonstrate the effectiveness of Long Short-Term Memory (LSTMs) networks a type of Recurrent Neural Network (RNN) in overcoming these issues using expert-labeled telemetry anomaly data from the Soil Moisture Active Passive (SMAP) satellite and the Mars Science Laboratory (MSL) rover Curiosity. We also propose a complementary unsupervised and nonparametric anomaly thresholding approach developed during a pilot implementation of an anomaly detection system for SMAP and offer false positive mitigation strategies along with other key improvements and lessons learned during development.;
Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Graph convolutional network (GCN) has been successfully applied to many graph-based applications however training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper we propose Cluster-GCN a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with previous algorithms. To test the scalability of our algorithm we create a new Amazon2M data with 2 million nodes and 61 million edges which is more than 5 times larger than the previous largest publicly available dataset (Reddit). For training a 3-layer GCN on this data Cluster-GCN is faster than the previous state-of-the-art VR-GCN (1523 seconds vs 1961 seconds) and using much less memory (2.2GB vs 11.2GB). Furthermore for training 4 layer GCN on this data our algorithm can finish in around 36 minutes while all the existing GCN training algorithms fail to train due to the out-of-memory issue. Furthermore Cluster-GCN allows us to train much deeper GCN without much time and memory overhead which leads to improved prediction accuracy---using a 5-layer Cluster-GCN we achieve state-of-the-art test F1 score 99.36 on the PPI dataset while the previous best result was 98.71 by~citezhang2018gaan.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Exploring the inherent technical challenges in realizing the potential of Big Data.;
Feminist HCI: taking stock and outlining an agenda for design;Feminism is a natural ally to interaction design due to its central commitments to issues such as agency fulfillment identity equity empowerment and social justice. In this paper I summarize the state of the art of feminism in HCI and propose ways to build on existing successes to more robustly integrate feminism into interaction design research and practice. I explore the productive role of feminism in analogous fields such as industrial design architecture and game design. I introduce examples of feminist interaction design already in the field. Finally I propose a set of femi-nist interaction design qualities intended to support design and evaluation processes directly as they unfold.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Recent technological advances in the development of flash-memory based devices have consolidated their leadership position as the preferred storage media in the embedded systems market and opened new vistas for deployment in enterprise-scale storage systems. Unlike hard disks flash devices are free from any mechanical moving parts have no seek or rotational delays and consume lower power. However the internal idiosyncrasies of flash technology make its performance highly dependent on workload characteristics. The poor performance of random writes has been a cause of major concern which needs to be addressed to better utilize the potential of flash in enterprise-scale environments. We examine one of the important causes of this poor performance: the design of the Flash Translation Layer (FTL) which performs the virtual-to-physical address translations and hides the erase-before-write characteristics of flash. We propose a complete paradigm shift in the design of the core FTL engine from the existing techniques with our Demand-based Flash Translation Layer (DFTL) which selectively caches page-level address mappings. We develop a flash simulation framework called FlashSim. Our experimental evaluation with realistic enterprise-scale workloads endorses the utility of DFTL in enterprise-scale storage systems by demonstrating: (i) improved performance (ii) reduced garbage collection overhead and (iii) better overload behavior compared to state-of-the-art FTL schemes. For example a predominantly random-write dominant I/O trace from an OLTP application running at a large financial institution shows a 78% improvement in average response time (due to a 3-fold reduction in operations of the garbage collector) compared to a state-of-the-art FTL scheme. Even for the well-known read-dominant TPC-H benchmark for which DFTL introduces additional overheads we improve system response time by 56%.;
Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems;Paid crowd work offers remarkable opportunities for improving productivity social mobility and the global economy by engaging a geographically distributed workforce to complete complex tasks on demand and at scale. But it is also possible that crowd work will fail to achieve its potential focusing on assembly-line piecework. Can we foresee a future crowd workplace in which we would want our children to participate? This paper frames the major challenges that stand in the way of this goal. Drawing on theory from organizational behavior and distributed computing as well as direct feedback from workers we outline a framework that will enable crowd work that is complex collaborative and sustainable. The framework lays out research challenges in twelve major areas: workflow task assignment hierarchy real-time response synchronous collaboration quality control crowds guiding AIs AIs guiding crowds platforms job design reputation and motivation.;
Proceedings of the 2013 Conference on Computer Supported Cooperative Work;To better understand the challenges in developing effective cloud-based resource schedulers we analyze the first publicly available trace data from a sizable multi-purpose cluster. The most notable workload characteristic is heterogeneity: in resource types (e.g. cores:RAM per machine) and their usage (e.g. duration and resources needed). Such heterogeneity reduces the effectiveness of traditional slot- and core-based scheduling. Furthermore some tasks are constrained as to the kind of machine types they can use increasing the complexity of resource assignment and complicating task migration. The workload is also highly dynamic varying over time and most workload features and is driven by many short jobs that demand quick scheduling decisions. While few simplifying assumptions apply we find that many longer-running jobs have relatively stable resource utilizations which can help adaptive resource schedulers.;
Proceedings of the Third ACM Symposium on Cloud Computing;A general-purpose MATLAB software program called GPOPS--II is described for solving multiple-phase optimal control problems using variable-order Gaussian quadrature collocation methods. The software employs a Legendre-Gauss-Radau quadrature orthogonal collocation method where the continuous-time optimal control problem is transcribed to a large sparse nonlinear programming problem (NLP). An adaptive mesh refinement method is implemented that determines the number of mesh intervals and the degree of the approximating polynomial within each mesh interval to achieve a specified accuracy. The software can be interfaced with either quasi-Newton (first derivative) or Newton (second derivative) NLP solvers and all derivatives required by the NLP solver are approximated using sparse finite-differencing of the optimal control problem functions. The key components of the software are described in detail and the utility of the software is demonstrated on five optimal control problems of varying complexity. The software described in this article provides researchers a useful platform upon which to solve a wide variety of complex constrained optimal control problems.;
Ligra: a lightweight graph processing framework for shared memory;There has been significant recent interest in parallel frameworks for processing graphs due to their applicability in studying social networks the Web graph networks in biology and unstructured meshes in scientific simulation. Due to the desire to process large graphs these systems have emphasized the ability to run on distributed memory machines. Today however a single multicore server can support more than a terabyte of memory which can fit graphs with tens or even hundreds of billions of edges. Furthermore for graph algorithms shared-memory multicores are generally significantly more efficient on a per core per dollar and per joule basis than distributed memory systems and shared-memory algorithms tend to be simpler than their distributed counterparts.In this paper we present a lightweight graph processing framework that is specific for shared-memory parallel/multicore machines which makes graph traversal algorithms easy to write. The framework has two very simple routines one for mapping over edges and one for mapping over vertices. Our routines can be applied to any subset of the vertices which makes the framework useful for many graph traversal algorithms that operate on subsets of the vertices. Based on recent ideas used in a very fast algorithm for breadth-first search (BFS) our routines automatically adapt to the density of vertex sets. We implement several algorithms in this framework including BFS graph radii estimation graph connectivity betweenness centrality PageRank and single-source shortest paths. Our algorithms expressed using this framework are very simple and concise and perform almost as well as highly optimized code. Furthermore they get good speedups on a 40-core machine and are significantly more efficient than previously reported results using graph frameworks on machines with many more cores.;
Proceedings of the 18th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming;This paper presents Soli a new robust high-resolution low-power miniature gesture sensing technology for human-computer interaction based on millimeter-wave radar. We describe a new approach to developing a radar-based sensor optimized for human-computer interaction building the sensor architecture from the ground up with the inclusion of radar design principles high temporal resolution gesture tracking a hardware abstraction layer (HAL) a solid-state radar chip and system architecture interaction models and gesture vocabularies and gesture recognition. We demonstrate that Soli can be used for robust gesture recognition and can track gestures with sub-millimeter accuracy running at over 10000 frames per second on embedded hardware.;
Numba: a LLVM-based Python JIT compiler;Dynamic interpreted languages like Python are attractive for domain-experts and scientists experimenting with new ideas. However the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition we share our experience in building a JIT compiler using LLVM[1].;
Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC;The literature provides a wide range of techniques to assess and improve the quality of data. Due to the diversity and complexity of these techniques research has recently focused on defining methodologies that help the selection customization and application of data quality assessment and improvement techniques. The goal of this article is to provide a systematic and comparative description of such methodologies. Methodologies are compared along several dimensions including the methodological phases and steps the strategies and techniques the data quality dimensions the types of data and finally the types of information systems addressed by each methodology. The article concludes with a summary description of each methodology.;
A biterm topic model for short texts;Uncovering the topics within short texts such as tweets and instant messages has become an important task for many content analysis applications. However directly applying conventional topic models (e.g. LDA and PLSA) on such short texts may not work well. The fundamental reason lies in that conventional topic models implicitly capture the document-level word co-occurrence patterns to reveal topics and thus suffer from the severe data sparsity in short documents. In this paper we propose a novel way for modeling topics in short texts referred as biterm topic model (BTM). Specifically in BTM we learn the topics by directly modeling the generation of word co-occurrence patterns (i.e. biterms) in the whole corpus. The major advantages of BTM are that 1) BTM explicitly models the word co-occurrence patterns to enhance the topic learning and 2) BTM uses the aggregated patterns in the whole corpus for learning topics to solve the problem of sparse word co-occurrence patterns at document-level. We carry out extensive experiments on real-world short text collections. The results demonstrate that our approach can discover more prominent and coherent topics and significantly outperform baseline methods on several evaluation metrics. Furthermore we find that BTM can outperform LDA even on normal texts showing the potential generality and wider usage of the new topic model.;
Proceedings of the 22nd International Conference on World Wide Web;Data generated as a side effect of game play also solves computational problems and trains AI algorithms.;
VTrack: accurate energy-aware road traffic delay estimation using mobile phones;"Traffic delays and congestion are a major source of inefficiency wasted fuel and commuter frustration. Measuring and localizing these delays and routing users around them is an important step towards reducing the time people spend stuck in traffic. As others have noted the proliferation of commodity smartphones that can provide location estimates using a variety of sensors---GPS WiFi and/or cellular triangulation---opens up the attractive possibility of using position samples from drivers' phones to monitor traffic delays at a fine spatiotemporal granularity. This paper presents VTrack a system for travel time estimation using this sensor data that addresses two key challenges: energy consumption and sensor unreliability. While GPS provides highly accurate location estimates it has several limitations: some phones don't have GPS at all the GPS sensor doesn't work in urban canyons"" (tall buildings and tunnels) or when the phone is inside a pocket and the GPS on many phones is power-hungry and drains the battery quickly. In these cases VTrack can use alternative less energy-hungry but noisier sensors like WiFi to estimate both a user's trajectory and travel time along the route. VTrack uses a hidden Markov model (HMM)-based map matching scheme and travel time estimation method that interpolates sparse data to identify the most probable road segments driven by the user and to attribute travel times to those segments. We present experimental results from real drive data and WiFi access point sightings gathered from a deployment on several cars. We show that VTrack can tolerate significant noise and outages in these location estimates and still successfully identify delay-prone segments and provide accurate enough delays for delay-aware routing algorithms. We also study the best sampling strategies for WiFi and GPS sensors for different energy cost regimes.""";
Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems;We present recent developments in the openSMILE feature extraction toolkit. Version 2.0 now unites feature extraction paradigms from speech music and general sound events with basic video features for multi-modal processing. Descriptors from audio and video can be processed jointly in a single framework allowing for time synchronization of parameters on-line incremental processing as well as off-line and batch processing and the extraction of statistical functionals (feature summaries) such as moments peaks regression parameters etc. Postprocessing of the features includes statistical classifiers such as support vector machine models or file export for popular toolkits such as Weka or HTK. Available low-level descriptors include popular speech music and video features including Mel-frequency and similar cepstral and spectral coefficients Chroma CENS auditory model based loudness voice quality local binary pattern color and optical flow histograms. Besides voice activity detection pitch tracking and face detection are supported. openSMILE is implemented in C++ using standard open source libraries for on-line audio and video input. It is fast runs on Unix and Windows platforms and has a modular component based architecture which makes extensions via plug-ins easy. openSMILE 2.0 is distributed under a research license and can be downloaded from http://opensmile.sourceforge.net/.;
Proceedings of the 21st ACM International Conference on Multimedia;We present a neural model for representing snippets of code as continuous distributed vectors (``code embeddings''). The main idea is to represent a code snippet as a single fixed-length code vector which can be used to predict semantic properties of the snippet. To this end code is first decomposed to a collection of paths in its abstract syntax tree. Then the network learns the atomic representation of each path while simultaneously learning how to aggregate a set of them.  We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 12M methods. We show that code vectors trained on this dataset can predict method names from files that were unobserved during training. Furthermore we show that our model learns useful method name vectors that capture semantic similarities combinations and analogies.  A comparison of our approach to previous techniques over the same dataset shows an improvement of more than 75% making it the first to successfully predict method names based on a large cross-project corpus. Our trained model visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code data and trained models are available at https://github.com/tech-srl/code2vec.;
Get another label? improving data quality and data mining using multiple noisy labelers;This paper addresses the repeated acquisition of labels for data items when the labeling is imperfect. We examine the improvement (or lack thereof) in data quality via repeated labeling and focus especially on the improvement of training labels for supervised induction. With the outsourcing of small tasks becoming easier for example via Rent-A-Coder or Amazon's Mechanical Turk it often is possible to obtain less-than-expert labeling at low cost. With low-cost labeling preparing the unlabeled part of the data can become considerably more expensive than labeling. We present repeated-labeling strategies of increasing complexity and show several main results. (i) Repeated-labeling can improve label quality and model quality but not always. (ii) When labels are noisy repeated labeling can be preferable to single labeling even in the traditional setting where labels are not particularly cheap. (iii) As soon as the cost of processing the unlabeled data is not free even the simple strategy of labeling everything multiple times can give considerable advantage. (iv) Repeatedly labeling a carefully chosen set of points is generally preferable and we present a robust technique that combines different notions of uncertainty to select data points for which quality should be improved. The bottom line: the results show clearly that when labeling is not perfect selective acquisition of multiple labels is a strategy that data miners should have in their repertoire for certain label-quality/cost regimes the benefit is substantial.;
Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;In this paper we seek to improve our understanding of human mobility in terms of social structures and to use these structures in the design of forwarding algorithms for Pocket Switched Networks (PSNs). Taking human mobility traces from the real world we discover that human interaction is heterogeneous both in terms of hubs (popular individuals) and groups or communities. We propose a social based forwarding algorithm BUBBLE which is shown empirically to improve the forwarding efficiency significantly compared to oblivious forwarding schemes and to PROPHET algorithm. We also show how this algorithm can be implemented in a distributed way which demonstrates that it is applicable in the decentralised environment of PSNs.;
Proceedings of the 9th ACM International Symposium on Mobile Ad Hoc Networking and Computing;Energy expenses are becoming an increasingly important fraction of data center operating costs. At the same time the energy expense per unit of computation can vary significantly between two different locations. In this paper we characterize the variation due to fluctuating electricity prices and argue that existing distributed systems should be able to exploit this variation for significant economic gains. Electricity prices exhibit both temporal and geographic variation due to regional demand differences transmission inefficiencies and generation diversity. Starting with historical electricity prices for twenty nine locations in the US and network traffic data collected on Akamai's CDN we use simulation to quantify the possible economic gains for a realistic workload. Our results imply that existing systems may be able to save millions of dollars a year in electricity costs by being cognizant of locational computation cost differences.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;We present a system that can reconstruct 3D geometry from large unorganized collections of photographs such as those found by searching for a given city (e.g. Rome) on Internet photo-sharing sites. Our system is built on a set of new distributed computer vision algorithms for image matching and 3D reconstruction designed to maximize parallelism at each stage of the pipeline and to scale gracefully with both the size of the problem and the amount of available computation. Our experimental results demonstrate that it is now possible to reconstruct city-scale image collections with more than a hundred thousand images in less than a day.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Android's permission system is intended to inform users about the risks of installing applications. When a user installs an application he or she has the opportunity to review the application's permission requests and cancel the installation if the permissions are excessive or objectionable. We examine whether the Android permission system is effective at warning users. In particular we evaluate whether Android users pay attention to understand and act on permission information during installation. We performed two usability studies: an Internet survey of 308 Android users and a laboratory study wherein we interviewed and observed 25 Android users. Study participants displayed low attention and comprehension rates: both the Internet survey and laboratory study found that 17% of participants paid attention to permissions during installation and only 3% of Internet survey respondents could correctly answer all three permission comprehension questions. This indicates that current Android permission warnings do not help most users make correct security decisions. However a notable minority of users demonstrated both awareness of permission warnings and reasonable rates of comprehension. We present recommendations for improving user attention and comprehension as well as identify open challenges.;
Proceedings of the Eighth Symposium on Usable Privacy and Security;"We propose UnLoc an unsupervised indoor localization scheme that bypasses the need for war-driving. Our key observation is that certain locations in an indoor environment present identifiable signatures on one or more sensing dimensions. An elevator for instance imposes a distinct pattern on a smartphone's accelerometer a corridor-corner may overhear a unique set of WiFi access points a specific spot may experience an unusual magnetic fluctuation. We hypothesize that these kind of signatures naturally exist in the environment and can be envisioned as internal landmarks of a building. Mobile devices that sense"" these landmarks can recalibrate their locations while dead-reckoning schemes can track them between landmarks. Results from 3 different indoor settings including a shopping mall demonstrate median location errors of 1:69m. War-driving is not necessary neither are floorplans the system simultaneously computes the locations of users and landmarks in a manner that they converge reasonably quickly. We believe this is an unconventional approach to indoor localization holding promise for real-world deployment.""";
Proceedings of the 10th International Conference on Mobile Systems Applications and Services;Most time series data mining algorithms use similarity search as a core subroutine and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms. The difficulty of scaling search to large datasets largely explains why most academic work on time series data mining has plateaued at considering a few millions of time series objects while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine truly massive time series for the first time. We demonstrate the following extremely unintuitive fact in large datasets we can exactly search under DTW much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. In particular the largest dataset we consider is larger than the combined size of all of the time series datasets considered in all data mining papers ever published. We show that our ideas allow us to solve higher-level time series data mining problem such as motif discovery and clustering at scales that would otherwise be untenable. In addition to mining massive datasets we will show that our ideas also have implications for real-time monitoring of data streams allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible.;
Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Activity monitoring in home environments has become increasingly important and has the potential to support a broad array of applications including elder care well-being management and latchkey child safety. Traditional approaches involve wearable sensors and specialized hardware installations. This paper presents device-free location-oriented activity identification at home through the use of existing WiFi access points and WiFi devices (e.g. desktops thermostats refrigerators smartTVs laptops). Our low-cost system takes advantage of the ever more complex web of WiFi links between such devices and the increasingly fine-grained channel state information that can be extracted from such links. It examines channel features and can uniquely identify both in-place activities and walking movements across a home by comparing them against signal profiles. Signal profiles construction can be semi-supervised and the profiles can be adaptively updated to accommodate the movement of the mobile devices and day-to-day signal calibration. Our experimental evaluation in two apartments of different size demonstrates that our approach can achieve over 96% average true positive rate and less than 1% average false positive rate to distinguish a set of in-place and walking activities with only a single WiFi access point. Our prototype also shows that our system can work with wider signal band (802.11ac) with even higher accuracy.;
Proceedings of the 20th Annual International Conference on Mobile Computing and Networking;"This paper describes how to automatically cross-reference documents with Wikipedia: the largest knowledge base ever known. It explains how machine learning can be used to identify significant terms within unstructured text and enrich it with links to the appropriate Wikipedia articles. The resulting link detector and disambiguator performs very well with recall and precision of almost 75%. This performance is constant whether the system is evaluated on Wikipedia articles or real world"" documents.This work has implications far beyond enriching documents with explanatory links. It can provide structured knowledge about any unstructured fragment of text. Any task that is currently addressed with bags of words - indexing clustering retrieval and summarization to name a few - could use the techniques described here to draw on a vast network of concepts and semantics.""";
Proceedings of the 17th ACM Conference on Information and Knowledge Management;Large cloud service providers have invested in increasingly larger datacenters to house the computing infrastructure required to support their services. Accordingly researchers and industry practitioners alike have focused a great deal of effort designing network fabrics to efficiently interconnect and manage the traffic within these datacenters in performant yet efficient fashions. Unfortunately datacenter operators are generally reticent to share the actual requirements of their applications making it challenging to evaluate the practicality of any particular design.Moreover the limited large-scale workload information available in the literature has for better or worse heretofore largely been provided by a single datacenter operator whose use cases may not be widespread. In this work we report upon the network traffic observed in some of Facebook's datacenters. While Facebook operates a number of traditional datacenter services like Hadoop its core Web service and supporting cache infrastructure exhibit a number of behaviors that contrast with those reported in the literature. We report on the contrasting locality stability and predictability of network traffic in Facebook's datacenters and comment on their implications for network architecture traffic engineering and switch design.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;There is currently considerable enthusiasm around the MapReduce (MR) paradigm for large-scale data analysis [17]. Although the basic control flow of this framework has existed in parallel SQL database management systems (DBMS) for over 20 years some have called MR a dramatically new computing model [8 17]. In this paper we describe and compare both paradigms. Furthermore we evaluate both kinds of systems in terms of performance and development complexity. To this end we define a benchmark consisting of a collection of tasks that we have run on an open source version of MR as well as on two parallel DBMSs. For each task we measure each system's performance for various degrees of parallelism on a cluster of 100 nodes. Our results reveal some interesting trade-offs. Although the process to load data into and tune the execution of parallel DBMSs took much longer than the MR system the observed performance of these DBMSs was strikingly better. We speculate about the causes of the dramatic performance difference and consider implementation concepts that future systems should take from both kinds of architectures.;
Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data;The sharp increase in the number of smartphones on the market with the Android platform posed to becoming a market leader makes the need for malware analysis on this platform an urgent issue.In this paper we capitalize on earlier approaches for dynamic analysis of application behavior as a means for detecting malware in the Android platform. The detector is embedded in a overall framework for collection of traces from an unlimited number of real users based on crowdsourcing. Our framework has been demonstrated by analyzing the data collected in the central server using two types of data sets: those from artificial malware created for test purposes and those from real malware found in the wild. The method is shown to be an effective means of isolating the malware and alerting the users of a downloaded malware. This shows the potential for avoiding the spreading of a detected malware to a larger community.;
Proceedings of the 1st ACM Workshop on Security and Privacy in Smartphones and Mobile Devices;begin{abstract;
Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation;Software Defined Networking (SDN) is an exciting technology that enables innovation in how we design and manage networks. Although this technology seems to have appeared suddenly SDN is part of a long history of efforts to make computer networks more programmable. In this paper we trace the intellectual history of programmable networks including active networks early efforts to separate the control and data plane and more recent work on OpenFlow and network operating systems. We highlight key concepts as well as the technology pushes and application pulls that spurred each innovation. Along the way we debunk common myths and misconceptions about the technologies and clarify the relationship between SDN and related technologies such as network virtualization.;
A survey of hard real-time scheduling for multiprocessor systems;This survey covers hard real-time scheduling algorithms and schedulability analysis techniques for homogeneous multiprocessor systems. It reviews the key results in this field from its origins in the late 1960s to the latest research published in late 2009. The survey outlines fundamental results about multiprocessor real-time scheduling that hold independent of the scheduling algorithms employed. It provides a taxonomy of the different scheduling methods and considers the various performance metrics that can be used for comparison purposes. A detailed review is provided covering partitioned global and hybrid scheduling algorithms approaches to resource sharing and the latest results from empirical investigations. The survey identifies open issues key research challenges and likely productive research directions.;
Mnemosyne: lightweight persistent memory;"New storage-class memory (SCM) technologies such as phase-change memory STT-RAM and memristors promise user-level access to non-volatile storage through regular memory instructions. These memory devices enable fast user-mode access to persistence allowing regular in-memory data structures to survive system crashes.In this paper we present Mnemosyne a simple interface for programming with persistent memory. Mnemosyne addresses two challenges: how to create and manage such memory and how to ensure consistency in the presence of failures. Without additional mechanisms a system failure may leave data structures in SCM in an invalid state crashing the program the next time it starts.In Mnemosyne programmers declare global persistent data with the keyword pstatic"" or allocate it dynamically. Mnemosyne provides primitives for directly modifying persistent variables and supports consistent updates through a lightweight transaction mechanism. Compared to past work on disk-based persistent memory Mnemosyne reduces latency to storage by writing data directly to memory at the granularity of an update rather than writing memory pages back to disk through the file system. In tests emulating the performance characteristics of forthcoming SCMs we show that Mnemosyne can persist data as fast as 3 microseconds. Furthermore it provides a 35 percent performance increase when applied in the OpenLDAP directory server. In microbenchmark studies we find that Mnemosyne can be up to 1400% faster than alternative persistence strategies such as Berkeley DB or Boost serialization that are designed for disks.""";
Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems;The past four years have seen the rise of conversational agents (CAs) in everyday life. Apple Microsoft Amazon Google and Facebook have all embedded proprietary CAs within their software and increasingly conversation is becoming a key mode of human-computer interaction. Whilst we have long been familiar with the notion of computers that speak the investigative concern within HCI has been upon multimodality rather than dialogue alone and there is no sense of how such interfaces are used in everyday life. This paper reports the findings of interviews with 14 users of CAs in an effort to understand the current interactional factors affecting everyday use. We find user expectations dramatically out of step with the operation of the systems particularly in terms of known machine intelligence system capability and goals. Using Norman's 'gulfs of execution and evaluation' [30] we consider the implications of these findings for the design of future systems.;
Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems;In this paper we present pFabric a minimalistic datacenter transport design that provides near theoretically optimal flow completion times even at the 99th percentile for short flows while still minimizing average flow completion time for long flows. Moreover pFabric delivers this performance with a very simple design that is based on a key conceptual insight: datacenter transport should decouple flow scheduling from rate control. For flow scheduling packets carry a single priority number set independently by each flow switches have very small buffers and implement a very simple priority-based scheduling/dropping mechanism. Rate control is also correspondingly simpler flows start at line rate and throttle back only under high and persistent packet loss. We provide theoretical intuition and show via extensive simulations that the combination of these two simple mechanisms is sufficient to provide near-optimal performance.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;In this paper we introduce Chisel a new hardware construction language that supports advanced hardware design using highly parameterized generators and layered domain-specific hardware languages. By embedding Chisel in the Scala programming language we raise the level of hardware design abstraction by providing concepts including object orientation functional programming parameterized types and type inference. Chisel can generate a high-speed C++-based cycle-accurate software simulator or low-level Verilog designed to map to either FPGAs or to a standard ASIC flow for synthesis. This paper presents Chisel its embedding in Scala hardware examples and results for C++ simulation Verilog emulation and ASIC synthesis.;
Proceedings of the 49th Annual Design Automation Conference;Humans move their hands and bodies together to communicate and solve tasks. Capturing and replicating such coordinated activity is critical for virtual characters that behave realistically. Surprisingly most methods treat the 3D modeling and tracking of bodies and hands separately. Here we formulate a model of hands and bodies interacting together and fit it to full-body 4D sequences. When scanning or capturing the full body in 3D hands are small and often partially occluded making their shape and pose hard to recover. To cope with low-resolution occlusion and noise we develop a new model called MANO (hand Model with Articulated and Non-rigid defOrmations). MANO is learned from around 1000 high-resolution 3D scans of hands of 31 subjects in a wide variety of hand poses. The model is realistic low-dimensional captures non-rigid shape changes with pose is compatible with standard graphics packages and can fit any human hand. MANO provides a compact mapping from hand poses to pose blend shape corrections and a linear manifold of pose synergies. We attach MANO to a standard parameterized 3D body shape model (SMPL) resulting in a fully articulated body and hand model (SMPL+H). We illustrate SMPL+H by fitting complex natural activities of subjects captured with a 4D scanner. The fitting is fully automatic and results in full body models that move naturally with detailed hand motions and a realism not seen before in full body performance capture. The models and data are freely available for research purposes at http://mano.is.tue.mpg.de.;
Most Tensor Problems Are NP-Hard;We prove that multilinear (tensor) analogues of many efficiently computable problems in numerical linear algebra are NP-hard. Our list includes: determining the feasibility of a system of bilinear equations deciding whether a 3-tensor possesses a given eigenvalue singular value or spectral norm approximating an eigenvalue eigenvector singular vector or the spectral norm and determining the rank or best rank-1 approximation of a 3-tensor. Furthermore we show that restricting these problems to symmetric tensors does not alleviate their NP-hardness. We also explain how deciding nonnegative definiteness of a symmetric 4-tensor is NP-hard and how computing the combinatorial hyperdeterminant is NP- #P- and VNP-hard.;
Whole-home gesture recognition using wireless signals;This paper presents WiSee a novel gesture recognition system that leverages wireless signals (e.g. Wi-Fi) to enable whole-home sensing and recognition of human gestures. Since wireless signals do not require line-of-sight and can traverse through walls WiSee can enable whole-home gesture recognition using few wireless sources. Further it achieves this goal without requiring instrumentation of the human body with sensing devices. We implement a proof-of-concept prototype of WiSee using USRP-N210s and evaluate it in both an office environment and a two- bedroom apartment. Our results show that WiSee can identify and classify a set of nine gestures with an average accuracy of 94%.;
Proceedings of the 19th Annual International Conference on Mobile Computing &amp Networking;We present the first large-scale analysis of failures in a data center network. Through our analysis we seek to answer several fundamental questions: which devices/links are most unreliable what causes failures how do failures impact network traffic and how effective is network redundancy? We answer these questions using multiple data sources commonly collected by network operators. The key findings of our study are that (1) data center networks show high reliability (2) commodity switches such as ToRs and AggS are highly reliable (3) load balancers dominate in terms of failure occurrences with many short-lived software related faults(4) failures have potential to cause loss of many small packets such as keep alive messages and ACKs and (5) network redundancy is only 40% effective in reducing the median impact of failure.;
Proceedings of the ACM SIGCOMM 2011 Conference;A large number of distributed applications requires continuous and timely processing of information as it flows from the periphery to the center of the system. Examples include intrusion detection systems which analyze network traffic in real-time to identify possible attacks environmental monitoring applications which process raw data coming from sensor networks to identify critical situations or applications performing online analysis of stock prices to identify trends and forecast future values.Traditional DBMSs which need to store and index data before processing it can hardly fulfill the requirements of timeliness coming from such domains. Accordingly during the last decade different research communities developed a number of tools which we collectively call Information flow processing (IFP) systems to support these scenarios. They differ in their system architecture data model rule model and rule language. In this article we survey these systems to help researchers who often come from different backgrounds in understanding how the various approaches they adopt may complement each other.In particular we propose a general unifying model to capture the different aspects of an IFP system and use it to provide a complete and precise classification of the systems and mechanisms proposed so far.;
Fast Matrix Factorization for Online Recommendation with Implicit Feedback;This paper contributes improvements on both the effectiveness and efficiency of Matrix Factorization (MF) methods for implicit feedback. We highlight two critical issues of existing works. First due to the large space of unobserved feedback most existing works resort to assign a uniform weight to the missing data to reduce computational complexity. However such a uniform assumption is invalid in real-world settings. Second most methods are also designed in an offline setting and fail to keep up with the dynamic nature of online data. We address the above two issues in learning MF models from implicit feedback. We first propose to weight the missing data based on item popularity which is more effective and flexible than the uniform-weight assumption. However such a non-uniform weighting poses efficiency challenge in learning the model. To address this we specifically design a new learning algorithm based on the element-wise Alternating Least Squares (eALS) technique for efficiently optimizing a MF model with variably-weighted missing data. We exploit this efficiency to then seamlessly devise an incremental update strategy that instantly refreshes a MF model given new feedback. Through comprehensive experiments on two public datasets in both offline and online protocols we show that our implemented open-source (https://github.com/hexiangnan/sigir16-eals) eALS consistently outperforms state-of-the-art implicit MF methods.;
Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval;The explosion of digital data and the ever-growing need for fast data analysis have made in-memory big-data processing in computer systems increasingly important. In particular large-scale graph processing is gaining attention due to its broad applicability from social science to machine learning. However scalable hardware design that can efficiently process large graphs in main memory is still an open problem. Ideally cost-effective and scalable graph processing systems can be realized by building a system whose performance increases proportionally with the sizes of graphs that can be stored in the system which is extremely challenging in conventional systems due to severe memory bandwidth limitations.In this work we argue that the conventional concept of processing-in-memory (PIM) can be a viable solution to achieve such an objective. The key modern enabler for PIM is the recent advancement of the 3D integration technology that facilitates stacking logic and memory dies in a single package which was not available when the PIM concept was originally examined. In order to take advantage of such a new technology to enable memory-capacity-proportional performance we design a programmable PIM accelerator for large-scale graph processing called Tesseract. Tesseract is composed of (1) a new hardware architecture that fully utilizes the available memory bandwidth (2) an efficient method of communication between different memory partitions and (3) a programming interface that reflects and exploits the unique hardware design. It also includes two hardware prefetchers specialized for memory access patterns of graph processing which operate based on the hints provided by our programming model. Our comprehensive evaluations using five state-of-the-art graph processing workloads with large real-world graphs show that the proposed architecture improves average system performance by a factor of ten and achieves 87% average energy reduction over conventional systems.;
Proceedings of the 42nd Annual International Symposium on Computer Architecture;Despite the growing interest in user experience (UX) it has been hard to gain a common agreement on the nature and scope of UX. In this paper we report a survey that gathered the views on UX of 275 researchers and practitioners from academia and industry. Most respondents agree that UX is dynamic context-dependent and subjective. With respect to the more controversial issues the authors propose to delineate UX as something individual (instead of social) that emerges from interacting with a product system service or an object. The draft ISO definition on UX seems to be in line with the survey findings although the issues of experiencing anticipated use and the object of UX will require further explication. The outcome of this survey lays ground for understanding scoping and defining the concept of user experience.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;An associate professor at New York Universitys Stern School of Business uncovers answers about who are the employers in paid crowdsourcing what tasks they post and how much they pay.;
A practical guide for using statistical tests to assess randomized algorithms in software engineering;Randomized algorithms have been used to successfully address many different types of software engineering problems. This type of algorithms employ a degree of randomness as part of their logic. Randomized algorithms are useful for difficult problems where a precise solution cannot be derived in a deterministic way within reasonable time. However randomized algorithms produce different results on every run when applied to the same problem instance. It is hence important to assess the effectiveness of randomized algorithms by collecting data from a large enough number of runs. The use of rigorous statistical tests is then essential to provide support to the conclusions derived by analyzing such data. In this paper we provide a systematic review of the use of randomized algorithms in selected software engineering venues in 2009. Its goal is not to perform a complete survey but to get a representative snapshot of current practice in software engineering research. We show that randomized algorithms are used in a significant percentage of papers but that in most cases randomness is not properly accounted for.This casts doubts on the validity of most empirical results assessing randomized algorithms. There are numerous statistical tests based on different assumptions and it is not always clear when and how to use these tests. We hence provide practical guidelines to support empirical research on randomized algorithms in software engineering;
Proceedings of the 33rd International Conference on Software Engineering;Energy is increasingly a first-order concern in computer systems. Exploiting energy-accuracy trade-offs is an attractive choice in applications that can tolerate inaccuracies. Recent work has explored exposing this trade-off in programming models. A key challenge though is how to isolate parts of the program that must be precise from those that can be approximated so that a program functions correctly even as quality of service degrades.We propose using type qualifiers to declare data that may be subject to approximate computation. Using these types the system automatically maps approximate variables to low-power storage uses low-power operations and even applies more energy-efficient algorithms provided by the programmer. In addition the system can statically guarantee isolation of the precise program component from the approximate component. This allows a programmer to control explicitly how information flows from approximate data to precise data. Importantly employing static analysis eliminates the need for dynamic checks further improving energy savings. As a proof of concept we develop EnerJ an extension to Java that adds approximate data types. We also propose a hardware architecture that offers explicit approximate storage and computation. We port several applications to EnerJ and show that our extensions are expressive and effective a small number of annotations lead to significant potential energy savings (10%-50%) at very little accuracy cost.;
Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation;The field of 3D face modeling has a large gap between high-end and low-end methods. At the high end the best facial animation is indistinguishable from real humans but this comes at the cost of extensive manual labor. At the low end face capture from consumer depth sensors relies on 3D face models that are not expressive enough to capture the variability in natural facial shape and expression. We seek a middle ground by learning a facial model from thousands of accurately aligned 3D scans. Our FLAME model (Faces Learned with an Articulated Model and Expressions) is designed to work with existing graphics software and be easy to fit to data. FLAME uses a linear shape space trained from 3800 scans of human heads. FLAME combines this linear shape space with an articulated jaw neck and eyeballs pose-dependent corrective blendshapes and additional global expression blendshapes. The pose and expression dependent articulations are learned from 4D face sequences in the D3DFACS dataset along with additional 4D sequences. We accurately register a template mesh to the scan sequences and make the D3DFACS registrations available for research purposes. In total the model is trained from over 33 000 scans. FLAME is low-dimensional but more expressive than the FaceWarehouse model and the Basel Face Model. We compare FLAME to these models by fitting them to static 3D scans and 4D sequences using the same optimization method. FLAME is significantly more accurate and is available for research purposes (http://flame.is.tue.mpg.de).;
Local light field fusion: practical view synthesis with prescriptive sampling guidelines;We present a practical and robust deep learning solution for capturing and rendering novel views of complex real world scenes for virtual exploration. Previous approaches either require intractably dense view sampling or provide little to no guidance for how users should sample views of a scene to reliably render high-quality novel views. Instead we propose an algorithm for view synthesis from an irregular grid of sampled views that first expands each sampled view into a local light field via a multiplane image (MPI) scene representation then renders novel views by blending adjacent local light fields. We extend traditional plenoptic sampling theory to derive a bound that specifies precisely how densely users should sample views of a given scene when using our algorithm. In practice we apply this bound to capture and render views of real world scenes that achieve the perceptual quality of Nyquist rate view sampling while using up to 4000X fewer views. We demonstrate our approach's practicality with an augmented reality smart-phone app that guides users to capture input images of a scene and viewers that enable realtime virtual exploration on desktop and mobile platforms.;
Using mobile phones to determine transportation modes;As mobile phones advance in functionality and capability they are being used for more than just communication. Increasingly these devices are being employed as instruments for introspection into habits and situations of individuals and communities. Many of the applications enabled by this new use of mobile phones rely on contextual information. The focus of this work is on one dimension of context the transportation mode of an individual when outside. We create a convenient (no specific position and orientation setting) classification system that uses a mobile phone with a built-in GPS receiver and an accelerometer. The transportation modes identified include whether an individual is stationary walking running biking or in motorized transport. The overall classification system consists of a decision tree followed by a first-order discrete Hidden Markov Model and achieves an accuracy level of 93.6% when tested on a dataset obtained from sixteen individuals.;
NV-Heaps: making persistent objects fast and safe with next-generation non-volatile memories;Persistent user-defined objects present an attractive abstraction for working with non-volatile program state. However the slow speed of persistent storage (i.e. disk) has restricted their design and limited their performance. Fast byte-addressable non-volatile technologies such as phase change memory will remove this constraint and allow programmers to build high-performance persistent data structures in non-volatile storage that is almost as fast as DRAM. Creating these data structures requires a system that is lightweight enough to expose the performance of the underlying memories but also ensures safety in the presence of application and system failures by avoiding familiar bugs such as dangling pointers multiple free()s and locking errors. In addition the system must prevent new types of hard-to-find pointer safety bugs that only arise with persistent objects. These bugs are especially dangerous since any corruption they cause will be permanent.We have implemented a lightweight high-performance persistent object system called NV-heaps that provides transactional semantics while preventing these errors and providing a model for persistence that is easy to use and reason about. We implement search trees hash tables sparse graphs and arrays using NV-heaps BerkeleyDB and Stasis. Our results show that NV-heap performance scales with thread count and that data structures implemented using NV-heaps out-perform BerkeleyDB and Stasis implementations by 32x and 244x respectively by avoiding the operating system and minimizing other software overheads. We also quantify the cost of enforcing the safety guarantees that NV-heaps provide and measure the costs of NV-heap primitive operations.;
Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems;The evolution of ubiquitous sensing technologies has led to intelligent environments that can monitor and react to our daily activities such as adapting our heating and cooling systems responding to our gestures and monitoring our elderly. In this paper we ask whether it is possible for smart environments to monitor our vital signs remotely without instrumenting our bodies. We introduce Vital-Radio a wireless sensing technology that monitors breathing and heart rate without body contact. Vital-Radio exploits the fact that wireless signals are affected by motion in the environment including chest movements due to inhaling and exhaling and skin vibrations due to heartbeats. We describe the operation of Vital-Radio and demonstrate through a user study that it can track users' breathing and heart rates with a median accuracy of 99% even when users are 8~meters away from the device or in a different room. Furthermore it can monitor the vital signs of multiple people simultaneously. We envision that Vital-Radio can enable smart homes that monitor people's vital signs without body instrumentation and actively contribute to their inhabitants' well-being.;
Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems;The motivation and key concepts behind answer set programming---a promising approach to declarative problem solving.;
The multikernel: a new OS architecture for scalable multicore systems;Commodity computer systems contain more and more processor cores and exhibit increasingly diverse architectural tradeoffs including memory hierarchies interconnects instruction sets and variants and IO configurations. Previous high-performance computing systems have scaled in specific cases but the dynamic nature of modern client and server workloads coupled with the impossibility of statically optimizing an OS for all workloads and hardware variants pose serious challenges for operating system structures.We argue that the challenge of future multicore hardware is best met by embracing the networked nature of the machine rethinking OS architecture using ideas from distributed systems. We investigate a new OS structure the multikernel that treats the machine as a network of independent cores assumes no inter-core sharing at the lowest level and moves traditional OS functionality to a distributed system of processes that communicate via message-passing.We have implemented a multikernel OS to show that the approach is promising and we describe how traditional scalability problems for operating systems (such as memory management) can be effectively recast using messages and can exploit insights from distributed systems and networking. An evaluation of our prototype on multicore systems shows that even on present-day machines the performance of a multikernel is comparable with a conventional OS and can scale better to support future hardware.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;We describe the design of a string programming/expression language that supports restricted forms of regular expressions conditionals and loops. The language is expressive enough to represent a wide variety of string manipulation tasks that end-users struggle with. We describe an algorithm based on several novel concepts for synthesizing a desired program in this language from input-output examples. The synthesis algorithm is very efficient taking a fraction of a second for various benchmark examples. The synthesis algorithm is interactive and has several desirable features: it can rank multiple solutions and has fast convergence it can detect noise in the user input and it supports an active interaction model wherein the user is prompted to provide outputs on inputs that may have multiple computational interpretations.The algorithm has been implemented as an interactive add-in for Microsoft Excel spreadsheet system. The prototype tool has met the golden test - it has synthesized part of itself and has been used to solve problems beyond author's imagination.;
Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages;"Service providers like Google and Amazon are moving into the SaaS (Software as a Service) business. They turn their huge infrastructure into a cloud-computing environment and aggressively recruit businesses to run applications on their platforms. To enforce security and privacy on such a service model we need to protect the data running on the platform. Unfortunately traditional encryption methods that aim at providing unbreakable"" protection are often not adequate because they do not support the execution of applications such as database queries on the encrypted data. In this paper we discuss the general problem of secure computation on an encrypted database and propose a SCONEDB Secure Computation ON an Encrypted DataBase) model which captures the execution and security requirements. As a case study we focus on the problem of k-nearest neighbor (kNN) computation on an encrypted database. We develop a new asymmetric scalar-product-preserving encryption (ASPE) that preserves a special type of scalar product. We use APSE to construct two secure schemes that support kNN computation on encrypted data each of these schemes is shown to resist practical attacks of a different background knowledge level at a different overhead cost. Extensive performance studies are carried out to evaluate the overhead and the efficiency of the schemes.""";
Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data;Deep learning has shown impressive performance on hard perceptual problems. However researchers found deep learning systems to be vulnerable to small specially crafted perturbations that are imperceptible to humans. Such perturbations cause deep learning systems to mis-classify adversarial examples with potentially disastrous consequences where safety or security is crucial. Prior defenses against adversarial examples either targeted specific attacks or were shown to be ineffective.We propose MagNet a framework for defending neural network classifiers against adversarial examples. MagNet neither modifies the protected classifier nor requires knowledge of the process for generating adversarial examples. MagNet includes one or more separate detector networks and a reformer network. The detector networks learn to differentiate between normal and adversarial examples by approximating the manifold of normal examples. Since they assume no specific process for generating adversarial examples they generalize well. The reformer network moves adversarial examples towards the manifold of normal examples which is effective for correctly classifying adversarial examples with small perturbation. We discuss the intrinsic difficulties in defending against whitebox attack and propose a mechanism to defend against graybox attack. Inspired by the use of randomness in cryptography we use diversity to strengthen MagNet. We show empirically that MagNet is effective against the most advanced state-of-the-art attacks in blackbox and graybox scenarios without sacrificing false positive rate on normal examples.;
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security;Contrary to widespread assumption dynamic RAM (DRAM) the main memory in most modern computers retains its contents for several seconds after power is lost even at room temperature and even if removed from a motherboard. Although DRAM becomes less reliable when it is not refreshed it is not immediately erased and its contents persist sufficiently for malicious (or forensic) acquisition of usable full-system memory images. We show that this phenomenon limits the ability of an operating system to protect cryptographic key material from an attacker with physical access to a machine. It poses a particular threat to laptop users who rely on disk encryption: we demonstrate that it could be used to compromise several popular disk encryption products without the need for any special devices or materials. We experimentally characterize the extent and predictability of memory retention and report that remanence times can be increased dramatically with simple cooling techniques. We offer new algorithms for finding cryptographic keys in memory images and for correcting errors caused by bit decay. Though we discuss several strategies for mitigating these risks we know of no simple remedy that would eliminate them.;
Tagoram: real-time tracking of mobile RFID tags to high precision using COTS devices;In many applications we have to identify an object and then locate the object to within high precision (centimeter- or millimeter-level). Legacy systems that can provide such accuracy are either expensive or suffering from performance degradation resulting from various impacts e.g. occlusion for computer vision based approaches.In this work we present an RFID-based system Tagoram for object localization and tracking using COTS RFID tags and readers. Tracking mobile RFID tags in real time has been a daunting task especially challenging for achieving high precision. Our system achieves these three goals by leveraging the phase value of the backscattered signal provided by the COTS RFID readers to estimate the location of the object. In Tagoram we exploit the tag's mobility to build a virtual antenna array by using readings from a few physical antennas over a time window. To illustrate the basic idea of our system we firstly focus on a simple scenario where the tag is moving along a fixed track known to the system. We propose Differential Augmented Hologram (DAH) which will facilitate the instant tracking of the mobile RFID tag to a high precision. We then devise a comprehensive solution to accurately recover the tag's moving trajectories and its locations relaxing the assumption of knowing tag's track function in advance.We have implemented the Tagoram system using COTS RFID tags and readers. The system has been tested extensively in the lab environment and used for more than a year in real airline applications. For lab environment we can track the mobile tags in real time with a millimeter accuracy to a median of 5mm and 7.29mm using linear and circular track respectively. In our year- long large scale baggage sortation systems deployed in two airports our results from real deployments show that Tagoram can achieve a centimeter-level accuracy to a median of 6.35cm in these real deployments.;
Proceedings of the 20th Annual International Conference on Mobile Computing and Networking;When bottleneck buffers are large loss-based congestion control keeps them full causing bufferbloat. When bottleneck buffers are small loss-based congestion control misinterprets loss as a signal of congestion leading to low throughput. Fixing these problems requires an alternative to loss-based congestion control. Finding this alternative requires an understanding of where and how network congestion originates.;
See through walls with WiFi!;Wi-Fi signals are typically information carriers between a transmitter and a receiver. In this paper we show that Wi-Fi can also extend our senses enabling us to see moving objects through walls and behind closed doors. In particular we can use such signals to identify the number of people in a closed room and their relative locations. We can also identify simple gestures made behind a wall and combine a sequence of gestures to communicate messages to a wireless receiver without carrying any transmitting device. The paper introduces two main innovations. First it shows how one can use MIMO interference nulling to eliminate reflections off static objects and focus the receiver on a moving target. Second it shows how one can track a human by treating the motion of a human body as an antenna array and tracking the resulting RF beam. We demonstrate the validity of our design by building it into USRP software radios and testing it in office buildings.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;The Internet is frequently used as a medium for exchange of information and opinions as well as propaganda dissemination. In this study the use of sentiment analysis methodologies is proposed for classification of Web forum opinions in multiple languages. The utility of stylistic and syntactic features is evaluated for sentiment classification of English and Arabic content. Specific feature extraction components are integrated to account for the linguistic characteristics of Arabic. The entropy weighted genetic algorithm (EWGA) is also developed which is a hybridized genetic algorithm that incorporates the information-gain heuristic for feature selection. EWGA is designed to improve performance and get a better assessment of key features. The proposed features and techniques are evaluated on a benchmark movie review dataset and U.S. and Middle Eastern Web forum postings. The experimental results using EWGA with SVM indicate high performance levels with accuracies of over 91% on the benchmark dataset as well as the U.S. and Middle Eastern forums. Stylistic features significantly enhanced performance across all testbeds while EWGA also outperformed other feature selection methods indicating the utility of these features and techniques for document-level classification of sentiments.;
Social coding in GitHub: transparency and collaboration in an open software repository;Social applications on the web let users track and follow the activities of a large number of others regardless of location or affiliation. There is a potential for this transparency to radically improve collaboration and learning in complex knowledge-based activities. Based on a series of in-depth interviews with central and peripheral GitHub users we examined the value of transparency for large-scale distributed collaborations and communities of practice. We find that people make a surprisingly rich set of social inferences from the networked activity information in GitHub such as inferring someone else's technical goals and vision when they edit code or guessing which of several similar projects has the best chance of thriving in the long term. Users combine these inferences into effective strategies for coordinating work advancing technical skills and managing their reputation.;
Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work;Indoor localization is of great importance for a range of pervasive applications attracting many research efforts in the past decades. Most radio-based solutions require a process of site survey in which radio signatures of an interested area are annotated with their real recorded locations. Site survey involves intensive costs on manpower and time limiting the applicable buildings of wireless localization worldwide. In this study we investigate novel sensors integrated in modern mobile phones and leverage user motions to construct the radio map of a floor plan which is previously obtained only by site survey. On this basis we design LiFS an indoor localization system based on off-the-shelf WiFi infrastructure and mobile phones. LiFS is deployed in an office building covering over 1600m2 and its deployment is easy and rapid since little human intervention is needed. In LiFS the calibration of fingerprints is crowdsourced and automatic. Experiment results show that LiFS achieves comparable location accuracy to previous approaches even without site survey.;
Proceedings of the 18th Annual International Conference on Mobile Computing and Networking;Users have begun downloading an increasingly large number of mobile phone applications in response to advancements in handsets and wireless networks. The increased number of applications results in a greater chance of installing Trojans and similar malware. In this paper we propose the Kirin security service for Android which performs lightweight certification of applications to mitigate malware at install time. Kirin certification uses security rules which are templates designed to conservatively match undesirable properties in security configuration bundled with applications. We use a variant of security requirements engineering techniques to perform an in-depth security analysis of Android to produce a set of rules that match malware characteristics. In a sample of 311 of the most popular applications downloaded from the official Android Market Kirin and our rules found 5 applications that implement dangerous functionality and therefore should be installed with extreme caution. Upon close inspection another five applications asserted dangerous rights but were within the scope of reasonable functional needs. These results indicate that security configuration bundled with Android applications provides practical means of detecting malware.;
Proceedings of the 16th ACM Conference on Computer and Communications Security;The ability to perform long accurate molecular dynamics (MD) simulations involving proteins and other biological macro-molecules could in principle provide answers to some of the most important currently outstanding questions in the fields of biology chemistry and medicine. A wide range of biologically interesting phenomena however occur over timescales on the order of a millisecond---several orders of magnitude beyond the duration of the longest current MD simulations.We describe a massively parallel machine called Anton which should be capable of executing millisecond-scale classical MD simulations of such biomolecular systems. The machine which is scheduled for completion by the end of 2008 is based on 512 identical MD-specific ASICs that interact in a tightly coupled manner using a specialized highspeed communication network. Anton has been designed to use both novel parallel algorithms and special-purpose logic to dramatically accelerate those calculations that dominate the time required for a typical MD simulation. The remainder of the simulation algorithm is executed by a programmable portion of each chip that achieves a substantial degree of parallelism while preserving the flexibility necessary to accommodate anticipated advances in physical models and simulation methods.;
Paragon: QoS-aware scheduling for heterogeneous datacenters;Large-scale datacenters (DCs) host tens of thousands of diverse applications each day. However interference between colocated workloads and the difficulty to match applications to one of the many hardware platforms available can degrade performance violating the quality of service (QoS) guarantees that many cloud workloads require. While previous work has identified the impact of heterogeneity and interference existing solutions are computationally intensive cannot be applied online and do not scale beyond few applications.We present Paragon an online and scalable DC scheduler that is heterogeneity and interference-aware. Paragon is derived from robust analytical methods and instead of profiling each application in detail it leverages information the system already has about applications it has previously seen. It uses collaborative filtering techniques to quickly and accurately classify an unknown incoming workload with respect to heterogeneity and interference in multiple shared resources by identifying similarities to previously scheduled applications. The classification allows Paragon to greedily schedule applications in a manner that minimizes interference and maximizes server utilization. Paragon scales to tens of thousands of servers with marginal scheduling overheads in terms of time or state.We evaluate Paragon with a wide range of workload scenarios on both small and large-scale systems including 1000 servers on EC2. For a 2500-workload scenario Paragon enforces performance guarantees for 91% of applications while significantly improving utilization. In comparison heterogeneity-oblivious interference-oblivious and least-loaded schedulers only provide similar guarantees for 14% 11% and 3% of workloads. The differences are more striking in oversubscribed scenarios where resource efficiency is more critical.;
Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems;While many public cloud providers offer pay-as-you-go computing their varying approaches to infrastructure virtualization and software services lead to a problem of plenty. To help customers pick a cloud that fits their needs we develop CloudCmp a systematic comparator of the performance and cost of cloud providers. CloudCmp measures the elastic computing persistent storage and networking services offered by a cloud along metrics that directly reflect their impact on the performance of customer applications. CloudCmp strives to ensure fairness representativeness and compliance of these measurements while limiting measurement cost. Applying CloudCmp to four cloud providers that together account for most of the cloud customers today we find that their offered services vary widely in performance and costs underscoring the need for thoughtful provider selection. From case studies on three representative cloud applications we show that CloudCmp can guide customers in selecting the best-performing provider for their applications.;
Proceedings of the 10th ACM SIGCOMM Conference on Internet Measurement;Two major trends in high-performance computing namely larger numbers of cores and the growing size of on-chip cache memory are creating significant challenges for evaluating the design space of future processor architectures. Fast and scalable simulations are therefore needed to allow for sufficient exploration of large multi-core systems within a limited simulation time budget. By bringing together accurate high-abstraction analytical models with fast parallel simulation architects can trade off accuracy with simulation speed to allow for longer application runs covering a larger portion of the hardware design space. Interval simulation provides this balance between detailed cycle-accurate simulation and one-IPC simulation allowing long-running simulations to be modeled much faster than with detailed cycle-accurate simulation while still providing the detail necessary to observe core-uncore interactions across the entire system. Validations against real hardware show average absolute errors within 25% for a variety of multi-threaded workloads more than twice as accurate on average as one-IPC simulation. Further we demonstrate scalable simulation speed of up to 2.0 MIPS when simulating a 16-core system on an 8-core SMP machine.;
Proceedings of 2011 International Conference for High Performance Computing Networking Storage and Analysis;Using detailed traces from 255 users we conduct a comprehensive study of smartphone use. We characterize intentional user activities -- interactions with the device and the applications used -- and the impact of those activities on network and energy usage. We find immense diversity among users. Along all aspects that we study users differ by one or more orders of magnitude. For instance the average number of interactions per day varies from 10 to 200 and the average amount of data received per day varies from 1 to 1000 MB. This level of diversity suggests that mechanisms to improve user experience or energy consumption will be more effective if they learn and adapt to user behavior. We find that qualitative similarities exist among users that facilitate the task of learning user behavior. For instance the relative application popularity for can be modeled using an exponential distribution with different distribution parameters for different users. We demonstrate the value of adapting to user behavior in the context of a mechanism to predict future energy drain. The 90th percentile error with adaptation is less than half compared to predictions based on average behavior across users.;
Proceedings of the 8th International Conference on Mobile Systems Applications and Services;RSSI is known to be a fickle indicator of whether a wireless link will work for many reasons. This greatly complicates operation because it requires testing and adaptation to find the best rate transmit power or other parameter that is tuned to boost performance. We show that for the first time wireless packet delivery can be accurately predicted for commodity 802.11 NICs from only the channel measurements that they provide. Our model uses 802.11n Channel State Information measurements as input to an OFDM receiver model we develop by using the concept of effective SNR. It is simple easy to deploy broadly useful and accurate. It makes packet delivery predictions for 802.11a/g SISO rates and 802.11n MIMO rates plus choices of transmit power and antennas. We report testbed experiments that show narrow transition regions (&lt2 dB for most links) similar to the near-ideal case of narrowband frequency-flat channels. Unlike RSSI this lets us predict the highest rate that will work for a link trim transmit power and more. We use trace-driven simulation to show that our rate prediction is as good as the best rate adaptation algorithms for 802.11a/g even over dynamic channels and extends this good performance to 802.11n.;
Proceedings of the ACM SIGCOMM 2010 Conference;Energy efficiency is the new fundamental limiter of processor performance way beyond numbers of processors.;
Write off-loading: Practical power management for enterprise storage;In enterprise data centers power usage is a problem impacting server density and the total cost of ownership. Storage uses a significant fraction of the power budget and there are no widely deployed power-saving solutions for enterprise storage systems. The traditional view is that enterprise workloads make spinning disks down ineffective because idle periods are too short. We analyzed block-level traces from 36 volumes in an enterprise data center for one week and concluded that significant idle periods exist and that they can be further increased by modifying the read/write patterns using write off-loading. Write off-loading allows write requests on spun-down disks to be temporarily redirected to persistent storage elsewhere in the data center.The key challenge is doing this transparently and efficiently at the block level without sacrificing consistency or failure resilience. We describe our write off-loading design and implementation that achieves these goals. We evaluate it by replaying portions of our traces on a rack-based testbed. Results show that just spinning disks down when idle saves 28--36% of energy and write off-loading further increases the savings to 45--60%.;
A survey of autonomic computingâ€”degrees models and applications;Autonomic Computing is a concept that brings together many fields of computing with the purpose of creating computing systems that self-manage. In its early days it was criticised as being a â€œhype topicâ€ or a rebadging of some Multi Agent Systems work. In this survey we hope to show that this was not indeed â€˜hypeâ€™ and that though it draws on much work already carried out by the Computer Science and Control communities its innovation is strong and lies in its robust application to the specific self-management of computing systems. To this end we first provide an introduction to the motivation and concepts of autonomic computing and describe some research that has been seen as seminal in influencing a large proportion of early work. Taking the components of an established reference model in turn we discuss the works that have provided significant contributions to that area. We then look at larger scaled systems that compose autonomic systems illustrating the hierarchical nature of their architectures. Autonomicity is not a well defined subject and as such different systems adhere to different degrees of Autonomicity therefore we cross-slice the body of work in terms of these degrees. From this we list the key applications of autonomic computing and discuss the research work that is missing and what we believe the community should be considering.;
An introduction to Docker for reproducible research;As computational work becomes more and more integral to many aspects of scientific research computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues including virtual machines and workflow systems and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization cross-platform portability modular re-usable elements versioning and a 'DevOps' philosophy to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.;
Wireless device identification with radiometric signatures;We design implement and evaluate a technique to identify the source network interface card (NIC) of an IEEE 802.11 frame through passive radio-frequency analysis. This technique called PARADIS leverages minute imperfections of transmitter hardware that are acquired at manufacture and are present even in otherwise identical NICs. These imperfections are transmitter-specific and manifest themselves as artifacts of the emitted signals. In PARADIS we measure differentiating artifacts of individual wireless frames in the modulation domain apply suitable machine-learning classification tools to achieve significantly higher degrees of NIC identification accuracy than prior best known schemes.We experimentally demonstrate effectiveness of PARADIS in differentiating between more than 130 identical 802.11 NICs with accuracy in excess of 99%. Our results also show that the accuracy of PARADIS is resilient against ambient noise and fluctuations of the wireless channel.Although our implementation deals exclusively with IEEE 802.11 the approach itself is general and will work with any digital modulation scheme.;
Proceedings of the 14th ACM International Conference on Mobile Computing and Networking;"The prospect of outsourcing an increasing amount of data storage and management to cloud services raises many new privacy concerns for individuals and businesses alike. The privacy concerns can be satisfactorily addressed if users encrypt the data they send to the cloud. If the encryption scheme is homomorphic the cloud can still perform meaningful computations on the data even though it is encrypted.In fact we now know a number of constructions of fully homomorphic encryption schemes that allow arbitrary computation on encrypted data. In the last two years solutions for fully homomorphic encryption have been proposed and improved upon but it is hard to ignore the elephant in the room namely efficiency -- can homomorphic encryption ever be efficient enough to be practical? Certainly it seems that all known fully homomorphic encryption schemes have a long way to go before they can be used in practice. Given this state of affairs our contribution is two-fold.First we exhibit a number of real-world applications in the medical financial and the advertising domains which require only that the encryption scheme is somewhat"" homomorphic. Somewhat homomorphic encryption schemes which support a limited number of homomorphic operations can be much faster and more compact than fully homomorphic encryption schemes.Secondly we show a proof-of-concept implementation of the recent somewhat homomorphic encryption scheme of Brakerski and Vaikuntanathan whose security relies on the ""ring learning with errors"" (Ring LWE) problem. The scheme is very efficient and has reasonably short ciphertexts. Our unoptimized implementation in magma enjoys comparable efficiency to even optimized pairing-based schemes with the same level of security and homomorphic capacity. We also show a number of application-specific optimizations to the encryption scheme most notably the ability to convert between different message encodings in a ciphertext.""";
Proceedings of the 3rd ACM Workshop on Cloud Computing Security Workshop;Learning effective feature representations and similarity measures are crucial to the retrieval performance of a content-based image retrieval (CBIR) system. Despite extensive research efforts for decades it remains one of the most challenging open problems that considerably hinders the successes of real-world CBIR systems. The key challenge has been attributed to the well-known ``semantic gap'' issue that exists between low-level image pixels captured by machines and high-level semantic concepts perceived by human. Among various techniques machine learning has been actively investigated as a possible direction to bridge the semantic gap in the long term. Inspired by recent successes of deep learning techniques for computer vision and other applications in this paper we attempt to address an open problem: if deep learning is a hope for bridging the semantic gap in CBIR and how much improvements in CBIR tasks can be achieved by exploring the state-of-the-art deep learning techniques for learning feature representations and similarity measures. Specifically we investigate a framework of deep learning with application to CBIR tasks with an extensive set of empirical studies by examining a state-of-the-art deep learning method (Convolutional Neural Networks) for CBIR tasks under varied settings. From our empirical studies we find some encouraging results and summarize some important insights for future research.;
Proceedings of the 22nd ACM International Conference on Multimedia;"Networks today rely on middleboxes to provide critical performance security and policy compliance capabilities. Achieving these benefits and ensuring that the traffic is directed through the desired sequence of middleboxes requires significant manual effort and operator expertise. In this respect Software-Defined Networking (SDN) offers a promising alternative. Middleboxes however introduce new aspects (e.g. policy composition resource management packet modifications) that fall outside the purvey of traditional L2/L3 functions that SDN supports (e.g. access control or routing). This paper presents SIMPLE a SDN-based policy enforcement layer for efficient middlebox-specific traffic steering''. In designing SIMPLE we take an explicit stance to work within the constraints of legacy middleboxes and existing SDN interfaces. To this end we address algorithmic and system design challenges to demonstrate the feasibility of using SDN to simplify middlebox traffic steering. In doing so we also take a significant step toward addressing industry concerns surrounding the ability of SDN to integrate with existing infrastructure and support L4-L7 capabilities.""";
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;Permissionless blockchains allow the execution of arbitrary programs (called smart contracts) enabling mutually untrusted entities to interact without relying on trusted third parties. Despite their potential repeated security concerns have shaken the trust in handling billions of USD by smart contracts. To address this problem we present Securify a security analyzer for Ethereum smart contracts that is scalable fully automated and able to prove contract behaviors as safe/unsafe with respect to a given property. Securify's analysis consists of two steps. First it symbolically analyzes the contract's dependency graph to extract precise semantic information from the code. Then it checks compliance and violation patterns that capture sufficient conditions for proving if a property holds or not. To enable extensibility all patterns are specified in a designated domain-specific language. Securify is publicly released it has analyzed &gt18K contracts submitted by its users and is regularly used to conduct security audits by experts. We present an extensive evaluation of Securify over real-world Ethereum smart contracts and demonstrate that it can effectively prove the correctness of smart contracts and discover critical violations.;
Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security;Sparse matrix-vector multiplication (SpMV) is of singular importance in sparse linear algebra. In contrast to the uniform regularity of dense linear algebra sparse operations encounter a broad spectrum of matrices ranging from the regular to the highly irregular. Harnessing the tremendous potential of throughput-oriented processors for sparse operations requires that we expose substantial fine-grained parallelism and impose sufficient regularity on execution paths and memory access patterns. We explore SpMV methods that are well-suited to throughput-oriented architectures like the GPU and which exploit several common sparsity classes. The techniques we propose are efficient successfully utilizing large percentages of peak bandwidth. Furthermore they deliver excellent total throughput averaging 16 GFLOP/s and 10 GFLOP/s in double precision for structured grid and unstructured mesh matrices respectively on a GeForce GTX 285. This is roughly 2.8 times the throughput previously achieved on Cell BE and more than 10 times that of a quad-core Intel Clovertown system.;
Proceedings of the Conference on High Performance Computing Networking Storage and Analysis;This work observes that a large fraction of the computations performed by Deep Neural Networks (DNNs) are intrinsically ineffectual as they involve a multiplication where one of the inputs is zero. This observation motivates Cnvlutin (CNV) a value-based approach to hardware acceleration that eliminates most of these ineffectual operations improving performance and energy over a state-of-the-art accelerator with no accuracy loss. CNV uses hierarchical data-parallel units allowing groups of lanes to proceed mostly independently enabling them to skip over the ineffectual computations. A co-designed data storage format encodes the computation elimination decisions taking them off the critical path while avoiding control divergence in the data parallel units. Combined the units and the data storage format result in a data-parallel architecture that maintains wide aligned accesses to its memory hierarchy and that keeps its data lanes busy. By loosening the ineffectual computation identification criterion CNV enables further performance and energy efficiency improvements and more so if a loss in accuracy is acceptable. Experimental measurements over a set of state-of-the-art DNNs for image classification show that CNV improves performance over a state-of-the-art accelerator from 1.24\texttimes{;
Proceedings of the 43rd International Symposium on Computer Architecture;We present the design implementation and evaluation of CONGA a network-based distributed congestion-aware load balancing mechanism for datacenters. CONGA exploits recent trends including the use of regular Clos topologies and overlays for network virtualization. It splits TCP flows into flowlets estimates real-time congestion on fabric paths and allocates flowlets to paths based on feedback from remote switches. This enables CONGA to efficiently balance load and seamlessly handle asymmetry without requiring any TCP modifications. CONGA has been implemented in custom ASICs as part of a new datacenter fabric. In testbed experiments CONGA has 5x better flow completion times than ECMP even with a single link failure and achieves 2-8x better throughput than MPTCP in Incast scenarios. Further the Price of Anarchy for CONGA is provably small in Leaf-Spine topologies hence CONGA is nearly as effective as a centralized scheduler while being able to react to congestion in microseconds. Our main thesis is that datacenter fabric load balancing is best done in the network and requires global schemes such as CONGA to handle asymmetry.;
Proceedings of the 2014 ACM Conference on SIGCOMM;We present O-CNN an Octree-based Convolutional Neural Network (CNN) for 3D shape analysis. Built upon the octree representation of 3D shapes our method takes the average normal vectors of a 3D model sampled in the finest leaf octants as input and performs 3D CNN operations on the octants occupied by the 3D shape surface. We design a novel octree data structure to efficiently store the octant information and CNN features into the graphics memory and execute the entire O-CNN training and evaluation on the GPU. O-CNN supports various CNN structures and works for 3D shapes in different representations. By restraining the computations on the octants occupied by 3D surfaces the memory and computational costs of the O-CNN grow quadratically as the depth of the octree increases which makes the 3D CNN feasible for high-resolution 3D models. We compare the performance of the O-CNN with other existing 3D CNN solutions and demonstrate the efficiency and efficacy of O-CNN in three shape analysis tasks including object classification shape retrieval and shape segmentation.;
P4p: provider portal for applications;As peer-to-peer (P2P) emerges as a major paradigm for scalable network application design it also exposes significant new challenges in achieving efficient and fair utilization of Internet network resources. Being largely network-oblivious many P2P applications may lead to inefficient network resource usage and/or low application performance. In this paper we propose a simple architecture called P4P to allow for more effective cooperative traffic control between applications and network providers. We conducted extensive simulations and real-life experiments on the Internet to demonstrate the feasibility and effectiveness of P4P. Our experiments demonstrated that P4P either improves or maintains the same level of application performance of native P2P applications while at the same time it substantially reduces network provider cost compared with either native or latency-based localized P2P applications.;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;"It is ubiquitous that meaningful structures are formed by or appear over textured surfaces. Extracting them under the complication of texture patterns which could be regular near-regular or irregular is very challenging but of great practical importance. We propose new inherent variation and relative total variation measures which capture the essential difference of these two types of visual forms and develop an efficient optimization system to extract main structures. The new variation measures are validated on millions of sample patches. Our approach finds a number of new applications to manipulate render and reuse the immense number of structure with texture"" images and drawings that were traditionally difficult to be edited properly.""";
Quincy: fair scheduling for distributed computing clusters;This paper addresses the problem of scheduling concurrent jobs on clusters where application data is stored on the computing nodes. This setting in which scheduling computations close to their data is crucial for performance is increasingly common and arises in systems such as MapReduce Hadoop and Dryad as well as many grid-computing environments. We argue that data-intensive computation benefits from a fine-grain resource sharing model that differs from the coarser semi-static resource allocations implemented by most existing cluster computing architectures. The problem of scheduling with locality and fairness constraints has not previously been extensively studied under this resource-sharing model.We introduce a powerful and flexible new framework for scheduling concurrent distributed jobs with fine-grain resource sharing. The scheduling problem is mapped to a graph datastructure where edge weights and capacities encode the competing demands of data locality fairness and starvation-freedom and a standard solver computes the optimal online schedule according to a global cost model. We evaluate our implementation of this framework which we call Quincy on a cluster of a few hundred computers using a varied workload of data-and CPU-intensive jobs. We evaluate Quincy against an existing queue-based algorithm and implement several policies for each scheduler with and without fairness constraints. Quincy gets better fairness when fairness is requested while substantially improving data locality. The volume of data transferred across the cluster is reduced by up to a factor of 3.9 in our experiments leading to a throughput increase of up to 40%.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;A sensor system capable of automatically recognizing activities would allow many potential ubiquitous applications. In this paper we present an easy to install sensor network and an accurate but inexpensive annotation method. A recorded dataset consisting of 28 days of sensor data and its annotation is described and made available to the community. Through a number of experiments we show how the hidden Markov model and conditional random fields perform in recognizing activities. We achieve a timeslice accuracy of 95.6% and a class accuracy of 79.4%.;
Proceedings of the 10th International Conference on Ubiquitous Computing;In the past five years there has been a dramatic increase in work on Search-Based Software Engineering (SBSE) an approach to Software Engineering (SE) in which Search-Based Optimization (SBO) algorithms are used to address problems in SE. SBSE has been applied to problems throughout the SE lifecycle from requirements and project planning to maintenance and reengineering. The approach is attractive because it offers a suite of adaptive automated and semiautomated solutions in situations typified by large complex problem spaces with multiple competing and conflicting objectives.This article1 provides a review and classification of literature on SBSE. The work identifies research trends and relationships between the techniques applied and the applications to which they have been applied and highlights gaps in the literature and avenues for further research.;
Jupiter Rising: A Decade of Clos Topologies and Centralized Control in Google's Datacenter Network;We present our approach for overcoming the cost operational complexity and limited scale endemic to datacenter networks a decade ago. Three themes unify the five generations of datacenter networks detailed in this paper. First multi-stage Clos topologies built from commodity switch silicon can support cost-effective deployment of building-scale networks. Second much of the general but complex decentralized network routing and management protocols supporting arbitrary deployment scenarios were overkill for single-operator pre-planned datacenter networks. We built a centralized control mechanism based on a global configuration pushed to all datacenter switches. Third modular hardware design coupled with simple robust software allowed our design to also support inter-cluster and wide-area networks. Our datacenter networks run at dozens of sites across the planet scaling in capacity by 100x over ten years to more than 1Pbps of bisection bandwidth.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;Network architectures such as Software-Defined Networks (SDNs) move the control logic off packet processing devices and onto external controllers. These network architectures with decoupled control planes open many unanswered questions regarding reliability scalability and performance when compared to more traditional purely distributed systems. This paper opens the investigation by focusing on two specific questions: given a topology how many controllers are needed and where should they go? To answer these questions we examine fundamental limits to control plane propagation latency on an upcoming Internet2 production deployment then expand our scope to over 100 publicly available WAN topologies. As expected the answers depend on the topology. More surprisingly one controller location is often sufficient to meet existing reaction-time requirements (though certainly not fault tolerance requirements).;
Proceedings of the First Workshop on Hot Topics in Software Defined Networks;Power delivery electricity consumption and heat management are becoming key challenges in data center environments. Several past solutions have individually evaluated different techniques to address separate aspects of this problem in hardware and software and at local and global levels. Unfortunately there has been no corresponding work on coordinating all these solutions. In the absence of such coordination these solutions are likely to interfere with one another in unpredictable (and potentially dangerous) ways. This paper seeks to address this problem. We make two key contributions. First we propose and validate a power management solution that coordinates different individual approaches. Using simulations based on 180 server traces from nine different real-world enterprises we demonstrate the correctness stability and efficiency advantages of our solution. Second using our unified architecture as the base we perform a detailed quantitative sensitivity analysis and draw conclusions about the impact of different architectures implementations workloads and system design choices.;
Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems;The challenges---and great promise---of modern symbolic execution techniques and the tools to help implement them.;
User interactions in social networks and their implications;"Social networks are popular platforms for interaction communication and collaboration between friends. Researchers have recently proposed an emerging class of applications that leverage relationships from social networks to improve security and performance in applications such as email web browsing and overlay routing. While these applications often cite social network connectivity statistics to support their designs researchers in psychology and sociology have repeatedly cast doubt on the practice of inferring meaningful relationships from social network connections alone.This leads to the question: Are social links valid indicators of real user interaction? If not then how can we quantify these factors to form a more accurate model for evaluating socially-enhanced applications? In this paper we address this question through a detailed study of user interactions in the Facebook social network. We propose the use of interaction graphs to impart meaning to online social links by quantifying user interactions. We analyze interaction graphs derived from Facebook user traces and show that they exhibit significantly lower levels of the small-world"" properties shown in their social graph counterparts. This means that these graphs have fewer ""supernodes"" with extremely high degree and overall network diameter increases significantly as a result. To quantify the impact of our observations we use both types of graphs to validate two well-known social-based applications (RE and SybilGuard). The results reveal new insights into both systems and confirm our hypothesis that studies of social applications should use real indicators of user interactions in lieu of social graphs.""";
Proceedings of the 4th ACM European Conference on Computer Systems;Algorithm fairness has started to attract the attention of researchers in AI Software Engineering and Law communities with more than twenty different notions of fairness proposed in the last few years. Yet there is no clear agreement on which definition to apply in each situation. Moreover the detailed differences between multiple definitions are difficult to grasp. To address this issue this paper collects the most prominent definitions of fairness for the algorithmic classification problem explains the rationale behind these definitions and demonstrates each of them on a single unifying case-study. Our analysis intuitively explains why the same case can be considered fair according to some definitions and unfair according to others.;
Proceedings of the International Workshop on Software Fairness;Big data promises automated actionable knowledge creation and predictive models for use by both humans and computers.;
c-Through: part-time optics in data centers;Data-intensive applications that operate on large volumes of data have motivated a fresh look at the design of data center networks. The first wave of proposals focused on designing pure packet-switched networks that provide full bisection bandwidth. However these proposals significantly increase network complexity in terms of the number of links and switches required and the restricted rules to wire them up. On the other hand optical circuit switching technology holds a very large bandwidth advantage over packet switching technology. This fact motivates us to explore how optical circuit switching technology could benefit a data center network. In particular we propose a hybrid packet and circuit switched data center network architecture (or HyPaC for short) which augments the traditional hierarchy of packet switches with a high speed low complexity rack-to-rack optical circuit-switched network to supply high bandwidth to applications. We discuss the fundamental requirements of this hybrid architecture and their design options. To demonstrate the potential benefits of the hybrid architecture we have built a prototype system called c-Through. c-Through represents a design point where the responsibility for traffic demand estimation and traffic demultiplexing resides in end hosts making it compatible with existing packet switches. Our emulation experiments show that the hybrid architecture can provide large benefits to unmodified popular data center applications at a modest scale. Furthermore our experimental experience provides useful insights on the applicability of the hybrid architecture across a range of deployment scenarios.;
Proceedings of the ACM SIGCOMM 2010 Conference;Windows Azure Storage (WAS) is a cloud storage system that provides customers the ability to store seemingly limitless amounts of data for any duration of time. WAS customers have access to their data from anywhere at any time and only pay for what they use and store. In WAS data is stored durably using both local and geographic replication to facilitate disaster recovery. Currently WAS storage comes in the form of Blobs (files) Tables (structured storage) and Queues (message delivery). In this paper we describe the WAS architecture global namespace and data model as well as its resource provisioning load balancing and replication systems.;
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles;Memory isolation is a key property of a reliable and secure computing system--an access to one memory address should not have unintended side effects on data stored in other addresses. However as DRAM process technology scales down to smaller dimensions it becomes more difficult to prevent DRAM cells from electrically interacting with each other. In this paper we expose the vulnerability of commodity DRAM chips to disturbance errors. By reading from the same address in DRAM we show that it is possible to corrupt data in nearby addresses. More specifically activating the same row in DRAM corrupts data in nearby rows. We demonstrate this phenomenon on Intel and AMD systems using a malicious program that generates many DRAM accesses. We induce errors in most DRAM modules (110 out of 129) from three major DRAM manufacturers. From this we conclude that many deployed systems are likely to be at risk. We identify the root cause of disturbance errors as the repeated toggling of a DRAM row's wordline which stresses inter-cell coupling effects that accelerate charge leakage from nearby rows. We provide an extensive characterization study of disturbance errors and their behavior using an FPGA-based testing platform. Among our key findings we show that (i) it takes as few as 139K accesses to induce an error and (ii) up to one in every 1.7K cells is susceptible to errors. After examining various potential ways of addressing the problem we propose a low-overhead solution to prevent the errors;
Proceeding of the 41st Annual International Symposium on Computer Architecuture;As HCI researchers have explored the possibilities of human computation they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk a popular human computation system as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large existing socio-technical systems.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;"Today embedded mobile and cyberphysical systems are ubiquitous and used in many applications from industrial control systems modern vehicles to critical infrastructure. Current trends and initiatives such as Industrie 4.0"" and Internet of Things (IoT) promise innovative business models and novel user experiences through strong connectivity and effective use of next generation of embedded devices. These systems generate process and exchange vast amounts of security-critical and privacy-sensitive data which makes them attractive targets of attacks. Cyberattacks on IoT systems are very critical since they may cause physical damage and even threaten human lives. The complexity of these systems and the potential impact of cyberattacks bring upon new threats.This paper gives an introduction to Industrial IoT systems the related security and privacy challenges and an outlook on possible solutions towards a holistic security framework for Industrial IoT systems.""";
Proceedings of the 52nd Annual Design Automation Conference;A growing number of mobile computing applications are centered around the user's location. The notion of location is broad ranging from physical coordinates (latitude/longitude) to logical labels (like Starbucks McDonalds). While extensive research has been performed in physical localization there have been few attempts in recognizing logical locations. This paper argues that the increasing number of sensors on mobile phones presents new opportunities for logical localization. We postulate that ambient sound light and color in a place convey a photo-acoustic signature that can be sensed by the phone's camera and microphone. In-built accelerometers in some phones may also be useful in inferring broad classes of user-motion often dictated by the nature of the place. By combining these optical acoustic and motion attributes it may be feasible to construct an identifiable fingerprint for logical localization. Hence users in adjacent stores can be separated logically even when their physical positions are extremely close. We propose SurroundSense a mobile phone based system that explores logical localization via ambience fingerprinting. Evaluation results from 51 different stores show that SurroundSense can achieve an average accuracy of 87% when all sensing modalities are employed. We believe this is an encouraging result opening new possibilities in indoor localization.;
Proceedings of the 15th Annual International Conference on Mobile Computing and Networking;Naiad is a distributed system for executing data parallel cyclic dataflow programs. It offers the high throughput of batch processors the low latency of stream processors and the ability to perform iterative and incremental computations. Although existing systems offer some of these features applications that require all three have relied on multiple platforms at the expense of efficiency maintainability and simplicity. Naiad resolves the complexities of combining these features in one framework.A new computational model timely dataflow underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataflow computation with timestamps that represent logical points in the computation and provide the basis for an efficient lightweight coordination mechanism.We show that many powerful high-level programming models can be built on Naiad's low-level primitives enabling such diverse tasks as streaming data analysis iterative machine learning and interactive graph mining. Naiad outperforms specialized systems in their target application domains and its unique features enable the development of new high-performance applications.;
Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles;Modern smartphone operating systems support the development of third-party applications with open system APIs. In addition to an open API the Android operating system also provides a rich inter-application message passing system. This encourages inter-application collaboration and reduces developer burden by facilitating component reuse. Unfortunately message passing is also an application attack surface. The content of messages can be sniffed modified stolen or replaced which can compromise user privacy. Also a malicious application can inject forged or otherwise malicious messages which can lead to breaches of user data and violate application security policies.We examine Android application interaction and identify security risks in application components. We provide a tool ComDroid that detects application communication vulnerabilities. ComDroid can be used by developers to analyze their own applications before release by application reviewers to analyze applications in the Android Market and by end users. We analyzed 20 applications with the help of ComDroid and found 34 exploitable vulnerabilities 12 of the 20 applications have at least one vulnerability.;
Proceedings of the 9th International Conference on Mobile Systems Applications and Services;GPUs have recently attracted the attention of many application developers as commodity data-parallel coprocessors. The newest generations of GPU architecture provide easier programmability and increased generality while maintaining the tremendous memory bandwidth and computational power of traditional GPUs. This opportunity should redirect efforts in GPGPU research from ad hoc porting of applications to establishing principles and strategies that allow efficient mapping of computation to graphics hardware. In this work we discuss the GeForce 8800 GTX processor's organization features and generalized optimization strategies. Key to performance on this platform is using massive multithreading to utilize the large number of cores and hide global memory latency. To achieve this developers face the challenge of striking the right balance between each thread's resource usage and the number of simultaneously active threads. The resources to manage include the number of registers and the amount of on-chip memory used per thread number of threads per multiprocessor and global memory bandwidth. We also obtain increased performance by reordering accesses to off-chip memory to combine requests to the same or contiguous memory locations and apply classical optimizations to reduce the number of executed operations. We apply these strategies across a variety of applications and domains and achieve between a 10.5X to 457X speedup in kernel codes and between 1.16X to 431X total application speedup.;
Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming;We present a new approach for performing high-quality edge-preserving filtering of images and videos in real time. Our solution is based on a transform that defines an isometry between curves on the 2D image manifold in 5D and the real line. This transform preserves the geodesic distance between points on these curves adaptively warping the input signal so that 1D edge-preserving filtering can be efficiently performed in linear time. We demonstrate three realizations of 1D edge-preserving filters show how to produce high-quality 2D edge-preserving filters by iterating 1D-filtering operations and empirically analyze the convergence of this process. Our approach has several desirable features: the use of 1D operations leads to considerable speedups over existing techniques and potential memory savings its computational cost is not affected by the choice of the filter parameters and it is the first edge-preserving filter to work on color images at arbitrary scales in real time without resorting to subsampling or quantization. We demonstrate the versatility of our domain transform and edge-preserving filters on several real-time image and video processing tasks including edge-preserving filtering depth-of-field effects stylization recoloring colorization detail enhancement and tone mapping.;
Mapping the landscape of sustainable HCI;With the recent growth in sustainable HCI now is a good time to map out the approaches being taken and the intellectual commitments that underlie the area to allow for community discussion about where the field should go. Here we provide an empirical analysis of how sustainable HCI is defining itself as a research field. Based on a corpus of published works we identify (1) established genres in the area (2) key unrecognized intellectual differences and (3) emerging issues including urgent avenues for further exploration opportunities for interdisciplinary engagement and key topics for debate.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Trust plays an important role in many Information Systems (IS)-enabled situations. Most IS research employs trust as a measure of interpersonal or person-to-firm relations such as trust in a Web vendor or a virtual team member. Although trust in other people is important this article suggests that trust in the Information Technology (IT) itself also plays a role in shaping IT-related beliefs and behavior. To advance trust and technology research this article presents a set of trust in technology construct definitions and measures. We also empirically examine these construct measures using tests of convergent discriminant and nomological validity. This study contributes to the literature by providing: (a) a framework that differentiates trust in technology from trust in people (b) a theory-based set of definitions necessary for investigating different kinds of trust in technology and (c) validated trust in technology measures useful to research and practice.;
Comparison and Modelling of Country-level Microblog User and Activity in Cyber-physical-social Systems Using Weibo and Twitter Data;As the rapid growth of social media technologies continues Cyber-Physical-Social System (CPSS) has been a hot topic in many industrial applications. The use of â€œmicrobloggingâ€ services such as Twitter has rapidly become an influential way to share information. While recent studies have revealed that understanding and modelling microblog user behaviour with massive usersâ€™ data in social media are keen to success of many practical applications in CPSS a key challenge in literatures is that diversity of geography and cultures in social media technologies strongly affect user behaviour and activity. The motivation of this article is to understand differences and similarities between microblogging users from different countries using social media technologies and to attempt to design a Country-Level Micro-Blog User (CLMB) behaviour and activity model for supporting CPSS applications. We proposed a CLMB model for analysing microblogging user behaviour and their activity across different countries in the CPSS applications. The model has considered three important characteristics of user behaviour in microblogging data including content of microblogging messages user emotion index and user relationship network. We evaluated CLBM model under the collected microblog dataset from 16 countries with the largest number of representative and active users in the world. Experimental results show that (1) for some countries with small population and strong cohesiveness users pay more attention to social functionalities of microblogging service (2) for some countries containing mostly large loose social groups users use microblogging services as a news dissemination platform (3) users in countries whose social network structure exhibits reciprocity rather than hierarchy will use more linguistic elements to express happiness in microblogging services.;
BLOCKBENCH: A Framework for Analyzing Private Blockchains;Blockchain technologies are taking the world by storm. Public blockchains such as Bitcoin and Ethereum enable secure peer-to-peer applications like crypto-currency or smart contracts. Their security and performance are well studied. This paper concerns recent private blockchain systems designed with stronger security (trust) assumption and performance requirement. These systems target and aim to disrupt applications which have so far been implemented on top of database systems for example banking finance and trading applications. Multiple platforms for private blockchains are being actively developed and fine tuned. However there is a clear lack of a systematic framework with which different systems can be analyzed and compared against each other. Such a framework can be used to assess blockchains' viability as another distributed data processing platform while helping developers to identify bottlenecks and accordingly improve their platforms.In this paper we first describe BLOCKBENCH the first evaluation framework for analyzing private blockchains. It serves as a fair means of comparison for different platforms and enables deeper understanding of different system design choices. Any private blockchain can be integrated to BLOCKBENCH via simple APIs and benchmarked against workloads that are based on real and synthetic smart contracts. BLOCKBENCH measures overall and component-wise performance in terms of throughput latency scalability and fault-tolerance. Next we use BLOCKBENCH to conduct comprehensive evaluation of three major private blockchains: Ethereum Parity and Hyperledger Fabric. The results demonstrate that these systems are still far from displacing current database systems in traditional data processing workloads. Furthermore there are gaps in performance among the three systems which are attributed to the design choices at different layers of the blockchain's software stack. We have released BLOCKBENCH for public use.;
Proceedings of the 2017 ACM International Conference on Management of Data;The problem of idle listening is one of the most significant sources of energy consumption in wireless sensor nodes and many techniques have been proposed based on duty cycling to reduce this cost. In this paper we present a new asynchronous duty cycle MAC protocol called Receiver-Initiated MAC (RI-MAC) that uses receiver-initiated data transmission in order to efficiently and effectively operate over a wide range of traffic loads. RI-MAC attempts to minimize the time a sender and its intended receiver occupy the wireless medium to find a rendezvous time for exchanging data while still decoupling the sender and receiver's duty cycle schedules. We show the performance of RI-MAC through detailed ns-2 simulation and through measurements of an implementation in TinyOS in a testbed of MICAz motes. Compared to the prior asynchronous duty cycling approach of X-MAC RI-MAC achieves higher throughput packet delivery ratio and power efficiency under a wide range of traffic loads. Especially when there are contending flows such as bursty traffic or transmissions from hidden nodes RI-MAC significantly improves throughput and packet delivery ratio. Even under light traffic load for which X-MAC is optimized RI-MAC achieves the same high performance in terms of packet delivery ratio and latency while maintaining comparable power efficiency.;
Proceedings of the 6th ACM Conference on Embedded Network Sensor Systems;This survey provides a structured and comprehensive overview of research on security and privacy in computer and communication networks that use game-theoretic approaches. We present a selected set of works to highlight the application of game theory in addressing different forms of security and privacy problems in computer networks and mobile applications. We organize the presented works in six main categories: security of the physical and MAC layers security of self-organizing networks intrusion detection systems anonymity and privacy economics of network security and cryptography. In each category we identify security problems players and game models. We summarize the main results of selected works such as equilibrium analysis and security mechanism designs. In addition we provide a discussion on the advantages drawbacks and future direction of using game theory in this field. In this survey our goal is to instill in the reader an enhanced understanding of different research approaches in applying game-theoretic methods to network security. This survey can also help researchers from various fields develop game-theoretic solutions to current and emerging security problems in computer networking.;
Ear-phone: an end-to-end participatory urban noise mapping system;A noise map facilitates monitoring of environmental noise pollution in urban areas. It can raise citizen awareness of noise pollution levels and aid in the development of mitigation strategies to cope with the adverse effects. However state-of-the-art techniques for rendering noise maps in urban areas are expensive and rarely updated (months or even years) as they rely on population and traffic models rather than on real data. Participatory urban sensing can be leveraged to create an open and inexpensive platform for rendering up-to-date noise maps.In this paper we present the design implementation and performance evaluation of an end-to-end participatory urban noise mapping system called Ear-Phone. Ear-Phone for the first time leverages Compressive Sensing to address the fundamental problem of recovering the noise map from incomplete and random samples obtained by crowdsourcing data collection. Ear-Phone implemented on Nokia N95 and HP iPAQ mobile devices also addresses the challenge of collecting accurate noise pollution readings at a mobile device. Extensive simulations and outdoor experiments demonstrate that Ear-Phone is a feasible platform to assess noise pollution incurring reasonable system resource consumption at mobile devices and providing high reconstruction accuracy of the noise map.;
Proceedings of the 9th ACM/IEEE International Conference on Information Processing in Sensor Networks;This paper presents a method to analyze the powers of a given trilinear form (a special kind of algebraic construction also called a tensor) and obtain upper bounds on the asymptotic complexity of matrix multiplication. Compared with existing approaches this method is based on convex optimization and thus has polynomial-time complexity. As an application we use this method to study powers of the construction given by Coppersmith and Winograd [Journal of Symbolic Computation 1990] and obtain the upper bound Ï‰ &lt 2.3728639 on the exponent of square matrix multiplication which slightly improves the best known upper bound.;
Proceedings of the 39th International Symposium on Symbolic and Algebraic Computation;We present the basic principles that underlie the high-performance implementation of the matrix-matrix multiplication that is part of the widely used GotoBLAS library. Design decisions are justified by successively refining a model of architectures with multilevel memories. A simple but effective algorithm for executing this operation results. Implementations on a broad selection of architectures are shown to achieve near-peak performance.;
Challenges design and analysis of a large-scale p2p-vod system;P2P file downloading and streaming have already become very popular Internet applications. These systems dramatically reduce the server loading and provide a platform for scalable content distribution as long as there is interest for the content. P2P-based video-on-demand (P2P-VoD) is a new challenge for the P2P technology. Unlike streaming live content P2P-VoD has less synchrony in the users sharing video content therefore it is much more difficult to alleviate the server loading and at the same time maintaining the streaming performance. To compensate a small storage is contributed by every peer and new mechanisms for coordinating content replication content discovery and peer scheduling are carefully designed. In this paper we describe and discuss the challenges and the architectural design issues of a large-scale P2P-VoD system based on the experiences of a real system deployed by PPLive. The system is also designed and instrumented with monitoring capability to measure both system and component specific performance metrics (for design improvements) as well as user satisfaction. After analyzing a large amount of collected data we present a number of results on user behavior various system performance metrics including user satisfaction and discuss what we observe based on the system design. The study of a real life system provides valuable insights for the future development of P2P-VoD technology.;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;We present novel designs for virtual and augmented reality near-eye displays based on phase-only holographic projection. Our approach is built on the principles of Fresnel holography and double phase amplitude encoding with additional hardware phase correction factors and spatial light modulator encodings to achieve full color high contrast and low noise holograms with high resolution and true per-pixel focal control. We provide a GPU-accelerated implementation of all holographic computation that integrates with the standard graphics pipeline and enables real-time (â‰¥90 Hz) calculation directly or through eye tracked approximations. A unified focus aberration correction and vision correction model along with a user calibration process accounts for any optical defects between the light source and retina. We use this optical correction ability not only to fix minor aberrations but to enable truly compact eyeglasses-like displays with wide fields of view (80Â°) that would be inaccessible through conventional means. All functionality is evaluated across a series of hardware prototypes we discuss remaining challenges to incorporate all features into a single device.;
Better never than late: meeting deadlines in datacenter networks;The soft real-time nature of large scale web applications in today's datacenters combined with their distributed workflow leads to deadlines being associated with the datacenter application traffic. A network flow is useful and contributes to application throughput and operator revenue if and only if it completes within its deadline. Today's transport pro- tocols (TCP included) given their Internet origins are agnostic to such flow deadlines. Instead they strive to share network resources fairly. We show that this can hurt application performance.Motivated by these observations and other (previously known) deficiencies of TCP in the datacenter environment this paper presents the design and implementation of D3 a deadline-aware control protocol that is customized for the datacenter environment. D3 uses explicit rate control to apportion bandwidth according to flow deadlines. Evaluation from a 19-node two-tier datacenter testbed shows that D3 even without any deadline information easily outper- forms TCP in terms of short flow latency and burst tolerance. Further by utilizing deadline information D3 effectively doubles the peak load that the datacenter network cansupport.;
Proceedings of the ACM SIGCOMM 2011 Conference;MapReduce programming model has simplified the implementation of many data parallel applications. The simplicity of the programming model and the quality of services provided by many implementations of MapReduce attract a lot of enthusiasm among distributed computing communities. From the years of experience in applying MapReduce to various scientific applications we identified a set of extensions to the programming model and improvements to its architecture that will expand the applicability of MapReduce to more classes of applications. In this paper we present the programming model and the architecture of Twister an enhanced MapReduce runtime that supports iterative MapReduce computations efficiently. We also show performance comparisons of Twister with other similar runtimes such as Hadoop and DryadLINQ for large scale data parallel applications.;
Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing;Automated data-driven decision making systems are increasingly being used to assist or even replace humans in many settings. These systems function by learning from historical decisions often taken by humans. In order to maximize the utility of these systems (or classifiers) their training involves minimizing the errors (or misclassifications) over the given historical data. However it is quite possible that the optimally trained classifier makes decisions for people belonging to different social groups with different misclassification rates (e.g. misclassification rates for females are higher than for males) thereby placing these groups at an unfair disadvantage. To account for and avoid such unfairness in this paper we introduce a new notion of unfairness disparate mistreatment which is defined in terms of misclassification rates. We then propose intuitive measures of disparate mistreatment for decision boundary-based classifiers which can be easily incorporated into their formulation as convex-concave constraints. Experiments on synthetic as well as real world datasets show that our methodology is effective at avoiding disparate mistreatment often at a small cost in terms of accuracy.;
Proceedings of the 26th International Conference on World Wide Web;CHOLMOD is a set of routines for factorizing sparse symmetric positive definite matrices of the form A or AAT updating/downdating a sparse Cholesky factorization solving linear systems updating/downdating the solution to the triangular system Lxâ€‰=â€‰b and many other sparse matrix functions for both symmetric and unsymmetric matrices. Its supernodal Cholesky factorization relies on LAPACK and the Level-3 BLAS and obtains a substantial fraction of the peak performance of the BLAS. Both real and complex matrices are supported. CHOLMOD is written in ANSI/ISO C with both C and MATLABTM interfaces. It appears in MATLAB 7.2 as xâ€‰=â€‰Ab when A is sparse symmetric positive definite as well as in several other sparse matrix functions.;
Proceedings of the Conference of the ACM Special Interest Group on Data Communication;We present PacketShader a high-performance software router framework for general packet processing with Graphics Processing Unit (GPU) acceleration. PacketShader exploits the massively-parallel processing power of GPU to address the CPU bottleneck in current software routers. Combined with our high-performance packet I/O engine PacketShader outperforms existing software routers by more than a factor of four forwarding 64B IPv4 packets at 39 Gbps on a single commodity PC. We have implemented IPv4 and IPv6 forwarding OpenFlow switching and IPsec tunneling to demonstrate the flexibility and performance advantage of PacketShader. The evaluation results show that GPU brings significantly higher throughput over the CPU-only implementation confirming the effectiveness of GPU for computation and memory-intensive operations in packet processing.;
Proceedings of the ACM SIGCOMM 2010 Conference;In machine learning the concept of interpretability is both important and slippery.;
Dynamic provable data possession;We consider the problem of efficiently proving the integrity of data stored at untrusted servers. In the provable data possession (PDP) model the client preprocesses the data and then sends it to an untrusted server for storage while keeping a small amount of meta-data. The client later asks the server to prove that the stored data has not been tampered with or deleted (without downloading the actual data). However the original PDP scheme applies only to static (or append-only) files.We present a definitional framework and efficient constructions for dynamic provable data possession (DPDP) which extends the PDP model to support provable updates to stored data. We use a new version of authenticated dictionaries based on rank information. The price of dynamic updates is a performance change from O(1) to O(logn) (or O(nÎµlog n) for a file consisting of n blocks while maintaining the same (or better respectively) probability of misbehavior detection. Our experiments show that this slowdown is very low in practice (e.g. 415KB proof size and 30ms computational overhead for a 1GB file). We also show how to apply our DPDP scheme to outsourced file systems and version control systems (e.g. CVS).;
Proceedings of the 16th ACM Conference on Computer and Communications Security;Comprising more than 61000 servers located across nearly 1000 networks in 70 countries worldwide the Akamai platform delivers hundreds of billions of Internet interactions daily helping thousands of enterprises boost the performance and reliability of their Internet applications. In this paper we give an overview of the components and capabilities of this large-scale distributed computing platform and offer some insight into its architecture design principles operation and management.;
Managing data transfers in computer clusters with orchestra;Cluster computing applications like MapReduce and Dryad transfer massive amounts of data between their computation stages. These transfers can have a significant impact on job performance accounting for more than 50% of job completion times. Despite this impact there has been relatively little work on optimizing the performance of these data transfers with networking researchers traditionally focusing on per-flow traffic management. We address this limitation by proposing a global management architecture and a set of algorithms that (1) improve the transfer times of common communication patterns such as broadcast and shuffle and (2) allow scheduling policies at the transfer level such as prioritizing a transfer over other transfers. Using a prototype implementation we show that our solution improves broadcast completion times by up to 4.5X compared to the status quo in Hadoop. We also show that transfer-level scheduling can reduce the completion time of high-priority transfers by 1.7X.;
Proceedings of the ACM SIGCOMM 2011 Conference;"PEIR the Personal Environmental Impact Report is a participatory sensing application that uses location data sampled from everyday mobile phones to calculate personalized estimates of environmental impact and exposure. It is an example of an important class of emerging mobile systems that combine the distributed processing capacity of the web with the personal reach of mobile technology. This paper documents and evaluates the running PEIR system which includes mobile handset based GPS location data collection and server-side processing stages such as HMM-based activity classification (to determine transportation mode) automatic location data segmentation into trips'' lookup of traffic weather and other context data needed by the models and environmental impact and exposure calculation using efficient implementations of established models. Additionally we describe the user interface components of PEIR and present usage statistics from a two month snapshot of system use. The paper also outlines new algorithmic components developed based on experience with the system and undergoing testing for integration into PEIR including: new map-matching and GSM-augmented activity classification techniques and a selective hiding mechanism that generates believable proxy traces for times a user does not want their real location revealed.""";
Proceedings of the 7th International Conference on Mobile Systems Applications and Services;In many applications data appear with a huge number of instances as well as features. Linear Support Vector Machines (SVM) is one of the most popular tools to deal with such large-scale sparse data. This paper presents a novel dual coordinate descent method for linear SVM with L1-and L2-loss functions. The proposed method is simple and reaches an Îµ-accurate solution in O(log(1/Îµ)) iterations. Experiments indicate that our method is much faster than state of the art solvers such as Pegasos TRON SVMperf and a recent primal coordinate descent implementation.;
Proceedings of the 25th International Conference on Machine Learning;Understanding how users behave when they connect to social networking sites creates opportunities for better interface design richer studies of social interactions and improved design of content distribution systems. In this paper we present a first of a kind analysis of user workloads in online social networks. Our study is based on detailed clickstream data collected over a 12-day period summarizing HTTP sessions of 37024 users who accessed four popular social networks: Orkut MySpace Hi5 and LinkedIn. The data were collected from a social network aggregator website in Brazil which enables users to connect to multiple social networks with a single authentication. Our analysis of the clickstream data reveals key features of the social network workloads such as how frequently people connect to social networks and for how long as well as the types and sequences of activities that users conduct on these sites. Additionally we crawled the social network topology of Orkut so that we could analyze user interaction data in light of the social graph. Our data analysis suggests insights into how users interact with friends in Orkut such as how frequently users visit their friends' or non-immediate friends' pages. In summary our analysis demonstrates the power of using clickstream data in identifying patterns in social network workloads and social interactions. Our analysis shows that browsing which cannot be inferred from crawling publicly available data accounts for 92% of all user activities. Consequently compared to using only crawled data considering silent interactions like browsing friends' pages increases the measured level of interaction among users.;
Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement;Recent advances in computing have led to an explosion in the amount of data being generated. Processing the ever-growing data in a timely manner has made throughput computing an important aspect for emerging applications. Our analysis of a set of important throughput computing kernels shows that there is an ample amount of parallelism in these kernels which makes them suitable for today's multi-core CPUs and GPUs. In the past few years there have been many studies claiming GPUs deliver substantial speedups (between 10X and 1000X) over multi-core CPUs on these kernels. To understand where such large performance difference comes from we perform a rigorous performance analysis and find that after applying optimizations appropriate for both CPUs and GPUs the performance gap between an Nvidia GTX280 processor and the Intel Core i7-960 processor narrows to only 2.5x on average. In this paper we discuss optimization techniques for both CPU and GPU analyze what architecture features contributed to performance differences between the two architectures and recommend a set of architectural features which provide significant improvement in architectural efficiency for throughput kernels.;
Proceedings of the 37th Annual International Symposium on Computer Architecture;Large networks are becoming a widely used abstraction for studying complex systems in a broad set of disciplines ranging from social-network analysis to molecular biology and neuroscience. Despite an increasing need to analyze and manipulate large networks only a limited number of tools are available for this task.Here we describe the Stanford Network Analysis Platform (SNAP) a general-purpose high-performance system that provides easy-to-use high-level operations for analysis and manipulation of large networks. We present SNAP functionality describe its implementational details and give performance benchmarks. SNAP has been developed for single big-memory machines and it balances the trade-off between maximum performance compact in-memory graph representation and the ability to handle dynamic graphs in which nodes and edges are being added or removed over time. SNAP can process massive networks with hundreds of millions of nodes and billions of edges. SNAP offers over 140 different graph algorithms that can efficiently manipulate large graphs calculate structural properties generate regular and random graphs and handle attributes and metadata on nodes and edges. Besides being able to handle large graphs an additional strength of SNAP is that networks and their attributes are fully dynamic they can be modified during the computation at low cost. SNAP is provided as an open-source library in C++ as well as a module in Python.We also describe the Stanford Large Network Dataset a set of social and information real-world networks and datasets which we make publicly available. The collection is a complementary resource to our SNAP software and is widely used for development and benchmarking of graph analytics algorithms.;
Convolutional Matrix Factorization for Document Context-Aware Recommendation;Sparseness of user-to-item rating data is one of the major factors that deteriorate the quality of recommender system. To handle the sparsity problem several recommendation techniques have been proposed that additionally consider auxiliary information to improve rating prediction accuracy. In particular when rating data is sparse document modeling-based approaches have improved the accuracy by additionally utilizing textual data such as reviews abstracts or synopses. However due to the inherent limitation of the bag-of-words model they have difficulties in effectively utilizing contextual information of the documents which leads to shallow understanding of the documents. This paper proposes a novel context-aware recommendation model convolutional matrix factorization (ConvMF) that integrates convolutional neural network (CNN) into probabilistic matrix factorization (PMF). Consequently ConvMF captures contextual information of documents and further enhances the rating prediction accuracy. Our extensive evaluations on three real-world datasets show that ConvMF significantly outperforms the state-of-the-art recommendation models even when the rating data is extremely sparse. We also demonstrate that ConvMF successfully captures subtle contextual difference of a word in a document. Our implementation and datasets are available at http://dm.postech.ac.kr/ConvMF.;
Proceedings of the 10th ACM Conference on Recommender Systems;Yahoo Answers (YA) is a large and diverse question-answer forum acting not only as a medium for sharing technical knowledge but as a place where one can seek advice gather opinions and satisfy one's curiosity about a countless number of things. In this paper we seek to understand YA's knowledge sharing and activity. We analyze the forum categories and cluster them according to content characteristics and patterns of interaction among the users. While interactions in some categories resemble expertise sharing forums others incorporate discussion everyday advice and support. With such a diversity of categories in which one can participate we find that some users focus narrowly on specific topics while others participate across categories. This not only allows us to map related categories but to characterize the entropy of the users' interests. We find that lower entropy correlates with receiving higher answer ratings but only for categories where factual expertise is primarily sought after. We combine both user attributes and answer characteristics to predict within a given category whether a particular answer will be chosen as the best answer by the asker.;
Proceedings of the 17th International Conference on World Wide Web;Emerging byte-addressable non-volatile memory technologies offer performance within an order of magnitude of DRAM prompting their inclusion in the processor memory subsystem. However such load/store accessible Persistent Memory (PM) has implications on system design both hardware and software. In this paper we explore system software support to enable low-overhead PM access by new and legacy applications. To this end we implement PMFS a light-weight POSIX file system that exploits PM's byte-addressability to avoid overheads of block-oriented storage and enable direct PM access by applications (with memory-mapped I/O). PMFS exploits the processor's paging and memory ordering features for optimizations such as fine-grained logging (for consistency) and transparent large page support (for faster memory-mapped I/O). To provide strong consistency guarantees PMFS requires only a simple hardware primitive that provides software enforceable guarantees of durability and ordering of stores to PM. Finally PMFS uses the processor's existing features to protect PM from stray writes thereby improving reliability.Using a hardware emulator we evaluate PMFS's performance with several workloads over a range of PM performance characteristics. PMFS shows significant (up to an order of magnitude) gains over traditional file systems (such as ext4) on a RAMDISK-like PM block device demonstrating the benefits of optimizing system software for PM.;
Proceedings of the Ninth European Conference on Computer Systems;Network lifetime has become the key characteristic for evaluating sensor networks in an application-specific way. Especially the availability of nodes the sensor coverage and the connectivity have been included in discussions on network lifetime. Even quality of service measures can be reduced to lifetime considerations. A great number of algorithms and methods were proposed to increase the lifetime of a sensor networkâ€”while their evaluations were always based on a particular definition of network lifetime. Motivated by the great differences in existing definitions of sensor network lifetime that are used in relevant publications we reviewed the state of the art in lifetime definitions their differences advantages and limitations. This survey was the starting point for our work towards a generic definition of sensor network lifetime for use in analytic evaluations as well as in simulation modelsâ€”focusing on a formal and concise definition of accumulated network lifetime and total network lifetime. Our definition incorporates the components of existing lifetime definitions and introduces some additional measures. One new concept is the ability to express the service disruption tolerance of a network. Another new concept is the notion of time-integration: in many cases it is sufficient if a requirement is fulfilled over a certain period of time instead of at every point in time. In addition we combine coverage and connectivity to form a single requirement called connected coverage. We show that connected coverage is different from requiring noncombined coverage and connectivity. Finally our definition also supports the concept of graceful degradation by providing means of estimating the degree of compliance with the application requirements. We demonstrate the applicability of our definition based on the surveyed lifetime definitions as well as using some example scenarios to explain the various aspects influencing sensor network lifetime.;
Dude where's my card? RFID positioning that works with multipath and non-line of sight;RFIDs are emerging as a vital component of the Internet of Things. In 2012 billions of RFIDs have been deployed to locate equipment track drugs tag retail goods etc. Current RFID systems however can only identify whether a tagged object is within radio range (which could be up to tens of meters) but cannot pinpoint its exact location. Past proposals for addressing this limitation rely on a line-of-sight model and hence perform poorly when faced with multipath effects or non-line-of-sight which are typical in real-world deployments. This paper introduces the first fine-grained RFID positioning system that is robust to multipath and non-line-of-sight scenarios. Unlike past work which considers multipath as detrimental our design exploits multipath to accurately locate RFIDs. The intuition underlying our design is that nearby RFIDs experience a similar multipath environment (e.g. reflectors in the environment) and thus exhibit similar multipath profiles. We capture and extract these multipath profiles by using a synthetic aperture radar (SAR) created via antenna motion. We then adapt dynamic time warping (DTW) techniques to pinpoint a tag's location. We built a prototype of our design using USRP software radios. Results from a deployment of 200 commercial RFIDs in our university library demonstrate that the new design can locate misplaced books with a median accuracy of 11~cm.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;"This paper presents a general framework for building classifiers that deal with short and sparse text &amp Web segments by making the most of hidden topics discovered from large-scale data collections. The main motivation of this work is that many classification tasks working with short segments of text &amp Web such as search snippets forum &amp chat messages blog &amp news feeds product reviews and book &amp movie summaries fail to achieve high accuracy due to the data sparseness. We therefore come up with an idea of gaining external knowledge to make the data more related as well as expand the coverage of classifiers to handle future data better. The underlying idea of the framework is that for each classification task we collect a large-scale external data collection called universal dataset"" and then build a classifier on both a (small) set of labeled training data and a rich set of hidden topics discovered from that data collection. The framework is general enough to be applied to different data domains and genres ranging from Web search results to medical text. We did a careful evaluation on several hundred megabytes of Wikipedia (30M words) and MEDLINE (18M words) with two tasks: ""Web search domain disambiguation"" and ""disease categorization for medical text"" and achieved significant quality enhancement.""";
Proceedings of the 17th International Conference on World Wide Web;Geography and social relationships are inextricably intertwined the people we interact with on a daily basis almost always live near us. As people spend more time online data regarding these two dimensions -- geography and social relationships -- are becoming increasingly precise allowing us to build reliable models to describe their interaction. These models have important implications in the design of location-based services security intrusion detection and social media supporting local communities.Using user-supplied address data and the network of associations between members of the Facebook social network we can directly observe and measure the relationship between geography and friendship. Using these measurements we introduce an algorithm that predicts the location of an individual from a sparse set of located users with performance that exceeds IP-based geolocation. This algorithm is efficient and scalable and could be run on a network containing hundreds of millions of users.;
Proceedings of the 19th International Conference on World Wide Web;Errors in dynamic random access memory (DRAM) are a common form of hardware failure in modern compute clusters. Failures are costly both in terms of hardware replacement costs and service disruption. While a large body of work exists on DRAM in laboratory conditions little has been reported on real DRAM failures in large production clusters. In this paper we analyze measurements of memory errors in a large fleet of commodity servers over a period of 2.5 years. The collected data covers multiple vendors DRAM capacities and technologies and comprises many millions of DIMM days.The goal of this paper is to answer questions such as the following: How common are memory errors in practice? What are their statistical properties? How are they affected by external factors such as temperature and utilization and by chip-specific factors such as chip density memory technology and DIMM age?We find that DRAM error behavior in the field differs in many key aspects from commonly held assumptions. For example we observe DRAM error rates that are orders of magnitude higher than previously reported with 25000 to 70000 errors per billion device hours per Mbit and more than 8% of DIMMs affected by errors per year. We provide strong evidence that memory errors are dominated by hard errors rather than soft errors which previous work suspects to be the dominant error mode. We find that temperature known to strongly impact DIMM error rates in lab conditions has a surprisingly small effect on error behavior in the field when taking all other factors into account. Finally unlike commonly feared we don't observe any indication that newer generations of DIMMs have worse error behavior.;
Proceedings of the Eleventh International Joint Conference on Measurement and Modeling of Computer Systems;"A key goal of the fair-ML community is to develop machine-learning based systems that once introduced into a social context can achieve social and legal outcomes such as fairness justice and due process. Bedrock concepts in computer science---such as abstraction and modular design---are used to define notions of fairness and discrimination to produce fairness-aware learning algorithms and to intervene at different stages of a decision-making pipeline to produce fair"" outcomes. In this paper however we contend that these concepts render technical interventions ineffective inaccurate and sometimes dangerously misguided when they enter the societal context that surrounds decision-making systems. We outline this mismatch with five ""traps"" that fair-ML work can fall into even as it attempts to be more context-aware in comparison to traditional data science. We draw on studies of sociotechnical systems in Science and Technology Studies to explain why such traps occur and how to avoid them. Finally we suggest ways in which technical designers can mitigate the traps through a refocusing of design in terms of process rather than solutions and by drawing abstraction boundaries to include social actors rather than purely technical ones.""";
Proceedings of the Conference on Fairness Accountability and Transparency;We describe here a library aimed at automating the solution of partial differential equations using the finite element method. By employing novel techniques for automated code generation the library combines a high level of expressiveness with efficient computation. Finite element variational forms may be expressed in near mathematical notation from which low-level code is automatically generated compiled and seamlessly integrated with efficient implementations of computational meshes and high-performance linear algebra. Easy-to-use object-oriented interfaces to the library are provided in the form of a C++ library and a Python module. This article discusses the mathematical abstractions and methods used in the design of the library and its implementation. A number of examples are presented to demonstrate the use of the library in application code.;
Mars: a MapReduce framework on graphics processors;We design and implement Mars a MapReduce framework on graphics processors (GPUs). MapReduce is a distributed programming framework originally proposed by Google for the ease of development of web search applications on a large number of commodity CPUs. Compared with CPUs GPUs have an order of magnitude higher computation power and memory bandwidth but are harder to program since their architectures are designed as a special-purpose co-processor and their programming interfaces are typically for graphics applications. As the first attempt to harness GPU's power for MapReduce we developed Mars on an NVIDIA G80 GPU which contains over one hundred processors and evaluated it in comparison with Phoenix the state-of-the-art MapReduce framework on multi-core CPUs. Mars hides the programming complexity of the GPU behind the simple and familiar MapReduce interface. It is up to 16 times faster than its CPU-based counterpart for six common web applications on a quad-core machine.;
Proceedings of the 17th International Conference on Parallel Architectures and Compilation Techniques;We present HotStuff a leader-based Byzantine fault-tolerant replication protocol for the partially synchronous model. Once network communication becomes synchronous HotStuff enables a correct leader to drive the protocol to consensus at the pace of actual (vs. maximum) network delay--a property called responsiveness---and with communication complexity that is linear in the number of replicas. To our knowledge HotStuff is the first partially synchronous BFT replication protocol exhibiting these combined properties. Its simplicity enables it to be further pipelined and simplified into a practical concise protocol for building large-scale replication services.;
Proceedings of the 2019 ACM Symposium on Principles of Distributed Computing;In this article we provide a comprehensive introduction to knowledge graphs which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse dynamic large-scale collections of data. After some opening remarks we motivate and contrast various graph-based data models as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs.;
Expected reciprocal rank for graded relevance;"While numerous metrics for information retrieval are available in the case of binary relevance there is only one commonly used metric for graded relevance namely the Discounted Cumulative Gain (DCG). A drawback of DCG is its additive nature and the underlying independence assumption: a document in a given position has always the same gain and discount independently of the documents shown above it. Inspired by the cascade"" user model we present a new editorial metric for graded relevance which overcomes this difficulty and implicitly discounts documents which are shown below very relevant documents. More precisely this new metric is defined as the expected reciprocal length of time that the user will take to find a relevant document. This can be seen as an extension of the classical reciprocal rank to the graded relevance case and we call this metric Expected Reciprocal Rank (ERR). We conduct an extensive evaluation on the query logs of a commercial search engine and show that ERR correlates better with clicks metrics than other editorial metrics.""";
Proceedings of the 18th ACM Conference on Information and Knowledge Management;Bundle adjustment constitutes a large nonlinear least-squares problem that is often solved as the last step of feature-based structure and motion estimation computer vision algorithms to obtain optimal estimates. Due to the very large number of parameters involved a general purpose least-squares algorithm incurs high computational and memory storage costs when applied to bundle adjustment. Fortunately the lack of interaction among certain subgroups of parameters results in the corresponding Jacobian being sparse a fact that can be exploited to achieve considerable computational savings. This article presents sba a publicly available C/C++ software package for realizing generic bundle adjustment with high efficiency and flexibility regarding parameterization.;
Frenetic: a network programming language;Modern networks provide a variety of interrelated services including routing traffic monitoring load balancing and access control. Unfortunately the languages used to program today's networks lack modern features - they are usually defined at the low level of abstraction supplied by the underlying hardware and they fail to provide even rudimentary support for modular programming. As a result network programs tend to be complicated error-prone and difficult to maintain.This paper presents Frenetic a high-level language for programming distributed collections of network switches. Frenetic provides a declarative query language for classifying and aggregating network traffic as well as a functional reactive combinator library for describing high-level packet-forwarding policies. Unlike prior work in this domain these constructs are - by design - fully compositional which facilitates modular reasoning and enables code reuse. This important property is enabled by Frenetic's novel run-time system which manages all of the details related to installing uninstalling and querying low-level packet-processing rules on physical switches.Overall this paper makes three main contributions: (1) We analyze the state-of-the art in languages for programming networks and identify the key limitations (2) We present a language design that addresses these limitations using a series of examples to motivate and validate our choices (3) We describe an implementation of the language and evaluate its performance on several benchmarks.;
Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming;Communication is becoming one of the central elements in software development. As a potential typed foundation for structured communication-centred programming session types have been studied over the last decade for a wide range of process calculi and programming languages focussing on binary (two-party) sessions. This work extends the foregoing theories of binary session types to multiparty asynchronous sessions which often arise in practical communication-centred applications. Presented as a typed calculus for mobile processes the theory introduces a new notion of types in which interactions involving multiple peers are directly abstracted as a global scenario. Global types retain a friendly type syntax of binary session types while capturing complex causal chains of multiparty asynchronous interactions. A global type plays the role of a shared agreement among communication peers and is used as a basis of efficient type checking through its projection onto individual peers. The fundamental properties of the session type discipline such as communication safety progress and session fidelity are established for generaln-party asynchronous interactions.;
Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages;Ideally enterprise administrators could specify fine-grain policies that drive how the underlying switches forward drop and measure traffic. However existing techniques for flow-based networking rely too heavily on centralized controller software that installs rules reactively based on the first packet of each flow. In this paper we propose DIFANE a scalable and efficient solution that keeps all traffic in the data plane by selectively directing packets through intermediate switches that store the necessary rules. DIFANE relegates the controller to the simpler task of partitioning these rules over the switches. DIFANE can be readily implemented with commodity switch hardware since all data-plane functions can be expressed in terms of wildcard rules that perform simple actions on matching packets. Experiments with our prototype on Click-based OpenFlow switches show that DIFANE scales to larger networks with richer policies.;
Proceedings of the ACM SIGCOMM 2010 Conference;Understanding perception is critical to effective visualization design. With its low cost and scalability crowdsourcing presents an attractive option for evaluating the large design space of visualizations however it first requires validation. In this paper we assess the viability of Amazon's Mechanical Turk as a platform for graphical perception experiments. We replicate previous studies of spatial encoding and luminance contrast and compare our results. We also conduct new experiments on rectangular area perception (as in treemaps or cartograms) and on chart size and gridline spacing. Our results demonstrate that crowdsourced perception experiments are viable and contribute new insights for visualization design. Lastly we report cost and performance data from our experiments and distill recommendations for the design of crowdsourced studies.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;This paper presents ZigZag an 802.11 receiver design that combats hidden terminals. ZigZag's core contribution is a new form of interference cancellation that exploits asynchrony across successive collisions. Specifically 802.11 retransmissions in the case of hidden terminals cause successive collisions. These collisions have different interference-free stretches at their start which ZigZag exploits to bootstrap its decoding.ZigZag makes no changes to the 802.11 MAC and introduces no overhead when there are no collisions. But when senders collide ZigZag attains the same throughput as if the colliding packets were a priori scheduled in separate time slots. We build a prototype of ZigZag in GNU Radio. In a testbed of 14 USRP nodes ZigZag reduces the average packet loss rate at hidden terminals from 72.6% to about 0.7%.;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;Radio link quality estimation in Wireless Sensor Networks (WSNs) has a fundamental impact on the network performance and also affects the design of higher-layer protocols. Therefore for about a decade it has been attracting a vast array of research works. Reported works on link quality estimation are typically based on different assumptions consider different scenarios and provide radically different (and sometimes contradictory) results. This article provides a comprehensive survey on related literature covering the characteristics of low-power links the fundamental concepts of link quality estimation in WSNs a taxonomy of existing link quality estimators and their performance analysis. To the best of our knowledge this is the first survey tackling in detail link quality estimation in WSNs. We believe our efforts will serve as a reference to orient researchers and system designers in this area.;
A survey of appearance models in visual object tracking;Visual object tracking is a significant computer vision task which can be applied to many domains such as visual surveillance human computer interaction and video compression. Despite extensive research on this topic it still suffers from difficulties in handling complex object appearance changes caused by factors such as illumination variation partial occlusion shape deformation and camera motion. Therefore effective modeling of the 2D appearance of tracked objects is a key issue for the success of a visual tracker. In the literature researchers have proposed a variety of 2D appearance models.To help readers swiftly learn the recent advances in 2D appearance models for visual object tracking we contribute this survey which provides a detailed review of the existing 2D appearance models. In particular this survey takes a module-based architecture that enables readers to easily grasp the key points of visual object tracking. In this survey we first decompose the problem of appearance modeling into two different processing stages: visual representation and statistical modeling. Then different 2D appearance models are categorized and discussed with respect to their composition modules. Finally we address several issues of interest as well as the remaining challenges for future research on this topic.The contributions of this survey are fourfold. First we review the literature of visual representations according to their feature-construction mechanisms (i.e. local and global). Second the existing statistical modeling schemes for tracking-by-detection are reviewed according to their model-construction mechanisms: generative discriminative and hybrid generative-discriminative. Third each type of visual representations or statistical modeling techniques is analyzed and discussed from a theoretical or practical viewpoint. Fourth the existing benchmark resources (e.g. source codes and video datasets) are examined in this survey.;
Pupil: an open source platform for pervasive eye tracking and mobile gaze-based interaction;In this paper we present Pupil -- an accessible affordable and extensible open source platform for pervasive eye tracking and gaze-based interaction. Pupil comprises 1) a light-weight eye tracking headset 2) an open source software framework for mobile eye tracking as well as 3) a graphical user interface to playback and visualize video and gaze data. Pupil features high-resolution scene and eye cameras for monocular and binocular gaze estimation. The software and GUI are platform-independent and include state-of-the-art algorithms for real-time pupil detection and tracking calibration and accurate gaze estimation. Results of a performance evaluation show that Pupil can provide an average gaze estimation accuracy of 0.6 degree of visual angle (0.08 degree precision) with a processing pipeline latency of only 0.045 seconds.;
Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication;Recent technology trends in the Web Services (WS) domain indicate that a solution eliminating the presumed complexity of the WS-* standards may be in sight: advocates of REpresentational State Transfer (REST) have come to believe that their ideas explaining why the World Wide Web works are just as applicable to solve enterprise application integration problems and to simplify the plumbing required to build service-oriented architectures. In this paper we objectify the WS-* vs. REST debate by giving a quantitative technical comparison based on architectural principles and decisions. We show that the two approaches differ in the number of architectural decisions that must be made and in the number of available alternatives. This discrepancy between freedom-from-choice and freedom-of-choice explains the complexity difference perceived. However we also show that there are significant differences in the consequences of certain decisions in terms of resulting development and maintenance costs. Our comparison helps technical decision makers to assess the two integration styles and technologies more objectively and select the one that best fits their needs: REST is well suited for basic ad hoc integration scenarios WS-* is more flexible and addresses advanced quality of service requirements commonly occurring in enterprise computing.;
Proceedings of the 17th International Conference on World Wide Web;Many commercial video players rely on bitrate adaptation logic to adapt the bitrate in response to changing network conditions. Past measurement studies have identified issues with today's commercial players with respect to three key metrics---efficiency fairness and stability---when multiple bitrate-adaptive players share a bottleneck link. Unfortunately our current understanding of why these effects occur and how they can be mitigated is quite limited.In this paper we present a principled understanding of bitrate adaptation and analyze several commercial players through the lens of an abstract player model. Through this framework we identify the root causes of several undesirable interactions that arise as a consequence of overlaying the video bitrate adaptation over HTTP. Building on these insights we develop a suite of techniques that can systematically guide the tradeoffs between stability fairness and efficiency and thus lead to a general framework for robust video adaptation. We pick one concrete instance from this design space and show that it significantly outperforms today's commercial players on all three key metrics across a range of experimental scenarios.;
Proceedings of the 8th International Conference on Emerging Networking Experiments and Technologies;In recent years the metaverse has attracted enormous attention from around the world with the development of related technologies. The expected metaverse should be a realistic society with more direct and physical interactions while the concepts of race gender and even physical disability would be weakened which would be highly beneficial for society. However the development of metaverse is still in its infancy with great potential for improvement. Regarding metaverse's huge potential industry has already come forward with advance preparation accompanied by feverish investment but there are few discussions about metaverse in academia to scientifically guide its development. In this paper we highlight the representative applications for social good. Then we propose a three-layer metaverse architecture from a macro perspective containing infrastructure interaction and ecosystem. Moreover we journey toward both a historical and novel metaverse with a detailed timeline and table of specific attributes. Lastly we illustrate our implemented blockchain-driven metaverse prototype of a university campus and discuss the prototype design and insights.;
Proceedings of the 29th ACM International Conference on Multimedia;Multi-user multiple-input multiple-output theory predicts manyfold capacity gains by leveraging many antennas on wireless base stations to serve multiple clients simultaneously through multi-user beamforming (MUBF). However realizing a base station with a large number antennas is non-trivial and has yet to be achieved in the real-world. We present the design realization and evaluation of Argos the first reported base station architecture that is capable of serving many terminals simultaneously through MUBF with a large number of antennas (M &gt&gt 10). Designed for extreme flexibility and scalability Argos exploits hierarchical and modular design principles properly partitions baseband processing and holistically considers real-time requirements of MUBF. Argos employs a novel completely distributed beamforming technique as well as an internal calibration procedure to enable implicit beamforming with channel estimation cost independent of the number of base station antennas. We report an Argos prototype with 64 antennas and capable of serving 15 clients simultaneously. We experimentally demonstrate that by scaling from 1 to 64 antennas the prototype can achieve up to 6.7 fold capacity gains while using a mere 1/64th of the transmission power.;
Proceedings of the 18th Annual International Conference on Mobile Computing and Networking;We present a new technology for enhancing touch interfaces with tactile feedback. The proposed technology is based on the electrovibration principle does not use any moving parts and provides a wide range of tactile feedback sensations to fingers moving across a touch surface. When combined with an interactive display and touch input it enables the design of a wide variety of interfaces that allow the user to feel virtual elements through touch. We present the principles of operation and an implementation of the technology. We also report the results of three controlled psychophysical experiments and a subjective user evaluation that describe and characterize users' perception of this technology. We conclude with an exploration of the design space of tactile touch screens using two comparable setups one based on electrovibration and another on mechanical vibrotactile actuation.;
Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology;Knowledge is indispensable to understanding. The ongoing information explosion highlights the need to enable machines to better understand electronic text in human language. Much work has been devoted to creating universal ontologies or taxonomies for this purpose. However none of the existing ontologies has the needed depth and breadth for universal understanding. In this paper we present a universal probabilistic taxonomy that is more comprehensive than any existing ones. It contains 2.7 million concepts harnessed automatically from a corpus of 1.68 billion web pages. Unlike traditional taxonomies that treat knowledge as black and white it uses probabilities to model inconsistent ambiguous and uncertain information it contains. We present details of how the taxonomy is constructed its probabilistic modeling and its potential applications in text understanding.;
Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data;Vector-matrix multiplication dominates the computation time and energy for many workloads particularly neural network algorithms and linear transforms (e.g the Discrete Fourier Transform). Utilizing the natural current accumulation feature of memristor crossbar we developed the Dot-Product Engine (DPE) as a high density high power efficiency accelerator for approximate matrix-vector multiplication. We firstly invented a conversion algorithm to map arbitrary matrix values appropriately to memristor conductances in a realistic crossbar array accounting for device physics and circuit issues to reduce computational errors. The accurate device resistance programming in large arrays is enabled by close-loop pulse tuning and access transistors. To validate our approach we simulated and benchmarked one of the state-of-the-art neural networks for pattern recognition on the DPEs. The result shows no accuracy degradation compared to software approach (99 % pattern recognition accuracy for MNIST data set) with only 4 Bit DAC/ADC requirement while the DPE can achieve a speed-efficiency product of 1000\texttimes{;
Proceedings of the 53rd Annual Design Automation Conference;This paper details the construction of an access-driven side-channel attack by which a malicious virtual machine (VM) extracts fine-grained information from a victim VM running on the same physical computer. This attack is the first such attack demonstrated on a symmetric multiprocessing system virtualized using a modern VMM (Xen). Such systems are very common today ranging from desktops that use virtualization to sandbox application or OS compromises to clouds that co-locate the workloads of mutually distrustful customers. Constructing such a side-channel requires overcoming challenges including core migration numerous sources of channel noise and the difficulty of preempting the victim with sufficient frequency to extract fine-grained information from it. This paper addresses these challenges and demonstrates the attack in a lab setting by extracting an ElGamal decryption key from a victim using the most recent version of the libgcrypt cryptographic library.;
Proceedings of the 2012 ACM Conference on Computer and Communications Security;GPU architectures are increasingly important in the multi-core era due to their high number of parallel processors. Programming thousands of massively parallel threads is a big challenge for software engineers but understanding the performance bottlenecks of those parallel programs on GPU architectures to improve application performance is even more difficult. Current approaches rely on programmers to tune their applications by exploiting the design space exhaustively without fully understanding the performance characteristics of their applications.To provide insights into the performance bottlenecks of parallel applications on GPU architectures we propose a simple analytical model that estimates the execution time of massively parallel programs. The key component of our model is estimating the number of parallel memory requests (we call this the memory warp parallelism) by considering the number of running threads and memory bandwidth. Based on the degree of memory warp parallelism the model estimates the cost of memory requests thereby estimating the overall execution time of a program. Comparisons between the outcome of the model and the actual execution time in several GPUs show that the geometric mean of absolute error of our model on micro-benchmarks is 5.4% and on GPU computing applications is 13.3%. All the applications are written in the CUDA programming language.;
Proceedings of the 36th Annual International Symposium on Computer Architecture;As our technologies travel to new cultural contexts and our designs and methods engage new constituencies both our design and analytical practices face significant challenges. We offer postcolonial computing as an analytical orientation to better understand these challenges. This analytic orientation inspires four key shifts in our approach to HCI4D efforts: generative models of culture development as a historical program uneven economic relations and cultural epistemologies. Then through reconsideration of the practices of engagement articulation and translation in other contexts we offer designers and researchers ways of understanding use and design practice to respond to global connectivity and movement.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;We present an end-to-end system for augmented and virtual reality telepresence called Holoportation. Our system demonstrates high-quality real-time 3D reconstructions of an entire space including people furniture and objects using a set of new depth cameras. These 3D models can also be transmitted in real-time to remote users. This allows users wearing virtual or augmented reality displays to see hear and interact with remote participants in 3D almost as if they were present in the same physical space. From an audio-visual perspective communicating and interacting with remote users edges closer to face-to-face communication. This paper describes the Holoportation technical system in full its key interactive capabilities the application scenarios it enables and an initial qualitative study of using this new communication medium.;
Proceedings of the 29th Annual Symposium on User Interface Software and Technology;We present Flicker an infrastructure for executing security-sensitive code in complete isolation while trusting as few as 250 lines of additional code. Flicker can also provide meaningful fine-grained attestation of the code executed (as well as its inputs and outputs) to a remote party. Flicker guarantees these properties even if the BIOS OS and DMA-enabled devices are all malicious. Flicker leverages new commodity processors from AMD and Intel and does not require a new OS or VMM. We demonstrate a full implementation of Flicker on an AMD platform and describe our development environment for simplifying the construction of Flicker-enabled code.;
Proceedings of the 3rd ACM SIGOPS/EuroSys European Conference on Computer Systems 2008;Malicious Web sites are a cornerstone of Internet criminal activities. As a result there has been broad interest in developing systems to prevent the end user from visiting such sites. In this paper we describe an approach to this problem based on automated URL classification using statistical methods to discover the tell-tale lexical and host-based properties of malicious Web site URLs. These methods are able to learn highly predictive models by extracting and automatically analyzing tens of thousands of features potentially indicative of suspicious URLs. The resulting classifiers obtain 95-99% accuracy detecting large numbers of malicious Web sites from their URLs with only modest false positives.;
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;"Researchers have studied how people use self-tracking technologies and discovered a long list of barriers including lack of time and motivation as well as difficulty in data integration and interpretation. Despite the barriers an increasing number of Quantified-Selfers diligently track many kinds of data about themselves and some of them share their best practices and mistakes through Meetup talks blogging and conferences. In this work we aim to gain insights from these extreme users"" who have used existing technologies and built their own workarounds to overcome different barriers. We conducted a qualitative and quantitative analysis of 52 video recordings of Quantified Self Meetup talks to understand what they did how they did it and what they learned. We highlight several common pitfalls to self-tracking including tracking too many things not tracking triggers and context and insufficient scientific rigor. We identify future research efforts that could help make progress toward addressing these pitfalls. We also discuss how our findings can have broad implications in designing and developing self-tracking technologies.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;X-Stream is a system for processing both in-memory and out-of-core graphs on a single shared-memory machine. While retaining the scatter-gather programming model with state stored in the vertices X-Stream is novel in (i) using an edge-centric rather than a vertex-centric implementation of this model and (ii) streaming completely unordered edge lists rather than performing random access. This design is motivated by the fact that sequential bandwidth for all storage media (main memory SSD and magnetic disk) is substantially larger than random access bandwidth.We demonstrate that a large number of graph algorithms can be expressed using the edge-centric scatter-gather model. The resulting implementations scale well in terms of number of cores in terms of number of I/O devices and across different storage media. X-Stream competes favorably with existing systems for graph processing. Besides sequential access we identify as one of the main contributors to better performance the fact that X-Stream does not need to sort edge lists during preprocessing.;
Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles;This paper describes a benchmark for evaluation of 3D mesh segmentation salgorithms. The benchmark comprises a data set with 4300 manually generated segmentations for 380 surface meshes of 19 different object categories and it includes software for analyzing 11 geometric properties of segmentations and producing 4 quantitative metrics for comparison of segmentations. The paper investigates the design decisions made in building the benchmark analyzes properties of human-generated and computer-generated segmentations and provides quantitative comparisons of 7 recently published mesh segmentation algorithms. Our results suggest that people are remarkably consistent in the way that they segment most 3D surface meshes that no one automatic segmentation algorithm is better than the others for all types of objects and that algorithms based on non-local shape features seem to produce segmentations that most closely resemble ones made by humans.;
Modeling attacks on physical unclonable functions;We show in this paper how several proposed Physical Unclonable Functions (PUFs) can be broken by numerical modeling attacks. Given a set of challenge-response pairs (CRPs) of a PUF our attacks construct a computer algorithm which behaves indistinguishably from the original PUF on almost all CRPs. This algorithm can subsequently impersonate the PUF and can be cloned and distributed arbitrarily. This breaks the security of essentially all applications and protocols that are based on the respective PUF. The PUFs we attacked successfully include standard Arbited PUFs and Ring Oscillator PUFs of arbitrary sizes and XO Arbiter PUFs Lightweight Secure PUFs and Feed-Forward Arbiter PUFs of up to a given size and complexity. Our attacks are based upon various machine learning techniques including Logistic Regression and Evolution Strategies. Our work leads to new design requirements for secure electrical PUFs and will be useful to PUF designers and attackers alike.;
Proceedings of the 17th ACM Conference on Computer and Communications Security;We present Path ORAM an extremely simple Oblivious RAM protocol with a small amount of client storage. Partly due to its simplicity Path ORAM is the most practical ORAM scheme for small client storage known to date. We formally prove that Path ORAM requires log^2 N / log X bandwidth overhead for block size B = X log N. For block sizes bigger than Omega(log^2 N) Path ORAM is asymptotically better than the best known ORAM scheme with small client storage. Due to its practicality Path ORAM has been adopted in the design of secure processors since its proposal.;
Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp Communications Security;In many online social systems social ties between users play an important role in dictating their behavior. One of the ways this can happen is through social influence the phenomenon that the actions of a user can induce his/her friends to behave in a similar way. In systems where social influence exists ideas modes of behavior or new technologies can diffuse through the network like an epidemic. Therefore identifying and understanding social influence is of tremendous interest from both analysis and design points of view.This is a difficult task in general since there are factors such as homophily or unobserved confounding variables that can induce statistical correlation between the actions of friends in a social network. Distinguishing influence from these is essentially the problem of distinguishing correlation from causality a notoriously hard statistical problem.In this paper we study this problem systematically. We define fairly general models that replicate the aforementioned sources of social correlation. We then propose two simple tests that can identify influence as a source of social correlation when the time series of user actions is available.We give a theoretical justification of one of the tests by proving that with high probability it succeeds in ruling out influence in a rather general model of social correlation. We also simulate our tests on a number of examples designed by randomly generating actions of nodes on a real social network (from Flickr) according to one of several models. Simulation results confirm that our test performs well on these data. Finally we apply them to real tagging data on Flickr exhibiting that while there is significant social correlation in tagging behavior on this system this correlation cannot be attributed to social influence.;
Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Currently multi-threaded C or C++ programs combine a single-threaded programming language with a separate threads library. This is not entirely sound [7].We describe an effort currently nearing completion to address these issues by explicitly providing semantics for threads in the next revision of the C++ standard. Our approach is similar to that recently followed by Java [25] in that at least for a well-defined and interesting subset of the language we give sequentially consistent semantics to programs that do not contain data races. Nonetheless a number of our decisions are often surprising even to those familiar with the Java effort:We (mostly) insist on sequential consistency for race-free programs in spite of implementation issues that came to light after the Java work.We give no semantics to programs with data races. There are no benign C++ data races.We use weaker semantics for trylock than existing languages or libraries allowing us to promise sequential consistency with an intuitive race definition even for programs with trylock.This paper describes the simple model we would like to be able to provide for C++ threads programmers and explain how this together with some practical but often under-appreciated implementation constraints drives us towards the above decisions.;
Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation;"In this paper we present a comparative analysis of the predictive power of two different sets of metrics for defect prediction. We choose one set of product related and one set of process related software metrics and use them for classifying Java files of the Eclipse project as defective respective defect-free. Classification models are built using three common machine learners: logistic regression Na\{\i""";
Proceedings of the 30th International Conference on Software Engineering;Big Data is a new term used to identify datasets that we can not manage with current methodologies or data mining software tools due to their large size and complexity. Big Data mining is the capability of extracting useful information from these large datasets or streams of data. New mining techniques are necessary due to the volume variability and velocity of such data. The Big Data challenge is becoming one of the most exciting opportunities for the years to come. We present in this issue a broad overview of the topic its current status controversy and a forecast to the future. We introduce four articles written by influential scientists in the field covering the most interesting and state-of-the-art topics on Big Data mining.;
Dynodroid: an input generation system for Android apps;We present a system Dynodroid for generating relevant inputs to unmodified Android apps. Dynodroid views an app as an event-driven program that interacts with its environment by means of a sequence of events through the Android framework. By instrumenting the framework once and for all Dynodroid monitors the reaction of an app upon each event in a lightweight manner using it to guide the generation of the next event to the app. Dynodroid also allows interleaving events from machines which are better at generating a large number of simple inputs with events from humans who are better at providing intelligent inputs.  We evaluated Dynodroid on 50 open-source Android apps and compared it with two prevalent approaches: users manually exercising apps and Monkey a popular fuzzing tool. Dynodroid humans and Monkey covered 55% 60% and 53% respectively of each app's Java source code on average. Monkey took 20X more events on average than Dynodroid. Dynodroid also found 9 bugs in 7 of the 50 apps and 6 bugs in 5 of the top 1000 free apps on Google Play.;
Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering;Software-defined networking empowers network operators with more flexibility to program their networks. With SDN network management moves from codifying functionality in terms of low-level device configurations to building software that facilitates network management and debugging. By separating the complexity of state distribution from network specification SDN provides new ways to solve long-standing problems in networking --- routing for instance --- while simultaneously allowing the use of security and dependability techniques such as access control or multi-path.However the security and dependability of the SDN itself is still an open issue. In this position paper we argue for the need to build secure and dependable SDNs by design. As a first step in this direction we describe several threat vectors that may enable the exploit of SDN vulnerabilities. We then sketch the design of a secure and dependable SDN control platform as a materialization of the concept here advocated. We hope that this paper will trigger discussions in the SDN community around these issues and serve as a catalyser to join efforts from the networking and security &amp dependability communities in the ultimate goal of building resilient control planes.;
Proceedings of the Second ACM SIGCOMM Workshop on Hot Topics in Software Defined Networking;Combinatorial Testing (CT) can detect failures triggered by interactions of parameters in the Software Under Test (SUT) with a covering array test suite generated by some sampling mechanisms. It has been an active field of research in the last twenty years. This article aims to review previous work on CT highlights the evolution of CT and identifies important issues methods and applications of CT with the goal of supporting and directing future practice and research in this area. First we present the basic concepts and notations of CT. Second we classify the research on CT into the following categories: modeling for CT test suite generation constraints failure diagnosis prioritization metric evaluation testing procedure and the application of CT. For each of the categories we survey the motivation key issues solutions and the current state of research. Then we review the contribution from different research groups and present the growing trend of CT research. Finally we recommend directions for future CT research including: (1) modeling for CT (2) improving the existing test suite generation algorithm (3) improving analysis of testing result (4) exploring the application of CT to different levels of testing and additional types of systems (5) conducting more empirical studies to fully understand limitations and strengths of CT and (6) combining CT with other testing techniques.;
Proceedings of the 2009 ACM Workshop on Cloud Computing Security;The goal of ensemble regression is to combine several models in order to improve the prediction accuracy in learning problems with a numerical target variable. The process of ensemble learning can be divided into three phases: the generation phase the pruning phase and the integration phase. We discuss different approaches to each of these phases that are able to deal with the regression problem categorizing them in terms of their relevant characteristics and linking them to contributions from different fields. Furthermore this work makes it possible to identify interesting areas for future research.;
The Scalable Heterogeneous Computing (SHOC) benchmark suite;Scalable heterogeneous computing systems which are composed of a mix of compute devices such as commodity multicore processors graphics processors reconfigurable processors and others are gaining attention as one approach to continuing performance improvement while managing the new challenge of energy efficiency. As these systems become more common it is important to be able to compare and contrast architectural designs and programming systems in a fair and open forum. To this end we have designed the Scalable HeterOgeneous Computing benchmark suite (SHOC). SHOC's initial focus is on systems containing graphics processing units (GPUs) and multi-core processors and on the new OpenCL programming standard. SHOC is a spectrum of programs that test the performance and stability of these scalable heterogeneous computing systems. At the lowest level SHOC uses microbenchmarks to assess architectural features of the system. At higher levels SHOC uses application kernels to determine system-wide performance including many system features such as intranode and internode communication among devices. SHOC includes benchmark implementations in both OpenCL and CUDA in order to provide a comparison of these programming models.;
Proceedings of the 3rd Workshop on General-Purpose Computation on Graphics Processing Units;The size of data sets being collected and analyzed in the industry for business intelligence is growing rapidly making traditional warehousing solutions prohibitively expensive. Hadoop [3] is a popular open-source map-reduce implementation which is being used as an alternative to store and process extremely large data sets on commodity hardware. However the map-reduce programming model is very low level and requires developers to write custom programs which are hard to maintain and reuse.;
A survey of intrusion detection techniques for cyber-physical systems;Pervasive healthcare systems smart grids and unmanned aircraft systems are examples of Cyber-Physical Systems (CPSs) that have become highly integrated in the modern world. As this integration deepens the importance of securing these systems increases. In order to identify gaps and propose research directions in CPS intrusion detection research we survey the literature of this area. Our approach is to classify modern CPS Intrusion Detection System (IDS) techniques based on two design dimensions: detection technique and audit material. We summarize advantages and drawbacks of each dimensionâ€™s options. We also summarize the most and least studied CPS IDS techniques in the literature and provide insight on the effectiveness of IDS techniques as they apply to CPSs. Finally we identify gaps in CPS IDS research and suggest future research areas.;
A survey of mobile malware in the wild;Mobile malware is rapidly becoming a serious threat. In this paper we survey the current state of mobile malware in the wild. We analyze the incentives behind 46 pieces of iOS Android and Symbian malware that spread in the wild from 2009 to 2011. We also use this data set to evaluate the effectiveness of techniques for preventing and identifying mobile malware. After observing that 4 pieces of malware use root exploits to mount sophisticated attacks on Android phones we also examine the incentives that cause non-malicious smartphone tinkerers to publish root exploits and survey the availability of root exploits.;
Proceedings of the 1st ACM Workshop on Security and Privacy in Smartphones and Mobile Devices;Click-through rate (CTR) prediction plays an important role in computational advertising. Models based on degree-2 polynomial mappings and factorization machines (FMs) are widely used for this task. Recently a variant of FMs field-aware factorization machines (FFMs) outperforms existing models in some world-wide CTR-prediction competitions. Based on our experiences in winning two of them in this paper we establish FFMs as an effective method for classifying large sparse data including those from CTR prediction. First we propose efficient implementations for training FFMs. Then we comprehensively analyze FFMs and compare this approach with competing models. Experiments show that FFMs are very useful for certain classification problems. Finally we have released a package of FFMs for public use.;
Proceedings of the 10th ACM Conference on Recommender Systems;Crowdfunding is changing how why and which ideas are brought into existence. With the increasing number of crowdfunded projects it is important to understand what drives people to either create or fund these projects. To shed light on this new social phenomenon we present a grounded theory of motivation informed by the first cross-platform qualitative study of the crowdfunding community. By performing 83 semistructured interviews we uncover creator motivations which include the desire to raise funds expand awareness of work connect with others gain approval maintain control and learn and supporter motivations which include the desire to collect rewards help others support causes and be part of a community. We also explore deterrents to crowdfunding participation including among creators fear of failure and for supporters lack of trust. Based on these findings we provide three emergent design principles to inform the design of effective crowdfunding platforms and support tools.;
A survey on automated dynamic malware-analysis techniques and tools;Anti-virus vendors are confronted with a multitude of potentially malicious samples today. Receiving thousands of new samples every day is not uncommon. The signatures that detect confirmed malicious threats are mainly still created manually so it is important to discriminate between samples that pose a new unknown threat and those that are mere variants of known malware.This survey article provides an overview of techniques based on dynamic analysis that are used to analyze potentially malicious samples. It also covers analysis programs that leverage these It also covers analysis programs that employ these techniques to assist human analysts in assessing in a timely and appropriate manner whether a given sample deserves closer manual inspection due to its unknown malicious behavior.;
Learning analytics and educational data mining: towards communication and collaboration;Growing interest in data and analytics in education teaching and learning raises the priority for increased high-quality research into the models methods technologies and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research methods and tools for data mining and analysis in the service of developing both LAK and EDM fields.;
Proceedings of the 2nd International Conference on Learning Analytics and Knowledge;In this article we revisit two popular convolutional neural networks in person re-identification (re-ID): verification and identification models. The two models have their respective advantages and limitations due to different loss functions. Here we shed light on how to combine the two models to learn more discriminative pedestrian descriptors. Specifically we propose a Siamese network that simultaneously computes the identification loss and verification loss. Given a pair of training images the network predicts the identities of the two input images and whether they belong to the same identity. Our network learns a discriminative embedding and a similarity measurement at the same time thus taking full usage of the re-ID annotations. Our method can be easily applied on different pretrained networks. Albeit simple the learned embedding improves the state-of-the-art performance on two public person re-ID benchmarks. Further we show that our architecture can also be applied to image retrieval. The code is available at https://github.com/layumi/2016_person_re-ID.;
Relational learning via latent social dimensions;Social media such as blogs Facebook Flickr etc. presents data in a network format rather than classical IID distribution. To address the interdependency among data instances relational learning has been proposed and collective inference based on network connectivity is adopted for prediction. However connections in social media are often multi-dimensional. An actor can connect to another actor for different reasons e.g. alumni colleagues living in the same city sharing similar interests etc. Collective inference normally does not differentiate these connections. In this work we propose to extract latent social dimensions based on network information and then utilize them as features for discriminative learning. These social dimensions describe diverse affiliations of actors hidden in the network and the discriminative learning can automatically determine which affiliations are better aligned with the class labels. Such a scheme is preferred when multiple diverse relations are associated with the same network. We conduct extensive experiments on social media data (one from a real-world blog site and the other from a popular content sharing site). Our model outperforms representative relational learning methods based on collective inference especially when few labeled data are available. The sensitivity of this model and its connection to existing methods are also examined.;
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium derive the upper bound of the convergence time and quantify its efficiency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation offloading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation offloading performance and scale well as the user size increases.;
VizWiz: nearly real-time answers to visual questions;The lack of access to visual information like text labels icons and colors can cause frustration and decrease independence for blind people. Current access technology uses automatic approaches to address some problems in this space but the technology is error-prone limited in scope and quite expensive. In this paper we introduce VizWiz a talking application for mobile phones that offers a new alternative to answering visual questions in nearly real-time - asking multiple people on the web. To support answering questions quickly we introduce a general approach for intelligently recruiting human workers in advance called quikTurkit so that workers are available when new questions arrive. A field deployment with 11 blind participants illustrates that blind people can effectively use VizWiz to cheaply answer questions in their everyday lives highlighting issues that automatic approaches will need to address to be useful. Finally we illustrate the potential of using VizWiz as part of the participatory design of advanced tools by using it to build and evaluate VizWiz::LocateIt an interactive mobile tool that helps blind people solve general visual search problems.;
Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology;Given a task T a pool of individuals X with different skills and a social network G that captures the compatibility among these individuals we study the problem of finding X a subset of X to perform the task. We call this the TEAM FORMATION problem. We require that members of X' not only meet the skill requirements of the task but can also work effectively together as a team. We measure effectiveness using the communication cost incurred by the subgraph in G that only involves X'. We study two variants of the problem for two different communication-cost functions and show that both variants are NP-hard. We explore their connections with existing combinatorial problems and give novel algorithms for their solution. To the best of our knowledge this is the first work to consider the TEAM FORMATION problem in the presence of a social network of individuals. Experiments on the DBLP dataset show that our framework works well in practice and gives useful and intuitive results.;
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;There are many interface schemes that allow users to work at and move between focused and contextual views of a dataset. We review and categorize these schemes according to the interface mechanisms used to separate and blend views. The four approaches are overview+detail which uses a spatial separation between focused and contextual views zooming which uses a temporal separation focus+context which minimizes the seam between views by displaying the focus within the context and cue-based techniques which selectively highlight or suppress items within the information space. Critical features of these categories and empirical evidence of their success are discussed. The aim is to provide a succinct summary of the state-of-the-art to illuminate both successful and unsuccessful interface strategies and to identify potentially fruitful areas for further work.;
Omega: flexible scalable schedulers for large compute clusters;Increasing scale and the need for rapid response to changing requirements are hard to meet with current monolithic cluster scheduler architectures. This restricts the rate at which new features can be deployed decreases efficiency and utilization and will eventually limit cluster growth. We present a novel approach to address these needs using parallelism shared state and lock-free optimistic concurrency control.We compare this approach to existing cluster scheduler designs evaluate how much interference between schedulers occurs and how much it matters in practice present some techniques to alleviate it and finally discuss a use case highlighting the advantages of our approach -- all driven by real-life Google production workloads.;
Proceedings of the 8th ACM European Conference on Computer Systems;We address the problem of synthesizing code completions for programs using APIs. Given a program with holes we synthesize completions for holes with the most likely sequences of method calls.Our main idea is to reduce the problem of code completion to a natural-language processing problem of predicting probabilities of sentences. We design a simple and scalable static analysis that extracts sequences of method calls from a large codebase and index these into a statistical language model. We then employ the language model to find the highest ranked sentences and use them to synthesize a code completion. Our approach is able to synthesize sequences of calls across multiple objects together with their arguments.Experiments show that our approach is fast and effective. Virtually all computed completions typecheck and the desired completion appears in the top 3 results in 90% of the cases.;
Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation;Reputation systems provide mechanisms to produce a metric encapsulating reputation for a given domain for each identity within the system. These systems seek to generate an accurate assessment in the face of various factors including but not limited to unprecedented community size and potentially adversarial environments.We focus on attacks and defense mechanisms in reputation systems. We present an analysis framework that allows for the general decomposition of existing reputation systems. We classify attacks against reputation systems by identifying which system components and design choices are the targets of attacks. We survey defense mechanisms employed by existing reputation systems. Finally we analyze several landmark systems in the peer-to-peer domain characterizing their individual strengths and weaknesses. Our work contributes to understanding (1) which design components of reputation systems are most vulnerable (2) what are the most appropriate defense mechanisms and (3) how these defense mechanisms can be integrated into existing or future reputation systems to make them resilient to attacks.;
Cuckoo Filter: Practically Better Than Bloom;"In many networking systems Bloom filters are used for high-speed set membership tests. They permit a small fraction of false positive answers with very good space efficiency. However they do not permit deletion of items from the set and previous attempts to extend standard"" Bloom filters to support deletion all degrade either space or performance.We propose a new data structure called the cuckoo filter that can replace Bloom filters for approximate set membership tests. Cuckoo filters support adding and removing items dynamically while achieving even higher performance than Bloom filters. For applications that store many items and target moderately low false positive rates cuckoo filters have lower space overhead than space-optimized Bloom filters. Our experimental results also show that cuckoo filters outperform previous data structures that extend Bloom filters to support deletions substantially in both time and space.""";
Proceedings of the 10th ACM International on Conference on Emerging Networking Experiments and Technologies;We introduce HAIL (High-Availability and Integrity Layer) a distributed cryptographic system that allows a set of servers to prove to a client that a stored file is intact and retrievable. HAIL strengthens formally unifies and streamlines distinct approaches from the cryptographic and distributed-systems communities. Proofs in HAIL are efficiently computable by servers and highly compact---typically tens or hundreds of bytes irrespective of file size. HAIL cryptographically verifies and reactively reallocates file shares. It is robust against an active mobile adversary i.e. one that may progressively corrupt the full set of servers. We propose a strong formal adversarial model for HAIL and rigorous analysis and parameter choices. We show how HAIL improves on the security and efficiency of existing tools like Proofs of Retrievability (PORs) deployed on individual servers. We also report on a prototype implementation.;
Proceedings of the 16th ACM Conference on Computer and Communications Security;The effects of data center traffic characteristics on data center traffic engineering is not well understood. In particular it is unclear how existing traffic engineering techniques perform under various traffic patterns namely how do the computed routes differ from the optimal routes. Our study reveals that existing traffic engineering techniques perform 15% to 20% worse than the optimal solution. We find that these techniques suffer mainly due to their inability to utilize global knowledge about flow characteristics and make coordinated decision for scheduling flows.To this end we have developed MicroTE a system that adapts to traffic variations by leveraging the short term and partial predictability of the traffic matrix. We implement MicroTE within the OpenFlow framework and with minor modification to the end hosts. In our evaluations we show that our system performs close to the optimal solution and imposes minimal overhead on the network making it appropriate for current and future data centers.;
Proceedings of the Seventh COnference on Emerging Networking EXperiments and Technologies;"As much of the world's computing continues to move into the cloud the overprovisioning of computing resources to ensure the performance isolation of latency-sensitive tasks such as web search in modern datacenters is a major contributor to low machine utilization. Being unable to accurately predict performance degradation due to contention for shared resources on multicore systems has led to the heavy handed approach of simply disallowing the co-location of high-priority latency-sensitive tasks with other tasks. Performing this precise prediction has been a challenging and unsolved problem.In this paper we present Bubble-Up a characterization methodology that enables the accurate prediction of the performance degradation that results from contention for shared resources in the memory subsystem. By using a bubble to apply a tunable amount of pressure"" to the memory subsystem on processors in production datacenters our methodology can predict the performance interference between co-locate applications with an accuracy within 1% to 2% of the actual performance degradation. Using this methodology to arrive at ""sensible"" co-locations in Google's production datacenters with real-world large-scale applications we can improve the utilization of a 500-machine cluster by 50% to 90% while guaranteeing a high quality of service of latency-sensitive applications.""";
Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture;General-purpose GPUs (GPGPUs) are becoming prevalent in mainstream computing and performance per watt has emerged as a more crucial evaluation metric than peak performance. As such GPU architects require robust tools that will enable them to quickly explore new ways to optimize GPGPUs for energy efficiency. We propose a new GPGPU power model that is configurable capable of cycle-level calculations and carefully validated against real hardware measurements. To achieve configurability we use a bottom-up methodology and abstract parameters from the microarchitectural components as the model's inputs. We developed a rigorous suite of 80 microbenchmarks that we use to bound any modeling uncertainties and inaccuracies. The power model is comprehensively validated against measurements of two commercially available GPUs and the measured error is within 9.9% and 13.4% for the two target GPUs (GTX 480 and Quadro FX5600). The model also accurately tracks the power consumption trend over time. We integrated the power model with the cycle-level simulator GPGPU-Sim and demonstrate the energy savings by utilizing dynamic voltage and frequency scaling (DVFS) and clock gating. Traditional DVFS reduces GPU energy consumption by 14.4% by leveraging within-kernel runtime variations. More finer-grained SM cluster-level DVFS improves the energy savings from 6.6% to 13.6% for those benchmarks that show clustered execution behavior. We also show that clock gating inactive lanes during divergence reduces dynamic power by 11.2%.;
Proceedings of the 40th Annual International Symposium on Computer Architecture;We propose a new high-quality and efficient single-image upscaling technique that extends existing example-based super-resolution frameworks. In our approach we do not rely on an external example database or use the whole input image as a source for example patches. Instead we follow a local self-similarity assumption on natural images and extract patches from extremely localized regions in the input image. This allows us to reduce considerably the nearest-patch search time without compromising quality in most images. Tests that we perform and report show that the local self-similarity assumption holds better for small scaling factors where there are more example patches of greater relevance. We implement these small scalings using dedicated novel nondyadic filter banks that we derive based on principles that model the upscaling process. Moreover the new filters are nearly biorthogonal and hence produce high-resolution images that are highly consistent with the input image without solving implicit back-projection equations. The local and explicit nature of our algorithm makes it simple efficient and allows a trivial parallel implementation on a GPU. We demonstrate the new method ability to produce high-quality resolution enhancement its application to video sequences with no algorithmic modification and its efficiency to perform real-time enhancement of low-resolution video standard into recent high-definition formats.;
Skinput: appropriating the body as an input surface;We present Skinput a technology that appropriates the human body for acoustic transmission allowing the skin to be used as an input surface. In particular we resolve the location of finger taps on the arm and hand by analyzing mechanical vibrations that propagate through the body. We collect these signals using a novel array of sensors worn as an armband. This approach provides an always available naturally portable and on-body finger input system. We assess the capabilities accuracy and limitations of our technique through a two-part twenty-participant user study. To further illustrate the utility of our approach we conclude with several proof-of-concept applications we developed.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Graph representation learning has emerged as a powerful technique for addressing real-world problems. Various downstream graph learning tasks have benefited from its recent developments such as node classification similarity search and graph classification. However prior arts on graph representation learning focus on domain specific problems and train a dedicated model for each graph dataset which is usually non-transferable to out-of-domain data. Inspired by the recent advances in pre-training from natural language processing and computer vision we design Graph Contrastive Coding (GCC) --- a self-supervised graph neural network pre-training framework --- to capture the universal network topological properties across multiple networks. We design GCC's pre-training task as subgraph instance discrimination in and across networks and leverage contrastive learning to empower graph neural networks to learn the intrinsic and transferable structural representations. We conduct extensive experiments on three graph learning tasks and ten graph datasets. The results show that GCC pre-trained on a collection of diverse datasets can achieve competitive or better performance to its task-specific and trained-from-scratch counterparts. This suggests that the pre-training and fine-tuning paradigm presents great potential for graph representation learning.;
Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Network functions virtualization (NFV) together with software-defined networking (SDN) has the potential to help operators satisfy tight service level agreements accurately monitor and manipulate network traffic and minimize operating expenses. However in scenarios that require packet processing to be redistributed across a collection of network function (NF) instances simultaneously achieving all three goals requires a framework that provides efficient coordinated control of both internal NF state and network forwarding state. To this end we design a control plane called OpenNF. We use carefully designed APIs and a clever combination of events and forwarding updates to address race conditions bound overhead and accommodate a variety of NFs. Our evaluation shows that OpenNF offers efficient state control without compromising flexibility and requires modest additions to NFs.;
Proceedings of the 2014 ACM Conference on SIGCOMM;Neural architecture search (NAS) has been proposed to automatically tune deep neural networks but existing search algorithms e.g. NASNet PNAS usually suffer from expensive computational cost. Network morphism which keeps the functionality of a neural network while changing its neural architecture could be helpful for NAS by enabling more efficient training during the search. In this paper we propose a novel framework enabling Bayesian optimization to guide the network morphism for efficient neural architecture search. The framework develops a neural network kernel and a tree-structured acquisition function optimization algorithm to efficiently explores the search space. Extensive experiments on real-world benchmark datasets have been done to demonstrate the superior performance of the developed framework over the state-of-the-art methods. Moreover we build an open-source AutoML system based on our method namely Auto-Keras. The code and documentation are available at https://autokeras.com. The system runs in parallel on CPU and GPU with an adaptive search strategy for different GPU memory limits.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Sensor network technology promises a vast increase in automatic data collection capabilities through efficient deployment of tiny sensing devices. The technology will allow users to measure phenomena of interest at unprecedented spatial and temporal densities. However as with almost every data-driven technology the many benefits come with a significant challenge in data reliability. If wireless sensor networks are really going to provide data for the scientific community citizen-driven activism or organizations which test that companies are upholding environmental laws then an important question arises: How can a user trust the accuracy of information provided by the sensor network? Data integrity is vulnerable to both node and system failures. In data collection systems faults are indicators that sensor nodes are not providing useful information. In data fusion systems the consequences are more dire the final outcome is easily affected by corrupted sensor measurements and the problems are no longer visibly obvious.In this article we investigate a generalized and unified approach for providing information about the data accuracy in sensor networks. Our approach is to allow the sensor nodes to develop a community of trust. We propose a framework where each sensor node maintains reputation metrics which both represent past behavior of other nodes and are used as an inherent aspect in predicting their future behavior. We employ a Bayesian formulation specifically a beta reputation system for the algorithm steps of reputation representation updates integration and trust evolution. This framework is available as a middleware service on motes and has been ported to two sensor network operating systems TinyOS and SOS. We evaluate the efficacy of this framework using multiple contexts: (1) a lab-scale test bed of Mica2 motes (2) Avrora simulations and (3) real data sets collected from sensor network deployments in James Reserve.;
A survey of trust in social networks;Web-based social networks have become popular as a medium for disseminating information and connecting like-minded people. The public accessibility of such networks with the ability to share opinions thoughts information and experience offers great promise to enterprises and governments. In addition to individuals using such networks to connect to their friends and families governments and enterprises have started exploiting these platforms for delivering their services to citizens and customers. However the success of such attempts relies on the level of trust that members have with each other as well as with the service provider. Therefore trust becomes an essential and important element of a successful social network. In this article we present the first comprehensive review of social and computer science literature on trust in social networks. We first review the existing definitions of trust and define social trust in the context of social networks. We then discuss recent works addressing three aspects of social trust: trust information collection trust evaluation and trust dissemination. Finally we compare and contrast the literature and identify areas for further research in social trust.;
DolphinAttack: Inaudible Voice Commands;"Speech recognition (SR) systems such as Siri or Google Now have become an increasingly popular human-computer interaction method and have turned various systems into voice controllable systems (VCS). Prior work on attacking VCS shows that the hidden voice commands that are incomprehensible to people can control the systems. Hidden voice commands though hidden"" are nonetheless audible. In this work we design a totally inaudible attack DolphinAttack that modulates voice commands on ultrasonic carriers (e.g. f &gt 20 kHz) to achieve inaudibility. By leveraging the nonlinearity of the microphone circuits the modulated low-frequency audio commands can be successfully demodulated recovered and more importantly interpreted by the speech recognition systems. We validated DolphinAttack on popular speech recognition systems including Siri Google Now Samsung S Voice Huawei HiVoice Cortana and Alexa. By injecting a sequence of inaudible voice commands we show a few proof-of-concept attacks which include activating Siri to initiate a FaceTime call on iPhone activating Google Now to switch the phone to the airplane mode and even manipulating the navigation system in an Audi automobile. We propose hardware and software defense solutions and suggest to re-design voice controllable systems to be resilient to inaudible voice command attacks.""";
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security;Current software attacks often build on exploits that subvert machine-code execution. The enforcement of a basic safety property control-flow integrity (CFI) can prevent such attacks from arbitrarily controlling program behavior. CFI enforcement is simple and its guarantees can be established formally even with respect to powerful adversaries. Moreover CFI enforcement is practical: It is compatible with existing software and can be done efficiently using software rewriting in commodity systems. Finally CFI provides a useful foundation for enforcing further security policies as we demonstrate with efficient software implementations of a protected shadow call stack and of access control for memory regions.;
A similarity measure for indefinite rankings;Ranked lists are encountered in research and daily life and it is often of interest to compare these lists even when they are incomplete or have only some members in common. An example is document rankings returned for the same query by different search engines. A measure of the similarity between incomplete rankings should handle nonconjointness weight high ranks more heavily than low and be monotonic with increasing depth of evaluation but no measure satisfying all these criteria currently exists. In this article we propose a new measure having these qualities namely rank-biased overlap (RBO). The RBO measure is based on a simple probabilistic user model. It provides monotonicity by calculating at a given depth of evaluation a base score that is non-decreasing with additional evaluation and a maximum score that is nonincreasing. An extrapolated score can be calculated between these bounds if a point estimate is required. RBO has a parameter which determines the strength of the weighting to top ranks. We extend RBO to handle tied ranks and rankings of different lengths. Finally we give examples of the use of the measure in comparing the results produced by public search engines and in assessing retrieval systems in the laboratory.;
Addressing shared resource contention in multicore processors via scheduling;Contention for shared resources on multicore processors remains an unsolved problem in existing systems despite significant research efforts dedicated to this problem in the past. Previous solutions focused primarily on hardware techniques and software page coloring to mitigate this problem. Our goal is to investigate how and to what extent contention for shared resource can be mitigated via thread scheduling. Scheduling is an attractive tool because it does not require extra hardware and is relatively easy to integrate into the system. Our study is the first to provide a comprehensive analysis of contention-mitigating techniques that use only scheduling. The most difficult part of the problem is to find a classification scheme for threads which would determine how they affect each other when competing for shared resources. We provide a comprehensive analysis of such classification schemes using a newly proposed methodology that enables to evaluate these schemes separately from the scheduling algorithm itself and to compare them to the optimal. As a result of this analysis we discovered a classification scheme that addresses not only contention for cache space but contention for other shared resources such as the memory controller memory bus and prefetching hardware. To show the applicability of our analysis we design a new scheduling algorithm which we prototype at user level and demonstrate that it performs within 2% of the optimal. We also conclude that the highest impact of contention-aware scheduling techniques is not in improving performance of a workload as a whole but in improving quality of service or performance isolation for individual applications.;
Proceedings of the Fifteenth International Conference on Architectural Support for Programming Languages and Operating Systems;"Where is the energy spent inside my app? Despite the immense popularity of smartphones and the fact that energy is the most crucial aspect in smartphone programming the answer to the above question remains elusive. This paper first presents eprof the first fine-grained energy profiler for smartphone apps. Compared to profiling the runtime of applications running on conventional computers profiling energy consumption of applications running on smartphones faces a unique challenge asynchronous power behavior where the effect on a component's power state due to a program entity lasts beyond the end of that program entity. We present the design implementation and evaluation of eprof on two mobile OSes Android and Windows Mobile.We then present an in-depth case study the first of its kind of six popular smartphones apps (including Angry-Birds Facebook and Browser). Eprof sheds lights on internal energy dissipation of these apps and exposes surprising findings like 65%-75% of energy in free apps is spent in third-party advertisement modules. Eprof also reveals several wakelock bugs"" a family of ""energy bugs"" in smartphone apps and effectively pinpoints their location in the source code. The case study highlights the fact that most of the energy in smartphone apps is spent in I/O and I/O events are clustered often due to a few routines. Thismotivates us to propose bundles a new accounting presentation of app I/O energy which helps the developer to quickly understand and optimize the energy drain of her app. Using the bundle presentation we reduced the energy consumption of four apps by 20% to 65%.""";
Proceedings of the 7th ACM European Conference on Computer Systems;We develop an automated approach for designing matrix multiplication algorithms based on constructions similar to the Coppersmith-Winograd construction. Using this approach we obtain a new improved bound on the matrix multiplication exponent Ï‰&lt2.3727.;
Proceedings of the Forty-Fourth Annual ACM Symposium on Theory of Computing;NOMAD is software that implements the Mesh Adaptive Direct Search (MADS) algorithm for blackbox optimization under general nonlinear constraints. Blackbox optimization is about optimizing functions that are usually given as costly programs with no derivative information and no function values returned for a significant number of calls attempted. NOMAD is designed for such problems and aims for the best possible solution with a small number of evaluations. The objective of this article is to describe the underlying algorithm the softwareâ€™s functionalities and its implementation.;
Spotting fake reviewer groups in consumer reviews;Opinionated social media such as product reviews are now widely used by individuals and organizations for their decision making. However due to the reason of profit or fame people try to game the system by opinion spamming (e.g. writing fake reviews) to promote or demote some target products. For reviews to reflect genuine user experiences and opinions such spam reviews should be detected. Prior works on opinion spam focused on detecting fake reviews and individual fake reviewers. However a fake reviewer group (a group of reviewers who work collaboratively to write fake reviews) is even more damaging as they can take total control of the sentiment on the target product due to its size. This paper studies spam detection in the collaborative setting i.e. to discover fake reviewer groups. The proposed method first uses a frequent itemset mining method to find a set of candidate groups. It then uses several behavioral models derived from the collusion phenomenon among fake reviewers and relation models based on the relationships among groups individual reviewers and products they reviewed to detect fake reviewer groups. Additionally we also built a labeled dataset of fake reviewer groups. Although labeling individual fake reviews and reviewers is very hard to our surprise labeling fake reviewer groups is much easier. We also note that the proposed technique departs from the traditional supervised learning approach for spam detection because of the inherent nature of our problem which makes the classic supervised learning approach less effective. Experimental results show that the proposed method outperforms multiple strong baselines including the state-of-the-art supervised classification regression and learning to rank algorithms.;
Proceedings of the 21st International Conference on World Wide Web;Malware has become the centerpiece of most security threats on the Internet. Malware analysis is an essential technology that extracts the runtime behavior of malware and supplies signatures to detection systems and provides evidence for recovery and cleanup. The focal point in the malware analysis battle is how to detect versus how to hide a malware analyzer from malware during runtime. State-of-the-art analyzers reside in or emulate part of the guest operating system and its underlying hardware making them easy to detect and evade. In this paper we propose a transparent and external approach to malware analysis which is motivated by the intuition that for a malware analyzer to be transparent it must not induce any side-effects that are unconditionally detectable by malware. Our analyzer Ether is based on a novel application of hardware virtualization extensions such as Intel VT and resides completely outside of the target OS environment. Thus there are no in-guest software components vulnerable to detection and there are no shortcomings that arise from incomplete or inaccurate systememulation. Our experiments are based on our study of obfuscation techniques used to create 25000 recent malware samples. The results show that Ether remains transparent and defeats the obfuscation tools that evade existing approaches.;
Proceedings of the 15th ACM Conference on Computer and Communications Security;Modern datacenter applications demand high throughput (40Gbps) and ultra-low latency (&lt 10 Î¼s per hop) from the network with low CPU overhead. Standard TCP/IP stacks cannot meet these requirements but Remote Direct Memory Access (RDMA) can. On IP-routed datacenter networks RDMA is deployed using RoCEv2 protocol which relies on Priority-based Flow Control (PFC) to enable a drop-free network. However PFC can lead to poor application performance due to problems like head-of-line blocking and unfairness. To alleviates these problems we introduce DCQCN an end-to-end congestion control scheme for RoCEv2. To optimize DCQCN performance we build a fluid model and provide guidelines for tuning switch buffer thresholds and other protocol parameters. Using a 3-tier Clos network testbed we show that DCQCN dramatically improves throughput and fairness of RoCEv2 RDMA traffic. DCQCN is implemented in Mellanox NICs and is being deployed in Microsoft's datacenters.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;The computer vision and pattern recognition communities have recently witnessed a surge of feature-based methods in object recognition and image retrieval applications. These methods allow representing images as collections of â€œvisual wordsâ€ and treat them using text search approaches following the â€œbag of featuresâ€ paradigm. In this article we explore analogous approaches in the 3D world applied to the problem of nonrigid shape retrieval in large databases. Using multiscale diffusion heat kernels as â€œgeometric wordsâ€ we construct compact and informative shape descriptors by means of the â€œbag of featuresâ€ approach. We also show that considering pairs of â€œgeometric wordsâ€ (â€œgeometric expressionsâ€) allows creating spatially sensitive bags of features with better discriminative power. Finally adopting metric learning approaches we show that shapes can be efficiently represented as binary codes. Our approach achieves state-of-the-art results on the SHREC 2010 large-scale shape retrieval benchmark.;
TIMELY: RTT-based Congestion Control for the Datacenter;Datacenter transports aim to deliver low latency messaging together with high throughput. We show that simple packet delay measured as round-trip times at hosts is an effective congestion signal without the need for switch feedback. First we show that advances in NIC hardware have made RTT measurement possible with microsecond accuracy and that these RTTs are sufficient to estimate switch queueing. Then we describe how TIMELY can adjust transmission rates using RTT gradients to keep packet latency low while delivering high bandwidth. We implement our design in host software running over NICs with OS-bypass capabilities. We show using experiments with up to hundreds of machines on a Clos network topology that it provides excellent performance: turning on TIMELY for OS-bypass messaging over a fabric with PFC lowers 99 percentile tail latency by 9X while maintaining near line-rate throughput. Our system also outperforms DCTCP running in an optimized kernel reducing tail latency by $13$X. To the best of our knowledge TIMELY is the first delay-based congestion control protocol for use in the datacenter and it achieves its results despite having an order of magnitude fewer RTT signals (due to NIC offload) than earlier delay-based schemes such as Vegas.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;This paper introduces architectural and interaction patterns for integrating crowdsourced human contributions directly into user interfaces. We focus on writing and editing complex endeavors that span many levels of conceptual and pragmatic activity. Authoring tools offer help with pragmatics but for higher-level help writers commonly turn to other people. We thus present Soylent a word processing interface that enables writers to call on Mechanical Turk workers to shorten proofread and otherwise edit parts of their documents on demand. To improve worker quality we introduce the Find-Fix-Verify crowd programming pattern which splits tasks into a series of generation and review stages. Evaluation studies demonstrate the feasibility of crowdsourced editing and investigate questions of reliability cost wait time and work time for edits.;
Proceedings of the 23nd Annual ACM Symposium on User Interface Software and Technology;Tagging plays an important role in many recent websites. Recommender systems can help to suggest a user the tags he might want to use for tagging a specific item. Factorization models based on the Tucker Decomposition (TD) model have been shown to provide high quality tag recommendations outperforming other approaches like PageRank FolkRank collaborative filtering etc. The problem with TD models is the cubic core tensor resulting in a cubic runtime in the factorization dimension for prediction and learning.In this paper we present the factorization model PITF (Pairwise Interaction Tensor Factorization) which is a special case of the TD model with linear runtime both for learning and prediction. PITF explicitly models the pairwise interactions between users items and tags. The model is learned with an adaption of the Bayesian personalized ranking (BPR) criterion which originally has been introduced for item recommendation. Empirically we show on real world datasets that this model outperforms TD largely in runtime and even can achieve better prediction quality. Besides our lab experiments PITF has also won the ECML/PKDD Discovery Challenge 2009 for graph-based tag recommendation.;
Proceedings of the Third ACM International Conference on Web Search and Data Mining;In the last years there has been an increasing interest in the security of process control and SCADA systems. Furthermore recent computer attacks such as the Stuxnet worm have shown there are parties with the motivation and resources to effectively attack control systems.While previous work has proposed new security mechanisms for control systems few of them have explored new and fundamentally different research problems for securing control systems when compared to securing traditional information technology (IT) systems. In particular the sophistication of new malware attacking control systems--malware including zero-days attacks rootkits created for control systems and software signed by trusted certificate authorities--has shown that it is very difficult to prevent and detect these attacks based solely on IT system information.In this paper we show how by incorporating knowledge of the physical system under control we are able to detect computer attacks that change the behavior of the targeted control system. By using knowledge of the physical system we are able to focus on the final objective of the attack and not on the particular mechanisms of how vulnerabilities are exploited and how the attack is hidden. We analyze the security and safety of our mechanisms by exploring the effects of stealthy attacks and by ensuring that automatic attack-response mechanisms will not drive the system to an unsafe state.A secondary goal of this paper is to initiate the discussion between control and security practitioners--two areas that have had little interaction in the past. We believe that control engineers can leverage security engineering to design--based on a combination of their best practices--control algorithms that go beyond safety and fault tolerance and include considerations to survive targeted attacks.;
Proceedings of the 6th ACM Symposium on Information Computer and Communications Security;BI technologies are essential to running today's businesses and this technology is going through sea changes.;
Deep photo: model-based photograph enhancement and viewing;In this paper we introduce a novel system for browsing enhancing and manipulating casual outdoor photographs by combining them with already existing georeferenced digital terrain and urban models. A simple interactive registration process is used to align a photograph with such a model. Once the photograph and the model have been registered an abundance of information such as depth texture and GIS data becomes immediately available to our system. This information in turn enables a variety of operations ranging from dehazing and relighting the photograph to novel view synthesis and overlaying with geographic information. We describe the implementation of a number of these applications and discuss possible extensions. Our results show that augmenting photographs with already available 3D models of the world supports a wide variety of new ways for us to experience and interact with our everyday snapshots.;
SecondNet: a data center network virtualization architecture with bandwidth guarantees;In this paper we propose virtual data center (VDC) as the unit of resource allocation for multiple tenants in the cloud. VDCs are more desirable than physical data centers because the resources allocated to VDCs can be rapidly adjusted as tenants' needs change. To enable the VDC abstraction we design a data center network virtualization architecture called SecondNet. SecondNet achieves scalability by distributing all the virtual-to-physical mapping routing and bandwidth reservation state in server hypervisors. Its port-switching based source routing (PSSR) further makes SecondNet applicable to arbitrary network topologies using commodity servers and switches. SecondNet introduces a centralized VDC allocation algorithm for bandwidth guaranteed virtual to physical mapping. Simulations demonstrate that our VDC allocation achieves high network utilization and low time complexity. Our implementation and experiments show that we can build SecondNet on top of various network topologies and SecondNet provides bandwidth guarantee and elasticity as designed.;
Proceedings of the 6th International COnference;Existing Greybox Fuzzers (GF) cannot be effectively directed for instance towards problematic changes or patches towards critical system calls or dangerous locations or towards functions in the stack-trace of a reported vulnerability that we wish to reproduce. In this paper we introduce Directed Greybox Fuzzing (DGF) which generates inputs with the objective of reaching a given set of target program locations efficiently. We develop and evaluate a simulated annealing-based power schedule that gradually assigns more energy to seeds that are closer to the target locations while reducing energy for seeds that are further away. Experiments with our implementation AFLGo demonstrate that DGF outperforms both directed symbolic-execution-based whitebox fuzzing and undirected greybox fuzzing. We show applications of DGF to patch testing and crash reproduction and discuss the integration of AFLGo into Google's continuous fuzzing platform OSS-Fuzz. Due to its directedness AFLGo could find 39 bugs in several well-fuzzed security-critical projects like LibXML2. 17 CVEs were assigned.;
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security;An algorithm is described to solve multiple-phase optimal control problems using a recently developed numerical method called the Gauss pseudospectral method. The algorithm is well suited for use in modern vectorized programming languages such as FORTRAN 95 and MATLAB. The algorithm discretizes the cost functional and the differential-algebraic equations in each phase of the optimal control problem. The phases are then connected using linkage conditions on the state and time. A large-scale nonlinear programming problem (NLP) arises from the discretization and the significant features of the NLP are described in detail. A particular reusable MATLAB implementation of the algorithm called GPOPS is applied to three classical optimal control problems to demonstrate its utility. The algorithm described in this article will provide researchers and engineers a useful software tool and a reference when it is desired to implement the Gauss pseudospectral method in other programming languages.;
Personal tracking as lived informatics;"This paper characterises the use of activity trackers as lived informatics"". This characterisation is contrasted with other discussions of personal informatics and the quantified self. The paper reports an interview study with activity tracker users. The study found: people do not logically organise but interweave various activity trackers sometimes with ostensibly the same functionality that tracking is often social and collaborative rather than personal that there are different styles of tracking including goal driven tracking and documentary tracking and that tracking information is often used and interpreted with reference to daily or short term goals and decision making. We suggest there will be difficulties in personal informatics if we ignore the way that personal tracking is enmeshed with everyday life and people's outlook on their future.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;High utility itemsets refer to the sets of items with high utility like profit in a database and efficient mining of high utility itemsets plays a crucial role in many real-life applications and is an important research issue in data mining area. To identify high utility itemsets most existing algorithms first generate candidate itemsets by overestimating their utilities and subsequently compute the exact utilities of these candidates. These algorithms incur the problem that a very large number of candidates are generated but most of the candidates are found out to be not high utility after their exact utilities are computed. In this paper we propose an algorithm called HUI-Miner (High Utility Itemset Miner) for high utility itemset mining. HUI-Miner uses a novel structure called utility-list to store both the utility information about an itemset and the heuristic information for pruning the search space of HUI-Miner. By avoiding the costly generation and utility computation of numerous candidate itemsets HUI-Miner can efficiently mine high utility itemsets from the utility-lists constructed from a mined database. We compared HUI-Miner with the state-of-the-art algorithms on various databases and experimental results show that HUI-Miner outperforms these algorithms in terms of both running time and memory consumption.;
Proceedings of the 21st ACM International Conference on Information and Knowledge Management;Decentralized cryptocurrencies feature the use of blockchain to transfer values among peers on networks without central agency. Smart contracts are programs running on top of the blockchain consensus protocol to enable people make agreements while minimizing trusts. Millions of smart contracts have been deployed in various decentralized applications. The security vulnerabilities within those smart contracts pose significant threats to their applications. Indeed many critical security vulnerabilities within smart contracts on Ethereum platform have caused huge financial losses to their users. In this work we present ContractFuzzer a novel fuzzer to test Ethereum smart contracts for security vulnerabilities. ContractFuzzer generates fuzzing inputs based on the ABI specifications of smart contracts defines test oracles to detect security vulnerabilities instruments the EVM to log smart contracts runtime behaviors and analyzes these logs to report security vulnerabilities. Our fuzzing of 6991 smart contracts has flagged more than 459 vulnerabilities with high precision. In particular our fuzzing tool successfully detects the vulnerability of the DAO contract that leads to USD 60 million loss and the vulnerabilities of Parity Wallet that have led to the loss of USD 30 million and the freezing of USD 150 million worth of Ether.;
Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering;We explore the indoor positioning problem with unmodified smartphones and slightly-modified commercial LED luminaires. The luminaires-modified to allow rapid on-off keying-transmit their identifiers and/or locations encoded in human-imperceptible optical pulses. A camera-equipped smartphone using just a single image frame capture can detect the presence of the luminaires in the image decode their transmitted identifiers and/or locations and determine the smartphone's location and orientation relative to the luminaires. Continuous image capture and processing enables continuous position updates. The key insights underlying this work are (i) the driver circuits of emerging LED lighting systems can be easily modified to transmit data through on-off keying (ii) the rolling shutter effect of CMOS imagers can be leveraged to receive many bits of data encoded in the optical transmissions with just a single frame capture (iii) a camera is intrinsically an angle-of-arrival sensor so the projection of multiple nearby light sources with known positions onto a camera's image plane can be framed as an instance of a sufficiently-constrained angle-of-arrival localization problem and (iv) this problem can be solved with optimization techniques. We explore the feasibility of the design through an analytical model demonstrate the viability of the design through a prototype system discuss the challenges to a practical deployment including usability and scalability and demonstrate decimeter-level accuracy in both carefully controlled and more realistic human mobility scenarios.;
Proceedings of the 20th Annual International Conference on Mobile Computing and Networking;Recently contrastive learning (CL) has emerged as a successful method for unsupervised graph representation learning. Most graph CL methods first perform stochastic augmentation on the input graph to obtain two graph views and maximize the agreement of representations in the two views. Despite the prosperous development of graph CL methods the design of graph augmentation schemesâ€”a crucial component in CLâ€”remains rarely explored. We argue that the data augmentation schemes should preserve intrinsic structures and attributes of graphs which will force the model to learn representations that are insensitive to perturbation on unimportant nodes and edges. However most existing methods adopt uniform data augmentation schemes like uniformly dropping edges and uniformly shuffling features leading to suboptimal performance. In this paper we propose a novel graph contrastive representation learning method with adaptive augmentation that incorporates various priors for topological and semantic aspects of the graph. Specifically on the topology level we design augmentation schemes based on node centrality measures to highlight important connective structures. On the node attribute level we corrupt node features by adding more noise to unimportant node features to enforce the model to recognize underlying semantic information. We perform extensive experiments of node classification on a variety of real-world datasets. Experimental results demonstrate that our proposed method consistently outperforms existing state-of-the-art baselines and even surpasses some supervised counterparts which validates the effectiveness of the proposed contrastive framework with adaptive augmentation.;
Proceedings of the Web Conference 2021;Smartphone sales have recently experienced explosive growth. Their popularity also encourages malware authors to penetrate various mobile marketplaces with malicious applications (or apps). These malicious apps hide in the sheer number of other normal apps which makes their detection challenging. Existing mobile anti-virus software are inadequate in their reactive nature by relying on known malware samples for signature extraction. In this paper we propose a proactive scheme to spot zero-day Android malware. Without relying on malware samples and their signatures our scheme is motivated to assess potential security risks posed by these untrusted apps. Specifically we have developed an automated system called RiskRanker to scalably analyze whether a particular app exhibits dangerous behavior (e.g. launching a root exploit or sending background SMS messages). The output is then used to produce a prioritized list of reduced apps that merit further investigation. When applied to examine 118318 total apps collected from various Android markets over September and October 2011 our system takes less than four days to process all of them and effectively reports 3281 risky apps. Among these reported apps we successfully uncovered 718 malware samples (in 29 families) and 322 of them are zero-day (in 11 families). These results demonstrate the efficacy and scalability of RiskRanker to police Android markets of all stripes.;
Proceedings of the 10th International Conference on Mobile Systems Applications and Services;Distributed controllers have been proposed for Software Defined Networking to address the issues of scalability and reliability that a centralized controller suffers from. One key limitation of the distributed controllers is that the mapping between a switch and a controller is statically configured which may result in uneven load distribution among the controllers. To address this problem we propose ElastiCon an elastic distributed controller architecture in which the controller pool is dynamically grown or shrunk according to traffic conditions and the load is dynamically shifted across controllers. We propose a novel switch migration protocol for enabling such load shifting which conforms with the Openflow standard. We also build a prototype to demonstrate the efficacy of our design.;
Proceedings of the Second ACM SIGCOMM Workshop on Hot Topics in Software Defined Networking;Social Mediator is a forum exploring the ways that HCI research and principles interact---or might interact---with practices in the social media world.Joe McCarthy Editor;
Cross-project defect prediction: a large scale experiment on data vs. domain vs. process;Prediction of software defects works well within projects as long as there is a sufficient amount of data available to train any models. However this is rarely the case for new software projects and for many companies. So far only a few have studies focused on transferring prediction models from one project to another. In this paper we study cross-project defect prediction models on a large scale. For 12 real-world applications we ran 622 cross-project predictions. Our results indicate that cross-project prediction is a serious challenge i.e. simply using models from projects in the same domain or with the same process does not lead to accurate predictions. To help software engineers choose models wisely we identified factors that do influence the success of cross-project predictions. We also derived decision trees that can provide early estimates for precision recall and accuracy before a prediction is attempted.;
Proceedings of the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering;Breadth-first search (BFS) is a core primitive for graph traversal and a basis for many higher-level graph analysis algorithms. It is also representative of a class of parallel computations whose memory accesses and work distribution are both irregular and data-dependent. Recent work has demonstrated the plausibility of GPU sparse graph traversal but has tended to focus on asymptotically inefficient algorithms that perform poorly on graphs with non-trivial diameter.We present a BFS parallelization focused on fine-grained task management constructed from efficient prefix sum that achieves an asymptotically optimal O(|V|+|E|) work complexity. Our implementation delivers excellent performance on diverse graphs achieving traversal rates in excess of 3.3 billion and 8.3 billion traversed edges per second using single and quad-GPU configurations respectively. This level of performance is several times faster than state-of-the-art implementations both CPU and GPU platforms.;
Proceedings of the 17th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming;The development of the Internet in recent years has made it possible and useful to access many different information systems anywhere in the world to obtain information. While there is much research on the integration of heterogeneous information systems most commercial systems stop short of the actual integration of available data. Data fusion is the process of fusing multiple records representing the same real-world object into a single consistent and clean representation.This article places data fusion into the greater context of data integration precisely defines the goals of data fusion namely complete concise and consistent data and highlights the challenges of data fusion namely uncertain and conflicting data values. We give an overview and classification of different ways of fusing data and present several techniques based on standard and advanced operators of the relational algebra and SQL. Finally the article features a comprehensive survey of data integration systems from academia and industry showing if and how data fusion is performed in each.;
Kandoo: a framework for efficient and scalable offloading of control applications;Limiting the overhead of frequent events on the control plane is essential for realizing a scalable Software-Defined Network. One way of limiting this overhead is to process frequent events in the data plane. This requires modifying switches and comes at the cost of visibility in the control plane. Taking an alternative route we propose Kandoo a framework for preserving scalability without changing switches. Kandoo has two layers of controllers: (i) the bottom layer is a group of controllers with no interconnection and no knowledge of the network-wide state and (ii) the top layer is a logically centralized controller that maintains the network-wide state. Controllers at the bottom layer run only local control applications (i.e. applications that can function using the state of a single switch) near datapaths. These controllers handle most of the frequent events and effectively shield the top layer. Kandoo's design enables network operators to replicate local controllers on demand and relieve the load on the top layer which is the only potential bottleneck in terms of scalability. Our evaluations show that a network controlled by Kandoo has an order of magnitude lower control channel consumption compared to normal OpenFlow networks.;
Proceedings of the First Workshop on Hot Topics in Software Defined Networks;Empirical evidence suggests that hashing is an effective strategy for dimensionality reduction and practical nonparametric estimation. In this paper we provide exponential tail bounds for feature hashing and show that the interaction between random subspaces is negligible with high probability. We demonstrate the feasibility of this approach with experimental results for a new use case --- multitask learning with hundreds of thousands of tasks.;
Proceedings of the 26th Annual International Conference on Machine Learning;"OmniTouch is a wearable depth-sensing and projection system that enables interactive multitouch applications on everyday surfaces. Beyond the shoulder-worn system there is no instrumentation of the user or environment. Foremost the system allows the wearer to use their hands arms and legs as graphical interactive surfaces. Users can also transiently appropriate surfaces from the environment to expand the interactive area (e.g. books walls tables). On such surfaces - without any calibration - OmniTouch provides capabilities similar to that of a mouse or touchscreen: X and Y location in 2D interfaces and whether fingers are clicked"" or hovering enabling a wide variety of interactions. Reliable operation on the hands for example requires buttons to be 2.3cm in diameter. Thus it is now conceivable that anything one can do on today's mobile devices they could do in the palm of their hand.""";
Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology;Top end mobile phones include a number of specialized (e.g. accelerometer compass GPS) and general purpose sensors (e.g. microphone camera) that enable new people-centric sensing applications. Perhaps the most ubiquitous and unexploited sensor on mobile phones is the microphone - a powerful sensor that is capable of making sophisticated inferences about human activity location and social events from sound. In this paper we exploit this untapped sensor not in the context of human communications but as an enabler of new sensing applications. We propose SoundSense a scalable framework for modeling sound events on mobile phones. SoundSense is implemented on the Apple iPhone and represents the first general purpose sound sensing system specifically designed to work on resource limited phones. The architecture and algorithms are designed for scalability and Soundsense uses a combination of supervised and unsupervised learning techniques to classify both general sound types (e.g. music voice) and discover novel sound events specific to individual users. The system runs solely on the mobile phone with no back-end interactions. Through implementation and evaluation of two proof of concept people-centric sensing applications we demostrate that SoundSense is capable of recognizing meaningful sound events that occur in users' everyday lives.;
Proceedings of the 7th International Conference on Mobile Systems Applications and Services;Deep learning (DL) defines a new data-driven programming paradigm that constructs the internal system logic of a crafted neuron network through a set of training data. We have seen wide adoption of DL in many safety-critical scenarios. However a plethora of studies have shown that the state-of-the-art DL systems suffer from various vulnerabilities which can lead to severe consequences when applied to real-world applications. Currently the testing adequacy of a DL system is usually measured by the accuracy of test data. Considering the limitation of accessible high quality test data good accuracy performance on test data can hardly provide confidence to the testing adequacy and generality of DL systems. Unlike traditional software systems that have clear and controllable logic and functionality the lack of interpretability in a DL system makes system analysis and defect detection difficult which could potentially hinder its real-world deployment. In this paper we propose DeepGauge a set of multi-granularity testing criteria for DL systems which aims at rendering a multi-faceted portrayal of the testbed. The in-depth evaluation of our proposed testing criteria is demonstrated on two well-known datasets five DL systems and with four state-of-the-art adversarial attack techniques against DL. The potential usefulness of DeepGauge sheds light on the construction of more generic and robust DL systems.;
Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering;Approximate computing is an emerging design paradigm that enables highly efficient hardware and software implementations by exploiting the inherent resilience of applications to in-exactness in their computations. Previous work in this area has demonstrated the potential for significant energy and performance improvements but largely consists of ad hoc techniques that have been applied to a small number of applications. Taking approximate computing closer to mainstream adoption requires (i) a deeper understanding of inherent application resilience across a broader range of applications (ii) tools that can quantitatively establish the inherent resilience of an application and (iii) methods to quickly assess the potential of various approximate computing techniques for a given application. We make two key contributions in this direction. Our primary contribution is the analysis and characterization of inherent application resilience present in a suite of 12 widely used applications from the domains of recognition data mining and search. Based on this analysis we present several new insights into the nature of resilience and its relationship to various key application characteristics. To facilitate our analysis we propose a systematic framework for Application Resilience Characterization (ARC) that (a) partitions an application into resilient and sensitive parts and (b) characterizes the resilient parts using approximation models that abstract a wide range of approximate computing techniques. We believe that the key insights that we present can help shape further research in the area of approximate computing while automatic resilience characterization frameworks such as ARC can greatly aid designers in the adoption approximate computing.;
Proceedings of the 50th Annual Design Automation Conference;We present a framework to synthesize character movements based on high level parameters such that the produced movements respect the manifold of human motion trained on a large motion capture dataset. The learned motion manifold which is represented by the hidden units of a convolutional autoencoder represents motion data in sparse components which can be combined to produce a wide range of complex movements. To map from high level parameters to the motion manifold we stack a deep feedforward neural network on top of the trained autoencoder. This network is trained to produce realistic motion sequences from parameters such as a curve over the terrain that the character should follow or a target location for punching and kicking. The feedforward control network and the motion manifold are trained independently allowing the user to easily switch between feedforward networks according to the desired interface without re-training the motion manifold. Once motion is generated it can be edited by performing optimization in the space of the motion manifold. This allows for imposing kinematic constraints or transforming the style of the motion while ensuring the edited motion remains natural. As a result the system can produce smooth high quality motion sequences without any manual pre-processing of the training data.;
Human computation: a survey and taxonomy of a growing field;"The rapid growth of human computation within research and industry has produced many novel ideas aimed at organizing web users to do great things. However the growth is not adequately supported by a framework with which to understand each new system in the context of the old. We classify human computation systems to help identify parallels between different systems and reveal holes"" in the existing work as opportunities for new research. Since human computation is often confused with ""crowdsourcing"" and other terms we explore the position of human computation with respect to these related topics.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;"Ethereum is a major blockchain-based platform for smart contracts - Turing complete programs that are executed in a decentralized network and usually manipulate digital units of value. Solidity is the most mature high-level smart contract language. Ethereum is a hostile execution environment where anonymous attackers exploit bugs for immediate financial gain. Developers have a very limited ability to patch deployed contracts. Hackers steal up to tens of millions of dollars from flawed contracts a well-known example being The DAO"" broken in June 2016. Advice on secure Ethereum programming practices is spread out across blogs papers and tutorials. Many sources are outdated due to a rapid pace of development in this field. Automated vulnerability detection tools which help detect potentially problematic language constructs are still underdeveloped in this area.We provide a comprehensive classification of code issues in Solidity and implement SmartCheck - an extensible static analysis tool that detects them1. SmartCheck translates Solidity source code into an XML-based intermediate representation and checks it against XPath patterns. We evaluated our tool on a big dataset of real-world contracts and compared the results with manual audit on three contracts. Our tool reflects the current state of knowledge on Solidity vulnerabilities and shows significant improvements over alternatives. SmartCheck has its limitations as detection of some bugs requires more sophisticated techniques such as taint analysis or even manual audit. We believe though that a static analyzer should be an essential part of contract developers' toolbox letting them fix simple bugs fast and allocate more effort to complex issues.""";
Proceedings of the 1st International Workshop on Emerging Trends in Software Engineering for Blockchain;Software algorithms are changing how people work in an ever-growing number of fields managing distributed human workers at a large scale. In these work settings human jobs are assigned optimized and evaluated through algorithms and tracked data. We explore the impact of this algorithmic data-driven management on human workers and work practices in the context of Uber and Lyft new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work provided informational support and evaluated their performance and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.;
Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems;Micro-blogs a relatively new phenomenon provide a new communication channel for people to broadcast information that they likely would not share otherwise using existing channels (e.g. email phone IM or weblogs). Micro-blogging has become popu-lar quite quickly raising its potential for serving as a new informal communication medium at work providing a variety of impacts on collaborative work (e.g. enhancing information sharing building common ground and sustaining a feeling of connectedness among colleagues). This exploratory research project is aimed at gaining an in-depth understanding of how and why people use Twitter - a popular micro-blogging tool - and exploring micro-blog's poten-tial impacts on informal communication at work.;
Proceedings of the 2009 ACM International Conference on Supporting Group Work;This paper presents S2E a platform for analyzing the properties and behavior of software systems. We demonstrate S2E's use in developing practical tools for comprehensive performance profiling reverse engineering of proprietary software and bug finding for both kernel-mode and user-mode binaries. Building these tools on top of S2E took less than 770 LOC and 40 person-hours each.S2E's novelty consists of its ability to scale to large real systems such as a full Windows stack. S2E is based on two new ideas: selective symbolic execution a way to automatically minimize the amount of code that has to be executed symbolically given a target analysis and relaxed execution consistency models a way to make principled performance/accuracy trade-offs in complex analyses. These techniques give S2E three key abilities: to simultaneously analyze entire families of execution paths instead of just one execution at a time to perform the analyses in-vivo within a real software stack--user programs libraries kernel drivers etc.--instead of using abstract models of these layers and to operate directly on binaries thus being able to analyze even proprietary software.Conceptually S2E is an automated path explorer with modular path analyzers: the explorer drives the target system down all execution paths of interest while analyzers check properties of each such path (e.g. to look for bugs) or simply collect information (e.g. count page faults). Desired paths can be specified in multiple ways and S2E users can either combine existing analyzers to build a custom analysis tool or write new analyzers using the S2E API.;
Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems;We investigate if WiFi access can be used to augment 3G capacity in mobile environments. We rst conduct a detailed study of 3G and WiFi access from moving vehicles in three different cities. We find that the average 3G and WiFi availability across the cities is 87% and 11% respectively. WiFi throughput is lower than 3G through-put and WiFi loss rates are higher. We then design a system called Wiffler to augments mobile 3G capacity. It uses two key ideas leveraging delay tolerance and fast switching -- to overcome the poor availability and performance of WiFi. For delay tolerant applications Wiffler uses a simple model of the environment to predict WiFi connectivity. It uses these predictions to delays transfers to offload more data on WiFi but only if delaying reduces 3G usage and the transfers can be completed within the application's tolerance threshold. For applications that are extremely sensitive to delay or loss (e.g. VoIP) Wiffler quickly switches to 3G if WiFi is unable to successfully transmit the packet within a small time window. We implement and deploy Wiffler in our vehicular testbed. Our experiments show that Wiffler significantly reduces 3G usage. For a realistic workload the reduction is 45% for a delay tolerance of 60 seconds.;
Proceedings of the 8th International Conference on Mobile Systems Applications and Services;The Linux Kernel currently supports at least 8 distinct virtualization systems: Xen KVM VMware's VMI IBM's System p IBM's System z User Mode Linux lguest and IBM's legacy iSeries. It seems likely that more such systems will appear and until recently each of these had its own block network console and other drivers with varying features and optimizations.The attempt to address this is virtio: a series of efficient well-maintained Linux drivers which can be adapted for various different hypervisor implementations using a shim layer. This includes a simple extensible feature mechanism for each driver. We also provide an obvious ring buffer transport implementation called vring which is currently used by KVM and lguest. This has the subtle effect of providing a path of least resistance for any new hypervisors: supporting this efficient transport mechanism will immediately reduce the amount of work which needs to be done. Finally we provide an implementation which presents the vring transport and device configuration as a PCI device: this means guest operating systems merely need a new PCI driver and hypervisors need only add vring support to the virtual devices they implement (currently only KVM does this).This paper will describe the virtio API layer as implemented in Linux then the vring implementation and finally its embodiment in a PCI device for simple adoption on otherwise fully-virtualized guests. We'll wrap up with some of the preliminary work to integrate this I/O mechanism deeper into the Linux host kernel.;
Evaluation methods for topic models;A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable several estimators for this probability have been used in the topic modeling literature including the harmonic mean method and empirical likelihood method. In this paper we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents and propose two alternative methods that are both accurate and efficient.;
Proceedings of the 26th Annual International Conference on Machine Learning;We present the Sketchy database the first large-scale collection of sketch-photo pairs. We ask crowd workers to sketch particular photographic objects sampled from 125 categories and acquire 75471 sketches of 12500 objects. The Sketchy database gives us fine-grained associations between particular photos and sketches and we use this to train cross-domain convolutional networks which embed sketches and photographs in a common feature space. We use our database as a benchmark for fine-grained retrieval and show that our learned representation significantly outperforms both hand-crafted features as well as deep features trained for sketch or photo classification. Beyond image retrieval we believe the Sketchy database opens up new opportunities for sketch and image understanding and synthesis.;
Investigating web services on the world wide web;Searching for Web service access points is no longer attached to service registries as Web search engines have become a new major source for discovering Web services. In this work we conduct a thorough analytical investigation on the plurality of Web service interfaces that exist on the Web today. Using our Web Service Crawler Engine (WSCE) we collect metadata service information on retrieved interfaces through accessible UBRs service portals and search engines. We use this data to determine Web service statistics and distribution based on object sizes types of technologies employed and the number of functioning services. This statistical data can be used to help determine the current status of Web services. We determine an intriguing result that 63% of the available Web services on the Web are considered to be active. We further use our findings to provide insights on improving the service retrieval process.;
Proceedings of the 17th International Conference on World Wide Web;Mobile sensing and computing applications usually require time-series inputs from sensors such as accelerometers gyroscopes and magnetometers. Some applications such as tracking can use sensed acceleration and rate of rotation to calculate displacement based on physical system models. Other applications such as activity recognition extract manually designed features from sensor inputs for classification. Such applications face two challenges. On one hand on-device sensor measurements are noisy. For many mobile applications it is hard to find a distribution that exactly describes the noise in practice. Unfortunately calculating target quantities based on physical system and noise models is only as accurate as the noise assumptions. Similarly in classification applications although manually designed features have proven to be effective it is not always straightforward to find the most robust features to accommodate diverse sensor noise patterns and heterogeneous user behaviors. To this end we propose DeepSense a deep learning framework that directly addresses the aforementioned noise and feature customization challenges in a unified manner. DeepSense integrates convolutional and recurrent neural networks to exploit local interactions among similar mobile sensors merge local interactions of different sensory modalities into global interactions and extract temporal relationships to model signal dynamics. DeepSense thus provides a general signal estimation and classification framework that accommodates a wide range of applications. We demonstrate the effectiveness of DeepSense using three representative and challenging tasks: car tracking with motion sensors heterogeneous human activity recognition and user identification with biometric motion analysis. DeepSense significantly outperforms the state-of-the-art methods for all three tasks. In addition we show that DeepSense is feasible to implement on smartphones and embedded devices thanks to its moderate energy consumption and low latency.;
Proceedings of the 26th International Conference on World Wide Web;The run-time binding of web services has been recently put forward in order to support rapid and dynamic web service compositions. With the growing number of alternative web services that provide the same functionality but differ in quality parameters the service composition becomes a decision problem on which component services should be selected such that user's end-to-end QoS requirements (e.g. availability response time) and preferences (e.g. price) are satisfied. Although very efficient local selection strategy fails short in handling global QoS requirements. Solutions based on global optimization on the other hand can handle global constraints but their poor performance renders them inappropriate for applications with dynamic and real-time requirements. In this paper we address this problem and propose a solution that combines global optimization with local selection techniques to benefit from the advantages of both worlds. The proposed solution consists of two steps: first we use mixed integer programming (MIP) to find the optimal decomposition of global QoS constraints into local constraints. Second we use distributed local selection to find the best web services that satisfy these local constraints. The results of experimental evaluation indicate that our approach significantly outperforms existing solutions in terms of computation time while achieving close-to-optimal results.;
Proceedings of the 18th International Conference on World Wide Web;Recommender systems traditionally assume that user profiles and movie attributes are static. Temporal dynamics are purely reactive that is they are inferred after they are observed e.g. after a user's taste has changed or based on hand-engineered temporal bias corrections for movies. We propose Recurrent Recommender Networks (RRN) that are able to predict future behavioral trajectories. This is achieved by endowing both users and movies with a Long Short-Term Memory (LSTM) autoregressive model that captures dynamics in addition to a more traditional low-rank factorization. On multiple real-world datasets our model offers excellent prediction accuracy and it is very compact since we need not learn latent state but rather just the state transition function.;
Proceedings of the Tenth ACM International Conference on Web Search and Data Mining;The advent of novel materials (such as conductive fibers) combined with accessible embedded computing platforms have made it possible to re-imagine the landscapes of fabric and electronic crafts--extending these landscapes with the creative range of electronic/computational textiles or e-textiles. This paper describes the LilyPad Arduino a fabric-based construction kit that enables novices to design and build their own soft wearables and other textile artifacts. The kit consists of a microcontroller and an assortment of sensors and actuators in stitch-able packages these elements can be sewn to cloth substrates and each other with conductive thread to build e-textiles. This paper will introduce the latest version of the kit reflect on its affordances present the results of our most recent user studies and discuss possible directions for future work in the area of personalized e-textile design and its relation to technology education.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Software defect prediction which predicts defective code regions can help developers find bugs and prioritize their testing efforts. To build accurate prediction models previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs and such a capability is needed for building accurate prediction models.To bridge the gap between programs' semantics and defect prediction features this paper proposes to leverage a powerful representation-learning algorithm deep learning to learn semantic representation of programs automatically from source code. Specifically we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs).Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision 11.5% in recall and 14.2% in F1. For CPDP our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1.;
Proceedings of the 38th International Conference on Software Engineering;Formal methods use mathematical models for analysis and verification at any part of the program life-cycle. We describe the state of the art in the industrial use of formal methods concentrating on their increasing use at the earlier stages of specification and design. We do this by reporting on a new survey of industrial use comparing the situation in 2009 with the most significant surveys carried out over the last 20 years. We describe some of the highlights of our survey by presenting a series of industrial projects and we draw some observations from these surveys and records of experience. Based on this we discuss the issues surrounding the industrial adoption of formal methods. Finally we look to the future and describe the development of a Verified Software Repository part of the worldwide Verified Software Initiative. We introduce the initial projects being used to populate the repository and describe the challenges they address.;
Q-clouds: managing performance interference effects for QoS-aware clouds;Cloud computing offers users the ability to access large pools of computational and storage resources on demand. Multiple commercial clouds already allow businesses to replace or supplement privately owned IT assets alleviating them from the burden of managing and maintaining these facilities. However there are issues that must be addressed before this vision of utility computing can be fully realized. In existing systems customers are charged based upon the amount of resources used or reserved but no guarantees are made regarding the application level performance or quality-of-service (QoS) that the given resources will provide. As cloud providers continue to utilize virtualization technologies in their systems this can become problematic. In particular the consolidation of multiple customer applications onto multicore servers introduces performance interference between collocated workloads significantly impacting application QoS. To address this challenge we advocate that the cloud should transparently provision additional resources as necessary to achieve the performance that customers would have realized if they were running in isolation. Accordingly we have developed Q-Clouds a QoS-aware control framework that tunes resource allocations to mitigate performance interference effects. Q-Clouds uses online feedback to build a multi-input multi-output (MIMO) model that captures performance interference interactions and uses it to perform closed loop resource management. In addition we utilize this functionality to allow applications to specify multiple levels of QoS as application Q-states. For such applications Q-Clouds dynamically provisions underutilized resources to enable elevated QoS levels thereby improving system efficiency. Experimental evaluations of our solution using benchmark applications illustrate the benefits: performance interference is mitigated completely when feasible and system utilization is improved by up to 35% using Q-states.;
Proceedings of the 5th European Conference on Computer Systems;This paper aims to detect users generating spam reviews or review spammers. We identify several characteristic behaviors of review spammers and model these behaviors so as to detect the spammers. In particular we seek to model the following behaviors. First spammers may target specific products or product groups in order to maximize their impact. Second they tend to deviate from the other reviewers in their ratings of products. We propose scoring methods to measure the degree of spam for each reviewer and apply them on an Amazon review dataset. We then select a subset of highly suspicious reviewers for further scrutiny by our user evaluators with the help of a web based spammer evaluation software specially developed for user evaluation experiments. Our results show that our proposed ranking and supervised methods are effective in discovering spammers and outperform other baseline method based on helpfulness votes alone. We finally show that the detected spammers have more significant impact on ratings compared with the unhelpful reviewers.;
Proceedings of the 19th ACM International Conference on Information and Knowledge Management;Several domain-specific languages (DSLs) for parallel graph analytics have been proposed recently. In this paper we argue that existing DSLs can be implemented on top of a general-purpose infrastructure that (i) supports very fine-grain tasks (ii) implements autonomous speculative execution of these tasks and (iii) allows application-specific control of task scheduling policies. To support this claim we describe such an implementation called the Galois system.We demonstrate the capabilities of this infrastructure in three ways. First we implement more sophisticated algorithms for some of the graph analytics problems tackled by previous DSLs and show that end-to-end performance can be improved by orders of magnitude even on power-law graphs thanks to the better algorithms facilitated by a more general programming model. Second we show that even when an algorithm can be expressed in existing DSLs the implementation of that algorithm in the more general system can be orders of magnitude faster when the input graphs are road networks and similar graphs with high diameter thanks to more sophisticated scheduling. Third we implement the APIs of three existing graph DSLs on top of the common infrastructure in a few hundred lines of code and show that even for power-law graphs the performance of the resulting implementations often exceeds that of the original DSL systems thanks to the lightweight infrastructure.;
Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles;The problem of cross-modal retrieval e.g. using a text query to search for images and vice-versa is considered in this paper. A novel model involving correspondence autoencoder (Corr-AE) is proposed here for solving this problem. The model is constructed by correlating hidden representations of two uni-modal autoencoders. A novel optimal objective which minimizes a linear combination of representation learning errors for each modality and correlation learning error between hidden representations of two modalities is used to train the model as a whole. Minimization of correlation learning error forces the model to learn hidden representations with only common information in different modalities while minimization of representation learning error makes hidden representations are good enough to reconstruct input of each modality. A parameter $alpha$ is used to balance the representation learning error and the correlation learning error. Based on two different multi-modal autoencoders Corr-AE is extended to other two correspondence models here we called Corr-Cross-AE and Corr-Full-AE. The proposed models are evaluated on three publicly available data sets from real scenes. We demonstrate that the three correspondence autoencoders perform significantly better than three canonical correlation analysis based models and two popular multi-modal deep models on cross-modal retrieval tasks.;
Proceedings of the 22nd ACM International Conference on Multimedia;A range of methods for measuring the effectiveness of information retrieval systems has been proposed. These are typically intended to provide a quantitative single-value summary of a document ranking relative to a query. However many of these measures have failings. For example recall is not well founded as a measure of satisfaction since the user of an actual system cannot judge recall. Average precision is derived from recall and suffers from the same problem. In addition average precision lacks key stability properties that are needed for robust experiments. In this article we introduce a new effectiveness metric rank-biased precision that avoids these problems. Rank-biased pre-cision is derived from a simple model of user behavior is robust if answer rankings are extended to greater depths and allows accurate quantification of experimental uncertainty even when only partial relevance judgments are available.;
Modeling online reviews with multi-grain topic models;In this paper we present a novel framework for extracting the ratable aspects of objects from online user reviews. Extracting such aspects is an important challenge in automatically mining product opinions from the web and in generating opinion-based summaries of user reviews [18 19 7 12 27 36 21]. Our models are based on extensions to standard topic modeling methods such as LDA and PLSA to induce multi-grain topics. We argue that multi-grain models are more appropriate for our task since standard models tend to produce topics that correspond to global properties of objects (e.g. the brand of a product type) rather than the aspects of an object that tend to be rated by a user. The models we present not only extract ratable aspects but also cluster them into coherent topics e.g. 'waitress' and 'bartender' are part of the same topic 'staff' for restaurants. This differentiates it from much of the previous work which extracts aspects through term frequency analysis with minimal clustering. We evaluate the multi-grain models both qualitatively and quantitatively to show that they improve significantly upon standard topic models.;
Proceedings of the 17th International Conference on World Wide Web;The continued success of Deep Neural Networks (DNNs) in classification tasks has sparked a trend of accelerating their execution with specialized hardware. While published designs easily give an order of magnitude improvement over general-purpose hardware few look beyond an initial implementation. This paper presents Minerva a highly automated co-design approach across the algorithm architecture and circuit levels to optimize DNN hardware accelerators. Compared to an established fixed-point accelerator baseline we show that fine-grained heterogeneous datatype optimization reduces power by 1.5\texttimes{;
Proceedings of the 43rd International Symposium on Computer Architecture;The Heartbleed vulnerability took the Internet by surprise in April 2014. The vulnerability one of the most consequential since the advent of the commercial Internet allowed attackers to remotely read protected memory from an estimated 24--55% of popular HTTPS sites. In this work we perform a comprehensive measurement-based analysis of the vulnerability's impact including (1) tracking the vulnerable population (2) monitoring patching behavior over time (3) assessing the impact on the HTTPS certificate ecosystem and (4) exposing real attacks that attempted to exploit the bug. Furthermore we conduct a large-scale vulnerability notification experiment involving 150000 hosts and observe a nearly 50% increase in patching by notified hosts. Drawing upon these analyses we discuss what went well and what went poorly in an effort to understand how the technical community can respond more effectively to such events in the future.;
Proceedings of the 2014 Conference on Internet Measurement Conference;"Powerful services and applications are being integrated and packaged on the Web in what the industry now calls cloud computing""""";
Resource Central: Understanding and Predicting Workloads for Improved Resource Management in Large Cloud Platforms;Cloud research to date has lacked data on the characteristics of the production virtual machine (VM) workloads of large cloud providers. A thorough understanding of these characteristics can inform the providers' resource management systems e.g. VM scheduler power manager server health manager. In this paper we first introduce an extensive characterization of Microsoft Azure's VM workload including distributions of the VMs' lifetime deployment size and resource consumption. We then show that certain VM behaviors are fairly consistent over multiple lifetimes i.e. history is an accurate predictor of future behavior. Based on this observation we next introduce Resource Central (RC) a system that collects VM telemetry learns these behaviors offline and provides predictions online to various resource managers via a general client-side library. As an example of RC's online use we modify Azure's VM scheduler to leverage predictions in oversubscribing servers (with oversubscribable VM types) while retaining high VM performance. Using real VM traces we then show that the prediction-informed schedules increase utilization and prevent physical resource exhaustion. We conclude that providers can exploit their workloads' characteristics and machine learning to improve resource management substantially.;
Proceedings of the 26th Symposium on Operating Systems Principles;Architectural simulation is time-consuming and the trend towards hundreds of cores is making sequential simulation even slower. Existing parallel simulation techniques either scale poorly due to excessive synchronization or sacrifice accuracy by allowing event reordering and using simplistic contention models. As a result most researchers use sequential simulators and model small-scale systems with 16-32 cores. With 100-core chips already available developing simulators that scale to thousands of cores is crucial.We present three novel techniques that together make thousand-core simulation practical. First we speed up detailed core models (including OOO cores) with instruction-driven timing models that leverage dynamic binary translation. Second we introduce bound-weave a two-phase parallelization technique that scales parallel simulation on multicore hosts efficiently with minimal loss of accuracy. Third we implement lightweight user-level virtualization to support complex workloads including multiprogrammed client-server and managed-runtime applications without the need for full-system simulation sidestepping the lack of scalable OSs and ISAs that support thousands of cores.We use these techniques to build zsim a fast scalable and accurate simulator. On a 16-core host zsim models a 1024-core chip at speeds of up to 1500 MIPS using simple cores and up to 300 MIPS using detailed OOO cores 2-3 orders of magnitude faster than existing parallel simulators. Simulator performance scales well with both the number of modeled cores and the number of host cores. We validate zsim against a real Westmere system on a wide variety of workloads and find performance and microarchitectural events to be within a narrow range of the real system.;
Proceedings of the 40th Annual International Symposium on Computer Architecture;Writing programs that scale with increasing numbers of cores should be as easy as writing programs for sequential computers.;
Satisfiability modulo theories: introduction and applications;Checking the satisfiability of logical formulas SMT solvers scale orders of magnitude beyond custom ad hoc solvers.;
Trends and Trajectories for Explainable Accountable and Intelligible Systems: An HCI Research Agenda;Advances in artificial intelligence sensors and big data management have far-reaching societal impacts. As these systems augment our everyday lives it becomes increasing-ly important for people to understand them and remain in control. We investigate how HCI researchers can help to develop accountable systems by performing a literature analysis of 289 core papers on explanations and explaina-ble systems as well as 12412 citing papers. Using topic modeling co-occurrence and network analysis we mapped the research space from diverse domains such as algorith-mic accountability interpretable machine learning context-awareness cognitive psychology and software learnability. We reveal fading and burgeoning trends in explainable systems and identify domains that are closely connected or mostly isolated. The time is ripe for the HCI community to ensure that the powerful new autonomous systems have intelligible interfaces built-in. From our results we propose several implications and directions for future research to-wards this goal.;
Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;This paper presents a many-core visual computing architecture code named Larrabee a new software rendering pipeline a manycore programming model and performance analysis for several applications. Larrabee uses multiple in-order x86 CPU cores that are augmented by a wide vector processor unit as well as some fixed function logic blocks. This provides dramatically higher performance per watt and per unit of area than out-of-order CPUs on highly parallel workloads. It also greatly increases the flexibility and programmability of the architecture as compared to standard GPUs. A coherent on-die 2nd level cache allows efficient inter-processor communication and high-bandwidth local data access by CPU cores. Task scheduling is performed entirely with software in Larrabee rather than in fixed function logic. The customizable software graphics rendering pipeline for this architecture uses binning in order to reduce required memory bandwidth minimize lock contention and increase opportunities for parallelism relative to standard GPUs. The Larrabee native programming model supports a variety of highly parallel applications that use irregular data structures. Performance analysis on those applications demonstrates Larrabee's potential for a broad range of parallel computation.;
Algorithm 915 SuiteSparseQR: Multifrontal multithreaded rank-revealing sparse QR factorization;SuiteSparseQR is a sparse QR factorization package based on the multifrontal method. Within each frontal matrix LAPACK and the multithreaded BLAS enable the method to obtain high performance on multicore architectures. Parallelism across different frontal matrices is handled with Intel's Threading Building Blocks library. The symbolic analysis and ordering phase pre-eliminates singletons by permuting the input matrix A into the form [R11 R12 0 A22] where R11 is upper triangular with diagonal entries above a given tolerance. Next the fill-reducing ordering column elimination tree and frontal matrix structures are found without requiring the formation of the pattern of ATA. Approximate rank-detection is performed within each frontal matrix using Heath's method. While Heath's method is not always exact it has the advantage of not requiring column pivoting and thus does not interfere with the fill-reducing ordering. For sufficiently large problems the resulting sparse QR factorization obtains a substantial fraction of the theoretical peak performance of a multicore computer.;
CHEX: statically vetting Android apps for component hijacking vulnerabilities;An enormous number of apps have been developed for Android in recent years making it one of the most popular mobile operating systems. However the quality of the booming apps can be a concern [4]. Poorly engineered apps may contain security vulnerabilities that can severally undermine users' security and privacy. In this paper we study a general category of vulnerabilities found in Android apps namely the component hijacking vulnerabilities. Several types of previously reported app vulnerabilities such as permission leakage unauthorized data access intent spoofing and etc. belong to this category.We propose CHEX a static analysis method to automatically vet Android apps for component hijacking vulnerabilities. Modeling these vulnerabilities from a data-flow analysis perspective CHEX analyzes Android apps and detects possible hijack-enabling flows by conducting low-overhead reachability tests on customized system dependence graphs. To tackle analysis challenges imposed by Android's special programming paradigm we employ a novel technique to discover component entry points in their completeness and introduce app splitting to model the asynchronous executions of multiple entry points in an app.We prototyped CHEX based on Dalysis a generic static analysis framework that we built to support many types of analysis on Android app bytecode. We evaluated CHEX with 5486 real Android apps and found 254 potential component hijacking vulnerabilities. The median execution time of CHEX on an app is 37.02 seconds which is fast enough to be used in very high volume app vetting and testing scenarios.;
Proceedings of the 2012 ACM Conference on Computer and Communications Security;The problem of gauging information credibility on social networks has received considerable attention in recent years. Most previous work has chosen Twitter the world's largest micro-blogging platform as the premise of research. In this work we shift the premise and study the problem of information credibility on Sina Weibo China's leading micro-blogging service provider. With eight times more users than Twitter Sina Weibo is more of a Facebook-Twitter hybrid than a pure Twitter clone and exhibits several important characteristics that distinguish it from Twitter. We collect an extensive set of microblogs which have been confirmed to be false rumors based on information from the official rumor-busting service provided by Sina Weibo. Unlike previous studies on Twitter where the labeling of rumors is done manually by the participants of the experiments the official nature of this service ensures the high quality of the dataset. We then examine an extensive set of features that can be extracted from the microblogs and train a classifier to automatically detect the rumors from a mixed set of true information and false information. The experiments show that some of the new features we propose are indeed effective in the classification and even the features considered in previous studies have different implications with Sina Weibo than with Twitter. To the best of our knowledge this is the first study on rumor analysis and detection on Sina Weibo.;
Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics;In this paper we propose WifiU which uses commercial WiFi devices to capture fine-grained gait patterns to recognize humans. The intuition is that due to the differences in gaits of different people the WiFi signal reflected by a walking human generates unique variations in the Channel State Information (CSI) on the WiFi receiver. To profile human movement using CSI we use signal processing techniques to generate spectrograms from CSI measurements so that the resulting spectrograms are similar to those generated by specifically designed Doppler radars. To extract features from spectrograms that best characterize the walking pattern we perform autocorrelation on the torso reflection to remove imperfection in spectrograms. We evaluated WifiU on a dataset with 2800 gait instances collected from 50 human subjects walking in a room with an area of 50 square meters. Experimental results show that WifiU achieves top-1 top-2 and top-3 recognition accuracies of 79.28% 89.52% and 93.05% respectively.;
Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing;Dialogue systems have attracted more and more attention. Recent advances on dialogue systems are overwhelmingly contributed by deep learning techniques which have been employed to enhance a wide range of big data applications such as computer vision natural language processing and recommender systems. For dialogue systems deep learning can leverage a massive amount of data to learn meaningful feature representations and response generation strategies while requiring a minimum amount of hand-crafting. In this article we give an overview to these recent advances on dialogue systems from various perspectives and discuss some possible research directions. In particular we generally divide existing dialogue systems into task-oriented and nontask- oriented models then detail how deep learning techniques help them with representative algorithms and finally discuss some appealing research directions that can bring the dialogue system research into a new frontier;
ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA;Long Short-Term Memory (LSTM) is widely used in speech recognition. In order to achieve higher prediction accuracy machine learning scientists have built increasingly larger models. Such large model is both computation intensive and memory intensive. Deploying such bulky model results in high power consumption and leads to a high total cost of ownership (TCO) of a data center. To speedup the prediction and make it energy efficient we first propose a load-balance-aware pruning method that can compress the LSTM model size by 20x (10x from pruning and 2x from quantization) with negligible loss of the prediction accuracy. The pruned model is friendly for parallel processing. Next we propose a scheduler that encodes and partitions the compressed model to multiple PEs for parallelism and schedule the complicated LSTM data flow. Finally we design the hardware architecture named Efficient Speech Recognition Engine (ESE) that works directly on the sparse LSTM model.Implemented on Xilinx KU060 FPGA running at 200MHz ESE has a performance of 282 GOPS working directly on the sparse LSTM network corresponding to 2.52 TOPS on the dense one and processes a full LSTM for speech recognition with a power dissipation of 41 Watts. Evaluated on the LSTM for speech recognition benchmark ESE is 43x and 3x faster than Core i7 5930k CPU and Pascal Titan X GPU implementations. It achieves 40x and 11.5x higher energy efficiency compared with the CPU and GPU respectively.;
Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays;Stochastic gradient descent (SGD) is a popular technique for large-scale optimization problems in machine learning. In order to parallelize SGD minibatch training needs to be employed to reduce the communication cost. However an increase in minibatch size typically decreases the rate of convergence. This paper introduces a technique based on approximate optimization of a conservatively regularized objective function within each minibatch. We prove that the convergence rate does not decrease with increasing minibatch size. Experiments demonstrate that with suitable implementations of approximate optimization the resulting algorithm can outperform standard SGD in many scenarios.;
Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;"Wikipedia's success is often attributed to the large numbers of contributors who improve the accuracy completeness and clarity of articles while reducing bias. However because of the coordination needed to write an article collaboratively adding contributors is costly. We examined how the number of editors in Wikipedia and the coordination methods they use affect article quality. We distinguish between explicit coordination in which editors plan the article through communication and implicit coordination in which a subset of editors structure the work by doing the majority of it. Adding more editors to an article improved article quality only when they used appropriate coordination techniques and was harmful when they did not. Implicit coordination through concentrating the work was more helpful when many editors contributed but explicit coordination through communication was not. Both types of coordination improved quality more when an article was in a formative stage. These results demonstrate the critical importance of coordination in effectively harnessing the wisdom of the crowd"" in online production environments.""";
Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work;Web 2.0 has brought about several new applications that have enabled arbitrary subsets of users to communicate with each other on a social basis. Such communication increasingly happens not just on Facebook and MySpace but on several smaller network applications such as Twitter and Dodgeball. We present a detailed characterization of Twitter an application that allows users to send short messages. We gathered three datasets (covering nearly 100000 users) including constrained crawls of the Twitter network using two different methodologies and a sampled collection from the publicly available timeline. We identify distinct classes of Twitter users and their behaviors geographic growth patterns and current size of the network and compare crawl results obtained under rate limiting constraints.;
Proceedings of the First Workshop on Online Social Networks;The surprising success of cryptocurrencies has led to a surge of interest in deploying large scale highly robust Byzantine fault tolerant (BFT) protocols for mission-critical applications such as financial transactions. Although the conventional wisdom is to build atop a (weakly) synchronous protocol such as PBFT (or a variation thereof) such protocols rely critically on network timing assumptions and only guarantee liveness when the network behaves as expected. We argue these protocols are ill-suited for this deployment scenario. We present an alternative HoneyBadgerBFT the first practical asynchronous BFT protocol which guarantees liveness without making any timing assumptions. We base our solution on a novel atomic broadcast protocol that achieves optimal asymptotic efficiency. We present an implementation and experimental results to show our system can achieve throughput of tens of thousands of transactions per second and scales to over a hundred nodes on a wide area network. We even conduct BFT experiments over Tor without needing to tune any parameters. Unlike the alternatives HoneyBadgerBFT simply does not care about the underlying network.;
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;"Among the leading reference implementations of the Software Defined Networking (SDN) paradigm is the OpenFlow framework which decouples the control plane into a centralized application. In this paper we consider two aspects of OpenFlow that pose security challenges and we propose two solutions that could address these concerns. The first challenge is the inherent communication bottleneck that arises between the data plane and the control plane which an adversary could exploit by mounting a control plane saturation attack"" that disrupts network operations. Indeed even well-mined adversarial models such as scanning or denial-of-service (DoS) activity can produce more potent impacts on OpenFlow networks than traditional networks. To address this challenge we introduce an extension to the OpenFlow data plane called ""connection migration"" which dramatically reduces the amount of data-to-control-plane interactions that arise during such attacks. The second challenge is that of enabling the control plane to expedite both detection of and responses to the changing flow dynamics within the data plane. For this we introduce ""actuating triggers"" over the data plane's existing statistics collection services. These triggers are inserted by control layer applications to both register for asynchronous call backs and insert conditional flow rules that are only activated when a trigger condition is detected within the data plane's statistics module. We present Avant-Guard an implementation of our two data plane extensions evaluate the performance impact and examine its use for developing more scalable and resilient SDN security services.""";
Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp Communications Security;The serious bugs and security vulnerabilities facilitated by C/C++'s lack of bounds checking are well known yet C and C++ remain in widespread use. Unfortunately C's arbitrary pointer arithmetic conflation of pointers and arrays and programmer-visible memory layout make retrofitting C/C++ with spatial safety guarantees extremely challenging. Existing approaches suffer from incompleteness have high runtime overhead or require non-trivial changes to the C source code. Thus far these deficiencies have prevented widespread adoption of such techniques.This paper proposes SoftBound a compile-time transformation for enforcing spatial safety of C. Inspired by HardBound a previously proposed hardware-assisted approach SoftBound similarly records base and bound information for every pointer as disjoint metadata. This decoupling enables SoftBound to provide spatial safety without requiring changes to C source code. Unlike HardBound SoftBound is a software-only approach and performs metadata manipulation only when loading or storing pointer values. A formal proof shows that this is sufficient to provide spatial safety even in the presence of arbitrary casts. SoftBound's full checking mode provides complete spatial violation detection with 67% runtime overhead on average. To further reduce overheads SoftBound has a store-only checking mode that successfully detects all the security vulnerabilities in a test suite at the cost of only 22% runtime overhead on average.;
Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation;Online social networks (OSNs) are immensely popular with some claiming over 200 million users. Users share private content such as personal information or photographs using OSN applications. Users must trust the OSN service to protect personal information even as the OSN provider benefits from examining and sharing that information. We present Persona an OSN where users dictate who may access their information. Persona hides user data with attribute-based encryption (ABE) allowing users to apply fine-grained policies over who may view their data. Persona provides an effective means of creating applications in which users not the OSN define policy over access to private data. We demonstrate new cryptographic mechanisms that enhance the general applicability of ABE. We show how Persona provides the functionality of existing online social networks with additional privacy benefits. We describe an implementation of Persona that replicates Facebook applications and show that Persona provides acceptable performance when browsing privacy-enhanced web pages even on mobile devices.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;With the ever-growing complexity and dynamicity of computer systems proactive fault management is an effective approach to enhancing availability. Online failure prediction is the key to such techniques. In contrast to classical reliability methods online failure prediction is based on runtime monitoring and a variety of models and methods that use the current state of a system and frequently the past experience as well. This survey describes these methods. To capture the wide spectrum of approaches concerning this area a taxonomy has been developed whose different approaches are explained and major concepts are described in detail.;
Online Tracking: A 1-million-site Measurement and Analysis;"We present the largest and most detailed measurement of online tracking conducted to date based on a crawl of the top 1 million websites. We make 15 types of measurements on each site including stateful (cookie-based) and stateless (fingerprinting-based) tracking the effect of browser privacy tools and the exchange of tracking data between different sites (cookie syncing""). Our findings include multiple sophisticated fingerprinting techniques never before measured in the wild. This measurement is made possible by our open-source web privacy measurement tool OpenWPM which uses an automated version of a full-fledged consumer browser. It supports parallelism for speed and scale automatic recovery from failures of the underlying browser and comprehensive browser instrumentation. We demonstrate our platform's strength in enabling researchers to rapidly detect quantify and characterize emerging online tracking behaviors.""";
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;Tasks in modern data parallel clusters have highly diverse resource requirements along CPU memory disk and network. Any of these resources may become bottlenecks and hence the likelihood of wasting resources due to fragmentation is now larger. Today's schedulers do not explicitly reduce fragmentation. Worse since they only allocate cores and memory the resources that they ignore (disk and network) can be over-allocated leading to interference failures and hogging of cores or memory that could have been used by other tasks. We present Tetris a cluster scheduler that packs i.e. matches multi-resource task requirements with resource availabilities of machines so as to increase cluster efficiency (makespan). Further Tetris uses an analog of shortest-running-time-first to trade-off cluster efficiency for speeding up individual jobs. Tetris' packing heuristics seamlessly work alongside a large class of fairness policies. Trace-driven simulations and deployment of our prototype on a 250 node cluster shows median gains of 30% in job completion time while achieving nearly perfect fairness.;
Proceedings of the 2014 ACM Conference on SIGCOMM;The introduction of a social networking site inside of a large enterprise enables a new method of communication between colleagues encouraging both personal and professional sharing inside the protected walls of a company intranet. Our analysis of user behavior and interviews presents the case that professionals use internal social networking to build stronger bonds with their weak ties and to reach out to employees they do not know. Their motivations in doing this include connecting on a personal level with coworkers advancing their career with the company and campaigning for their projects.;
Proceedings of the 2008 ACM Conference on Computer Supported Cooperative Work;Sentiment classification aims to automatically predict sentiment polarity (e.g. positive or negative) of users publishing sentiment data (e.g. reviews blogs). Although traditional classification algorithms can be used to train sentiment classifiers from manually labeled text data the labeling work can be time-consuming and expensive. Meanwhile users often use some different words when they express sentiment in different domains. If we directly apply a classifier trained in one domain to other domains the performance will be very low due to the differences between these domains. In this work we develop a general solution to sentiment classification when we do not have any labels in a target domain but have some labeled data in a different domain regarded as source domain. In this cross-domain sentiment classification setting to bridge the gap between the domains we propose a spectral feature alignment (SFA) algorithm to align domain-specific words from different domains into unified clusters with the help of domain-independent words as a bridge. In this way the clusters can be used to reduce the gap between domain-specific words of the two domains which can be used to train sentiment classifiers in the target domain accurately. Compared to previous approaches SFA can discover a robust representation for cross-domain data by fully exploiting the relationship between the domain-specific and domain-independent words via simultaneously co-clustering them in a common latent space. We perform extensive experiments on two real world datasets and demonstrate that SFA significantly outperforms previous approaches to cross-domain sentiment classification.;
Proceedings of the 19th International Conference on World Wide Web;Past research on shape displays has primarily focused on rendering content and user interface elements through shape output with less emphasis on dynamically changing UIs. We propose utilizing shape displays in three different ways to mediate interaction: to facilitate by providing dynamic physical affordances through shape change to restrict by guiding users with dynamic physical constraints and to manipulate by actuating physical objects. We outline potential interaction techniques and introduce Dynamic Physical Affordances and Constraints with our inFORM system built on top of a state-of-the-art shape display which provides for variable stiffness rendering and real-time user input through direct touch and tangible interaction. A set of motivating examples demonstrates how dynamic affordances constraints and object actuation can create novel interaction possibilities.;
Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology;Innovations like domain-specific hardware enhanced security open instruction sets and agile chip development will lead the way.;
The state of the art in end-user software engineering;Most programs today are written not by professional software developers but by people with expertise in other domains working towards goals for which they need computational support. For example a teacher might write a grading spreadsheet to save time grading or an interaction designer might use an interface builder to test some user interface design ideas. Although these end-user programmers may not have the same goals as professional developers they do face many of the same software engineering challenges including understanding their requirements as well as making decisions about design reuse integration testing and debugging. This article summarizes and classifies research on these activities defining the area of End-User Software Engineering (EUSE) and related terminology. The article then discusses empirical research about end-user software engineering activities and the technologies designed to support them. The article also addresses several crosscutting issues in the design of EUSE tools including the roles of risk reward and domain complexity and self-efficacy in the design of EUSE tools and the potential of educating users about software engineering principles.;
Predicting defects using network analysis on dependency graphs;In software development resources for quality assurance are limited by time and by cost. In order to allocate resources effectively managers need to rely on their experience backed by code complexity metrics. But often dependencies exist between various pieces of code over which managers may have little knowledge. These dependencies can be construed as a low level graph of the entire system. In this paper we propose to use network analysis on these dependency graphs. This allows managers to identify central program units that are more likely to face defects. In our evaluation on Windows Server 2003 we found that the recall for models built from network measures is by 10% points higher than for models built from complexity metrics. In addition network measures could identify 60% of the binaries that the Windows developers considered as critical-twice as many as identified by complexity metrics.;
Proceedings of the 30th International Conference on Software Engineering;The Simon and Speck families of block ciphers were designed specifically to offer security on constrained devices where simplicity of design is crucial. However the intended use cases are diverse and demand flexibility in implementation. Simplicity security and flexibility are ever-present yet conflicting goals in cryptographic design. This paper outlines how these goals were balanced in the design of Simon and Speck.;
Proceedings of the 52nd Annual Design Automation Conference;The NVIDIAÂ® OptiXâ„¢ ray tracing engine is a programmable system designed for NVIDIA GPUs and other highly parallel architectures. The OptiX engine builds on the key observation that most ray tracing algorithms can be implemented using a small set of programmable operations. Consequently the core of OptiX is a domain-specific just-in-time compiler that generates custom ray tracing kernels by combining user-supplied programs for ray generation material shading object intersection and scene traversal. This enables the implementation of a highly diverse set of ray tracing-based algorithms and applications including interactive rendering offline rendering collision detection systems artificial intelligence queries and scientific simulations such as sound propagation. OptiX achieves high performance through a compact object model and application of several ray tracing-specific compiler optimizations. For ease of use it exposes a single-ray programming model with full support for recursion and a dynamic dispatch mechanism similar to virtual function calls.;
Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?;The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice however it is crucial that their design be informed by an understanding of real-world needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners we conduct the first systematic investigation of commercial product teams' challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings we highlight directions for future ML and HCI research that will better address practitioners' needs.;
Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;As semiconductor manufacturing requires greater capital investments the use of contract foundries has grown dramatically increasing exposure to mask theft and unauthorized excess production. While only recently studied IC piracy has now become a major challenge for the electronics and defense industries [6].We propose a novel comprehensive technique to end piracy of integrated circuits (EPIC). It requires that every chip be activated with an external key which can only be generated by the holder of IP rights and cannot be duplicated. EPIC is based on (i) automatically-generated chip IDs (ii) a novel combinational locking algorithm and (iii) innovative use of public-key cryptography. Our evaluation suggests that the overhead of EPIC on circuit delay and power is negligible and the standard flows for verification and test do not require change. In fact major required components have already been integrated into several chips in production. We also use formal methods to evaluate combinational locking and computational attacks. A comprehensive protocol analysis concludes that EPIC is surprisingly resistant to various piracy attempts.;
Proceedings of the Conference on Design Automation and Test in Europe;Elastic resource scaling lets cloud systems meet application service level objectives (SLOs) with minimum resource provisioning costs. In this paper we present CloudScale a system that automates fine-grained elastic resource scaling for multi-tenant cloud computing infrastructures. CloudScale employs online resource demand prediction and prediction error handling to achieve adaptive resource allocation without assuming any prior knowledge about the applications running inside the cloud. CloudScale can resolve scaling conflicts between applications using migration and integrates dynamic CPU voltage/frequency scaling to achieve energy savings with minimal effect on application SLOs. We have implemented CloudScale on top of Xen and conducted extensive experiments using a set of CPU and memory intensive applications (RUBiS Hadoop IBM System S). The results show that CloudScale can achieve significantly higher SLO conformance than other alternatives with low resource and energy cost. CloudScale is non-intrusive and light-weight and imposes negligible overhead (&lt 2% CPU in Domain 0) to the virtualized computing cluster.;
Proceedings of the 2nd ACM Symposium on Cloud Computing;Debugging is notoriously difficult and extremely time consuming. Researchers have therefore invested a considerable amount of effort in developing automated techniques and tools for supporting various debugging tasks. Although potentially useful most of these techniques have yet to demonstrate their practical effectiveness. One common limitation of existing approaches for instance is their reliance on a set of strong assumptions on how developers behave when debugging (e.g. the fact that examining a faulty statement in isolation is enough for a developer to understand and fix the corresponding bug). In more general terms most existing techniques just focus on selecting subsets of potentially faulty statements and ranking them according to some criterion. By doing so they ignore the fact that understanding the root cause of a failure typically involves complex activities such as navigating program dependencies and rerunning the program with different inputs. The overall goal of this research is to investigate how developers use and benefit from automated debugging tools through a set of human studies. As a first step in this direction we perform a preliminary study on a set of developers by providing them with an automated debugging tool and two tasks to be performed with and without the tool. Our results provide initial evidence that several assumptions made by automated debugging techniques do not hold in practice. Through an analysis of the results we also provide insights on potential directions for future work in the area of automated debugging.;
Proceedings of the 2011 International Symposium on Software Testing and Analysis;Supporting continuous sensing applications on mobile phones is challenging because of the resource demands of long-term sensing inference and communication algorithms. We present the design implementation and evaluation of the Jigsaw continuous sensing engine which balances the performance needs of the application and the resource demands of continuous sensing on the phone. Jigsaw comprises a set of sensing pipelines for the accelerometer microphone and GPS sensors which are built in a plug and play manner to support: i) resilient accelerometer data processing which allows inferences to be robust to different phone hardware orientation and body positions ii) smart admission control and on-demand processing for the microphone and accelerometer data which adaptively throttles the depth and sophistication of sensing pipelines when the input data is low quality or uninformative and iii) adaptive pipeline processing which judiciously triggers power hungry pipeline stages (e.g. sampling the GPS) taking into account the mobility and behavioral patterns of the user to drive down energy costs. We implement and evaluate Jigsaw on the Nokia N95 and the Apple iPhone two popular smartphone platforms to demonstrate its capability to recognize user activities and perform long term GPS tracking in an energy-efficient manner.;
Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems;"Due to their high volume general-purpose processors and now chip multiprocessors (CMPs) are much more cost effective than ASICs but lag significantly in terms of performance and energy efficiency. This paper explores the sources of these performance and energy overheads in general-purpose processing systems by quantifying the overheads of a 720p HD H.264 encoder running on a general-purpose CMP system. It then explores methods to eliminate these overheads by transforming the CPU into a specialized system for H.264 encoding. We evaluate the gains from customizations useful to broad classes of algorithms such as SIMD units as well as those specific to particular computation such as customized storage and functional units.The ASIC is 500x more energy efficient than our original four-processor CMP. Broadly applicable optimizations improve performance by 10x and energy by 7x. However the very low energy costs of actual core ops (100s fJ in 90nm) mean that over 90% of the energy used in these solutions is still overhead"". Achieving ASIC-like performance and efficiency requires algorithm-specific optimizations. For each sub-algorithm of H.264 we create a large specialized functional unit that is capable of executing 100s of operations per instruction. This improves performance and energy by an additional 25x and the final customized CMP matches an ASIC solution's performance within 3x of its energy and within comparable area.""";
Proceedings of the 37th Annual International Symposium on Computer Architecture;Virtualization is often used in cloud computing platforms for its several advantages in efficiently managing resources. However virtualization raises certain additional challenges and one of them is lack of power metering for virtual machines (VMs). Power management requirements in modern data centers have led to most new servers providing power usage measurement in hardware and alternate solutions exist for older servers using circuit and outlet level measurements. However VM power cannot be measured purely in hardware. We present a solution for VM power metering named Joulemeter. We build power models to infer power consumption from resource usage at runtime and identify the challenges that arise when applying such models for VM power metering. We show how existing instrumentation in server hardware and hypervisors can be used to build the required power models on real platforms with low error. Our approach is designed to operate with extremely low runtime overhead while providing practically useful accuracy. We illustrate the use of the proposed metering capability for VM power capping a technique to reduce power provisioning costs in data centers. Experiments are performed on server traces from several thousand production servers hosting Microsoft's real-world applications such as Windows Live Messenger. The results show that not only does VM power metering allows virtualized data centers to achieve the same savings that non-virtualized data centers achieved through physical server power capping but also that it enables further savings in provisioning costs with virtualization.;
Proceedings of the 1st ACM Symposium on Cloud Computing;"We present a study of anonymized data capturing a month of high-level communication activities within the whole of the Microsoft Messenger instant-messaging system. We examine characteristics and patterns that emerge from the collective dynamics of large numbers of people rather than the actions and characteristics of individuals. The dataset contains summary properties of 30 billion conversations among 240 million people. From the data we construct a communication graph with 180 million nodes and 1.3 billion undirected edges creating the largest social network constructed and analyzed to date. We report on multiple aspects of the dataset and synthesized graph. We find that the graph is well-connected and robust to node removal. We investigate on a planetary-scale the oft-cited report that people are separated by six degrees of separation"" and find that the average path length among Messenger users is 6.6. We find that people tend to communicate more with each other when they have similar age language and location and that cross-gender conversations are both more frequent and of longer duration than conversations with the same gender.""";
Proceedings of the 17th International Conference on World Wide Web;An open source project typically maintains an open bug repository so that bug reports from all over the world can be gathered. When a new bug report is submitted to the repository a person called a triager examines whether it is a duplicate of an existing bug report. If it is the triager marks it as DUPLICATE and the bug report is removed from consideration for further work. In the literature there are approaches exploiting only natural language information to detect duplicate bug reports. In this paper we present a new approach that further involves execution information. In our approach when a new bug report arrives its natural language information and execution information are compared with those of the existing bug reports. Then a small number of existing bug reports are suggested to the triager as the most similar bug reports to the new bug report. Finally the triager examines the suggested bug reports to determine whether the new bug report duplicates an existing bug report. We calibrated our approach on a subset of the Eclipse bug repository and evaluated our approach on a subset of the Firefox bug repository. The experimental results show that our approach can detect 67%-93% of duplicate bug reports in the Firefox bug repository compared to 43%-72% using natural language information alone.;
Proceedings of the 30th International Conference on Software Engineering;The advent of distributed version control systems has led to the development of a new paradigm for distributed software development instead of pushing changes to a central repository developers pull them from other repositories and merge them locally. Various code hosting sites notably Github have tapped on the opportunity to facilitate pull-based development by offering workflow support tools such as code reviewing systems and integrated issue trackers. In this work we explore how pull-based software development works first on the GHTorrent corpus and then on a carefully selected sample of 291 projects. We find that the pull request model offers fast turnaround increased opportunities for community engagement and decreased time to incorporate contributions. We show that a relatively small number of factors affect both the decision to merge a pull request and the time to process it. We also examine the reasons for pull request rejection and find that technical ones are only a small minority.;
Proceedings of the 36th International Conference on Software Engineering;Energy-efficient computing is important in several systems ranging from embedded devices to large scale data centers. Several application domains offer the opportunity to tradeoff quality of service/solution (QoS) for improvements in performance and reduction in energy consumption. Programmers sometimes take advantage of such opportunities albeit in an ad-hoc manner and often without providing any QoS guarantees.We propose a system called Green that provides a simple and flexible framework that allows programmers to take advantage of such approximation opportunities in a systematic manner while providing statistical QoS guarantees. Green enables programmers to approximate expensive functions and loops and operates in two phases. In the calibration phase it builds a model of the QoS loss produced by the approximation. This model is used in the operational phase to make approximation decisions based on the QoS constraints specified by the programmer. The operational phase also includes an adaptation function that occasionally monitors the runtime behavior and changes the approximation decisions and QoS model to provide strong statistical QoS guarantees.To evaluate the effectiveness of Green we implemented our system and language extensions using the Phoenix compiler framework. Our experiments using benchmarks from domains such as graphics machine learning signal processing and finance and an in-production real-world web search engine indicate that Green can produce significant improvements in performance and energy consumption with small and controlled QoS degradation.;
Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation;Hekaton is a new database engine optimized for memory resident data and OLTP workloads. Hekaton is fully integrated into SQL Server it is not a separate system. To take advantage of Hekaton a user simply declares a table memory optimized. Hekaton tables are fully transactional and durable and accessed using T-SQL in the same way as regular SQL Server tables. A query can reference both Hekaton tables and regular tables and a transaction can update data in both types of tables. T-SQL stored procedures that reference only Hekaton tables can be compiled into machine code for further performance improvements. The engine is designed for high con-currency. To achieve this it uses only latch-free data structures and a new optimistic multiversion concurrency control technique. This paper gives an overview of the design of the Hekaton engine and reports some experimental results.;
Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data;A prominent parallel data processing tool MapReduce is gaining significant momentum from both industry and academia as the volume of data to analyze grows rapidly. While MapReduce is used in many areas where massive data analysis is required there are still debates on its performance efficiency per node and simple abstraction. This survey intends to assist the database and open source communities in understanding various technical aspects of the MapReduce framework. In this survey we characterize the MapReduce framework and discuss its inherent pros and cons. We then introduce its optimization strategies reported in the recent literature. We also discuss the open issues and challenges raised on parallel data analysis with MapReduce.;
What makes a good bug report?;In software development bug reports provide crucial information to developers. However these reports widely differ in their quality. We conducted a survey among developers and users of APACHE ECLIPSE and MOZILLA to find out what makes a good bug report.The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce stack traces and test cases as helpful which are at the same time most difficult to provide for users. Such insight is helpful to design new bug tracking tools that guide users at collecting and providing more helpful information.Our CUEZILLA prototype is such a tool and measures the quality of new bug reports it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports rated by developers as part of the survey. In our experiments CUEZILLA was able to predict the quality of 31--48% of bug reports accurately.;
Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering;In the same way businesses use big data to pursue profits governments use it to promote the public good.;
Taming the torrent: a practical approach to reducing cross-isp traffic in peer-to-peer systems;Peer-to-peer (P2P) systems which provide a variety of popular services such as file sharing video streaming and voice-over-IP contribute a significant portion of today's Internet traffic. By building overlay networks that are oblivious to the underlying Internet topology and routing these systems have become one of the greatest traffic-engineering challenges for Internet Service Providers (ISPs) and the source of costly data traffic flows. In an attempt to reduce these operational costs ISPs have tried to shape block or otherwise limit P2P traffic much to the chagrin of their subscribers who consistently finds ways to eschew these controls or simply switch providers.In this paper we present the design deployment and evaluation of an approach to reducing this costly cross-ISP traffic without sacrificing system performance. Our approach recycles network views gathered at low cost from content distribution networks to drive biased neighbor selection without any path monitoring or probing. Using results collected from a deployment in BitTorrent with over 120000 users in nearly 3000 networks we show that our lightweight approach significantly reduces cross-ISP traffic and over 33% of the time it selects peers along paths that are within a single autonomous system (AS). Further we find that our system locates peers along paths that have two orders of magnitude lower latency and 30% lower loss rates than those picked at random and that these high-quality paths can lead to significant improvements in transfer rates. In challenged settings where peers are overloaded in terms of available bandwidth our approach provides 31% average download-rate improvement in environments with large available bandwidth it increases download rates by 207% on average (and improves median rates by 883%;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;Details in mesh animations are difficult to generate but they have great impact on visual quality. In this work we demonstrate a practical software system for capturing such details from multi-view video recordings. Given a stream of synchronized video images that record a human performance from multiple viewpoints and an articulated template of the performer our system captures the motion of both the skeleton and the shape. The output mesh animation is enhanced with the details observed in the image silhouettes. For example a performance in casual loose-fitting clothes will generate mesh animations with flowing garment motions. We accomplish this with a fast pose tracking method followed by nonrigid deformation of the template to fit the silhouettes. The entire process takes less than sixteen seconds per frame and requires no markers or texture cues. Captured meshes are in full correspondence making them readily usable for editing operations including texturing deformation transfer and deformation model learning.;
Systematic literature studies: database searches vs. backward snowballing;"Systematic studies of the literature can be done in different ways. In particular different guidelines propose different first steps in their recommendations e.g. start with search strings in different databases or start with the reference lists of a starting set of papers.In software engineering the main recommended first step is using search strings in a number of databases while in information systems snowballing has been recommended as the first step. This paper compares the two different search approaches for conducting literature review studies.The comparison is conducted by searching for articles addressing Agile practices in global software engineering"". The focus of the paper is on evaluating the two different search approaches.Despite the differences in the included papers the conclusions and the patterns found in both studies are quite similar. The strengths and weaknesses of each first step are discussed separately and in comparison with each other.It is concluded that none of the first steps is outperforming the other and the choice of guideline to follow and hence the first step may be context-specific i.e. depending on the area of study.""";
Proceedings of the ACM-IEEE International Symposium on Empirical Software Engineering and Measurement;A good test suite is one that detects real faults. Because the set of faults in a program is usually unknowable this definition is not useful to practitioners who are creating test suites nor to researchers who are creating and evaluating tools that generate test suites. In place of real faults testing research often uses mutants which are artificial faults -- each one a simple syntactic variation -- that are systematically seeded throughout the program under test. Mutation analysis is appealing because large numbers of mutants can be automatically-generated and used to compensate for low quantities or the absence of known real faults. Unfortunately there is little experimental evidence to support the use of mutants as a replacement for real faults. This paper investigates whether mutants are indeed a valid substitute for real faults i.e. whether a test suiteâ€™s ability to detect mutants is correlated with its ability to detect real faults that developers have fixed. Unlike prior studies these investigations also explicitly consider the conflating effects of code coverage on the mutant detection rate. Our experiments used 357 real faults in 5 open-source applications that comprise a total of 321000 lines of code. Furthermore our experiments used both developer-written and automatically-generated test suites. The results show a statistically significant correlation between mutant detection and real fault detection independently of code coverage. The results also give concrete suggestions on how to improve mutation analysis and reveal some inherent limitations.;
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering;Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment and once deployed emergent issues can become difficult or impossible to trace back to their source.In this paper we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end to be applied throughout the internal organization development life-cycle. Each stage of the audit yields a set of documents that together form an overall audit report drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing framework is intended to contribute to closing the accountability gap in the development and deployment of large-scale artificial intelligence systems by embedding a robust process to ensure audit integrity.;
Proceedings of the 2020 Conference on Fairness Accountability and Transparency;Storm has long served as the main platform for real-time analytics at Twitter. However as the scale of data being processed in real-time at Twitter has increased along with an increase in the diversity and the number of use cases many limitations of Storm have become apparent. We need a system that scales better has better debug-ability has better performance and is easier to manage -- all while working in a shared cluster infrastructure. We considered various alternatives to meet these needs and in the end concluded that we needed to build a new real-time stream data processing system. This paper presents the design and implementation of this new system called Heron. Heron is now the de facto stream data processing engine inside Twitter and in this paper we also share our experiences from running Heron in production. In this paper we also provide empirical evidence demonstrating the efficiency and scalability of Heron.;
Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data;"Recent years have witnessed incredible popularity and adoption of smartphones and mobile devices which is accompanied by large amount and wide variety of feature-rich smartphone applications. These smartphone applications (or apps) typically organized in different application marketplaces can be conveniently browsed by mobile users and then simply clicked to install on a variety of mobile devices. In practice besides the official marketplaces from platform vendors (e.g. Google and Apple) a number of third-party alternative marketplaces have also been created to host thousands of apps (e.g. to meet regional or localization needs). To maintain and foster a hygienic smartphone app ecosystem there is a need for each third-party marketplace to offer quality apps to mobile users.In this paper we perform a systematic study on six popular Android-based third-party marketplaces. Among them we find a common in-the-wild"" practice of repackaging legitimate apps (from the official Android Market) and distributing repackaged ones via third-party marketplaces. To better understand the extent of such practice we implement an app similarity measurement system called DroidMOSS that applies a fuzzy hashing technique to effectively localize and detect the changes from app-repackaging behavior. The experiments with DroidMOSS show a worrisome fact that 5% to 13% of apps hosted on these studied marketplaces are repackaged. Further manual investigation indicates that these repackaged apps are mainly used to replace existing in-app advertisements or embed new ones to ""steal"" or re-route ad revenues. We also identify a few cases with planted backdoors or malicious payloads among repackaged apps. The results call for the need of a rigorous vetting process for better regulation of third-party smartphone application marketplaces.""";
Proceedings of the Second ACM Conference on Data and Application Security and Privacy;Prior work in RF-based positioning has mainly focused on discovering the absolute location of an RF source where state-of-the-art systems can achieve an accuracy on the order of tens of centimeters using a large number of antennas. However many applications in gaming and gesture based interface see more benefits in knowing the detailed shape of a motion. Such trajectory tracing requires a resolution several fold higher than what existing RF-based positioning systems can offer.This paper shows that one can provide a dramatic increase in trajectory tracing accuracy even with a small number of antennas. The key enabler for our design is a multi-resolution positioning technique that exploits an intrinsic tradeoff between improving the resolution and resolving ambiguity in the location of the RF source. The unique property of this design is its ability to precisely reconstruct the minute details in the trajectory shape even when the absolute position might have an offset. We built a prototype of our design with commercial off-the-shelf RFID readers and tags and used it to enable a virtual touch screen which allows a user to interact with a desired computing device by gesturing or writing her commands in the air where each letter is only a few centimeters wide.;
Proceedings of the 2014 ACM Conference on SIGCOMM;Growing transistor counts limited power budgets and the breakdown of voltage scaling are currently conspiring to create a utilization wall that limits the fraction of a chip that can run at full speed at one time. In this regime specialized energy-efficient processors can increase parallelism by reducing the per-computation power requirements and allowing more computations to execute under the same power budget. To pursue this goal this paper introduces conservation cores. Conservation cores or c-cores are specialized processors that focus on reducing energy and energy-delay instead of increasing performance. This focus on energy makes c-cores an excellent match for many applications that would be poor candidates for hardware acceleration (e.g. irregular integer codes). We present a toolchain for automatically synthesizing c-cores from application source code and demonstrate that they can significantly reduce energy and energy-delay for a wide range of applications. The c-cores support patching a form of targeted reconfigurability that allows them to adapt to new versions of the software they target. Our results show that conservation cores can reduce energy consumption by up to 16.0x for functions and by up to 2.1x for whole applications while patching can extend the useful lifetime of individual c-cores to match that of conventional processors.;
Proceedings of the Fifteenth International Conference on Architectural Support for Programming Languages and Operating Systems;People often turn to their friends families and colleagues when they have questions. The recent rapid rise of online social networking tools has made doing this on a large scale easy and efficient. In this paper we explore the phenomenon of using social network status messages to ask questions. We conducted a survey of 624 people asking them to share the questions they have asked and answered of their online social networks. We present detailed data on the frequency of this type of question asking the types of questions asked and respondents' motivations for asking their social networks rather than using more traditional search tools like Web search engines. We report on the perceived speed and quality of the answers received as well as what motivates people to respond to questions seen in their friends' status messages. We then discuss the implications of our findings for the design of next-generation search tools.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;This article presents an improved approach to assist diagnosis of failures in software (fault localisation) by ranking program statements or blocks in accordance with to how likely they are to be buggy. We present a very simple single-bug program to model the problem. By examining different possible execution paths through this model program over a number of test cases the effectiveness of different proposed spectral ranking methods can be evaluated in idealised conditions. The results are remarkably consistent to those arrived at empirically using the Siemens test suite and Space benchmarks. The model also helps identify groups of metrics that are equivalent for ranking. Due to the simplicity of the model an optimal ranking method can be devised. This new method out-performs previously proposed methods for the model program the Siemens test suite and Space. It also helps provide insight into other ranking methods.;
Compiler validation via equivalence modulo inputs;We introduce equivalence modulo inputs (EMI) a simple widely applicable methodology for validating optimizing compilers. Our key insight is to exploit the close interplay between (1) dynamically executing a program on some test inputs and (2) statically compiling the program to work on all possible inputs. Indeed the test inputs induce a natural collection of the original program's EMI variants which can help differentially test any compiler and specifically target the difficult-to-find miscompilations.To create a practical implementation of EMI for validating C compilers we profile a program's test executions and stochastically prune its unexecuted code. Our extensive testing in eleven months has led to 147 confirmed unique bug reports for GCC and LLVM alone. The majority of those bugs are miscompilations and more than 100 have already been fixed.Beyond testing compilers EMI can be adapted to validate program transformation and analysis systems in general. This work opens up this exciting new direction.;
Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation;Power delay profiles characterize multipath channel features which are widely used in motion- or localization-based applications. Recent studies show that the power delay profile may be derived from the CSI traces collected from commodity WiFi devices but the performance is limited by two dominating factors. The resolution of the derived power delay profile is determined by the channel bandwidth which is however limited on commodity WiFi. The collected CSI reflects the signal distortions due to both the channel attenuation and the hardware imperfection. A direct derivation of power delay profiles using raw CSI measures as has been done in the literature results in significant inaccuracy. In this paper we present Splicer a software-based system that derives high-resolution power delay profiles by splicing the CSI measurements from multiple WiFi frequency bands. We propose a set of key techniques to separate the mixed hardware errors from the collected CSI measurements. Splicer adapts its computations within stringent channel coherence time and thus can perform well in presence of mobility. Our experiments with commodity WiFi NICs show that Splicer substantially improves the accuracy in profiling multipath characteristics reducing the errors of multipath distance estimation to be less than $2m$. Splicer can immediately benefit upper-layer applications. Our case study with recent single-AP localization achieves a median localization error of $0.95m$.;
Proceedings of the 21st Annual International Conference on Mobile Computing and Networking;With the ubiquity of mobile devices spatial crowdsourcing is emerging as a new platform enabling spatial tasks (i.e. tasks related to a location) assigned to and performed by human workers. In this paper for the first time we introduce a taxonomy for spatial crowdsourcing. Subsequently we focus on one class of this taxonomy in which workers send their locations to a centralized server and thereafter the server assigns to every worker his nearby tasks with the objective of maximizing the overall number of assigned tasks. We formally define this maximum task assignment (or MTA) problem in spatial crowdsourcing and identify its challenges. We propose alternative solutions to address these challenges by exploiting the spatial properties of the problem space. Finally our experimental evaluations on both real-world and synthetic data verify the applicability of our proposed approaches and compare them by measuring both the number of assigned tasks and the travel cost of the workers.;
Proceedings of the 20th International Conference on Advances in Geographic Information Systems;Camera sensors can only capture a limited range of luminance simultaneously and in order to create high dynamic range (HDR) images a set of different exposures are typically combined. In this paper we address the problem of predicting information that have been lost in saturated image areas in order to enable HDR reconstruction from a single exposure. We show that this problem is well-suited for deep learning algorithms and propose a deep convolutional neural network (CNN) that is specifically designed taking into account the challenges in predicting HDR values. To train the CNN we gather a large dataset of HDR images which we augment by simulating sensor saturation for a range of cameras. To further boost robustness we pre-train the CNN on a simulated HDR dataset created from a subset of the MIT Places database. We demonstrate that our approach can reconstruct high-resolution visually convincing HDR results in a wide range of situations and that it generalizes well to reconstruction of images captured with arbitrary and low-end cameras that use unknown camera response functions and post-processing. Furthermore we compare to existing methods for HDR expansion and show high quality results also for image based lighting. Finally we evaluate the results in a subjective experiment performed on an HDR display. This shows that the reconstructed HDR images are visually convincing with large improvements as compared to existing methods.;
Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries;We present a novel approach to automatic synthesis of loop-free programs. The approach is based on a combination of oracle-guided learning from examples and constraint-based synthesis from components using satisfiability modulo theories (SMT) solvers. Our approach is suitable for many applications including as an aid to program understanding tasks such as deobfuscating malware. We demonstrate the efficiency and effectiveness of our approach by synthesizing bit-manipulating programs and by deobfuscating programs.;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1;In this paper we propose PDRAM a novel energy efficient main memory architecture based on phase change random access memory (PRAM) and DRAM. The paper explores the challenges involved in incorporating PRAM into the main memory hierarchy of computing systems and proposes a low overhead hybrid hardware-software solution for managing it. Our experimental results indicate that our solution is able to achieve average energy savings of 30% at negligible overhead over conventional memory architectures.;
Proceedings of the 46th Annual Design Automation Conference;"We provide a novel algorithm to approximately factor large matrices with millions of rows millions of columns and billions of nonzero elements. Our approach rests on stochastic gradient descent (SGD) an iterative stochastic optimization algorithm. We first develop a novel stratified"" SGD variant (SSGD) that applies to general loss-minimization problems in which the loss function can be expressed as a weighted sum of ""stratum losses."" We establish sufficient conditions for convergence of SSGD using results from stochastic approximation theory and regenerative process theory. We then specialize SSGD to obtain a new matrix-factorization algorithm called DSGD that can be fully distributed and run on web-scale datasets using e.g. MapReduce. DSGD can handle a wide variety of matrix factorizations. We describe the practical techniques used to optimize performance in our DSGD implementation. Experiments suggest that DSGD converges significantly faster and has better scalability properties than alternative algorithms.""";
Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Data races are a particularly unpleasant kind of threading bugs. They are hard to find and reproduce -- you may not observe a bug during the entire testing cycle and will only see it in production as rare unexplainable failures. This paper presents ThreadSanitizer -- a dynamic detector of data races. We describe the hybrid algorithm (based on happens-before and locksets) used in the detector. We introduce what we call dynamic annotations -- a sort of race detection API that allows a user to inform the detector about any tricky synchronization in the user program. Various practical aspects of using ThreadSanitizer for testing multithreaded C++ code at Google are also discussed.;
Proceedings of the Workshop on Binary Instrumentation and Applications;Convolutional Neural Networks (CNNs) have gained popularity in many computer vision applications such as image classification face detection and video analysis because of their ability to train and classify with high accuracy. Due to multiple convolution and fully-connected layers that are compute-/memory-intensive it is difficult to perform real-time classification with low power consumption on today?s computing systems. FPGAs have been widely explored as hardware accelerators for CNNs because of their reconfigurability and energy efficiency as well as fast turn-around-time especially with high-level synthesis methodologies. Previous FPGA-based CNN accelerators however typically implemented generic accelerators agnostic to the CNN configuration where the reconfigurable capabilities of FPGAs are not fully leveraged to maximize the overall system throughput. In this work we present a systematic design space exploration methodology to maximize the throughput of an OpenCL-based FPGA accelerator for a given CNN model considering the FPGA resource constraints such as on-chip memory registers computational resources and external memory bandwidth. The proposed methodology is demonstrated by optimizing two representative large-scale CNNs AlexNet and VGG on two Altera Stratix-V FPGA platforms DE5-Net and P395-D8 boards which have different hardware resources. We achieve a peak performance of 136.5 GOPS for convolution operation and 117.8 GOPS for the entire VGG network that performs ImageNet classification on P395-D8 board.;
Proceedings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays;This paper presents a new cluster architecture for low-power data-intensive computing. FAWN couples low-power embedded CPUs to small amounts of local flash storage and balances computation and I/O capabilities to enable efficient massively parallel access to data.The key contributions of this paper are the principles of the FAWN architecture and the design and implementation of FAWN-KV--a consistent replicated highly available and high-performance key-value storage system built on a FAWN prototype. Our design centers around purely log-structured datastores that provide the basis for high performance on flash storage as well as for replication and consistency obtained using chain replication on a consistent hashing ring. Our evaluation demonstrates that FAWN clusters can handle roughly 350 key-value queries per Joule of energy--two orders of magnitude more than a disk-based system.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;An important piece of the cellular network infrastructure is the radio access network (RAN) that provides wide-area wireless connectivity to mobile devices. The fundamental problem the RAN solves is figuring out how best to use and manage limited spectrum to achieve this connectivity. In a dense wireless deployment with mobile nodes and limited spectrum it becomes a difficult task to allocate radio resources implement handovers manage interference balance load between cells etc.We argue that LTE's current distributed control plane is suboptimal in achieving the above objective. We propose SoftRAN a fundamental rethink of the radio access layer. SoftRAN is a software defined centralized control plane for radio access networks that abstracts all base stations in a local geographical area as a virtual big-base station comprised of a central controller and radio elements (individual physical base stations). In defining such an architecture we create a framework through which a local geographical network can effectively perform load balancing and interference management as well as maximize throughput global utility or any other objective.;
Proceedings of the Second ACM SIGCOMM Workshop on Hot Topics in Software Defined Networking;When network is undergoing problems such as congestion scan attack DDoS attack etc. measurements are much more important than usual. In this case traffic characteristics including available bandwidth packet rate and flow size distribution vary drastically significantly degrading the performance of measurements. To address this issue we propose the Elastic sketch. It is adaptive to currently traffic characteristics. Besides it is generic to measurement tasks and platforms. We implement the Elastic sketch on six platforms: P4 FPGA GPU CPU multi-core CPU and OVS to process six typical measurement tasks. Experimental results and theoretical analysis show that the Elastic sketch can adapt well to traffic characteristics. Compared to the state-of-the-art the Elastic sketch achieves 44.6 âˆ¼ 45.2 times faster speed and 2.0 âˆ¼ 273.7 smaller error rate.;
Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication;We present a discrete treatment of adapted framed curves parallel transport and holonomy thus establishing the language for a discrete geometric model of thin flexible rods with arbitrary cross section and undeformed configuration. Our approach differs from existing simulation techniques in the graphics and mechanics literature both in the kinematic description---we represent the material frame by its angular deviation from the natural Bishop frame---as well as in the dynamical treatment---we treat the centerline as dynamic and the material frame as quasistatic. Additionally we describe a manifold projection method for coupling rods to rigid-bodies and simultaneously enforcing rod inextensibility. The use of quasistatics and constraints provides an efficient treatment for stiff twisting and stretching modes at the same time we retain the dynamic bending of the centerline and accurately reproduce the coupling between bending and twisting modes. We validate the discrete rod model via quantitative buckling stability and coupled-mode experiments and via qualitative knot-tying comparisons.;
On the effectiveness of secret key extraction from wireless signal strength in real environments;We evaluate the effectiveness of secret key extraction for private communication between two wireless devices from the received signal strength (RSS) variations on the wireless channel between the two devices. We use real world measurements of RSS in a variety of environments and settings. Our experimental results show that (i) in certain environments due to lack of variations in the wireless channel the extracted bits have very low entropy making these bits unsuitable for a secret key (ii) an adversary can cause predictable key generation in these static environments and (iii) in dynamic scenarios where the two devices are mobile and/or where there is a significant movement in the environment high entropy bits are obtained fairly quickly. Building on the strengths of existing secret key extraction approaches we develop an environment adaptive secret key generation scheme that uses an adaptive lossy quantizer in conjunction with Cascade-based information reconciliation [7] and privacy amplification [14]. Our measurements show that our scheme in comparison to the existing ones that we evaluate performs the best in terms of generating high entropy bits at a high bit rate. The secret key bit streams generated by our scheme also pass the randomness tests of the NIST test suite [21] that we conduct.;
Proceedings of the 15th Annual International Conference on Mobile Computing and Networking;Our daily digital life is full of algorithmically selected content such as social media feeds recommendations and personalized search results. These algorithms have great power to shape users' experiences yet users are often unaware of their presence. Whether it is useful to give users insight into these algorithms' existence or functionality and how such insight might affect their experience are open questions. To address them we conducted a user study with 40 Facebook users to examine their perceptions of the Facebook News Feed curation algorithm. Surprisingly more than half of the participants (62.5%) were not aware of the News Feed curation algorithm's existence at all. Initial reactions for these previously unaware participants were surprise and anger. We developed a system FeedVis to reveal the difference between the algorithmically curated and an unadulterated News Feed to users and used it to study how users perceive this difference. Participants were most upset when close friends and family were not shown in their feeds. We also found participants often attributed missing stories to their friends' decisions to exclude them rather than to Facebook News Feed algorithm. By the end of the study however participants were mostly satisfied with the content on their feeds. Following up with participants two to six months after the study we found that for most satisfaction levels remained similar before and after becoming aware of the algorithm's presence however algorithmic awareness led to more active engagement with Facebook and bolstered overall feelings of control on the site.;
Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems;Configuration changes are a common source of instability in networks leading to outages performance disruptions and security vulnerabilities. Even when the initial and final configurations are correct the update process itself often steps through intermediate configurations that exhibit incorrect behaviors. This paper introduces the notion of consistent network updates---updates that are guaranteed to preserve well-defined behaviors when transitioning mbetween configurations. We identify two distinct consistency levels per-packet and per-flow and we present general mechanisms for implementing them in Software-Defined Networks using switch APIs like OpenFlow. We develop a formal model of OpenFlow networks and prove that consistent updates preserve a large class of properties. We describe our prototype implementation including several optimizations that reduce the overhead required to perform consistent updates. We present a verification tool that leverages consistent updates to significantly reduce the complexity of checking the correctness of network control software. Finally we describe the results of some simple experiments demonstrating the effectiveness of these optimizations on example applications.;
Proceedings of the ACM SIGCOMM 2012 Conference on Applications Technologies Architectures and Protocols for Computer Communication;We present BackFi a novel communication system that enables high throughput long range communication between very low power backscatter devices and WiFi APs using ambient WiFi transmissions as the excitation signal. Specifically we show that it is possible to design devices and WiFi APs such that the WiFi AP in the process of transmitting data to normal WiFi clients can decode backscatter signals which the devices generate by modulating information on to the ambient WiFi transmission. We show via prototypes and experiments that it is possible to achieve communication rates of up to 5 Mbps at a range of 1 m and 1 Mbps at a range of 5 meters. Such performance is an order to three orders of magnitude better than the best known prior WiFi backscatter system [2725]. BackFi design is energy efficient as it relies on backscattering alone and needs insignificant power hence the energy consumed per bit is small.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;Advanced analysis of data streams is quickly becoming a key area of data mining research as the number of applications demanding such processing increases. Online mining when such data streams evolve over time that is when concepts drift or change completely is becoming one of the core issues. When tackling non-stationary concepts ensembles of classifiers have several advantages over single classifier methods: they are easy to scale and parallelize they can adapt to change quickly by pruning under-performing parts of the ensemble and they therefore usually also generate more accurate concept descriptions. This paper proposes a new experimental data stream framework for studying concept drift and two new variants of Bagging: ADWIN Bagging and Adaptive-Size Hoeffding Tree (ASHT) Bagging. Using the new experimental framework an evaluation study on synthetic and real-world datasets comprising up to ten million examples shows that the new ensemble methods perform very well compared to several known methods.;
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;In this paper we introduce a new open source high-level synthesis tool called LegUp that allows software techniques to be used for hardware design. LegUp accepts a standard C program as input and automatically compiles the program to a hybrid architecture containing an FPGA-based MIPS soft processor and custom hardware accelerators that communicate through a standard bus interface. Results show that the tool produces hardware solutions of comparable quality to a commercial high-level synthesis tool.;
Proceedings of the 19th ACM/SIGDA International Symposium on Field Programmable Gate Arrays;The problem of cross-platform binary code similarity detection aims at detecting whether two binary functions coming from different platforms are similar or not. It has many security applications including plagiarism detection malware detection vulnerability search etc. Existing approaches rely on approximate graph-matching algorithms which are inevitably slow and sometimes inaccurate and hard to adapt to a new task. To address these issues in this work we propose a novel neural network-based approach to compute the embedding i.e. a numeric vector based on the control flow graph of each binary function then the similarity detection can be done efficiently by measuring the distance between the embeddings for two functions. We implement a prototype called Gemini. Our extensive evaluation shows that Gemini outperforms the state-of-the-art approaches by large margins with respect to similarity detection accuracy. Further Gemini can speed up prior art's embedding generation time by 3 to 4 orders of magnitude and reduce the required training time from more than 1 week down to 30 minutes to 10 hours. Our real world case studies demonstrate that Gemini can identify significantly more vulnerable firmware images than the state-of-the-art i.e. Genius. Our research showcases a successful application of deep learning on computer security problems.;
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security;Keystroke privacy is critical for ensuring the security of computer systems and the privacy of human users as what being typed could be passwords or privacy sensitive information. In this paper we show for the first time that WiFi signals can also be exploited to recognize keystrokes. The intuition is that while typing a certain key the hands and fingers of a user move in a unique formation and direction and thus generate a unique pattern in the time-series of Channel State Information (CSI) values which we call CSI-waveform for that key. In this paper we propose a WiFi signal based keystroke recognition system called WiKey. WiKey consists of two Commercial Off-The-Shelf (COTS) WiFi devices a sender (such as a router) and a receiver (such as a laptop). The sender continuously emits signals and the receiver continuously receives signals. When a human subject types on a keyboard WiKey recognizes the typed keys based on how the CSI values at the WiFi signal receiver end. We implemented the WiKey system using a TP-Link TL-WR1043ND WiFi router and a Lenovo X200 laptop. WiKey achieves more than 97.5% detection rate for detecting the keystroke and 96.4% recognition accuracy for classifying single keys. In real-world experiments WiKey can recognize keystrokes in a continuously typed sentence with an accuracy of 93.5%.;
Proceedings of the 21st Annual International Conference on Mobile Computing and Networking;Data stream mining is an active research area that has recently emerged to discover knowledge from large amounts of continuously generated data. In this context several data stream clustering algorithms have been proposed to perform unsupervised learning. Nevertheless data stream clustering imposes several challenges to be addressed such as dealing with nonstationary unbounded data that arrive in an online fashion. The intrinsic nature of stream data requires the development of algorithms capable of performing fast and incremental processing of data objects suitably addressing time and memory limitations. In this article we present a survey of data stream clustering algorithms providing a thorough discussion of the main design components of state-of-the-art algorithms. In addition this work addresses the temporal aspects involved in data stream clustering and presents an overview of the usually employed experimental methodologies. A number of references are provided that describe applications of data stream clustering in different domains such as network intrusion detection sensor networks and stock market analysis. Information regarding software packages and data repositories are also available for helping researchers and practitioners. Finally some important issues and open questions that can be subject of future research are discussed.;
An integrated GPU power and performance model;GPU architectures are increasingly important in the multi-core era due to their high number of parallel processors. Performance optimization for multi-core processors has been a challenge for programmers. Furthermore optimizing for power consumption is even more difficult. Unfortunately as a result of the high number of processors the power consumption of many-core processors such as GPUs has increased significantly.Hence in this paper we propose an integrated power and performance (IPP) prediction model for a GPU architecture to predict the optimal number of active processors for a given application. The basic intuition is that when an application reaches the peak memory bandwidth using more cores does not result in performance improvement.We develop an empirical power model for the GPU. Unlike most previous models which require measured execution times hardware performance counters or architectural simulations IPP predicts execution times to calculate dynamic power events. We then use the outcome of IPP to control the number of running cores. We also model the increases in power consumption that resulted from the increases in temperature.With the predicted optimal number of active cores we show that we can save up to 22.09%of runtime GPU energy consumption and on average 10.99% of that for the five memory bandwidth-limited benchmarks.;
Proceedings of the 37th Annual International Symposium on Computer Architecture;We show that on both the x86 and ARM architectures it is possible to mount return-oriented programming attacks without using return instructions. Our attacks instead make use of certain instruction sequences that behave like a return which occur with sufficient frequency in large libraries on (x86) Linux and (ARM) Android to allow creation of Turing-complete gadget sets.Because they do not make use of return instructions our new attacks have negative implications for several recently proposed classes of defense against return-oriented programming: those that detect the too-frequent use of returns in the instruction stream those that detect violations of the last-in first-out invariant normally maintained for the return-address stack and those that modify compilers to produce code that avoids the return instruction.;
Proceedings of the 17th ACM Conference on Computer and Communications Security;Firedrake is a new tool for automating the numerical solution of partial differential equations. Firedrake adopts the domain-specific language for the finite element method of the FEniCS project but with a pure Python runtime-only implementation centered on the composition of several existing and new abstractions for particular aspects of scientific computing. The result is a more complete separation of concerns that eases the incorporation of separate contributions from computer scientists numerical analysts and application specialists. These contributions may add functionality or improve performance.Firedrake benefits from automatically applying new optimizations. This includes factorizing mixed function spaces transforming and vectorizing inner loops and intrinsically supporting block matrix operations. Importantly Firedrake presents a simple public API for escaping the UFL abstraction. This allows users to implement common operations that fall outside of pure variational formulations such as flux limiters.;
Multi2Sim: a simulation framework for CPU-GPU computing;Accurate simulation is essential for the proper design and evaluation of any computing platform. Upon the current move toward the CPU-GPU heterogeneous computing era researchers need a simulation framework that can model both kinds of computing devices and their interaction. In this paper we present Multi2Sim an open-source modular and fully configurable toolset that enables ISA-level simulation of an x86 CPU and an AMD Evergreen GPU. Focusing on a model of the AMD Radeon 5870 GPU we address program emulation correctness as well as architectural simulation accuracy using AMD's OpenCL benchmark suite. Simulation capabilities are demonstrated with a preliminary architectural exploration study and workload characterization examples. The project source code benchmark packages and a detailed user's guide are publicly available at www.multi2sim.org.;
Proceedings of the 21st International Conference on Parallel Architectures and Compilation Techniques;We report about the iCub a humanoid robot for research in embodied cognition. At 104 cm tall the iCub has the size of a three and half year old child. It will be able to crawl on all fours and sit up to manipulate objects. Its hands have been designed to support sophisticate manipulation skills. The iCub is distributed as Open Source following the GPL/FDL licenses. The entire design is available for download from the project homepage and repository (http://www.robotcub.org). In the following we will concentrate on the description of the hardware and software systems. The scientific objectives of the project and its philosophical underpinning are described extensively elsewhere [1].;
Proceedings of the 8th Workshop on Performance Metrics for Intelligent Systems;We present Prophet a novel patch generation system that works with a set of successful human patches obtained from open- source software repositories to learn a probabilistic application-independent model of correct code. It generates a space of candidate patches uses the model to rank the candidate patches in order of likely correctness and validates the ranked patches against a suite of test cases to find correct patches. Experimental results show that on a benchmark set of 69 real-world defects drawn from eight open-source projects Prophet significantly outperforms the previous state-of-the-art patch generation system.;
Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages;As data centers become more and more central in Internet communications both research and operations communities have begun to explore how to better design and manage them. In this paper we present a preliminary empirical study of end-to-end traffic patterns in data center networks that can inform and help evaluate research and operational approaches. We analyze SNMP logs collected at 19 data centers to examine temporal and spatial variations in link loads and losses. We find that while links in the core are heavily utilized the ones closer to the edge observe a greater degree of loss. We then study packet traces collected at a small number of switches in one data center and find evidence of ON-OFF traffic behavior. Finally we develop a framework that derives ON-OFF traffic parameters for data center traffic sources that best explain the SNMP data collected for the data center. We show that the framework can be used to evaluate data center traffic engineering approaches. We are also applying the framework to design network-level traffic generators for data centers.;
Proceedings of the 1st ACM Workshop on Research on Enterprise Networking;Social networking websites allow users to create and share content. Big information cascades of post resharing can form as users of these sites reshare others' posts with their friends and followers. One of the central challenges in understanding such cascading behaviors is in forecasting information outbreaks where a single post becomes widely popular by being reshared by many users. In this paper we focus on predicting the final number of reshares of a given post. We build on the theory of self-exciting point processes to develop a statistical model that allows us to make accurate predictions. Our model requires no training or expensive feature engineering. It results in a simple and efficiently computable formula that allows us to answer questions in real-time such as: Given a post's resharing history so far what is our current estimate of its final number of reshares? Is the post resharing cascade past the initial stage of explosive growth? And which posts will be the most reshared in the future?We validate our model using one month of complete Twitter data and demonstrate a strong improvement in predictive accuracy over existing approaches. Our model gives only 15% relative error in predicting final size of an average information cascade after observing it for just one hour.;
Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Scale up your datasets enough and your apps come undone. What are the typical problems and where do the bottlenecks surface?;
k-Shape: Efficient and Accurate Clustering of Time Series;The proliferation and ubiquity of temporal data across many disciplines has generated substantial interest in the analysis and mining of time series. Clustering is one of the most popular data mining methods not only due to its exploratory power but also as a preprocessing step or subroutine for other techniques. In this paper we present k-Shape a novel algorithm for time-series clustering. k-Shape relies on a scalable iterative refinement procedure which creates homogeneous and well-separated clusters. As its distance measure k-Shape uses a normalized version of the cross-correlation measure in order to consider the shapes of time series while comparing them. Based on the properties of that distance measure we develop a method to compute cluster centroids which are used in every iteration to update the assignment of time series to clusters. To demonstrate the robustness of k-Shape we perform an extensive experimental evaluation of our approach against partitional hierarchical and spectral clustering methods with combinations of the most competitive distance measures. k-Shape outperforms all scalable approaches in terms of accuracy. Furthermore k-Shape also outperforms all non-scalable (and hence impractical) combinations with one exception that achieves similar accuracy results. However unlike k-Shape this combination requires tuning of its distance measure and is two orders of magnitude slower than k-Shape. Overall k-Shape emerges as a domain-independent highly accurate and highly efficient clustering approach for time series with broad applications.;
Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data;Silo is a new in-memory database that achieves excellent performance and scalability on modern multicore machines. Silo was designed from the ground up to use system memory and caches efficiently. For instance it avoids all centralized contention points including that of centralized transaction ID assignment. Silo's key contribution is a commit protocol based on optimistic concurrency control that provides serializability while avoiding all shared-memory writes for records that were only read. Though this might seem to complicate the enforcement of a serial order correct logging and recovery is provided by linking periodically-updated epochs with the commit protocol. Silo provides the same guarantees as any serializable database without unnecessary scalability bottlenecks or much additional latency. Silo achieves almost 700000 transactions per second on a standard TPC-C workload mix on a 32-core machine as well as near-linear scalability. Considered per core this is several times higher than previously reported results.;
Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles;This article studies runtime verification of properties expressed either in lineartime temporal logic (LTL) or timed lineartime temporal logic (TLTL). It classifies runtime verification in identifying its distinguishing features to model checking and testing respectively. It introduces a three-valued semantics (with truth values true false inconclusive) as an adequate interpretation as to whether a partial observation of a running system meets an LTL or TLTL property.For LTL a conceptually simple monitor generation procedure is given which is optimal in two respects: First the size of the generated deterministic monitor is minimal and second the monitor identifies a continuously monitored trace as either satisfying or falsifying a property as early as possible. The feasibility of the developed methodology is demontrated using a collection of real-world temporal logic specifications. Moreover the presented approach is related to the properties monitorable in general and is compared to existing concepts in the literature. It is shown that the set of monitorable properties does not only encompass the safety and cosafety properties but is strictly larger.For TLTL the same road map is followed by first defining a three-valued semantics. The corresponding construction of a timed monitor is more involved yet as shown possible.;
GRAM: Graph-based Attention Model for Healthcare Representation Learning;Deep learning methods exhibit promising performance for predictive modeling in healthcare but two important challenges remain: - Data insufficiency: Often in healthcare predictive modeling the sample size is insufficient for deep learning methods to achieve satisfactory results.Interpretation: The representations learned by deep learning methods should align with medical knowledge.To address these challenges we propose GRaph-based Attention Model (GRAM) that supplements electronic health records (EHR) with hierarchical information inherent to medical ontologies. Based on the data volume and the ontology structure GRAM represents a medical concept as a combination of its ancestors in the ontology via an attention mechanism.We compared predictive performance (i.e. accuracy data needs interpretability) of GRAM to various methods including the recurrent neural network (RNN) in two sequential diagnoses prediction tasks and one heart failure prediction task. Compared to the basic RNN GRAM achieved 10% higher accuracy for predicting diseases rarely observed in the training data and 3% improved area under the ROC curve for predicting heart failure using an order of magnitude less training data. Additionally unlike other methods the medical concept representations learned by GRAM are well aligned with the medical ontology. Finally GRAM exhibits intuitive attention behaviors by adaptively generalizing to higher level concepts when facing data insufficiency at the lower level concepts.;
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Communication in data-parallel applications often involves a collection of parallel flows. Traditional techniques to optimize flow-level metrics do not perform well in optimizing such collections because the network is largely agnostic to application-level requirements. The recently proposed coflow abstraction bridges this gap and creates new opportunities for network scheduling. In this paper we address inter-coflow scheduling for two different objectives: decreasing communication time of data-intensive jobs and guaranteeing predictable communication time. We introduce the concurrent open shop scheduling with coupled resources problem analyze its complexity and propose effective heuristics to optimize either objective. We present Varys a system that enables data-intensive frameworks to use coflows and the proposed algorithms while maintaining high network utilization and guaranteeing starvation freedom. EC2 deployments and trace-driven simulations show that communication stages complete up to 3.16X faster on average and up to 2X more coflows meet their deadlines using Varys in comparison to per-flow mechanisms. Moreover Varys outperforms non-preemptive coflow schedulers by more than 5X.;
Proceedings of the 2014 ACM Conference on SIGCOMM;User-facing latency-sensitive services such as websearch underutilize their computing resources during daily periods of low traffic. Reusing those resources for other tasks is rarely done in production services since the contention for shared resources can cause latency spikes that violate the service-level objectives of latency-sensitive tasks. The resulting under-utilization hurts both the affordability and energy-efficiency of large-scale datacenters. With technology scaling slowing down it becomes important to address this opportunity.We present Heracles a feedback-based controller that enables the safe colocation of best-effort tasks alongside a latency-critical service. Heracles dynamically manages multiple hardware and software isolation mechanisms such as CPU memory and network isolation to ensure that the latency-sensitive job meets latency targets while maximizing the resources given to best-effort tasks. We evaluate Heracles using production latency-critical and batch workloads from Google and demonstrate average server utilizations of 90% without latency violations across all the load and colocation scenarios that we evaluated.;
Proceedings of the 42nd Annual International Symposium on Computer Architecture;At the heart of software evolution is a sequence of edit actions called an edit script made to a source code file. Since software systems are stored version by version the edit script has to be computed from these versions which is known as a complex task. Existing approaches usually compute edit scripts at the text granularity with only add line and delete line actions. However inferring syntactic changes from such an edit script is hard. Since moving code is a frequent action performed when editing code it should also be taken into account. In this paper we tackle these issues by introducing an algorithm computing edit scripts at the abstract syntax tree granularity including move actions. Our objective is to compute edit scripts that are short and close to the original developer intent. Our algorithm is implemented in a freely-available and extensible tool that has been intensively validated.;
Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering;We introduce Sapienz an approach to Android testing that uses multi-objective search-based testing to automatically explore and optimise test sequences minimising length while simultaneously maximising coverage and fault revelation. Sapienz combines random fuzzing systematic and search-based exploration exploiting seeding and multi-level instrumentation. Sapienz significantly outperforms (with large effect size) both the state-of-the-art technique Dynodroid and the widely-used tool Android Monkey in 7/10 experiments for coverage 7/10 for fault detection and 10/10 for fault-revealing sequence length. When applied to the top 1000 Google Play apps Sapienz found 558 unique previously unknown crashes. So far we have managed to make contact with the developers of 27 crashing apps. Of these 14 have confirmed that the crashes are caused by real faults. Of those 14 six already have developer-confirmed fixes.;
Proceedings of the 25th International Symposium on Software Testing and Analysis;We present NetCache a new key-value store architecture that leverages the power and flexibility of new-generation programmable switches to handle queries on hot items and balance the load across storage nodes. NetCache provides high aggregate throughput and low latency even under highly-skewed and rapidly-changing workloads. The core of NetCache is a packet-processing pipeline that exploits the capabilities of modern programmable switch ASICs to efficiently detect index cache and serve hot key-value items in the switch data plane. Additionally our solution guarantees cache coherence with minimal overhead. We implement a NetCache prototype on Barefoot Tofino switches and commodity servers and demonstrate that a single switch can process 2+ billion queries per second for 64K items with 16-byte keys and 128-byte values while only consuming a small portion of its hardware resources. To the best of our knowledge this is the first time that a sophisticated application-level functionality such as in-network caching has been shown to run at line rate on programmable switches. Furthermore we show that NetCache improves the throughput by 3-10x and reduces the latency of up to 40% of queries by 50% for high-performance in-memory key-value stores.;
Proceedings of the 26th Symposium on Operating Systems Principles;Program autotuning has been shown to achieve better or more portable performance in a number of domains. However autotuners themselves are rarely portable between projects for a number of reasons: using a domain-informed search space representation is critical to achieving good results search spaces can be intractably large and require advanced machine learning techniques and the landscape of search spaces can vary greatly between different problems sometimes requiring domain specific search techniques to explore efficiently.This paper introduces OpenTuner a new open source framework for building domain-specific multi-objective program autotuners. OpenTuner supports fully-customizable configuration representations an extensible technique representation to allow for domain-specific techniques and an easy to use interface for communicating with the program to be autotuned. A key capability inside OpenTuner is the use of ensembles of disparate search techniques simultaneously techniques that perform well will dynamically be allocated a larger proportion of tests. We demonstrate the efficacy and generality of OpenTuner by building autotuners for 7 distinct projects and 16 total benchmarks showing speedups over prior techniques of these projects of up to 2.8x with little programmer effort.;
Proceedings of the 23rd International Conference on Parallel Architectures and Compilation;Code clone detection is an important problem for software maintenance and evolution. Many approaches consider either structure or identifiers but none of the existing detection techniques model both sources of information. These techniques also depend on generic handcrafted features to represent code fragments. We introduce learning-based detection techniques where everything for representing terms and fragments in source code is mined from the repository. Our code analysis supports a framework which relies on deep learning for automatically linking patterns mined at the lexical level with patterns mined at the syntactic level. We evaluated our novel learning-based approach for code clone detection with respect to feasibility from the point of view of software maintainers. We sampled and manually evaluated 398 file- and 480 method-level pairs across eight real-world Java systems 93% of the file- and method-level samples were evaluated to be true positives. Among the true positives we found pairs mapping to all four clone types. We compared our approach to a traditional structure-oriented technique and found that our learning-based approach detected clones that were either undetected or suboptimally reported by the prominent tool Deckard. Our results affirm that our learning-based approach is suitable for clone detection and a tenable technique for researchers.;
Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering;In this paper we propose a new latent semantic model that incorporates a convolutional-pooling structure over word sequences to learn low-dimensional semantic vector representations for search queries and Web documents. In order to capture the rich contextual structures in a query or a document we start with each word within a temporal context window in a word sequence to directly capture contextual features at the word n-gram level. Next the salient word n-gram features in the word sequence are discovered by the model and are then aggregated to form a sentence-level feature vector. Finally a non-linear transformation is applied to extract high-level semantic information to generate a continuous vector representation for the full text string. The proposed convolutional latent semantic model (CLSM) is trained on clickthrough data and is evaluated on a Web document ranking task using a large-scale real-world data set. Results show that the proposed model effectively captures salient semantic information in queries and documents for the task while significantly outperforming previous state-of-the-art semantic models.;
Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management;Whitebox fuzzing is a form of automatic dynamic test generation based on symbolic execution and constraint solving designed for security testing of large applications. Unfortunately the current effectiveness of whitebox fuzzing is limited when testing applications with highly-structured inputs such as compilers and interpreters. These applications process their inputs in stages such as lexing parsing and evaluation. Due to the enormous number of control paths in early processing stages whitebox fuzzing rarely reaches parts of the application beyond those first stages.In this paper we study how to enhance whitebox fuzzing of complex structured-input applications with a grammar-based specification of their valid inputs. We present a novel dynamic test generation algorithm where symbolic execution directly generates grammar-based constraints whose satisfiability is checked using a custom grammar-based constraint solver. We have implemented this algorithm and evaluated it on a large security-critical application the JavaScript interpreter of Internet Explorer 7 (IE7). Results of our experiments show that grammar-based whitebox fuzzing explores deeper program paths and avoids dead-ends due to non-parsable inputs. Compared to regular whitebox fuzzing grammar-based whitebox fuzzing increased coverage of the code generation module of the IE7 JavaScript interpreter from 53% to 81% while using three times fewer tests.;
Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation;During software maintenance code comments help developers comprehend programs and reduce additional time spent on reading and navigating source code. Unfortunately these comments are often mismatched missing or outdated in the software projects. Developers have to infer the functionality from the source code. This paper proposes a new approach named DeepCom to automatically generate code comments for Java methods. The generated comments aim to help developers understand the functionality of Java methods. DeepCom applies Natural Language Processing (NLP) techniques to learn from a large code corpus and generates comments from learned features. We use a deep neural network that analyzes structural information of Java methods for better comments generation. We conduct experiments on a large-scale Java corpus built from 9714 open source projects from GitHub. We evaluate the experimental results on a machine translation metric. Experimental results demonstrate that our method DeepCom outperforms the state-of-the-art by a substantial margin.;
Proceedings of the 26th Conference on Program Comprehension;Datacenter workloads demand high computational capabilities flexibility power efficiency and low cost. It is challenging to improve all of these factors simultaneously. To advance datacenter capabilities beyond what commodity server designs can provide we have designed and built a composable reconfigurablefabric to accelerate portions of large-scale software services. Each instantiation of the fabric consists of a 6x8 2-D torus of high-end Stratix V FPGAs embedded into a half-rack of 48 machines. One FPGA is placed into each server accessible through PCIe and wired directly to other FPGAs with pairs of 10 Gb SAS cablesIn this paper we describe a medium-scale deployment of this fabric on a bed of 1632 servers and measure its efficacy in accelerating the Bing web search engine. We describe the requirements and architecture of the system detail the critical engineering challenges and solutions needed to make the system robust in the presence of failures and measure the performance power and resilience of the system when ranking candidate documents. Under high load the largescale reconfigurable fabric improves the ranking throughput of each server by a factor of 95% for a fixed latency distribution--- or while maintaining equivalent throughput reduces the tail latency by 29%;
Proceeding of the 41st Annual International Symposium on Computer Architecuture;Clusters provide powerful computing environments but in practice much of this power goes to waste due to the static allocation of tasks to nodes regardless of their changing computational requirements. Dynamic consolidation is an approach that migrates tasks within a cluster as their computational requirements change both to reduce the number of nodes that need to be active and to eliminate temporary overload situations. Previous dynamic consolidation strategies have relied on task placement heuristics that use only local optimization and typically do not take migration overhead into account. However heuristics based on only local optimization may miss the globally optimal solution resulting in unnecessary resource usage and the overhead for migration may nullify the benefits of consolidation.In this paper we propose the Entropy resource manager for homogeneous clusters which performs dynamic consolidation based on constraint programming and takes migration overhead into account. The use of constraint programming allows Entropy to find mappings of tasks to nodes that are better than those found by heuristics based on local optimizations and that are frequently globally optimal in the number of nodes. Because migration overhead is taken into account Entropy chooses migrations that can be implemented efficiently incurring a low performance overhead.;
Proceedings of the 2009 ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments;In this paper we present the results of a roleplay survey instrument administered to 1001 online survey respondents to study both the relationship between demographics and phishing susceptibility and the effectiveness of several anti-phishing educational materials. Our results suggest that women are more susceptible than men to phishing and participants between the ages of 18 and 25 are more susceptible to phishing than other age groups. We explain these demographic factors through a mediation analysis. Educational materials reduced users' tendency to enter information into phishing webpages by 40% percent however some of the educational materials we tested also slightly decreased participants' tendency to click on legitimate links.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;"Botnets networks of malware-infected machines that are controlled by an adversary are the root cause of a large number of security problems on the Internet. A particularly sophisticated and insidious type of bot is Torpig a malware program that is designed to harvest sensitive information (such as bank account and credit card data) from its victims. In this paper we report on our efforts to take control of the Torpig botnet and study its operations for a period of ten days. During this time we observed more than 180 thousand infections and recorded almost 70 GB of data that the bots collected. While botnets have been hijacked"" and studied previously the Torpig botnet exhibits certain properties that make the analysis of the data particularly interesting. First it is possible (with reasonable accuracy) to identify unique bot infections and relate that number to the more than 1.2 million IP addresses that contacted our command and control server. Second the Torpig botnet is large targets a variety of applications and gathers a rich and diverse set of data from the infected victims. This data provides a new understanding of the type and amount of personal information that is stolen by botnets.""";
Proceedings of the 16th ACM Conference on Computer and Communications Security;Efficiently scheduling data processing jobs on distributed compute clusters requires complex algorithms. Current systems use simple generalized heuristics and ignore workload characteristics since developing and tuning a scheduling policy for each workload is infeasible. In this paper we show that modern machine learning techniques can generate highly-efficient policies automatically.Decima uses reinforcement learning (RL) and neural networks to learn workload-specific scheduling algorithms without any human instruction beyond a high-level objective such as minimizing average job completion time. However off-the-shelf RL techniques cannot handle the complexity and scale of the scheduling problem. To build Decima we had to develop new representations for jobs' dependency graphs design scalable RL models and invent RL training methods for dealing with continuous stochastic job arrivals.Our prototype integration with Spark on a 25-node cluster shows that Decima improves average job completion time by at least 21% over hand-tuned scheduling heuristics achieving up to 2x improvement during periods of high cluster load.;
Proceedings of the ACM Special Interest Group on Data Communication;Exploiting the multiprocessors that have recently become ubiquitous requires high-performance and reliable concurrent systems code for concurrent data structures operating system kernels synchronization libraries compilers and so on. However concurrent programming which is always challenging is made much more so by two problems. First real multiprocessors typically do not provide the sequentially consistent memory that is assumed by most work on semantics and verification. Instead they have relaxed memory models varying in subtle ways between processor families in which different hardware threads may have only loosely consistent views of a shared memory. Second the public vendor architectures supposedly specifying what programmers can rely on are often in ambiguous informal prose (a particularly poor medium for loose specifications) leading to widespread confusion.In this paper we focus on x86 processors. We review several recent Intel and AMD specifications showing that all contain serious ambiguities some are arguably too weak to program above and some are simply unsound with respect to actual hardware. We present a new x86-TSO programmer's model that to the best of our knowledge suffers from none of these problems. It is mathematically precise (rigorously defined in HOL4) but can be presented as an intuitive abstract machine which should be widely accessible to working programmers. We illustrate how this can be used to reason about the correctness of a Linux spinlock implementation and describe a general theory of data-race freedom for x86-TSO. This should put x86 multiprocessor system building on a more solid foundation it should also provide a basis for future work on verification of such systems.;
Single image dehazing;In this paper we present a new method for estimating the optical transmission in hazy scenes given a single input image. Based on this estimation the scattered light is eliminated to increase scene visibility and recover haze-free scene contrasts. In this new approach we formulate a refined image formation model that accounts for surface shading in addition to the transmission function. This allows us to resolve ambiguities in the data by searching for a solution in which the resulting shading and transmission functions are locally statistically uncorrelated. A similar principle is used to estimate the color of the haze. Results demonstrate the new method abilities to remove the haze layer as well as provide a reliable transmission estimate which can be used for additional applications such as image refocusing and novel view synthesis.;
ACM SIGGRAPH 2008 Papers;In today's world online social media plays a vital role during real world events especially crisis events. There are both positive and negative effects of social media coverage of events it can be used by authorities for effective disaster management or by malicious entities to spread rumors and fake news. The aim of this paper is to highlight the role of Twitter during Hurricane Sandy (2012) to spread fake images about the disaster. We identified 10350 unique tweets containing fake images that were circulated on Twitter during Hurricane Sandy. We performed a characterization analysis to understand the temporal social reputation and influence patterns for the spread of fake images. Eighty six percent of tweets spreading the fake images were retweets hence very few were original tweets. Our results showed that top thirty users out of 10215 users (0.3%) resulted in 90% of the retweets of fake images also network links such as follower relationships of Twitter contributed very less (only 11%) to the spread of these fake photos URLs. Next we used classification models to distinguish fake images from real images of Hurricane Sandy. Best results were obtained from Decision Tree classifier we got 97% accuracy in predicting fake images from real. Also tweet based features were very effective in distinguishing fake images tweets from real while the performance of user based features was very poor. Our results showed that automated techniques can be used in identifying real images from fake images posted on Twitter.;
Proceedings of the 22nd International Conference on World Wide Web;Disciplined approximate programming lets programmers declare which parts of a program can be computed approximately and consequently at a lower energy cost. The compiler proves statically that all approximate computation is properly isolated from precise computation. The hardware is then free to selectively apply approximate storage and approximate computation with no need to perform dynamic correctness checks.In this paper we propose an efficient mapping of disciplined approximate programming onto hardware. We describe an ISA extension that provides approximate operations and storage which give the hardware freedom to save energy at the cost of accuracy. We then propose Truffle a microarchitecture design that efficiently supports the ISA extensions. The basis of our design is dual-voltage operation with a high voltage for precise operations and a low voltage for approximate operations. The key aspect of the microarchitecture is its dependence on the instruction stream to determine when to use the low voltage. We evaluate the power savings potential of in-order and out-of-order Truffle configurations and explore the resulting quality of service degradation. We evaluate several applications and demonstrate energy savings up to 43%.;
Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems;Network management requires accurate estimates of metrics for traffic engineering (e.g. heavy hitters) anomaly detection (e.g. entropy of source addresses) and security (e.g. DDoS detection). Obtaining accurate estimates given router CPU and memory constraints is a challenging problem. Existing approaches fall in one of two undesirable extremes: (1) low fidelity general-purpose approaches such as sampling or (2) high fidelity but complex algorithms customized to specific application-level metrics. Ideally a solution should be both general (i.e. supports many applications) and provide accuracy comparable to custom algorithms. This paper presents UnivMon a framework for flow monitoring which leverages recent theoretical advances and demonstrates that it is possible to achieve both generality and high accuracy. UnivMon uses an application-agnostic data plane monitoring primitive different (and possibly unforeseen) estimation algorithms run in the control plane and use the statistics from the data plane to compute application-level metrics. We present a proof-of-concept implementation of UnivMon using P4 and develop simple coordination techniques to provide a ``one-big-switch'' abstraction for network-wide monitoring. We evaluate the effectiveness of UnivMon using a range of trace-driven evaluations and show that it offers comparable (and sometimes better) accuracy relative to custom sketching solutions.;
Proceedings of the 2016 ACM SIGCOMM Conference;In this work we present a characterization of spam on Twitter. We find that 8% of 25 million URLs posted to the site point to phishing malware and scams listed on popular blacklists. We analyze the accounts that send spam and find evidence that it originates from previously legitimate accounts that have been compromised and are now being puppeteered by spammers. Using clickthrough data we analyze spammers' use of features unique to Twitter and the degree that they affect the success of spam. We find that Twitter is a highly successful platform for coercing users to visit spam pages with a clickthrough rate of 0.13% compared to much lower rates previously reported for email spam. We group spam URLs into campaigns and identify trends that uniquely distinguish phishing malware and spam to gain an insight into the underlying techniques used to attract users.Given the absence of spam filtering on Twitter we examine whether the use of URL blacklists would help to significantly stem the spread of Twitter spam. Our results indicate that blacklists are too slow at identifying new threats allowing more than 90% of visitors to view a page before it becomes blacklisted. We also find that even if blacklist delays were reduced the use by spammers of URL shortening services for obfuscation negates the potential gains unless tools that use blacklists develop more sophisticated spam filtering.;
Proceedings of the 17th ACM Conference on Computer and Communications Security;Despite flash memory's promise it suffers from many idiosyncrasies such as limited durability data integrity problems and asymmetry in operation granularity. As architects we aim to find ways to overcome these idiosyncrasies while exploiting flash memory's useful characteristics. To be successful we must understand the trade-offs between the performance cost (in both power and dollars) and reliability of flash memory. In addition we must understand how different usage patterns affect these characteristics. Flash manufacturers provide conservative guidelines about these metrics and this lack of detail makes it difficult to design systems that fully exploit flash memory's capabilities. We have empirically characterized flash memory technology from five manufacturers by directly measuring the performance power and reliability. We demonstrate that performance varies significantly between vendors devices and from publicly available datasheets. We also demonstrate and quantify some unexpected device characteristics and show how we can use them to improve responsiveness and energy consumption of solid state disks by 44% and 13% respectively as well as increase flash device lifetime by 5.2x.;
Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture;"The greatest contributor of CO2 emissions in the average American household is personal transportation. Because transportation is inherently a mobile activity mobile devices are well suited to sense and provide feedback about these activities. In this paper we explore the use of personal ambient displays on mobile phones to give users feedback about sensed and self-reported transportation behaviors. We first present results from a set of formative studies exploring our respondents' existing transportation routines willingness to engage in and maintain green transportation behavior and reactions to early mobile phone green"" application design concepts. We then describe the results of a 3-week field study (N=13) of the UbiGreen Transportation Display prototype a mobile phone application that semi-automatically senses and reveals information about transportation behavior. Our contributions include a working system for semi-automatically tracking transit activity a visual design capable of engaging users in the goal of increasing green transportation and the results of our studies which have implications for the design of future green applications.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Software-product-line engineering has gained considerable momentum in recent years both in industry and in academia. A software product line is a family of software products that share a common set of features. Software product lines challenge traditional analysis techniques such as type checking model checking and theorem proving in their quest of ensuring correctness and reliability of software. Simply creating and analyzing all products of a product line is usually not feasible due to the potentially exponential number of valid feature combinations. Recently researchers began to develop analysis techniques that take the distinguishing properties of software product lines into account for example by checking feature-related code in isolation or by exploiting variability information during analysis. The emerging field of product-line analyses is both broad and diverse so it is difficult for researchers and practitioners to understand their similarities and differences. We propose a classification of product-line analyses to enable systematic research and application. Based on our insights with classifying and comparing a corpus of 123 research articles we develop a research agenda to guide future research on product-line analyses.;
The perception of egocentric distances in virtual environments - A review;Over the last 20 years research has been done on the question of how egocentric distances i.e. the subjectively reported distance from a human observer to an object are perceived in virtual environments. This review surveys the existing literature on empirical user studies on this topic. In summary there is a mean estimation of egocentric distances in virtual environments of about 74% of the modeled distances. Many factors possibly influencing distance estimates were reported in the literature. We arranged these factors into four groups namely measurement methods technical factors compositional factors and human factors. The research on these factors is summarized conclusions are drawn and promising areas for future research are outlined.;
Leakage-Abuse Attacks Against Searchable Encryption;Schemes for secure outsourcing of client data with search capability are being increasingly marketed and deployed. In the literature schemes for accomplishing this efficiently are called Searchable Encryption (SE). They achieve high efficiency with provable security by means of a quantifiable leakage profile. However the degree to which SE leakage can be exploited by an adversary is not well understood.To address this we present a characterization of the leakage profiles of in-the-wild searchable encryption products and SE schemes in the literature and present attack models based on an adversarial server's prior knowledge. Then we empirically investigate the security of searchable encryption by providing query recovery and plaintext recovery attacks that exploit these leakage profiles. We term these leakage-abuse attacks and demonstrate their effectiveness for varying leakage profiles and levels of server knowledge for realistic scenarios. Amongst our contributions are realistic active attacks which have not been previously explored.;
Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security;Many modern computations (such as video and audio encoders Monte Carlo simulations and machine learning algorithms) are designed to trade off accuracy in return for increased performance. To date such computations typically use ad-hoc domain-specific techniques developed specifically for the computation at hand. Loop perforation provides a general technique to trade accuracy for performance by transforming loops to execute a subset of their iterations. A criticality testing phase filters out critical loops (whose perforation produces unacceptable behavior) to identify tunable loops (whose perforation produces more efficient and still acceptably accurate computations). A perforation space exploration algorithm perforates combinations of tunable loops to find Pareto-optimal perforation policies. Our results indicate that for a range of applications this approach typically delivers performance increases of over a factor of two (and up to a factor of seven) while changing the result that the application produces by less than 10%.;
Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering;Location-based social networks (LBSNs) have attracted an inordinate number of users and greatly enriched the urban experience in recent years. The availability of spatial temporal and social information in online LBSNs offers an unprecedented opportunity to study various aspects of human behavior and enable a variety of location-based services such as location recommendation. Previous work studied spatial and social influences on location recommendation in LBSNs. Due to the strong correlations between a user's check-in time and the corresponding check-in location recommender systems designed for location recommendation inevitably need to consider temporal effects. In this paper we introduce a novel location recommendation framework based on the temporal properties of user movement observed from a real-world LBSN dataset. The experimental results exhibit the significance of temporal patterns in explaining user behavior and demonstrate their power to improve location recommendation performance.;
Proceedings of the 7th ACM Conference on Recommender Systems;Software-defined networks facilitate rapid and open innovation at the network control layer by providing a programmable network infrastructure for computing flow policies on demand. However the dynamism of programmable networks also introduces new security challenges that demand innovative solutions. A critical challenge is efficient detection and reconciliation of potentially conflicting flow rules imposed by dynamic OpenFlow (OF) applications. To that end we introduce FortNOX a software extension that provides role-based authorization and security constraint enforcement for the NOX OpenFlow controller. FortNOX enables NOX to check flow rule contradictions in real time and implements a novel analysis algorithm that is robust even in cases where an adversarial OF application attempts to strategically insert flow rules that would otherwise circumvent flow rules imposed by OF security applications. We demonstrate the utility of FortNOX through a prototype implementation and use it to examine performance and efficiency aspects of the proposed framework.;
Proceedings of the First Workshop on Hot Topics in Software Defined Networks;Three decades of active research on the teaching of introductory programming has had limited effect on classroom practice. Although relevant research exists across several disciplines including education and cognitive science disciplinary differences have made this material inaccessible to many computing educators. Furthermore computer science instructors have not had access to a comprehensive survey of research in this area. This paper collects and classifies this literature identifies important work and mediates it to computing educators and professional bodies.We identify research that gives well-supported advice to computing academics teaching introductory programming. Limitations and areas of incomplete coverage of existing research efforts are also identified. The analysis applies publication and research quality metrics developed by a previous ITiCSE working group [74].;
Working Group Reports on ITiCSE on Innovation and Technology in Computer Science Education;"Smart contracts are programs that execute autonomously on blockchains. Their key envisioned uses (e.g. financial instruments) require them to consume data from outside the blockchain (e.g. stock quotes). Trustworthy data feeds that support a broad range of data requests will thus be critical to smart contract ecosystems.We present an authenticated data feed system called Town Crier (TC). TC acts as a bridge between smart contracts and existing web sites which are already commonly trusted for non-blockchain applications. It combines a blockchain front end with a trusted hardware back end to scrape HTTPS-enabled websites and serve source-authenticated data to relying smart contracts.TC also supports confidentiality. It enables private data requests with encrypted parameters. Additionally in a generalization that executes smart-contract logic within TC the system permits secure use of user credentials to scrape access-controlled online data sources.We describe TC's design principles and architecture and report on an implementation that uses Intel's recently introduced Software Guard Extensions (SGX) to furnish data to the Ethereum smart contract system. We formally model TC and define and prove its basic security properties in the Universal Composibility (UC) framework. Our results include definitions and techniques of general interest relating to resource consumption (Ethereum's gas"" fee system) and TCB minimization. We also report on experiments with three example applications.We plan to launch TC soon as an online public service.""";
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;Smart speakers with voice assistants like Amazon Echo and Google Home provide benefits and convenience but also raise privacy concerns due to their continuously listening microphones. We studied people's reasons for and against adopting smart speakers their privacy perceptions and concerns and their privacy-seeking behaviors around smart speakers. We conducted a diary study and interviews with seventeen smart speaker users and interviews with seventeen non-users. We found that many non-users did not see the utility of smart speakers or did not trust speaker companies. In contrast users express few privacy concerns but their rationalizations indicate an incomplete understanding of privacy risks a complicated trust relationship with speaker companies and a reliance on the socio-technical context in which smart speakers reside. Users trade privacy for convenience with different levels of deliberation and privacy resignation. Privacy tensions arise between primary secondary and incidental users of smart speakers. Finally current smart speaker privacy controls are rarely used as they are not well-aligned with users' needs. Our findings can inform future smart speaker designs in particular we recommend better integrating privacy controls into smart speaker interaction.;
Mobile fog: a programming model for large-scale applications on the internet of things;The ubiquitous deployment of mobile and sensor devices is creating a new environment namely the Internet of Things(IoT) that enables a wide range of future Internet applications. In this work we present Mobile Fog a high level programming model for the future Internet applications that are geospatially distributed large-scale and latency-sensitive. We analyze use cases for the programming model with camera network and connected vehicle applications to show the efficacy of Mobile Fog. We also evaluate application performance through simulation.;
Proceedings of the Second ACM SIGCOMM Workshop on Mobile Cloud Computing;The distance transform (DT) is a general operator forming the basis of many methods in computer vision and geometry with great potential for practical applications. However all the optimal algorithms for the computation of the exact Euclidean DT (EDT) were proposed only since the 1990s. In this work state-of-the-art sequential 2D EDT algorithms are reviewed and compared in an effort to reach more solid conclusions regarding their differences in speed and their exactness. Six of the best algorithms were fully implemented and compared in practice.;
Safe and effective fine-grained TCP retransmissions for datacenter communication;This paper presents a practical solution to a problem facing high-fan-in high-bandwidth synchronized TCP workloads in datacenter Ethernets---the TCP incast problem. In these networks receivers can experience a drastic reduction in application throughput when simultaneously requesting data from many servers using TCP. Inbound data overfills small switch buffers leading to TCP timeouts lasting hundreds of milliseconds. For many datacenter workloads that have a barrier synchronization requirement (e.g. filesystem reads and parallel data-intensive queries) throughput is reduced by up to 90%. For latency-sensitive applications TCP timeouts in the datacenter impose delays of hundreds of milliseconds in networks with round-trip-times in microseconds.Our practical solution uses high-resolution timers to enable microsecond-granularity TCP timeouts. We demonstrate that this technique is effective in avoiding TCP incast collapse in simulation and in real-world experiments. We show that eliminating the minimum retransmission timeout bound is safe for all environments including the wide-area.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;While Deep Neural Networks (DNNs) have established the fundamentals of image-based autonomous driving systems they may exhibit erroneous behaviors and cause fatal accidents. To address the safety issues in autonomous driving systems a recent set of testing techniques have been designed to automatically generate artificial driving scenes to enrich test suite e.g. generating new input images transformed from the original ones. However these techniques are insufficient due to two limitations: first many such synthetic images often lack diversity of driving scenes and hence compromise the resulting efficacy and reliability. Second for machine-learning-based systems a mismatch between training and application domain can dramatically degrade system accuracy such that it is necessary to validate inputs for improving system robustness.  In this paper we propose DeepRoad an unsupervised DNN-based framework for automatically testing the consistency of DNN-based autonomous driving systems and online validation. First DeepRoad automatically synthesizes large amounts of diverse driving scenes without using image transformation rules (e.g. scale shear and rotation). In particular DeepRoad is able to produce driving scenes with various weather conditions (including those with rather extreme conditions) by applying Generative Adversarial Networks (GANs) along with the corresponding real-world weather scenes. Second DeepRoad utilizes metamorphic testing techniques to check the consistency of such systems using synthetic images. Third DeepRoad validates input images for DNN-based systems by measuring the distance of the input and training images using their VGGNet features. We implement DeepRoad to test three well-recognized DNN-based autonomous driving systems in Udacity self-driving car challenge. The experimental results demonstrate that DeepRoad can detect thousands of inconsistent behaviors for these systems and effectively validate input images to potentially enhance the system robustness as well.;
Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering;Heterogeneous multiprocessors are increasingly important in the multi-core era due to their potential for high performance and energy efficiency. In order for software to fully realize this potential the step that maps computations to processing elements must be as automated as possible. However the state-of-the-art approach is to rely on the programmer to specify this mapping manually and statically. This approach is not only labor intensive but also not adaptable to changes in runtime environments like problem sizes and hardware/software configurations. In this study we propose adaptive mapping a fully automatic technique to map computations to processing elements on a CPU+GPU machine. We have implemented it in our experimental heterogeneous programming system called Qilin. Our results show that by judiciously distributing works over the CPU and GPU automatic adaptive mapping achieves a 25% reduction in execution time and a 20% reduction in energy consumption than static mappings on average for a set of important computation benchmarks. We also demonstrate that our technique is able to adapt to changes in the input problem size and system configuration.;
Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture;Bugs in multi-threaded programs often arise due to data races. Numerous static and dynamic program analysis techniques have been proposed to detect data races. We propose a novel randomized dynamic analysis technique that utilizes potential data race information obtained from an existing analysis tool to separate real races from false races without any need for manual inspection. Specifically we use potential data race information obtained from an existing dynamic analysis technique to control a random scheduler of threads so that real race conditions get created with very high probability and those races get resolved randomly at runtime. Our approach has several advantages over existing dynamic analysis tools. First we can create a real race condition and resolve the race randomly to see if an error can occur due to the race. Second we can replay a race revealing execution efficiently by simply using the same seed for random number generation--we do not need to record the execution. Third our approach has very low overhead compared to other precise dynamic race detection techniques because we only track all synchronization operations and a single pair of memory access statements that are reported to be in a potential race by an existing analysis. We have implemented the technique in a prototype tool for Java and have experimented on a number of large multi-threaded Java programs. We report a number of previously known and unknown bugs and real races in these Java programs.;
Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation;The delivery of audio-visual content over the Hypertext Transfer Protocol (HTTP) got lot of attention in recent years and with dynamic adaptive streaming over HTTP (DASH) a standard is now available. Many papers cover this topic and present their research results but unfortunately all of them use their own private dataset which -- in most cases -- is not publicly available. Hence it is difficult to compare e.g. adaptation algorithms in an objective way due to the lack of a common dataset which shall be used as basis for such experiments. In this paper we present our DASH dataset including our DASHEncoder an open source DASH content generation tool. We also provide basic evaluations of the different segment lengths the influence of HTTP server settings and in this context we show some of the advantages as well as problems of shorter segment lengths.;
Proceedings of the 3rd Multimedia Systems Conference;K-Nearest Neighbor Graph (K-NNG) construction is an important operation with many web related applications including collaborative filtering similarity search and many others in data mining and machine learning. Existing methods for K-NNG construction either do not scale or are specific to certain similarity measures. We present NN-Descent a simple yet efficient algorithm for approximate K-NNG construction with arbitrary similarity measures. Our method is based on local search has minimal space overhead and does not rely on any shared global index. Hence it is especially suitable for large-scale applications where data structures need to be distributed over the network. We have shown with a variety of datasets and similarity measures that the proposed method typically converges to above 90% recall with each point comparing only to several percent of the whole dataset on average.;
Proceedings of the 20th International Conference on World Wide Web;Energy has become a first-class design constraint in computer systems. Memory is a significant contributor to total system power. This paper introduces Flikker an application-level technique to reduce refresh power in DRAM memories. Flikker enables developers to specify critical and non-critical data in programs and the runtime system allocates this data in separate parts of memory. The portion of memory containing critical data is refreshed at the regular refresh-rate while the portion containing non-critical data is refreshed at substantially lower rates. This partitioning saves energy at the cost of a modest increase in data corruption in the non-critical data. Flikker thus exposes and leverages an interesting trade-off between energy consumption and hardware correctness. We show that many applications are naturally tolerant to errors in the non-critical data and in the vast majority of cases the errors have little or no impact on the application's final outcome. We also find that Flikker can save between 20-25% of the power consumed by the memory sub-system in a mobile device with negligible impact on application performance. Flikker is implemented almost entirely in software and requires only modest changes to the hardware.;
Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems;"Flash Memory based Solid State Drive (SSD) has been called a pivotal technology"" that could revolutionize data storage systems. Since SSD shares a common interface with the traditional hard disk drive (HDD) both physically and logically an effective integration of SSD into the storage hierarchy is very important. However details of SSD hardware implementations tend to be hidden behind such narrow interfaces. In fact since sophisticated algorithms are usually of necessity adopted in SSD controller firmware more complex performance dynamics are to be expected in SSD than in HDD systems. Most existing literature or product specifications on SSD just provide high-level descriptions and standard performance data such as bandwidth and latency.In order to gain insight into the unique performance characteristics of SSD we have conducted intensive experiments and measurements on different types of state-of-the-art SSDs from low-end to high-end products. We have observed several unexpected performance issues and uncertain behavior of SSDs which have not been reported in the literature. For example we found that fragmentation could seriously impact performance -- by a factor of over 14 times on a recently announced SSD. Moreover contrary to the common belief that accesses to SSD are uncorrelated with access patterns we found a strong correlation between performance and the randomness of data accesses for both reads and writes. In the worst case average latency could increase by a factor of 89 and bandwidth could drop to only 0.025MB/sec. Our study reveals several unanticipated aspects in the performance dynamics of SSD technology that must be addressed by system designers and data-intensive application users in order to effectively place it in the storage hierarchy.""";
Proceedings of the Eleventh International Joint Conference on Measurement and Modeling of Computer Systems;Recent advances in technology have brought major breakthroughs in data collection enabling a large amount of data to be gathered over time and thus generating time series. Mining this data has become an important task for researchers and practitioners in the past few years including the detection of outliers or anomalies that may represent errors or events of interest. This review aims to provide a structured and comprehensive state-of-the-art on unsupervised outlier detection techniques in the context of time series. To this end a taxonomy is presented based on the main aspects that characterize an outlier detection technique.;
Double-spending fast payments in bitcoin;Bitcoin is a decentralized payment system that relies on Proof-of-Work (PoW) to verify payments. Nowadays Bitcoin is increasingly used in a number of fast payment scenarios where the time between the exchange of currency and goods is short (in the order of few seconds). While the Bitcoin payment verification scheme is designed to prevent double-spending our results show that the system requires tens of minutes to verify a transaction and is therefore inappropriate for fast payments. An example of this use of Bitcoin was recently reported in the media: Bitcoins were used as a form of emph{fast;
Proceedings of the 2012 ACM Conference on Computer and Communications Security;We present the Unified Form Language (UFL) which is a domain-specific language for representing weak formulations of partial differential equations with a view to numerical approximation. Features of UFL include support for variational forms and functionals automatic differentiation of forms and expressions arbitrary function space hierarchies for multifield problems general differential operators and flexible tensor algebra. With these features UFL has been used to effortlessly express finite element methods for complex systems of partial differential equations in near-mathematical notation resulting in compact intuitive and readable programs. We present in this work the language and its construction. An implementation of UFL is freely available as an open-source software library. The library generates abstract syntax tree representations of variational problems which are used by other software libraries to generate concrete low-level implementations. Some application examples are presented and libraries that support UFL are highlighted.;
Reproducible network experiments using container-based emulation;In an ideal world all research papers would be runnable: simply click to replicate all results using the same setup as the authors. One approach to enable runnable network systems papers is Container-Based Emulation (CBE) where an environment of virtual hosts switches and links runs on a modern multicore server using real application and kernel code with software-emulated network elements. CBE combines many of the best features of software simulators and hardware testbeds but its performance fidelity is unproven.In this paper we put CBE to the test using our prototype Mininet-HiFi to reproduce key results from published network experiments such as DCTCP Hedera and router buffer sizing. We report lessons learned from a graduate networking class at Stanford where 37 students used our platform to replicate 18 published results of their own choosing. Our experiences suggest that CBE makes research results easier to reproduce and build upon.;
Proceedings of the 8th International Conference on Emerging Networking Experiments and Technologies;The role of prototypes is well established in the field of HCI and Design. A lack of knowledge however about the fundamental nature of prototypes still exists. Researchers have attempted to identify different types of prototypes such as low- vs. high-fidelity prototypes but these attempts have centered on evaluation rather than support of design exploration. There have also been efforts to provide new ways of thinking about the activity of using prototypes such as experience prototyping and paper prototyping but these efforts do not provide a discourse for understanding fundamental characteristics of prototypes. In this article we propose an anatomy of prototypes as a framework for prototype conceptualization. We view prototypes not only in their role in evaluation but also in their generative role in enabling designers to reflect on their design activities in exploring a design space. We base this framework on the findings of two case studies that reveal two key dimensions: prototypes as filters and prototypes as manifestations. We explain why these two dimensions are important and how this conceptual framework can benefit our field by establishing more solid and systematic knowledge about prototypes and prototyping.;
UltraHaptics: multi-point mid-air haptic feedback for touch surfaces;We introduce UltraHaptics a system designed to provide multi-point haptic feedback above an interactive surface. UltraHaptics employs focused ultrasound to project discrete points of haptic feedback through the display and directly on to users' unadorned hands. We investigate the desirable properties of an acoustically transparent display and demonstrate that the system is capable of creating multiple localised points of feedback in mid-air. Through psychophysical experiments we show that feedback points with different tactile properties can be identified at smaller separations. We also show that users are able to distinguish between different vibration frequencies of non-contact points with training. Finally we explore a number of exciting new interaction possibilities that UltraHaptics provides.;
Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology;Scalable database management systems (DBMS)---both for update intensive application workloads as well as decision support systems for descriptive and deep analytics---are a critical part of the cloud infrastructure and play an important role in ensuring the smooth transition of applications from the traditional enterprise infrastructures to next generation cloud infrastructures. Though scalable data management has been a vision for more than three decades and much research has focussed on large scale data management in traditional enterprise setting cloud computing brings its own set of novel challenges that must be addressed to ensure the success of data management solutions in the cloud environment. This tutorial presents an organized picture of the challenges faced by application developers and DBMS designers in developing and deploying internet scale applications. Our background study encompasses both classes of systems: (i) for supporting update heavy applications and (ii) for ad-hoc analytics and decision support. We then focus on providing an in-depth analysis of systems for supporting update intensive web-applications and provide a survey of the state-of-the-art in this domain. We crystallize the design choices made by some successful systems large scale database management systems analyze the application demands and access patterns and enumerate the desiderata for a cloud-bound DBMS.;
Proceedings of the 14th International Conference on Extending Database Technology;Modern day datacenters host hundreds of thousands of servers that coordinate tasks in order to deliver highly available cloud computing services. These servers consist of multiple hard disks memory modules network cards processors etc. each of which while carefully engineered are capable of failing. While the probability of seeing any such failure in the lifetime (typically 3-5 years in industry) of a server can be somewhat small these numbers get magnified across all devices hosted in a datacenter. At such a large scale hardware component failure is the norm rather than an exception.Hardware failure can lead to a degradation in performance to end-users and can result in losses to the business. A sound understanding of the numbers as well as the causes behind these failures helps improve operational experience by not only allowing us to be better equipped to tolerate failures but also to bring down the hardware cost through engineering directly leading to a saving for the company. To the best of our knowledge this paper is the first attempt to study server failures and hardware repairs for large datacenters. We present a detailed analysis of failure characteristics as well as a preliminary analysis on failure predictors. We hope that the results presented in this paper will serve as motivation to foster further research in this area.;
Proceedings of the 1st ACM Symposium on Cloud Computing;"This paper presents Open Data Kit (ODK) an extensible open-source suite of tools designed to build information services for developing regions. ODK currently provides four tools to this end: Collect Aggregate Voice and Build. Collect is a mobile platform that renders application logic and supports the manipulation of data. Aggregate provides a click-to-deploy"" server that supports data storage and transfer in the ""cloud"" or on local servers. Voice renders application logic using phone prompts that users respond to with keypad presses. Finally Build is a application designer that generates the logic used by the tools. Designed to be used together or independently ODK core tools build on existing open standards and are supported by an open-source community that has contributed additional tools. We describe four deployments that demonstrate how the decisions made in the system architecture of ODK enable services that can both push and pull information in developing regions.""";
Proceedings of the 4th ACM/IEEE International Conference on Information and Communication Technologies and Development;"Geo-replicated distributed data stores that support complex online applications such as social networks must provide an always-on"" experience where operations always complete with low latency. Today's systems often sacrifice strong consistency to achieve these goals exposing inconsistencies to their clients and necessitating complex application logic. In this paper we identify and define a consistency model---causal consistency with convergent conflict handling or causal+---that is the strongest achieved under these constraints.We present the design and implementation of COPS a key-value store that delivers this consistency model across the wide-area. A key contribution of COPS is its scalability which can enforce causal dependencies between keys stored across an entire cluster rather than a single server like previous systems. The central approach in COPS is tracking and explicitly checking whether causal dependencies between keys are satisfied in the local cluster before exposing writes. Further in COPS-GT we introduce get transactions in order to obtain a consistent view of multiple keys without locking or blocking. Our evaluation shows that COPS completes operations in less than a millisecond provides throughput similar to previous systems when using one server per cluster and scales well as we increase the number of servers in each cluster. It also shows that COPS-GT provides similar latency throughput and scaling to COPS for common workloads.""";
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles;What is Mixed Reality (MR)? To revisit this question given the many recent developments we conducted interviews with ten AR/VR experts from academia and industry as well as a literature survey of 68 papers. We find that while there are prominent examples there is no universally agreed on one-size-fits-all definition of MR. Rather we identified six partially competing notions from the literature and experts' responses. We then started to isolate the different aspects of reality relevant for MR experiences going beyond the primarily visual notions and extending to audio motion haptics taste and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments number of users level of immersion level of virtuality degree of interaction input and output. Our goal with this paper is to support classification and discussion of MR applications' design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape.;
Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems;Bitcoin is a digital currency which relies on a distributed set of miners to mint coins and on a peer-to-peer network to broadcast transactions. The identities of Bitcoin users are hidden behind pseudonyms (public keys) which are recommended to be changed frequently in order to increase transaction unlinkability.We present an efficient method to deanonymize Bitcoin users which allows to link user pseudonyms to the IP addresses where the transactions are generated. Our techniques work for the most common and the most challenging scenario when users are behind NATs or firewalls of their ISPs. They allow to link transactions of a user behind a NAT and to distinguish connections and transactions of different users behind the same NAT. We also show that a natural countermeasure of using Tor or other anonymity services can be cut-off by abusing anti-DoS countermeasures of the Bitcoin network. Our attacks require only a few machines and have been experimentally verified. The estimated success rate is between 11% and 60% depending on how stealthy an attacker wants to be. We propose several countermeasures to mitigate these new attacks.;
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security;Although chip-multiprocessors have become the industry standard developing parallel applications that target them remains a daunting task. Non-determinism inherent in threaded applications causes significant challenges for parallel programmers by hindering their ability to create parallel applications with repeatable results. As a consequence parallel applications are significantly harder to debug test and maintain than sequential programs.This paper introduces Kendo: a new software-only system that provides deterministic multithreading of parallel applications. Kendo enforces a deterministic interleaving of lock acquisitions and specially declared non-protected reads through a novel dynamically load-balanced deterministic scheduling algorithm. The algorithm tracks the progress of each thread using performance counters to construct a deterministic logical time that is used to compute an interleaving of shared data accesses that is both deterministic and provides good load balancing. Kendo can run on today's commodity hardware while incurring only a modest performance cost. Experimental results on the SPLASH-2 applications yield a geometric mean overhead of only 16% when running on 4 processors. This low overhead makes it possible to benefit from Kendo even after an application is deployed. Programmers can start using Kendo today to program parallel applications that are easier to develop debug and test.;
Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems;The reliance on multi/many-core systems to satisfy the high performance requirement of complex embedded software applications is increasing. This necessitates the need to realize efficient mapping methodologies for such complex computing platforms. This paper provides an extensive survey and categorization of state-of-the-art mapping methodologies and highlights the emerging trends for multi/many-core systems. The methodologies aim at optimizing system's resource usage performance power consumption temperature distribution and reliability for varying application models. The methodologies perform design-time and run-time optimization for static and dynamic workload scenarios respectively. These optimizations are necessary to fulfill the end-user demands. Comparison of the methodologies based on their optimization aim has been provided. The trend followed by the methodologies and open research challenges have also been discussed.;
Proceedings of the 50th Annual Design Automation Conference;We examine two privacy controls for Android smartphones that empower users to run permission-hungry applications while protecting private data from being exfiltrated: (1) covertly substituting shadow data in place of data that the user wants to keep private and (2) blocking network transmissions that contain data the user made available to the application for on-device use only. We retrofit the Android operating system to implement these two controls for use with unmodified applications. A key challenge of imposing shadowing and exfiltration blocking on existing applications is that these controls could cause side effects that interfere with user-desired functionality. To measure the impact of side effects we develop an automated testing methodology that records screenshots of application executions both with and without privacy controls then automatically highlights the visual differences between the different executions. We evaluate our privacy controls on 50 applications from the Android Market selected from those that were both popular and permission-hungry. We find that our privacy controls can successfully reduce the effective permissions of the application without causing side effects for 66% of the tested applications. The remaining 34% of applications implemented user-desired functionality that required violating the privacy requirements our controls were designed to enforce there was an unavoidable choice between privacy and user-desired functionality.;
Proceedings of the 18th ACM Conference on Computer and Communications Security;Measuring bottleneck bandwidth and round-trip propagation time.;
Ability-Based Design: Concept Principles and Examples;Current approaches to accessible computing share a common goal of making technology accessible to users with disabilities. Perhaps because of this goal they may also share a tendency to centralize disability rather than ability. We present a refinement to these approaches called ability-based design that consists of focusing on ability throughout the design process in an effort to create systems that leverage the full range of human potential. Just as user-centered design shifted the focus of interactive system design from systems to users ability-based design attempts to shift the focus of accessible design from disability to ability. Although prior approaches to accessible computing may consider usersâ€™ abilities to some extent ability-based design makes ability its central focus. We offer seven ability-based design principles and describe the projects that inspired their formulation. We also present a research agenda for ability-based design.;
Internet traffic classification demystified: myths caveats and the best practices;Recent research on Internet traffic classification algorithms has yield a flurry of proposed approaches for distinguishing types of traffic but no systematic comparison of the various algorithms. This fragmented approach to traffic classification research leaves the operational community with no basis for consensus on what approach to use when and how to interpret results. In this work we critically revisit traffic classification by conducting a thorough evaluation of three classification approaches based on transport layer ports host behavior and flow features. A strength of our work is the broad range of data against which we test the three classification approaches: seven traces with payload collected in Japan Korea and the US. The diverse geographic locations link characteristics and application traffic mix in these data allowed us to evaluate the approaches under a wide variety of conditions. We analyze the advantages and limitations of each approach evaluate methods to overcome the limitations and extract insights and recommendations for both the study and practical application of traffic classification. We make our software classifiers and data available for researchers interested in validating or extending this work.;
Proceedings of the 2008 ACM CoNEXT Conference;In this paper we propose design strategies for persuasive technologies that help people who want to change their everyday behaviors. Our strategies use theory and prior work to substantially extend a set of existing design goals. Our extensions specifically account for social characteristics and other tactics that should be supported by persuasive technologies that target long-term discretionary use throughout everyday life. We used these strategies to design and build a system that encourages people to lead a physically active lifestyle. Results from two field studies of the system - a three-week trial and a three-month experiment - have shown that the system was successful at helping people maintain a more physically active lifestyle and validate the usefulness of the strategies.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;We revisit the problem of scaling software routers motivated by recent advances in server technology that enable high-speed parallel processing--a feature router workloads appear ideally suited to exploit. We propose a software router architecture that parallelizes router functionality both across multiple servers and across multiple cores within a single server. By carefully exploiting parallelism at every opportunity we demonstrate a 35Gbps parallel router prototype this router capacity can be linearly scaled through the use of additional servers. Our prototype router is fully programmable using the familiar Click/Linux environment and is built entirely from off-the-shelf general-purpose server hardware.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;We introduce tensor displays: a family of compressive light field displays comprising all architectures employing a stack of time-multiplexed light-attenuating layers illuminated by uniform or directional backlighting (i.e. any low-resolution light field emitter). We show that the light field emitted by an N-layer M-frame tensor display can be represented by an Nth-order rank-M tensor. Using this representation we introduce a unified optimization framework based on nonnegative tensor factorization (NTF) encompassing all tensor display architectures. This framework is the first to allow joint multilayer multiframe light field decompositions significantly reducing artifacts observed with prior multilayer-only and multiframe-only decompositions it is also the first optimization method for designs combining multiple layers with directional backlighting. We verify the benefits and limitations of tensor displays by constructing a prototype using modified LCD panels and a custom integral imaging backlight. Our efficient GPU-based NTF implementation enables interactive applications. Through simulations and experiments we show that tensor displays reveal practical architectures with greater depths of field wider fields of view and thinner form factors compared to prior automultiscopic displays.;
Deep API learning;Developers often wonder how to implement a certain functionality (e.g. how to parse XML files) using APIs. Obtaining an API usage sequence based on an API-related natural language query is very helpful in this regard. Given a query existing approaches utilize information retrieval models to search for matching API sequences. These approaches treat queries and APIs as bags-of-words and lack a deep understanding of the semantics of the query. We propose DeepAPI a deep learning based approach to generate API usage sequences for a given natural language query. Instead of a bag-of-words assumption it learns the sequence of words in a query and the sequence of associated APIs. DeepAPI adapts a neural language model named RNN Encoder-Decoder. It encodes a word sequence (user query) into a fixed-length context vector and generates an API sequence based on the context vector. We also augment the RNN Encoder-Decoder by considering the importance of individual APIs. We empirically evaluate our approach with more than 7 million annotated code snippets collected from GitHub. The results show that our approach generates largely accurate API sequences and outperforms the related approaches.;
Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering;We present Logically Qualified Data Types abbreviated to Liquid Types a system that combines Hindley-Milner type inference with Predicate Abstraction to automatically infer dependent types precise enough to prove a variety of safety properties. Liquid types allow programmers to reap many of the benefits of dependent types namely static verification of critical properties and the elimination of expensive run-time checks without the heavy price of manual annotation. We have implemented liquid type inference in DSOLVE which takes as input an OCAML program and a set of logical qualifiers and infers dependent types for the expressions in the OCAML program. To demonstrate the utility of our approach we describe experiments using DSOLVE to statically verify the safety of array accesses on a set of OCAML benchmarks that were previously annotated with dependent types as part of the DML project. We show that when used in conjunction with a fixed set of array bounds checking qualifiers DSOLVE reduces the amount of manual annotation required for proving safety from 31% of program text to under 1%.;
Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation;Static configurations serve great advantage for adversaries in discovering network targets and launching attacks. Identifying active IP addresses in a target domain is a precursory step for many attacks. Frequently changing hosts' IP addresses is a novel proactive moving target defense (MTD) that hides network assets from external/internal scanners. In this paper we use OpenFlow to develop a MTD architecture that transparently mutates host IP addresses with high unpredictability and rate while maintaining configuration integrity and minimizing operation overhead. The presented technique is called OpenFlow Random Host Mutation (OF-RHM) in which the OpenFlow controller frequently assigns each host a random virtual IP that is translated to/from the real IP of the host. The real IP remains untouched so IP mutation is completely transparent for end-hosts. Named hosts are reachable via the virtual IP addresses acquired via DNS but real IP addresses can be only reached by authorized entities. Our implementation and evaluation show that OF-RHM can effectively defend against stealthy scanning worm propagation and other scanning-based attack.;
Proceedings of the First Workshop on Hot Topics in Software Defined Networks;With the popularity of smartphones and mobile devices mobile application (a.k.a. â€œappâ€) markets have been growing exponentially in terms of number of users and downloads. App developers spend considerable effort on collecting and exploiting user feedback to improve user satisfaction but suffer from the absence of effective user review analytics tools. To facilitate mobile app developers discover the most â€œinformativeâ€ user reviews from a large and rapidly increasing pool of user reviews we present â€œAR-Minerâ€ â€” a novel computational framework for App Review Mining which performs comprehensive analytics from raw user reviews by (i) first extracting informative user reviews by filtering noisy and irrelevant ones (ii) then grouping the informative reviews automatically using topic modeling (iii) further prioritizing the informative reviews by an effective review ranking scheme (iv) and finally presenting the groups of most â€œinformativeâ€ reviews via an intuitive visualization approach. We conduct extensive experiments and case studies on four popular Android apps to evaluate AR-Miner from which the encouraging results indicate that AR-Miner is effective efficient and promising for app developers.;
Proceedings of the 36th International Conference on Software Engineering;We describe the architecture and prototype implementation of an assistive system based on Google Glass devices for users in cognitive decline. It combines the first-person image capture and sensing capabilities of Glass with remote processing to perform real-time scene interpretation. The system architecture is multi-tiered. It offers tight end-to-end latency bounds on compute-intensive operations while addressing concerns such as limited battery capacity and limited processing capability of wearable devices. The system gracefully degrades services in the face of network failures and unavailability of distant architectural tiers.;
Proceedings of the 12th Annual International Conference on Mobile Systems Applications and Services;A recent trojan attack on deep neural network (DNN) models is one insidious variant of data poisoning attacks. Trojan attacks exploit an effective backdoor created in a DNN model by leveraging the difficulty in interpretability of the learned model to misclassify any inputs signed with the attacker's chosen trojan trigger. Since the trojan trigger is a secret guarded and exploited by the attacker detecting such trojan inputs is a challenge especially at run-time when models are in active operation. This work builds &ltu&gtSTR&lt/u&gtong &ltu&gtI&lt/u&gtntentional &ltu&gtP&lt/u&gterturbation (STRIP) based run-time trojan attack detection system and focuses on vision system. We intentionally perturb the incoming input for instance by superimposing various image patterns and observe the randomness of predicted classes for perturbed inputs from a given deployed model---malicious or benign. A low entropy in predicted classes violates the input-dependence property of a benign model and implies the presence of a malicious input---a characteristic of a trojaned input. The high efficacy of our method is validated through case studies on three popular and contrasting datasets: MNIST CIFAR10 and GTSRB. We achieve an overall false acceptance rate (FAR) of less than 1% given a preset false rejection rate (FRR) of 1% for different types of triggers. Using CIFAR10 and GTSRB we have empirically achieved result of 0% for both FRR and FAR. We have also evaluated STRIP robustness against a number of trojan attack variants and adaptive attacks.;
Proceedings of the 35th Annual Computer Security Applications Conference;Return-oriented programming is an effective code-reuse attack in which short code sequences ending in a ret instruction are found within existing binaries and executed in arbitrary order by taking control of the stack. This allows for Turing-complete behavior in the target program without the need for injecting attack code thus significantly negating current code injection defense efforts (e.g. WâŠ•X). On the other hand its inherent characteristics such as the reliance on the stack and the consecutive execution of return-oriented gadgets have prompted a variety of defenses to detect or prevent it from happening.In this paper we introduce a new class of code-reuse attack called jump-oriented programming. This new attack eliminates the reliance on the stack and ret instructions (including ret-like instructions such as pop+jmp) seen in return-oriented programming without sacrificing expressive power. This attack still builds and chains functional gadgets each performing certain primitive operations except these gadgets end in an indirect branch rather than ret. Without the convenience of using ret to unify them the attack relies on a dispatcher gadget to dispatch and execute the functional gadgets. We have successfully identified the availability of these jump-oriented gadgets in the GNU libc library. Our experience with an example shellcode attack demonstrates the practicality and effectiveness of this technique.;
Proceedings of the 6th ACM Symposium on Information Computer and Communications Security;Looking past the systems people use they target the people using the systems.;
PIM-enabled instructions: a low-overhead locality-aware processing-in-memory architecture;Processing-in-memory (PIM) is rapidly rising as a viable solution for the memory wall crisis rebounding from its unsuccessful attempts in 1990s due to practicality concerns which are alleviated with recent advances in 3D stacking technologies. However it is still challenging to integrate the PIM architectures with existing systems in a seamless manner due to two common characteristics: unconventional programming models for in-memory computation units and lack of ability to utilize large on-chip caches.In this paper we propose a new PIM architecture that (1) does not change the existing sequential programming models and (2) automatically decides whether to execute PIM operations in memory or processors depending on the locality of data. The key idea is to implement simple in-memory computation using compute-capable memory commands and use specialized instructions which we call PIM-enabled instructions to invoke in-memory computation. This allows PIM operations to be interoperable with existing programming models cache coherence protocols and virtual memory mechanisms with no modification. In addition we introduce a simple hardware structure that monitors the locality of data accessed by a PIM-enabled instruction at runtime to adaptively execute the instruction at the host processor (instead of in memory) when the instruction can benefit from large on-chip caches. Consequently our architecture provides the illusion that PIM operations are executed as if they were host processor instructions.We provide a case study of how ten emerging data-intensive workloads can benefit from our new PIM abstraction and its hardware implementation. Evaluations show that our architecture significantly improves system performance and more importantly combines the best parts of conventional and PIM architectures by adapting to data locality of applications.;
Proceedings of the 42nd Annual International Symposium on Computer Architecture;Background: This paper describes an analysis that was conducted on newly collected repository with 92 versions of 38 proprietary open-source and academic projects. A preliminary study perfomed before showed the need for a further in-depth analysis in order to identify project clusters.Aims: The goal of this research is to perform clustering on software projects in order to identify groups of software projects with similar characteristic from the defect prediction point of view. One defect prediction model should work well for all projects that belong to such group. The existence of those groups was investigated with statistical tests and by comparing the mean value of prediction efficiency.Method: Hierarchical and k-means clustering as well as Kohonen's neural network was used to find groups of similar projects. The obtained clusters were investigated with the discriminant analysis. For each of the identified group a statistical analysis has been conducted in order to distinguish whether this group really exists. Two defect prediction models were created for each of the identified groups. The first one was based on the projects that belong to a given group and the second one - on all the projects. Then both models were applied to all versions of projects from the investigated group. If the predictions from the model based on projects that belong to the identified group are significantly better than the all-projects model (the mean values were compared and statistical tests were used) we conclude that the group really exists.Results: Six different clusters were identified and the existence of two of them was statistically proven: 1) cluster proprietary B -- T=19 p=0.035 r=0.40 2) cluster proprietary/open - t(17)=3.18 p=0.05 r=0.59. The obtained effect sizes (r) represent large effects according to Cohen's benchmark which is a substantial finding.Conclusions: The two identified clusters were described and compared with results obtained by other researchers. The results of this work makes next step towards defining formal methods of reuse defect prediction models by identifying groups of projects within which the same defect prediction model may be used. Furthermore a method of clustering was suggested and applied.;
Proceedings of the 6th International Conference on Predictive Models in Software Engineering;Fuzz testing has enjoyed great success at discovering security critical bugs in real software. Recently researchers have devoted significant effort to devising new fuzzing techniques strategies and algorithms. Such new ideas are primarily evaluated experimentally so an important question is: What experimental setup is needed to produce trustworthy results? We surveyed the recent research literature and assessed the experimental evaluations carried out by 32 fuzzing papers. We found problems in every evaluation we considered. We then performed our own extensive experimental evaluation using an existing fuzzer. Our results showed that the general problems we found in existing experimental evaluations can indeed translate to actual wrong or misleading assessments. We conclude with some guidelines that we hope will help improve experimental evaluations of fuzz testing algorithms making reported results more robust.;
Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security;In aerodynamics related design analysis and optimization problems flow fields are simulated using computational fluid dynamics (CFD) solvers. However CFD simulation is usually a computationally expensive memory demanding and time consuming iterative process. These drawbacks of CFD limit opportunities for design space exploration and forbid interactive design. We propose a general and flexible approximation model for real-time prediction of non-uniform steady laminar flow in a 2D or 3D domain based on convolutional neural networks (CNNs). We explored alternatives for the geometry representation and the network architecture of CNNs. We show that convolutional neural networks can estimate the velocity field two orders of magnitude faster than a GPU-accelerated CFD solver and four orders of magnitude faster than a CPU-based CFD solver at a cost of a low error rate. This approach can provide immediate feedback for real-time design iterations at the early stage of design. Compared with existing approximation models in the aerodynamics domain CNNs enable an efficient estimation for the entire velocity field. Furthermore designers and engineers can directly apply the CNN approximation model in their design space exploration algorithms without training extra lower-dimensional surrogate models.;
Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Non-intrusive load monitoring or energy disaggregation aims to separate household energy consumption data collected from a single point of measurement into appliance-level consumption data. In recent years the field has rapidly expanded due to increased interest as national deployments of smart meters have begun in many countries. However empirically comparing disaggregation algorithms is currently virtually impossible. This is due to the different data sets used the lack of reference implementations of these algorithms and the variety of accuracy metrics employed. To address this challenge we present the Non-intrusive Load Monitoring Toolkit (NILMTK) an open source toolkit designed specifically to enable the comparison of energy disaggregation algorithms in a reproducible manner. This work is the first research to compare multiple disaggregation approaches across multiple publicly available data sets. Our toolkit includes parsers for a range of existing data sets a collection of preprocessing algorithms a set of statistics for describing data sets two reference benchmark disaggregation algorithms and a suite of accuracy metrics. We demonstrate the range of reproducible analyses which are made possible by our toolkit including the analysis of six publicly available data sets and the evaluation of both benchmark disaggregation algorithms across such data sets.;
Proceedings of the 5th International Conference on Future Energy Systems;Automatic detection of diseases by use of computers is an important but still unexplored field of research. Such innovations may improve medical practice and refine health care systems all over the world. However datasets containing medical images are hardly available making reproducibility and comparison of approaches almost impossible. In this paper we present KVASIR a dataset containing images from inside the gastrointestinal (GI) tract. The collection of images are classified into three important anatomical landmarks and three clinically significant findings. In addition it contains two categories of images related to endoscopic polyp removal. Sorting and annotation of the dataset is performed by medical doctors (experienced endoscopists). In this respect KVASIR is important for research on both single- and multi-disease computer aided detection. By providing it we invite and enable multimedia researcher into the medical domain of detection and retrieval.;
Proceedings of the 8th ACM on Multimedia Systems Conference;Social networking sites have been increasingly gaining popularity. Well-known sites such as Facebook have been reporting growth rates as high as 3% per week. Many social networking sites have millions of registered users who use these sites to share photographs contact long-lost friends establish new business contacts and to keep in touch. In this paper we investigate how easy it would be for a potential attacker to launch automated crawling and identity theft attacks against a number of popular social networking sites in order to gain access to a large volume of personal user information. The first attack we present is the automated identity theft of existing user profiles and sending of friend requests to the contacts of the cloned victim. The hope from the attacker's point of view is that the contacted users simply trust and accept the friend request. By establishing a friendship relationship with the contacts of a victim the attacker is able to access the sensitive personal information provided by them. In the second more advanced attack we present we show that it is effective and feasible to launch an automated cross-site profile cloning attack. In this attack we are able to automatically create a forged profile in a network where the victim is not registered yet and contact the victim's friends who are registered on both networks. Our experimental results with real users show that the automated attacks we present are effective and feasible in practice.;
Proceedings of the 18th International Conference on World Wide Web;Digits is a wrist-worn sensor that recovers the full 3D pose of the user's hand. This enables a variety of freehand interactions on the move. The system targets mobile settings and is specifically designed to be low-power and easily reproducible using only off-the-shelf hardware. The electronics are self-contained on the user's wrist but optically image the entirety of the user's hand. This data is processed using a new pipeline that robustly samples key parts of the hand such as the tips and lower regions of each finger. These sparse samples are fed into new kinematic models that leverage the biomechanical constraints of the hand to recover the 3D pose of the user's hand. The proposed system works without the need for full instrumentation of the hand (for example using data gloves) additional sensors in the environment or depth cameras which are currently prohibitive for mobile scenarios due to power and form-factor considerations. We demonstrate the utility of Digits for a variety of application scenarios including 3D spatial interaction with mobile devices eyes-free interaction on-the-move and gaming. We conclude with a quantitative and qualitative evaluation of our system and discussion of strengths limitations and future work.;
Proceedings of the 25th Annual ACM Symposium on User Interface Software and Technology;Stress can have long term adverse effects on individuals' physical and mental well-being. Changes in the speech production process is one of many physiological changes that happen during stress. Microphones embedded in mobile phones and carried ubiquitously by people provide the opportunity to continuously and non-invasively monitor stress in real-life situations. We propose StressSense for unobtrusively recognizing stress from human voice using smartphones. We investigate methods for adapting a one-size-fits-all stress model to individual speakers and scenarios. We demonstrate that the StressSense classifier can robustly identify stress across multiple individuals in diverse acoustic environments: using model adaptation StressSense achieves 81% and 76% accuracy for indoor and outdoor environments respectively. We show that StressSense can be implemented on commodity Android phones and run in real-time. To the best of our knowledge StressSense represents the first system to consider voice based stress detection and model adaptation in diverse real-life conversational situations using smartphones.;
Proceedings of the 2012 ACM Conference on Ubiquitous Computing;"Since debugging is a time-consuming activity automated program repair tools such as GenProg have garnered interest. A recent study revealed that the majority of GenProg repairs avoid bugs simply by deleting functionality. We found that SPR a state-of-the-art repair tool proposed in 2015 still deletes functionality in their many plausible"" repairs. Unlike generate-and-validate systems such as GenProg and SPR semantic analysis based repair techniques synthesize a repair based on semantic information of the program. While such semantics-based repair methods show promise in terms of quality of generated repairs their scalability has been a concern so far. In this paper we present Angelix a novel semantics-based repair method that scales up to programs of similar size as are handled by search-based repair tools such as GenProg and SPR. This shows that Angelix is more scalable than previously proposed semantics based repair methods such as SemFix and DirectFix. Furthermore our repair method can repair multiple buggy locations that are dependent on each other. Such repairs are hard to achieve using SPR and GenProg. In our experiments Angelix generated repairs from large-scale real-world software such as wireshark and php and these generated repairs include multi-location repairs. We also report our experience in automatically repairing the well-known Heartbleed vulnerability.""";
Proceedings of the 38th International Conference on Software Engineering;Large volumes of event data are becoming increasingly available in a wide variety of applications such as healthcare analytics smart cities and social network analysis. The precise time interval or the exact distance between two events carries a great deal of information about the dynamics of the underlying systems. These characteristics make such data fundamentally different from independently and identically distributed data and time-series data where time and space are treated as indexes rather than random variables. Marked temporal point processes are the mathematical framework for modeling event data with covariates. However typical point process models often make strong assumptions about the generative processes of the event data which may or may not reflect the reality and the specifically fixed parametric assumptions also have restricted the expressive power of the respective processes. Can we obtain a more expressive model of marked temporal point processes? How can we learn such a model from massive data?In this paper we propose the Recurrent Marked Temporal Point Process (RMTPP) to simultaneously model the event timings and the markers. The key idea of our approach is to view the intensity function of a temporal point process as a nonlinear function of the history and use a recurrent neural network to automatically learn a representation of influences from the event history. We develop an efficient stochastic gradient algorithm for learning the model parameters which can readily scale up to millions of events. Using both synthetic and real world datasets we show that in the case where the true models have parametric specifications RMTPP can learn the dynamics of such models without the need to know the actual parametric forms and in the case where the true models are unknown RMTPP can also learn the dynamics and achieve better predictive performance than other parametric alternatives based on particular prior assumptions.;
Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Little is known about the duration and prevalence of zero-day attacks which exploit vulnerabilities that have not been disclosed publicly. Knowledge of new vulnerabilities gives cyber criminals a free pass to attack any target of their choosing while remaining undetected. Unfortunately these serious threats are difficult to analyze because in general data is not available until after an attack is discovered. Moreover zero-day attacks are rare events that are unlikely to be observed in honeypots or in lab experiments.In this paper we describe a method for automatically identifying zero-day attacks from field-gathered data that records when benign and malicious binaries are downloaded on 11 million real hosts around the world. Searching this data set for malicious files that exploit known vulnerabilities indicates which files appeared on the Internet before the corresponding vulnerabilities were disclosed. We identify 18 vulnerabilities exploited before disclosure of which 11 were not previously known to have been employed in zero-day attacks. We also find that a typical zero-day attack lasts 312 days on average and that after vulnerabilities are disclosed publicly the volume of attacks exploiting them increases by up to 5 orders of magnitude.;
Proceedings of the 2012 ACM Conference on Computer and Communications Security;"For more than thirty years the parallel programming community has used the dependence graph as the main abstraction for reasoning about and exploiting parallelism in regular"" algorithms that use dense arrays such as finite-differences and FFTs. In this paper we argue that the dependence graph is not a suitable abstraction for algorithms in new application areas like machine learning and network analysis in which the key data structures are ""irregular"" data structures like graphs trees and sets.To address the need for better abstractions we introduce a data-centric formulation of algorithms called the operator formulation in which an algorithm is expressed in terms of its action on data structures. This formulation is the basis for a structural analysis of algorithms that we call tao-analysis. Tao-analysis can be viewed as an abstraction of algorithms that distills out algorithmic properties important for parallelization. It reveals that a generalized form of data-parallelism called amorphous data-parallelism is ubiquitous in algorithms and that depending on the tao-structure of the algorithm this parallelism may be exploited by compile-time inspector-executor or optimistic parallelization thereby unifying these seemingly unrelated parallelization techniques. Regular algorithms emerge as a special case of irregular algorithms and many application-specific optimization techniques can be generalized to a broader context.These results suggest that the operator formulation and tao-analysis of algorithms can be the foundation of a systematic approach to parallel programming.""";
Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation;Computational thinking (CT) is broadly defined as the mental activity for abstracting problems and formulating solutions that can be automated. In an increasingly information-based society CT is becoming an essential skill for everyone. To ensure that students develop this ability at the K-12 level it is important to provide teachers with an adequate knowledge about CT and how to incorporate it into their teaching. This article describes a study on designing and introducing computational thinking modules and assessing their impact on preservice teachersâ€™ understanding of CT concepts as well as their attitude towards computing. Results demonstrate that introducing computational thinking into education courses can effectively influence preservice teachersâ€™ understanding of CT concepts.;
Towards automatically generating summary comments for Java methods;Studies have shown that good comments can help programmers quickly understand what a method does aiding program comprehension and software maintenance. Unfortunately few software projects adequately comment the code. One way to overcome the lack of human-written summary comments and guard against obsolete comments is to automatically generate them. In this paper we present a novel technique to automatically generate descriptive summary comments for Java methods. Given the signature and body of a method our automatic comment generator identifies the content for the summary and generates natural language text that summarizes the method's overall actions. According to programmers who judged our generated comments the summaries are accurate do not miss important content and are reasonably concise.;
Proceedings of the 25th IEEE/ACM International Conference on Automated Software Engineering;The high accuracy of deep neural networks (NNs) has led to the development of NN accelerators that improve performance by two orders of magnitude. However scaling these accelerators for higher performance with increasingly larger NNs exacerbates the cost and energy overheads of their memory systems including the on-chip SRAM buffers and the off-chip DRAM channels.This paper presents the hardware architecture and software scheduling and partitioning techniques for TETRIS a scalable NN accelerator using 3D memory. First we show that the high throughput and low energy characteristics of 3D memory allow us to rebalance the NN accelerator design using more area for processing elements and less area for SRAM buffers. Second we move portions of the NN computations close to the DRAM banks to decrease bandwidth pressure and increase performance and energy efficiency. Third we show that despite the use of small SRAM buffers the presence of 3D memory simplifies dataflow scheduling for NN computations. We present an analytical scheduling scheme that matches the efficiency of schedules derived through exhaustive search. Finally we develop a hybrid partitioning scheme that parallelizes the NN computations over multiple accelerators. Overall we show that TETRIS improves mthe performance by 4.1x and reduces the energy by 1.5x over NN accelerators with conventional low-power DRAM memory systems.;
Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems;Spanner is Googleâ€™s scalable multiversion globally distributed and synchronously replicated database. It is the first system to distribute data at global scale and support externally-consistent distributed transactions. This article describes how Spanner is structured its feature set the rationale underlying various design decisions and a novel time API that exposes clock uncertainty. This API and its implementation are critical to supporting external consistency and a variety of powerful features: nonblocking reads in the past lock-free snapshot transactions and atomic schema changes across all of Spanner.;
Old wine in new bottles or novel challenges: a critical analysis of empirical studies of user experience;This paper reviews how empirical research on User Experience (UX) is conducted. It integrates products dimensions of experience and methodologies across a systematically selected sample of 51 publications from 2005-2009 reporting a total of 66 empirical studies. Results show a shift in the products and use contexts that are studied from work towards leisure from controlled tasks towards open use situations and from desktop computing towards consumer products and art. Context of use and anticipated use often named key factors of UX are rarely researched. Emotions enjoyment and aesthetics are the most frequently assessed dimensions. The methodologies used are mostly qualitative and known from traditional usability studies though constructive methods with unclear validity are being developed and used. Many studies use self-developed questionnaires without providing items or statistical validations. We discuss underexplored research questions and potential improvements of UX research.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;To implement a program functionality developers can reuse previously written code snippets by searching through a large-scale codebase. Over the years many code search tools have been proposed to help developers. The existing approaches often treat source code as textual documents and utilize information retrieval models to retrieve relevant code snippets that match a given query. These approaches mainly rely on the textual similarity between source code and natural language query. They lack a deep understanding of the semantics of queries and source code.In this paper we propose a novel deep neural network named CODEnn (Code-Description Embedding Neural Network). Instead of matching text similarity CODEnn jointly embeds code snippets and natural language descriptions into a high-dimensional vector space in such a way that code snippet and its corresponding description have similar vectors. Using the unified vector representation code snippets related to a natural language query can be retrieved according to their vectors. Semantically related words can also be recognized and irrelevant/noisy keywords in queries can be handled.As a proof-of-concept application we implement a code search tool named DeepCS using the proposed CODEnn model. We empirically evaluate DeepCS on a large scale codebase collected from GitHub. The experimental results show that our approach can effectively retrieve relevant code snippets and outperforms previous techniques.;
Proceedings of the 40th International Conference on Software Engineering;We propose the first differentially private aggregation algorithm for distributed time-series data that offers good practical utility without any trusted server. This addresses two important challenges in participatory data-mining applications where (i) individual users collect temporally correlated time-series data (such as location traces web history personal health data) and (ii) an untrusted third-party aggregator wishes to run aggregate queries on the data.To ensure differential privacy for time-series data despite the presence of temporal correlation we propose the Fourier Perturbation Algorithm (FPAk). Standard differential privacy techniques perform poorly for time-series data. To answer n queries such techniques can result in a noise of Î˜(n) to each query answer making the answers practically useless if n is large. Our FPAk algorithm perturbs the Discrete Fourier Transform of the query answers. For answering n queries FPAk improves the expected error from Î˜(n) to roughly Î˜(k) where k is the number of Fourier coefficients that can (approximately) reconstruct all the n query answers. Our experiments show that k &lt&lt n for many real-life data-sets resulting in a huge error-improvement for FPAk.To deal with the absence of a trusted central server we propose the Distributed Laplace Perturbation Algorithm (DLPA) to add noise in a distributed way in order to guarantee differential privacy. To the best of our knowledge DLPA is the first distributed differentially private algorithm that can scale with a large number of users: DLPA outperforms the only other distributed solution for differential privacy proposed so far by reducing the computational load per user from O(U) to O(1) where U is the number of users.;
Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data;Recent research has demonstrated the feasibility of detecting human respiration rate non-intrusively leveraging commodity WiFi devices. However is it always possible to sense human respiration no matter where the subject stays and faces? What affects human respiration sensing and what's the theory behind? In this paper we first introduce the Fresnel model in free space then verify the Fresnel model for WiFi radio propagation in indoor environment. Leveraging the Fresnel model and WiFi radio propagation properties derived we investigate the impact of human respiration on the receiving RF signals and develop the theory to relate one's breathing depth location and orientation to the detectability of respiration. With the developed theory not only when and why human respiration is detectable using WiFi devices become clear it also sheds lights on understanding the physical limit and foundation of WiFi-based sensing systems. Intensive evaluations validate the developed theory and case studies demonstrate how to apply the theory to the respiration monitoring system design.;
Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing;The data in many disciplines such as social networks Web analysis etc. is link-based and the link structure can be exploited for many different data mining tasks. In this article we consider the problem of temporal link prediction: Given link data for times 1 through T can we predict the links at time T + 1? If our data has underlying periodic structure can we predict out even further in time i.e. links at time T + 2 T + 3 etc.? In this article we consider bipartite graphs that evolve over time and consider matrix- and tensor-based methods for predicting future links. We present a weight-based method for collapsing multiyear data into a single matrix. We show how the well-known Katz method for link prediction can be extended to bipartite graphs and moreover approximated in a scalable way using a truncated singular value decomposition. Using a CANDECOMP/PARAFAC tensor decomposition of the data we illustrate the usefulness of exploiting the natural three-dimensional structure of temporal link data. Through several numerical experiments we demonstrate that both matrix- and tensor-based techniques are effective for temporal link prediction despite the inherent difficulty of the problem. Additionally we show that tensor-based techniques are particularly effective for temporal data with varying periodic patterns.;
You've been warned: an empirical study of the effectiveness of web browser phishing warnings;Many popular web browsers are now including active phishing warnings after previous research has shown that passive warnings are often ignored. In this laboratory study we examine the effectiveness of these warnings and examine if how and why they fail users. We simulated a spear phishing attack to expose users to browser warnings. We found that 97% of our sixty participants fell for at least one of the phishing messages that we sent them. However we also found that when presented with the active warnings 79% of participants heeded them which was not the case for the passive warning that we tested---where only one participant heeded the warnings. Using a model from the warning sciences we analyzed how users perceive warning messages and offer suggestions for creating more effective warning messages within the phishing context.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;A research agenda for making the smart grid a reality.;
Greening geographical load balancing;"Energy expenditure has become a significant fraction of data center operating costs. Recently geographical load balancing"" has been suggested to reduce energy cost by exploiting the electricity price differences across regions. However this reduction of cost can paradoxically increase total energy use.This paper explores whether the geographical diversity of Internet-scale systems can additionally be used to provide environmental gains. Specifically we explore whether geographical load balancing can encourage use of ""green"" renewable energy and reduce use of ""brown"" fossil fuel energy. We make two contributions. First we derive two distributed algorithms for achieving optimal geographical load balancing. Second we show that if electricity is dynamically priced in proportion to the instantaneous fraction of the total energy that is brown then geographical load balancing provides significant reductions in brown energy use. However the benefits depend strongly on the degree to which systems accept dynamic energy pricing and the form of pricing used.""";
Proceedings of the ACM SIGMETRICS Joint International Conference on Measurement and Modeling of Computer Systems;An ideal datacenter network should provide several properties including low median and tail latency high utilization (throughput) fair allocation of network resources between users or applications deadline-aware scheduling and congestion (loss) avoidance. Current datacenter networks inherit the principles that went into the design of the Internet where packet transmission and path selection decisions are distributed among the endpoints and routers. Instead we propose that each sender should delegate control---to a centralized arbiter---of when each packet should be transmitted and what path it should follow.This paper describes Fastpass a datacenter network architecture built using this principle. Fastpass incorporates two fast algorithms: the first determines the time at which each packet should be transmitted while the second determines the path to use for that packet. In addition Fastpass uses an efficient protocol between the endpoints and the arbiter and an arbiter replication strategy for fault-tolerant failover. We deployed and evaluated Fastpass in a portion of Facebook's datacenter network. Our results show that Fastpass achieves high throughput comparable to current networks at a 240x reduction is queue lengths (4.35 Mbytes reducing to 18 Kbytes) achieves much fairer and consistent flow throughputs than the baseline TCP (5200x reduction in the standard deviation of per-flow throughput with five concurrent connections) scalability from 1 to 8 cores in the arbiter implementation with the ability to schedule 2.21 Terabits/s of traffic in software on eight cores and a 2.5x reduction in the number of TCP retransmissions in a latency-sensitive service at Facebook.;
Proceedings of the 2014 ACM Conference on SIGCOMM;Foveated rendering synthesizes images with progressively less detail outside the eye fixation region potentially unlocking significant speedups for wide field-of-view displays such as head mounted displays where target framerate and resolution is increasing faster than the performance of traditional real-time renderers.To study and improve potential gains we designed a foveated rendering user study to evaluate the perceptual abilities of human peripheral vision when viewing today's displays. We determined that filtering peripheral regions reduces contrast inducing a sense of tunnel vision. When applying a postprocess contrast enhancement subjects tolerated up to 2\texttimes{;
White space networking with wi-fi like connectivity;Networking over UHF white spaces is fundamentally different from conventional Wi-Fi along three axes: spatial variation temporal variation and fragmentation of the UHF spectrum. Each of these differences gives rise to new challenges for implementing a wireless network in this band. We present the design and implementation of Net7 the first Wi-Fi like system constructed on top of UHF white spaces. Net7 incorporates a new adaptive spectrum assignment algorithm to handle spectrum variation and fragmentation and proposes a low overhead protocol to handle temporal variation. builds on a simple technique called SIFT that reduces the time to detect transmissions in variable channel width systems by analyzing raw signals in the time domain. We provide an extensive evaluation of the system in terms of a prototype implementation and detailed experimental and simulation results.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;Smart contracts---stateful executable objects hosted on blockchains like Ethereum---carry billions of dollars worth of coins and cannot be updated once deployed. We present a new systematic characterization of a class of trace vulnerabilities which result from analyzing multiple invocations of a contract over its lifetime. We focus attention on three example properties of such trace vulnerabilities: finding contracts that either lock funds indefinitely leak them carelessly to arbitrary users or can be killed by anyone. We implemented Maian the first tool for specifying and reasoning about trace properties which employs interprocedural symbolic analysis and concrete validator for exhibiting real exploits. Our analysis of nearly one million contracts flags 34 200 (2 365 distinct) contracts vulnerable in 10 seconds per contract. On a subset of 3 759 contracts which we sampled for concrete validation and manual analysis we reproduce real exploits at a true positive rate of 89% yielding exploits for 3 686 contracts. Our tool finds exploits for the infamous Parity bug that indirectly locked $200 million US worth in Ether which previous analyses failed to capture.;
Proceedings of the 34th Annual Computer Security Applications Conference;"The Audio/Visual Emotion Challenge and Workshop (AVEC 2016) Depression Mood and Emotion"" will be the sixth competition event aimed at comparison of multimedia processing and machine learning methods for automatic audio visual and physiological depression and emotion analysis with all participants competing under strictly the same conditions. The goal of the Challenge is to provide a common benchmark test set for multi-modal information processing and to bring together the depression and emotion recognition communities as well as the audio video and physiological processing communities to compare the relative merits of the various approaches to depression and emotion recognition under well-defined and strictly comparable conditions and establish to what extent fusion of the approaches is possible and beneficial. This paper presents the challenge guidelines the common data used and the performance of the baseline system on the two tasks.""";
Proceedings of the 6th International Workshop on Audio/Visual Emotion Challenge;"A goal in cloud computing is to allocate (and thus pay for) only those cloud resources that are truly needed. To date cloud practitioners have pursued schedule-based (e.g. time-of-day) and rule-based mechanisms to attempt to automate this matching between computing requirements and computing resources. However most of these auto-scaling"" mechanisms only support simple resource utilization indicators and do not specifically consider both user performance requirements and budget concerns. In this paper we present an approach whereby the basic computing elements are virtual machines (VMs) of various sizes/costs jobs are specified as workflows users specify performance requirements by assigning (soft) deadlines to jobs and the goal is to ensure all jobs are finished within their deadlines at minimum financial cost. We accomplish our goal by dynamically allocating/deallocating VMs and scheduling tasks on the most cost-efficient instances. We evaluate our approach in four representative cloud workload patterns and show cost savings from 9.8% to 40.4% compared to other approaches.""";
Proceedings of 2011 International Conference for High Performance Computing Networking Storage and Analysis;Many Android apps have a legitimate need to communicate over the Internet and are then responsible for protecting potentially sensitive data during transit. This paper seeks to better understand the potential security threats posed by benign Android apps that use the SSL/TLS protocols to protect data they transmit. Since the lack of visual security indicators for SSL/TLS usage and the inadequate use of SSL/TLS can be exploited to launch Man-in-the-Middle (MITM) attacks an analysis of 13500 popular free apps downloaded from Google's Play Market is presented. We introduce MalloDroid a tool to detect potential vulnerability against MITM attacks. Our analysis revealed that 1074 (8.0%) of the apps examined contain SSL/TLS code that is potentially vulnerable to MITM attacks. Various forms of SSL/TLS misuse were discovered during a further manual audit of 100 selected apps that allowed us to successfully launch MITM attacks against 41 apps and gather a large variety of sensitive data. Furthermore an online survey was conducted to evaluate users' perceptions of certificate warnings and HTTPS visual security indicators in Android's browser showing that half of the 754 participating users were not able to correctly judge whether their browser session was protected by SSL/TLS or not. We conclude by considering the implications of these findings and discuss several countermeasures with which these problems could be alleviated.;
Proceedings of the 2012 ACM Conference on Computer and Communications Security;We propose a novel latent factor model to accurately predict response for large scale dyadic data in the presence of features. Our approach is based on a model that predicts response as a multiplicative function of row and column latent factors that are estimated through separate regressions on known row and column features. In fact our model provides a single unified framework to address both cold and warm start scenarios that are commonplace in practical applications like recommender systems online advertising web search etc. We provide scalable and accurate model fitting methods based on Iterated Conditional Mode and Monte Carlo EM algorithms. We show our model induces a stochastic process on the dyadic space with kernel (covariance) given by a polynomial function of features. Methods that generalize our procedure to estimate factors in an online fashion for dynamic applications are also considered. Our method is illustrated on benchmark datasets and a novel content recommendation application that arises in the context of Yahoo! Front Page. We report significant improvements over several commonly used methods on all datasets.;
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Since the electricity bill of a data center constitutes a significant portion of its overall operational costs reducing this has become important. We investigate cost reduction opportunities that arise by the use of uninterrupted power supply (UPS) units as energy storage devices. This represents a deviation from the usual use of these devices as mere transitional fail-over mechanisms between utility and captive sources such as diesel generators. We consider the problem of opportunistically using these devices to reduce the time average electric utility bill in a data center. Using the technique of Lyapunov optimization we develop an online control algorithm that can optimally exploit these devices to minimize the time average cost. This algorithm operates without any knowledge of the statistics of the workload or electricity cost processes making it attractive in the presence of workload and pricing uncertainties. An interesting feature of our algorithm is that its deviation from optimality reduces as the storage capacity is increased. Our work opens up a new area in data center power management.;
Proceedings of the ACM SIGMETRICS Joint International Conference on Measurement and Modeling of Computer Systems;Suppose that one observes an incomplete subset of entries selected from a low-rank matrix. When is it possible to complete the matrix and recover the entries that have not been seen? We demonstrate that in very general settings one can perfectly recover all of the missing entries from most sufficiently large subsets by solving a convex programming problem that finds the matrix with the minimum nuclear norm agreeing with the observed entries. The techniques used in this analysis draw upon parallels in the field of compressed sensing demonstrating that objects other than signals and images can be perfectly reconstructed from very limited information.;
Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Despite a decade of active research there has been a marked lack in clone detection techniques that scale to large repositories for detecting near-miss clones. In this paper we present a token-based clone detector SourcererCC that can detect both exact and near-miss clones from large inter-project repositories using a standard workstation. It exploits an optimized inverted-index to quickly query the potential clones of a given code block. Filtering heuristics based on token ordering are used to significantly reduce the size of the index the number of code-block comparisons needed to detect the clones as well as the number of required token-comparisons needed to judge a potential clone. We evaluate the scalability execution time recall and precision of SourcererCC and compare it to four publicly available and state-of-the-art tools. To measure recall we use two recent benchmarks: (1) a big benchmark of real clones BigCloneBench and (2) a Mutation/Injection-based framework of thousands of fine-grained artificial clones. We find SourcererCC has both high recall and precision and is able to scale to a large inter-project repository (25K projects 250MLOC) using a standard workstation.;
Proceedings of the 38th International Conference on Software Engineering;Logs are widely used by large and complex software-intensive systems for troubleshooting. There have been a lot of studies on log-based anomaly detection. To detect the anomalies the existing methods mainly construct a detection model using log event data extracted from historical logs. However we find that the existing methods do not work well in practice. These methods have the close-world assumption which assumes that the log data is stable over time and the set of distinct log events is known. However our empirical study shows that in practice log data often contains previously unseen log events or log sequences. The instability of log data comes from two sources: 1) the evolution of logging statements and 2) the processing noise in log data. In this paper we propose a new log-based anomaly detection approach called LogRobust. LogRobust extracts semantic information of log events and represents them as semantic vectors. It then detects anomalies by utilizing an attention-based Bi-LSTM model which has the ability to capture the contextual information in the log sequences and automatically learn the importance of different log events. In this way LogRobust is able to identify and handle unstable log events and sequences. We have evaluated LogRobust using logs collected from the Hadoop system and an actual online service system of Microsoft. The experimental results show that the proposed approach can well address the problem of log instability and achieve accurate and robust results on real-world ever-changing log data.;
Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Mood disorders are inherently related to emotion. In particular the behaviour of people suffering from mood disorders such as unipolar depression shows a strong temporal correlation with the affective dimensions valence and arousal. In addition psychologists and psychiatrists take the observation of expressive facial and vocal cues into account while evaluating a patient's condition. Depression could result in expressive behaviour such as dampened facial expressions avoiding eye contact and using short sentences with flat intonation. It is in this context that we present the third Audio-Visual Emotion recognition Challenge (AVEC 2013). The challenge has two goals logically organised as sub-challenges: the first is to predict the continuous values of the affective dimensions valence and arousal at each moment in time. The second sub-challenge is to predict the value of a single depression indicator for each recording in the dataset. This paper presents the challenge guidelines the common data used and the performance of the baseline system on the two tasks.;
Proceedings of the 3rd ACM International Workshop on Audio/Visual Emotion Challenge;Given the increasing complexity of modern electronics and the cost of fabrication entities from around the globe have become more heavily involved in all phases of the electronics supply chain. In this environment hardware Trojans (i.e. malicious modifications or inclusions made by untrusted third parties) pose major security concerns especially for those integrated circuits (ICs) and systems used in critical applications and cyber infrastructure. While hardware Trojans have been explored significantly in academia over the last decade there remains room for improvement. In this article we examine the research on hardware Trojans from the last decade and attempt to capture the lessons learned. A comprehensive adversarial model taxonomy is introduced and used to examine the current state of the art. Then the past countermeasures and publication trends are categorized based on the adversarial model and topic. Through this analysis we identify what has been covered and the important problems that are underinvestigated. We also identify the most critical lessons for those new to the field and suggest a roadmap for future hardware Trojan research.;
Overshadow: a virtualization-based approach to retrofitting protection in commodity operating systems;"Commodity operating systems entrusted with securing sensitive data are remarkably large and complex and consequently frequently prone to compromise. To address this limitation we introduce a virtual-machine-based system called Overshadow that protects the privacy and integrity of application data even in the event of a total OScompromise. Overshadow presents an application with a normal view of its resources but the OS with an encrypted view. This allows the operating system to carry out the complex task of managing an application's resources without allowing it to read or modify them. Thus Overshadow offers a last line of defense for application data.Overshadow builds on multi-shadowing a novel mechanism that presents different views of physical"" memory depending on the context performing the access. This primitive offers an additional dimension of protection beyond the hierarchical protection domains implemented by traditional operating systems and processor architectures.We present the design and implementation of Overshadow and show how its new protection semantics can be integrated with existing systems. Our design has been fully implemented and used to protect a wide range of unmodified legacy applications running on an unmodified Linux operating system. We evaluate the performance of our implementation demonstrating that this approach is practical.""";
Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems;With the advent of instant mobile messaging applications traditional SMS is in danger of loosing it's reign as the king of mobile messaging. Applications like WhatsApp allow mobile users to send real-time text messages to individuals or groups of friends at no cost. While there is a vast body of research on traditional text messaging practices little is understood about how and why people have adopted and appropriated instant mobile messaging applications. The goal of this work is to provide a deeper understanding of the motives and perceptions of a popular mobile messaging application called WhatsApp and to learn more about what this service offers above and beyond traditional SMS. To this end we present insights from two studies an interview study and a large-scale survey highlighting that while WhatsApp offers benefits such as cost sense of community and immediacy SMS is still considered a more reliable privacy preserving technology for mobile communication.;
Proceedings of the 15th International Conference on Human-Computer Interaction with Mobile Devices and Services;We present RF-Capture a system that captures the human figure -- i.e. a coarse skeleton -- through a wall. RF-Capture tracks the 3D positions of a person's limbs and body parts even when the person is fully occluded from its sensor and does so without placing any markers on the subject's body. In designing RF-Capture we built on recent advances in wireless research which have shown that certain radio frequency (RF) signals can traverse walls and reflect off the human body allowing for the detection of human motion through walls. In contrast to these past systems which abstract the entire human body as a single point and find the overall location of that point through walls we show how we can reconstruct various human body parts and stitch them together to capture the human figure. We built a prototype of RF-Capture and tested it on 15 subjects. Our results show that the system can capture a representative human figure through walls and use it to distinguish between various users.;
TraCI: an interface for coupling road traffic and network simulators;Vehicular Ad-Hoc Networks (VANETs) enable communication among vehicles as well as between vehicles and roadside infrastructures. Currently available software tools for VANET research still lack the ability to asses the usability of vehicular applications. In this article we present &ltu&gtTra&lt/u&gtffic &ltu&gtC&lt/u&gtontrol &ltu&gtI&lt/u&gtnterface (TraCI) a technique for interlinking road traffic and network simulators. It permits us to control the behavior of vehicles during simulation runtime and consequently to better understand the influence of VANET applications on traffic patterns.In contrast to the existing approaches i.e. generating mobility traces that are fed to a network simulator as static input files the online coupling allows the adaptation of drivers' behavior during simulation runtime. This technique is not limited to a special traffic simulator or to a special network simulator. We introduce a general framework for controlling the mobility which is adaptable towards other research areas.We describe the basic concept design decisions and the message format of this open-source architecture. Additionally we provide implementations for non-commercial traffic and network simulators namely SUMO and ns2 respectively. This coupling enables for the first time systematic evaluations of VANET applications in realistic settings.;
Proceedings of the 11th Communications and Networking Simulation Symposium;Current practice in Human Computer Interaction as encouraged by educational institutes academic review processes and institutions with usability groups advocate usability evaluation as a critical part of every design process. This is for good reason: usability evaluation has a significant role to play when conditions warrant it. Yet evaluation can be ineffective and even harmful if naively done 'by rule' rather than 'by thought'. If done during early stage design it can mute creative ideas that do not conform to current interface norms. If done to test radical innovations the many interface issues that would likely arise from an immature technology can quash what could have been an inspired vision. If done to validate an academic prototype it may incorrectly suggest a design's scientific worthiness rather than offer a meaningful critique of how it would be adopted and used in everyday practice. If done without regard to how cultures adopt technology over time then today's reluctant reactions by users will forestall tomorrow's eager acceptance. The choice of evaluation methodology - if any - must arise from and be appropriate for the actual problem or research question under consideration.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Convolutional neural networks (CNN) applications range from recognition and reasoning (such as handwriting recognition facial expression recognition and video surveillance) to intelligent text applications such as semantic text analysis and natural language processing applications. Two key observations drive the design of a new architecture for CNN. First CNN workloads exhibit a widely varying mix of three types of parallelism: parallelism within a convolution operation intra-output parallelism where multiple input sources (features) are combined to create a single output and inter-output parallelism where multiple independent outputs (features) are computed simultaneously. Workloads differ significantly across different CNN applications and across different layers of a CNN. Second the number of processing elements in an architecture continues to scale (as per Moore's law) much faster than off-chip memory bandwidth (or pin-count) of chips. Based on these two observations we show that for a given number of processing elements and off-chip memory bandwidth a new CNN hardware architecture that dynamically configures the hardware on-the-fly to match the specific mix of parallelism in a given workload gives the best throughput performance. Our CNN compiler automatically translates high abstraction network specification into a parallel microprogram (a sequence of low-level VLIW instructions) that is mapped scheduled and executed by the coprocessor. Compared to a 2.3 GHz quad-core dual socket Intel Xeon 1.35 GHz C870 GPU and a 200 MHz FPGA implementation our 120 MHz dynamically configurable architecture is 4x to 8x faster. This is the first CNN architecture to achieve real-time video stream processing (25 to 30 frames per second) on a wide range of object detection and recognition tasks.;
Proceedings of the 37th Annual International Symposium on Computer Architecture;This paper presents SoftRate a wireless bit rate adaptation protocol that is responsive to rapidly varying channel conditions. Unlike previous work that uses either frame receptions or signal-to-noise ratio (SNR) estimates to select bit rates SoftRate uses confidence information calculated by the physical layer and exported to higher layers via the SoftPHY interface to estimate the prevailing channel bit error rate (BER). Senders use this BER estimate calculated over each received packet (even when the packet has no bit errors) to pick good bit rates. SoftRate's novel BER computation works across different wireless environments and hardware without requiring any retraining. SoftRate also uses abrupt changes in the BER estimate to identify interference enabling it to reduce the bit rate only in response to channel errors caused by attenuation or fading. Our experiments conducted using a software radio prototype show that SoftRate achieves 2X higher throughput than popular frame-level protocols such as SampleRate and RRAA. It also achieves 20% more throughput than an SNR-based protocol trained on the operating environment and up to 4X higher throughput than an untrained SNR-based protocol. The throughput gains using SoftRate stem from its ability to react to channel variations within a single packet-time and its robustness to collision losses.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;Most existing Augmented Reality (AR) and Mixed Reality (MR) systems are able to understand the 3D geometry of the surroundings but lack the ability to detect and classify complex objects in the real world. Such capabilities can be enabled with deep Convolutional Neural Networks (CNN) but it remains difficult to execute large networks on mobile devices. Offloading object detection to the edge or cloud is also very challenging due to the stringent requirements on high detection accuracy and low end-to-end latency. The long latency of existing offloading techniques can significantly reduce the detection accuracy due to changes in the user's view. To address the problem we design a system that enables high accuracy object detection for commodity AR/MR system running at 60fps. The system employs low latency offloading techniques decouples the rendering pipeline from the offloading pipeline and uses a fast object tracking method to maintain detection accuracy. The result shows that the system can improve the detection accuracy by 20.2%-34.8% for the object detection and human keypoint detection tasks and only requires 2.24ms latency for object tracking on the AR device. Thus the system leaves more time and computational resources to render virtual elements for the next frame and enables higher quality AR/MR experiences.;
The 25th Annual International Conference on Mobile Computing and Networking;Location information is an important source of context for ubiquitous computing systems. This paper looks at how a foot-mounted inertial unit a detailed building model and a particle filter can be combined to provide absolute positioning despite the presence of drift in the inertial unit and without knowledge of the user's initial location. We show how to handle multiple floors and stairways how to handle symmetry in the environment and how to initialise the localisation algorithm using WiFi signal strength to reduce initial complexity.We evaluate the entire system experimentally using an independent tracking system for ground truth. Our results show that we can track a user throughout a 8725 m2 building spanning three floors to within 0.5m 75% of the time and to within 0.73 m 95% of the time.;
Proceedings of the 10th International Conference on Ubiquitous Computing;The majority of recommender systems are designed to make recommendations for individual users. However in some circumstances the items to be selected are not intended for personal usage but for a group e.g. a DVD could be watched by a group of friends. In order to generate effective recommendations for a group the system must satisfy as much as possible the individual preferences of the group's members.This paper analyzes the effectiveness of group recommendations obtained aggregating the individual lists of recommendations produced by a collaborative filtering system. We compare the effectiveness of individual and group recommendation lists using normalized discounted cumulative gain. It is observed that the effectiveness of a group recommendation does not necessarily decrease when the group size grows. Moreover when individual recommendations are not effective a user could obtain better suggestions looking at the group recommendations. Finally it is shown that the more alike the users in the group are the more effective the group recommendations are.;
Proceedings of the Fourth ACM Conference on Recommender Systems;Tracking human vital signs of breathing and heart rates during sleep is important as it can help to assess the general physical health of a person and provide useful clues for diagnosing possible diseases. Traditional approaches (e.g. Polysomnography (PSG)) are limited to clinic usage. Recent radio frequency (RF) based approaches require specialized devices or dedicated wireless sensors and are only able to track breathing rate. In this work we propose to track the vital signs of both breathing rate and heart rate during sleep by using off-the-shelf WiFi without any wearable or dedicated devices. Our system re-uses existing WiFi network and exploits the fine-grained channel information to capture the minute movements caused by breathing and heart beats. Our system thus has the potential to be widely deployed and perform continuous long-term monitoring. The developed algorithm makes use of the channel information in both time and frequency domain to estimate breathing and heart rates and it works well when either individual or two persons are in bed. Our extensive experiments demonstrate that our system can accurately capture vital signs during sleep under realistic settings and achieve comparable or even better performance comparing to traditional and existing approaches which is a strong indication of providing non-invasive continuous fine-grained vital signs monitoring without any additional cost.;
Proceedings of the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing;Android is the first mass-produced consumer-market open source mobile platform that allows developers to easily create applications and users to readily install them. However giving users the ability to install third-party applications poses serious security concerns. While the existing security mechanism in Android allows a mobile phone user to see which resources an application requires she has no choice but to allow access to all the requested permissions if she wishes to use the applications. There is no way of granting some permissions and denying others. Moreover there is no way of restricting the usage of resources based on runtime constraints such as the location of the device or the number of times a resource has been previously used. In this paper we present Apex -- a policy enforcement framework for Android that allows a user to selectively grant permissions to applications as well as impose constraints on the usage of resources. We also describe an extended package installer that allows the user to set these constraints through an easy-to-use interface. Our enforcement framework is implemented through a minimal change to the existing Android code base and is backward compatible with the current security mechanism.;
Proceedings of the 5th ACM Symposium on Information Computer and Communications Security;This paper describes Scratch a visual block-based programming language designed to facilitate media manipulation for novice programmers. We report on the Scratch programming experiences of urban youth ages 8-18 at a Computer Clubhouse 'an after school center' over an 18-month period. Our analyses of 536 Scratch projects collected during this time documents the learning of key programming concepts even in the absence of instructional interventions or experienced mentors. We discuss the motivations of urban youth who choose to program in Scratch rather than using one of the many other software packages available to them and the implications for introducing programming at after school settings in underserved communities.;
Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education;Processing-in-memory (PIM) provides high bandwidth massive parallelism and high energy efficiency by implementing computations in main memory therefore eliminating the overhead of data movement between CPU and memory. While most of the recent work focused on PIM in DRAM memory with 3D die-stacking technology we propose to leverage the unique features of emerging non-volatile memory (NVM) such as resistance-based storage and current sensing to enable efficient PIM design in NVM. We propose Pinatubo1 a &ltu&gtP&lt/u&gtrocessing &ltu&gtI&lt/u&gtn &ltu&gtN&lt/u&gton-volatile memory &ltu&gtA&lt/u&gtrchi&ltu&gtT&lt/u&gtecture for b&ltu&gtU&lt/u&gtlk &ltu&gtB&lt/u&gtitwise &ltu&gtO&lt/u&gtperations. Instead of integrating complex logic inside the cost-sensitive memory Pinatubo redesigns the read circuitry so that it can compute the bitwise logic of two or more memory rows very efficiently and support one-step multi-row operations. The experimental results on data intensive graph processing and database applications show that Pinatubo achieves a ~500\texttimes{;
Proceedings of the 53rd Annual Design Automation Conference;Phase-Change Memory (PCM) technology has received substantial attention recently. Because PCM is byte-addressable and exhibits access times in the nanosecond range it can be used in main memory designs. In fact PCM has higher density and lower idle power consumption than DRAM. Unfortunately PCM is also slower than DRAM and has limited endurance. For these reasons researchers have proposed memory systems that combine a small amount of DRAM and a large amount of PCM. In this paper we propose a new hybrid design that features a hardware-driven page placement policy. The policy relies on the memory controller (MC) to monitor access patterns migrate pages between DRAM and PCM and translate the memory addresses coming from the cores. Periodically the operating system updates its page mappings based on the translation information used by the MC. Detailed simulations of 27 workloads show that our system is more robust and exhibits lower energy-delay2 than state-of-the-art hybrid systems.;
Proceedings of the International Conference on Supercomputing;This paper analyzes a Question &amp Answer site for programmers Stack Overflow that dramatically improves on the utility and performance of Q&ampA systems for technical domains. Over 92% of Stack Overflow questions about expert topics are answered - in a median time of 11 minutes. Using a mixed methods approach that combines statistical data analysis with user interviews we seek to understand this success. We argue that it is not primarily due to an a priori superior technical design but also to the high visibility and daily involvement of the design team within the community they serve. This model of continued community leadership presents challenges to both CSCW systems research as well as to attempts to apply the Stack Overflow model to other specialized knowledge domains.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Driven by the need to cope with exponentially growing mobile data traffic and to support new traffic types from massive numbers of machine-type devices academia and industry are thinking beyond the current generation of mobile cellular networks to chalk a path towards fifth generation (5G) mobile networks. Several new approaches and technologies are being considered as potential elements making up such a future mobile network including cloud RANs application of SDN principles exploiting new and unused portions of spectrum use of massive MIMO and full-duplex communications. Research on these technologies requires realistic and flexible experimentation platforms that offer a wide range of experimentation modes from real-world experimentation to controlled and scalable evaluations while at the same time retaining backward compatibility with current generation systems. Towards this end we present OpenAirInterface (OAI) as a suitably flexible platform. In addition we discuss the use of OAI in the context of several widely mentioned 5G research directions.;
A type and effect system for deterministic parallel Java;Today's shared-memory parallel programming models are complex and error-prone.While many parallel programs are intended to be deterministic unanticipated thread interleavings can lead to subtle bugs and nondeterministic semantics. In this paper we demonstrate that a practical type and effect system can simplify parallel programming by guaranteeing deterministic semantics with modular compile-time type checking even in a rich concurrent object-oriented language such as Java. We describe an object-oriented type and effect system that provides several new capabilities over previous systems for expressing deterministic parallel algorithms.We also describe a language called Deterministic Parallel Java (DPJ) that incorporates the new type system features and we show that a core subset of DPJ is sound. We describe an experimental validation showing thatDPJ can express a wide range of realistic parallel programs that the new type system features are useful for such programs and that the parallel programs exhibit good performance gains (coming close to or beating equivalent nondeterministic multithreaded programs where those are available).;
Proceedings of the 24th ACM SIGPLAN Conference on Object Oriented Programming Systems Languages and Applications;In this paper we describe a GPU parallelization of the 3D finite difference computation using CUDA. Data access redundancy is used as the metric to determine the optimal implementation for both the stencil-only computation as well as the discretization of the wave equation which is currently of great interest in seismic computing. For the larger stencils the described approach achieves the throughput of between 2400 to over 3000 million of output points per second on a single Tesla 10-series GPU. This is roughly an order of magnitude higher than a 4-core Harpertown CPU running a similar code from seismic industry. Multi-GPU parallelization is also described achieving linear scaling with GPUs by overlapping inter-GPU communication with computation.;
Proceedings of 2nd Workshop on General Purpose Processing on Graphics Processing Units;Driven by a wide range of real-world applications significant efforts have recently been made to explore device-free human activity recognition techniques that utilize the information collected by various wireless infrastructures to infer human activities without the need for the monitored subject to carry a dedicated device. Existing device free human activity recognition approaches and systems though yielding reasonably good performance in certain cases are faced with a major challenge. The wireless signals arriving at the receiving devices usually carry substantial information that is specific to the environment where the activities are recorded and the human subject who conducts the activities. Due to this reason an activity recognition model that is trained on a specific subject in a specific environment typically does not work well when being applied to predict another subject's activities that are recorded in a different environment. To address this challenge in this paper we propose EI a deep-learning based device free activity recognition framework that can remove the environment and subject specific information contained in the activity data and extract environment/subject-independent features shared by the data collected on different subjects under different environments. We conduct extensive experiments on four different device free activity recognition testbeds: WiFi ultrasound 60 GHz mmWave and visible light. The experimental results demonstrate the superior effectiveness and generalizability of the proposed EI framework.;
Proceedings of the 24th Annual International Conference on Mobile Computing and Networking;Cell phone cameras have small apertures which limits the number of photons they can gather leading to noisy images in low light. They also have small sensor pixels which limits the number of electrons each pixel can store leading to limited dynamic range. We describe a computational photography pipeline that captures aligns and merges a burst of frames to reduce noise and increase dynamic range. Our system has several key features that help make it robust and efficient. First we do not use bracketed exposures. Instead we capture frames of constant exposure which makes alignment more robust and we set this exposure low enough to avoid blowing out highlights. The resulting merged image has clean shadows and high bit depth allowing us to apply standard HDR tone mapping methods. Second we begin from Bayer raw frames rather than the demosaicked RGB (or YUV) frames produced by hardware Image Signal Processors (ISPs) common on mobile platforms. This gives us more bits per pixel and allows us to circumvent the ISP's unwanted tone mapping and spatial denoising. Third we use a novel FFT-based alignment algorithm and a hybrid 2D/3D Wiener filter to denoise and merge the frames in a burst. Our implementation is built atop Android's Camera2 API which provides per-frame camera control and access to raw imagery and is written in the Halide domain-specific language (DSL). It runs in 4 seconds on device (for a 12 Mpix image) requires no user intervention and ships on several mass-produced cell phones.;
Unsafe exposure analysis of mobile in-app advertisements;"In recent years there has been explosive growth in smartphone sales which is accompanied with the availability of a huge number of smartphone applications (or simply apps). End users or consumers are attracted by the many interesting features offered by these devices and the associated apps. The developers of these apps are also benefited by the prospect of financial compensation either by selling their apps directly or by embedding one of the many ad libraries available on smartphone platforms. In this paper we focus on potential privacy and security risks posed by these embedded or in-app advertisement libraries (henceforth ad libraries"" for brevity). To this end we study the popular Android platform and collect 100000 apps from the official Android Market in March-May 2011. Among these apps we identify 100 representative in-app ad libraries (embedded in 52.1% of them) and further develop a system called AdRisk to systematically identify potential risks. In particular we first decouple the embedded ad libraries from host apps and then apply our system to statically examine the ad libraries ranging from whether they will upload privacy-sensitive information to remote (ad) servers or whether they will download untrusted code from remote servers. Our results show that most existing ad libraries collect private information: some of them may be used for legitimate targeting purposes (i.e. the user's location) while others are hard to justify by invasively collecting the information such as the user's call logs phone number browser bookmarks or even the list of installed apps on the phone. Moreover additional ones go a step further by making use of an unsafe mechanism to directly fetch and run code from the Internet which immediately leads to serious security risks. Our investigation indicates the symbiotic relationship between embedded ad libraries and host apps is one main reason behind these exposed risks. These results clearly show the need for better regulating the way ad libraries are integrated in Android apps.""";
Proceedings of the Fifth ACM Conference on Security and Privacy in Wireless and Mobile Networks;We present Masstree a fast key-value database designed for SMP machines. Masstree keeps all data in memory. Its main data structure is a trie-like concatenation of B+-trees each of which handles a fixed-length slice of a variable-length key. This structure effectively handles arbitrary-length possiblybinary keys including keys with long shared prefixes. +-tree fanout was chosen to minimize total DRAM delay when descending the tree and prefetching each tree node. Lookups use optimistic concurrency control a read-copy-update-like technique and do not write shared data structures updates lock only affected nodes. Logging and checkpointing provide consistency and durability. Though some of these ideas appear elsewhere Masstree is the first to combine them. We discuss design variants and their consequences.On a 16-core machine with logging enabled and queries arriving over a network Masstree executes more than six million simple queries per second. This performance is comparable to that of memcached a non-persistent hash table server and higher (often much higher) than that of VoltDB MongoDB and Redis.;
Proceedings of the 7th ACM European Conference on Computer Systems;The maturation of the Web platform has given rise to sophisticated and demanding Web applications such as interactive 3D visualization audio and video software and games. With that efficiency and security of code on the Web has become more important than ever. Yet JavaScript as the only built-in language of the Web is not well-equipped to meet these requirements especially as a compilation target.  Engineers from the four major browser vendors have risen to the challenge and collaboratively designed a portable low-level bytecode called WebAssembly. It offers compact representation efficient validation and compilation and safe low to no-overhead execution. Rather than committing to a specific programming model WebAssembly is an abstraction over modern hardware making it language- hardware- and platform-independent with use cases beyond just the Web. WebAssembly has been designed with a formal semantics from the start. We describe the motivation design and formal semantics of WebAssembly and provide some preliminary experience with implementations.;
Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation;We live in a world where many kinds of data about us can be collected and more will be collected as Ubicomp technologies mature. People reflect on this data using different tools for personal informatics. However current tools do not have sufficient understanding of users' self-reflection needs to appropriately leverage Ubicomp technologies. To design tools that effectively assist self-reflection we need to comprehensively understand what kinds of questions people have about their data why they ask these questions how they answer them with current tools and what kinds of problems they encounter. To explore this we conducted interviews with people who use various kinds of tools for personal informatics. We found six kinds of questions that people asked about their data. We also found that certain kinds of questions are more important at certain times which we call phases. We identified two phases of reflection: Discovery and Maintenance. We discuss the kinds of questions and the phases in detail and identify features that should be supported in personal informatics tools for which Ubicomp technologies can play an important role.;
Proceedings of the 13th International Conference on Ubiquitous Computing;In this paper we consider the problem of multi-view face detection. While there has been significant research on this problem current state-of-the-art approaches for this task require annotation of facial landmarks e.g. TSM [25] or annotation of face poses [28 22]. They also require training dozens of models to fully capture faces in all orientations e.g. 22 models in HeadHunter method [22]. In this paper we propose Deep Dense Face Detector (DDFD) a method that does not require pose/landmark annotation and is able to detect faces in a wide range of orientations using a single model based on deep convolutional neural networks. The proposed method has minimal complexity unlike other recent deep learning object detection methods [9] it does not require additional components such as segmentation bounding-box regression or SVM classifiers. Furthermore we analyzed scores of the proposed face detector for faces in different orientations and found that 1) the proposed method is able to detect faces from different angles and can handle occlusion to some extent 2) there seems to be a correlation between distribution of positive examples in the training set and scores of the proposed face detector. The latter suggests that the proposed method's performance can be further improved by using better sampling strategies and more sophisticated data augmentation techniques. Evaluations on popular face detection benchmark datasets show that our single-model face detector algorithm has similar or better performance compared to the previous methods which are more complex and require annotations of either different poses or facial landmarks.;
Proceedings of the 5th ACM on International Conference on Multimedia Retrieval;Diagnosing problems in networks is a time-consuming and error-prone process. Existing tools to assist operators primarily focus on analyzing control plane configuration. Configuration analysis is limited in that it cannot find bugs in router software and is harder to generalize across protocols since it must model complex configuration languages and dynamic protocol behavior.This paper studies an alternate approach: diagnosing problems through static analysis of the data plane. This approach can catch bugs that are invisible at the level of configuration files and simplifies unified analysis of a network across many protocols and implementations. We present Anteater a tool for checking invariants in the data plane. Anteater translates high-level network invariants into boolean satisfiability problems (SAT) checks them against network state using a SAT solver and reports counterexamples if violations have been found. Applied to a large university network Anteater revealed 23 bugs including forwarding loops and stale ACL rules with only five false positives. Nine of these faults are being fixed by campus network operators.;
Proceedings of the ACM SIGCOMM 2011 Conference;Systematic exploration of Android apps is an enabler for a variety of app analysis and testing tasks. Performing the exploration while apps run on actual phones is essential for exploring the full range of app capabilities. However exploring real-world apps on real phones is challenging due to non-determinism non-standard control flow scalability and overhead constraints. Relying on end-users to conduct the exploration might not be very effective: we performed a 7-use study on popular Android apps and found that the combined 7-use coverage was 30.08% of the app screens and 6.46% of the app methods. Prior approaches for automated exploration of Android apps have run apps in an emulator or focused on small apps whose source code was available. To address these problems we present A3E an approach and tool that allows substantial Android apps to be explored systematically while running on actual phones yet without requiring access to the app's source code. The key insight of our approach is to use a static taint-style dataflow analysis on the app bytecode in a novel way to construct a high-level control flow graph that captures legal transitions among activities (app screens). We then use this graph to develop an exploration strategy named Targeted Exploration that permits fast direct exploration of activities including activities that would be difficult to reach during normal use. We also developed a strategy named Depth-first Exploration that mimics user actions for exploring activities and their constituents in a slower but more systematic way. To measure the effectiveness of our techniques we use two metrics: activity coverage (number of screens explored) and method coverage. Experiments with using our approach on 25 popular Android apps including BBC News Gas Buddy Amazon Mobile YouTube Shazam Encore and CNN show that our exploration techniques achieve 59.39--64.11% activity coverage and 29.53--36.46% method coverage.;
Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp Applications;Existing blockchain systems scale poorly because of their distributed consensus protocols. Current attempts at improving blockchain scalability are limited to cryptocurrency. Scaling blockchain systems under general workloads (i.e. non-cryptocurrency applications) remains an open question. This work takes a principled approach to apply sharding to blockchain systems in order to improve their transaction throughput at scale. This is challenging however due to the fundamental difference in failure models between databases and blockchain. To achieve our goal we first enhance the performance of Byzantine consensus protocols improving individual shards' throughput. Next we design an efficient shard formation protocol that securely assigns nodes into shards. We rely on trusted hardware namely Intel SGX to achieve high performance for both consensus and shard formation protocol. Third we design a general distributed transaction protocol that ensures safety and liveness even when transaction coordinators are malicious. Finally we conduct an extensive evaluation of our design both on a local cluster and on Google Cloud Platform. The results show that our consensus and shard formation protocols outperform state-of-the-art solutions at scale. More importantly our sharded blockchain reaches a high throughput that can handle Visa-level workloads and is the largest ever reported in a realistic environment.;
Proceedings of the 2019 International Conference on Management of Data;Informally an obfuscator O is an (efficient probabilistic) â€œcompilerâ€ that takes as input a program (or circuit) P and produces a new program O(P) that has the same functionality as P yet is â€œunintelligibleâ€ in some sense. Obfuscators if they exist would have a wide variety of cryptographic and complexity-theoretic applications ranging from software protection to homomorphic encryption to complexity-theoretic analogues of Rice's theorem. Most of these applications are based on an interpretation of the â€œunintelligibilityâ€ condition in obfuscation as meaning that O(P) is a â€œvirtual black boxâ€ in the sense that anything one can efficiently compute given O(P) one could also efficiently compute given oracle access to P.In this work we initiate a theoretical investigation of obfuscation. Our main result is that even under very weak formalizations of the above intuition obfuscation is impossible. We prove this by constructing a family of efficient programs P that are unobfuscatable in the sense that (a) given any efficient program P' that computes the same function as a program P âˆˆ p the â€œsource codeâ€ P can be efficiently reconstructed yet (b) given oracle access to a (randomly selected) program P âˆˆ p no efficient algorithm can reconstruct P (or even distinguish a certain bit in the code from random) except with negligible probability.We extend our impossibility result in a number of ways including even obfuscators that (a) are not necessarily computable in polynomial time (b) only approximately preserve the functionality and (c) only need to work for very restricted models of computation (TC0). We also rule out several potential applications of obfuscators by constructing â€œunobfuscatableâ€ signature schemes encryption schemes and pseudorandom function families.;
Energy-efficient rate-adaptive GPS-based positioning for smartphones;Many emerging smartphone applications require position information to provide location-based or context-aware services. In these applications GPS is often preferred over its alternatives such as GSM/WiFi based positioning systems because it is known to be more accurate. However GPS is extremely power hungry. Hence a common approach is to periodically duty-cycle GPS. However GPS duty-cycling trades-off positioning accuracy for lower energy. A key requirement for such applications then is a positioning system that provides accurate position information while spending minimal energy.In this paper we present RAPS rate-adaptive positioning system for smartphone applications. It is based on the observation that GPS is generally less accurate in urban areas so it suffices to turn on GPS only as often as necessary to achieve this accuracy. RAPS uses a collection of techniques to cleverly determine when to turn on GPS. It uses the location-time history of the user to estimate user velocity and adaptively turn on GPS only if the estimated uncertainty in position exceeds the accuracy threshold. It also efficiently estimates user movement using a duty-cycled accelerometer and utilizes Bluetooth communication to reduce position uncertainty among neighboring devices. Finally it employs celltower-RSS blacklisting to detect GPS unavailability (e.g. indoors) and avoid turning on GPS in these cases. We evaluate RAPS through real-world experiments using a prototype implementation on a modern smartphone and show that it can increase phone lifetimes by more than a factor of 3.8 over an approach where GPS is always on.;
Proceedings of the 8th International Conference on Mobile Systems Applications and Services;The proliferation of computers in any domain is followed by the proliferation of malware in that domain. Systems including the latest mobile platforms are laden with viruses rootkits spyware adware and other classes of malware. Despite the existence of anti-virus software malware threats persist and are growing as there exist a myriad of ways to subvert anti-virus (AV) software. In fact attackers today exploit bugs in the AV software to break into systems.In this paper we examine the feasibility of building a malware detector in hardware using existing performance counters. We find that data from performance counters can be used to identify malware and that our detection techniques are robust to minor variations in malware programs. As a result after examining a small set of variations within a family of malware on Android ARM and Intel Linux platforms we can detect many variations within that family. Further our proposed hardware modifications allow the malware detector to run securely beneath the system software thus setting the stage for AV implementations that are simpler and less buggy than software AV. Combined the robustness and security of hardware AV techniques have the potential to advance state-of-the-art online malware detection.;
Proceedings of the 40th Annual International Symposium on Computer Architecture;This paper examines the location traces of 489 users of a location sharing social network for relationships between the users' mobility patterns and structural properties of their underlying social network. We introduce a novel set of location-based features for analyzing the social context of a geographic region including location entropy which measures the diversity of unique visitors of a location. Using these features we provide a model for predicting friendship between two users by analyzing their location trails. Our model achieves significant gains over simpler models based only on direct properties of the co-location histories such as the number of co-locations. We also show a positive relationship between the entropy of the locations the user visits and the number of social ties that user has in the network. We discuss how the offline mobility of users can have implications for both researchers and designers of online social networks.;
Proceedings of the 12th ACM International Conference on Ubiquitous Computing;"Coverage-based Greybox Fuzzing (CGF) is a random testing approach that requires no program analysis. A new test is generated by slightly mutating a seed input. If the test exercises a new and interesting path it is added to the set of seeds otherwise it is discarded. We observe that most tests exercise the same few high-frequency"" paths and develop strategies to explore significantly more paths with the same number of tests by gravitating towards low-frequency paths. We explain the challenges and opportunities of CGF using a Markov chain model which specifies the probability that fuzzing the seed that exercises path i generates an input that exercises path j. Each state (i.e. seed) has an energy that specifies the number of inputs to be generated from that seed. We show that CGF is considerably more efficient if energy is inversely proportional to the density of the stationary distribution and increases monotonically every time that seed is chosen. Energy is controlled with a power schedule.We implemented the exponential schedule by extending AFL. In 24 hours AFLFAST exposes 3 previously unreported CVEs that are not exposed by AFL and exposes 6 previously unreported CVEs 7x faster than AFL. AFLFAST produces at least an order of magnitude more unique crashes than AFL.""";
Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security;GPGPUs have recently emerged as powerful vehicles for general-purpose high-performance computing. Although a new Compute Unified Device Architecture (CUDA) programming model from NVIDIA offers improved programmability for general computing programming GPGPUs is still complex and error-prone. This paper presents a compiler framework for automatic source-to-source translation of standard OpenMP applications into CUDA-based GPGPU applications. The goal of this translation is to further improve programmability and make existing OpenMP applications amenable to execution on GPGPUs. In this paper we have identified several key transformation techniques which enable efficient GPU global memory access to achieve high performance. Experimental results from two important kernels (JACOBI and SPMUL) and two NAS OpenMP Parallel Benchmarks (EP and CG) show that the described translator and compile-time optimizations work well on both regular and irregular applications leading to performance improvements of up to 50X over the unoptimized translation (up to 328X over serial).;
Proceedings of the 14th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming;Articulated hand-tracking systems have been widely used in virtual reality but are rarely deployed in consumer applications due to their price and complexity. In this paper we propose an easy-to-use and inexpensive system that facilitates 3-D articulated user-input using the hands. Our approach uses a single camera to track a hand wearing an ordinary cloth glove that is imprinted with a custom pattern. The pattern is designed to simplify the pose estimation problem allowing us to employ a nearest-neighbor approach to track hands at interactive rates. We describe several proof-of-concept applications enabled by our system that we hope will provide a foundation for new interactions in modeling animation control and augmented reality.;
Graphical passwords: Learning from the first twelve years;Starting around 1999 a great many graphical password schemes have been proposed as alternatives to text-based password authentication. We provide a comprehensive overview of published research in the area covering both usability and security aspects as well as system evaluation. The article first catalogues existing approaches highlighting novel features of selected schemes and identifying key usability or security advantages. We then review usability requirements for knowledge-based authentication as they apply to graphical passwords identify security threats that such systems must address and review known attacks discuss methodological issues related to empirical evaluation and identify areas for further research and improved methodology.;
Dynamic performance tuning of word-based software transactional memory;The current generation of software transactional memories has the advantage of being simple and efficient. Nevertheless there are several parameters that affect the performance of a transactional memory for example the locality of the application and the cache line size of the processor. In this paper we investigate dynamic tuning mechanisms on a new time-based software transactional memory implementation. We study in extensive measurements the performance of our implementation and exhibit the benefits of dynamic tuning. We compare our results with TL2 which is currently one of the fastest word-based software transactional memories.;
Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming;We present the DOOP framework for points-to analysis of Java programs. DOOP builds on the idea of specifying pointer analysis algorithms declaratively using Datalog: a logic-based language for defining (recursive) relations. We carry the declarative approach further than past work by describing the full end-to-end analysis in Datalog and optimizing aggressively using a novel technique specifically targeting highly recursive Datalog programs.As a result DOOP achieves several benefits including full order-of-magnitude improvements in runtime. We compare DOOP with Lhotak and Hendren's PADDLE which defines the state of the art for context-sensitive analyses. For the exact same logical points-to definitions (and consequently identical precision) DOOP is more than 15x faster than PADDLE for a 1-call-site sensitive analysis of the DaCapo benchmarks with lower but still substantial speedups for other important analyses. Additionally DOOP scales to very precise analyses that are impossible with PADDLE and Whaley et al.'s bddbddb directly addressing open problems in past literature. Finally our implementation is modular and can be easily configured to analyses with a wide range of characteristics largely due to its declarativeness.;
Proceedings of the 24th ACM SIGPLAN Conference on Object Oriented Programming Systems Languages and Applications;Web service composition enables seamless and dynamic integration of business applications on the web. The performance of the composed application is determined by the performance of the involved web services. Therefore non-functional quality of service aspects are crucial for selecting the web services to take part in the composition. Identifying the best candidate web services from a set of functionally-equivalent services is a multi-criteria decision making problem. The selected services should optimize the overall QoS of the composed application while satisfying all the constraints specified by the client on individual QoS parameters. In this paper we propose an approach based on the notion of skyline to effectively and efficiently select services for composition reducing the number of candidate services to be considered. We also discuss how a provider can improve its service to become more competitive and increase its potential of being included in composite applications. We evaluate our approach experimentally using both real and synthetically generated datasets.;
Proceedings of the 19th International Conference on World Wide Web;Virtualized data centers enable sharing of resources among hosted applications. However it is difficult to satisfy service-level objectives(SLOs) of applications on shared infrastructure as application workloads and resource consumption patterns change over time. In this paper we present AutoControl a resource control system that automatically adapts to dynamic workload changes to achieve application SLOs. AutoControl is a combination of an online model estimator and a novel multi-input multi-output (MIMO) resource controller. The model estimator captures the complex relationship between application performance and resource allocations while the MIMO controller allocates the right amount of multiple virtualized resources to achieve application SLOs. Our experimental evaluation with RUBiS and TPC-W benchmarks along with production-trace-driven workloads indicates that AutoControl can detect and mitigate CPU and disk I/O bottlenecks that occur over time and across multiple nodes by allocating each resource accordingly. We also show that AutoControl can be used to provide service differentiation according to the application priorities during resource contention.;
Proceedings of the 4th ACM European Conference on Computer Systems;Frequent itemset mining (FIM) is a useful tool for discovering frequently co-occurrent items. Since its inception a number of significant FIM algorithms have been developed to speed up mining performance. Unfortunately when the dataset size is huge both the memory use and computational cost can still be prohibitively expensive. In this work we propose to parallelize the FP-Growth algorithm (we call our parallel algorithm PFP) on distributed machines. PFP partitions computation in such a way that each machine executes an independent group of mining tasks. Such partitioning eliminates computational dependencies between machines and thereby communication between them. Through empirical study on a large dataset of 802939 Web pages and 1021107 tags we demonstrate that PFP can achieve virtually linear speedup. Besides scalability the empirical study demonstrates that PFP to be promising for supporting query recommendation for search engines.;
Proceedings of the 2008 ACM Conference on Recommender Systems;Today's mobile phones represent a rich and powerful computing platform given their sensing processing and communication capabilities. Phones are also part of the everyday life of billions of people and therefore represent an exceptionally suitable tool for conducting social and psychological experiments in an unobtrusive way.de the ability of sensing individual emotions as well as activities verbal and proximity interactions among members of social groups. Moreover the system is programmable by means of a declarative language that can be used to express adaptive rules to improve power saving. We evaluate a system prototype on Nokia Symbian phones by means of several small-scale experiments aimed at testing performance in terms of accuracy and power consumption. Finally we present the results of real deployment where we study participants emotions and interactions. We cross-validate our measurements with the results obtained through questionnaires filled by the users and the results presented in social psychological studies using traditional methods. In particular we show how speakers and participants' emotions can be automatically detected by means of classifiers running locally on off-the-shelf mobile phones and how speaking and interactions can be correlated with activity and location measures.;
Proceedings of the 12th ACM International Conference on Ubiquitous Computing;Can we get network latency between any two servers at any time in large-scale data center networks? The collected latency data can then be used to address a series of challenges: telling if an application perceived latency issue is caused by the network or not defining and tracking network service level agreement (SLA) and automatic network troubleshooting. We have developed the Pingmesh system for large-scale data center network latency measurement and analysis to answer the above question affirmatively. Pingmesh has been running in Microsoft data centers for more than four years and it collects tens of terabytes of latency data per day. Pingmesh is widely used by not only network software developers and engineers but also application and service developers and operators.;
Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication;Tagging systems have become major infrastructures on the Web. They allow users to create tags that annotate and categorize content and share them with other users very helpful in particular for searching multimedia content. However as tagging is not constrained by a controlled vocabulary and annotation guidelines tags tend to be noisy and sparse. Especially new resources annotated by only a few users have often rather idiosyncratic tags that do not reflect a common perspective useful for search. In this paper we introduce an approach based on Latent Dirichlet Allocation (LDA) for recommending tags of resources in order to improve search. Resources annotated by many users and thus equipped with a fairly stable and complete tag set are used to elicit latent topics to which new resources with only a few tags are mapped. Based on this other tags belonging to a topic can be recommended for the new resource. Our evaluation shows that the approach achieves significantly better precision and recall than the use of association rules suggested in previous work and also recommends more specific tags. Moreover extending resources with these recommended tags significantly improves search for new resources.;
Proceedings of the Third ACM Conference on Recommender Systems;Building software product lines (SPLs) with features is a challenging task. Many SPL implementations support features with coarse granularity - e.g. the ability to add and wrap entire methods. However fine-grained extensions like adding a statement in the middle of a method either require intricate workarounds or obfuscate the base code with annotations. Though many SPLs can and have been implemented with the coarse granularity of existing approaches fine-grained extensions are essential when extracting features from legacy applications. Furthermore also some existing SPLs could benefit from fine-grained extensions to reduce code replication or improve readability. In this paper we analyze the effects of feature granularity in SPLs and present a tool called Colored IDE (CIDE) that allows features to implement coarse-grained and fine-grained extensions in a concise way. In two case studies we show how CIDE simplifies SPL development compared to traditional approaches.;
Proceedings of the 30th International Conference on Software Engineering;In this paper we present Spade - the System S declarative stream processing engine. System S is a large-scale distributed data stream processing middleware under development at IBM T. J. Watson Research Center. As a front-end for rapid application development for System S Spade provides (1) an intermediate language for flexible composition of parallel and distributed data-flow graphs (2) a toolkit of type-generic built-in stream processing operators that support scalar as well as vectorized processing and can seamlessly inter-operate with user-defined operators and (3) a rich set of stream adapters to ingest/publish data from/to outside sources. More importantly Spade automatically brings performance optimization and scalability to System S applications. To that end Spade employs a code generation framework to create highly-optimized applications that run natively on the Stream Processing Core (SPC) the execution and communication substrate of System S and take full advantage of other System S services. Spade allows developers to construct their applications with fine granular stream operators without worrying about the performance implications that might exist even in a distributed system. Spade's optimizing compiler automatically maps applications into appropriately sized execution units in order to minimize communication overhead while at the same time exploiting available parallelism. By virtue of the scalability of the System S runtime and Spade's effective code generation and optimization we can scale applications to a large number of nodes. Currently we can run Spade jobs on â‰ˆ 500 processors within more than 100 physical nodes in a tightly connected cluster environment. Spade has been in use at IBM Research to create real-world streaming applications ranging from monitoring financial market feeds to radio telescopes to semiconductor fabrication lines.;
Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data;We present Dionysus a system for fast consistent network updates in software-defined networks. Dionysus encodes as a graph the consistency-related dependencies among updates at individual switches and it then dynamically schedules these updates based on runtime differences in the update speeds of different switches. This dynamic scheduling is the key to its speed prior update methods are slow because they pre-determine a schedule which does not adapt to runtime conditions. Testbed experiments and data-driven simulations show that Dionysus improves the median update speed by 53--88% in both wide area and data center networks compared to prior methods.;
Proceedings of the 2014 ACM Conference on SIGCOMM;This paper presents a systematic literature review of the recent (2006--2010) development of automatic assessment tools for programming exercises. We discuss the major features that the tools support and the different approaches they are using both from the pedagogical and the technical point of view. Examples of these features are ways for the teacher to define tests resubmission policies security issues and so forth. We have also identified a list of novel features like assessing web software that are likely to get more research attention in the future. As a conclusion we state that too many new systems are developed but also acknowledge the current reasons for the phenomenon. As one solution we encourage opening up the existing systems and joining efforts on developing those further. Selected systems from our survey are briefly described in Appendix A.;
Proceedings of the 10th Koli Calling International Conference on Computing Education Research;We present unikernels a new approach to deploying cloud services via applications written in high-level source code. Unikernels are single-purpose appliances that are compile-time specialised into standalone kernels and sealed against modification when deployed to a cloud platform. In return they offer significant reduction in image sizes improved efficiency and security and should reduce operational costs. Our Mirage prototype compiles OCaml code into unikernels that run on commodity clouds and offer an order of magnitude reduction in code size without significant performance penalty. The architecture combines static type-safety with a single address-space layout that can be made immutable via a hypervisor extension. Mirage contributes a suite of type-safe protocol libraries and our results demonstrate that the hypervisor is a platform that overcomes the hardware compatibility issues that have made past library operating systems impractical to deploy in the real-world.;
Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems;We are witnessing a dramatic change in computer architecture due to the multicore paradigm shift as every electronic device from cell phones to supercomputers confronts parallelism of unprecedented scale. To fully unleash the potential of these systems the HPC community must develop multicore specific optimization methodologies for important scientific computations. In this work we examine sparse matrix-vector multiply (SpMV) - one of the most heavily used kernels in scientific computing - across a broad spectrum of multicore designs. Our experimental platform includes the homogeneous AMD dual-core and Intel quad-core designs the heterogeneous STI Cell as well as the first scientific study of the highly multithreaded Sun Niagara2. We present several optimization strategies especially effective for the multicore environment and demonstrate significant performance improvements compared to existing state-of-the-art serial and parallel SpMV implementations. Additionally we present key insights into the architectural tradeoffs of leading multicore design strategies in the context of demanding memory-bound numerical algorithms.;
Proceedings of the 2007 ACM/IEEE Conference on Supercomputing;The Laplacian pyramid is ubiquitous for decomposing images into multiple scales and is widely used for image analysis. However because it is constructed with spatially invariant Gaussian kernels the Laplacian pyramid is widely believed as being unable to represent edges well and as being ill-suited for edge-aware operations such as edge-preserving smoothing and tone mapping. To tackle these tasks a wealth of alternative techniques and representations have been proposed e.g. anisotropic diffusion neighborhood filtering and specialized wavelet bases. While these methods have demonstrated successful results they come at the price of additional complexity often accompanied by higher computational cost or the need to post-process the generated results. In this paper we show state-of-the-art edge-aware processing using standard Laplacian pyramids. We characterize edges with a simple threshold on pixel values that allows us to differentiate large-scale edges from small-scale details. Building upon this result we propose a set of image filters to achieve edge-preserving smoothing detail enhancement tone mapping and inverse tone mapping. The advantage of our approach is its simplicity and flexibility relying only on simple point-wise nonlinearities and small Gaussian convolutions no optimization or post-processing is required. As we demonstrate our method produces consistently high-quality results without degrading edges or introducing halos.;
Beyond News Contents: The Role of Social Context for Fake News Detection;Social media is becoming popular for news consumption due to its fast dissemination easy access and low cost. However it also enables the wide propagation of fake news i.e. news with intentionally false information. Detecting fake news is an important task which not only ensures users receive authentic information but also helps maintain a trustworthy news ecosystem. The majority of existing detection algorithms focus on finding clues from news contents which are generally not effective because fake news is often intentionally written to mislead users by mimicking true news. Therefore we need to explore auxiliary information to improve detection. The social context during news dissemination process on social media forms the inherent tri-relationship the relationship among publishers news pieces and users which has the potential to improve fake news detection. For example partisan-biased publishers are more likely to publish fake news and low-credible users are more likely to share fake news. In this paper we study the novel problem of exploiting social context for fake news detection. We propose a tri-relationship embedding framework TriFN which models publisher-news relations and user-news interactions simultaneously for fake news classification. We conduct experiments on two real-world datasets which demonstrate that the proposed approach significantly outperforms other baseline methods for fake news detection.;
Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining;As the field of data science continues to grow there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning--pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization which produces compact pipelines without sacrificing classification accuracy. As such this work represents an important step toward fully automating machine learning pipeline design.;
Proceedings of the Genetic and Evolutionary Computation Conference 2016;With lower latency and higher bandwidth than its predecessor 3G networks the latest cellular technology 4G LTE has been attracting many new users. However the interactions among applications network transport protocol and the radio layer still remain unexplored. In this work we conduct an in-depth study of these interactions and their impact on performance using a combination of active and passive measurements. We observed that LTE has significantly shorter state promotion delays and lower RTTs than those of 3G networks. We discovered various inefficiencies in TCP over LTE such as undesired slow start. We further developed a novel and lightweight passive bandwidth estimation technique for LTE networks. Using this tool we discovered that many TCP connections significantly under-utilize the available bandwidth. On average the actually used bandwidth is less than 50% of the available bandwidth. This causes data downloads to be longer and incur additional energy overhead. We found that the under-utilization can be caused by both application behavior and TCP parameter setting. We found that 52.6% of all downlink TCP flows have been throttled by limited TCP receive window and that data transfer patterns for some popular applications are both energy and network unfriendly. All these findings highlight the need to develop transport protocol mechanisms and applications that are more LTE-friendly.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;Highly accurate indoor localization of smartphones is critical to enable novel location based features for users and businesses. In this paper we first conduct an empirical investigation of the suitability of WiFi localization for this purpose. We find that although reasonable accuracy can be achieved significant errors (e.g. $6sim8m$) always exist. The root cause is the existence of distinct locations with similar signatures which is a fundamental limit of pure WiFi-based methods. Inspired by high densities of smartphones in public spaces we propose a peer assisted localization approach to eliminate such large errors. It obtains accurate acoustic ranging estimates among peer phones then maps their locations jointly against WiFi signature map subjecting to ranging constraints. We devise techniques for fast acoustic ranging among multiple phones and build a prototype. Experiments show that it can reduce the maximum and 80-percentile errors to as small as $2m$ and $1m$ in time no longer than the original WiFi scanning with negligible impact on battery lifetime.;
Proceedings of the 18th Annual International Conference on Mobile Computing and Networking;"Concurrency has long been touted as the next big thing"" and ""the way of the future"" but for the past 30 years mainstream software development has been able to ignore it. Our parallel future has finally arrived: new machines will be parallel machines and this will require major changes in the way we develop software. The introductory article in this issue describes the hardware imperatives behind this shift in computer architecture from uniprocessors to multicore processors also known as CMPs.""";
WTF: the who to follow service at Twitter;"WTF (Who to Follow"") is Twitter's user recommendation service which is responsible for creating millions of connections daily between users based on shared interests common connections and other related factors. This paper provides an architectural overview and shares lessons we learned in building and running the service over the past few years. Particularly noteworthy was our design decision to process the entire Twitter graph in memory on a single server which significantly reduced architectural complexity and allowed us to develop and deploy the service in only a few months. At the core of our architecture is Cassovary an open-source in-memory graph processing engine we built from scratch for WTF. Besides powering Twitter's user recommendations Cassovary is also used for search discovery promoted products and other services as well. We describe and evaluate a few graph recommendation algorithms implemented in Cassovary including a novel approach based on a combination of random walks and SALSA. Looking into the future we revisit the design of our architecture and comment on its limitations which are presently being addressed in a second-generation system under development.""";
Proceedings of the 22nd International Conference on World Wide Web;This paper proposes a novel machine learning architecture specifically designed for radio-frequency based gesture recognition. We focus on high-frequency (60]GHz) short-range radar based sensing in particular Google's Soli sensor. The signal has unique properties such as resolving motion at a very fine level and allowing for segmentation in range and velocity spaces rather than image space. This enables recognition of new types of inputs but poses significant difficulties for the design of input recognition algorithms. The proposed algorithm is capable of detecting a rich set of dynamic gestures and can resolve small motions of fingers in fine detail. Our technique is based on an end-to-end trained combination of deep convolutional and recurrent neural networks. The algorithm achieves high recognition rates (avg 87%) on a challenging set of 11 dynamic gestures and generalizes well across 10 users. The proposed model runs on commodity hardware at 140 Hz (CPU only).;
Proceedings of the 29th Annual Symposium on User Interface Software and Technology;Deep learning neural networks (DNNs) have been successful in solving a wide range of machine learning problems. Specialized hardware accelerators have been proposed to accelerate the execution of DNN algorithms for high-performance and energy efficiency. Recently they have been deployed in datacenters (potentially for business-critical or industrial applications) and safety-critical systems such as self-driving cars. Soft errors caused by high-energy particles have been increasing in hardware systems and these can lead to catastrophic failures in DNN systems. Traditional methods for building resilient systems e.g. Triple Modular Redundancy (TMR) are agnostic of the DNN algorithm and the DNN accelerator's architecture. Hence these traditional resilience approaches incur high overheads which makes them challenging to deploy. In this paper we experimentally evaluate the resilience characteristics of DNN systems (i.e. DNN software running on specialized accelerators). We find that the error resilience of a DNN system depends on the data types values data reuses and types of layers in the design. Based on our observations we propose two efficient protection techniques for DNN systems.;
Proceedings of the International Conference for High Performance Computing Networking Storage and Analysis;Whereas people learn many different types of knowledge from diverse experiences over many years and become better learners over time most current machine learning systems are much more narrow learning just a single function or data model based on statistical analysis of a single data set. We suggest that people learn better than computers precisely because of this difference and we suggest a key direction for machine learning research is to develop software architectures that enable intelligent agents to also learn many types of knowledge continuously over many years and to become better learners over time. In this paper we define more precisely this never-ending learning paradigm for machine learning and we present one case study: the Never-Ending Language Learner (NELL) which achieves a number of the desired properties of a never-ending learner. NELL has been learning to read the Web 24hrs/day since January 2010 and so far has acquired a knowledge base with 120mn diverse confidence-weighted beliefs (e.g. servedWith(teabiscuits)) while learning thousands of interrelated functions that continually improve its reading competence over time. NELL has also learned to reason over its knowledge base to infer new beliefs it has not yet read from those it has and NELL is inventing new relational predicates to extend the ontology it uses to represent beliefs. We describe the design of NELL experimental results illustrating its behavior and discuss both its successes and shortcomings as a case study in never-ending learning. NELL can be tracked online at http://rtw.ml.cmu.edu and followed on Twitter at @CMUNELL.;
AM-GCN: Adaptive Multi-channel Graph Convolutional Networks;Graph Convolutional Networks (GCNs) have gained great popularity in tackling various analytics tasks on graph and network data. However some recent studies raise concerns about whether GCNs can optimally integrate node features and topological structures in a complex graph with rich information. In this paper we first present an experimental investigation. Surprisingly our experimental results clearly show that the capability of the state-of-the-art GCNs in fusing node features and topological structures is distant from optimal or even satisfactory. The weakness may severely hinder the capability of GCNs in some classification tasks since GCNs may not be able to adaptively learn some deep correlation information between topological structures and node features. Can we remedy the weakness and design a new type of GCNs that can retain the advantages of the state-of-the-art GCNs and at the same time enhance the capability of fusing topological structures and node features substantially? We tackle the challenge and propose an adaptive multi-channel graph convolutional networks for semi-supervised classification (AM-GCN). The central idea is that we extract the specific and common embeddings from node features topological structures and their combinations simultaneously and use the attention mechanism to learn adaptive importance weights of the embeddings. Our extensive experiments on benchmark data sets clearly show that AM-GCN extracts the most correlated information from both node features and topological structures substantially and improves the classification accuracy with a clear margin.;
Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;Cloud services have recently started undergoing a major shift from monolithic applications to graphs of hundreds or thousands of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with and present both opportunities and challenges when optimizing for quality of service (QoS) and cloud utilization.In this paper we explore the implications microservices have across the cloud system stack. We first present DeathStarBench a novel open-source benchmark suite built with microservices that is representative of large end-to-end services modular and extensible. DeathStarBench includes a social network a media service an e-commerce site a banking system and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices their implications in networking and operating systems their challenges with respect to cluster management and their trade-offs in terms of application design and programming frameworks. Finally we explore the tail at scale effects of microservices in real deployments with hundreds of users and highlight the increased pressure they put on performance predictability.;
Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems;This paper presents ElectriSense a new solution for automatically detecting and classifying the use of electronic devices in a home from a single point of sensing. ElectriSense relies on the fact that most modern consumer electronics and fluorescent lighting employ switch mode power supplies (SMPS) to achieve high efficiency. These power supplies continuously generate high frequency electromagnetic interference (EMI) during operation that propagates throughout a home's power wiring. We show both analytically and by in-home experimentation that EMI signals are stable and predictable based on the device's switching frequency characteristics. Unlike past transient noise-based solutions this new approach provides the ability for EMI signatures to be applicable across homes while still being able to differentiate between similar devices in a home. We have evaluated our solution in seven homes including one six-month deployment. Our results show that ElectriSense can identify and classify the usage of individual devices with a mean accuracy of 93.82%.;
Proceedings of the 12th ACM International Conference on Ubiquitous Computing;Urban sensing participatory sensing and user activity recognition can provide rich contextual information for mobile applications such as social networking and location-based services. However continuously capturing this contextual information on mobile devices consumes huge amount of energy. In this paper we present a novel design framework for an Energy Efficient Mobile Sensing System (EEMSS). EEMSS uses hierarchical sensor management strategy to recognize user states as well as to detect state transitions. By powering only a minimum set of sensors and using appropriate sensor duty cycles EEMSS significantly improves device battery life. We present the design implementation and evaluation of EEMSS that automatically recognizes a set of users' daily activities in real time using sensors on an off-the-shelf high-end smart phone. Evaluation of EEMSS with 10 users over one week shows that our approach increases the device battery life by more than 75% while maintaining both high accuracy and low latency in identifying transitions between end-user activities.;
Proceedings of the 7th International Conference on Mobile Systems Applications and Services;NUMA systems are characterized by Non-Uniform Memory Access times where accessing data in a remote node takes longer than a local access. NUMA hardware has been built since the late 80's and the operating systems designed for it were optimized for access locality. They co-located memory pages with the threads that accessed them so as to avoid the cost of remote accesses. Contrary to older systems modern NUMA hardware has much smaller remote wire delays and so remote access costs per se are not the main concern for performance as we discovered in this work. Instead congestion on memory controllers and interconnects caused by memory traffic from data-intensive applications hurts performance a lot more. Because of that memory placement algorithms must be redesigned to target traffic congestion. This requires an arsenal of techniques that go beyond optimizing locality. In this paper we describe Carrefour an algorithm that addresses this goal. We implemented Carrefour in Linux and obtained performance improvements of up to 3.6 relative to the default kernel as well as significant improvements compared to NUMA-aware patchsets available for Linux. Carrefour never hurts performance by more than 4% when memory placement cannot be improved. We present the design of Carrefour the challenges of implementing it on modern hardware and draw insights about hardware support that would help optimize system software on future NUMA systems.;
Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems;Similarity search methods based on hashing for effective and efficient cross-modal retrieval on large-scale multimedia databases with massive text and images have attracted considerable attention. The core problem of cross-modal hashing is how to effectively construct correlation between multi-modal representations which are heterogeneous intrinsically in the process of hash function learning. Analogous to Canonical Correlation Analysis (CCA) most existing cross-modal hash methods embed the heterogeneous data into a joint abstraction space by linear projections. However these methods fail to bridge the semantic gap more effectively and capture high-level latent semantic information which has been proved that it can lead to better performance for image retrieval. To address these challenges in this paper we propose a novel Latent Semantic Sparse Hashing (LSSH) to perform cross-modal similarity search by employing Sparse Coding and Matrix Factorization. In particular LSSH uses Sparse Coding to capture the salient structures of images and Matrix Factorization to learn the latent concepts from text. Then the learned latent semantic features are mapped to a joint abstraction space. Moreover an iterative strategy is applied to derive optimal solutions efficiently and it helps LSSH to explore the correlation between multi-modal representations efficiently and automatically. Finally the unified hashcodes are generated through the high level abstraction space by quantization. Extensive experiments on three different datasets highlight the advantage of our method under cross-modal scenarios and show that LSSH significantly outperforms several state-of-the-art methods.;
Proceedings of the 37th International ACM SIGIR Conference on Research &amp Development in Information Retrieval;The use of social networking software by professionals is increasing dramatically. How it is used whether it enhances or reduces productivity and how enterprise-friendly design and use might evolve are open questions. We examine attitudes and behaviors in a large technologically-savvy organization through a broad survey and thirty focused interviews. We find extensive social and work uses with complex patterns that differ with software system and networker age. Tensions arise when use spans social groups and the organization's firewall. Although use is predominantly to support weak ties whose contribution to productivity can be difficult to prove we anticipate rapid uptake of social networking technology by organizations.;
Proceedings of the 2009 ACM International Conference on Supporting Group Work;High dynamic range (HDR) imaging from a set of sequential exposures is an easy way to capture high-quality images of static scenes but suffers from artifacts for scenes with significant motion. In this paper we propose a new approach to HDR reconstruction that draws information from all the exposures but is more robust to camera/scene motion than previous techniques. Our algorithm is based on a novel patch-based energy-minimization formulation that integrates alignment and reconstruction in a joint optimization through an equation we call the HDR image synthesis equation. This allows us to produce an HDR result that is aligned to one of the exposures yet contains information from all of them. We present results that show considerable improvement over previous approaches.;
Mathematizing C++ concurrency;Shared-memory concurrency in C and C++ is pervasive in systems programming but has long been poorly defined. This motivated an ongoing shared effort by the standards committees to specify concurrent behaviour in the next versions of both languages. They aim to provide strong guarantees for race-free programs together with new (but subtle) relaxed-memory atomic primitives for high-performance concurrent code. However the current draft standards while the result of careful deliberation are not yet clear and rigorous definitions and harbour substantial problems in their details.In this paper we establish a mathematical (yet readable) semantics for C++ concurrency. We aim to capture the intent of the current (`Final Committee') Draft as closely as possible but discuss changes that fix many of its problems. We prove that a proposed x86 implementation of the concurrency primitives is correct with respect to the x86-TSO model and describe our Cppmem tool for exploring the semantics of examples using code generated from our Isabelle/HOL definitions.Having already motivated changes to the draft standard this work will aid discussion of any further changes provide a correctness condition for compilers and give a much-needed basis for analysis and verification of concurrent C and C++ programs.;
Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages;It is often suggested that users are hopelessly lazy and unmotivated on security questions. They chose weak passwords ignore security warnings and are oblivious to certificates errors. We argue that users' rejection of the security advice they receive is entirely rational from an economic perspective. The advice offers to shield them from the direct costs of attacks but burdens them with far greater indirect costs in the form of effort. Looking at various examples of security advice we find that the advice is complex and growing but the benefit is largely speculative or moot. For example much of the advice concerning passwords is outdated and does little to address actual treats and fully 100% of certificate error warnings appear to be false positives. Further if users spent even a minute a day reading URLs to avoid phishing the cost (in terms of user time) would be two orders of magnitude greater than all phishing losses. Thus we find that most security advice simply offers a poor cost-benefit tradeoff to users and is rejected. Security advice is a daily burden applied to the whole population while an upper bound on the benefit is the harm suffered by the fraction that become victims annually. When that fraction is small designing security advice that is beneficial is very hard. For example it makes little sense to burden all users with a daily task to spare 0.01% of them a modest annual pain.;
Proceedings of the 2009 Workshop on New Security Paradigms Workshop;We present the design implementation and evaluation of an API for applications to control a software-defined network (SDN). Our API is implemented by an OpenFlow controller that delegates read and write authority from the network's administrators to end users or applications and devices acting on their behalf. Users can then work with the network rather than around it to achieve better performance security or predictable behavior. Our API serves well as the next layer atop current SDN stacks. Our design addresses the two key challenges: how to safely decompose control and visibility of the network and how to resolve conflicts between untrusted users and across requests while maintaining baseline levels of fairness and security. Using a real OpenFlow testbed we demonstrate our API's feasibility through microbenchmarks and its usefulness by experiments with four real applications modified to take advantage of it.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;Mobile devices are increasingly being relied on for services that go beyond simple connectivity and require more complex processing. Fortunately a mobile device encounters possibly intermittently many entities capable of lending it computational resources. At one extreme is the traditional cloud-computing context where a mobile device is connected to remote cloud resources maintained by a service provider with which it has an established relationship. In this paper we consider the other extreme where a mobile device's contacts are only with other mobile devices where both the computation initiator and the remote computational resources are mobile and where intermittent connectivity among these entities is the norm. We present the design and implementation of a system Serendipity that enables a mobile computation initiator to use remote computational resources available in other mobile systems in its environment to speedup computing and conserve energy. We propose a simple but powerful job structure that is suitable for such a system. Serendipity relies on the collaboration among mobile devices for task allocation and task progress monitoring functions. We develop algorithms that are designed to disseminate tasks among mobile devices by accounting for the specific properties of the available connectivity. We also undertake an extensive evaluation of our system including experience with a prototype that demonstrates Serendipity's performance.;
Proceedings of the Thirteenth ACM International Symposium on Mobile Ad Hoc Networking and Computing;Recent years have seen the advent of new RF-localization systems that demonstrate tens of centimeters of accuracy. However such systems require either deployment of new infrastructure or extensive fingerprinting of the environment through training or crowdsourcing impeding their wide-scale adoption.We present Ubicarse an accurate indoor localization system for commodity mobile devices with no specialized infrastructure or fingerprinting. Ubicarse enables handheld devices to emulate large antenna arrays using a new formulation of Synthetic Aperture Radar (SAR). Past work on SAR requires measuring mechanically controlled device movement with millimeter precision far beyond what commercial accelerometers can provide. In contrast Ubicarse's core contribution is the ability to perform SAR on handheld devices twisted by their users along unknown paths. Ubicarse is not limited to localizing RF devices it combines RF localization with stereo-vision algorithms to localize common objects with no RF source attached to them. We implement Ubicarse on a HP SplitX2 tablet and empirically demonstrate a median error of 39 cm in 3-D device localization and 17 cm in object geotagging in complex indoor settings.;
Proceedings of the 20th Annual International Conference on Mobile Computing and Networking;"The relationship between financial incentives and performance long of interest to social scientists has gained new relevance with the advent of web-based crowd-sourcing"" models of production. Here we investigate the effect of compensation on performance in the context of two experiments conducted on Amazon's Mechanical Turk (AMT). We find that increased financial incentives increase the quantity but not the quality of work performed by participants where the difference appears to be due to an ""anchoring"" effect: workers who were paid more also perceived the value of their work to be greater and thus were no more motivated than workers paid less. In contrast with compensation levels we find the details of the compensation scheme do matter---specifically a ""quota"" system results in better work for less pay than an equivalent ""piece rate"" system. Although counterintuitive these findings are consistent with previous laboratory studies and may have real-world analogs as well.""";
Proceedings of the ACM SIGKDD Workshop on Human Computation;As leakage and other charge storage limitations begin to impair the scalability of DRAM non-volatile resistive memories are being developed as a potential replacement. Unfortunately current error correction techniques are poorly suited to this emerging class of memory technologies. Unlike DRAM PCM and other resistive memories have wear lifetimes measured in writes that are sufficiently short to make cell failures common during a system's lifetime. However resistive memories are much less susceptible to transient faults than DRAM. The Hamming-based ECC codes used in DRAM are designed to handle transient faults with no effective lifetime limits but ECC codes applied to resistive memories would wear out faster than the cells they are designed to repair. This paper evaluates Error-Correcting Pointers (ECP) a new approach to error correction optimized for memories in which errors are the result of permanent cell failures that occur and are immediately detectable at write time. ECP corrects errors by permanently encoding the locations of failed cells into a table and assigning cells to replace them. ECP provides longer lifetimes than previously proposed solutions with equivalent overhead. What's more as the level of variance in cell lifetimes increases -- a likely consequence of further scalaing -- ECP's margin of improvement over existing schemes increases.;
Proceedings of the 37th Annual International Symposium on Computer Architecture;Server farms today consume more than 1.5% of the total electricity in the U.S. at a cost of nearly $4.5 billion. Given the rising cost of energy many industries are now seeking solutions for how to best make use of their available power. An important question which arises in this context is how to distribute available power among servers in a server farm so as to get maximum performance.By giving more power to a server one can get higher server frequency (speed). Hence it is commonly believed that for a given power budget performance can be maximized by operating servers at their highest power levels. However it is also conceivable that one might prefer to run servers at their lowest power levels which allows more servers to be turned on for a given power budget. To fully understand the effect of power allocation on performance in a server farm with a fixed power budget we introduce a queueing theoretic model which allows us to predict the optimal power allocation in a variety of scenarios. Results are verified via extensive experiments on an IBM BladeCenter.We find that the optimal power allocation varies for different scenarios. In particular it is not always optimal to run servers at their maximum power levels. There are scenarios where it might be optimal to run servers at their lowest power levels or at some intermediate power levels. Our analysis shows that the optimal power allocation is non-obvious and depends on many factors such as the power-to-frequency relationship in the processors the arrival rate of jobs the maximum server frequency the lowest attainable server frequency and the server farm configuration. Furthermore our theoretical model allows us to explore more general settings than we can implement including arbitrarily large server farms and different power-to-frequency curves. Importantly we show that the optimal power allocation can significantly improve server farm performance by a factor of typically 1.4 and as much as a factor of 5 in some cases.;
Proceedings of the Eleventh International Joint Conference on Measurement and Modeling of Computer Systems;An increasing number of wireless applications rely on GPS signals for localization navigation and time synchronization. However civilian GPS signals are known to be susceptible to spoofing attacks which make GPS receivers in range believe that they reside at locations different than their real physical locations. In this paper we investigate the requirements for successful GPS spoofing attacks on individuals and groups of victims with civilian or military GPS receivers. In particular we are interested in identifying from which locations and with which precision the attacker needs to generate its signals in order to successfully spoof the receivers. We will show for example that any number of receivers can easily be spoofed to one arbitrary location however the attacker is restricted to only few transmission locations when spoofing a group of receivers while preserving their constellation. In addition we investigate the practical aspects of a satellite-lock takeover in which a victim receives spoofed signals after first being locked on to legitimate GPS signals. Using a civilian GPS signal generator we perform a set of experiments and find the minimal precision of the attacker's spoofing signals required for covert satellite-lock takeover.;
Proceedings of the 18th ACM Conference on Computer and Communications Security;The drastic increase of Android malware has led to a strong interest in developing methods to automate the malware analysis process. Existing automated Android malware detection and classification methods fall into two general categories: 1) signature-based and 2) machine learning-based. Signature-based approaches can be easily evaded by bytecode-level transformation attacks. Prior learning-based works extract features from application syntax rather than program semantics and are also subject to evasion. In this paper we propose a novel semantic-based approach that classifies Android malware via dependency graphs. To battle transformation attacks we extract a weighted contextual API dependency graph as program semantics to construct feature sets. To fight against malware variants and zero-day malware we introduce graph similarity metrics to uncover homogeneous application behaviors while tolerating minor implementation differences. We implement a prototype system DroidSIFT in 23 thousand lines of Java code. We evaluate our system using 2200 malware samples and 13500 benign samples. Experiments show that our signature detection can correctly label 93% of malware instances our anomaly detector is capable of detecting zero-day malware with a low false negative rate (2%) and an acceptable false positive rate (5.15%) for a vetting purpose.;
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security;Tapenade is an Automatic Differentiation (AD) tool which given a Fortran or C code that computes a function creates a new code that computes its tangent or adjoint derivatives. Tapenade puts particular emphasis on adjoint differentiation which computes gradients at a remarkably low cost. This article describes the principles of Tapenade a subset of the general principles of AD. We motivate and illustrate with examples the AD model of Tapenade that is the structure of differentiated codes and the strategies used to make them more efficient. Along with this informal description we formally specify this model by means of data-flow equations and rules of Operational Semantics making this the reference specification of the tangent and adjoint modes of Tapenade. One benefit we expect from this formal specification is the capacity to formally study the AD model itself especially for the adjoint mode and its sophisticated strategies. This article also describes the architectural choices of the implementation of Tapenade. We describe the current performance of Tapenade on a set of codes that include industrial-size applications. We present the extensions of the tool that are planned in a foreseeable future deriving from our ongoing research on AD.;
MARSS: a full system simulator for multicore x86 CPUs;We present MARSS an open source fast full system simulation tool built on QEMU to support cycle-accurate simulation of superscalar homogeneous and heterogeneous multicore x86 processors. MARSS includes detailed models of coherent caches interconnections chipsets memory and IO devices. MARSS simulates the execution of all software components in the system including unmodified binaries of applications OS and libraries.;
Proceedings of the 48th Design Automation Conference;Amazon.com has introduced the Simple Storage Service (S3) a commodity-priced storage utility. S3 aims to provide storage as a low-cost highly available service with a simple 'pay-as-you-go' charging model. This article makes three contributions. First we evaluate S3's ability to provide storage support to large-scale science projects from a cost availability and performance perspective. Second we identify a set of additional functionalities that storage services targeting data-intensive science applications should support. Third we propose unbundling the success metrics for storage utility performance as a solution to reduce storage costs.;
Proceedings of the 2008 International Workshop on Data-Aware Distributed Computing;Few research studies focus on how the use of assistive technologies is affected by social interaction among people. We present an interview study of 20 individuals to determine how assistive technology use is affected by social and professional contexts and interactions. We found that specific assistive devices sometimes marked their users as having disabilities that functional access took priority over feeling self-conscious when using assistive technologies and that two misperceptions pervaded assistive technology use: (1) that assistive devices could functionally eliminate a disability and (2) that people with disabilities would be helpless without their devices. Our findings provide further evidence that accessibility should be built into mainstream technologies. When this is not feasible assistive devices should incorporate cutting edge technologies and strive to be designed for social acceptability a new design approach we propose here.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Demosaicking and denoising are the key first stages of the digital imaging pipeline but they are also a severely ill-posed problem that infers three color values per pixel from a single noisy measurement. Earlier methods rely on hand-crafted filters or priors and still exhibit disturbing visual artifacts in hard cases such as moir\'{e;
Fairness of Exposure in Rankings;Rankings are ubiquitous in the online world today. As we have transitioned from finding books in libraries to ranking products jobs job applicants opinions and potential romantic partners there is a substantial precedent that ranking systems have a responsibility not only to their users but also to the items being ranked. To address these often conflicting responsibilities we propose a conceptual and computational framework that allows the formulation of fairness constraints on rankings in terms of exposure allocation. As part of this framework we develop efficient algorithms for finding rankings that maximize the utility for the user while provably satisfying a specifiable notion of fairness. Since fairness goals can be application specific we show how a broad range of fairness constraints can be implemented using our framework including forms of demographic parity disparate treatment and disparate impact constraints. We illustrate the effect of these constraints by providing empirical results on two ranking problems.;
Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp Data Mining;The market for civilian unmanned aerial vehicles also known as drones is expanding rapidly as new applications are emerging to incorporate the use of civilian drones in our daily lives. On one hand the convenience of offering certain services via drones is attractive. On the other hand the mere operation of these airborne machines which rely heavily on their cyber capabilities poses great threats to people and property. Also while the Federal Aviation Administration NextGen project aims to integrate civilian drones into the national airspace the regulation is still a work-in-progress and does not cope with their threats. This article surveys the main security privacy and safety aspects associated with the use of civilian drones in the national airspace. In particular we identify both the physical and cyber threats of such systems and discuss the security properties required by their critical operation environment. We also identify the research challenges and possible future directions in the fields of civilian drone security safety and privacy. Based on our investigation we forecast that security will be a central enabling technology for the next generation of civilian unmanned aerial vehicles.;
Foveated 3D graphics;"We exploit the falloff of acuity in the visual periphery to accelerate graphics computation by a factor of 5-6 on a desktop HD display (1920x1080). Our method tracks the user's gaze point and renders three image layers around it at progressively higher angular size but lower sampling rate. The three layers are then magnified to display resolution and smoothly composited. We develop a general and efficient antialiasing algorithm easily retrofitted into existing graphics code to minimize twinkling"" artifacts in the lower-resolution layers. A standard psychophysical model for acuity falloff assumes that minimum detectable angular size increases linearly as a function of eccentricity. Given the slope characterizing this falloff we automatically compute layer sizes and sampling rates. The result looks like a full-resolution image but reduces the number of pixels shaded by a factor of 10-15.We performed a user study to validate these results. It identifies two levels of foveation quality: a more conservative one in which users reported foveated rendering quality as equivalent to or better than non-foveated when directly shown both and a more aggressive one in which users were unable to correctly label as increasing or decreasing a short quality progression relative to a high-quality foveated reference. Based on this user study we obtain a slope value for the model of 1.32-1.65 arc minutes per degree of eccentricity. This allows us to predict two future advantages of foveated rendering: (1) bigger savings with larger sharper displays than exist currently (e.g. 100 times speedup at a field of view of 70Â° and resolution matching foveal acuity) and (2) a roughly linear (rather than quadratic or worse) increase in rendering cost with increasing display field of view for planar displays at a constant sharpness.""";
ZenCrowd: leveraging probabilistic reasoning and crowdsourcing techniques for large-scale entity linking;We tackle the problem of entity linking for large collections of online pages Our system ZenCrowd identifies entities from natural language text using state of the art techniques and automatically connects them to the Linked Open Data cloud. We show how one can take advantage of human intelligence to improve the quality of the links by dynamically generating micro-tasks on an online crowdsourcing platform. We develop a probabilistic framework to make sensible decisions about candidate links and to identify unreliable human workers. We evaluate ZenCrowd in a real deployment and show how a combination of both probabilistic reasoning and crowdsourcing techniques can significantly improve the quality of the links while limiting the amount of work performed by the crowd.;
Proceedings of the 21st International Conference on World Wide Web;Congestion control (CC) is the key to achieving ultra-low latency high bandwidth and network stability in high-speed networks. From years of experience operating large-scale and high-speed RDMA networks we find the existing high-speed CC schemes have inherent limitations for reaching these goals. In this paper we present HPCC (High Precision Congestion Control) a new high-speed CC mechanism which achieves the three goals simultaneously. HPCC leverages in-network telemetry (INT) to obtain precise link load information and controls traffic precisely. By addressing challenges such as delayed INT information during congestion and overreac-tion to INT information HPCC can quickly converge to utilize free bandwidth while avoiding congestion and can maintain near-zero in-network queues for ultra-low latency. HPCC is also fair and easy to deploy in hardware. We implement HPCC with commodity programmable NICs and switches. In our evaluation compared to DCQCN and TIMELY HPCC shortens flow completion times by up to 95% causing little congestion even under large-scale incasts.;
Proceedings of the ACM Special Interest Group on Data Communication;We describe a technique that transforms a video from a hand-held video camera so that it appears as if it were taken with a directed camera motion. Our method adjusts the video to appear as if it were taken from nearby viewpoints allowing 3D camera movements to be simulated. By aiming only for perceptual plausibility rather than accurate reconstruction we are able to develop algorithms that can effectively recreate dynamic scenes from a single source video. Our technique first recovers the original 3D camera motion and a sparse set of 3D static scene points using an off-the-shelf structure-from-motion system. Then a desired camera path is computed either automatically (e.g. by fitting a linear or quadratic path) or interactively. Finally our technique performs a least-squares optimization that computes a spatially-varying warp from each input video frame into an output frame. The warp is computed to both follow the sparse displacements suggested by the recovered 3D structure and avoid deforming the content in the video frame. Our experiments on stabilizing challenging videos of dynamic scenes demonstrate the effectiveness of our technique.;
Google Vizier: A Service for Black-Box Optimization;Any sufficiently complex system acts as a black box when it becomes easier to experiment with than to understand. Hence black-box optimization has become increasingly important as systems have become more complex. In this paper we describe Google Vizier a Google-internal service for performing black-box optimization that has become the de facto parameter tuning engine at Google. Google Vizier is used to optimize many of our machine learning models and other systems and also provides core capabilities to Google's Cloud Machine Learning HyperTune subsystem. We discuss our requirements infrastructure design underlying algorithms and advanced features such as transfer learning and automated early stopping that the service provides.;
Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Cloud storage systems are becoming increasingly popular. A promising technology that keeps their cost down is deduplication which stores only a single copy of repeating data. Client-side deduplication attempts to identify deduplication opportunities already at the client and save the bandwidth of uploading copies of existing files to the server. In this work we identify attacks that exploit client-side deduplication allowing an attacker to gain access to arbitrary-size files of other users based on a very small hash signatures of these files. More specifically an attacker who knows the hash signature of a file can convince the storage service that it owns that file hence the server lets the attacker download the entire file. (In parallel to our work a subset of these attacks were recently introduced in the wild with respect to the Dropbox file synchronization service.) To overcome such attacks we introduce the notion of proofs-of-ownership (PoWs) which lets a client efficiently prove to a server that that the client holds a file rather than just some short information about it. We formalize the concept of proof-of-ownership under rigorous security definitions and rigorous efficiency requirements of Petabyte scale storage systems. We then present solutions based on Merkle trees and specific encodings and analyze their security. We implemented one variant of the scheme. Our performance measurements indicate that the scheme incurs only a small overhead compared to naive client-side deduplication.;
Proceedings of the 18th ACM Conference on Computer and Communications Security;A view from computational journalism.;
PetaBricks: a language and compiler for algorithmic choice;It is often impossible to obtain a one-size-fits-all solution for high performance algorithms when considering different choices for data distributions parallelism transformations and blocking. The best solution to these choices is often tightly coupled to different architectures problem sizes data and available system resources. In some cases completely different algorithms may provide the best performance. Current compiler and programming language techniques are able to change some of these parameters but today there is no simple way for the programmer to express or the compiler to choose different algorithms to handle different parts of the data. Existing solutions normally can handle only coarse-grained library level selections or hand coded cutoffs between base cases and recursive cases.We present PetaBricks a new implicitly parallel language and compiler where having multiple implementations of multiple algorithms to solve a problem is the natural way of programming. We make algorithmic choice a first class construct of the language. Choices are provided in a way that also allows our compiler to tune at a finer granularity. The PetaBricks compiler autotunes programs by making both fine-grained as well as algorithmic choices. Choices also include different automatic parallelization techniques data distributions algorithmic parameters transformations and blocking.Additionally we introduce novel techniques to autotune algorithms for different convergence criteria. When choosing between various direct and iterative methods the PetaBricks compiler is able to tune a program in such a way that delivers near-optimal efficiency for any desired level of accuracy. The compiler has the flexibility of utilizing different convergence criteria for the various components within a single algorithm providing the user with accuracy choice alongside algorithmic choice.;
Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation;MapReduce complements DBMSs since databases are not designed for extract-transform-load tasks a MapReduce specialty.;
Mementos: system support for long-running computation on RFID-scale devices;Transiently powered computing devices such as RFID tags kinetic energy harvesters and smart cards typically rely on programs that complete a task under tight time constraints before energy starvation leads to complete loss of volatile memory. Mementos is a software system that transforms general-purpose programs into interruptible computations that are protected from frequent power losses by automatic energy-aware state checkpointing. Mementos comprises a collection of optimization passes for the LLVM compiler infrastructure and a linkable library that exercises hardware support for energy measurement while managing state checkpoints stored in nonvolatile memory. We evaluate Mementos against diverse test cases in a trace-driven simulator of transiently powered RFID-scale devices. Although Mementos's energy checks increase run time when energy is plentiful they allow Mementos to safely suspend execution when energy dwindles effectively spreading computation across zero or more power failures. This paper's contributions are: a study of the runtime environment for programs on RFID-scale devices an energy-aware state checkpointing system for these devices that is implemented for the MSP430 family of microcontrollers and a trace-driven simulator of transiently powered RFID-scale devices.;
Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems;We present a unified dynamics framework for real-time visual effects. Using particles connected by constraints as our fundamental building block allows us to treat contact and collisions in a unified manner and we show how this representation is flexible enough to model gases liquids deformable solids rigid bodies and cloth with two-way interactions. We address some common problems with traditional particle-based methods and describe a parallel constraint solver based on position-based dynamics that is efficient enough for real-time applications.;
Sequential Recommendation with User Memory Networks;User preferences are usually dynamic in real-world recommender systems and a userÂ»s historical behavior records may not be equally important when predicting his/her future interests. Existing recommendation algorithms -- including both shallow and deep approaches -- usually embed a userÂ»s historical records into a single latent vector/representation which may have lost the per item- or feature-level correlations between a userÂ»s historical records and future interests. In this paper we aim to express store and manipulate usersÂ» historical records in a more explicit dynamic and effective manner. To do so we introduce the memory mechanism to recommender systems. Specifically we design a memory-augmented neural network (MANN) integrated with the insights of collaborative filtering for recommendation. By leveraging the external memory matrix in MANN we store and update usersÂ» historical records explicitly which enhances the expressiveness of the model. We further adapt our framework to both item- and feature-level versions and design the corresponding memory reading/writing operations according to the nature of personalized recommendation scenarios. Compared with state-of-the-art methods that consider usersÂ» sequential behavior for recommendation e.g. sequential recommenders with recurrent neural networks (RNN) or Markov chains our method achieves significantly and consistently better performance on four real-world datasets. Moreover experimental analyses show that our method is able to extract the intuitive patterns of how usersÂ» future actions are affected by previous behaviors.;
Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining;"Automatic Gender Recognition (AGR) is a subfield of facial recognition that aims to algorithmically identify the gender of individuals from photographs or videos. In wider society the technology has proposed applications in physical access control data analytics and advertising. Within academia it is already used in the field of Human-Computer Interaction (HCI) to analyse social media usage. Given the long-running critiques of HCI for failing to consider and include transgender (trans) perspectives in research and the potential implications of AGR for trans people if deployed I sought to understand how AGR and HCI understand the term gender"" and how HCI describes and deploys gender recognition technology. Using a content analysis of papers from both fields I show that AGR consistently operationalises gender in a trans-exclusive way and consequently carries disproportionate risk for trans people subject to it. In addition I use the dearth of discussion of this in HCI papers that apply AGR to discuss how HCI operationalises gender and the implications that this has for the field's research. I conclude with recommendations for alternatives to AGR and some ideas for how HCI can work towards a more effective and trans-inclusive treatment of gender.""";
Reactive NUCA: near-optimal block placement and replication in distributed caches;Increases in on-chip communication delay and the large working sets of server and scientific workloads complicate the design of the on-chip last-level cache for multicore processors. The large working sets favor a shared cache design that maximizes the aggregate cache capacity and minimizes off-chip memory requests. At the same time the growing on-chip communication delay favors core-private caches that replicate data to minimize delays on global wires. Recent hybrid proposals offer lower average latency than conventional designs but they address the placement requirements of only a subset of the data accessed by the application require complex lookup and coherence mechanisms that increase latency or fail to scale to high core counts.In this work we observe that the cache access patterns of a range of server and scientific workloads can be classified into distinct classes where each class is amenable to different block placement policies. Based on this observation we propose Reactive NUCA (R-NUCA) a distributed cache design which reacts to the class of each cache access and places blocks at the appropriate location in the cache. R-NUCA cooperates with the operating system to support intelligent placement migration and replication without the overhead of an explicit coherence mechanism for the on-chip last-level cache. In a range of server scientific and multiprogrammed workloads R-NUCA matches the performance of the best cache design for each workload improving performance by 14% on average over competing designs and by 32% at best while achieving performance within 5% of an ideal cache design.;
Proceedings of the 36th Annual International Symposium on Computer Architecture;We present a combined hardware and software solution for markerless reconstruction of non-rigidly deforming physical objects with arbitrary shape in real-time. Our system uses a single self-contained stereo camera unit built from off-the-shelf components and consumer graphics hardware to generate spatio-temporally coherent 3D models at 30 Hz. A new stereo matching algorithm estimates real-time RGB-D data. We start by scanning a smooth template model of the subject as they move rigidly. This geometric surface prior avoids strong scene assumptions such as a kinematic human skeleton or a parametric shape model. Next a novel GPU pipeline performs non-rigid registration of live RGB-D data to the smooth template using an extended non-linear as-rigid-as-possible (ARAP) framework. High-frequency details are fused onto the final mesh using a linear deformation model. The system is an order of magnitude faster than state-of-the-art methods while matching the quality and robustness of many offline algorithms. We show precise real-time reconstructions of diverse scenes including: large deformations of users' heads hands and upper bodies fine-scale wrinkles and folds of skin and clothing and non-rigid interactions performed by users on flexible objects such as toys. We demonstrate how acquired models can be used for many interactive scenarios including re-texturing online performance capture and preview and real-time shape and motion re-targeting.;
Two studies of opportunistic programming: interleaving web foraging learning and writing code;"This paper investigates the role of online resources in problem solving. We look specifically at how programmers - an exemplar form of knowledge workers - opportunistically interleave Web foraging learning and writing code. We describe two studies of how programmers use online resources. The first conducted in the lab observed participants' Web use while building an online chat room. We found that programmers leverage online resources with a range of intentions: They engage in just-in-time learning of new skills and approaches clarify and extend their existing knowledge and remind themselves of details deemed not worth remembering. The results also suggest that queries for different purposes have different styles and durations. Do programmers' queries in the wild"" have the same range of intentions or is this result an artifact of the particular lab setting? We analyzed a month of queries to an online programming portal examining the lexical structure refinements made and result pages visited. Here we also saw traits that suggest the Web is being used for learning and reminding. These results contribute to a theory of online resource usage in programming and suggest opportunities for tools to facilitate online knowledge work.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Camouflaging is a layout-level technique that hampers an attacker from reverse engineering by introducing in one embodiment dummy contacts into the layout. By using a mix of real and dummy contacts one can camouflage a standard cell whose functionality can be one of many. If an attacker cannot resolve the functionality of a camouflaged gate he/she will extract an incorrect netlist. In this paper we analyze the feasibility of identifying the functionality of camouflaged gates. We also propose techniques to make the dummy contact-based IC camouflaging technique resilient to reverse engineering. Furthermore we judiciously select gates to camouflage by using techniques which ensure that the outputs of the extracted netlist are controllably corrupted. The techniques leverage IC testing principles such as justification and sensitization. The proposed techniques are evaluated using ISCAS benchmark circuits and OpenSparc T1 microprocessor controllers.;
Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp Communications Security;Dynamic languages such as JavaScript are more difficult to compile than statically typed ones. Since no concrete type information is available traditional compilers need to emit generic code that can handle all possible type combinations at runtime. We present an alternative compilation technique for dynamically-typed languages that identifies frequently executed loop traces at run-time and then generates machine code on the fly that is specialized for the actual dynamic types occurring on each path through the loop. Our method provides cheap inter-procedural type specialization and an elegant and efficient way of incrementally compiling lazily discovered alternative paths through nested loops. We have implemented a dynamic compiler for JavaScript based on our technique and we have measured speedups of 10x and more for certain benchmark programs.;
Proceedings of the 30th ACM SIGPLAN Conference on Programming Language Design and Implementation;We present a new real-time hand tracking system based on a single depth camera. The system can accurately reconstruct complex hand poses across a variety of subjects. It also allows for robust tracking rapidly recovering from any temporary failures. Most uniquely our tracker is highly flexible dramatically improving upon previous approaches which have focused on front-facing close-range scenarios. This flexibility opens up new possibilities for human-computer interaction with examples including tracking at distances from tens of centimeters through to several meters (for controlling the TV at a distance) supporting tracking using a moving depth camera (for mobile scenarios) and arbitrary camera placements (for VR headsets). These features are achieved through a new pipeline that combines a multi-layered discriminative reinitialization strategy for per-frame pose estimation followed by a generative model-fitting stage. We provide extensive technical details and a detailed qualitative and quantitative analysis.;
Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems;Computers are increasingly used to make decisions that have significant impact on people's lives. Often these predictions can affect different population subgroups disproportionately. As a result the issue of fairness has received much recent interest and a number of fairness-enhanced classifiers have appeared in the literature. This paper seeks to study the following questions: how do these different techniques fundamentally compare to one another and what accounts for the differences? Specifically we seek to bring attention to many under-appreciated aspects of such fairness-enhancing interventions that require investigation for these algorithms to receive broad adoption.We present the results of an open benchmark we have developed that lets us compare a number of different algorithms under a variety of fairness measures and existing datasets. We find that although different algorithms tend to prefer specific formulations of fairness preservations many of these measures strongly correlate with one another. In addition we find that fairness-preserving algorithms tend to be sensitive to fluctuations in dataset composition (simulated in our benchmark by varying training-test splits) and to different forms of preprocessing indicating that fairness interventions might be more brittle than previously thought.;
Proceedings of the Conference on Fairness Accountability and Transparency;In this work we propose a novel method to recognize daily routines as a probabilistic combination of activity patterns. The use of topic models enables the automatic discovery of such patterns in a user's daily routine. We report experimental results that show the ability of the approach to model and recognize daily routines without user annotation.;
Proceedings of the 10th International Conference on Ubiquitous Computing;This paper was first published online by the Internet Society in December 20031 and is being re-published in ACM SIGCOMM Computer Communication Review because of its historic import. It was written at the urging of its primary editor the late Barry Leiner. He felt that a factual rendering of the events and activities associated with the development of the early Internet would be a valuable contribution. The contributing authors did their best to incorporate only factual material into this document. There are sure to be many details that have not been captured in the body of the document but it remains one of the most accurate renderings of the early period of development available.;
Foundations of garbled circuits;Garbled circuits a classical idea rooted in the work of Yao have long been understood as a cryptographic technique not a cryptographic goal. Here we cull out a primitive corresponding to this technique. We call it a garbling scheme. We provide a provable-security treatment for garbling schemes endowing them with a versatile syntax and multiple security definitions. The most basic of these privacy suffices for two-party secure function evaluation (SFE) and private function evaluation (PFE). Starting from a PRF we provide an efficient garbling scheme achieving privacy and we analyze its concrete security. We next consider obliviousness and authenticity properties needed for private and verifiable outsourcing of computation. We extend our scheme to achieve these ends. We provide highly efficient blockcipher-based instantiations of both schemes. Our treatment of garbling schemes presages more efficient garbling more rigorous analyses and more modularly designed higher-level protocols.;
Proceedings of the 2012 ACM Conference on Computer and Communications Security;"Analysis of technology and application trends reveals a growing imbalance in the peak compute-to-memory-capacity ratio for future servers. At the same time the fraction contributed by memory systems to total datacenter costs and power consumption during typical usage is increasing. In response to these trends this paper re-examines traditional compute-memory co-location on a single system and details the design of a new general-purpose architectural building block-a memory blade-that allows memory to be disaggregated"" across a system ensemble. This remote memory blade can be used for memory capacity expansion to improve performance and for sharing memory across servers to reduce provisioning and power costs. We use this memory blade building block to propose two new system architecture solutions-(1) page-swapped remote memory at the virtualization layer and (2) block-access remote memory with support in the coherence hardware-that enable transparent memory expansion and sharing on commodity-based systems. Using simulations of a mix of enterprise benchmarks supplemented with traces from live datacenters we demonstrate that memory disaggregation can provide substantial performance benefits (on average 10X) in memory constrained environments while the sharing enabled by our solutions can improve performance-per-dollar by up to 57% when optimizing memory provisioning across multiple servers.""";
Proceedings of the 36th Annual International Symposium on Computer Architecture;In Autonomous Vehicles (AVs) one fundamental pillar is perceptionwhich leverages sensors like cameras and LiDARs (Light Detection and Ranging) to understand the driving environment. Due to its direct impact on road safety multiple prior efforts have been made to study its the security of perception systems. In contrast to prior work that concentrates on camera-based perception in this work we perform the first security study of LiDAR-based perception in AV settings which is highly important but unexplored. We consider LiDAR spoofing attacks as the threat model and set the attack goal as spoofing obstacles close to the front of a victim AV. We find that blindly applying LiDAR spoofing is insufficient to achieve this goal due to the machine learning-based object detection process.Thus we then explore the possibility of strategically controlling the spoofed attack to fool the machine learning model. We formulate this task as an optimization problem and design modeling methods for the input perturbation function and the objective function.We also identify the inherent limitations of directly solving the problem using optimization and design an algorithm that combines optimization and global sampling which improves the attack success rates to around 75%. As a case study to understand the attack impact at the AV driving decision level we construct and evaluate two attack scenarios that may damage road safety and mobility.We also discuss defense directions at the AV system sensor and machine learning model levels.;
Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security;"Database management system (DBMS) configuration tuning is an essential aspect of any data-intensive application effort. But this is historically a difficult task because DBMSs have hundreds of configuration knobs"" that control everything in the system such as the amount of memory to use for caches and how often data is written to storage. The problem with these knobs is that they are not standardized (i.e. two DBMSs use a different name for the same knob) not independent (i.e. changing one knob can impact others) and not universal (i.e. what works for one application may be sub-optimal for another). Worse information about the effects of the knobs typically comes only from (expensive) experience.To overcome these challenges we present an automated approach that leverages past experience and collects new information to tune DBMS configurations: we use a combination of supervised and unsupervised machine learning methods to (1) select the most impactful knobs (2) map unseen database workloads to previous workloads from which we can transfer experience and (3) recommend knob settings. We implemented our techniques in a new tool called OtterTune and tested it on two DBMSs. Our evaluation shows that OtterTune recommends configurations that are as good as or better than ones generated by existing tools or a human expert.""";
Proceedings of the 2017 ACM International Conference on Management of Data;Current shared memory multicore and multiprocessor systems are nondeterministic. Each time these systems execute a multithreaded application even if supplied with the same input they can produce a different output. This frustrates debugging and limits the ability to properly test multithreaded code becoming a major stumbling block to the much-needed widespread adoption of parallel programming.In this paper we make the case for fully deterministic shared memory multiprocessing (DMP). The behavior of an arbitrary multithreaded program on a DMP system is only a function of its inputs. The core idea is to make inter-thread communication fully deterministic. Previous approaches to coping with nondeterminism in multithreaded programs have focused on replay a technique useful only for debugging. In contrast while DMP systems are directly useful for debugging by offering repeatability by default we argue that parallel programs should execute deterministically in the field as well. This has the potential to make testing more assuring and increase the reliability of deployed multithreaded software. We propose a range of approaches to enforcing determinism and discuss their implementation trade-offs. We show that determinism can be provided with little performance cost using our architecture proposals on future hardware and that software-only approaches can be utilized on existing systems.;
Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems;Permission-based security models provide controlled access to various system resources. The expressiveness of the permission set plays an important role in providing the right level of granularity in access control. In this work we present a methodology for the empirical analysis of permission-based security models which makes novel use of the Self-Organizing Map (SOM) algorithm of Kohonen (2001). While the proposed methodology may be applicable to a wide range of architectures we analyze 1100 Android applications as a case study. Our methodology is of independent interest for visualization of permission-based systems beyond our present Android-specific empirical analysis. We offer some discussion identifying potential points of improvement for the Android permission model attempting to increase expressiveness where needed without increasing the total number of permissions or overall complexity.;
Proceedings of the 17th ACM Conference on Computer and Communications Security;The explosion of user-generated content on the Web has led to new opportunities and significant challenges for companies that are increasingly concerned about monitoring the discussion around their products. Tracking such discussion on weblogs provides useful insight on how to improve products or market them more effectively. An important component of such analysis is to characterize the sentiment expressed in blogs about specific brands and products. Sentiment Analysis focuses on this task of automatically identifying whether a piece of text expresses a positive or negative opinion about the subject matter. Most previous work in this area uses prior lexical knowledge in terms of the sentiment-polarity of words. In contrast some recent approaches treat the task as a text classification problem where they learn to classify sentiment based only on labeled training data. In this paper we present a unified framework in which one can use background lexical information in terms of word-class associations and refine this information for specific domains using any available training examples. Empirical results on diverse domains show that our approach performs better than using background knowledge or training data in isolation as well as alternative approaches to using lexical knowledge with text classification.;
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;As an important component of the virtual reality (VR) technology 360-degree videos provide users with panoramic view and allow them to freely control their viewing direction during video playback. Usually a player displays only the visible portion of a 360 video. Thus fetching the entire raw video frame wastes bandwidth. In this paper we consider the problem of optimizing 360 video delivery over cellular networks. We first conduct a measurement study on commercial 360 video platforms. We then propose a cellular-friendly streaming scheme that delivers only 360 videos' visible portion based on head movement prediction. Using viewing data collected from real users we demonstrate the feasibility of our approach which can reduce bandwidth consumption by up to 80% based on a trace-driven simulation.;
Proceedings of the 5th Workshop on All Things Cellular: Operations Applications and Challenges;"We propose near-eye light field displays that enable thin lightweight head-mounted displays (HMDs) capable of presenting nearly correct convergence accommodation binocular disparity and retinal defocus depth cues. Sharp images are depicted by out-of-focus elements by synthesizing light fields corresponding to virtual objects within a viewer's natural accommodation range. We formally assess the capabilities of microlens arrays to achieve practical near-eye light field displays. Building on concepts shared with existing integral imaging displays and light field cameras we optimize performance in the context of near-eye viewing. We establish fundamental trade-offs between the quantitative parameters of resolution field of view and depth of field as well as the ergonomic parameters of form factor and ranges of allowed eye movement. As with light field cameras our design supports continuous accommodation of the eye throughout a finite depth of field as a result binocular configurations provide a means to address the accommodation-convergence conflict occurring with existing stereoscopic displays. We construct a complete prototype display system comprising: a custom-fabricated HMD using modified off-the-shelf parts and real-time GPU-accelerated light field renderers (including a general ray tracing method and a backward compatible"" rasterization method supporting existing stereoscopic content). Through simulations and experiments we motivate near-eye light field displays as thin lightweight alternatives to conventional near-eye displays.""";
Querying and mining of time series data: experimental comparison of representations and distance measures;The last decade has witnessed a tremendous growths of interests in applications that deal with querying and mining of time series data. Numerous representation methods for dimensionality reduction and similarity measures geared towards time series have been introduced. Each individual work introducing a particular method has made specific claims and aside from the occasional theoretical justifications provided quantitative experimental observations. However for the most part the comparative aspects of these experiments were too narrowly focused on demonstrating the benefits of the proposed methods over some of the previously introduced ones. In order to provide a comprehensive validation we conducted an extensive set of time series experiments re-implementing 8 different representation methods and 9 similarity measures and their variants and testing their effectiveness on 38 time series data sets from a wide variety of application domains. In this paper we give an overview of these different techniques and present our comparative experimental findings regarding their effectiveness. Our experiments have provided both a unified validation of some of the existing achievements and in some cases suggested that certain claims in the literature may be unduly optimistic.;
Trinity: a distributed graph engine on a memory cloud;Computations performed by graph algorithms are data driven and require a high degree of random data access. Despite the great progresses made in disk technology it still cannot provide the level of efficient random access required by graph computation. On the other hand memory-based approaches usually do not scale due to the capacity limit of single machines. In this paper we introduce Trinity a general purpose graph engine over a distributed memory cloud. Through optimized memory management and network communication Trinity supports fast graph exploration as well as efficient parallel computing. In particular Trinity leverages graph access patterns in both online and offline computation to optimize memory and communication for best performance. These enable Trinity to support efficient online query processing and offline analytics on large graphs with just a few commodity machines. Furthermore Trinity provides a high level specification language called TSL for users to declare data schema and communication protocols which brings great ease-of-use for general purpose graph management and computing. Our experiments show Trinity's performance in both low latency graph queries as well as high throughput graph analytics on web-scale billion-node graphs.;
Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data;A brief review of the Internet history reveals the fact that the Internet evolved after the formation of primarily independent networks. Similarly interconnected clouds also called Inter-cloud can be viewed as a natural evolution of cloud computing. Recent studies show the benefits in utilizing multiple clouds and present attempts for the realization of an Inter-cloud or federated cloud environment. However cloud vendors have not taken into account cloud interoperability issues and each cloud comes with its own solution and interfaces for services. This survey initially discusses all the relevant aspects motivating cloud interoperability. Furthermore it categorizes and identifies possible cloud interoperability scenarios and architectures. The spectrum of challenges and obstacles that the Inter-cloud realization is faced with are covered a taxonomy of them is provided and fitting enablers that tackle each challenge are identified. All these aspects require a comprehensive review of the state of the art including ongoing projects and studies in the area. We conclude by discussing future directions and trends toward the holistic approach in this regard.;
Base-delta-immediate compression: practical data compression for on-chip caches;Cache compression is a promising technique to increase on-chip cache capacity and to decrease on-chip and off-chip bandwidth usage. Unfortunately directly applying well-known compression algorithms (usually implemented in software) leads to high hardware complexity and unacceptable decompression/compression latencies which in turn can negatively affect performance. Hence there is a need for a simple yet efficient compression technique that can effectively compress common in-cache data patterns and has minimal effect on cache access latency.In this paper we introduce a new compression algorithm called Base-Delta-Immediate (BÎ”I) compression a practical technique for compressing data in on-chip caches. The key idea is that for many cache lines the values within the cache line have a low dynamic range - i.e. the differences between values stored within the cache line are small. As a result a cache line can be represented using a base value and an array of differences whose combined size is much smaller than the original cache line (we call this the base+delta encoding). Moreover many cache lines intersperse such base+delta values with small values - our BÎ”I technique efficiently incorporates such immediate values into its encoding.Compared to prior cache compression approaches our studies show that BÎ”I strikes a sweet-spot in the tradeoff between compression ratio decompression/compression latencies and hardware complexity. Our results show that BÎ”I compression improves performance for both single-core (8.1% improvement) and multi-core workloads (9.5% / 11.2% improvement for two/four cores). For many applications BÎ”I provides the performance benefit of doubling the cache size of the baseline system effectively increasing average cache capacity by 1.53X.;
Proceedings of the 21st International Conference on Parallel Architectures and Compilation Techniques;Hundreds of millions of people play computer games every day. For them game contentâ€”from 3D objects to abstract puzzlesâ€”plays a major entertainment role. Manual labor has so far ensured that the quality and quantity of game content matched the demands of the playing community but is facing new scalability challenges due to the exponential growth over the last decade of both the gamer population and the production costs. Procedural Content Generation for Games (PCG-G) may address these challenges by automating or aiding in game content generation. PCG-G is difficult since the generator has to create the content satisfy constraints imposed by the artist and return interesting instances for gamers. Despite a large body of research focusing on PCG-G particularly over the past decade ours is the first comprehensive survey of the field of PCG-G. We first introduce a comprehensive six-layered taxonomy of game content: bits space systems scenarios design and derived. Second we survey the methods used across the whole field of PCG-G from a large research body. Third we map PCG-G methods to game content layers it turns out that many of the methods used to generate game content from one layer can be used to generate content from another. We also survey the use of methods in practice that is in commercial or prototype games. Fourth and last we discuss several directions for future research in PCG-G which we believe deserve close attention in the near future.;
Learning structural SVMs with latent variables;We present a large-margin formulation and algorithm for structured output prediction that allows the use of latent variables. Our proposal covers a large range of application problems with an optimization problem that can be solved efficiently using Concave-Convex Programming. The generality and performance of the approach is demonstrated through three applications including motiffinding noun-phrase coreference resolution and optimizing precision at k in information retrieval.;
Proceedings of the 26th Annual International Conference on Machine Learning;In this paper we show that up to hundreds of software load balancer (SLB) servers can be replaced by a single modern switching ASIC potentially reducing the cost of load balancing by over two orders of magnitude. Today large data centers typically employ hundreds or thousands of servers to load-balance incoming traffic over application servers. These software load balancers (SLBs) map packets destined to a service (with a virtual IP address or VIP) to a pool of servers tasked with providing the service (with multiple direct IP addresses or DIPs). An SLB is stateful it must always map a connection to the same server even if the pool of servers changes and/or if the load is spread differently across the pool. This property is called per-connection consistency or PCC. The challenge is that the load balancer must keep track of millions of connections simultaneously.Until recently it was not possible to implement a load balancer with PCC in a merchant switching ASIC because high-performance switching ASICs typically can not maintain per-connection states with PCC. Newer switching ASICs provide resources and primitives to enable PCC at a large scale. In this paper we explore how to use switching ASICs to build much faster load balancers than have been built before. Our system called SilkRoad is defined in a 400 line P4 program and when compiled to a state-of-the-art switching ASIC we show it can load-balance ten million connections simultaneously at line rate.;
Proceedings of the Conference of the ACM Special Interest Group on Data Communication;Light field photography has gained a significant research interest in the last two decades today commercial light field cameras are widely available. Nevertheless most existing acquisition approaches either multiplex a low-resolution light field into a single 2D sensor image or require multiple photographs to be taken for acquiring a high-resolution light field. We propose a compressive light field camera architecture that allows for higher-resolution light fields to be recovered than previously possible from a single image. The proposed architecture comprises three key components: light field atoms as a sparse representation of natural light fields an optical design that allows for capturing optimized 2D light field projections and robust sparse reconstruction methods to recover a 4D light field from a single coded 2D projection. In addition we demonstrate a variety of other applications for light field atoms and sparse coding including 4D light field compression and denoising.;
Topic modeling with network regularization;In this paper we formally define the problem of topic modeling with network structure (TMN). We propose a novel solution to this problem which regularizes a statistical topic model with a harmonic regularizer based on a graph structure in the data. The proposed method bridges topic modeling and social network analysis which leverages the power of both statistical topic models and discrete regularization. The output of this model well summarizes topics in text maps a topic on the network and discovers topical communities. With concrete selection of a topic model and a graph-based regularizer our model can be applied to text mining problems such as author-topic analysis community discovery and spatial text mining. Empirical experiments on two different genres of data show that our approach is effective which improves text-oriented methods as well as network-oriented methods. The proposed model is general it can be applied to any text collections with a mixture of topics and an associated network structure.;
Proceedings of the 17th International Conference on World Wide Web;Data-driven models help mobile app designers understand best practices and trends and can be used to make predictions about design performance and support the creation of adaptive UIs. This paper presents Rico the largest repository of mobile app designs to date created to support five classes of data-driven applications: design search UI layout generation UI code generation user interaction modeling and user perception prediction. To create Rico we built a system that combines crowdsourcing and automation to scalably mine design and interaction data from Android apps at runtime. The Rico dataset contains design data from more than 9.7k Android apps spanning 27 categories. It exposes visual textual structural and interactive design properties of more than 72k unique UI screens. To demonstrate the kinds of applications that Rico enables we present results from training an autoencoder for UI layout similarity which supports query- by-example search over UIs.;
Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology;Scientific discovery and engineering innovation requires unifying traditionally separated high-performance computing and big data analytics.;
HCI and environmental sustainability: the politics of design and the design of politics;Many HCI researchers have recently begun to examine the opportunities to use ICTs to promote environmental sustainability and ecological consciousness on the part of technology users. This paper examines the way that traditional HCI discourse obscures political and cultural contexts of environmental practice that must be part of an effective solution. Research on ecological politics and the political economy of environmentalism highlight some missing elements in contemporary HCI analysis and suggest some new directions for the relationship between sustainability and HCI. In particular I propose that questions of scale -- the scales of action and the scales of effects -- might provide a useful new entry point for design practice.;
Proceedings of the 8th ACM Conference on Designing Interactive Systems;Distributed computing remains inaccessible to a large number of users in spite of many open source platforms and extensive commercial offerings. While distributed computation frameworks have moved beyond a simple map-reduce model many users are still left to struggle with complex cluster management and configuration tools even for running simple embarrassingly parallel jobs. We argue that stateless functions represent a viable platform for these users eliminating cluster management overhead fulfilling the promise of elasticity. Furthermore using our prototype implementation PyWren we show that this model is general enough to implement a number of distributed computing models such as BSP efficiently. Extrapolating from recent trends in network bandwidth and the advent of disaggregated storage we suggest that stateless functions are a natural fit for data processing in future computing environments.;
Proceedings of the 2017 Symposium on Cloud Computing;Alongside the growing interest within HCI and arguably computing more generally in conducting research that has substantial societal benefits there is a need for new ways to think about and to articulate the challenges of these engaged research projects as well as their results. Action Research (AR) is a class of methods and approaches for conducting democratic and collaborative research with community partners. AR has evolved over the last several decades and offers HCI researchers theoretical lenses methodological approaches and pragmatic guidance for conducting socially relevant collaborative and engaged research. In this article I describe the historical context and origins of AR the scientifically rigorous practice of conducting and evaluating AR projects and the ways in which AR might meaningfully be applied to HCI research.;
BTRFS: The Linux B-Tree Filesystem;BTRFS is a Linux filesystem that has been adopted as the default filesystem in some popular versions of Linux. It is based on copy-on-write allowing for efficient snapshots and clones. It uses B-trees as its main on-disk data structure. The design goal is to work well for many use cases and workloads. To this end much effort has been directed to maintaining even performance as the filesystem ages rather than trying to support a particular narrow benchmark use-case.Linux filesystems are installed on smartphones as well as enterprise servers. This entails challenges on many different fronts.---Scalability. The filesystem must scale in many dimensions: disk space memory and CPUs.---Data integrity. Losing data is not an option and much effort is expended to safeguard the content. This includes checksums metadata duplication and RAID support built into the filesystem.---Disk diversity. The system should work well with SSDs and hard disks. It is also expected to be able to use an array of different sized disks which poses challenges to the RAID and striping mechanisms.This article describes the core ideas data structures and algorithms of this filesystem. It sheds light on the challenges posed by defragmentation in the presence of snapshots and the tradeoffs required to maintain even performance in the face of a wide spectrum of workloads.;
Are we really making much progress? A worrying analysis of recent neural recommendation approaches;Deep learning techniques have become the method of choice for researchers working on algorithmic aspects of recommender systems. With the strongly increased interest in machine learning in general it has as a result become difficult to keep track of what represents the state-of-the-art at the moment e.g. for top-n recommendation tasks. At the same time several recent publications point out problems in today's research practice in applied machine learning e.g. in terms of the reproducibility of the results or the choice of the baselines when proposing new models.In this work we report the results of a systematic analysis of algorithmic proposals for top-n recommendation tasks. Specifically we considered 18 algorithms that were presented at top-level research conferences in the last years. Only 7 of them could be reproduced with reasonable effort. For these methods it however turned out that 6 of them can often be outperformed with comparably simple heuristic methods e.g. based on nearest-neighbor or graph-based techniques. The remaining one clearly outperformed the baselines but did not consistently outperform a well-tuned non-neural linear ranking method. Overall our work sheds light on a number of potential problems in today's machine learning scholarship and calls for improved scientific practices in this area.;
Proceedings of the 13th ACM Conference on Recommender Systems;This remark describes an improvement and a correction to Algorithm 778. It is shown that the performance of the algorithm can be improved significantly by making a relatively simple modification to the subspace minimization phase. The correction concerns an error caused by the use of routine dpmeps to estimate machine precision.;
A lived informatics model of personal informatics;Current models of how people use personal informatics systems are largely based in behavior change goals. They do not adequately characterize the integration of self-tracking into everyday life by people with varying goals. We build upon prior work by embracing the perspective of lived informatics to propose a new model of personal informatics. We examine how lived informatics manifests in the habits of self-trackers across a variety of domains first by surveying 105 99 and 83 past and present trackers of physical activity finances and location and then by interviewing 22 trackers regarding their lived informatics experiences. We develop a model characterizing tracker processes of deciding to track and selecting a tool elaborate on tool usage during collection integration and reflection as components of tracking and acting and discuss the lapsing and potential resuming of tracking. We use our model to surface underexplored challenges in lived informatics thus identifying future directions for personal informatics design and research.;
Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing;Dynamic random-access memory (DRAM) is the building block of modern main memory systems. DRAM cells must be periodically refreshed to prevent loss of data. These refresh operations waste energy and degrade system performance by interfering with memory accesses. The negative effects of DRAM refresh increase as DRAM device capacity increases. Existing DRAM devices refresh all cells at a rate determined by the leakiest cell in the device. However most DRAM cells can retain data for significantly longer. Therefore many of these refreshes are unnecessary.In this paper we propose RAIDR (Retention-Aware Intelligent DRAM Refresh) a low-cost mechanism that can identify and skip unnecessary refreshes using knowledge of cell retention times. Our key idea is to group DRAM rows into retention time bins and apply a different refresh rate to each bin. As a result rows containing leaky cells are refreshed as frequently as normal while most rows are refreshed less frequently. RAIDR uses Bloom filters to efficiently implement retention time bins. RAIDR requires no modification to DRAM and minimal modification to the memory controller. In an 8-core system with 32 GB DRAM RAIDR achieves a 74.6% refresh reduction an average DRAM power reduction of 16.1% and an average system performance improvement of 8.6% over existing systems at a modest storage overhead of 1.25 KB in the memory controller. RAIDR's benefits are robust to variation in DRAM system configuration and increase as memory capacity increases.;
Proceedings of the 39th Annual International Symposium on Computer Architecture;Web applications support many of our daily activities but they often have security problems and their accessibility makes them easy to exploit. In cross-site scripting (XSS) an attacker exploits the trust a web client (browser) has for a trusted server and executes injected script on the browser with the server's privileges. In 2006 XSS constituted the largest class of newly reported vulnerabilities making it the most prevalent class of attacks today. Web applications have XSS vulnerabilities because the validation they perform on untrusted input does not suffice to prevent that input from invoking a browser's JavaScript interpreter and this validation is particularly difficult to get right if it must admit some HTML mark-up. Most existing approaches to finding XSS vulnerabilities are taint-based and assume input validation functions to be adequate so they either miss real vulnerabilities or report many false positives.This paper presents a static analysis for finding XSS vulnerabilities that directly addresses weak or absent input validation. Our approach combines work on tainted information flow with string analysis. Proper input validation is difficult largely because of the many ways to invoke the JavaScript interpreter we face the same obstacle checking for vulnerabilities statically and we address it by formalizing a policy based on the W3C recommendation the Firefox source code and online tutorials about closed-source browsers. We provide effective checking algorithms based on our policy. We implement our approach and provide an extensive evaluation that finds both known and unknown vulnerabilities in real-world web applications.;
Proceedings of the 30th International Conference on Software Engineering;Developers frequently use inefficient code sequences that could be fixed by simple patches. These inefficient code sequences can cause significant performance degradation and resource waste referred to as performance bugs. Meager increases in single threaded performance in the multi-core era and increasing emphasis on energy efficiency call for more effort in tackling performance bugs.This paper conducts a comprehensive study of 110 real-world performance bugs that are randomly sampled from five representative software suites (Apache Chrome GCC Mozilla and MySQL). The findings of this study provide guidance for future work to avoid expose detect and fix performance bugs.Guided by our characteristics study efficiency rules are extracted from 25 patches and are used to detect performance bugs. 332 previously unknown performance problems are found in the latest versions of MySQL Apache and Mozilla applications including 219 performance problems found by applying rules across applications.;
Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation;The JavaScript programming language is widely used for web programming and increasingly for general purpose computing. As such improving the correctness security and performance of JavaScript applications has been the driving force for research in type systems static analysis and compiler techniques for this language. Many of these techniques aim to reign in some of the most dynamic features of the language yet little seems to be known about how programmers actually utilize the language or these features. In this paper we perform an empirical study of the dynamic behavior of a corpus of widely-used JavaScript programs and analyze how and why the dynamic features are used. We report on the degree of dynamism that is exhibited by these JavaScript programs and compare that with assumptions commonly made in the literature and accepted industry benchmark suites.;
Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation;"Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly in the wild"" contexts and understand how practices evolve over long-term naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings which both support and contrast with those of previous research paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.""";
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Current-generation Deep Neural Networks (DNNs) such as AlexNet and VGG rely heavily on dense floating-point matrix multiplication (GEMM) which maps well to GPUs (regular parallelism high TFLOP/s). Because of this GPUs are widely used for accelerating DNNs. Current FPGAs offer superior energy efficiency (Ops/Watt) but they do not offer the performance of today's GPUs on DNNs. In this paper we look at upcoming FPGA technology advances the rapid pace of innovation in DNN algorithms and consider whether future high-performance FPGAs will outperform GPUs for next-generation DNNs. The upcoming IntelÂ® 14-nm Stratix? 10 FPGAs will have thousands of hard floating-point units (DSPs) and on-chip RAMs (M20K memory blocks). They will also have high bandwidth memories (HBMs) and improved frequency (HyperFlex? core architecture). This combination of features brings FPGA raw floating point performance within striking distance of GPUs. Meanwhile DNNs are quickly evolving. For example recent innovations that exploit sparsity (e.g. pruning) and compact data types (e.g. 1-2 bit) result in major leaps in algorithmic efficiency. However these innovations introduce irregular parallelism on custom data types which are difficult for GPUs to handle but would be a great fit for FPGA's extreme customizability.This paper evaluates a selection of emerging DNN algorithms on two generations of Intel FPGAs (Arria'10 Stratix'10) against the latest highest performance Titan X Pascal GPU. We created a customizable DNN accelerator template for FPGAs and used it in our evaluations. First we study various GEMM operations for next-generation DNNs. Our results show that Stratix 10 FPGA is 10% 50% and 5.4x better in performance (TOP/sec) than Titan X Pascal GPU on GEMM operations for pruned Int6 and binarized DNNs respectively. Then we present a detailed case study on accelerating Ternary ResNet which relies on sparse GEMM on 2-bit weights (i.e. weights constrained to 0+1-1) and full-precision neurons. The Ternary ResNet accuracy is within ~1% of the full-precision ResNet which won the 2015 ImageNet competition. On Ternary-ResNet the Stratix 10 FPGA can deliver 60% better performance over Titan X Pascal GPU while being 2.3x better in performance/watt. Our results indicate that FPGAs may become the platform of choice for accelerating next-generation DNNs.;
Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays;This paper presents Widar2.0 the first WiFi-based system that enables passive human localization and tracking using a single link on commodity off-the-shelf devices. Previous works based on either specialized or commercial hardware all require multiple links preventing their wide adoption in scenarios like homes where typically only one single AP is installed. The key insight underlying Widar2.0 to circumvent the use of multiple links is to leverage multi-dimensional signal parameters from one single link. To this end we build a unified model accounting for Angle-of-Arrival Time-of-Flight and Doppler shifts together and devise an efficient algorithm for their joint estimation. We then design a pipeline to translate the erroneous raw parameters into precise locations which first finds parameters corresponding to the reflections of interests then refines range estimates and ultimately outputs target locations. Our implementation and evaluation on commodity WiFi devices demonstrate that Widar2.0 achieves better or comparable performance to state-of-the-art localization systems which either use specialized hardwares or require 2 to 40 Wi-Fi links.;
Proceedings of the 16th Annual International Conference on Mobile Systems Applications and Services;Despite of several years of innovative research indoor localization is still not mainstream. Existing techniques either employ cumbersome fingerprinting or rely upon the deployment of additional infrastructure. Towards a solution that is easier to adopt we propose CUPID which is free from these restrictions yet is comparable in accuracy. While existing WiFi based solutions are highly susceptible to indoor multipath CUPID utilizes physical layer (PHY) information to extract the signal strength and the angle of only the direct path successfully avoiding the effect of multipath reflections. Our main observation is that natural human mobility when combined with PHY layer information can help in accurately estimating the angle and distance of a mobile device from an wireless access point (AP). Real-world indoor experiments using off-the-shelf wireless chipsets confirm the feasibility of CUPID. In addition while previous approaches rely on multiple APs CUPID is able to localize a device when only a single AP is present. When a few more APs are available CUPID can improve the median localization error to 2.7m which is comparable to schemes that rely on expensive fingerprinting or additional infrastructure.;
Proceeding of the 11th Annual International Conference on Mobile Systems Applications and Services;"Programmers commonly reuse existing frameworks or libraries to reduce software development efforts. One common problem in reusing the existing frameworks or libraries is that the programmers know what type of object that they need but do not know how to get that object with a specific method sequence. To help programmers to address this issue we have developed an approach that takes queries of the form Source object type â†’ Destination object type"" as input and suggests relevant method-invocation sequences that can serve as solutions that yield the destination object from the source object given in the query. Our approach interacts with a code search engine (CSE) to gather relevant code samples and performs static analysis over the gathered samples to extract required sequences. As code samples are collected on demand through CSE our approach is not limited to queries of any specific set of frameworks or libraries. We have implemented our approach with a tool called PARSEWeb and conducted four different evaluations to show that our approach is effective in addressing programmer's queries. We also show that PARSEWeb performs better than existing related tools: Prospector and Strathcona""";
Proceedings of the 22nd IEEE/ACM International Conference on Automated Software Engineering;Multicore hardware is making concurrent programs pervasive. Unfortunately concurrent programs are prone to bugs. Among different types of concurrency bugs atomicity violation bugs are common and important. Existing techniques to detect atomicity violation bugs suffer from one limitation: requiring bugs to manifest during monitored runs which is an open problem in concurrent program testing.This paper makes two contributions. First it studies the interleaving characteristics of the common practice in concurrent program testing (i.e. running a program over and over) to understand why atomicity violation bugs are hard to expose. Second it proposes CTrigger to effectively and efficiently expose atomicity violation bugs in large programs. CTrigger focuses on a special type of interleavings (i.e. unserializable interleavings) that are inherently correlated to atomicity violation bugs and uses trace analysis to systematically identify (likely) feasible unserializable interleavings with low occurrence-probability. CTrigger then uses minimum execution perturbation to exercise low-probability interleavings and expose difficult-to-catch atomicity violation.We evaluate CTrigger with real-world atomicity violation bugs from four sever/desktop applications (Apache MySQL Mozilla and PBZIP2) and three SPLASH2 applications on 8-core machines. CTrigger efficiently exposes the tested bugs within 1--235 seconds two to four orders of magnitude faster than stress testing. Without CTrigger some of these bugs do not manifest even after 7 full days of stress testing. In addition without deterministic replay support once a bug is exposed CTrigger can help programmers reliably reproduce it for diagnosis. Our tested bugs are reproduced by CTrigger mostly within 5 seconds 300 to over 60000 times faster than stress testing.;
Proceedings of the 14th International Conference on Architectural Support for Programming Languages and Operating Systems;Though widespread interest in software containers is a relatively recent phenomenon at Google we have been managing Linux containers at scale for more than ten years and built three different container-management systems in that time. Each system was heavily influenced by its predecessors even though they were developed for different reasons. This article describes the lessons weâ€™ve learned from developing and operating them.;
Accelerating CUDA graph algorithms at maximum warp;Graphs are powerful data representations favored in many computational domains. Modern GPUs have recently shown promising results in accelerating computationally challenging graph problems but their performance suffered heavily when the graph structure is highly irregular as most real-world graphs tend to be. In this study we first observe that the poor performance is caused by work imbalance and is an artifact of a discrepancy between the GPU programming model and the underlying GPU architecture.We then propose a novel virtual warp-centric programming method that exposes the traits of underlying GPU architectures to users. Our method significantly improves the performance of applications with heavily imbalanced workloads and enables trade-offs between workload imbalance and ALU underutilization for fine-tuning the performance. Our evaluation reveals that our method exhibits up to 9x speedup over previous GPU algorithms and 12x over single thread CPU execution on irregular graphs. When properly configured it also yields up to 30% improvement over previous GPU algorithms on regular graphs. In addition to performance gains on graph algorithms our programming method achieves 1.3x to 15.1x speedup on a set of GPU benchmark applications. Our study also confirms that the performance gap between GPUs and other multi-threaded CPU graph implementations is primarily due to the large difference in memory bandwidth.;
Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming;Based on concepts of the human visual system computational visual attention systems aim to detect regions of interest in images. Psychologists neurobiologists and computer scientists have investigated visual attention thoroughly during the last decades and profited considerably from each other. However the interdisciplinarity of the topic holds not only benefits but also difficulties: Concepts of other fields are usually hard to access due to differences in vocabulary and lack of knowledge of the relevant literature. This article aims to bridge this gap and bring together concepts and ideas from the different research areas. It provides an extensive survey of the grounding psychological and biological research on visual attention as well as the current state of the art of computational systems. Furthermore it presents a broad range of applications of computational attention systems in fields like computer vision cognitive systems and mobile robotics. We conclude with a discussion on the limitations and open questions in the field.;
Digital game design for elderly users;The current paper reviews and discusses digital game design for elderly users. The aim of the paper is to look beyond the traditional perspective of usability requirements imposed by age-related functional limitations towards the design opportunities that exist to create digital games that will offer engaging content combined with an interface that seniors can easily and pleasurably use.;
Proceedings of the 2007 Conference on Future Play;With the development of the NAND-Flash technology NAND-Flash based Solid-State Disk (SSD) has been attracting a great deal of attention from both industry and academia. While a range of SSD research topics from interface techniques to buffer management and Flash Translation Layer (FTL) from performance to endurance and energy efficiency have been extensively studied in the literature the SSD being studied was by and large treated as a grey or black box in that many of the internal features such as advanced commands physical-page allocation schemes and data granularity are hidden or assumed away. We argue that based on our experimental study it is these internal features and their interplay that will help provide the missing but significant insights to designing high-performance and high-endurance SSDs.In this paper we use our highly accurate and multi-tiered SSD simulator called SSDsim to analyze several key internal SSD factors to characterize their performance impacts interplay and parallelisms for the purpose of performance and endurance en-hancement of SSDs. From the results of our experiments we found that: (1) larger pages tend to have significantly negative impact on SSD performance under many workloads (2) different physical-page allocation schemes have different deployment en-vironments where an optimal allocation scheme can be found for each workload (3) although advanced commands provided by flash manufacturers can improve performance in some cases they may jeopardize the SSD performance and endurance when used inappropriately (4) since the parallelisms of SSD can be classified into four levels namely channel-level chip-level die-level and plane-level the priority order of SSD parallelism resulting from the strong interplay among physical-page allocation schemes and advanced commands can have a very significant impact on SSD performance and endurance.;
Proceedings of the International Conference on Supercomputing;Exploring the factors that may lead to the inability of professionals to adapt or cope with emerging IS in a healthy manner.;
Principles of Explanatory Debugging to Personalize Interactive Machine Learning;How can end users efficiently influence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging an approach in which the system explains to users how it made each of its predictions and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants' understanding of the learning system by 52% and allowed participants to correct its mistakes up to twice as efficiently as participants using a traditional learning system.;
Proceedings of the 20th International Conference on Intelligent User Interfaces;The vision of embedding connectivity into billions of everyday objects runs into the reality of existing communication technologies -- there is no existing wireless technology that can provide reliable and long-range communication at tens of microwatts of power as well as cost less than a dime. While backscatter is low-power and low-cost it is known to be limited to short ranges. This paper overturns this conventional wisdom about backscatter and presents the first wide-area backscatter system. Our design can successfully backscatter from any location between an RF source and receiver separated by 475 m while being compatible with commodity LoRa hardware. Further when our backscatter device is co-located with the RF source the receiver can be as far as 2.8 km away. We deploy our system in a 4800 ft2 (446 m2) house spread across three floors a 13024 ft2 (1210 m2) office area covering 41 rooms as well as a one-acre (4046 m2) vegetable farm and show that we can achieve reliable coverage using only a single RF source and receiver. We also build a contact lens prototype as well as a flexible epidermal patch device attached to the human skin. We show that these devices can reliably backscatter data across a 3328 ft2 (309 m2) room. Finally we present a design sketch of a LoRa backscatter IC that shows that it costs less than a dime at scale and consumes only 9.25 Î¼W of power which is more than 1000x lower power than LoRa radio chipsets.;
ARIA: automatic resource inference and allocation for mapreduce environments;MapReduce and Hadoop represent an economically compelling alternative for efficient large scale data processing and advanced analytics in the enterprise. A key challenge in shared MapReduce clusters is the ability to automatically tailor and control resource allocations to different applications for achieving their performance goals. Currently there is no job scheduler for MapReduce environments that given a job completion deadline could allocate the appropriate amount of resources to the job so that it meets the required Service Level Objective (SLO). In this work we propose a framework called ARIA to address this problem. It comprises of three inter-related components. First for a production job that is routinely executed on a new dataset we build a job profile that compactly summarizes critical performance characteristics of the underlying application during the map and reduce stages. Second we design a MapReduce performance model that for a given job (with a known profile) and its SLO (soft deadline) estimates the amount of resources required for job completion within the deadline. Finally we implement a novel SLO-based scheduler in Hadoop that determines job ordering and the amount of resources to allocate for meeting the job deadlines.We validate our approach using a set of realistic applications. The new scheduler effectively meets the jobs' SLOs until the job demands exceed the cluster resources. The results of the extensive simulation study are validated through detailed experiments on a 66-node Hadoop cluster.;
Proceedings of the 8th ACM International Conference on Autonomic Computing;Environment monitoring in coal mines is an important application of wireless sensor networks (WSNs) that has commercial potential. We discuss the design of a Structure-Aware Self-Adaptive WSN system SASA. By regulating the mesh sensor network deployment and formulating a collaborative mechanism based on a regular beacon strategy SASA is able to rapidly detect structure variations caused by underground collapses. We further develop a sound and robust mechanism for efficiently handling queries under instable circumstances. A prototype is deployed with 27 mica2 motes in a real coal mine. We present our implementation experiences as well as the experimental results. To better evaluate the scalability and reliability of SASA we also conduct a large-scale trace-driven simulation based on real data collected from the experiments.;
Sensor network data fault types;This tutorial presents a detailed study of sensor faults that occur in deployed sensor networks and a systematic approach to model these faults. We begin by reviewing the fault detection literature for sensor networks. We draw from current literature our own experience and data collected from scientific deployments to develop a set of commonly used features useful in detecting and diagnosing sensor faults. We use this feature set to systematically define commonly observed faults and provide examples of each of these faults from sensor data collected at recent deployments.;
Bubble-flux: precise online QoS management for increased utilization in warehouse scale computers;"Ensuring the quality of service (QoS) for latency-sensitive applications while allowing co-locations of multiple applications on servers is critical for improving server utilization and reducing cost in modern warehouse-scale computers (WSCs). Recent work relies on static profiling to precisely predict the QoS degradation that results from performance interference among co-running applications to increase the number of safe"" co-locations. However these static profiling techniques have several critical limitations: 1) a priori knowledge of all workloads is required for profiling 2) it is difficult for the prediction to capture or adapt to phase or load changes of applications and 3) the prediction technique is limited to only two co-running applications.To address all of these limitations we present Bubble-Flux an integrated dynamic interference measurement and online QoS management mechanism to provide accurate QoS control and maximize server utilization. Bubble-Flux uses a Dynamic Bubble to probe servers in real time to measure the instantaneous pressure on the shared hardware resources and precisely predict how the QoS of a latency-sensitive job will be affected by potential co-runners. Once ""safe"" batch jobs are selected and mapped to a server Bubble-Flux uses an Online Flux Engine to continuously monitor the QoS of the latency-sensitive application and control the execution of batch jobs to adapt to dynamic input phase and load changes to deliver satisfactory QoS. Batch applications remain in a state of flux throughout execution. Our results show that the utilization improvement achieved by Bubble-Flux is up to 2.2x better than the prior static approach.""";
Proceedings of the 40th Annual International Symposium on Computer Architecture;Rather more than 25 years ago as part of a usability engineering program I developed a questionnaire---the System Usability Scale (SUS)---that could be used to take a quick measurement of how people perceived the usability of computer systems on which they were working. This proved to be an extremely simple and reliable tool for use when doing usability evaluations and I decided with the blessing of engineering management at Digital Equipment Co. Ltd (DEC where I developed SUS) that it was probably something that could be used by other organizations (the benefit for us being that if they did use it we potentially had something we could use to compare their systems against ours). So in 1986 I made SUS freely available to a number of colleagues with permission to pass it on to anybody else who might find it useful and over the next few years occasionally heard of evaluations of systems where researchers and usability engineers had used it with some success.;
Embree: a kernel framework for efficient CPU ray tracing;We describe Embree an open source ray tracing framework for x86 CPUs. Embree is explicitly designed to achieve high performance in professional rendering environments in which complex geometry and incoherent ray distributions are common. Embree consists of a set of low-level kernels that maximize utilization of modern CPU architectures and an API which enables these kernels to be used in existing renderers with minimal programmer effort. In this paper we describe the design goals and software architecture of Embree and show that for secondary rays in particular the performance of Embree is competitive with (and often higher than) existing state-of-the-art methods on CPUs and GPUs.;
Cabernet: vehicular content delivery using WiFi;Cabernet is a system for delivering data to and from moving vehicles using open 802.11 (WiFi) access points encountered opportunistically during travel. Using open WiFi access from the road can be challenging. Network connectivity in Cabernet is both fleeting (access points are typically within range for a few seconds) and intermittent (because the access points do not provide continuous coverage) and suffers from high packet loss rates over the wireless channel. On the positive side WiFi data transfers when available can occur at broadband speeds.In this paper we introduce two new components for improving openWiFi data delivery to moving vehicles: The first QuickWiFi is a streamlined client-side process to establish end-to-end connectivity reducing mean connection time to less than 400 ms from over 10 seconds when using standard wireless networking software. The second part CTP is a transport protocol that distinguishes congestion on the wired portion of the path from losses over the wireless link resulting in a 2x throughput improvement over TCP. To characterize the amount of open WiFi capacity available to vehicular users we deployed Cabernet on a fleet of 10 taxis in the Boston area. The long-term average transfer rate achieved was approximately 38 Mbytes/hour per car (86 kbit/s) making Cabernet a viable system for a number of non-interactive applications.;
Proceedings of the 14th ACM International Conference on Mobile Computing and Networking;Smart home Internet of Things (IoT) devices are rapidly increasing in popularity with more households including Internet-connected devices that continuously monitor user activities. In this study we conduct eleven semi-structured interviews with smart home owners investigating their reasons for purchasing IoT devices perceptions of smart home privacy risks and actions taken to protect their privacy from those external to the home who create manage track or regulate IoT devices and/or their data. We note several recurring themes. First users' desires for convenience and connectedness dictate their privacy-related behaviors for dealing with external entities such as device manufacturers Internet Service Providers governments and advertisers. Second user opinions about external entities collecting smart home data depend on perceived benefit from these entities. Third users trust IoT device manufacturers to protect their privacy but do not verify that these protections are in place. Fourth users are unaware of privacy risks from inference algorithms operating on data from non-audio/visual devices. These findings motivate several recommendations for device designers researchers and industry standards to better match device privacy features to the expectations and preferences of smart home owners.;
Automatically patching errors in deployed software;We present ClearView a system for automatically patching errors in deployed software. ClearView works on stripped Windows x86 binaries without any need for source code debugging information or other external information and without human intervention.ClearView (1) observes normal executions to learn invariants thatcharacterize the application's normal behavior (2) uses error detectors to distinguish normal executions from erroneous executions (3) identifies violations of learned invariants that occur during erroneous executions (4) generates candidate repair patches that enforce selected invariants by changing the state or flow of control to make the invariant true and (5) observes the continued execution of patched applications to select the most successful patch.ClearView is designed to correct errors in software with high availability requirements. Aspects of ClearView that make it particularly appropriate for this context include its ability to generate patches without human intervention apply and remove patchesto and from running applications without requiring restarts or otherwise perturbing the execution and identify and discard ineffective or damaging patches by evaluating the continued behavior of patched applications.ClearView was evaluated in a Red Team exercise designed to test its ability to successfully survive attacks that exploit security vulnerabilities. A hostile external Red Team developed ten code injection exploits and used these exploits to repeatedly attack an application protected by ClearView. ClearView detected and blocked all of the attacks. For seven of the ten exploits ClearView automatically generated patches that corrected the error enabling the application to survive the attacks and continue on to successfully process subsequent inputs. Finally the Red Team attempted to make Clear-View apply an undesirable patch but ClearView's patch evaluation mechanism enabled ClearView to identify and discard both ineffective patches and damaging patches.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;Recent years have witnessed the impacts of distributed content sharing (Wikipedia Blogger) social networks (Facebook MySpace) sensor networks and pervasive computing. We believe that significant more impact is latent in the convergence of these ideas on the mobile phone platform. Phones can be envisioned as people-centric sensors capable of aggregating participatory as well as sensory inputs from local surroundings. The inputs can be visualized in different dimensions such as space and time. When plugged into the Internet the collaborative inputs from phones may enable a high resolution view of the world. This paper presents the architecture and implementation of one such system called Micro-Blog. New kinds of application-driven challenges are identified and addressed in the context of this system. Implemented on Nokia N95 mobile phones Micro-Blog was distributed to volunteers for real life use. Promising feedback suggests that Micro-Blog can be a deployable tool for sharing browsing and querying global information.;
Proceedings of the 6th International Conference on Mobile Systems Applications and Services;Soft materials may enable the automation of tasks beyond the capacities of current robotic technology.;
Writeprints: A stylometric approach to identity-level identification and similarity detection in cyberspace;One of the problems often associated with online anonymity is that it hinders social accountability as substantiated by the high levels of cybercrime. Although identity cues are scarce in cyberspace individuals often leave behind textual identity traces. In this study we proposed the use of stylometric analysis techniques to help identify individuals based on writing style. We incorporated a rich set of stylistic features including lexical syntactic structural content-specific and idiosyncratic attributes. We also developed the Writeprints technique for identification and similarity detection of anonymous identities. Writeprints is a Karhunen-Loeve transforms-based technique that uses a sliding window and pattern disruption algorithm with individual author-level feature sets. The Writeprints technique and extended feature set were evaluated on a testbed encompassing four online datasets spanning different domains: email instant messaging feedback comments and program code. Writeprints outperformed benchmark techniques including SVM Ensemble SVM PCA and standard Karhunen-Loeve transforms on the identification and similarity detection tasks with accuracy as high as 94% when differentiating between 100 authors. The extended feature set also significantly outperformed a baseline set of features commonly used in previous research. Furthermore individual-author-level feature sets generally outperformed use of a single group of attributes.;
SCOPE: easy and efficient parallel processing of massive data sets;Companies providing cloud-scale services have an increasing need to store and analyze massive data sets such as search logs and click streams. For cost and performance reasons processing is typically done on large clusters of shared-nothing commodity machines. It is imperative to develop a programming model that hides the complexity of the underlying system but provides flexibility by allowing users to extend functionality to meet a variety of requirements.In this paper we present a new declarative and extensible scripting language SCOPE (Structured Computations Optimized for Parallel Execution) targeted for this type of massive data analysis. The language is designed for ease of use with no explicit parallelism while being amenable to efficient parallel execution on large clusters. SCOPE borrows several features from SQL. Data is modeled as sets of rows composed of typed columns. The select statement is retained with inner joins outer joins and aggregation allowed. Users can easily define their own functions and implement their own versions of operators: extractors (parsing and constructing rows from a file) processors (row-wise processing) reducers (group-wise processing) and combiners (combining rows from two inputs). SCOPE supports nesting of expressions but also allows a computation to be specified as a series of steps in a manner often preferred by programmers. We also describe how scripts are compiled into efficient parallel execution plans and executed on large clusters.;
User-defined motion gestures for mobile interaction;Modern smartphones contain sophisticated sensors to monitor three-dimensional movement of the device. These sensors permit devices to recognize motion gestures - deliberate movements of the device by end-users to invoke commands. However little is known about best-practices in motion gesture design for the mobile computing paradigm. To address this issue we present the results of a guessability study that elicits end-user motion gestures to invoke commands on a smartphone device. We demonstrate that consensus exists among our participants on parameters of movement and on mappings of motion gestures onto commands. We use this consensus to develop a taxonomy for motion gestures and to specify an end-user inspired motion gesture set. We highlight the implications of this work to the design of smartphone applications and hardware. Finally we argue that our results influence best practices in design for all gestural interfaces.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Low-latency anonymization networks such as Tor and JAP claim to hide the recipient and the content of communications from a local observer i.e. an entity that can eavesdrop the traffic between the user and the first anonymization node. Especially users in totalitarian regimes strongly depend on such networks to freely communicate. For these people anonymity is particularly important and an analysis of the anonymization methods against various attacks is necessary to ensure adequate protection. In this paper we show that anonymity in Tor and JAP is not as strong as expected so far and cannot resist website fingerprinting attacks under certain circumstances. We first define features for website fingerprinting solely based on volume time and direction of the traffic. As a result the subsequent classification becomes much easier. We apply support vector machines with the introduced features. We are able to improve recognition results of existing works on a given state-of-the-art dataset in Tor from 3% to 55% and in JAP from 20% to 80%. The datasets assume a closed-world with 775 websites only. In a next step we transfer our findings to a more complex and realistic open-world scenario i.e. recognition of several websites in a set of thousands of random unknown websites. To the best of our knowledge this work is the first successful attack in the open-world scenario. We achieve a surprisingly high true positive rate of up to 73% for a false positive rate of 0.05%. Finally we show preliminary results of a proof-of-concept implementation that applies camouflage as a countermeasure to hamper the fingerprinting attack. For JAP the detection rate decreases from 80% to 4% and for Tor it drops from 55% to about 3%.;
Proceedings of the 10th Annual ACM Workshop on Privacy in the Electronic Society;Many basic network engineering tasks (e.g. traffic engineering capacity planning anomaly detection) rely heavily on the availability and accuracy of traffic matrices. However in practice it is challenging to reliably measure traffic matrices. Missing values are common. This observation brings us into the realm of compressive sensing a generic technique for dealing with missing values that exploits the presence of structure and redundancy in many real-world systems. Despite much recent progress made in compressive sensing existing compressive-sensing solutions often perform poorly for traffic matrix interpolation because real traffic matrices rarely satisfy the technical conditions required for these solutions.To address this problem we develop a novel spatio-temporal compressive sensing framework with two key components: (i) a new technique called Sparsity Regularized Matrix Factorization (SRMF) that leverages the sparse or low-rank nature of real-world traffic matrices and their spatio-temporal properties and (ii) a mechanism for combining low-rank approximations with local interpolation procedures. We illustrate our new framework and demonstrate its superior performance in problems involving interpolation with real traffic matrices where we can successfully replace up to 98% of the values. Evaluation in applications such as network tomography traffic prediction and anomaly detection confirms the flexibility and effectiveness of our approach.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;Ageing has become a significant area of interest in Human-Computer Interaction (HCI) in recent years. In this article we provide a critical analysis of 30 years of ageing research published across the ACM Special Interest Group on Computer-Human Interaction (SIGCHI) community. Discourse analysis of the content of 644 archival papers highlights how ageing is typically framed as a â€œproblemâ€ that can be managed by technology. We highlight how ageing is typically defined through an emphasis on the economic and societal impact of health and care needs of older people concerns around socialisation as people age and declines in abilities and associated reductions in performance when using technology. We draw from research within the fields of social and critical gerontology to highlight how these discourses in SIGCHI literature represent common stereotypes around old age that have also prevailed in the wider literature in gerontology. We conclude by proposing strategies for future research at the intersection of ageing and HCI.;
The beacon openflow controller;Beacon is a Java-based open source OpenFlow controller created in 2010. It has been widely used for teaching research and as the basis of Floodlight. This paper describes the architectural decisions and implementation that achieves three of Beacon's goals: to improve developer productivity to provide the runtime ability to start and stop existing and new applications and to be high performance.;
Proceedings of the Second ACM SIGCOMM Workshop on Hot Topics in Software Defined Networking;Modern enterprises almost ubiquitously deploy middlebox processing services to improve security and performance in their networks. Despite this we find that today's middlebox infrastructure is expensive complex to manage and creates new failure modes for the networks that use them. Given the promise of cloud computing to decrease costs ease management and provide elasticity and fault-tolerance we argue that middlebox processing can benefit from outsourcing the cloud. Arriving at a feasible implementation however is challenging due to the need to achieve functional equivalence with traditional middlebox deployments without sacrificing performance or increasing network complexity.In this paper we motivate design and implement APLOMB a practical service for outsourcing enterprise middlebox processing to the cloud.Our discussion of APLOMB is data-driven guided by a survey of 57 enterprise networks the first large-scale academic study of middlebox deployment. We show that APLOMB solves real problems faced by network administrators can outsource over 90% of middlebox hardware in a typical large enterprise network and in a case study of a real enterprise imposes an average latency penalty of 1.1ms and median bandwidth inflation of 3.8%.;
Defining and evaluating network communities based on ground-truth;Nodes in real-world networks such as social information or technological networks organize into communities where edges appear with high concentration among the members of the community. Identifying communities in networks has proven to be a challenging task mainly due to a plethora of definitions of a community intractability of algorithms issues with evaluation and the lack of a reliable gold-standard ground-truth.We study a set of 230 large social collaboration and information networks where nodes explicitly define group memberships. We use these groups to define the notion of ground-truth communities. We then propose a methodology which allows us to compare and quantitatively evaluate different definitions of network communities on a large scale. We choose 13 commonly used definitions of network communities and examine their quality sensitivity and robustness. We show that the 13 definitions naturally group into four classes. We find that two of these definitions Conductance and Triad-participation-ratio consistently give the best performance in identifying ground-truth communities.;
Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics;Micro-task markets such as Amazon's Mechanical Turk represent a new paradigm for accomplishing work in which employers can tap into a large population of workers around the globe to accomplish tasks in a fraction of the time and money of more traditional methods. However such markets have been primarily used for simple independent tasks such as labeling an image or judging the relevance of a search result. Here we present a general purpose framework for accomplishing complex and interdependent tasks using micro-task markets. We describe our framework a web-based prototype and case studies on article writing decision making and science journalism that demonstrate the benefits and limitations of the approach.;
Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology;AI models are increasingly applied in high-stakes domains like health and conservation. Data quality carries an elevated significance in high-stakes AI due to its heightened downstream impact impacting predictions like cancer detection wildlife poaching and loan allocations. Paradoxically data is the most under-valued and de-glamorised aspect of AI. In this paper we report on data practices in high-stakes AI from interviews with 53 AI practitioners in India East and West African countries and USA. We define identify and present empirical evidence on Data Cascadesâ€”compounding events causing negative downstream effects from data issuesâ€”triggered by conventional AI/ML practices that undervalue data quality. Data cascades are pervasive (92% prevalence) invisible delayed but often avoidable. We discuss HCI opportunities in designing and incentivizing data excellence as a first-class citizen of AI resulting in safer and more robust systems for all.;
Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems;In this work we apply machine learning algorithms on network traffic data for accurate identification of IoT devices connected to a network. To train and evaluate the classifier we collected and labeled network traffic data from nine distinct IoT devices and PCs and smartphones. Using supervised learning we trained a multi-stage meta classifier in the first stage the classifier can distinguish between traffic generated by IoT and non-IoT devices. In the second stage each IoT device is associated a specific IoT device class. The overall IoT classification accuracy of our model is 99.281+.;
Proceedings of the Symposium on Applied Computing;Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example AI systems can make unpredictable errors and these errors damage UX and even lead to undesired societal impact. However HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research our own design and research experience and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities 2) AI's output complexity spanning from simple to adaptive complex. We identify four levels of AI systems. On each level designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers researchers and design tool makers in productively addressing the challenges of human-AI interaction going forward.;
Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems;GPS (for Graph Processing System) is a complete open-source system we developed for scalable fault-tolerant and easy-to-program execution of algorithms on extremely large graphs. This paper serves the dual role of describing the GPS system and presenting techniques and experimental results for graph partitioning in distributed graph-processing systems like GPS. GPS is similar to Google's proprietary Pregel system with three new features: (1) an extended API to make global computations more easily expressed and more efficient (2) a dynamic repartitioning scheme that reassigns vertices to different workers during the computation based on messaging patterns and (3) an optimization that distributes adjacency lists of high-degree vertices across all compute nodes to improve performance. In addition to presenting the implementation of GPS and its novel features we also present experimental results on the performance effects of both static and dynamic graph partitioning schemes and we describe the compilation of a high-level domain-specific programming language to GPS enabling easy expression of complex algorithms.;
Proceedings of the 25th International Conference on Scientific and Statistical Database Management;Social bookmarking is a recent phenomenon which has the potential to give us a great deal of data about pages on the web. One major question is whether that data can be used to augment systems like web search. To answer this question over the past year we have gathered what we believe to be the largest dataset from a social bookmarking site yet analyzed by academic researchers. Our dataset represents about forty million bookmarks from the social bookmarking site del.icio.us. We contribute a characterization of posts to del.icio. us: how many bookmarks exist (about 115 million) how fast is it growing and how active are the URLs being posted about (quite active). We also contribute a characterization of tags used by bookmarkers. We found that certain tags tend to gravitate towards certain domains and vice versa. We also found that tags occur in over 50 percent of the pages that they annotate and in only 20 percent of cases do they not occur in the page text backlink page text or forward link page text of the pages they annotate. We conclude that social bookmarking can provide search data not currently provided by other sources though it may currently lack the size and distribution of tags necessary to make a significant impact;
Proceedings of the 2008 International Conference on Web Search and Data Mining;Spoofax is a language workbench for efficient agile development of textual domain-specific languages with state-of-the-art IDE support. Spoofax integrates language processing techniques for parser generation meta-programming and IDE development into a single environment. It uses concise declarative specifications for languages and IDE services. In this paper we describe the architecture of Spoofax and introduce idioms for high-level specifications of language semantics using rewrite rules showing how analyses can be reused for transformations code generation and editor services such as error marking reference resolving and content completion. The implementation of these services is supported by language-parametric editor service classes that can be dynamically loaded by the Eclipse IDE allowing new languages to be developed and used side-by-side in the same Eclipse environment.;
Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications;We propose a new approach to conduct static analysis for security vetting of Android apps and built a general framework called Amandroid for determining points-to information for all objects in an Android app in a flow- and context-sensitive way across Android apps components. We show that: (a) this type of comprehensive analysis is completely feasible in terms of computing resources needed with modern hardware (b) one can easily leverage the results from this general analysis to build various types of specialized security analyses -- in many cases the amount of additional coding needed is around 100 lines of code and (c) the result of those specialized analyses leveraging Amandroid is at least on par and often exceeds prior works designed for the specific problems which we demonstrate by comparing Amandroid's results with those of prior works whenever we can obtain the executable of those tools. Since Amandroid's analysis directly handles inter-component control and data flows it can be used to address security problems that result from interactions among multiple components from either the same or different apps. Amandroid's analysis is sound in that it can provide assurance of the absence of the specified security problems in an app with well-specified and reasonable assumptions on Android runtime system and its library.;
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security;MapReduce and similar systems significantly ease the task of writing data-parallel code. However many real-world computations require a pipeline of MapReduces and programming and managing such pipelines can be difficult. We present FlumeJava a Java library that makes it easy to develop test and run efficient data-parallel pipelines. At the core of the FlumeJava library are a couple of classes that represent immutable parallel collections each supporting a modest number of operations for processing them in parallel. Parallel collections and their operations present a simple high-level uniform abstraction over different data representations and execution strategies. To enable parallel operations to run efficiently FlumeJava defers their evaluation instead internally constructing an execution plan dataflow graph. When the final results of the parallel operations are eventually needed FlumeJava first optimizes the execution plan and then executes the optimized operations on appropriate underlying primitives (e.g. MapReduces). The combination of high-level abstractions for parallel data and computation deferred evaluation and optimization and efficient parallel primitives yields an easy-to-use system that approaches the efficiency of hand-optimized pipelines. FlumeJava is in active use by hundreds of pipeline developers within Google.;
Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation;We analyse the corpus of user relationships of the Slashdot technology news site. The data was collected from the Slashdot Zoo feature where users of the website can tag other users as friends and foes providing positive and negative endorsements. We adapt social network analysis techniques to the problem of negative edge weights. In particular we consider signed variants of global network characteristics such as the clustering coefficient node-level characteristics such as centrality and popularity measures and link-level characteristics such as distances and similarity measures. We evaluate these measures on the task of identifying unpopular users as well as on the task of predicting the sign of links and show that the network exhibits multiplicative transitivity which allows algebraic methods based on matrix multiplication to be used. We compare our methods to traditional methods which are only suitable for positively weighted edges.;
Proceedings of the 18th International Conference on World Wide Web;To address privacy concerns over Online Social Networks (OSNs) we propose a distributed peer-to-peer approach coupled with encryption. Moreover extending this distributed approach by direct data exchange between user devices removes the strict Internet-connectivity requirements of web-based OSNs. In order to verify the feasibility of this approach we designed a two-tiered architecture and protocols that recreate the core features of OSNs in a decentralized way. This paper focuses on the description of the prototype built for the P2P infrastructure for social networks as a first step without the encryption part and shares early experiences from the prototype and insights gained since first outlining the challenges and possibilities of decentralized alternatives to OSNs.;
Proceedings of the Second ACM EuroSys Workshop on Social Network Systems;To seamlessly integrate into the human physical and social environment robots must display appropriate proxemic behavior - that is follow societal norms in establishing their physical and psychological distancing with people. Social-scientific theories suggest competing models of human proxemic behavior but all conclude that individuals' proxemic behavior is shaped by the proxemic behavior of others and the individual's psychological closeness to them. The present study explores whether these models can also explain how people physically and psychologically distance themselves from robots and suggest guidelines for future design of proxemic behaviors for robots. In a controlled laboratory experiment participants interacted with Wakamaru to perform two tasks that examined physical and psychological distancing of the participants. We manipulated the likeability (likeable/dislikeable) and gaze behavior (mutual gaze/averted gaze) of the robot. Our results on physical distancing showed that participants who disliked the robot compensated for the increase in the robot's gaze by maintaining a greater physical distance from the robot while participants who liked the robot did not differ in their distancing from the robot across gaze conditions. The results on psychological distancing suggest that those who disliked the robot also disclosed less to the robot. Our results offer guidelines for the design of appropriate proxemic behaviors for robots so as to facilitate effective human-robot interaction.;
Proceedings of the 6th International Conference on Human-Robot Interaction;SSL (Secure Sockets Layer) is the de facto standard for secure Internet communications. Security of SSL connections against an active network attacker depends on correctly validating public-key certificates presented when the connection is established.We demonstrate that SSL certificate validation is completely broken in many security-critical applications and libraries. Vulnerable software includes Amazon's EC2 Java library and all cloud clients based on it Amazon's and PayPal's merchant SDKs responsible for transmitting payment details from e-commerce sites to payment gateways integrated shopping carts such as osCommerce ZenCart Ubercart and PrestaShop AdMob code used by mobile websites Chase mobile banking and several other Android apps and libraries Java Web-services middleware including Apache Axis Axis 2 Codehaus XFire and Pusher library for Android and all applications employing this middleware. Any SSL connection from any of these programs is insecure against a man-in-the-middle attack.The root causes of these vulnerabilities are badly designed APIs of SSL implementations (such as JSSE OpenSSL and GnuTLS) and data-transport libraries (such as cURL) which present developers with a confusing array of settings and options. We analyze perils and pitfalls of SSL certificate validation in software based on these APIs and present our recommendations.;
Proceedings of the 2012 ACM Conference on Computer and Communications Security;Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the upper limbs a condition casually termed as the gorilla-arm effect. Designers have often associated limitations of their mid-air interactions with arm fatigue but do not possess a quantitative method to assess and therefore mitigate it. In this paper we propose a novel metric Consumed Endurance (CE) derived from the biomechanical structure of the upper arm and aimed at characterizing the gorilla-arm effect. We present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based skeleton tracking system and demonstrate that CE correlates strongly with the Borg CR10 scale of perceived exertion. We show how designers can use CE as a complementary metric for evaluating existing and designing novel mid-air interactions including tasks with repetitive input such as mid-air text-entry. Finally we propose a series of guidelines for the design of fatigue-efficient mid-air interfaces.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;This paper introduces a generic and scalable framework for automated anomaly detection on large scale time-series data. Early detection of anomalies plays a key role in maintaining consistency of person's data and protects corporations against malicious attackers. Current state of the art anomaly detection approaches suffer from scalability use-case restrictions difficulty of use and a large number of false positives. Our system at Yahoo EGADS uses a collection of anomaly detection and forecasting models with an anomaly filtering layer for accurate and scalable anomaly detection on time-series. We compare our approach against other anomaly detection systems on real and synthetic data with varying time-series characteristics. We found that our framework allows for 50-60% improvement in precision and recall for a variety of use-cases. Both the data and the framework are being open-sourced. The open-sourcing of the data in particular represents the first of its kind effort to establish the standard benchmark for anomaly detection.;
Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;This paper presents a study of finger-based text entry for mobile devices with touchscreens. Many devices are now coming to market that have no physical keyboards (the Apple iPhone being a very popular example). Touchscreen keyboards lack any tactile feedback and this may cause problems for entering text and phone numbers. We ran an experiment to compare devices with a physical keyboard a standard touchscreen and a touchscreen with tactile feedback added. We tested this in both static and mobile environments. The results showed that the addition of tactile feedback to the touchscreen significantly improved finger-based text entry bringing it close to the performance of a real physical keyboard. A second experiment showed that higher specification tactile actuators could improve performance even further. The results suggest that manufacturers should use tactile feedback in their touchscreen devices to regain some of the feeling lost when interacting on a touchscreen with a finger.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;To understand why and how people share health information online we interviewed fourteen people with significant health concerns who participate in both online health communities and Facebook. Qualitative analysis of these interviews highlighted the ways that people think about with whom and how to share different types of information as they pursue social goals related to their personal health including emotional support motivation accountability and advice. Our study suggests that success in these goals depends on how well they develop their social networks and how effectively they communicate within those networks. Effective communication is made more challenging by the need to strike a balance between sharing information related to specific needs and the desire to manage self-presentation. Based on these observations we outline a set of design opportunities for future systems to support health-oriented social interactions online including tools to help users shape their social networks and communicate effectively within those.;
Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work;Today's data centers face extreme challenges in providing low latency. However fair sharing a principle commonly adopted in current congestion control protocols is far from optimal for satisfying latency requirements.We propose Preemptive Distributed Quick (PDQ) flow scheduling a protocol designed to complete flows quickly and meet flow deadlines. PDQ enables flow preemption to approximate a range of scheduling disciplines. For example PDQ can emulate a shortest job first algorithm to give priority to the short flows by pausing the contending flows. PDQ borrows ideas from centralized scheduling disciplines and implements them in a fully distributed manner making it scalable to today's data centers. Further we develop a multipath version of PDQ to exploit path diversity.Through extensive packet-level and flow-level simulation we demonstrate that PDQ significantly outperforms TCP RCP and D3 in data center environments. We further show that PDQ is stable resilient to packet loss and preserves nearly all its performance gains even given inaccurate flow information.;
Proceedings of the ACM SIGCOMM 2012 Conference on Applications Technologies Architectures and Protocols for Computer Communication;The coverage of a test suite is often used as a proxy for its ability to detect faults. However previous studies that investigated the correlation between code coverage and test suite effectiveness have failed to reach a consensus about the nature and strength of the relationship between these test suite characteristics. Moreover many of the studies were done with small or synthetic programs making it unclear whether their results generalize to larger programs and some of the studies did not account for the confounding influence of test suite size. In addition most of the studies were done with adequate suites which are are rare in practice so the results may not generalize to typical test suites.  We have extended these studies by evaluating the relationship between test suite size coverage and effectiveness for large Java programs. Our study is the largest to date in the literature: we generated 31000 test suites for five systems consisting of up to 724000 lines of source code. We measured the statement coverage decision coverage and modified condition coverage of these suites and used mutation testing to evaluate their fault detection effectiveness.  We found that there is a low to moderate correlation between coverage and effectiveness when the number of test cases in the suite is controlled for. In addition we found that stronger forms of coverage do not provide greater insight into the effectiveness of the suite. Our results suggest that coverage while useful for identifying under-tested parts of a program should not be used as a quality target because it is not a good indicator of test suite effectiveness.;
Proceedings of the 36th International Conference on Software Engineering;There is a tremendous interest in big data by academia industry and a large user base. Several commercial and open source providers unleashed a variety of products to support big data storage and processing. As these products mature there is a need to evaluate and compare the performance of these systems.In this paper we present BigBench an end-to-end big data benchmark proposal. The underlying business model of BigBench is a product retailer. The proposal covers a data model and synthetic data generator that addresses the variety velocity and volume aspects of big data systems containing structured semi-structured and unstructured data. The structured part of the BigBench data model is adopted from the TPC-DS benchmark which is enriched with semi-structured and unstructured data components. The semi-structured part captures registered and guest user clicks on the retailer's website. The unstructured data captures product reviews submitted online. The data generator designed for BigBench provides scalable volumes of raw data based on a scale factor. The BigBench workload is designed around a set of queries against the data model. From a business prospective the queries cover the different categories of big data analytics proposed by McKinsey. From a technical prospective the queries are designed to span three different dimensions based on data sources query processing types and analytic techniques.We illustrate the feasibility of BigBench by implementing it on the Teradata Aster Database. The test includes generating and loading a 200 Gigabyte BigBench data set and testing the workload by executing the BigBench queries (written using Teradata Aster SQL-MR) and reporting their response times.;
Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data;Cellular core networks suffer from inflexible and expensive equipment as well as from complex control-plane protocols. To address these challenges we present SoftCell a scalable architecture that supports fine-grained policies for mobile devices in cellular core networks using commodity switches and servers. SoftCell enables operators to realize high-level service policies that direct traffic through sequences of middleboxes based on subscriber attributes and applications. To minimize the size of the forwarding tables SoftCell aggregates traffic along multiple dimensions---the service policy the base station and the mobile device---at different switches in the network. Since most traffic originates from mobile devices SoftCell performs fine-grained packet classification at the access switches next to the base stations where software switches can easily handle the state and bandwidth requirements. SoftCell guarantees that packets belonging to the same connection traverse the same sequence of middleboxes in both directions even in the presence of mobility. We demonstrate that SoftCell improves the scalability and flexibility of cellular core networks by analyzing real LTE workloads performing micro-benchmarks on our prototype controller as well as large-scale simulations.;
Proceedings of the Ninth ACM Conference on Emerging Networking Experiments and Technologies;The SAP HANA database is positioned as the core of the SAP HANA Appliance to support complex business analytical processes in combination with transactionally consistent operational workloads. Within this paper we outline the basic characteristics of the SAP HANA database emphasizing the distinctive features that differentiate the SAP HANA database from other classical relational database management systems. On the technical side the SAP HANA database consists of multiple data processing engines with a distributed query processing environment to provide the full spectrum of data processing -- from classical relational data supporting both row- and column-oriented physical representations in a hybrid engine to graph and text processing for semi- and unstructured data management within the same system.From a more application-oriented perspective we outline the specific support provided by the SAP HANA database of multiple domain-specific languages with a built-in set of natively implemented business functions. SQL -- as the lingua franca for relational database systems -- can no longer be considered to meet all requirements of modern applications which demand the tight interaction with the data management layer. Therefore the SAP HANA database permits the exchange of application semantics with the underlying data management platform that can be exploited to increase query expressiveness and to reduce the number of individual application-to-database round trips.;
Less pain most of the gain: incrementally deployable ICN;Information-Centric Networking (ICN) has seen a significant resurgence in recent years. ICN promises benefits to users and service providers along several dimensions (e.g. performance security and mobility). These benefits however come at a non-trivial cost as many ICN proposals envision adding significant complexity to the network by having routers serve as content caches and support nearest-replica routing. This paper is driven by the simple question of whether this additional complexity is justified and if we can achieve these benefits in an incrementally deployable fashion. To this end we use trace-driven simulations to analyze the quantitative benefits attributed to ICN (e.g. lower latency and congestion). Somewhat surprisingly we find that pervasive caching and nearest-replica routing are not fundamentally necessary---most of the performance benefits can be achieved with simpler caching architectures. We also discuss how the qualitative benefits of ICN (e.g. security mobility) can be achieved without any changes to the network. Building on these insights we present a proof-of-concept design of an incrementally deployable ICN architecture.;
Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM;We present PowerDial a system for dynamically adapting application behavior to execute successfully in the face of load and power fluctuations. PowerDial transforms static configuration parameters into dynamic knobs that the PowerDial control system can manipulate to dynamically trade off the accuracy of the computation in return for reductions in the computational resources that the application requires to produce its results. These reductions translate directly into performance improvements and power savings.Our experimental results show that PowerDial can enable our benchmark applications to execute responsively in the face of power caps that would otherwise significantly impair responsiveness. They also show that PowerDial can significantly reduce the number of machines required to service intermittent load spikes enabling reductions in power and capital costs.;
Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems;In the everyday world much of what we do is dictated by how we interpret spatial relationships or proxemics. What is surprising is how little proxemics are used to mediate people's interactions with surrounding digital devices. We imagine proxemic interaction as devices with fine-grained knowledge of nearby people and other devices -- their position identity movement and orientation -- and how such knowledge can be exploited to design interaction techniques. In particular we show how proxemics can: regulate implicit and explicit interaction trigger such interactions by continuous movement or by movement of people and devices in and out of discrete proxemic regions mediate simultaneous interaction of multiple people and interpret and exploit people's directed attention to other people and objects. We illustrate these concepts through an interactive media player running on a vertical surface that reacts to the approach identity movement and orientation of people and their personal devices.;
ACM International Conference on Interactive Tabletops and Surfaces;"bug report is typically assigned to a single developer who is then responsible for fixing the bug. In Mozilla and Eclipse between 37%-44% of bug reports are tossed"" (reassigned) to other developers for example because the bug has been assigned by accident or another developer with additional expertise is needed. In any case tossing increases the time-to-correction for a bug.In this paper we introduce a graph model based on Markov chains which captures bug tossing history. This model has several desirable qualities. First it reveals developer networks which can be used to discover team structures and to find suitable experts for a new task. Second it helps to better assign developers to bug reports. In our experiments with 445000 bug reports our model reduced tossing events by up to 72%. In addition the model increased the prediction accuracy by up to 23 percentage points compared to traditional bug triaging approaches.""";
Proceedings of the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering;Software defect information including links between bugs and committed changes plays an important role in software maintenance such as measuring quality and predicting defects. Usually the links are automatically mined from change logs and bug reports using heuristics such as searching for specific keywords and bug IDs in change logs. However the accuracy of these heuristics depends on the quality of change logs. Bird et al. found that there are many missing links due to the absence of bug references in change logs. They also found that the missing links lead to biased defect information and it affects defect prediction performance. We manually inspected the explicit links which have explicit bug IDs in change logs and observed that the links exhibit certain features. Based on our observation we developed an automatic link recovery algorithm ReLink which automatically learns criteria of features from explicit links to recover missing links. We applied ReLink to three open source projects. ReLink reliably identified links with 89% precision and 78% recall on average while the traditional heuristics alone achieve 91% precision and 64% recall. We also evaluated the impact of recovered links on software maintainability measurement and defect prediction and found the results of ReLink yields significantly better accuracy than those of traditional heuristics.;
Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering;Over more than two decades numerous variability modeling techniques have been introduced in academia and industry. However little is known about the actual use of these techniques. While dozens of experience reports on software product line engineering exist only very few focus on variability modeling. This lack of empirical data threatens the validity of existing techniques and hinders their improvement. As part of our effort to improve empirical understanding of variability modeling we present the results of a survey questionnaire distributed to industrial practitioners. These results provide insights into application scenarios and perceived benefits of variability modeling the notations and tools used the scale of industrial models and experienced challenges and mitigation strategies.;
Proceedings of the 7th International Workshop on Variability Modelling of Software-Intensive Systems;A mobile device like a smart phone is becoming one of main information processing devices for users these days. Using it a user not only receives and makes calls but also performs information tasks. However a mobile device is still resource constrained and some applications especially work related ones usually demand more resources than a mobile device can afford. To alleviate this a mobile device should get resources from an external source. One of such sources is cloud computing platforms. Nevertheless an access to these platforms is not always guaranteed to be available and/or is too expensive to access them. We envision a way to overcome this issue by creating a virtual cloud computing platform using mobile phones. We argue that due to the pervasiveness of mobile phones and the enhancement in their capabilities this idea is feasible. We show prior evaluation results to support our concept and discuss future developments.;
Proceedings of the 1st ACM Workshop on Mobile Cloud Computing &amp Services: Social Networks and Beyond;The CIPRES Science Gateway (CSG) provides researchers and educators with browser-based access to community codes for inference of phylogenetic relationships from DNA and protein sequence data. The CSG allows users to deploy jobs on the high-performance computers of the TeraGrid without requiring detailed knowledge of their complexities. Use of the CSG has grown rapidly through March 2011 it had more than 2200 users and enabled more than 180 peer-reviewed publications. The rapid growth in resource consumption was accommodated by deploying codes on Trestles a new TeraGrid computer. Tools and policies were developed to insure efficient and effective resource use. This paper describes progress in managing the growth of this public cyberinfrastructure resource and reviews the domain science that it has enabled.;
Proceedings of the 2011 TeraGrid Conference: Extreme Digital Discovery;"With the increasing prevalence of warehouse-scale (WSC) and cloud computing understanding the interactions of server applications with the underlying microarchitecture becomes ever more important in order to extract maximum performance out of server hardware. To aid such understanding this paper presents a detailed microarchitectural analysis of live datacenter jobs measured on more than 20000 Google machines over a three year period and comprising thousands of different applications.We first find that WSC workloads are extremely diverse breeding the need for architectures that can tolerate application variability without performance loss. However some patterns emerge offering opportunities for co-optimization of hardware and software. For example we identify common building blocks in the lower levels of the software stack. This datacenter tax"" can comprise nearly 30% of cycles across jobs running in the fleet which makes its constituents prime candidates for hardware specialization in future server systems-on-chips. We also uncover opportunities for classic microarchitectural optimizations for server processors especially in the cache hierarchy. Typical workloads place significant stress on instruction caches and prefer memory latency over bandwidth. They also stall cores often but compute heavily in bursts. These observations motivate several interesting directions for future warehouse-scale computers.""";
Proceedings of the 42nd Annual International Symposium on Computer Architecture;The 60 GHz wireless technology that is now emerging has the potential to provide dense and extremely fast connectivity at low cost. In this paper we explore its use to relieve hotspots in oversubscribed data center (DC) networks. By experimenting with prototype equipment we show that the DC environment is well suited to a deployment of 60GHz links contrary to concerns about interference and link reliability. Using directional antennas many wireless links can run concurrently at multi-Gbps rates on top-of-rack (ToR) switches. The wired DC network can be used to sidestep several common wireless problems. By analyzing production traces of DC traffic for four real applications we show that adding a small amount of network capacity in the form of wireless flyways to the wired DC network can improve performance. However to be of significant value we find that one hop indirect routing is needed. Informed by our 60GHz experiments and DC traffic analysis we present a design that uses DC traffic levels to select and adds flyways to the wired DC network. Trace-driven evaluations show that network-limited DC applications with predictable traffic workloads running on a 1:2 oversubscribed network can be sped up by 45% in 95% of the cases with just one wireless device per ToR switch. With two devices in 40% of the cases the performance is identical to that of a non-oversubscribed network.;
Proceedings of the ACM SIGCOMM 2011 Conference;Matching images and sentences demands a fine understanding of both modalities. In this article we propose a new system to discriminatively embed the image and text to a shared visual-textual space. In this field most existing works apply the ranking loss to pull the positive image/text pairs close and push the negative pairs apart from each other. However directly deploying the ranking loss on heterogeneous features (i.e. text and image features) is less effective because it is hard to find appropriate triplets at the beginning. So the naive way of using the ranking loss may compromise the network from learning inter-modal relationship. To address this problem we propose the instance loss which explicitly considers the intra-modal data distribution. It is based on an unsupervised assumption that each image/text group can be viewed as a class. So the network can learn the fine granularity from every image/text group. The experiment shows that the instance loss offers better weight initialization for the ranking loss so that more discriminative embeddings can be learned. Besides existing works usually apply the off-the-shelf features i.e. word2vec and fixed visual feature. So in a minor contribution this article constructs an end-to-end dual-path convolutional network to learn the image and text representations. End-to-end learning allows the system to directly learn from the data and fully utilize the supervision. On two generic retrieval datasets (Flickr30k and MSCOCO) experiments demonstrate that our method yields competitive accuracy compared to state-of-the-art methods. Moreover in language-based person retrieval we improve the state of the art by a large margin. The code has been made publicly available.;
How do programmers ask and answer questions on the web? (NIER track);Question and Answer (Q&ampA) websites such as Stack Overflow use social media to facilitate knowledge exchange between programmers and fill archives with millions of entries that contribute to the body of knowledge in software development. Understanding the role of Q&ampA websites in the documentation landscape will enable us to make recommendations on how individuals and companies can leverage this knowledge effectively. In this paper we analyze data from Stack Overflow to categorize the kinds of questions that are asked and to explore which questions are answered well and which ones remain unanswered. Our preliminary findings indicate that Q&ampA websites are particularly effective at code reviews and conceptual questions. We pose research questions and suggest future work to explore the motivations of programmers that contribute to Q&ampA websites and to understand the implications of turning Q&ampA exchanges into technical mini-blogs through the editing of questions and answers.;
Proceedings of the 33rd International Conference on Software Engineering;The increasing popularity of cloud storage is leading organizations to consider moving data out of their own data centers and into the cloud. However success for cloud storage providers can present a significant risk to customers namely it becomes very expensive to switch storage providers. In this paper we make a case for applying RAID-like techniques used by disks and file systems but at the cloud storage level. We argue that striping user data across multiple providers can allow customers to avoid vendor lock-in reduce the cost of switching providers and better tolerate provider outages or failures. We introduce RACS a proxy that transparently spreads the storage load over many providers. We evaluate a prototype of our system and estimate the costs incurred and benefits reaped. Finally we use trace-driven simulations to demonstrate how RACS can reduce the cost of switching storage vendors for a large organization such as the Internet Archive by seven-fold or more by varying erasure-coding parameters.;
Proceedings of the 1st ACM Symposium on Cloud Computing;Modern enterprises almost ubiquitously deploy middlebox processing services to improve security and performance in their networks. Despite this we find that today's middlebox infrastructure is expensive complex to manage and creates new failure modes for the networks that use them. Given the promise of cloud computing to decrease costs ease management and provide elasticity and fault-tolerance we argue that middlebox processing can benefit from outsourcing the cloud. Arriving at a feasible implementation however is challenging due to the need to achieve functional equivalence with traditional middlebox deployments without sacrificing performance or increasing network complexity.In this paper we motivate design and implement APLOMB a practical service for outsourcing enterprise middlebox processing to the cloud.Our discussion of APLOMB is data-driven guided by a survey of 57 enterprise networks the first large-scale academic study of middlebox deployment. We show that APLOMB solves real problems faced by network administrators can outsource over 90% of middlebox hardware in a typical large enterprise network and in a case study of a real enterprise imposes an average latency penalty of 1.1ms and median bandwidth inflation of 3.8%.;
Proceedings of the ACM SIGCOMM 2012 Conference on Applications Technologies Architectures and Protocols for Computer Communication;The uptake of new interface technologies such as the Oculus Rift have generated renewed interest in virtual reality especially for private entertainment use. However long standing issues with unwanted side effects such as nausea from cybersickness continue to impact on the general use of devices such as head mounted displays. This in turn has slowed the uptake of more immersive interfaces for computer gaming and indeed more serious applications in training and health. In this paper we report a systematic review in the area of cybersickness with a focus on measuring the diverse symptoms experienced. Indeed the related conditions of simulator sickness and motion sickness have previously been well studied and yet many of the issues are unresolved. Here we report on these issues along with a number of measures both subjective and objective in nature using either questionnaires or psychophysiological measures that have been used to study cybersickness. We also report on the factors individual device related and task dependent that impact on the condition. We conclude that there remains a need to develop more cost-effective and objective physiological measures of both the impact of cybersickness and a person's susceptibility to the condition.;
Proceedings of the 2014 Conference on Interactive Entertainment;"Manually crafted combinatorial features have been the secret sauce"" behind many successful models. For web-scale applications however the variety and volume of features make these manually crafted features expensive to create maintain and deploy. This paper proposes the Deep Crossing model which is a deep neural network that automatically combines features to produce superior models. The input of Deep Crossing is a set of individual features that can be either dense or sparse. The important crossing features are discovered implicitly by the networks which are comprised of an embedding and stacking layer as well as a cascade of Residual Units. Deep Crossing is implemented with a modeling tool called the Computational Network Tool Kit (CNTK) powered by a multi-GPU platform. It was able to build from scratch two web-scale models for a major paid search engine and achieve superior results with only a sub-set of the features used in the production models. This demonstrates the potential of using Deep Crossing as a general modeling paradigm to improve existing products as well as to speed up the development of new models with a fraction of the investment in feature engineering and acquisition of deep domain knowledge.""";
Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;We consider the problem of data mining with formal privacy guarantees given a data access interface based on the differential privacy framework. Differential privacy requires that computations be insensitive to changes in any particular individual's record thereby restricting data leaks through the results. The privacy preserving interface ensures unconditionally safe access to the data and does not require from the data miner any expertise in privacy. However as we show in the paper a naive utilization of the interface to construct privacy preserving data mining algorithms could lead to inferior data mining results. We address this problem by considering the privacy and the algorithmic requirements simultaneously focusing on decision tree induction as a sample application. The privacy mechanism has a profound effect on the performance of the methods chosen by the data miner. We demonstrate that this choice could make the difference between an accurate classifier and a completely useless one. Moreover an improved algorithm can achieve the same level of accuracy and privacy as the naive implementation but with an order of magnitude fewer learning samples.;
Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;We consider social media as a promising tool for public health focusing on the use of Twitter posts to build predictive models about the forthcoming influence of childbirth on the behavior and mood of new mothers. Using Twitter posts we quantify postpartum changes in 376 mothers along dimensions of social engagement emotion social network and linguistic style. We then construct statistical models from a training set of observations of these measures before and after the reported childbirth to forecast significant postpartum changes in mothers. The predictive models can classify mothers who will change significantly following childbirth with an accuracy of 71% using observations about their prenatal behavior and as accurately as 80-83% when additionally leveraging the initial 2-3 weeks of postnatal data. The study is motivated by the opportunity to use social media to identify mothers at risk of postpartum depression an underreported health concern among large populations and to inform the design of low-cost privacy-sensitive early-warning systems and intervention programs aimed at promoting wellness postpartum.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;In product line engineering systems are developed in families and differences between family members are expressed in terms of features. Formal modelling and verification is an important issue in this context as more and more critical systems are developed this way. Since the number of systems in a family can be exponential in the number of features two major challenges are the scalable modelling and the efficient verification of system behaviour. Currently the few attempts to address them fail to recognise the importance of features as a unit of difference or do not offer means for automated verification.In this paper we tackle those challenges at a fundamental level. We first extend transition systems with features in order to describe the combined behaviour of an entire system family. We then define and implement a model checking technique that allows to verify such transition systems against temporal properties. An empirical evaluation shows substantial gains over classical approaches.;
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 1;Dynamic capacity provisioning is a useful technique for handling the multi-time-scale variations seen in Internet workloads. In this article we propose a novel dynamic provisioning technique for multi-tier Internet applications that employs (1) a flexible queuing model to determine how much of the resources to allocate to each tier of the application and (2) a combination of predictive and reactive methods that determine when to provision these resources both at large and small time scales. We propose a novel data center architecture based on virtual machine monitors to reduce provisioning overheads. Our experiments on a forty-machine Xen/Linux-based hosting platform demonstrate the responsiveness of our technique in handling dynamic workloads. In one scenario where a flash crowd caused the workload of a three-tier application to double our technique was able to double the application capacity within five minutes thus maintaining response-time targets. Our technique also reduced the overhead of switching servers across applications from several minutes to less than a second while meeting the performance targets of residual sessions.;
On the correctness of transactional memory;Transactional memory (TM) is perceived as an appealing alternative to critical sections for general purpose concurrent programming. Despite the large amount of recent work on TM implementations however very little effort has been devoted to precisely defining what guarantees these implementations should provide. A formal description of such guarantees is necessary in order to check the correctness of TM systems as well as to establish TM optimality results and inherent trade-offs.This paper presents opacity a candidate correctness criterion for TM implementations. We define opacity as a property of concurrent transaction histories and give its graph theoretical interpretation. Opacity captures precisely the correctness requirements that have been intuitively described by many TM designers. Most TM systems we know of do ensure opacity.At a very first approximation opacity can be viewed as an extension of the classical database serializability property with the additional requirement that even non-committed transactions are prevented from accessing inconsistent states. Capturing this requirement precisely in the context of general objects and without precluding pragmatic strategies that are often used by modern TM implementations such as versioning invisible reads lazy updates and open nesting is not trivial.As a use case of opacity we prove the first lower bound on the complexity of TM implementations. Basically we show that every single-version TM system that uses invisible reads and does not abort non-conflicting transactions requires in the worst caseâ€¯?(k) steps for an operation to terminate where k is the total number of objects shared by transactions. This (tight) bound precisely captures an inherent trade-off in the design of TM systems. The bound also highlights a fundamental gap between systems in which transactions can be fully isolated from the outside environment e.g. databases or certain specialized transactional languages and systems that lack such isolation capabilities e.g. general TM frameworks.;
Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming;As an increasing amount of RDF data is published as Linked Data intuitive ways of accessing this data become more and more important. Question answering approaches have been proposed as a good compromise between intuitiveness and expressivity. Most question answering systems translate questions into triples which are matched against the RDF data to retrieve an answer typically relying on some similarity metric. However in many cases triples do not represent a faithful representation of the semantic structure of the natural language question with the result that more expressive queries can not be answered. To circumvent this problem we present a novel approach that relies on a parse of the question to produce a SPARQL template that directly mirrors the internal structure of the question. This template is then instantiated using statistical entity identification and predicate detection. We show that this approach is competitive and discuss cases of questions that can be answered with our approach but not with competing approaches.;
Proceedings of the 21st International Conference on World Wide Web;DIY hacking and craft have recently drawn attention in HCI and CSCW largely as a collaborative and creative hobbyist practice. We shift the focus from the recreational elements of this practice to the ways in which it democratizes design and manufacturing. This democratized technological practice we argue unifies playfulness utility and expressiveness relying on some industrial infrastructures while creating demand for new types of tools and literacies. Thriving on top of collaborative digital systems the Maker movement both implicates and impacts professional designers. As users move more towards personalization and reappropriation new design opportunities are created for HCI.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Wireless communication has become an intrinsic part of modern implantable medical devices (IMDs). Recent work however has demonstrated that wireless connectivity can be exploited to compromise the confidentiality of IMDs' transmitted data or to send unauthorized commands to IMDs---even commands that cause the device to deliver an electric shock to the patient. The key challenge in addressing these attacks stems from the difficulty of modifying or replacing already-implanted IMDs. Thus in this paper we explore the feasibility of protecting an implantable device from such attacks without modifying the device itself. We present a physical-layer solution that delegates the security of an IMD to a personal base station called the shield. The shield uses a novel radio design that can act as a jammer-cum-receiver. This design allows it to jam the IMD's messages preventing others from decoding them while being able to decode them itself. It also allows the shield to jam unauthorized commands---even those that try to alter the shield's own transmissions. We implement our design in a software radio and evaluate it with commercial IMDs. We find that it effectively provides confidentiality for private data and protects the IMD from unauthorized commands.;
Proceedings of the ACM SIGCOMM 2011 Conference;"We present the design implementation and evaluation of post-copy based live migration for virtual machines (VMs) across a Gigabit LAN. Live migration is an indispensable feature in today's virtualization technologies. Post-copy migration defers the transfer of a VM's memory contents until after its processor state has been sent to the target host. This deferral is in contrast to the traditional pre-copy approach which first copies the memory state over multiple iterations followed by a final transfer of the processor state. The post-copy strategy can provide a win-win"" by reducing total migration time closer to its equivalent time achieved by non-live VM migration. This is done while maintaining the liveness benefits of the pre-copy approach. We compare post-copy extensively against the traditional pre-copy approach on top of the Xen Hypervisor. Using a range of VM workloads we show improvements in several migration metrics including pages transferred total migration time and network overhead. We facilitate the use of post-copy with adaptive pre-paging in order to eliminate all duplicate page transmissions. Our implementation is able to reduce the number of network-bound page faults to within 21% of the VM's working set for large workloads. Finally we eliminate the transfer of free memory pages in both migration schemes through a dynamic self-ballooning (DSB) mechanism. DSB periodically releases free pages in a guest VM back to the hypervisor and significantly speeds up migration with negligible performance degradation.""";
Proceedings of the 2009 ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments;"Deep learning technologies which are the key components of state-of-the-art Artificial Intelligence (AI) services have shown great success in providing human-level capabilities for a variety of tasks such as visual analysis speech recognition and natural language processing and etc. Building a production-level deep learning model is a non-trivial task which requires a large amount of training data powerful computing resources and human expertises. Therefore illegitimate reproducing distribution and the derivation of proprietary deep learning models can lead to copyright infringement and economic harm to model creators. Therefore it is essential to devise a technique to protect the intellectual property of deep learning models and enable external verification of the model ownership.In this paper we generalize the digital watermarking'' concept from multimedia ownership verification to deep neural network (DNNs) models. We investigate three DNN-applicable watermark generation algorithms propose a watermark implanting approach to infuse watermark into deep learning models and design a remote verification mechanism to determine the model ownership. By extending the intrinsic generalization and memorization capabilities of deep neural networks we enable the models to learn specially crafted watermarks at training and activate with pre-specified predictions when observing the watermark patterns at inference. We evaluate our approach with two image recognition benchmark datasets. Our framework accurately (100%) and quickly verifies the ownership of all the remotely deployed deep learning models without affecting the model accuracy for normal input data. In addition the embedded watermarks in DNN models are robust and resilient to different counter-watermark mechanisms such as fine-tuning parameter pruning and model inversion attacks.""";
Proceedings of the 2018 on Asia Conference on Computer and Communications Security;Frequency overlap across wireless networks with different radio technologies can cause severe interference and reduce communication reliability. The circumstances are particularly unfavorable for ZigBee networks that share the 2.4 GHz ISM band with WiFi senders capable of 10 to 100 times higher transmission power. Our work first examines the interference patterns between ZigBee and WiFi networks at the bit-level granularity. Under certain conditions ZigBee activities can trigger a nearby WiFi transmitter to back off in which case the header is often the only part of the Zig-Bee packet being corrupted. We call this the symmetric interference regions in comparison to the asymmetric regions where the ZigBee signal is too weak to be detected by WiFi senders but WiFi activity can uniformly corrupt any bit in a ZigBee packet. With these observations we design BuzzBuzz to mitigate WiFi interference through header and payload redundancy. Multi-Headers provides header redundancy giving ZigBee nodes multiple opportunities to detect incoming packets. Then TinyRS a full-featured Reed Solomon library for resource-constrained devices helps decoding polluted packet payload. On a medium-sized testbed BuzzBuzz improves the ZigBee network delivery rate by 70%. Furthermore BuzzBuzz reduces ZigBee retransmissions by a factor of three which increases the WiFi throughput by 10%.;
Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems;Content-Centric Networking (CCN) is a novel networking paradigm centered around content distribution rather than host-to-host connectivity. This change from host-centric to content-centric has several attractive advantages such as network load reduction low dissemination latency and energy efficiency. However it is unclear whether today's technology is ready for the CCN (r)evolution. The major contribution of this paper is a systematic evaluation of the suitability of existing software and hardware components in today's routers for the support of CCN. Our main conclusion is that a CCN deployment is feasible at a Content Distribution Network (CDN) and ISP scale whereas today's technology is not yet ready to support an Internet scale deployment.;
Proceedings of the ACM SIGCOMM Workshop on Information-Centric Networking;The throughput of existing MIMO LANs is limited by the number of antennas on the AP. This paper shows how to overcome this limit. It presents interference alignment and cancellation (IAC) a new approach for decoding concurrent sender-receiver pairs in MIMO networks. IAC synthesizes two signal processing techniques interference alignment and interference cancellation showing that the combination applies to scenarios where neither interference alignment nor cancellation applies alone. We show analytically that IAC almost doubles the throughput of MIMO LANs. We also implement IAC in GNU-Radio and experimentally demonstrate that for 2x2 MIMO LANs IAC increases the average throughput by 1.5x on the downlink and 2x on the uplink.;
Proceedings of the ACM SIGCOMM 2009 Conference on Data Communication;We present Apposcopy a new semantics-based approach for identifying a prevalent class of Android malware that steals private user information. Apposcopy incorporates (i) a high-level language for specifying signatures that describe semantic characteristics of malware families and (ii) a static analysis for deciding if a given application matches a malware signature. The signature matching algorithm of Apposcopy uses a combination of static taint analysis and a new form of program representation called Inter-Component Call Graph to efficiently detect Android applications that have certain control- and data-flow properties. We have evaluated Apposcopy on a corpus of real-world Android applications and show that it can effectively and reliably pinpoint malicious applications that belong to certain malware families.;
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering;Convolutional neural networks (CNN) are the current stateof-the-art for many computer vision tasks. CNNs outperform older methods in accuracy but require vast amounts of computation and memory. As a result existing CNN applications are typically run on clusters of CPUs or GPUs. Studies into the FPGA acceleration of CNN workloads has achieved reductions in power and energy consumption. However large GPUs outperform modern FPGAs in throughput and the existence of compatible deep learning frameworks give GPUs a significant advantage in programmability. Recent research in machine learning demonstrates the potential of very low precision CNNs -- i.e. CNNs with binarized weights and activations. Such binarized neural networks (BNNs) appear well suited for FPGA implementation as their dominant computations are bitwise logic operations and their memory requirements are reduced. A combination of low-precision networks and high-level design methodology may help address the performance and productivity gap between FPGAs and GPUs. In this paper we present the design of a BNN accelerator that is synthesized from C++ to FPGA-targeted Verilog. The accelerator outperforms existing FPGA-based CNN accelerators in GOPS as well as energy and resource efficiency.;
Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays;A number of online services nowadays rely upon machine learning to extract valuable information from data collected in the wild. This exposes learning algorithms to the threat of data poisoning i.e. a coordinate attack in which a fraction of the training data is controlled by the attacker and manipulated to subvert the learning process. To date these attacks have been devised only against a limited class of binary learning algorithms due to the inherent complexity of the gradient-based procedure used to optimize the poisoning points (a.k.a. adversarial training examples). In this work we first extend the definition of poisoning attacks to multiclass problems. We then propose a novel poisoning algorithm based on the idea of back-gradient optimization i.e. to compute the gradient of interest through automatic differentiation while also reversing the learning procedure to drastically reduce the attack complexity. Compared to current poisoning strategies our approach is able to target a wider class of learning algorithms trained with gradient-based procedures including neural networks and deep learning architectures. We empirically evaluate its effectiveness on several application examples including spam filtering malware detection and handwritten digit recognition. We finally show that similarly to adversarial test examples adversarial training examples can also be transferred across different learning algorithms.;
Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security;The MapReduce framework is increasingly being used to analyze large volumes of data. One important type of data analysis done with MapReduce is log processing in which a click-stream or an event log is filtered aggregated or mined for patterns. As part of this analysis the log often needs to be joined with reference data such as information about users. Although there have been many studies examining join algorithms in parallel and distributed DBMSs the MapReduce framework is cumbersome for joins. MapReduce programmers often use simple but inefficient algorithms to perform joins. In this paper we describe crucial implementation details of a number of well-known join strategies in MapReduce and present a comprehensive experimental comparison of these join techniques on a 100-node Hadoop cluster. Our results provide insights that are unique to the MapReduce platform and offer guidance on when to use a particular join algorithm on this platform.;
Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data;An atomic cross-chain swap is a distributed coordination task where multiple parties exchange assets across multiple blockchains for example trading bitcoin for ether.An atomic swap protocol guarantees (1) if all parties conform to the protocol then all swaps take place (2) if some coalition deviates from the protocol then no conforming party ends up worse off and (3) no coalition has an incentive to deviate from the protocol.A cross-chain swap is modeled as a directed graph D whose vertexes are parties and whose arcs are proposed asset transfers. For any pair (D L) where D = (VA) is a strongly-connected directed graph and L âŠ‚ V a feedback vertex set for D we give an atomic cross-chain swap protocol for D using a form of hashed timelock contracts where the vertexes in L generate the hashlocked secrets. We show that no such protocol is possible if D is not strongly connected or if D is strongly connected but L is not a feedback vertex set. The protocol has time complexityO(diam(D)) and space complexity (bits stored on all blockchains) O(|A|2).;
Proceedings of the 2018 ACM Symposium on Principles of Distributed Computing;Modern camera calibration and multiview stereo techniques enable users to smoothly navigate between different views of a scene captured using standard cameras. The underlying automatic 3D reconstruction methods work well for buildings and regular structures but often fail on vegetation vehicles and other complex geometry present in everyday urban scenes. Consequently missing depth information makes Image-Based Rendering (IBR) for such scenes very challenging. Our goal is to provide plausible free-viewpoint navigation for such datasets. To do this we introduce a new IBR algorithm that is robust to missing or unreliable geometry providing plausible novel views even in regions quite far from the input camera positions. We first oversegment the input images creating superpixels of homogeneous color content which often tends to preserve depth discontinuities. We then introduce a depth synthesis approach for poorly reconstructed regions based on a graph structure on the oversegmentation and appropriate traversal of the graph. The superpixels augmented with synthesized depth allow us to define a local shape-preserving warp which compensates for inaccurate depth. Our rendering algorithm blends the warped images and generates plausible image-based novel views for our challenging target scenes. Our results demonstrate novel view synthesis in real time for multiple challenging scenes with significant depth complexity providing a convincing immersive navigation experience.;
Apache hadoop goes realtime at Facebook;Facebook recently deployed Facebook Messages its first ever user-facing application built on the Apache Hadoop platform. Apache HBase is a database-like layer built on Hadoop designed to support billions of messages per day. This paper describes the reasons why Facebook chose Hadoop and HBase over other systems such as Apache Cassandra and Voldemort and discusses the application's requirements for consistency availability partition tolerance data model and scalability. We explore the enhancements made to Hadoop to make it a more effective realtime system the tradeoffs we made while configuring the system and how this solution has significant advantages over the sharded MySQL database scheme used in other applications at Facebook and many other web-scale companies. We discuss the motivations behind our design choices the challenges that we face in day-to-day operations and future capabilities and improvements still under development. We offer these observations on the deployment as a model for other companies who are contemplating a Hadoop-based solution over traditional sharded RDBMS deployments.;
Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data;In the domain of computer games research into the interaction between player and game has centred on 'enjoyment' often drawing in particular on optimal experience research and Csikszentmihalyi's 'Flow theory'. Flow is a well-established construct for examining experience in any setting and its application to game-play is intuitive. Nevertheless it's not immediately obvious how to translate between the flow construct and an operative description of game-play. Previous research has attempted this translation through analogy. In this article we propose a practical integrated approach for analysis of the mechanics and aesthetics of game-play which helps develop deeper insights into the capacity for flow within games.The relationship between player and game characterized by learning and enjoyment is central to our analysis. We begin by framing that relationship within Cowley's user-system-experience (USE) model and expand this into an information systems framework which enables a practical mapping of flow onto game-play. We believe this approach enhances our understanding of a player's interaction with a game and provides useful insights for games' researchers seeking to devise mechanisms to adapt game-play to individual players.;
A measurement study of google play;Although millions of users download and use third-party Android applications from the Google Play store little information is known on an aggregated level about these applications. We have built PlayDrone the first scalable Google Play store crawler and used it to index and analyze over 1100000 applications in the Google Play store on a daily basis the largest such index of Android applications. PlayDrone leverages various hacking techniques to circumvent Google's roadblocks for indexing Google Play store content and makes proprietary application sources available including source code for over 880000 free applications. We demonstrate the usefulness of PlayDrone in decompiling and analyzing application content by exploring four previously unaddressed issues: the characterization of Google Play application content at large scale and its evolution over time library usage in applications and its impact on application portability duplicative application content in Google Play and the ineffectiveness of OAuth and related service authentication mechanisms resulting in malicious users being able to easily gain unauthorized access to user data and resources on Amazon Web Services and Facebook.;
The 2014 ACM International Conference on Measurement and Modeling of Computer Systems;"We present FairplayMP (for Fairplay Multi-Party"") a system for secure multi-party computation. Secure computation is one of the great achievements of modern cryptography enabling a set of untrusting parties to compute any function of their private inputs while revealing nothing but the result of the function. In a sense FairplayMP lets the parties run a joint computation that emulates a trusted party which receives the inputs from the parties computes the function and privately informs the parties of their outputs. FairplayMP operates by receiving a high-level language description of a function and a configuration file describing the participating parties. The system compiles the function into a description as a Boolean circuit and perform a distributed evaluation of the circuit while revealing nothing else. FairplayMP supplements the Fairplay system [16] which supported secure computation between two parties. The underlying protocol of FairplayMP is the Beaver-Micali-Rogaway (BMR) protocol which runs in a constant number of communication rounds (eight rounds in our implementation). We modified the BMR protocol in a novel way and considerably improved its performance by using the Ben-Or-Goldwasser-Wigderson (BGW) protocol for the purpose of constructing gate tables. We chose to use this protocol since we believe that the number of communication rounds is a major factor on the overall performance of the protocol. We conducted different experiments which measure the effect of different parameters on the performance of the system and demonstrate its scalability. (We can now tell for example that running a second-price auction between four bidders using five computation players takes about 8 seconds.)""";
Proceedings of the 15th ACM Conference on Computer and Communications Security;"We present the first large-scale studies of three advanced web tracking mechanisms - canvas fingerprinting evercookies and use of cookie syncing"" in conjunction with evercookies. Canvas fingerprinting a recently developed form of browser fingerprinting has not previously been reported in the wild our results show that over 5% of the top 100000 websites employ it. We then present the first automated study of evercookies and respawning and the discovery of a new evercookie vector IndexedDB. Turning to cookie syncing we present novel techniques for detection and analysing ID flows and we quantify the amplification of privacy-intrusive tracking practices due to cookie syncing. Our evaluation of the defensive techniques used by privacy-aware users finds that there exist subtle pitfalls --- such as failing to clear state on multiple browsers at once - in which a single lapse in judgement can shatter privacy defenses. This suggests that even sophisticated users face great difficulties in evading tracking techniques.""";
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security;Over the last decade process mining emerged as a new research field that focuses on the analysis of processes using event data. Classical data mining techniques such as classification clustering regression association rule learning and sequence/episode mining do not focus on business process models and are often only used to analyze a specific step in the overall process. Process mining focuses on end-to-end processes and is possible because of the growing availability of event data and new process discovery and conformance checking techniques.Process models are used for analysis (e.g. simulation and verification) and enactment by BPM/WFM systems. Previously process models were typically made by hand without using event data. However activities executed by people machines and software leave trails in so-called event logs. Process mining techniques use such logs to discover analyze and improve business processes.Recently the Task Force on Process Mining released the Process Mining Manifesto. This manifesto is supported by 53 organizations and 77 process mining experts contributed to it. The active involvement of end-users tool vendors consultants analysts and researchers illustrates the growing significance of process mining as a bridge between data mining and business process modeling. The practical relevance of process mining and the interesting scientific challenges make process mining one of the â€œhotâ€ topics in Business Process Management (BPM). This article introduces process mining as a new research field and summarizes the guiding principles and challenges described in the manifesto.;
Polyhedral parallel code generation for CUDA;This article addresses the compilation of a sequential program for parallel execution on a modern GPU. To this end we present a novel source-to-source compiler called PPCG. PPCG singles out for its ability to accelerate computations from any static control loop nest generating multiple CUDA kernels when necessary. We introduce a multilevel tiling strategy and a code generation scheme for the parallelization and locality optimization of imperfectly nested loops managing memory and exposing concurrency according to the constraints of modern GPUs. We evaluate our algorithms and tool on the entire PolyBench suite.;
Anonysense: privacy-aware people-centric sensing;Personal mobile devices are increasingly equipped with the capability to sense the physical world (through cameras microphones and accelerometers for example) and the network world (with Wi-Fi and Bluetooth interfaces). Such devices offer many new opportunities for cooperative sensing applications. For example users' mobile phones may contribute data to community-oriented information services from city-wide pollution monitoring to enterprise-wide detection of unauthorized Wi-Fi access points. This people-centric mobile-sensing model introduces a new security challenge in the design of mobile systems: protecting the privacy of participants while allowing their devices to reliably contribute high-quality data to these large-scale applications.We describe AnonySense a privacy-aware architecture for realizing pervasive applications based on collaborative opportunistic sensing by personal mobile devices. AnonySense allows applications to submit sensing tasks that will be distributed across anonymous participating mobile devices later receiving verified yet anonymized sensor data reports back from the field thus providing the first secure implementation of this participatory sensing model. We describe our trust model and the security properties that drove the design of the AnonySense system. We evaluate our prototype implementation through experiments that indicate the feasibility of this approach and through two applications: a Wi-Fi rogue access point detector and a lost-object finder.;
Proceedings of the 6th International Conference on Mobile Systems Applications and Services;Question and answer (Q&ampA) sites such as Yahoo! Answers are places where users ask questions and others answer them. In this paper we investigate predictors of answer quality through a comparative controlled field study of responses provided across several online Q&ampA sites. Along with several quantitative results concerning the effects of factors such as question topic and rhetorical strategy we present two high-level messages. First you get what you pay for in Q&ampA sites. Answer quality was typically higher in Google Answers (a fee-based site) than in the free sites we studied and paying more money for an answer led to better outcomes. Second we find that a Q&ampA site's community of users contributes to its success. Yahoo! Answers a Q&ampA site where anybody can answer questions outperformed sites that depend on specific individuals to answer questions such as library reference services.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;This paper presents a programmable and scalable digital neuromorphic architecture based on 3D high-density memory integrated with logic tier for efficient neural computing. The proposed architecture consists of clusters of processing engines connected by 2D mesh network as a processing tier which is integrated in 3D with multiple tiers of DRAM. The PE clusters access multiple memory channels (vaults) in parallel. The operating principle referred to as the memory centric computing embeds specialized state-machines within the vault controllers of HMC to drive data into the PE clusters. The paper presents the basic architecture of the Neurocube and an analysis of the logic tier synthesized in 28nm and 15nm process technologies. The performance of the Neurocube is evaluated and illustrated through the mapping of a Convolutional Neural Network and estimating the subsequent power and performance for both training and inference.;
Proceedings of the 43rd International Symposium on Computer Architecture;"In this work we study interactive proofs for tractable languages. The (honest) prover should be efficient and run in polynomial time or in other words a muggle"". The verifier should be super-efficient and run in nearly-linear time. These proof systems can be used for delegating computation: a server can run a computation for a client and interactively prove the correctness of the result. The client can verify the result's correctness in nearly-linear time (instead of running the entire computation itself). Previously related questions were considered in the Holographic Proof setting by Babai Fortnow Levin and Szegedy in the argument setting under computational assumptions by Kilian and in the random oracle model by Micali. Our focus however is on the original interactive proof model where no assumptions are made on the computational power or adaptiveness of dishonest provers. Our main technical theorem gives a public coin interactive proof for any language computable by a log-space uniform boolean circuit with depth d and input length n. The verifier runs in time (n+d) â€¢ polylog(n) and space O(log(n)) the communication complexity is d â€¢ polylog(n) and the prover runs in time poly(n). In particular for languages computable by log-space uniform NC (circuits of polylog(n) depth) the prover is efficient the verifier runs in time n â€¢ polylog(n) and space O(log(n)) and the communication complexity is polylog(n). Using this theorem we make progress on several questions: We show how to construct short (polylog size) computationally sound non-interactive certificates of correctness for any log-space uniform NC computation in the public-key model. The certificates can be verified in quasi-linear time and are for a designated verifier: each certificate is tailored to the verifier's public key. This result uses a recent transformation of Kalai and Raz from public-coin interactive proofs to one-round arguments. The soundness of the certificates is based on the existence of a PIR scheme with polylog communication. Interactive proofs with public-coin log-space poly-time verifiers for all of P. This settles an open question regarding the expressive power of proof systems with such verifiers. Zero-knowledge interactive proofs with communication complexity that is quasi-linear in the witness length for any NP language verifiable in NC based on the existence of one-way functions. Probabilistically checkable arguments (a model due to Kalai and Raz) of size polynomial in the witness length (rather than the instance length) for any NP language verifiable in NC under computational assumptions.""";
Proceedings of the Fortieth Annual ACM Symposium on Theory of Computing;Gesture is becoming an increasingly popular means of interacting with computers. However it is still relatively costly to deploy robust gesture recognition sensors in existing mobile platforms. We present SoundWave a technique that leverages the speaker and microphone already embedded in most commodity devices to sense in-air gestures around the device. To do this we generate an inaudible tone which gets frequency-shifted when it reflects off moving objects like the hand. We measure this shift with the microphone to infer various gestures. In this note we describe the phenomena and detection algorithm demonstrate a variety of gestures and present an informal evaluation on the robustness of this approach across different devices and people.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;This article attempts to bridge the gap between widely discussed ethical principles of Human-centered AI (HCAI) and practical steps for effective governance. Since HCAI systems are developed and implemented in multiple organizational structures I propose 15 recommendations at three levels of governance: team organization and industry. The recommendations are intended to increase the reliability safety and trustworthiness of HCAI systems: (1) reliable systems based on sound software engineering practices (2) safety culture through business management strategies and (3) trustworthy certification by independent oversight. Software engineering practices within teams include audit trails to enable analysis of failures software engineering workflows verification and validation testing bias testing to enhance fairness and explainable user interfaces. The safety culture within organizations comes from management strategies that include leadership commitment to safety hiring and training oriented to safety extensive reporting of failures and near misses internal review boards for problems and future plans and alignment with industry standard practices. The trustworthiness certification comes from industry-wide efforts that include government interventions and regulation accounting firms conducting external audits insurance companies compensating for failures non-governmental and civil society organizations advancing design principles and professional organizations and research institutes developing standards policies and novel ideas. The larger goal of effective governance is to limit the dangers and increase the benefits of HCAI to individuals organizations and society.;
Checking app behavior against app descriptions;"How do we know a program does what it claims to do? After clustering Android apps by their description topics we identify outliers in each cluster with respect to their API usage. A weather"" app that sends messages thus becomes an anomaly likewise a ""messaging"" app would typically not be expected to access the current location. Applied on a set of 22500+ Android applications our CHABADA prototype identified several anomalies additionally it flagged 56% of novel malware as such without requiring any known malware patterns.""";
Proceedings of the 36th International Conference on Software Engineering;Extracting knowledge by performing computations on graphs is becoming increasingly challenging as graphs grow in size. A standard approach distributes the graph over a cluster of nodes but performing computations on a distributed graph is expensive if large amount of data have to be moved. Without partitioning the graph communication quickly becomes a limiting factor in scaling the system up. Existing graph partitioning heuristics incur high computation and communication cost on large graphs sometimes as high as the future computation itself. Observing that the graph has to be loaded into the cluster we ask if the partitioning can be done at the same time with a lightweight streaming algorithm.We propose natural simple heuristics and compare their performance to hashing and METIS a fast offline heuristic. We show on a large collection of graph datasets that our heuristics are a significant improvement with the best obtaining an average gain of 76%. The heuristics are scalable in the size of the graphs and the number of partitions. Using our streaming partitioning methods we are able to speed up PageRank computations on Spark a distributed computation system by 18% to 39% for large social networks.;
Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;"We present the design implementation and evaluation of post-copy based live migration for virtual machines (VMs) across a Gigabit LAN. Post-copy migration defers the transfer of a VM's memory contents until after its processor state has been sent to the target host. This deferral is in contrast to the traditional pre-copy approach which first copies the memory state over multiple iterations followed by a final transfer of the processor state. The post-copy strategy can provide a win-win"" by reducing total migration time while maintaining the liveness of the VM during migration. We compare post-copy extensively against the traditional pre-copy approach on the Xen Hypervisor. Using a range of VM workloads we show that post-copy improves several metrics including pages transferred total migration time and network overhead. We facilitate the use of post-copy with adaptive prepaging techniques to minimize the number of page faults across the network. We propose different prepaging strategies and quantitatively compare their effectiveness in reducing network-bound page faults. Finally we eliminate the transfer of free memory pages in both pre-copy and post-copy through a dynamic self-ballooning (DSB) mechanism. DSB periodically reclaims free pages from a VM and significantly speeds up migration with negligible performance impact on VM workload.""";
A randomized scheduler with probabilistic guarantees of finding bugs;This paper presents a randomized scheduler for finding concurrency bugs. Like current stress-testing methods it repeatedly runs a given test program with supplied inputs. However it improves on stress-testing by finding buggy schedules more effectively and by quantifying the probability of missing concurrency bugs. Key to its design is the characterization of the depth of a concurrency bug as the minimum number of scheduling constraints required to find it. In a single run of a program with n threads and k steps our scheduler detects a concurrency bug of depth d with probability at least 1/nkd-1. We hypothesize that in practice many concurrency bugs (including well-known types such as ordering errors atomicity violations and deadlocks) have small bug-depths and we confirm the efficiency of our schedule randomization by detecting previously unknown and known concurrency bugs in several production-scale concurrent programs.;
Proceedings of the Fifteenth International Conference on Architectural Support for Programming Languages and Operating Systems;While residential broadband Internet access is popular in many parts of the world only a few studies have examined the characteristics of such traffic. In this paper we describe observations from monitoring the network activity for more than 20000 residential DSL customers in an urban area. To ensure privacy all data is immediately anonymized. We augment the anonymized packet traces with information about DSL-level sessions IP (re-)assignments and DSL link bandwidth.Our analysis reveals a number of surprises in terms of the mental models we developed from the measurement literature. For example we find that HTTP - not peer-to-peer - traffic dominates by a significant margin that more often than not the home user's immediate ISP connectivity contributes more to the round-trip times the user experiences than the WAN portion of the path and that the DSL lines are frequently not the bottleneck in bulk-transfer performance.;
Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement;Collaborative filtering (CF) has been widely employed within recommender systems to solve many real-world problems. Learning effective latent factors plays the most important role in collaborative filtering. Traditional CF methods based upon matrix factorization techniques learn the latent factors from the user-item ratings and suffer from the cold start problem as well as the sparsity problem. Some improved CF methods enrich the priors on the latent factors by incorporating side information as regularization. However the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information. To tackle this problem we learn effective latent representations via deep learning. Deep learning models have emerged as very appealing in learning effective representations in many applications. In particular we propose a general deep architecture for CF by integrating matrix factorization with deep feature learning. We provide a natural instantiations of our architecture by combining probabilistic matrix factorization with marginalized denoising stacked auto-encoders. The combined framework leads to a parsimonious fit over the latent features as indicated by its improved performance in comparison to prior state-of-art models over four large datasets for the tasks of movie/book recommendation and response prediction.;
Proceedings of the 24th ACM International on Conference on Information and Knowledge Management;As the size of Deep Neural Networks (DNNs) continues to grow to increase accuracy and solve more complex problems their energy footprint also scales. Weight pruning reduces DNN model size and the computation by removing redundant weights. However we implemented weight pruning for several popular networks on a variety of hardware platforms and observed surprising results. For many networks the network sparsity caused by weight pruning will actually hurt the overall performance despite large reductions in the model size and required multiply-accumulate operations. Also encoding the sparse format of pruned networks incurs additional storage space overhead. To overcome these challenges we propose Scalpel that customizes DNN pruning to the underlying hardware by matching the pruned network structure to the data-parallel hardware organization. Scalpel consists of two techniques: SIMD-aware weight pruning and node pruning. For low-parallelism hardware (e.g. microcontroller) SIMD-aware weight pruning maintains weights in aligned fixed-size groups to fully utilize the SIMD units. For high-parallelism hardware (e.g. GPU) node pruning removes redundant nodes not redundant weights thereby reducing computation without sacrificing the dense matrix format. For hardware with moderate parallelism (e.g. desktop CPU) SIMD-aware weight pruning and node pruning are synergistically applied together. Across the microcontroller CPU and GPU Scalpel achieves mean speedups of 3.54x 2.61x and 1.25x while reducing the model sizes by 88% 82% and 53%. In comparison traditional weight pruning achieves mean speedups of 1.90x 1.06x 0.41x across the three platforms.;
Proceedings of the 44th Annual International Symposium on Computer Architecture;"Delivering increasingly complex software-reliant systems demands better ways to manage the long-term effects of short-term expedients. The technical debt metaphor is gaining significant traction in the agile development community as a way to understand and communicate such issues. The idea is that developers sometimes accept compromises in a system in one dimension (e.g. modularity) to meet an urgent demand in some other dimension (e.g. a deadline) and that such compromises incur a debt"": on which ""interest"" has to be paid and which the ""principal"" should be repaid at some point for the long-term health of the project. We argue that the software engineering research community has an opportunity to study and improve this concept. We can offer software engineers a foundation for managing such trade-offs based on models of their economic impacts. Therefore we propose managing technical debt as a part of the future research agenda for the software engineering field.""";
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;This paper describes an inter-procedural technique for computing symbolic bounds on the number of statements a procedure executes in terms of its scalar inputs and user-defined quantitative functions of input data-structures. Such computational complexity bounds for even simple programs are usually disjunctive non-linear and involve numerical properties of heaps. We address the challenges of generating these bounds using two novel ideas.We introduce a proof methodology based on multiple counter instrumentation (each counter can be initialized and incremented at potentially multiple program locations) that allows a given linear invariant generation tool to compute linear bounds individually on these counter variables. The bounds on these counters are then composed together to generate total bounds that are non-linear and disjunctive. We also give an algorithm for automating this proof methodology. Our algorithm generates complexity bounds that are usually precise not only in terms of the computational complexity but also in terms of the constant factors.Next we introduce the notion of user-defined quantitative functions that can be associated with abstract data-structures e.g. length of a list height of a tree etc. We show how to compute bounds in terms of these quantitative functions using a linear invariant generation tool that has support for handling uninterpreted functions. We show application of this methodology to commonly used data-structures (namely lists list of lists trees bit-vectors) using examples from Microsoft product code. We observe that a few quantitative functions for each data-structure are usually sufficient to allow generation of symbolic complexity bounds of a variety of loops that iterate over these data-structures and that it is straightforward to define these quantitative functions.The combination of these techniques enables generation of precise computational complexity bounds for real-world examples (drawn from Microsoft product code and C++ STL library code) for some of which it is non-trivial to even prove termination. Such automatically generated bounds are very useful for early detection of egregious performance problems in large modular codebases that are constantly being changed by multiple developers who make heavy use of code written by others without a good understanding of their implementation complexity.;
Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages;Approximate computing has emerged as a new design paradigm that exploits the inherent error resilience of a wide range of application domains by allowing hardware implementations to forsake exact Boolean equivalence with algorithmic specifications. A slew of manual design techniques for approximate computing have been proposed in recent years but very little effort has been devoted to design automation.We propose SALSA a Systematic methodology for Automatic Logic Synthesis of Approximate circuits. Given a golden RTL specification of a circuit and a quality constraint that defines the amount of error that may be introduced in the implementation SALSA synthesizes an approximate version of the circuit that adheres to the pre-specified quality bounds. We make two key contributions: (i) the rigorous formulation of the problem of approximate logic synthesis enabling the generation of circuits that are correct by construction and (ii) mapping the problem of approximate synthesis into an equivalent traditional logic synthesis problem thereby allowing the capabilities of existing synthesis tools to be fully utilized for approximate logic synthesis. In order to achieve these benefits SALSA encodes the quality constraints using logic functions called Q-functions and captures the flexibility that they engender as Approximation Don't Cares (ADCs) which are used for circuit simplification using traditional don't care based optimization techniques. We have implemented SALSA using two off-the-shelf logic synthesis tools - SIS and Synopsys Design Compiler. We automatically synthesize approximate circuits ranging from arithmetic building blocks (adders multipliers MAC) to entire datapaths (DCT FIR IIR SAD FFT Butterfly Euclidean distance) demonstrating scalability and significant improvements in area (1.1X to 1.85X for tight error constraints and 1.2X to 4.75X for relaxed error constraints) and power (1.15X to 1.75X for tight error constraints and 1.3X to 5.25X for relaxed error constraints).;
Proceedings of the 49th Annual Design Automation Conference;Grounded Theory (GT) has proved an extremely useful research approach in several fields including medical sociology nursing education and management theory. However GT is a complex method based on an inductive paradigm that is fundamentally different from the traditional hypothetico-deductive research model. As there are at least three variants of GT some ostensibly GT research suffers from method slurring where researchers adopt an arbitrary subset of GT practices that are not recognizable as GT. In this paper we describe the variants of GT and identify the core set of GT practices. We then analyze the use of grounded theory in software engineering. We carefully and systematically selected 98 articles that mention GT of which 52 explicitly claim to use GT with the other 46 using GT techniques only. Only 16 articles provide detailed accounts of their research procedures. We offer guidelines to improve the quality of both conducting and reporting GT studies. The latter is an important extension since current GT guidelines in software engineering do not cover the reporting process despite good reporting being necessary for evaluating a study and informing subsequent research.;
Proceedings of the 38th International Conference on Software Engineering;Dynamic analysis of software systems produces behavioral models that are useful for analysis verification and testing.The main techniques for extracting models of functional behavior generate either models of constraints on data usually in the form of Boolean expressions or models of interactions between components usually in the form of finite state machines. Both data and interaction models are useful for analyzing and verifying different aspects of software behavior but none of them captures the complex interplay between data values and components interactions. Thus related analysis and testing techniques can miss important information.In this paper we focus on the generation of models of relations between data values and component interactions and we present GK-tail a technique to automatically generate extended finite state machines (EFSMs) from interaction traces. EFSMs model the interplay between data values and component interactions by annotating FSM edges with conditions on data values. We show that EFSMs include details that are not captured by either Boolean expressions or (classic) FSM alone and allow for more accurate analysis and verification than separate models even if considered jointly.;
Proceedings of the 30th International Conference on Software Engineering;Exploring architectures for large modern FPGAs requires sophisticated software that can model and target hypothetical devices. Furthermore research into new CAD algorithms often requires a complete and open source baseline CAD flow. This article describes recent advances in the open source Verilog-to-Routing (VTR) CAD flow that enable further research in these areas. VTR now supports designs with multiple clocks in both timing analysis and optimization. Hard adder/carry logic can be included in an architecture in various ways and significantly improves the performance of arithmetic circuits. The flow now models energy consumption an increasingly important concern. The speed and quality of the packing algorithms have been significantly improved. VTR can now generate a netlist of the final post-routed circuit which enables detailed simulation of a design for a variety of purposes. We also release new FPGA architecture files and models that are much closer to modern commercial architectures enabling more realistic experiments. Finally we show that while this version of VTR supports new and complex features it has a 1.5\texttimes{;
The Architectural Implications of Autonomous Driving: Constraints and Acceleration;Autonomous driving systems have attracted a significant amount of interest recently and many industry leaders such as Google Uber Tesla and Mobileye have invested a large amount of capital and engineering power on developing such systems. Building autonomous driving systems is particularly challenging due to stringent performance requirements in terms of both making the safe operational decisions and finishing processing at real-time. Despite the recent advancements in technology such systems are still largely under experimentation and architecting end-to-end autonomous driving systems remains an open research question. To investigate this question we first present and formalize the design constraints for building an autonomous driving system in terms of performance predictability storage thermal and power. We then build an end-to-end autonomous driving system using state-of-the-art award-winning algorithms to understand the design trade-offs for building such systems. In our real-system characterization we identify three computational bottlenecks which conventional multicore CPUs are incapable of processing under the identified design constraints. To meet these constraints we accelerate these algorithms using three accelerator platforms including GPUs FPGAs and ASICs which can reduce the tail latency of the system by 169x 10x and 93x respectively. With accelerator-based designs we are able to build an end-to-end autonomous driving system that meets all the design constraints and explore the trade-offs among performance power and the higher accuracy enabled by higher resolution cameras.;
Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems;With the marvelous development of wireless techniques and ubiquitous deployment of wireless systems indoors myriad indoor location-based services (ILBSs) have permeated into numerous aspects of modern life. The most fundamental functionality is to pinpoint the location of the target via wireless devices. According to how wireless devices interact with the target wireless indoor localization schemes roughly fall into two categories: device based and device free. In device-based localization a wireless device (e.g. a smartphone) is attached to the target and computes its location through cooperation with other deployed wireless devices. In device-free localization the target carries no wireless devices while the wireless infrastructure deployed in the environment determines the targetâ€™s location by analyzing its impact on wireless signals.This article is intended to offer a comprehensive state-of-the-art survey on wireless indoor localization from the device perspective. In this survey we review the recent advances in both modes by elaborating on the underlying wireless modalities basic localization principles and data fusion techniques with special emphasis on emerging trends in (1) leveraging smartphones to integrate wireless and sensor capabilities and extend to the social context for device-based localization and (2) extracting specific wireless features to trigger novel human-centric device-free localization. We comprehensively compare each scheme in terms of accuracy cost scalability and energy efficiency. Furthermore we take a first look at intrinsic technical challenges in both categories and identify several open research issues associated with these new challenges.;
Make it stand: balancing shapes for 3D fabrication;Imbalance suggests a feeling of dynamism and movement in static objects. It is therefore not surprising that many 3D models stand in impossibly balanced configurations. As long as the models remain in a computer this is of no consequence: the laws of physics do not apply. However fabrication through 3D printing breaks the illusion: printed models topple instead of standing as initially intended. We propose to assist users in producing novel properly balanced designs by interactively deforming an existing model. We formulate balance optimization as an energy minimization improving stability by modifying the volume of the object while preserving its surface details. This takes place during interactive editing: the user cooperates with our optimizer towards the end result. We demonstrate our method on a variety of models. With our technique users can produce fabricated objects that stand in one or more surprising poses without requiring glue or heavy pedestals.;
Suspended accounts in retrospect: an analysis of twitter spam;In this study we examine the abuse of online social networks at the hands of spammers through the lens of the tools techniques and support infrastructure they rely upon. To perform our analysis we identify over 1.1 million accounts suspended by Twitter for disruptive activities over the course of seven months. In the process we collect a dataset of 1.8 billion tweets 80 million of which belong to spam accounts. We use our dataset to characterize the behavior and lifetime of spam accounts the campaigns they execute and the wide-spread abuse of legitimate web services such as URL shorteners and free web hosting. We also identify an emerging marketplace of illegitimate programs operated by spammers that include Twitter account sellers ad-based URL shorteners and spam affiliate programs that help enable underground market diversification.Our results show that 77% of spam accounts identified by Twitter are suspended within on day of their first tweet. Because of these pressures less than 9% of accounts form social relationships with regular Twitter users. Instead 17% of accounts rely on hijacking trends while 52% of accounts use unsolicited mentions to reach an audience. In spite of daily account attrition we show how five spam campaigns controlling 145 thousand accounts combined are able to persist for months at a time with each campaign enacting a unique spamming strategy. Surprisingly three of these campaigns send spam directing visitors to reputable store fronts blurring the line regarding what constitutes spam on social networks.;
Proceedings of the 2011 ACM SIGCOMM Conference on Internet Measurement Conference;With substantial efforts in ubiquitous computing ICT4D and sustainable interaction design among others HCI is increasingly engaging with matters of social change that go beyond the immediate qualities of interaction. In doing so HCI takes on scientific and moral concerns. This paper explores the potential for feminist social science to contribute to and potentially benefit from HCI's rising interest in social change. It describes how feminist contributions to debates in the philosophy of science have helped clarify relationships among objectivity values data collection and interpretation and social consequences. Feminists have proposed and implemented strategies to pursue scientific and moral agendas together and with equal rigor. In this paper we assess the epistemologies methodologies and methods of feminist social science relative to prior and ongoing research efforts in HCI. We conclude by proposing an outline of a feminist HCI methodology.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Convolutional neural networks (CNNs) have been widely applied in many deep learning applications. In recent years the FPGA implementation for CNNs has attracted much attention because of its high performance and energy efficiency. However existing implementations have difficulty to fully leverage the computation power of the latest FPGAs. In this paper we implement CNN on an FPGA using a systolic array architecture which can achieve high clock frequency under high resource utilization. We provide an analytical model for performance and resource utilization and develop an automatic design space exploration framework as well as source-to-source code transformation from a C program to a CNN implementation using systolic array. The experimental results show that our framework is able to generate the accelerator for real-life CNN models achieving up to 461 GFlops for floating point data type and 1.2 Tops for 8-16 bit fixed point.;
Proceedings of the 54th Annual Design Automation Conference 2017;While traffic signals are necessary to safely control competing flows of traffic they inevitably enforce a stop-and-go movement pattern that increases fuel consumption reduces traffic flow and causes traffic jams. These side effects can be alleviated by providing drivers and their onboard computational devices (e.g. vehicle computer smartphone) with information about the schedule of the traffic signals ahead. Based on when the signal ahead will turn green drivers can then adjust speed so as to avoid coming to a complete halt. Such information is called Green Light Optimal Speed Advisory (GLOSA). Alternatively the onboard computational device may suggest an efficient detour that will save the driver from stops and long waits at red lights ahead.This paper introduces and evaluates SignalGuru a novel software service that relies solely on a collection of mobile phones to detect and predict the traffic signal schedule enabling GLOSA and other novel applications. Our SignalGuru leverages windshield-mounted phones to opportunistically detect current traffic signals with their cameras collaboratively communicate and learn traffic signal schedule patterns and predict their future schedule.Results from two deployments of SignalGuru using iPhones in cars in Cambridge (MA USA) and Singapore show that traffic signal schedules can be predicted accurately. On average SignalGuru comes within 0.66s for pre-timed traffic signals and within 2.45s for traffic-adaptive traffic signals. Feeding SignalGuru's predicted traffic schedule to our GLOSA application our vehicle fuel consumption measurements show savings of 20.3% on average.;
Proceedings of the 9th International Conference on Mobile Systems Applications and Services;In multi-label learning each training example is associated with a set of labels and the task is to predict the proper label set for the unseen example. Due to the tremendous (exponential) number of possible label sets the task of learning from multi-label examples is rather challenging. Therefore the key to successful multi-label learning is how to effectively exploit correlations between different labels to facilitate the learning process. In this paper we propose to use a Bayesian network structure to efficiently encode the conditional dependencies of the labels as well as the feature set with the feature set as the common parent of all labels. To make it practical we give an approximate yet efficient procedure to find such a network structure. With the help of this network multi-label learning is decomposed into a series of single-label classification problems where a classifier is constructed for each label by incorporating its parental labels as additional features. Label sets of unseen examples are predicted recursively according to the label ordering given by the network. Extensive experiments on a broad range of data sets validate the effectiveness of our approach against other well-established methods.;
Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Regression testing is a crucial part of software development. It checks that software changes do not break existing functionality. An important assumption of regression testing is that test outcomes are deterministic: an unmodified test is expected to either always pass or always fail for the same code under test. Unfortunately in practice some tests often called flaky testsâ€”have non-deterministic outcomes. Such tests undermine the regression testing as they make it difficult to rely on test results. We present the first extensive study of flaky tests. We study in detail a total of 201 commits that likely fix flaky tests in 51 open-source projects. We classify the most common root causes of flaky tests identify approaches that could manifest flaky behavior and describe common strategies that developers use to fix flaky tests. We believe that our insights and implications can help guide future research on the important topic of (avoiding) flaky tests.;
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering;Developers use cryptographic APIs in Android with the intent of securing data such as passwords and personal information on mobile devices. In this paper we ask whether developers use the cryptographic APIs in a fashion that provides typical cryptographic notions of security e.g. IND-CPA security. We develop program analysis techniques to automatically check programs on the Google Play marketplace and find that 10.327 out of 11748 applications that use cryptographic APIs -- 88% overall -- make at least one mistake. These numbers show that applications do not use cryptographic APIs in a fashion that maximizes overall security. We then suggest specific remediations based on our analysis towards improving overall cryptographic security in Android applications.;
Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp Communications Security;We consider applying computer vision to video on cloud-backed mobile devices using Deep Neural Networks (DNNs). The computational demands of DNNs are high enough that without careful resource management such applications strain device battery wireless data and cloud cost budgets. We pose the corresponding resource management problem which we call Approximate Model Scheduling as one of serving a stream of heterogeneous (i.e. solving multiple classification problems) requests under resource constraints. We present the design and implementation of an optimizing compiler and runtime scheduler to address this problem. Going beyond traditional resource allocators we allow each request to be served approximately by systematically trading off DNN classification accuracy for resource use and remotely by reasoning about on-device/cloud execution trade-offs. To inform the resource allocator we characterize how several common DNNs when subjected to state-of-the art optimizations trade off accuracy for resource use such as memory computation and energy. The heterogeneous streaming setting is a novel one for DNN execution and we introduce two new and powerful DNN optimizations that exploit it. Using the challenging continuous mobile vision domain as a case study we show that our techniques yield significant reductions in resource usage and perform effectively over a broad range of operating conditions.;
Proceedings of the 14th Annual International Conference on Mobile Systems Applications and Services;Over the past one and half years we have been using RDMA over commodity Ethernet (RoCEv2) to support some of Microsoft's highly-reliable latency-sensitive services. This paper describes the challenges we encountered during the process and the solutions we devised to address them. In order to scale RoCEv2 beyond VLAN we have designed a DSCP-based priority flow-control (PFC) mechanism to ensure large-scale deployment. We have addressed the safety challenges brought by PFC-induced deadlock (yes it happened!) RDMA transport livelock and the NIC PFC pause frame storm problem. We have also built the monitoring and management systems to make sure RDMA works as expected. Our experiences show that the safety and scalability issues of running RoCEv2 at scale can all be addressed and RDMA can replace TCP for intra data center communications and achieve low latency low CPU overhead and high throughput.;
Proceedings of the 2016 ACM SIGCOMM Conference;We review the empirical research on Free/Libre and Open-Source Software (FLOSS) development and assess the state of the literature. We develop a framework for organizing the literature based on the input-mediator-output-input (IMOI) model from the small groups literature. We present a quantitative summary of articles selected for the review and then discuss findings of this literature categorized into issues pertaining to inputs (e.g. member characteristics technology use and project characteristics) processes (software development practices social processes and firm involvement practices) emergent states (e.g. social states and task-related states) and outputs (e.g. team performance FLOSS implementation and project evolution). Based on this review we suggest topics for future research as well as identify methodological and theoretical issues for future inquiry in this area including issues relating to sampling and the need for more longitudinal studies.;
CoreDet: a compiler and runtime system for deterministic multithreaded execution;The behavior of a multithreaded program does not depend only on its inputs. Scheduling memory reordering timing and low-level hardware effects all introduce nondeterminism in the execution of multithreaded programs. This severely complicates many tasks including debugging testing and automatic replication. In this work we avoid these complications by eliminating their root cause: we develop a compiler and runtime system that runs arbitrary multithreaded C/C++ POSIX Threads programs deterministically.A trivial non-performant approach to providing determinism is simply deterministically serializing execution. Instead we present a compiler and runtime infrastructure that ensures determinism but resorts to serialization rarely for handling interthread communication and synchronization. We develop two basic approaches both of which are largely dynamic with performance improved by some static compiler optimizations. First an ownership-based approach detects interthread communication via an evolving table that tracks ownership of memory regions by threads. Second a buffering approach uses versioned memory and employs a deterministic commit protocol to make changes visible to other threads. While buffering has larger single-threaded overhead than ownership it tends to scale better (serializing less often). A hybrid system sometimes performs and scales better than either approach individually.Our implementation is based on the LLVM compiler infrastructure. It needs neither programmer annotations nor special hardware. Our empirical evaluation uses the PARSEC and SPLASH2 benchmarks and shows that our approach scales comparably to nondeterministic execution.;
Proceedings of the Fifteenth International Conference on Architectural Support for Programming Languages and Operating Systems;We collected file system content data from 857 desktop computers at Microsoft over a span of 4 weeks. We analyzed the data to determine the relative efficacy of data deduplication particularly considering whole-file versus block-level elimination of redundancy. We found that whole-file deduplication achieves about three quarters of the space savings of the most aggressive block-level deduplication for storage of live file systems and 87% of the savings for backup images. We also studied file fragmentation finding that it is not prevalent and updated prior file system metadata studies finding that the distribution of file sizes continues to skew toward very large unstructured files.;
Why people hate your app: making sense of user feedback in a mobile app store;User review is a crucial component of open mobile app markets such as the Google Play Store. How do we automatically summarize millions of user reviews and make sense out of them? Unfortunately beyond simple summaries such as histograms of user ratings there are few analytic tools that can provide insights into user reviews. In this paper we propose Wiscom a system that can analyze tens of millions user ratings and comments in mobile app markets at three different levels of detail. Our system is able to (a) discover inconsistencies in reviews (b) identify reasons why users like or dislike a given app and provide an interactive zoomable view of how users' reviews evolve over time and (c) provide valuable insights into the entire app market identifying users' major concerns and preferences of different types of apps. Results using our techniques are reported on a 32GB dataset consisting of over 13 million user reviews of 171493 Android apps in the Google Play Store. We discuss how the techniques presented herein can be deployed to help a mobile app market operator such as Google as well as individual app developers and end-users.;
Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;Hardware design today bears similarities to software design. Often vendors buy and integrate code acquired from third-party organizations into their designs especially in embedded/system-on-chip designs. Currently there is no way to determine if third-party designs have built-in backdoors that can compromise security after deployment.The key observation we use to approach this problem is that hardware backdoors incorporate logic that is nearly-unused i.e. stealthy. The wires used in stealthy backdoor circuits almost never influence the outputs of those circuits. Typically they do so only when triggered using external inputs from an attacker. In this paper we present FANCI a tool that flags suspicious wires in a design which have the potential to be malicious. FANCI uses scalable approximate boolean functional analysis to detect these wires.Our examination of the TrustHub hardware backdoor benchmark suite shows that FANCI is able to flag all suspicious paths in the benchmarks that are associated with backdoors. Unlike prior work in the area FANCI is not hindered by incomplete test suite coverage and thus is able to operate in practice without false negatives. Furthermore FANCI reports low false positive rates: less than 1% of wires are reported as suspicious in most cases. All TrustHub designs were analyzed in a day or less. We also analyze a backdoor-free out-of-order microprocessor core to demonstrate applicability beyond benchmarks.;
Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp Communications Security;Online social networking sites like MySpace Orkut and Flickr are among the most popular sites on the Web and continue to experience dramatic growth in their user population. The popularity of these sites offers a unique opportunity to study the dynamics of social networks at scale. Having a proper understanding of how online social networks grow can provide insights into the network structure allow predictions of future growth and enable simulation of systems on networks of arbitrary size. However to date most empirical studies have focused on static network snapshots rather than growth dynamics.In this paper we collect and examine detailed growth data from the Flickr online social network focusing on the ways in which new links are formed. Our study makes two contributions. First we collect detailed data covering three months of growth encompassing 950143 new users and over 9.7 million new links and we make this data available to the research community. Second we use a first-principles approach to investigate the link formation process. In short we find that links tend to be created by users who already have many links that users tend to respond to incoming links by creating links back to the source and that users link to other users who are already close in the network.;
Proceedings of the First Workshop on Online Social Networks;This paper provides an overview of important software engineering research issues related to the development of applications that run on mobile devices. Among the topics are development processes tools user interface design application portability quality and security.;
Proceedings of the FSE/SDP Workshop on Future of Software Engineering Research;In this article we survey ambient intelligence (AmI) including its applications some of the technologies it uses and its social and ethical implications. The applications include AmI at home care of the elderly healthcare commerce and business recommender systems museums and tourist scenarios and group decision making. Among technologies we focus on ambient data management and artificial intelligence for example planning learning event-condition-action rules temporal reasoning and agent-oriented technologies. The survey is not intended to be exhaustive but to convey a broad range of applications technologies and technical social and ethical challenges.;
NetKAT: semantic foundations for networks;Recent years have seen growing interest in high-level languages for programming networks. But the design of these languages has been largely ad hoc driven more by the needs of applications and the capabilities of network hardware than by foundational principles. The lack of a semantic foundation has left language designers with little guidance in determining how to incorporate new features and programmers without a means to reason precisely about their code.This paper presents NetKAT a new network programming language that is based on a solid mathematical foundation and comes equipped with a sound and complete equational theory. We describe the design of NetKAT including primitives for filtering modifying and transmitting packets union and sequential composition operators and a Kleene star operator that iterates programs. We show that NetKAT is an instance of a canonical and well-studied mathematical structure called a Kleene algebra with tests (KAT) and prove that its equational theory is sound and complete with respect to its denotational semantics. Finally we present practical applications of the equational theory including syntactic techniques for checking reachability proving non-interference properties that ensure isolation between programs and establishing the correctness of compilation algorithms.;
Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages;Todayâ€™s cloud computing infrastructure requires substantial trust. Cloud users rely on both the providerâ€™s staff and its globally distributed software/hardware platform not to expose any of their private data.We introduce the notion of shielded execution which protects the confidentiality and integrity of a program and its data from the platform on which it runs (i.e. the cloud operatorâ€™s OS VM and firmware). Our prototype Haven is the first system to achieve shielded execution of unmodified legacy applications including SQL Server and Apache on a commodity OS (Windows) and commodity hardware. Haven leverages the hardware protection of Intel SGX to defend against privileged code and physical attacks such as memory probes and also addresses the dual challenges of executing unmodified legacy binaries and protecting them from a malicious host. This work motivated recent changes in the SGX specification.;
Slide rule: making mobile touch screens accessible to blind people using multi-touch interaction techniques;Recent advances in touch screen technology have increased the prevalence of touch screens and have prompted a wave of new touch screen-based devices. However touch screens are still largely inaccessible to blind users who must adopt error-prone compensatory strategies to use them or find accessible alternatives. This inaccessibility is due to interaction techniques that require the user to visually locate objects on the screen. To address this problem we introduce Slide Rule a set of audio-based multi-touch interaction techniques that enable blind users to access touch screen applications. We describe the design of Slide Rule our interaction techniques and a user study in which 10 blind people used Slide Rule and a button-based Pocket PC screen reader. Results show that Slide Rule was significantly faster than the button-based system and was preferred by 7 of 10 users. However users made more errors when using Slide Rule than when using the more familiar button-based system.;
Proceedings of the 10th International ACM SIGACCESS Conference on Computers and Accessibility;We survey recent progress in software model checking.;
Using formal specifications to support testing;Formal methods and testing are two important approaches that assist in the development of high-quality software. While traditionally these approaches have been seen as rivals in recent years a new consensus has developed in which they are seen as complementary. This article reviews the state of the art regarding ways in which the presence of a formal specification can be used to assist testing.;
Knowledge-Defined Networking;The research community has considered in the past the application of Artificial Intelligence (AI) techniques to control and operate networks. A notable example is the Knowledge Plane proposed by D.Clark et al. However such techniques have not been extensively prototyped or deployed in the field yet. In this paper we explore the reasons for the lack of adoption and posit that the rise of two recent paradigms: Software-Defined Networking (SDN) and Network Analytics (NA) will facilitate the adoption of AI techniques in the context of network operation and control. We describe a new paradigm that accommodates and exploits SDN NA and AI and provide use-cases that illustrate its applicability and benefits. We also present simple experimental results that support for some relevant use-cases its feasibility. We refer to this new paradigm as Knowledge-Defined Networking (KDN).;
Heavy-Hitter Detection Entirely in the Data Plane;"Identifying the heavy hitter"" flows or flows with large traffic volumes in the data plane is important for several applications e.g. flow-size aware routing DoS detection and traffic engineering. However measurement in the data plane is constrained by the need for line-rate processing (at 10-100Gb/s) and limited memory in switching hardware. We propose HashPipe a heavy hitter detection algorithm using emerging programmable data planes. HashPipe implements a pipeline of hash tables which retain counters for heavy flows while evicting lighter flows over time. We prototype HashPipe in P4 and evaluate it with packet traces from an ISP backbone link and a data center. On the ISP trace (which contains over 400000 flows) we find that HashPipe identifies 95% of the 300 heaviest flows with less than 80KB of memory.""";
Proceedings of the Symposium on SDN Research;Many multi-core processors employ a large last-level cache (LLC) shared among the multiple cores. Past research has demonstrated that sharing-oblivious cache management policies (e.g. LRU) can lead to poor performance and fairness when the multiple cores compete for the limited LLC capacity. Different memory access patterns can cause cache contention in different ways and various techniques have been proposed to target some of these behaviors. In this work we propose a new cache management approach that combines dynamic insertion and promotion policies to provide the benefits of cache partitioning adaptive insertion and capacity stealing all with a single mechanism. By handling multiple types of memory behaviors our proposed technique outperforms techniques that target only either capacity partitioning or adaptive insertion.;
Proceedings of the 36th Annual International Symposium on Computer Architecture;Although mobile devices are gaining more and more capabilities (i.e. CPU power memory connectivity ...) they still fall short to execute complex rich media and data analysis applications. Offloading to the cloud is not always a solution because of the high WAN latencies especially for applications with real-time constraints such as augmented reality. Therefore the cloud has to be moved closer to the mobile user in the form of cloudlets. Instead of moving a complete virtual machine from the cloud to the cloudlet we propose a more fine grained cloudlet concept that manages applications on a component level. Cloudlets do not have to be fixed infrastructure close to the wireless access point but can be formed in a dynamic way with any device in the LAN network with available resources. We present a cloudlet architecture together with a prototype implementation showing the advantages and capabilities for a mobile real-time augmented reality application.;
Proceedings of the Third ACM Workshop on Mobile Cloud Computing and Services;We present an algorithm and a system for generating input events to exercise smartphone apps. Our approach is based on concolic testing and generates sequences of events automatically and systematically. It alleviates the path-explosion problem by checking a condition on program executions that identifies subsumption between different event sequences. We also describe our implementation of the approach for Android the most popular smartphone app platform and the results of an evaluation that demonstrates its effectiveness on five Android apps.;
Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering;"The past few years have witnessed the great potential of exploiting channel state information retrieved from commodity WiFi devices for respiration monitoring. However existing approaches only work when the target is close to the WiFi transceivers and the performance degrades significantly when the target is far away. On the other hand most home environments only have one WiFi access point and it may not be located in the same room as the target. This sensing range constraint greatly limits the application of the proposed approaches in real life.This paper presents FarSense--the first real-time system that can reliably monitor human respiration when the target is far away from the WiFi transceiver pair. FarSense works well even when one of the transceivers is located in another room moving a big step towards real-life deployment. We propose two novel schemes to achieve this goal: (1) Instead of applying the raw CSI readings of individual antenna for sensing we employ the ratio of CSI readings from two antennas whose noise is mostly canceled out by the division operation to significantly increase the sensing range (2) The division operation further enables us to utilize the phase information which is not usable with one single antenna for sensing. The orthogonal amplitude and phase are elaborately combined to address the blind spots"" issue and further increase the sensing range. Extensive experiments show that FarSense is able to accurately monitor human respiration even when the target is 8 meters away from the transceiver pair increasing the sensing range by more than 100%.1 We believe this is the first system to enable through-wall respiration sensing with commodity WiFi devices and the proposed method could also benefit other sensing applications.""";
Whole-system persistence;"Today's databases and key-value stores commonly keep all their data in main memory. A single server can have over 100 GB of memory and a cluster of such servers can have 10s to 100s of TB. However a storage back end is still required for recovery from failures. Recovery can last for minutes for a single server or hours for a whole cluster causing heavy load on the back end. Non-volatile main memory (NVRAM) technologies can help by allowing near-instantaneous recovery of in-memory state. However today's software does not support this well. Block-based approaches such as persistent buffer caches suffer from data duplication and block transfer overheads. Recently user-level persistent heaps have been shown to have much better performance than these. However they require substantial application modification and still have significant runtime overheads. This paper proposes whole-system persistence (WSP) as an alternative. WSP is aimed at systems where all memory is non-volatile. It transparently recovers an application's entire state making a failure appear as a suspend/resume event. Runtime overheads are eliminated by using flush on fail"": transient state in processor registers and caches is flushed to NVRAM only on failure using the residual energy from the system power supply. Our evaluation shows that this approach has 1.6--13 times better runtime performance than a persistent heap and that flush-on-fail can complete safely within 2--35% of the residual energy window provided by standard power supplies.""";
Proceedings of the Seventeenth International Conference on Architectural Support for Programming Languages and Operating Systems;RAMCloud is a DRAM-based storage system that provides inexpensive durability and availability by recovering quickly after crashes rather than storing replicas in DRAM. RAMCloud scatters backup data across hundreds or thousands of disks and it harnesses hundreds of servers in parallel to reconstruct lost data. The system uses a log-structured approach for all its data in DRAM as well as on disk: this provides high performance both during normal operation and during recovery. RAMCloud employs randomized techniques to manage the system in a scalable and decentralized fashion. In a 60-node cluster RAMCloud recovers 35 GB of data from a failed server in 1.6 seconds. Our measurements suggest that the approach will scale to recover larger memory sizes (64 GB or more) in less time with larger clusters.;
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles;In this article we provide a detailed survey of 3D Morphable Face Models over the 20 years since they were first proposed. The challenges in building and applying these models namely capture modeling image formation and image analysis are still active research topics and we review the state-of-the-art in each of these areas. We also look ahead identifying unsolved challenges proposing directions for future research and highlighting the broad range of current and future applications.;
Adaptive threshold-based approach for energy-efficient consolidation of virtual machines in cloud data centers;The rapid growth in demand for computational power driven by modern service applications combined with the shift to the Cloud computing model have led to the establishment of large-scale virtualized data centers. Such data centers consume enormous amounts of electrical energy resulting in high operating costs and carbon dioxide emissions. Dynamic consolidation of virtual machines (VMs) and switching idle nodes off allow Cloud providers to optimize resource usage and reduce energy consumption. However the obligation of providing high quality of service to customers leads to the necessity in dealing with the energy-performance trade-off. We propose a novel technique for dynamic consolidation of VMs based on adaptive utilization thresholds which ensures a high level of meeting the Service Level Agreements (SLA). We validate the high efficiency of the proposed technique across different kinds of workloads using workload traces from more than a thousand PlanetLab servers.;
Proceedings of the 8th International Workshop on Middleware for Grids Clouds and e-Science;Bias in Web data and use taints the algorithms behind Web-based applications delivering equally biased results.;
The socialbot network: when bots socialize for fame and money;Online Social Networks (OSNs) have become an integral part of today's Web. Politicians celebrities revolutionists and others use OSNs as a podium to deliver their message to millions of active web users. Unfortunately in the wrong hands OSNs can be used to run astroturf campaigns to spread misinformation and propaganda. Such campaigns usually start off by infiltrating a targeted OSN on a large scale. In this paper we evaluate how vulnerable OSNs are to a large-scale infiltration by socialbots: computer programs that control OSN accounts and mimic real users. We adopt a traditional web-based botnet design and built a Socialbot Network (SbN): a group of adaptive socialbots that are orchestrated in a command-and-control fashion. We operated such an SbN on Facebook---a 750 million user OSN---for about 8 weeks. We collected data related to users' behavior in response to a large-scale infiltration where socialbots were used to connect to a large number of Facebook users. Our results show that (1) OSNs such as Facebook can be infiltrated with a success rate of up to 80% (2) depending on users' privacy settings a successful infiltration can result in privacy breaches where even more users' data are exposed when compared to a purely public access and (3) in practice OSN security defenses such as the Facebook Immune System are not effective enough in detecting or stopping a large-scale infiltration as it occurs.;
Proceedings of the 27th Annual Computer Security Applications Conference;"Privacy enhancing technologies like OpenSSL OpenVPN or Tor establish an encrypted tunnel that enables users to hide content and addresses of requested websites from external observers This protection is endangered by local traffic analysis attacks that allow an external passive attacker between the PET system and the user to uncover the identity of the requested sites. However existing proposals for such attacks are not practicable yet.We present a novel method that applies common text mining techniques to the normalised frequency distribution of observable IP packet sizes. Our classifier correctly identifies up to 97% of requests on a sample of 775 sites and over 300000 real-world traffic dumps recorded over a two-month period. It outperforms previously known methods like Jaccard's classifier and Na\{\i""";
Proceedings of the 2009 ACM Workshop on Cloud Computing Security;In this paper we discuss a screening process used in conjunction with a survey administered via Amazon.com's Mechanical Turk. We sought an easily implementable method to disqualify those people who participate but don't take the study tasks seriously. By using two previously pilot tested screening questions we identified 764 of 1962 people who did not answer conscientiously. Young men seem to be most likely to fail the qualification task. Those that are professionals students and non-workers seem to be more likely to take the task seriously than financial workers hourly workers and other workers. Men over 30 and women were more likely to answer seriously.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Open source software is commonly portrayed as a meritocracy where decisions are based solely on their technical merit. However literature on open source suggests a complex social structure underlying the meritocracy. Social work environments such as GitHub make the relationships between users and between users and work artifacts transparent. This transparency enables developers to better use information such as technical value and social connections when making work decisions. We present a study on open source software contribution in GitHub that focuses on the task of evaluating pull requests which are one of the primary methods for contributing code in GitHub. We analyzed the association of various technical and social measures with the likelihood of contribution acceptance. We found that project managers made use of information signaling both good technical contribution practices for a pull request and the strength of the social connection between the submitter and project manager when evaluating pull requests. Pull requests with many comments were much less likely to be accepted moderated by the submitter's prior interaction in the project. Well-established projects were more conservative in accepting pull requests. These findings provide evidence that developers use both technical and social information when evaluating potential contributions to open source software projects.;
Proceedings of the 36th International Conference on Software Engineering;We describe the design and implementation of Walter a key-value store that supports transactions and replicates data across distant sites. A key feature behind Walter is a new property called Parallel Snapshot Isolation (PSI). PSI allows Walter to replicate data asynchronously while providing strong guarantees within each site. PSI precludes write-write conflicts so that developers need not worry about conflict-resolution logic. To prevent write-write conflicts and implement PSI Walter uses two new and simple techniques: preferred sites and counting sets. We use Walter to build a social networking application and port a Twitter-like application.;
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles;The Cypher property graph query language is an evolving language originally designed and implemented as part of the Neo4j graph database and it is currently used by several commercial database products and researchers. We describe Cypher 9 which is the first version of the language governed by the openCypher Implementers Group. We first introduce the language by example and describe its uses in industry. We then provide a formal semantic definition of the core read-query features of Cypher including its variant of the property graph data model and its ASCII Art graph pattern matching mechanism for expressing subgraphs of interest to an application. We compare the features of Cypher to other property graph query languages and describe extensions at an advanced stage of development which will form part of Cypher 10 turning the language into a compositional language which supports graph projections and multiple named graphs.;
Proceedings of the 2018 International Conference on Management of Data;Reproducing bugs is hard. Deterministic replay systems address this problem by providing a high-fidelity replica of an original program run that can be repeatedly executed to zero-in on bugs. Unfortunately existing replay systems for multiprocessor programs fall short. These systems either incur high overheads rely on non-standard multiprocessor hardware or fail to reliably reproduce executions. Their primary stumbling block is data races -- a source of nondeterminism that must be captured if executions are to be faithfully reproduced.In this paper we present ODR--a software-only replay system that reproduces bugs and provides low-overhead multiprocessor recording. The key observation behind ODR is that for debugging purposes a replay system does not need to generate a high-fidelity replica of the original execution. Instead it suffices to produce any execution that exhibits the same outputs as the original. Guided by this observation ODR relaxes its fidelity guarantees to avoid the problem of reproducing data-races altogether. The result is a system that replays real multiprocessor applications such as Apache MySQL and the Java Virtual Machine and provides low record-mode overhead.;
Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles;Motivated by the needs of precise forest inventory and real-time surveillance for ecosystem management in this paper we present GreenOrbs [2] a wireless sensor network system and its application for canopy closure estimates. Both the hardware and software designs of GreenOrbs are tailored for sensing in wild environments without human supervision including a firm weatherproof enclosure of sensor motes and a light-weight mechanism for node state monitoring and data collection. By incorporating a pre-deployment training process as well as a distributed calibration method the estimates of canopy closure stay accurate and consistent against uncertain sensory data and dynamic environments. We have implemented a prototype system of GreenOrbs and carried out multiple rounds of deployments. The evaluation results demonstrate that GreenOrbs outperforms the conventional approaches for canopy closure estimates. Some early experiences are reported in this paper.;
Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems;Do online ads suggestive of arrest records appear more often with searches of black-sounding names than white-sounding names? What is a black-sounding name or white-sounding name anyway? How many more times would an ad have to appear adversely affecting one racial group for it to be considered discrimination? Is online activity so ubiquitous that computer scientists have to think about societal consequences such as structural racism in technology design? If so how is this technology to be built? Letâ€™s take a scientific dive into online ad delivery to find answers.;
Early application identification;The automatic detection of applications associated with network traffic is an essential step for network security and traffic engineering. Unfortunately simple port-based classification methods are not always efficient and systematic analysis of packet payloads is too slow. Most recent research proposals use flow statistics to classify traffic flows once they are finished which limit their applicability for online classification. In this paper we evaluate the feasibility of application identification at the beginning of a TCP connection. Based on an analysis of packet traces collected on eight different networks we find that it is possible to distinguish the behavior of an application from the observation of the size and the direction of the first few packets of the TCP connection. We apply three techniques to cluster TCP connections: K-Means Gaussian Mixture Model and spectral clustering. Resulting clusters are used together with assignment and labeling heuristics to design classifiers. We evaluate these classifiers on different packet traces. Our results show that the first four packets of a TCP connection are sufficient to classify known applications with an accuracy over 90% and to identify new applications as unknown with a probability of 60%.;
Proceedings of the 2006 ACM CoNEXT Conference;IntroductionUsability evaluation is essential to make sure that software products newly released are easy to use efficient and effective to reach goals and satisfactory to users. For example when a software company wants to develop and sell a new product the company needs to evaluate usability of the new product before launching it at a market to avoid the possibility that the new product may contain usability problems which span from cosmetic problems to severe functional problems.Three widely used methods for usability evaluation are Think Aloud (TA) Heuristic Evaluation (HE) and Cognitive Walkthrough (CW). TA method is commonly employed with a lab-based user testing while there are variants of TA methods including thinking out aloud at user's workplace instead of at labs. What we discuss here is the TA method that is combined with a lab-based user testing in which test users use products while simultaneously and continuously thinking out aloud and experimenters record users' behaviors and verbal protocols in the laboratory. HE is a usability inspection method in which a small number of evaluators find usability problems in a user interface design by examining an interface and judging its compliance with well-known usability principles called heuristics. CW is a theory-based method in which evaluators evaluate every step necessary to perform a scenario-based task and look for usability problems that would interfere with learning by exploration. These three methods have their own advantages and disadvantages. For instance TA method provides good qualitative data from a small number of test users but laboratory environment may influence test user's behaviors. HE is a cheap fast and easy-to-use method while it often finds too specific and low-priority usability problems including even not real problems. CW helps find mismatches between users' and designers' conceptualization of a task but it needs extensive knowledge of cognitive psychology and technical details to apply.However even though these advantages and disadvantages show overall characteristics of three major usability evaluation methods we cannot compare them quantitatively and see their efficiency clearly. Because one of reasons why so-called discounted methods such as HE and CW were developed is to save costs of usability evaluation cost-related criteria for comparing usability evaluation are meaningful to usability practitioners as well as usability researchers. One of the most disputable issues related to cost of usability evaluation is sample size. That is how many users or evaluators are needed to achieve a targeted usability evaluation performance for example 80% of overall discovery rate? The sample size of usability evaluation is known to depend on an estimate of problem discovery rate across participants. The overall discovery rate is a common quantitative measure that is used to show the effectiveness of a specific usability evaluation method in most of usability evaluation studies. It is also called overall detection rate or thoroughness measure which is the ratio of 'the sum of unique usability problems detected by all experiment participants' against 'the number of usability problems that exist in the evaluated systems' ranging between 0 and 1. The overall discovery rates were reported more than any other criterion measure in the usability evaluation experiments and also a key component for projecting required sample size for usability evaluation study. Thus how many test users or evaluators participate in the usability evaluation is a critical issue considering its cost-effectiveness.;
Into the wild: studying real user activity patterns to guide power optimizations for mobile architectures;As the market for mobile architectures continues its rapid growth it has become increasingly important to understand and optimize the power consumption of these battery-driven devices. While energy consumption has been heavily explored there is one critical factor that is often overlooked -- the end user. Ultimately the energy consumption of a mobile architecture is defined by user activity. In this paper we study mobile architectures in their natural environment -- in the hands of the end user. Specifically we develop a logger application for Android G1 mobile phones and release the logger into the wild to collect traces of real user activity. We then show how the traces can be used to characterize power consumption and guide the development of power optimizations.We present a regression-based power estimation model that only relies on easily-accessible measurements collected by our logger. The model accurately estimates power consumption and provides insights about the power breakdown among hardware components. We show that energy consumption widely varies depending upon the user. In addition our results show that the screen and the CPU are the two largest power consuming components. We also study patterns in user behavior to derive power optimizations. We observe that majority of the active screen time is dominated by long screen intervals. To reduce the energy consumption during these long intervals we implement a scheme that slowly reduces the screen brightness over time. Our results reveal that the users are happier with a system that slowly reduces the screen brightness rather than abruptly doing so even though the two schemes settle at the same brightness. Similarly we experiment with a scheme that slowly reduces the CPU frequency over time. We evaluate these optimizations with a user study and demonstrate 10.6% total system energy savings with a minimal impact on user satisfaction.;
Proceedings of the 42nd Annual IEEE/ACM International Symposium on Microarchitecture;Datacenter networks employ multi-rooted topologies (e.g. Leaf-Spine Fat-Tree) to provide large bisection bandwidth. These topologies use a large degree of multipathing and need a data-plane load-balancing mechanism to effectively utilize their bisection bandwidth. The canonical load-balancing mechanism is equal-cost multi-path routing (ECMP) which spreads traffic uniformly across multiple paths. Motivated by ECMP's shortcomings congestion-aware load-balancing techniques such as CONGA have been developed. These techniques have two limitations. First because switch memory is limited they can only maintain a small amount of congestion-tracking state at the edge switches and do not scale to large topologies. Second because they are implemented in custom hardware they cannot be modified in the field.This paper presents HULA a data-plane load-balancing algorithm that overcomes both limitations. First instead of having the leaf switches track congestion on all paths to a destination each HULA switch tracks congestion for the best path to a destination through a neighboring switch. Second we design HULA for emerging programmable switches and program it in P4 to demonstrate that HULA could be run on such programmable chipsets without requiring custom hardware. We evaluate HULA extensively in simulation showing that it outperforms a scalable extension to CONGA in average flow completion time (1.6 x at 50% load 3 x at 90% load).;
Proceedings of the Symposium on SDN Research;Effective visual features are essential for computational aesthetic quality rating systems. Existing methods used machine learning and statistical modeling techniques on handcrafted features or generic image descriptors. A recently-published large-scale dataset the AVA dataset has further empowered machine learning based approaches. We present the RAPID (RAting PIctorial aesthetics using Deep learning) system which adopts a novel deep neural network approach to enable automatic feature learning. The central idea is to incorporate heterogeneous inputs generated from the image which include a global view and a local view and to unify the feature learning and classifier training using a double-column deep convolutional neural network. In addition we utilize the style attributes of images to help improve the aesthetic quality categorization accuracy. Experimental results show that our approach significantly outperforms the state of the art on the AVA dataset.;
Proceedings of the 22nd ACM International Conference on Multimedia;"Frigyes Karinthy in his 1929 short story L\'{a""";
Proceedings of the 4th Annual ACM Web Science Conference;The past decade has seen the great potential of applying deep neural network (DNN) based software to safety-critical scenarios such as autonomous driving. Similar to traditional software DNNs could exhibit incorrect behaviors caused by hidden defects leading to severe accidents and losses. In this paper we propose DeepHunter a coverage-guided fuzz testing framework for detecting potential defects of general-purpose DNNs. To this end we first propose a metamorphic mutation strategy to generate new semantically preserved tests and leverage multiple extensible coverage criteria as feedback to guide the test generation. We further propose a seed selection strategy that combines both diversity-based and recency-based seed selection. We implement and incorporate 5 existing testing criteria and 4 seed selection strategies in DeepHunter. Large-scale experiments demonstrate that (1) our metamorphic mutation strategy is useful to generate new valid tests with the same semantics as the original seed by up to a 98% validity ratio (2) the diversity-based seed selection generally weighs more than recency-based seed selection in boosting the coverage and in detecting defects (3) DeepHunter outperforms the state of the arts by coverage as well as the quantity and diversity of defects identified (4) guided by corner-region based criteria DeepHunter is useful to capture defects during the DNN quantization for platform migration.;
Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis;The field of quantum algorithms is vibrant. Still there is currently a lack of programming languages for describing quantum computation on a practical scale i.e. not just at the level of toy problems. We address this issue by introducing Quipper a scalable expressive functional higher-order quantum programming language. Quipper has been used to program a diverse set of non-trivial quantum algorithms and can generate quantum gate representations using trillions of gates. It is geared towards a model of computation that uses a classical computer to control a quantum device but is not dependent on any particular model of quantum hardware. Quipper has proven effective and easy to use and opens the door towards using formal methods to analyze quantum algorithms.;
Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation;Many important applications trigger bulk bitwise operations i.e. bitwise operations on large bit vectors. In fact recent works design techniques that exploit fast bulk bitwise operations to accelerate databases (bitmap indices BitWeaving) and web search (BitFunnel). Unfortunately in existing architectures the throughput of bulk bitwise operations is limited by the memory bandwidth available to the processing unit (e.g. CPU GPU FPGA processing-in-memory).To overcome this bottleneck we propose Ambit an Accelerator-in-Memory for bulk bitwise operations. Unlike prior works Ambit exploits the analog operation of DRAM technology to perform bitwise operations completely inside DRAM thereby exploiting the full internal DRAM bandwidth. Ambit consists of two components. First simultaneous activation of three DRAM rows that share the same set of sense amplifiers enables the system to perform bitwise AND and OR operations. Second with modest changes to the sense amplifier the system can use the inverters present inside the sense amplifier to perform bitwise NOT operations. With these two components Ambit can perform any bulk bitwise operation efficiently inside DRAM. Ambit largely exploits existing DRAM structure and hence incurs low cost on top of commodity DRAM designs (1% of DRAM chip area). Importantly Ambit uses the modern DRAM interface without any changes and therefore it can be directly plugged onto the memory bus.Our extensive circuit simulations show that Ambit works as expected even in the presence of significant process variation. Averaged across seven bulk bitwise operations Ambit improves performance by 32X and reduces energy consumption by 35X compared to state-of-the-art systems. When integrated with Hybrid Memory Cube (HMC) a 3D-stacked DRAM with a logic layer Ambit improves performance of bulk bitwise operations by 9.7X compared to processing in the logic layer of the HMC. Ambit improves the performance of three real-world data-intensive applications 1) database bitmap indices 2) BitWeaving a technique to accelerate database scans and 3) bit-vector-based implementation of sets by 3X-7X compared to a state-of-the-art baseline using SIMD optimizations. We describe four other applications that can benefit from Ambit including a recent technique proposed to speed up web search. We believe that large performance and energy improvements provided by Ambit can enable other applications to use bulk bitwise operations.;
Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture;Nowadays power consumption of data centers has huge impacts on environments. Researchers are seeking to find effective solutions to make data centers reduce power consumption while keep the desired quality of service or service level objectives. Virtual Machine (VM) technology has been widely applied in data center environments due to its seminal features including reliability flexibility and the ease of management. We present the GreenCloud architecture which aims to reduce data center power consumption while guarantee the performance from users' perspective. GreenCloud architecture enables comprehensive online-monitoring live virtual machine migration and VM placement optimization. To verify the efficiency and effectiveness of the proposed architecture we take an online real-time game Tremulous as a VM application. Evaluation results show that we can save up to 27% of the energy when applying GreenCloud architecture.;
Proceedings of the 6th International Conference Industry Session on Autonomic Computing and Communications Industry Session;With the rapid prevalence of smart mobile devices and the dramatic proliferation of location-based social networks (LBSNs) location-based recommendation has become an important means to help people discover attractive and interesting points of interest (POIs). However the extreme sparsity of user-POI matrix and cold-start issue create severe challenges causing CF-based methods to degrade significantly in their recommendation performance. Moreover location-based recommendation requires spatiotemporal context awareness and dynamic tracking of the user's latest preferences in a real-time manner.To address these challenges we stand on recent advances in embedding learning techniques and propose a generic graph-based embedding model called GE in this paper. GE jointly captures the sequential effect geographical influence temporal cyclic effect and semantic effect in a unified way by embedding the four corresponding relational graphs (POI-POI POI-Region POI-Time and POI-Word)into a shared low dimensional space. Then to support the real-time recommendation we develop a novel time-decay method to dynamically compute the user's latest preferences based on the embedding of his/her checked-in POIs learnt in the latent space. We conduct extensive experiments to evaluate the performance of our model on two real large-scale datasets and the experimental results show its superiority over other competitors especially in recommending cold-start POIs. Besides we study the contribution of each factor to improve location-based recommendation and find that both sequential effect and temporal cyclic effect play more important roles than geographical influence and semantic effect.;
Proceedings of the 25th ACM International on Conference on Information and Knowledge Management;The shift from single to multiple core architectures means that programmers must write concurrent multithreaded programs in order to increase application performance. Unfortunately multithreaded applications are susceptible to numerous errors including deadlocks race conditions atomicity violations and order violations. These errors are notoriously difficult for programmers to debug.This paper presents Grace a software-only runtime system that eliminates concurrency errors for a class of multithreaded programs: those based on fork-join parallelism. By turning threads into processes leveraging virtual memory protection and imposing a sequential commit protocol Grace provides programmers with the appearance of deterministic sequential execution while taking advantage of available processing cores to run code concurrently and efficiently. Experimental results demonstrate Grace's effectiveness: with modest code changes across a suite of computationally-intensive benchmarks (1-16 lines) Grace can achieve high scalability and performance while preventing concurrency errors.;
Proceedings of the 24th ACM SIGPLAN Conference on Object Oriented Programming Systems Languages and Applications;In this paper we give an overview of the HDF5 technology suite and some of its applications. We discuss the HDF5 data model the HDF5 software architecture and some of its performance enhancing capabilities.;
Proceedings of the EDBT/ICDT 2011 Workshop on Array Databases;Rather than try to capture everything system design should focus on the psychological basis of human memory.;
Coflow: a networking abstraction for cluster applications;Cluster computing applications -- frameworks like MapReduce and user-facing applications like search platforms -- have application-level requirements and higher-level abstractions to express them. However there exists no networking abstraction that can take advantage of the rich semantics readily available from these data parallel applications.We propose coflow a networking abstraction to express the communication requirements of prevalent data parallel programming paradigms. Coflows make it easier for the applications to convey their communication semantics to the network which in turn enables the network to better optimize common communication patterns.;
Proceedings of the 11th ACM Workshop on Hot Topics in Networks;Stock prediction aims to predict the future trends of a stock in order to help investors make good investment decisions. Traditional solutions for stock prediction are based on time-series models. With the recent success of deep neural networks in modeling sequential data deep learning has become a promising choice for stock prediction.However most existing deep learning solutions are not optimized toward the target of investment i.e. selecting the best stock with the highest expected revenue. Specifically they typically formulate stock prediction as a classification (to predict stock trends) or a regression problem (to predict stock prices). More importantly they largely treat the stocks as independent of each other. The valuable signal in the rich relations between stocks (or companies) such as two stocks are in the same sector and two companies have a supplier-customer relation is not considered.In this work we contribute a new deep learning solution named Relational Stock Ranking (RSR) for stock prediction. Our RSR method advances existing solutions in two major aspects: (1) tailoring the deep learning models for stock ranking and (2) capturing the stock relations in a time-sensitive manner. The key novelty of our work is the proposal of a new component in neural network modeling named Temporal Graph Convolution which jointly models the temporal evolution and relation network of stocks. To validate our method we perform back-testing on the historical data of two stock markets NYSE and NASDAQ. Extensive experiments demonstrate the superiority of our RSR method. It outperforms state-of-the-art stock prediction solutions achieving an average return ratio of 98% and 71% on NYSE and NASDAQ respectively.;
Rise of the expert amateur: DIY projects communities and cultures;This paper presents a large-scale study of Do-It-Yourself (DIY) communities cultures and projects. We focus on the adoption and appropriation of human-computer interaction and collaboration technologies and their role in motivating and sustaining communities of builders crafters and makers. Our survey of over 2600 individuals across a range of DIY communities (Instructables Dorkbot Craftster Ravelry Etsy and Adafruit) reveals a unique set of values emphasizing open sharing learning and creativity over profit and social capital. We derive design implications to embed these values into other everyday practices and hope that our work serves to engage CHI practitioners with DIY expert amateurs.;
Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries;Multi-tenant cloud which usually leases resources in the form of virtual machines has been commercially available for years. Unfortunately with the adoption of commodity virtualized infrastructures software stacks in typical multi-tenant clouds are non-trivially large and complex and thus are prone to compromise or abuse from adversaries including the cloud operators which may lead to leakage of security-sensitive data.In this paper we propose a transparent backward-compatible approach that protects the privacy and integrity of customers' virtual machines on commodity virtualized infrastructures even facing a total compromise of the virtual machine monitor (VMM) and the management VM. The key of our approach is the separation of the resource management from security protection in the virtualization layer. A tiny security monitor is introduced underneath the commodity VMM using nested virtualization and provides protection to the hosted VMs. As a result our approach allows virtualization software (e.g. VMM management VM and tools) to handle complex tasks of managing leased VMs for the cloud without breaking security of users' data inside the VMs.We have implemented a prototype by leveraging commercially-available hardware support for virtualization. The prototype system called CloudVisor comprises only 5.5K LOCs and supports the Xen VMM with multiple Linux and Windows as the guest OSes. Performance evaluation shows that CloudVisor incurs moderate slow-down for I/O intensive applications and very small slowdown for other applications.;
Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles;Different studies show that programmers are more interested in finding definitions of functions and their uses than variables statements or arbitrary code fragments [30 29 31]. Therefore programmers require support in finding relevant functions and determining how those functions are used. Unfortunately existing code search engines do not provide enough of this support to developers thus reducing the effectiveness of code reuse.We provide this support to programmers in a code search system called Portfolio that retrieves and visualizes relevant functions and their usages. We have built Portfolio using a combination of models that address surfing behavior of programmer and sharing Related concepts among functions. We conducted an experiment with 49 professional programmers to compare Portfolio to Google Code Search and Koders using a standard methodology. The results show with strong statistical significance that users find more relevant functions with higher precision with Portfolio than with Google Code Search and Koders.;
Proceedings of the 33rd International Conference on Software Engineering;The growth of mobile phone users has lead to a dramatic increasing of SMS spam messages. In practice fighting mobile phone spam is difficult by several factors including the lower rate of SMS that has allowed many users and service providers to ignore the issue and the limited availability of mobile phone spam-filtering software. On the other hand in academic settings a major handicap is the scarcity of public SMS spam datasets that are sorely needed for validation and comparison of different classifiers. Moreover as SMS messages are fairly short content-based spam filters may have their performance degraded. In this paper we offer a new real public and non-encoded SMS spam collection that is the largest one as far as we know. Moreover we compare the performance achieved by several established machine learning methods. The results indicate that Support Vector Machine outperforms other evaluated classifiers and hence it can be used as a good baseline for further comparison.;
Proceedings of the 11th ACM Symposium on Document Engineering;Accurate fine-grained online energy estimation and accounting of mobile devices such as smartphones is of critical importance to understanding and debugging the energy consumption of mobile applications. We observe that state-of-the-art utilization-based power modeling correlates the (actual) utilization of a hardware component with its power state and hence is insufficient in capturing several power behavior not directly related to the component utilization in modern smartphones. Such behavior arise due to various low level power optimizations programmed in the device drivers. We propose a new system-call-based power modeling approach which gracefully encompasses both utilization-based and non-utilization-based power behavior. We present the detailed design of such a power modeling scheme and its implementation on Android and Windows Mobile. Our experimental results using a diverse set of applications confirm that the new model significantly improves the fine-grained as well as whole-application energy consumption accuracy. We further demonstrate fine-grained energy accounting enabled by such a fined-grained power model via amanually implemented eprof the energy counterpart of the classic gprof tool for profiling application energy drain.;
Proceedings of the Sixth Conference on Computer Systems;Traditional data structure designs whether lock-based or lock-free provide parallelism via fine grained synchronization among threads.We introduce a new synchronization paradigm based on coarse locking which we call flat combining. The cost of synchronization in flat combining is so low that having a single thread holding a lock perform the combined access requests of all others delivers up to a certain non-negligible concurrency level better performance than the most effective parallel finely synchronized implementations. We use flat-combining to devise among other structures new linearizable stack queue and priority queue algorithms that greatly outperform all prior algorithms.;
Proceedings of the Twenty-Second Annual ACM Symposium on Parallelism in Algorithms and Architectures;Networks are complex and prone to bugs. Existing tools that check configuration files and data-plane state operate offline at timescales of seconds to hours and cannot detect or prevent bugs as they arise.Is it possible to check network-wide invariants in real time as the network state evolves? The key challenge here is to achieve extremely low latency during the checks so that network performance is not affected. In this paper we present a preliminary design VeriFlow which suggests that this goal is achievable. VeriFlow is a layer between a software-defined networking controller and network devices that checks for network-wide invariant violations dynamically as each forwarding rule is inserted. Based on an implementation using a Mininet OpenFlow network and Route Views trace data we find that VeriFlow can perform rigorous checking within hundreds of microseconds per rule insertion.;
Proceedings of the First Workshop on Hot Topics in Software Defined Networks;Finding a good join order is crucial for query performance. In this paper we introduce the Join Order Benchmark (JOB) and experimentally revisit the main components in the classic query optimizer architecture using a complex real-world data set and realistic multi-join queries. We investigate the quality of industrial-strength cardinality estimators and find that all estimators routinely produce large errors. We further show that while estimates are essential for finding a good join order query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model we find that it has much less influence on query performance than the cardinality estimates. Finally we investigate plan enumeration techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the sub-optimal cardinality estimates.;
Privacy wizards for social networking sites;"Privacy is an enormous problem in online social networking sites. While sites such as Facebook allow users fine-grained control over who can see their profiles it is difficult for average users to specify this kind of detailed policy.In this paper we propose a template for the design of a social networking privacy wizard. The intuition for the design comes from the observation that real users conceive their privacy preferences (which friends should be able to see which information) based on an implicit set of rules. Thus with a limited amount of user input it is usually possible to build a machine learning model that concisely describes a particular user's preferences and then use this model to configure the user's privacy settings automatically.As an instance of this general framework we have built a wizard based on an active learning paradigm called uncertainty sampling. The wizard iteratively asks the user to assign privacy labels"" to selected (""informative"") friends and it uses this input to construct a classifier which can in turn be used to automatically assign privileges to the rest of the user's (unlabeled) friends.To evaluate our approach we collected detailed privacy preference data from 45 real Facebook users. Our study revealed two important things. First real users tend to conceive their privacy preferences in terms of communities which can easily be extracted from a social network graph using existing techniques. Second our active learning wizard using communities as features is able to recommend high-accuracy privacy settings using less user input than existing policy-specification tools.""";
Proceedings of the 19th International Conference on World Wide Web;The hypervolume indicator is a set measure used in evolutionary multiobjective optimization to evaluate the performance of search algorithms and to guide the search. Multiobjective evolutionary algorithms using the hypervolume indicator transform multiobjective problems into single objective ones by searching for a finite set of solutions maximizing the corresponding hypervolume indicator. In this paper we theoretically investigate how those optimal Î¼--distributions-finite sets of Î¼ solutions maximizing the hypervolume indicator-are spread over the Pareto front of biobjective problems. This problem is of high importance for practical applications as these sets characterize the preferences that the hypervolume indicator encodes i.e. which types of Pareto set approximations are favored.In particular we tackle the question whether the hypervolume indicator is biased towards certain regions. For linear fronts we prove that the distribution is uniform with constant distance between two consecutive points. For general fronts where it is presumably impossible to characterize exactly the distribution we derive a limit result when the number of points grows to infinity proving that the empirical density of points converges to a density proportional to the square root of the negative of the derivative of the front. Our analyses show that it is not the shape of the Pareto front but only its slope that determines how the points that maximize the hypervolume indicator are distributed. Experimental results illustrate that the limit density is a good approximation of the empirical density for small Î¼. Furthermore we analyze the issue of where to place the reference point of the indicator such that the extremes of the front can be found if the hypervolume indicator is optimized. We derive an explicit lower bound (possibly infinite) ensuring the presence of the extremes in the optimal distribution. This result contradicts the common belief that the reference point has to be chosen close to the nadir point: for certain types of fronts we show that no finite reference point allows to have the extremes in the optimal Î¼-distribution.;
Proceedings of the Tenth ACM SIGEVO Workshop on Foundations of Genetic Algorithms;"Twitter is one of the biggest platforms where massive instant messages (i.e. tweets) are published every day. Users tend to express their real feelings freely in Twitter which makes it an ideal source for capturing the opinions towards various interesting topics such as brands products or celebrities etc. Naturally people may anticipate an approach to receiving the common sentiment tendency towards these topics directly rather than through reading the huge amount of tweets about them. On the other side Hashtags starting with a symbol #"" ahead of keywords or phrases are widely used in tweets as coarse-grained topics. In this paper instead of presenting the sentiment polarity of each tweet relevant to the topic we focus our study on hashtag-level sentiment classification. This task aims to automatically generate the overall sentiment polarity for a given hashtag in a certain time period which markedly differs from the conventional sentence-level and document-level sentiment analysis. Our investigation illustrates that three types of information is useful to address the task including (1) sentiment polarity of tweets containing the hashtag (2) hashtags co-occurrence relationship and (3) the literal meaning of hashtags. Consequently in order to incorporate the first two types of information into a classification framework where hashtags can be classified collectively we propose a novel graph model and investigate three approximate collective classification algorithms for inference. Going one step further we show that the performance can be remarkably improved using an enhanced boosting classification setting in which we employ the literal meaning of hashtags as semi-supervised information. Experimental results on a real-life data set consisting of 29195 tweets and 2181 hashtags show the effectiveness of the proposed model and algorithms.""";
Proceedings of the 20th ACM International Conference on Information and Knowledge Management;Newly emerging location-based and event-based social network services provide us with a new platform to understand users' preferences based on their activity history. A user can only visit a limited number of venues/events and most of them are within a limited distance range so the user-item matrix is very sparse which creates a big challenge for traditional collaborative filtering-based recommender systems. The problem becomes more challenging when people travel to a new city where they have no activity history.In this paper we propose LCARS a location-content-aware recommender system that offers a particular user a set of venues (e.g. restaurants) or events (e.g. concerts and exhibitions) by giving consideration to both personal interest and local preference. This recommender system can facilitate people's travel not only near the area in which they live but also in a city that is new to them. Specifically LCARS consists of two components: offline modeling and online recommendation. The offline modeling part called LCA-LDA is designed to learn the interest of each individual user and the local preference of each individual city by capturing item co-occurrence patterns and exploiting item contents. The online recommendation part automatically combines the learnt interest of the querying user and the local preference of the querying city to produce the top-k recommendations. To speed up this online process a scalable query processing technique is developed by extending the classic Threshold Algorithm (TA). We evaluate the performance of our recommender system on two large-scale real data sets DoubanEvent and Foursquare. The results show the superiority of LCARS in recommending spatial items for users especially when traveling to new cities in terms of both effectiveness and efficiency.;
Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining;This paper introduces a low cost fast and accessible technology to support the rapid prototyping of functional electronic devices. Central to this approach of 'instant inkjet circuits' is the ability to print highly conductive traces and patterns onto flexible substrates such as paper and plastic films cheaply and quickly. In addition to providing an alternative to breadboarding and conventional printed circuits we demonstrate how this technique readily supports large area sensors and high frequency applications such as antennas. Unlike existing methods for printing conductive patterns conductivity emerges within a few seconds without the need for special equipment. We demonstrate that this technique is feasible using commodity inkjet printers and commercially available ink for an initial investment of around US$300. Having presented this exciting new technology we explain the tools and techniques we have found useful for the first time. Our main research contribution is to characterize the performance of instant inkjet circuits and illustrate a range of possibilities that are enabled by way of several example applications which we have built. We believe that this technology will be of immediate appeal to researchers in the ubiquitous computing domain since it supports the fabrication of a variety of functional electronic device prototypes.;
Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing;We present a machine learning technique for driving 3D facial animation by audio input in real time and with low latency. Our deep neural network learns a mapping from input waveforms to the 3D vertex coordinates of a face model and simultaneously discovers a compact latent code that disambiguates the variations in facial expression that cannot be explained by the audio alone. During inference the latent code can be used as an intuitive control for the emotional state of the face puppet.We train our network with 3--5 minutes of high-quality animation data obtained using traditional vision-based performance capture methods. Even though our primary goal is to model the speaking style of a single actor our model yields reasonable results even when driven with audio from other speakers with different gender accent or language as we demonstrate with a user study. The results are applicable to in-game dialogue low-cost localization virtual reality avatars and telepresence.;
Networking named content;Current network use is dominated by content distribution and retrieval yet current networking protocols are designed for conversations between hosts. Accessing content and services requires mapping from the what that users care about to the network's where. We present Content-Centric Networking (CCN) which uses content chunks as a primitive---decoupling location from identity security and access and retrieving chunks of content by name. Using new approaches to routing named content derived from IP CCN simultaneously achieves scalability security and performance. We describe our implementation of the architecture's basic features and demonstrate its performance and resilience with secure file downloads and VoIP calls.;
An analysis of patch plausibility and correctness for generate-and-validate patch generation systems;We analyze reported patches for three existing generate-and- validate patch generation systems (GenProg RSRepair and AE). The basic principle behind generate-and-validate systems is to accept only plausible patches that produce correct outputs for all inputs in the validation test suite. Because of errors in the patch evaluation infrastructure the majority of the reported patches are not plausible â€” they do not produce correct outputs even for the inputs in the validation test suite. The overwhelming majority of the reported patches are not correct and are equivalent to a single modification that simply deletes functionality. Observed negative effects include the introduction of security vulnerabilities and the elimination of desirable functionality. We also present Kali a generate-and-validate patch generation system that only deletes functionality. Working with a simpler and more effectively focused search space Kali generates at least as many correct patches as prior GenProg RSRepair and AE systems. Kali also generates at least as many patches that produce correct outputs for the inputs in the validation test suite as the three prior systems. We also discuss the patches produced by ClearView a generate-and-validate binary hot patching system that lever- ages learned invariants to produce patches that enable systems to survive otherwise fatal defects and security attacks. Our analysis indicates that ClearView successfully patches 9 of the 10 security vulnerabilities used to evaluate the system. At least 4 of these patches are correct.;
Proceedings of the 2015 International Symposium on Software Testing and Analysis;Social networking sites (SNS) are only as good as the content their users share. Therefore designers of SNS seek to improve the overall user experience by encouraging members to contribute more content. However user motivations for contribution in SNS are not well understood. This is particularly true for newcomers who may not recognize the value of contribution. Using server log data from approximately 140000 newcomers in Facebook we predict long-term sharing based on the experiences the newcomers have in their first two weeks. We test four mechanisms: social learning singling out feedback and distribution.In particular we find support for social learning: newcomers who see their friends contributing go on to share more content themselves. For newcomers who are initially inclined to contribute receiving feedback and having a wide audience are also predictors of increased sharing. On the other hand singling out appears to affect only those newcomers who are not initially inclined to share. The paper concludes with design implications for motivating newcomer sharing in online communities.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Resource constrained mobile devices need to leverage computation on nearby servers to run responsive applications that recognize objects people or gestures from real-time video. The two key questions that impact performance are what computation to offload and how to structure the parallelism across the mobile device and server. To answer these questions we develop and evaluate three interactive perceptual applications. We find that offloading and parallelism choices should be dynamic even for a given application as performance depends on scene complexity as well as environmental factors such as the network and device capabilities. To this end we develop Odessa a novel lightweight runtime that automatically and adaptively makes offloading and parallelism decisions for mobile interactive perception applications. Our evaluation shows that the incremental greedy strategy of Odessa converges to an operating point that is close to an ideal offline partitioning. It provides more than a 3x improvement in application performance over partitioning suggested by domain experts. Odessa works well across a variety of execution environments and is agile to changes in the network device and application inputs.;
Proceedings of the 9th International Conference on Mobile Systems Applications and Services;Indoor human tracking is fundamental to many real-world applications such as security surveillance behavioral analysis and elderly care. Previous solutions usually require dedicated device being carried by the human target which is inconvenient or even infeasible in scenarios such as elderly care and break-ins. However compared with device-based tracking device-free tracking is particularly challenging because the much weaker reflection signals are employed for tracking. The problem becomes even more difficult with commodity Wi-Fi devices which have limited number of antennas small bandwidth size and severe hardware noise.In this work we propose IndoTrack a device-free indoor human tracking system that utilizes only commodity Wi-Fi devices. IndoTrack is composed of two innovative methods: (1) Doppler-MUSIC is able to extract accurate Doppler velocity information from noisy Wi-Fi Channel State Information (CSI) samples and (2) Doppler-AoA is able to determine the absolute trajectory of the target by jointly estimating target velocity and location via probabilistic co-modeling of spatial-temporal Doppler and AoA information. Extensive experiments demonstrate that IndoTrack can achieve a 35cm median error in human trajectory estimation outperforming the state-of-the-art systems and provide accurate location and velocity information for indoor human mobility and behavioral analysis.;
A case for adapting channel width in wireless networks;We study a fundamental yet under-explored facet in wireless communication -- the width of the spectrum over which transmitters spread their signals or the channel width. Through detailed measurements in controlled and live environments and using only commodity 802.11 hardware we first quantify the impact of channel width on throughput range and power consumption. Taken together our findings make a strong case for wireless systems that adapt channel width. Such adaptation brings unique benefits. For instance when the throughput required is low moving to a narrower channel increases range and reduces power consumption in fixed-width systems these two quantities are always in conflict. We then present a channel width adaptation algorithm called SampleWidth for the base case of two communicating nodes. This algorithm is based on a simple search process that builds on top of existing techniques for adapting modulation. Per specified policy it can maximize throughput or minimize power consumption. Evaluation using a prototype implementation shows that SampleWidth correctly identities the optimal width under a range of scenarios. In our experiments with mobility it increases throughput by more than 60% compared to the best fixed-width configuration.;
Proceedings of the ACM SIGCOMM 2008 Conference on Data Communication;The damage personal attacks cause to online discourse motivates many platforms to try to curb the phenomenon. However understanding the prevalence and impact of personal attacks in online platforms at scale remains surprisingly difficult. The contribution of this paper is to develop and illustrate a method that combines crowdsourcing and machine learning to analyze personal attacks at scale. We show an evaluation method for a classifier in terms of the aggregated number of crowd-workers it can approximate. We apply our methodology to English Wikipedia generating a corpus of over 100k high quality human-labeled comments and 63M machine-labeled ones from a classifier that is as good as the aggregate of 3 crowd-workers as measured by the area under the ROC curve and Spearman correlation. Using this corpus of machine-labeled scores our methodology allows us to explore some of the open questions about the nature of online personal attacks. This reveals that the majority of personal attacks on Wikipedia are not the result of a few malicious users nor primarily the consequence of allowing anonymous contributions from unregistered users.;
Proceedings of the 26th International Conference on World Wide Web;Smartphones and tablets with rich graphical user interfaces (GUI) are becoming increasingly popular. Hundreds of thousands of specialized applications called apps are available for such mobile platforms. Manual testing is the most popular technique for testing graphical user interfaces of such apps. Manual testing is often tedious and error-prone. In this paper we propose an automated technique called Swift-Hand for generating sequences of test inputs for Android apps. The technique uses machine learning to learn a model of the app during testing uses the learned model to generate user inputs that visit unexplored states of the app and uses the execution of the app on the generated inputs to refine the model. A key feature of the testing algorithm is that it avoids restarting the app which is a significantly more expensive operation than executing the app on a sequence of inputs. An important insight behind our testing algorithm is that we do not need to learn a precise model of an app which is often computationally intensive if our goal is to simply guide test execution into unexplored parts of the state space. We have implemented our testing algorithm in a publicly available tool for Android apps written in Java. Our experimental results show that we can achieve significantly better coverage than traditional random testing and L*-based testing in a given time budget. Our algorithm also reaches peak coverage faster than both random and L*-based testing.;
Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp Applications;Android phones often carry personal information attracting malicious developers to embed code in Android applications to steal sensitive data. With known techniques in the literature one may easily determine if sensitive data is being transmitted out of an Android phone. However transmission of sensitive data in itself does not necessarily indicate privacy leakage a better indicator may be whether the transmission is by user intention or not. When transmission is not intended by the user it is more likely a privacy leakage. The problem is how to determine if transmission is user intended. As a first solution in this space we present a new analysis framework called AppIntent. For each data transmission AppIntent can efficiently provide a sequence of GUI manipulations corresponding to the sequence of events that lead to the data transmission thus helping an analyst to determine if the data transmission is user intended or not. The basic idea is to use symbolic execution to generate the aforementioned event sequence but straightforward symbolic execution proves to be too time-consuming to be practical. A major innovation in AppIntent is to leverage the unique Android execution model to reduce the search space without sacrificing code coverage. We also present an evaluation of AppIntent with a set of 750 malicious apps as well as 1000 top free apps from Google Play. The results show that AppIntent can effectively help separate the apps that truly leak user privacy from those that do not.;
Proceedings of the 2013 ACM SIGSAC Conference on Computer &amp Communications Security;The increasing popularity of cloud storage services has lead companies that handle critical data to think about using these services for their storage needs. Medical record databases large biomedical datasets historical information about power systems and financial data are some examples of critical data that could be moved to the cloud. However the reliability and security of data stored in the cloud still remain major concerns. In this work we present DepSky a system that improves the availability integrity and confidentiality of information stored in the cloud through the encryption encoding and replication of the data on diverse clouds that form a cloud-of-clouds. We deployed our system using four commercial clouds and used PlanetLab to run clients accessing the service from different countries. We observed that our protocols improved the perceived availability and in most cases the access latency when compared with cloud providers individually. Moreover the monetary costs of using DepSky in this scenario is at most twice the cost of using a single cloud which is optimal and seems to be a reasonable cost given the benefits.;
SCMFS: a file system for storage class memory;This paper considers the problem of how to implement a file system on Storage Class Memory (SCM) that is directly connected to the memory bus byte addressable and is also non-volatile. In this paper we propose a new file system called SCMFS which is implemented on the virtual address space. In SCMFS we utilize the existing memory management module in the operating system to do the block management and keep the space always contiguous for each file. The simplicity of SCMFS not only makes it easy to implement but also improves the performance. We have implemented a prototype in Linux and evaluated its performance through multiple benchmarks.;
Proceedings of 2011 International Conference for High Performance Computing Networking Storage and Analysis;"Software Defined Networking envisions smart centralized controllers governing the forwarding behavior of dumb low-cost switches. But are dumb"" switches an actual strategic choice or (at least to some extent) are they a consequence of the lack of viable alternatives to OpenFlow as programmatic data plane forwarding interface? Indeed some level of (programmable) control logic in the switches might be beneficial to offload logically centralized controllers (de facto complex distributed systems) from decisions just based on local states (versus network-wide knowledge) which could be handled at wire speed inside the device itself. Also it would reduce the amount of flow processing tasks currently delegated to specialized middleboxes. The underlying challenge is: can we devise a stateful data plane programming abstraction (versus the stateless OpenFlow match/action table) which still entails high performance and remains consistent with the vendors' preference for closed platforms? We posit that a promising answer revolves around the usage of extended finite state machines as an extension (super-set) of the OpenFlow match/action abstraction. We concretely turn our proposed abstraction into an actual table-based API and perhaps surprisingly we show how it can be supported by (mostly) reusing core primitives already implemented in OpenFlow devices.""";
Heuristic evaluation for games: usability principles for video game design;Most video games require constant interaction so game designers must pay careful attention to usability issues. However there are few formal methods for evaluating the usability of game interfaces. In this paper we introduce a new set of heuristics that can be used to carry out usability inspections of video games. The heuristics were developed to help identify usability problems in both early and functional game prototypes. We developed the heuristics by analyzing PC game reviews from a popular gaming website and the review set covered 108 different games and included 18 from each of 6 major game genres. We analyzed the reviews and identified twelve common classes of usability problems seen in games. We developed ten usability heuristics based on the problem categories and they describe how common game usability problems can be avoided. A preliminary evaluation of the heuristics suggests that they help identify game-specific usability problems that can easily be overlooked otherwise.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Machine learning (ML) is becoming a commodity. Numerous ML frameworks and services are available to data holders who are not ML experts but want to train predictive models on their data. It is important that ML models trained on sensitive inputs (e.g. personal images or documents) not leak too much information about the training data.We consider a malicious ML provider who supplies model-training code to the data holder does emph{not;
Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security;More and more web users keep up with newest information through information streams such as the popular micro-blogging website Twitter. In this paper we studied content recommendation on Twitter to better direct user attention. In a modular approach we explored three separate dimensions in designing such a recommender: content sources topic interest models for users and social voting. We implemented 12 recommendation engines in the design space we formulated and deployed them to a recommender service on the web to gather feedback from real Twitter users. The best performing algorithm improved the percentage of interesting content to 72% from a baseline of 33%. We conclude this work by discussing the implications of our recommender design and how our design can generalize to other information streams.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Autopilot systems are typically composed of an â€œinner loopâ€ providing stability and control whereas an â€œouter loopâ€ is responsible for mission-level objectives such as way-point navigation. Autopilot systems for unmanned aerial vehicles are predominately implemented using Proportional-Integral-Derivative&nbsp(PID) control systems which have demonstrated exceptional performance in stable environments. However more sophisticated control is required to operate in unpredictable and harsh environments. Intelligent flight control systems is an active area of research addressing limitations of PID control most recently through the use of reinforcement learning&nbsp(RL) which has had success in other applications such as robotics. Yet previous work has focused primarily on using RL at the mission-level controller. In this work we investigate the performance and accuracy of the inner control loop providing attitude control when using intelligent flight control systems trained with state-of-the-art RL algorithmsâ€”Deep Deterministic Policy Gradient Trust Region Policy Optimization and Proximal Policy Optimization. To investigate these unknowns we first developed an open source high-fidelity simulation environment to train a flight controller attitude control of a quadrotor through RL. We then used our environment to compare their performance to that of a PID controller to identify if using RL is appropriate in high-precision time-critical flight control.;
The design and implementation of typed scheme;When scripts in untyped languages grow into large programs maintaining them becomes difficult. A lack of types in typical scripting languages means that programmers must (re)discover critical pieces of design information every time they wish to change a program. This analysis step both slows down the maintenance process and may even introduce mistakes due to the violation of undiscovered invariants.This paper presents Typed Scheme an explicitly typed extension of an untyped scripting language. Its type system is based on the novel notion of occurrence typing which we formalize and mechanically prove sound. The implementation of Typed Scheme additionally borrows elements from a range of approaches including recursive types true unions and subtyping plus polymorphism combined with a modicum of local inference. Initial experiments with the implementation suggest that Typed Scheme naturally accommodates the programming style of the underlying scripting language at least for the first few thousand lines of ported code.;
Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages;Digital immersion is moving into public space. Interactive screens and public displays are deployed in urban environments malls and shop windows. Inner city areas airports train stations and stadiums are experiencing a transformation from traditional to digital displays enabling new forms of multimedia presentation and new user experiences. Imagine a walkway with digital displays that allows a user to immerse herself in her favorite content while moving through public space. In this paper we discuss the fundamentals for creating exciting public displays and multimedia experiences enabling new forms of engagement with digital content. Interaction in public space and with public displays can be categorized in phases each having specific requirements. Attracting engaging and motivating the user are central design issues that are addressed in this paper. We provide a comprehensive analysis of the design space explaining mental models and interaction modalities and we conclude a taxonomy for interactive public display from this analysis. Our analysis and the taxonomy are grounded in a large number of research projects art installations and experience. With our contribution we aim at providing a comprehensive guide for designers and developers of interactive multimedia on public displays.;
Proceedings of the 18th ACM International Conference on Multimedia;Home heating is a major factor in worldwide energy use. Our system PreHeat aims to more efficiently heat homes by using occupancy sensing and occupancy prediction to automatically control home heating. We deployed PreHeat in five homes three in the US and two in the UK. In UK homes we controlled heating on a per-room basis to enable further energy savings. We compared PreHeat's prediction algorithm with a static program over an average 61 days per house alternating days between these conditions and measuring actual gas consumption and occupancy. In UK homes PreHeat both saved gas and reduced MissTime (the time that the house was occupied but not warm). In US homes PreHeat decreased MissTime by a factor of 6-12 while consuming a similar amount of gas. In summary PreHeat enables more efficient heating while removing the need for users to program thermostat schedules.;
Proceedings of the 13th International Conference on Ubiquitous Computing;Memristor crossbars are circuits capable of performing analog matrix-vector multiplications overcoming the fundamental energy efficiency limitations of digital logic. They have been shown to be effective in special-purpose accelerators for a limited set of neural network applications. We present the Programmable Ultra-efficient Memristor-based Accelerator (PUMA) which enhances memristor crossbars with general purpose execution units to enable the acceleration of a wide variety of Machine Learning (ML) inference workloads. PUMA's microarchitecture techniques exposed through a specialized Instruction Set Architecture (ISA) retain the efficiency of in-memory computing and analog circuitry without compromising programmability. We also present the PUMA compiler which translates high-level code to PUMA ISA. The compiler partitions the computational graph and optimizes instruction scheduling and register allocation to generate code for large and complex workloads to run on thousands of spatial cores. We have developed a detailed architecture simulator that incorporates the functionality timing and power models of PUMA's components to evaluate performance and energy consumption. A PUMA accelerator running at 1 GHz can reach area and power efficiency of 577 GOPS/s/mm 2  and 837~GOPS/s/W respectively. Our evaluation of diverse ML applications from image recognition machine translation and language modelling (5M-800M synapses) shows that PUMA achieves up to 2446\texttimes{;
Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems;Nested paging is a hardware solution for alleviating the software memory management overhead imposed by system virtualization. Nested paging complements existing page walk hardware to form a two-dimensional (2D) page walk which reduces the need for hypervisor intervention in guest page table management. However the extra dimension also increases the maximum number of architecturally-required page table references.This paper presents an in-depth examination of the 2D page table walk overhead and options for decreasing it. These options include using the AMD Opteron processor's page walk cache to exploit the strong reuse of page entry references. For a mix of server and SPEC benchmarks the presented results show a 15%-38% improvement in guest performance by extending the existing page walk cache to also store the nested dimension of the 2D page walk. Caching nested page table translations and skipping multiple page entry references produce an additional 3%-7% improvement.Much of the remaining 2D page walk overhead is due to low-locality nested page entry references which result in additional memory hierarchy misses. By using large pages the hypervisor can eliminate many of these long-latency accesses and further improve the guest performance by 3%-22%.;
Proceedings of the 13th International Conference on Architectural Support for Programming Languages and Operating Systems;Post-task ratings of difficulty in a usability test have the potential to provide diagnostic information and be an additional measure of user satisfaction. But the ratings need to be reliable as well as easy to use for both respondents and researchers. Three one-question rating types were compared in a study with 26 participants who attempted the same five tasks with two software applications. The types were a Likert scale a Usability Magnitude Estimation (UME) judgment and a Subjective Mental Effort Question (SMEQ). All three types could distinguish between the applications with 26 participants but the Likert and SMEQ types were more sensitive with small sample sizes. Both the Likert and SMEQ types were easy to learn and quick to execute. The online version of the SMEQ question was highly correlated with other measures and had equal sensitivity to the Likert question type.;
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;Personal cloud storage services are gaining popularity. With a rush of providers to enter the market and an increasing offer of cheap storage space it is to be expected that cloud storage will soon generate a high amount of Internet traffic. Very little is known about the architecture and the performance of such systems and the workload they have to face. This understanding is essential for designing efficient cloud storage systems and predicting their impact on the network.This paper presents a characterization of Dropbox the leading solution in personal cloud storage in our datasets. By means of passive measurements we analyze data from four vantage points in Europe collected during 42 consecutive days. Our contributions are threefold: Firstly we are the first to study Dropbox which we show to be the most widely-used cloud storage system already accounting for a volume equivalent to around one third of the YouTube traffic at campus networks on some days. Secondly we characterize the workload users in different environments generate to the system highlighting how this reflects on network traffic. Lastly our results show possible performance bottlenecks caused by both the current system architecture and the storage protocol. This is exacerbated for users connected far from storage data-centers.All measurements used in our analyses are publicly available in anonymized form at the SimpleWeb trace repository: http://traces.simpleweb.org/dropbox/;
Proceedings of the 2012 Internet Measurement Conference;Often software systems are developed by organizations consisting of many teams of individuals working together. Brooks states in the Mythical Man Month book that product quality is strongly affected by organization structure. Unfortunately there has been little empirical evidence to date to substantiate this assertion. In this paper we present a metric scheme to quantify organizational complexity in relation to the product development process to identify if the metrics impact failure-proneness. In our case study the organizational metrics when applied to data from Windows Vista were statistically significant predictors of failure-proneness. The precision and recall measures for identifying failure-prone binaries using the organizational metrics was significantly higher than using traditional metrics like churn complexity coverage dependencies and pre-release bug measures that have been used to date to predict failure-proneness. Our results provide empirical evidence that the organizational metrics are related to and are effective predictors of failure-proneness.;
Proceedings of the 30th International Conference on Software Engineering;"Drawing inspiration from several previous projects we present an ownership-record-free software transactional memory (STM) system that combines extremely low overhead with unusually clean semantics. While unlikely to scale to hundreds of active threads this NOrec"" system offers many appealing features: very low fast-path latency--as low as any system we know of that admits concurrent updates publication and privatization safety livelock freedom a small constant amount of global metadata and full compatibility with existing data structure layouts no false conflicts due to hash collisions compatibility with both managed and unmanaged languages and both static and dynamic compilation and easy acccommodation of closed nesting inevitable (irrevocable) transactions and starvation avoidance mechanisms. To the best of our knowledge no extant STM system combines this set of features.While transactional memory for processors with hundreds of cores is likely to require hardware support software implementations will be required for backward compatibility with current and near-future processors with 2--64 cores as well as for fall-back in future machines when hardware resources are exhausted. Our experience suggests that NOrec may be an ideal candidate for such a software system. We also observe that it has considerable appeal for use within the operating system and in systems that require both closed nesting and publication safety.""";
Introduction to the computing surveys' electronic symposium on object-oriented application frameworks;As class schedules become more sensitive to the needs of non-traditional students flexible environments for managing student coursework are becoming more and more important. We describe a system developed at the University of Louisiana at Monroe to provide a secure working environment both for students developing projects and for instructors evaluating projects. The system's core feature is a software tool for submitting projects which manages the transition between these environments in a secure validated manner. We show how the system addresses many curricular and institutional goals and how the system is managed. Finally we identify several unexpected benefits and applications for the system.;
Using summarization for automatic briefing generation;We describe a system which automatically generates multimedia briefings from high-level outlines. The system uses summarization in content selection and creation and in helping form a coherent narrative for the briefing. The approach does not require a domain knowledge base.;
Proceedings of the 2000 NAACL-ANLP Workshop on Automatic Summarization;Much of the historical and current summarization literature has been technologycentered with the questions posed and answered having implications for technology development. Though commercial summarization products have appeared in the market place and developers continue to explore new summarization areas few papers have been user-centered examining summarization technology in-use. In this paper we show how applied work and the knowledge gleaned about technology in-use can temper theoretical considerations and motivate as well as direct development likely to result in higher return on investment.;
Proceedings of the 2000 NAACL-ANLP Workshop on Automatic Summarization;This paper describes a framework for multi-document summarization which combines three premises: coherent themes can be identified reliably highly representative themes running across subsets of the document collection can function as multi-document summary surrogates and effective end-use of such themes should be facilitated by a visualization environment which clarifies the relationship between themes and documents. We present algorithms that formalize our framework describe an implementation and demonstrate a prototype system and interface.;
Proceedings of the 2000 NAACL-ANLP Workshop on Automatic Summarization;"This paper will describe a way to organize the salient objects their attributes and relationships between the objects in a given domain. This organization allows us to assign an information value to each collection and to the domain as a whole which corresponds to the number of things to talk about"" in the domain. This number gives a measure of semantic complexity that is it will correspond to the number of objects attributes and relationships in the domain but not to the level of syntactic diversity allowed when conveying these meanings.Defining a measure of semantic complexity for a dialog system domain will give an insight towards making a complexity measurement standard. With such a standard natural language programmers can measure the feasibility of making a natural language interface compare different language processors' ability to handle more and more complex domains and quantify the abilities of the current state of the art in natural language processors.""";
NAACL-ANLP 2000 Workshop: Syntactic and Semantic Complexity in Natural Language Processing Systems;We describe a method of text summarization that produces indicative-informative abstracts for technical papers. The abstracts are generated by a process of conceptual identification topic extraction and re-generation. We have carried out an evaluation to assess indicativeness and text acceptability relying on human judgment. The results so far indicate good performance in both tasks when compared with other summarization technologies.;
Proceedings of the 2000 NAACL-ANLP Workshop on Automatic Summarization;We propose a method for dealing with semantic complexities occurring in information retrieval systems on the basis of linguistic observations. Our method follows from an analysis indicating that long runs of content words appear in a stopped document cluster and our observation that these long runs predominately originate from the prepositional phrase and subject complement positions and as such may be useful predictors of semantic coherence. From this linguistic basis we test three statistical hypotheses over a small collection of documents from different genre. By coordinating thesaurus semantic categories (SEMCATs) of the long run words to the semantic categories of paragraphs we conclude that for paragraphs containing both long runs and short runs the SEMCAT weight of long runs of content words is a strong predictor of the semantic coherence of the paragraph.;
NAACL-ANLP 2000 Workshop: Syntactic and Semantic Complexity in Natural Language Processing Systems;We describe an architecture for spoken dialogue interfaces to semi-autonomous systems that transforms speech signals through successive representations of linguistic dialogue and domain knowledge. Each step produces an output and a meta-output describing the transformation with an executable program in a simple scripting language as the final result. The output/meta-output distinction permits perspicuous treatment of diverse tasks such as resolving pronouns correcting user misconceptions and optimizing scripts.;
Proceedings of the ANLP-NAACL 2000 Workshop on Conversational Systems;This paper proposes an end-to-end process analysis template with replicable measures to evaluate the filtering performance of a Scan-OCR-MT system. Preliminary results across three language-specific FALCon systems show that with one exception the derived measures consistently yield the same performance ranking: Haitian Creole at the low end Arabic in the middle and Spanish at the high end.;
ANLP-NAACL 2000 Workshop: Embedded Machine Translation Systems;A growing trend in Machine Translation (MT) is to view MT as an embedded part of an overall process instead of an end result itself. For the last four years we have fielded (primarily) Commercial-Off-The-Shelf (COTS) MT systems in an operational process. MT has been used to facilitate cross-language information retrieval (IR) topic detection and other wide-scoped scenarios. These uses caused a fundamental shift in our views about MT -- everything from user interface to system evaluation to the basic system structures. This paper presents our lessons learned in developing an MT service for a wide range of user needs.;
ANLP-NAACL 2000 Workshop: Embedded Machine Translation Systems;This paper accompanies a demo of the GoDiS system. Work on this system was reported at IJCAI-99 (Bohlin et al. 1999). GoDiS is a prototype dialogue system for information-seeking dialogue capable of accommodating questions and tasks to enable the user to present information in any desired order without explicitly naming the dialogue task. GoDiS is implemented using the TRINDIKIT software package which enables implementation of these behaviours in a compact and natural way.;
Proceedings of the ANLP-NAACL 2000 Workshop on Conversational Systems;"The importance of machine translation (MT) in the stream of text-handling processes has become readily apparent in many current production settings as well as in research programs such as the Translingual Information Detection Extraction and Summarization (TIDES) program. The MT Proficiency Scale project has developed a means of baselining the inherent tolerance"" that a text-handling task has for raw MT output and thus how good the output must be in order to be of use to that task. This method allows for a prediction of how useful a particular system can be in a text-handling process stream whether in integrated MT-embedded processes or less integrated user-intensive processes.""";
ANLP-NAACL 2000 Workshop: Embedded Machine Translation Systems;Stochastic finite-state models are efficiently learnable from data effective for decoding and are associated with a calculus for composing models which allows for tight integration of constraints from various levels of language processing. In this paper we present a method for stochastic finite-state machine translation that is trained automatically from pairs of source and target utterances. We use this method to develop models for English-Japanese and Japanese-English translation. We have embedded the Japanese-English translation system in a call routing task of unconstrained speech utterances. We evaluate the efficacy of the translation system in the context of this application.;
ANLP-NAACL 2000 Workshop: Embedded Machine Translation Systems;We describe robustness techniques used in the CommandTalk system at the recognition level the parsing level and the dialogue level and how these were influenced by the lack of domain data. We used interviews with subject matter experts (SME's) to develop a single grammar for recognition understanding and generation thus eliminating the need for a robust parser. We broadened the coverage of the recognition grammar by allowing word insertions and deletions and we implemented clarification and correction subdialogues to increase robustness at the dialogue level. We discuss the applicability of these techniques to other domains.;
Proceedings of the ANLP-NAACL 2000 Workshop on Conversational Systems;In this paper we propose to adapt parallelizing transformations more specifically reduction parallelizations to the actual reference pattern executed by a loop i.e. to the particular input data and dynamic phase of a program. More precisely we will show how after validating a reduction at run-time (when this is not possible at compile time) we can dynamically characterize its reference pattern and choose the most appropriate method for parallelizing it. For this purpose we develop a library of parallel reduction algorithms including both previously known and novel schemes which includes algorithms specialized for different classes of access behavior. In particular each algorithm in our library has identified strengths related to specific reference pattern characteristics which are matched at run-time with measured characteristics of the actual reference pattern. The matching of algorithm to reference pattern is performed using a decision-tree based selection scheme. The contribution of this work consists in new optimizations for reduction parallelization and in the introduction of a new approach to the optimization of irregular applications: Characteristic based customization.;
ACM International Conference on Supercomputing 25th Anniversary Volume;We present an approach for synthesizing transformations to enhance locality in imperfectly-nested loops. The key idea is to embed the iteration space of every statement in a loop nest into a special iteration space called the product space. The product space can be viewed as a perfectly-nested loop nest so embedding generalizes techniques like code sinking and loop fusion that are used in ad hoc ways in current compilers to produce perfectly-nested loops from imperfectly-nested ones. In contrast to these ad hoc techniques however our embeddings are chosen carefully to enhance locality. The product space is then transformed further to enhance locality after which fully permutable loops are tiled and code is generated. We evaluate the effectiveness of this approach for dense numerical linear algebra benchmarks relaxation codes and the tomcatv code from the SPEC benchmarks.;
ACM International Conference on Supercomputing 25th Anniversary Volume;The rapid advancements of networking technology have boosted potential bandwidth to the point that the cabling is no longer the bottleneck. Rather the bottlenecks lie at the crossing points the nodes of the network where data traffic is intercepted or forwarded. As a result there has been tremendous interest in speeding those nodes making the equipment run faster by means of specialized chips to handle data trafficking. The Network Processor is the blanket name thrown over such chips in their varied forms. To date no performance data exist to aid in the decision of what processor architecture to use in next generation network processor. Our goal is to remedy this situation. In this study we characterize both the application workloads that network processors need to support as well as emerging applications that we anticipate may be supported in the future. Then we consider the performance of three sample benchmarks drawn from these workloads on several state-of-the-art processor architectures including: an aggressive out-of-order speculative super-scalar processor a fine-grained multithreaded processor a single chip multiprocessor and a simultaneous multithreaded processor (SMT). The network interface environment is simulated in detail and our results indicate that SMT is the architecture best suited to this environment.;
ACM International Conference on Supercomputing 25th Anniversary Volume;"This paper proposes an easy and simple method for constructing a super-structure on the Web which provides current Web contents with new value and new means of use. The super-structure is based on external annotations to Web documents. We have developed a system for any user to annotate any element of any Web document with additional information. We have also developed a proxy that transcodes requested contents by considering annotations assigned to them. In this paper we classify annotations into three categories. One is linguistic annotation which helps the transcoder understand the semantic structure of textual elements. The second is commentary annotation which helps the transcoder manipulate non-textual elements such as images and sounds. The third is multimedia annotation which is a combination of the above two types. All types of annotation are described using XML and correspondence between annotations and document elements is defined using URLs and XPaths. We call the entire process semantic transcoding"" because we deal with the deep semantic content of documents with annotations. The current semantic transcoding process mainly handles text and video summarization language translation and speech synthesis of documents including images.""";
Proceedings of the COLING-2000 Workshop on Semantic Annotation and Intelligent Content;This paper describes the semantic annotations we are performing on the CallHome Japanese corpus of spontaneous unscripted telephone conversations (LDC 1996). Our annotations include (i) semantic classes for all nouns and verbs (ii) verb senses for all main verbs and (iii) relations between main verbs and their complements in the same utterance. Our semantic tagset is taken from NTT's Goi-Taikei semantic lexicon and ontology (Ikehara et al. 1997). A pilot study demonstrates that the verb sense tagging can be efficiently performed by native Japanese speakers using computer-generated HTML forms and that good inter-annotator reliability can be obtained in the right conditions.;
Proceedings of the COLING-2000 Workshop on Semantic Annotation and Intelligent Content;In general a program is composed of smaller program segments using composition conditional constructs or loop constructs. We present a theory which enables us to algebraically define and compute the composition of conditional expressions. The conditional expressions are represented using tabular notation. The formal definition of the composition allows us to compute the close form representation of the composition of tabular expressions. The presented approach is based on a many sorted algebra containing information preserving composition. This formal definition of composition is then â€œliftedâ€ to an extended algebra containing tabular expressions. The presented theory provides very compact algorithms and proofs.;
Program Algebra for Component Code;The jump instruction is considered essential for an adequate theoretical understanding of imperative sequential programming. Using atomic actions and tests as a basis we outline an algebra of programs denoted PGA which captures the crux of sequential programming. PGA provides an ontology for programs rather than a semantics. Out of a multitude of conceivable semantic views on PGA we single out a behaviour extraction operator which assigns to each program a behaviour. The meaning of the constants of PGA is explained in terms of the extracted behaviour. Using PGA a small hierarchy of program notations is developed. Projection semantics is proposed as a tool for the description of program semantics.;
Composing and Refining Dense Temporal Logic Specifications;A dense temporal logic development method for the specification refinement composition and verification of reactive systems is introduced. A reactive system is specified by a pair consisting of a machine and a condition that indicate the valid computations of this machine. Compositionality is achieved by indicating whether each step is an environment step a system step or a communication step. Refinement can be expressed straightforwardly in the logic because the stutter problem is elegantly solved by using the dense structure of the logic. Compositionality enables us to break refinement between complex systems into refinement between small and simple systems. The latter can then be verified by existing proof rules for refinement which are reformulated in our formalism.;
Class Refinement as Semantics of Correct Object Substitutability;Subtype polymorphism based on syntactic conformance of objects' methods and used for substituting subtype objects for supertype objects is a characteristic feature of the object-oriented programming style. While certainly very useful typechecking of syntactic conformance of subtype objects to supertype objects is insufficient to guarantee correctness of object substitutability. In addition the behaviour of subtype objects must be constrained to achieve correctness. In class-based systems classes specify the behaviour of the objects they instantiate. In this paper we define the class refinement relation which captures the semantic constraints that must be imposed on classes to guarantee correctness of substitutability in all clients of the objects these classes instantiate. Clients of class instances are modelled as programs making an iterative choice over invocation of class methods and we formally prove that when a class Câ€² refines a class C substituting instances of Câ€² for instances of C is refinement for the clients.;
Natural Semantics-Directed Generation of Compilers and Abstract Machines;In this paper we present the motivation theory and transformations of our semantics-directed compiler generator. The main novelty of our generator is that it generates compilers and abstract machines. The execution times of the abstract machine programs produced by our generated compiler compare well to those of target programs produced by compilers generated by other semantics-directed generators. The generated specifications of compilers and abstract machines are suitable as a starting point for handwriting compilers and abstract machines. Our generator is fully automated and its core transformations are proved correct.;
ADL: An Activity Description Language for Real-Time Networks;This paper introduces and motivates ADL a new formal notation for the specification of the temporal and functional behaviour of concurrent processes. ADL is tailored to be directly compatible with the DORIS design method. It combines a graphical Activity State-Machine (ASM) notation and a model-based Activity Functional Behaviour (AFB) notation. The abstract syntax and static and dynamic semantics for the ASM notation are given the dynamic semantics being given proof-theoretically in many-sorted logic extended with the RTL â€˜occurrenceâ€™ relation Î˜ and the ERTL â€˜holdingâ€™ relation Î¦. ADL is used to specify a small network and proofs are given of its timeliness and safety properties.;
Comparing corpora using frequency profiling;This paper describes a method of comparing corpora which uses frequency profiling. The method can be used to discover key words in the corpora which differentiate one corpus from another. Using annotated corpora it can be applied to discover key grammatical or word-sense categories. This can be used as a quick way in to find the differences between the corpora and is shown to have applications in the study of social differentiation in the use of English vocabulary profiling of learner English and document analysis in the software engineering process.;
Proceedings of the Workshop on Comparing Corpora;WordSmith Tools (Scott 1998) offers a program for comparing corpora known as KeyWords. KeyWords compares a word list extracted from what has been called 'the study corpus' (the corpus which the researcher is interested in describing) with a word list made from a reference corpus. The only requirement for a word list to be accepted as reference corpus by the software is that must be larger than the study corpus. one of the most pressing questions with respect to using KeyWords seems to be what would be the ideal size of a reference corpus. The aim of this paper is thus to propose answers to this question. Five English corpora were compared to reference corpora of various sizes (varying from two to 100 times larger than the study corpus). The results indicate that a reference corpus that is five times as large as the study corpus yielded a larger number of keywords than a smaller reference corpus. Corpora larger than five times the size of the study corpus yielded similar amounts of keywords. The implication is that a larger reference corpus is not always better than a smaller one for WordSmith Tools Keywords analysis while a reference corpus that is less than five times the size of the study corpus may not be reliable. There seems to be no need for using extremely large reference corpora given that the number of keywords yielded do not seem to change by using corpora larger than five times the size of the study corpus.;
Proceedings of the Workshop on Comparing Corpora;Despite being widely regarded as a gloss on first-order logic and set theory Z has not been found to be very supportive of proof. This paper attempts to distinguish between the different philosophies of proof in Z. It discusses some of the issues which must be addressed in creating a proof technology for Z namely schemas undefinedness and what kind of logic to use.;
Data Abstraction Techniques in the Validation of CSP-OZ Specifications;CSP-OZ is an integrated formal method which combines the state-oriented specification language Object-Z with the process algebra CSP thereby allowing a description of static as well as dynamic aspects of a system. Checking correctness of CSP-OZ specifications can be done via a translation into (FDR-)CSP on which automatic verification can be performed with the FDR model checker if the state space of the resulting CSP process is not too large to be processed. This paper investigates how data abstraction techniques can be used to bring a translated specification within range of automatic verification.;
csp2B: A Practical Approach to Combining CSP and B;This paper describes the tool csp2B which provides a means of combining CSP-like descriptions with standard B specifications. The notation of CSP provides a convenient way of describing the order in which the operations of a B machine may occur. The function of the tool is to convert CSP-like specifications into standard machine-readable B specifications which means that they may be animated and appropriate proof obligations may be generated. Use of csp2B means that abstract specifications and refinements may be specified purely using CSP or using a combination of CSP and B. The translation is justified in terms of an operational semantics.;
Abstraction and Testing in CSP;Restricted views of process behaviour result in a form of abstraction which is useful in the construction of specifications involving fault-tolerance and atomicity. This paper presents an operational characterisation of abstraction for refusable and non-refusable events in terms of testing. This view is a generalisation of standard notions of testing and is given a new denotational characterisation encapsulated within the CSP denotational semantics. It informs reinforces and extends the traditional denotational approach to abstraction.;
Representational Reasoning and Verification;Formal approaches to the design of interactive systems rely on reasoning about properties of the system at a very high level of abstraction. Specifications to support such an approach typically provide little scope for reasoning about presentations and the representation of information in the presentation. In contrast psychological theories such as distributed cognition place a strong emphasis on the role of representations and their perception by the user in the cognitive process. However the post-hoc techniques for the observation and analysis of existing systems which have developed out of the theory do not help us in addressing such issues at the design stage. Mn this paper we show how a formalisation can be used to investigate the representational aspects of an interface. Our goal is to provide a framework to help identify and resolve potential problems with the representation of information and to support understanding of representational issues in design. We present a model for linking properties at the abstract and perceptual levels and illustrate its use in a case study of a ight deck instrument. There is a widespread consensus that proper tool support is a prerequisite for the adoption of formal techniques but the use of such tools can have a profound effect on the process itself. In order to explore this issue we apply a higher-order logic theorem prover to the analysis.;
Modelling and Validation: AUTOFOCUS and Quest;We describe the graphical description techniques their underlaying semantics and the validation techniques that have been applied to the FM99 example furthermore we sketch the model and discuss the validation results we have obtained. AUTOFOCUS is the modelling tool and the Quest environment connects the model to a broad spectrum of validation tools including model checkers (SMV SATO) theorem provers (VSE) and test tools (CTE). The original contribution further publications and AUTOFOCUS can be downloaded from http://autofocus.in.tum.de.;
The Cash-Point (ATM) â€˜Problemâ€™;This paper provides a description and summary of the solutions submitted to a competition in formal specification which was held during FM'99 in Toulouse September 1999.;
Testing Conformance to a Quasi-Non-Deterministic Stream X-Machine;Stream X-machines have been used in order to specify a range of systems. One of the strengths of this approach is that under certain well-defined conditions it is possible to produce a finite test that is guaranteed to determine the correctness of the implementation under test (IUT). Initially only deterministic stream X-machines were considered in the literature. This is largely because the standard test algorithm relies on the stream X-machine being deterministic.More recently the problem of testing to determine whether the IUT is equivalent to a non-deterministic stream X-machine specification has been tackled. Since non-determinism can be important for specifications this is an extremely useful extension. In many cases however we wish to test for a weaker notion of correctness called conformance. This paper considers a particular form of non-determinism within stream X-machines that will be called quasi-non-determinism. It then investigates the generation of tests that are guaranteed to determine whether the IUT conforms to a quasi-non-deterministic stream X-machine specification. The test generation algorithm given is a generalisation of that used for testing from a deterministic stream X-machine.;
What are X-Machines?;X-machines were introduced by S. Eilenberg in 1974 ([Eil74]) as a mathematical framework for examining the relationships between languages and automata. The X-machine definition provided a very general concept that captured in a simple and elegant way a wide variety of existing models and their computational behaviour. Thus finite state machines pushdown automata and Turing machines all provided different examples of X-machines obtained by varying some of the components of the X-machine's definition.;
Data Refinement of Remote Procedures;Recently the action systems formalism for parallel and distributed systems has been extended with the procedure mechanism. This gives us a very general framework for describing different communication paradigms for action systems e.g. remote procedure calls. Action systems come with a design methodology based on the refinement calculus. Data refinement is a powerful technique for refining action systems. In this paper we will develop a theory and proof rules for the refinement of action systems that communicate via remote procedures based on the data refinement approach. The proof rules we develop are compositional so that modular refinement of action systems is supported. As an example we will especially study the atomicity refinement of actions. This is an important refinement strategy as it potentially increases the degree of parallelism in an action system.;
Modelling and Verifying of a â€˜Cash-Point Serviceâ€™ Using MOBY/PLC;MOBY/PLC is a graphical design tool for PLC-Automata a special class of hierarchical real-time automata suitable for the description of distributed real-time systems that are implementable on a widely used hardware platform so-called Programmable logic controllers (PLCs). In the full paper we sketch the modelling language in use and some features of MOBY/PLC like several validation methods and code generation. We employ this tool suite to deal with the benchmark case study (â€˜cash-point serviceâ€™).;
Encoding Decoding and Data Refinement;Data refinement is the systematic replacement of a data structure with another one in program development. Data refinement between program statements can on an abstract level be described as a commutativity property where the abstraction relationship between the data structures involved is represented by an abstract statement (a decoding). We generalise the traditional notion of data refinement by defining an encoding operator that describes the least (most abstract) data refinement with respect to a given abstraction. We investigate the categorical and algebraic properties of encoding and describe a number of special cases which include traditional notions of data refinement. The dual operator of encoding is decoding which we investigate and give an intuitive interpretation to. Finally we show a number of applications of encoding and decoding.;
Interfaces for Refining Recursion and Procedures;This paper presents novel definitions of interfaced recursion blocks interfaced procedures and interfaced recursive procedures for the Refinement Calculus. These definitions allow step-wise refinement rules to be formally stated and proved for these constructs. An interface is associated with a (recursive) call by preceding the body of the implementation by an assertion statement which says that the interface refines to the implementation. An interface will typically be a specification statement but in principle can be any command. The theory and rules presented in this paper have been mechanised in the theorem prover Isabelle/ZF.;
Algebraic Models of Correctness for Microprocessors;We present a method of describing microprocessors at different levels of temporal and data abstraction and consider pipelined and superscalar processors. We model microprocessors using iterated maps defined by equations which evolve a system from an initial state by the iterative application of a next-state function. Levels of timing abstraction are related by temporal abstraction maps called retimings. We state correctness conditions for microprogrammed pipelined and superscalar processors. We introduce one-step theorems that permit verification of correctness conditions to be considerably simplified under well-defined conditions. We extend the one-step theorems to superscalar microprocessors.;
Generalised Stream X-Machines and Cooperating Distributed Grammar Systems;Stream X-machines are a general and powerful computational model. By coupling the control structure of a stream X-machine with a set of formal grammars a new machine called a generalised stream X-machine with underlying distributed grammars acting as a translator is obtained. By introducing this new mechanism a hierarchy of computational models is provided. If the grammars are of a particular class say regular or context-free then finite sets are translated into finite sets whenâ€¯?k = k derivation strategies are used and regular or context-free sets respectively are obtained forâ€¯?k * and terminal derivation strategies. In both cases regular or context-free grammars the regular sets are translated into non-context-free languages. Moreover any language accepted by a Turing machine may be written as a translation of a regular set performed by a generalised stream X-machine with underlying distributed grammars based on context-free rules under = k derivation strategy. On the other hand the languages generated by some classes of cooperating distributed grammar systems may be obtained as images of regular sets through some X-machines with underlying distributed grammars. Other relations of the families of languages computed by generalised stream X-machines with the families of languages generated by cooperating distributed grammar systems are established. At the end an example dealing with the specification of a scanner system illustrates the use of the introduced mechanism as a formal specification model.;
Demonstrating the Cognitive Plausibility of Interactive System Specifications;Much of the behaviour of an interactive system is determined by its user population. This paper describes how assumptions about the user can be brought into system models in order to reason about their behaviour. We describe a system model containing reasonable assumptions about the user as being â€˜cognitively plausibleâ€™. Before asserting the plausibility of a model however we must first be able to make the assumptions made in that model inspectable.There is a tension between the inspectability of user assumptions and the tractability of models inspectable models tend to not be very tractable and vice versa. We describe how we can get round this tension by deriving tractable models from explicit user assumptions. The resulting models may not of themselves be very inspectable to human-factors workers but the process by which they are derived is inspectable. Hence we claim that we can have both tractability and inspectability. We exemplify our claims using a simple cognitive model and â€˜Meeting Makerâ€™ an interactive electronic diary system.;
Conformance Tests for Real-Time Systems with Timed Automata Specifications;A method is introduced for testing the conformance of implemented real-time systems to timed automata specifications. Uppaal timed automata are transformed into testable timed transition systems (TTTSs) using a test view. Fault hypotheses and a test generation algorithm for TTTSs are defined. Results of applying the method are presented.;
Design of an Automatic Teller Machine with Esterel Studio;This paper describes how the cash-point service can be specified and simulated using Esterel Studio.;
Generating Test Sets from Non-Deterministic Stream X-Machines;X-machines were proposed by Holcombe as a possible specification language and since then a number of further investigations have demonstrated that the model is intuitive and easy to use as well as general enough to cater for a wide range of applications. In particular (generalised) stream X-machines have been found to be extremely useful as a specification method and most of the theory developed so far has concentrated on this particular class of X-machines. Furthermore a method for testing systems specified by stream X-machines exists and is proved to detect all faults of the implementation provided that the system meets certain initial requirements. However this method can only be used to generate test sequences from deterministic X-machine specifications. In this paper we present the theoretical basis for a method for generating test sets from non-deterministic generalised stream X-machines.;
Generalised Stream X-Machines with Output Delimited Type;Some conditions relating to the automata involved in the W-testing method are discussed. It is also shown how to use the method for reduced automata instead of minimal automata. New design test conditions (weak output distinguishable strong test-complete and output delimited type) are considered for the generalised stream X-machines (stream X-machines with basic functions replaced by relations and having as output strings of symbols rather than single symbols). It is proved that testing methods similar to those already developed for ordinary deterministic stream X-machines may be applied for generalised stream X-machines with output delimited types. A particular case of generalised stream X-machine with output delimited type is the X-machine with output delimiter which produces outputs having a distinct right end character.;
The Cash-Point Service in NUT;This paper describes how the cash-point service can be modelled and simulated using the NUT system.;
Reverse engineering;In this paper we give an overall description of the Italian lexical sample task for SENSEVAL-2 together with some general reflections about on the one hand the overall task of lexical-semantic annotation and on the other about the adequacy of existing lexical-semantic reference resources.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;This paper describes our use of Prolog Word Experts (PWEs) in the Senseval-2 competition. We explain how we specify our PWEs as sequences of transformation rules and how they can be trained on sense tagged corpus data. We give a semantics of PWEs by translating them into first order predicate logic and we describe how PWEs can be compiled into Prolog procedures. We finally present our results for the Swedish lexical sample task: 63% (fine-grained score) for our best PWE and a second place in the ranking.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;CL Research's word-sense disambiguation (WSD) system is part of the DIMAP dictionary software designed to use any full dictionary as the basis for unsupervised disambiguation. Official SENSEVAL-2 results were generated using WordNet and separately using the New Oxford Dictionary of English (NODE). The disambiguation functionality exploits whatever information is made available by the lexical database. Special routines examined multiword units and contextual clues (both collocations definition and example content words and subject matter analyses) syntactic constraints have not yet been employed. The official coarse-grained precision was 0.367 for the lexical sample task and 0.460 for the all-words task (these are actually recall with actual precision of 0.390 and 0.506 for the two tasks). NODE definitions were automatically mapped into WordNet with precision of 0.405 and 0.418 on 75% and 70% mapping for the lexical sample and all-words tasks respectively comparable to WordNet. Bug fixes and implementation of incomplete routines have increased the precision for the lexical sample to 0.429 (with many improvements still likely).;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;In this paper we describe the structure organisation and results of the SENSEVAL exercise for Spanish. We present several design decisions we taked for the exercise we describe the creation of the gold-standard data and finally we present the results of the evaluation. Twelve systems from five different universities were evaluated. Final scores ranged from 0.56 to 0.65.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;This paper describes the sixteen Duluth entries in the Senseval-2 comparative exercise among word sense disambiguation systems. There were eight pairs of Duluth systems entered in the Spanish and English lexical sample tasks. These are all based on standard machine learning algorithms that induce classifiers from sense-tagged training text where the context in which ambiguous words occur are represented by simple lexical features. These are highly portable robust methods that can serve as a foundation for more tailored approaches.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;We describe the Dutch word sense disambiguation data submitted to SENSEVAL-2 and give preliminary results on the data using a WSD system based on memory-based learning and statistical keyword selection.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;This paper describes the Spr\r{a;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;The WSD system presented at Senseval-2 uses a knowledge-based method for noun disambiguation and a corpus-based method for verbs and adjectives. The methods are respectively Specification Marks and Maximum Entropy probability models. So we can say that this is a hybrid system which joins an unsupervised method with a supervised method. The whole system has been used in lexical sample english task and lexical sample spanish task.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;We submitted four systems to the Japanese dictionary-based lexical-sample task of Senseval-2. They were i) the support vector machine method ii) the simple Bayes method iii) a method combining the two and iv) a method combining two kinds of each. The combined methods obtained the best precision among the submitted systems. After the contest we tuned the parameter used in the simple Bayes method and it obtained higher precision. An explanation of these systems used in Japanese word sense disambiguation was provided.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;This paper describes a system for word sense disambiguation that participated in the Swedish Lexical Sample task of SENSEVAL-2. The system LIU-WSD is based on letting different contextual features cast votes on preferred senses according to a ranking scheme.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;SENSEVAL-2: The Second International Workshop on Evaluating Word Sense Disambiguation Systems was held on July 5-6 2001. This paper gives an overview of SENSEVAL-2 discussing the evaluation exercise the tasks the scoring system and the results. It ends with some recommendations for future evaluation exercises.;
The Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems;This paper introduces an iterative model for the software development process of distributed systems. It is based on dealing with the system evolution and maintenance activities as similar stages of the system development. In order to formalise this model a multi-valued causal temporal logic referred to as Simple Causal Temporal Logic (SCTL) is defined for the acquisition and specification of the functional requirements. A Model of Unspecified States (MUS) is also defined with a double goal: firstly to show the fundamental aspects of system behaviour which has been specified through a set of SCTL requirements and secondly to verify the consistency and completeness of the specified requirements.The combination of SCTL and MUS allows obtaining the specification of the initial architecture of the system formally. Besides the design decisions are stored with the goal of making the evolution and maintenance tasks easier. The translation between MUS and a constructive formal description technique (LOTOS) is automatic from the definition of architectural operators.;
Stream-Based Specification of Mobile Systems;This paper presents a formal specification technique for mobile systems based on input/output relations on streams. We consider networks of components communicating asynchronously via unbounded directed channels. Mobility is achieved by allowing the components to communicate channel ports. We distinguish between many-to-many and two variants of point-to-point communication. The communication paradigms are semantically underpinned by denotational models. The models are formulated in the context of timed non-deterministic data ow networks and presented in a stepwise fashion. The emphasis is on capturing the special kind of dynamic hiding characterising mobile systems. We demonstrate the proposed approach in a number of small examples.;
Presheaves as Configured Specifications;The paper addresses a notion of configuring systems constructing them from specified component parts with specified sharing. This notion is independent of any underlying specification language and has been abstractly identified with the taking of colimits in category theory. Mathematically it is known that these can be expressed by presheaves and the present paper applies this idea to configuration.We interpret the category theory informally as follows. Supposeâ€¯? is a category whose objects are interpreted as specifications and for which each morphism uâ€¯: Xâ†’Y is interpreted as contravariant â€˜instance reductionâ€™ reducing instances of specification Y to instances of X. Then a presheaf P: Setâ€¯?op represents a collection of instances that is closed under reduction. We develop an algebraic account of presheaves in which we present configurations by generators (for components) and relations (for shared reducts) and we outline a proposed configuration language based on the techniques. Oriat uses diagrams to express colimits of specifications and we show that Oriat's category Diag(?) of finite diagrams is equivalent to the category of finitely presented presheaves overâ€¯?.;
My SIGDOC conference trip report;In this paper we propose the concept of continuous evaluation which combines existing evaluation approaches in the construction of an evaluation toolkit consisting of guidelines methods and software tools for the monitoring analysis and optimization of cooperative learning. The concept of continuous evaluation is interesting to those who wish to make systematic evaluations of CSCL systems. It describes those evaluation activities which are appropriate when planning and designing CSCL during early field studies and throughout the ongoing maintenance of established courses. The aim of continuous evaluation is to build up a suite of evaluation methods and tools to be used by course organizers authors tutors and learners which are tailored to a specific e-learning setting and are iteratively improved over time.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This interactive session at CSCL 2002 will present and add to our ongoing study of design principles for educational technology. We are seeking to capture key findings of the field using a three-level framework including these interlinked components: educational goals design principles and software features.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper tackles to develop and evaluate the asynchronous virtual classroom called AVC which enables learners to participate in at anytime and from anywhere. Its environment provides on-demand multimedia learning-materials e.g. videos of the lecture slides and web pages. To utilize the two types of learning resources on-demand materials and asynchronous interactions the system synchronizes links and reproduces them toward efficient learning. To realize that a software agent participates to the classroom behalf of a real learner and replays the past interactions along with the video. Besides this we propose the model that a software agent recommends the suitable interactions for the current learner according to his/her interest.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Trends in distance education show a growing emphasis in collaborative learning stimulating students to exchange ideas and information. A collaborative environment however will demand a higher effort from the teacher who will supervise all discussions among learners so that they do not deviate from the intended topic for a lesson. Moreover the information proceeding from interactions among students will provide to the teacher features that allow an individual evaluation of each student and his course. In this way this paper describes a first experience using a multi-agent architecture that is able to monitor communication tools in a distance-learning group.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;We describe a program of research to explore how Palm Pilot technology can facilitate inquiry activities in K-12 science and mathematics curriculum. This research was conducted within the context of the Web-based Inquiry Science Environment (WISE) project which addresses fundamental questions concerning the role of inquiry and technology in science education. Working in close collaboration with two large school districts we developed new approaches for integrating Palm applications into existing WISE curriculum. We developed a sophisticated and generalized solution to enable hand held survey and observation forms that can be uploaded into a class data set.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;One of the biggest challenges in helping students learn via CSCL is embedding their work in appropriate social contexts and helping create a culture of inquiry and collaboration. This article describes how design-based research allowed the deliberate evolution of a set of tools and practices to help students collaborate effectively. The SpeakEasy one of the earliest Web-based discussion boards was evolved from prior discussion tools adapted to an Internet-based science learning environment and evolved to work with both online and offline classroom projects and practices. Research conducted as part of the evolution shows how social cues can be used to help students develop an integrated understanding of science. Implications for the design of socio-technical systems are discussed.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper discusses how an inquiry-support software the Progress Portfolio can help students engage in reflective inquiry. We argue that self-regulation is one of the most critical components of reflective inquiry and present an empirical case of how the Progress Portfolio tool was designed to enable students to become self-regulated in their learning. Even though there is a rich literature on self-regulation little has been written about group self-regulation in inquiry-based science. Preliminary results from a study with middle school students show that students do use the Progress Portfolio tool to engage in self-regulating cognitive activities such as setting goals planning and monitoring their work.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;ITCOLE is a project funded by the European community aimed at designing software for collaborative knowledge building supporting a virtual learning community. The software is designed so to represent metaphorically the model of Learning by Inquiry. In this paper we propose a methodology to assess the contextual uses of the software as to further develop synchronous communication tools.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Most CSCL works put forward the fact that learners working together would only need a means of communication. We feel this is not always sufficient. We have focussed on the collaborative activity itself and the way of enhancing collaboration. We have proposed a general framework which gives the teacher the possibility of defining and constructing pedagogical collaborative situations. It is based on regulation functions allowing the teacher to manage groups to define the roles played by the participants in a group and to describe the way actions can be performed (by means of scenarios). This framework has been implemented as an independent software that can be plugged into any collaborative application. It has already been tested with a collaborative drawing software for young children.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;As Internet bandwidth improves and connections become more reliable on-line course designers will be encouraged to make more structured use of synchronous communications. Little work has so far been reported on how to make the best use of synchronous communications to support a problem solving approach. The OTIS pilot course made extensive use of synchronous communication to support learning through case studies in occupational therapy. The transcripts of communication sessions have been analysed using the SOLO taxonomy to study the development of deep learning week by week. Results show that synchronous peer-to-peer working meetings have an important role to play in the development of deep learning.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This presentation describes multiplicity and flexibility as important factors in designing online collaborative learning environments. The presentation: (1) describes the design features of an award-winning Web-based course using extensive online collaborative learning (2) examines and discusses four aspects and specific features of the course that supported multiplicity in design development implementation and assessment (3) discusses implications for future course design and research of online collaborative learning environments.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This interactive session brings together researchers and educators interested in using external representations to facilitate and assess learning. The session will juxtapose four systems each of which takes a different design approach. The representations include concept maps metaphorical textual descriptions or visualizations for helping students learn in complex domains such as science or programming.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Teachers and students have established social roles norms and conventions when they encounter Computer-Supported Collaborative Learning (CSCL) systems in the classroom. Authority a major force in the classroom gives certain people objects representations or ideas the power to affect thought and behavior and influences communication and interaction. Effective computer-supported collaborative learning requires students and teachers to change how they understand and assign authority. This paper describes two studies in which students' perceptions of authority led to learning difficulties while they were engaged in collaborative learning. Students converged on either a representation or representational style that they believed was authoritative instead of basing their choice on how well the available representations communicated a concept. Methods to help students avoid such premature convergence are suggested.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;The Dialogue application is an innovative web-based communication tool that extends classroom boundaries and supports collaborative instructional goals. A key feature is the workspace environment in which professional dialogue is modeled and nurtured. For example students in teacher preparation programs initiate dialogue that link the preservice teachers' university-based learning with field related experience in public schools. Another aspect is the shared dialogue across K-12 schools around student centered research projects. The Dialogue applications enables equal partnerships with community agencies university students and families. It supports networking and timely feedback to resolve issues. Additional features sustain communication and educational requirements of a learning community within a school and across semesters.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Influenced by EPSS generative learning and intentional learning strategies a Web-based tool -- called the Web Resource Collaboration Center (WRCC) -- was developed to support learning communities in building their own Web-based learning and performance support systems to support lifelong learning and professional development. Using various online communication and collaboration technologies the WRCC is designed to not only enable learning communities to (1) build a learning and professional development resource that will provide them with immediate support and guidance and (2) help them develop structure strategies and skills for subsequent lifelong learning and professional development activities but also (3) take responsibility for creating original resources that support lifelong learning and professional development.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper describes a study that examined why groupware that was tailored to support collaborative student learning (Lotus Notes) was unsuccessful. In particular it examines why the tutors' aspirations of helping the students to collaborate were not met. It was found that students tended not to use the groupware preferring other self-developed support tools. Our study shows that the failure was multidetermined: there was a complex interacting set of factors including software use problems systems integration issues conflicting tutor/student perceptions of the value of using the groupware and conflicts in each group's view of how best to complete the course. There has been interest in using Activity Theory to approach multidimensional analysis in CSCL but existing Activity Theory-based frameworks can be difficult to apply to instances of collaborative learning marked by conflict. To address this need we use an Activity Theory-based analytic tool called the Activity Space. The tool is also used to show how multiple changes could be made to improve the potential for groupware to be used as intended.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Project-based learning has long been an important element in teaching informatics topics because it allows students to acquire important social and methodological competences in addition to professional competence. Groupware systems are increasingly used in such settings. In our paper we present the didactic concept we have applied to more than ten cooperative educational projects over the last few years. We describe how electronic media have become an integral part of our concept and we introduce CommSy a web-based application designed specifically to fit the needs of project-based learning.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;There has been much interest in using software tools to scaffold learners in complex tasks that is to provide supports that enable students to deal with more complex content and skill demands than they could otherwise handle. Many different approaches to scaffolding techniques have been presented in a broad range of software tools. I discuss two mechanisms to explain how software tools can scaffold learners. Software tools can help structure the learning task guiding learners through key components and supporting their planning and performance. In addition tools can shape students' performance and understanding of the task in terms of key disciplinary content and strategies thereby problematizing this important content. While making the task more difficult in the short term by forcing learners to address these ideas such scaffolded tools make this work more productive opportunities for learning.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;In this paper we explore issues to do with intersubjectivity and shared knowledge in human activity. We discuss these issues by contrasting two different views of language and communication one being a model developed by Clark and Brennan the other being a situated action approach. Clark and Brennan's model has gained substantial popularity in CSCL research. We develop our argument by presenting illustrative analyses of two data extracts concerned with the development of shared knowledge the negotiation of goals and the conditional relevance of technological tools. We conclude that Clark and Brennan's model retains a communication-as-transfer view of language and communication and that a situated action approach is more suitable for grasping the complex dynamics of joint activity.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;"This paper introduces a new learning technology for in-classroom and remote learning. The system and practice is called Livenotes"" and is motivated by the empirical success of peer learning methods and by theoretical considerations of distributed dialogue among student peers as a facilitator of learning. The technical part of Livenotes is a collaborative whiteboard running on wireless handheld computers. We describe the system and the affordances we have developed for it to support the distributed dialogue model. We then examine the interactive dialogue that resulted from two classroom trials using transcript captures and analyze how users developed ways to navigate between pages organize space on screens determine whether the system was operational and create social rapport. Finally we suggest several issues that researchers can consider in designing collaborative software.""";
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Although considerable attention in the CSCL community has been on distributed- Web- or distance-learning applications there is evidence suggesting that much of learning particularly in open-ended problem-solving activities based on tacit information does not occur in isolation but in face-to-face settings. This has led our research to explore ways to develop technologies and media that enhance participation collaboration and learning in face-to-face copresent settings.This paper explores the history of our research on developing such technologies in the context of our Envisionment and Discovery Collaboratory at the Center for LifeLong Learning &amp Design at the University of Colorado at Boulder and discusses my research on interface design to support learning and participation in collaborative settings.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Traditional computer technology offers limited support for face-to-face synchronous collaboration. As a result children who wish to collaborate using computers must adapt their interactions to the single-user paradigm most personal computers are based on. More recently co-located groupware systems offering support for concurrent multi-user interactions around a shared display have become technologically feasible. Unlike traditional groupware systems that provide multi-user interaction through the use of separate computers these systems share the physical workspace as well as the virtual workspace. These systems provide a unique mechanism through which children can interact with each other. However ways to best utilize the technology in this manner has not been fully evaluated. This paper investigates how technological support for children's synchronous interactions facilitates their collaborative activities. In particular we examined whether a shared workspace facilitates the development of a shared understanding during a computer-based collaborative activity. We present a field study that observed pairs of children playing an educational game in several display configurations. The findings from this research suggest strengths and weaknesses of various types of support for synchronous interactions and discusses issues related to the design and development of more effective computer systems to support children's face-to-face interactions.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Studying and evaluating real experiences that promote active and collaborative learning is a crucial field in CSCL. Major issues that remain unsolved deal with the merging of qualitative and quantitative methods and data especially in educational settings that involve direct as well as computer-supported collaboration. In this paper we present an evaluation methodology and its application to a university course that took place during the last two academic years. We have developed EL2AM a tool that allows an automatic processing of computer logs using social network analysis. It has been used jointly with a commercial qualitative research tool in order to support the evaluation process. Experimental results allow us to reflect and draw conclusions on the changes of attitudes towards collaboration experimented by the students along the course.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;The aim of the study was to evaluate an innovative learning project in which middle school students and teachers completed chosen group inquiries through virtual collaboration in a web-based learning environment. The students' task was to accomplish a cross disciplinary inquiry into cultural phenomena. Students worked mainly at home during the project and took much responsibility for their own work and course achievements. The investigators analyzed the content of the students' and teachers' communication in the web-based environment. The findings suggest that the virtual environment was used as a communication tool for organizing the collaborative work more than as a genuine knowledge-building tool. Also the tension between the conventional school culture and the novel working practices apparently affected students' participation and patterns of activity in the course.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;We evaluated a pedagogical agent that coaches collaborative problem solving by tracking student participation and comparing students' individual and group solutions. The software coach encourages negotiation when differences are detected between solutions and encourages participation in other ways. Evaluations based on expert judgment and on students' behavior shows that the quality of the advice was good and that the coach helped guide the collaborative session although specific areas for improvement were identified.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper describes an overview of a panel that will be held as an interactive event in CSCL2002. Multicultural issues in design evaluations and dissemination of CSCL systems are discussed. Four outstanding panelists will share their rich experiences and propose how multicultural issues should be considered and examined in the context of system design and development and practice in school education what problems should be dealt with and how information technologies can contribute to promoting multicultural learning. Discussions are not limited to the panelists: active participation from the audience will be welcomed.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;The notion of Grid computing has arisen with the desire to use computational communication and content resources on the internet efficiently and effectively in solving scientific problems. The origin of the term as now used is from the Supercomputing 97 Conference in which a demonstration involving using 3600 processors from 15 sites in U.S. Germany and Sweden to solve scientific computing problems in 10 application areas was given using software from the GLOBUS project that made the coordination of these computations possible. In this workshop we would like to explore the use of the GRID for learning - thus the term Learning GRID. The workshop goal is to formulate a plan for using Grid technologies in the establishment of a Learning Grid. In particular a desired outcome will be a determination of priorities for Grid development and areas of research requiring support in order to make the Grid an effective learning tool.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;"Computer-supported collaborative problem solving requires new methodological approaches of interaction and problem solving analysis. Usually analysis of collaborative problem solving situations is done through discourse analysis or interaction analysis where in the center of attention are the actors involved (students tutors etc.). An alternative framework called Object-oriented Collaboration Analysis Framework (OCAF)"" is presented here according to which the objects of the collaboratively developed solution become the center of attention and are studied as entities that carry their own history. This approach produces a view of the process according to which the solution is made of structural components that are 'owned' by actors who have contributed in various degrees to their development. OCAF is based on both actions and dialogues of actors providing qualitative as well as quantitative indicators of collaboration and solution quality. The paper presents first the framework notation. Examples of its use in analysis of distance groups and face-to-face collaborative activities are provided next followed by the dimensions of the framework supported analysis for teachers and researchers. Web-based tools supporting the OCAF approach are also presented.""";
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;How can classroom teachers be assisted in developing constructivist learning environments supported by technology in schools with large populations of traditionally underserved students? What role does available technology and professional development and support play in allowing or promoting changes in teaching methods? Results of the Southwest Educational Development Lab project Applying Technology to Restructuring and Learning (ATRL) indicate that teachers changed their classrooms practices and professional development coupled with access to technology was instrumental in that change. Teacher knowledge of how computer technology can be used to enhance learning and how to plan effective learning activities were shown to be more important than strong personal computer skills.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;An innovative learning environment enabling collaborative modeling activities is introduced in this paper. ModelsCreator 3.0 (MC3) supports semi-quantitative quantitative and qualitative reasoning during modeling activities of collaborating young children. MC3 is also an open environment in terms of primitive modeling entities models and collaborating partners. Synchronous modeling activity can be performed at a distance using MC3 based on a mechanism of light multiple processes (reactive agents) residing in collaborating hosts.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;In order to better understand how software design choices may influence students' collaborative learning we conducted a study of the influence of tools for constructing representations of evidential models on collaborative learning processes and outcomes. Pairs of participants worked with one of three representations (matrix graph text) while investigating a complex public health problem. Focusing on students' collaborative investigative processes and post-hoc essays we present several analyses that assess the impact of representation type on students' elaborations of their emerging knowledge. Our analyses indicate significant impacts on the extent to which students revisit knowledge and the likelihood that they will use that knowledge later.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Elementary school science focuses on the early phases of science inquiry: observation description data collection reflection and reporting. Technologies afford opportunities to scaffold and extend the domains of inquiry but successful adoption depends on their integration with classroom organization and practice. In elementary schools small group and whole class activities dominate over solitary activity and the effective use of traditional desktop computer systems has proven to be a difficult challenge for classroom teachers. Increasingly affordable large-format displays more naturally support small-group collaboration but require careful activity design to maximize utility. We describe an activity design employing large displays that accommodates both the constraints of the classroom and the play experiences of children in support of observational science learning.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper summarises two different approaches using technology to support young children's collaborative interaction in a classroom setting. KidPad a 2 1/2D drawing package with zooming capabilities was adapted for use with multiple mice and tangible interfaces. The first section of the paper focuses on a study carried out to evaluate the effect of multiple mice on children's collaborative behaviour at a desktop computer. Positive effects of the use of two mice included symmetry of mouse use amongst pairs and a greater degree of engagement in the task. However a number of usability issues were identified when children attempted to collaborate particular problems were faced when the shared control was taken away and one of the users took control for example when navigating. Different types of working styles were also evident between the one mouse and two mice conditions. The second section of the paper describes a move away from the desktop computer towards room-based technologies. Tangible interfaces to KidPad were developed in order to facilitate shared control over actions such as navigation where difficulties had been identified in a desktop situation. The visibility of action is highlighted as a fundamental element in the support of collaboration on a larger scale. Finally future work and the potential of these technologies in encouraging shareable co-present interaction in a real school context are briefly discussed.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;A principled approach to the design of problem-oriented web-based learning at the university level is presented. The principles include providing authentic contexts with multimedia supporting collaborative knowledge construction making thinking visible with dynamic visualisation quick access to content resources via ICT and flexible support by tele-tutoring. These principles are used in the MUNICS learning environment which is designed to help students of computer science to apply their conceptual knowledge from the lectures to complex real-world problems. For example students may model the information flow in an educational organization with a dynamic visualisation tool. A main finding in the formative evaluation study with the prototype is the ignorance of the students concerning the additional content resources. This finding is discussed on the background of the well-known phenomenon of insufficient use of help systems in software applications.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;In this paper we present and provide the theoretical basis of a computer supported and mediated educational research project which encourages cultural production and sustainability. We first describe the CD-Golem project which was developed in light of the perceived needs of a Diaspora community's attempts to impart its youth with a sense of belonging and continuity. Next we characterize Cultural Education and discuss the theoretical rationale of our approach in the context of current theories of identity and cultural construction multicultural education and computer-supported collaborative learning. We conclude by briefly reviewing and critically evaluating some of the lessons we have learned in our first years of activity.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Looking at computer supported collaborative learning (CSCL) in terms of (a) collaborative knowledge building (b) group and individual perspectives (c) mediation by artifacts and (d) micro-analysis of conversation provides a rich multi-dimensional starting point for conceptualizing and studying a specific variant of CSCL.These four contributions to CSCL are inter-related. The notion of collaborative knowledge building defines a useful paradigm for conceptualizing learning as social practice. The social interactions and knowledge management activities in which shared knowledge is constructed can be analyzed as the result of interweaving group and personal conversational perspectives. In general collaborative interaction is mediated by artifacts: sometimes only by transitory artifacts like spoken words or gestures but increasingly by physical or digital artifacts and media. Empirical studies of collaborative knowledge building employing micro-ethnographic analysis of speech gesture artifacts and media can make the details of these collaboration interactions visible highlighting the interplay of perspectives and artifacts in the trans-personal construction of knowledge.A theoretical framework incorporating models of knowledge building perspectives and artifacts -- and grounded in empirical analysis of collaborative interaction -- can guide the design of computer-based artifacts and media as support for collaborative learning with appropriate elaborated and unified conceptualizations.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper describes an experiment that examines how computer supported collaboration influences how children learn to solve a simple puzzle. We found that collaboration resulted in relatively poor performance during a 'training' period but that it appeared to aid puzzle comprehension during a later 'testing' period. Results also showed that girls found it harder than boys to solve the puzzle when collaborating.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Today's cheaper personal computers with improved computational power have made the technology of networked desktop virtual reality environments accessible to typical end users including students. This paper describes C-VISions a collaborative virtual environment developed to support interactive and collaborative learning using virtual simulations. The research effort is grounded on the principles of active experiential learning and constructivist/social constructivist ideas with their attendant commitment to group sense making discourse-based learning and community building processes. The paper also provides an overview of the system's design and implementation. Finally we explain the current status of the research effort and articulate plans for future work.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;CoWeb is a collaborative learning environment used in many classes at Georgia Institute of Technology it is an extremely simple domain-independent collaboration tool. Our aim is to show that such a simple system can sustain useful peer-to-peer and instructor-to-student interaction that fosters better performance and learning without incurring a high cost. In this paper we present evidence of the success of this tool in supporting learning at low cost in one environment---freshman-level English classes.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Designs for CSCL applications usually presume a desktop/laptop computer. Yet future classrooms are likely to be organized around Wireless Internet Learning Devices (WILD) that resemble graphing calculators or Palm handhelds connected by short-range wireless networking. WILD learning will have physical affordances that are different from today's computer lab and different from classrooms with 5 students per computer. These differing affordances may lead to learning activities that deviate significantly from today's images of K-12 CSCL activities. Drawing upon research across a range of recent handheld projects we suggest application-level affordances around which WILD-based CSCL has begun to organize: (a) augmenting physical space (b) leveraging topological space (c) aggregating coherently across all students (d) conducting the class and (e) act becomes artifact. We speculate on how CSCL research may consequently evolve towards a focus on kinds of systemic coupling in an augmented activity space.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper reports from a user requirement design and evaluation study on supporting collaborative learning by visual perception in the medical education domain. The CANTOR (Converging Agreement by Networking Telematics for Object Recognition) system can briefly be described as a tool that support collaborative consensus making when classifying sets of medical images or objects in medical images An evaluation experiment showed that using CANTOR seems to give a better learning effect than by using traditional methods.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Students bring to a collaborative learning situation a great deal of specialized knowledge and experiences that undoubtedly shape the collaboration and learning processes. How effectively this unique knowledge is shared and assimilated by the group affects both the process and the product of the collaboration. In this paper we describe a machine learning approach Hidden Markov Modeling to analyzing and assessing on-line knowledge sharing conversations. We show that this approach can determine the effectiveness of knowledge sharing episodes with 93% accuracy performing 43% over the baseline. Understanding how members of collaborative learning groups share assimilate and build knowledge together may help us identify situations in which facilitation may increase the effectiveness of the group interaction.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper is based on the central idea that networked teaching may best be improved by those engaged in it. Systematic enquiry into educational interactions can yield understandings and insights about one of the fundamental relationships of all educational endeavours: between teaching and learning. The paper explores this relationship through analyses of teaching and learning in a networked collaborative learning environment using two new content analysis schemas. The first of these probes the social co-construction of knowledge in a collaborative online event by analysing the social cognitive and metacognitive contributions to an online learning event. In the second schema the presence of teacher processes is investigated. Computer assisted qualitative data analysis is used for this. In conclusion consideration is given to the prospects for this type of approach as a means of enriching understandings of the complexity of the relationship between teaching and learning in networked collaborative learning environments.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Newsgroups and online discussion boards have long been used to supplement class discussions. We describe a study comparing the use of two systems WebAnn and EPost to support class discussion of technical papers in a graduate course. WebAnn is a shared annotation system that supports anchored discussions on web pages and allows users to easily associate comments with a particular paragraph phrase or word in the paper being discussed. EPost is a high-quality conventional discussion board system. In our study students contributed almost twice as much to the online discussion using WebAnn. WebAnn also encouraged a different discussion style focused on specific points in the paper. We expected WebAnn discussions to serve as a starting point for in-depth discussions in the classroom but in fact online discussions often competed with classroom discussions. We conclude with implications of the study for technology design and the process of its use.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Distributed learning environments such as groupware give two or more users the means for working together remotely on a shared task. This activity is more than the sum of single users working on their own to solve the same task. Although most people will agree about this there is neither agreement nor much discussion in the literature on how coordination and collaboration skill should be distributed between users and computer tools. We present a new approach that uses a process model adapted from Activity theory to guide our efforts. The model outlines steps towards capturing crystallised experience.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Using FLE2 groupware (Future Learning Environment 2 http://fle2.uiah.fi) we have tried to integrate a distance education course into the regular academic programme at Roskilde University Denmark. The course was offered jointly by two universities attracting students and involving teachers from both institutions. The practical and pedagogical problems encountered are discussed and it is suggested that while net-based teaching may be suitable only under certain circumstances in a normal academic programme skills of communicating and working in an online environment are important qualifications that should be introduced broadly into academic life.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;"Design education has a strong reliance on passive presence awareness and unfocused interaction. This paper reports on Compadres a system for support of distributed collaborators through creation of group presence awareness on the web. Compadres provides various configurable communications options in both synchronous and asynchronous modes including links for email chat and file transfer. It includes two levels of presence awareness: current status and an extended radar view providing asynchronous presence."" The system supports itinerant or mobile users (such as students) as well as situated users (such as faculty).Our experiences with Compadres which has been used by several classes and our research group support those of others regarding the power of presence and messaging in supporting group cohesion and indicate that it is possible to support infrequent or occasional collaboration as well as frequent interaction via the web.""";
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;In this paper we attempt to draw comparisons between our research experiences of Computer Supported Collaborative Learning in the workplace in schools and in universities. We present an outline description of our activities in each setting. As a possible contribution to foundational theory in CSCL we focus on the crucial but complex issue of learner motivation. We argue that the dominant issues of motivation may vary from setting to setting but that CSCL can play an important role in engaging learner motivation in all settings. In particular we consider the inauthenticity of most university education and consider how this might be addressed by CSCL.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;We report a series of studies on the role of eye contact in video-mediated communication. These are part of an ongoing research program which is investigating the usefulness of the technological mediated collaborative problem solving for distance learning. Technological mediation consists of access to shared simulations and access to a variety of means of communication. The means of communication we have explored range from audio only contact to video mediated communication with or without eye contact. The motivating question behind this research program is 'what is different when members of a problem-solving group are physically separated but technologically connected?' The studies are set in the context of pairs of adults working with shared simulations of either physics or statistical experiments. The first set of studies investigated pairs working on a shared simulation of a physics experiment developed in SharedARK. The study compared remote technological mediated communication with communication that occurred during physical co-presence. There were no differences in performance but the addition of computer mediated communication did influence the pattern of interaction. These experiments suggested that eye contact influenced problem solving. The second set of studies compared pairs and groups of threes and fours using a simulation of a statistic experiment developed in a system called Kansas. In these studies we compared learners with either video-mediated communication or audio only communication. The addition of the visual communication channel altered the pattern of interaction. The most recent study presents evidence that suggests eye contact facilitated conceptual understanding.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;We have implemented ubiquitous computing technology in a primary school setting to support rich classroom activities particularly in the field of early literacy. After initial tests have corroborated the benefit of this technology with respect to attaining curricular goals and to better supporting learner-centred classroom methodologies we are now exploring specific intelligent support mechanisms e.g. to inform participants - both teachers and pupils - about automatically assessed learning opportunities.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;In this paper we sketch an approach to integrate courses for individual learning into a powerful CSCL environment by using the Point of Cooperation (PoC) approach. We show how PoCs can be set up to create a collaborative learnflow which exploits individual learning phases as well as different phases of asynchronous and synchronous collaboration. The implementation of the PoC approach in the L3 project is presented.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;In this paper we present Sam an embodied conversational storyteller who tells stories interactively with children. Sam was designed to appear as a peer to preschool children but to tell stories in a developmentally advanced way in order to model narrative skills important for literacy. Literacy learning - learning how to read and write begins long before children enter school. One of the key skills to reading and writing is the ability to represent thoughts symbolically and share them in language with an audience who does not share the same background. Children learn and practice such important language skills in the informal setting of everyday storytelling with their peers and adults available around them. In particular storytelling in a context of peer collaboration provides a perfect place where children not only learn language skills important for literacy but also learn to be critical listeners of others' stories. Preliminary evaluation showed that by interacting with Sam 5-year-old children's stories more closely resembled Sam's linguistically advanced stories with more quoted speech and temporal and spatial expressions. In addition the children listened to Sam's stories carefully assisting her and giving suggestions on how to improve them. With Sam children not only learned new linguistic behaviors that are important for literacy but also to become critical listeners of other's stories.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;Successful elementary and secondary educational reform requires analogous reform in teacher education however the standard undergraduate setting in schools of education poses considerable obstacles. In this paper we describe the STEP environment for distributed problem-based learning (www.eSTEPweb.org) which represents one of many efforts to create a viable model for teacher education reform. Here we describe our approach to creating a socio-technical infrastructure designed to help foster a knowledge-building community among preservice teachers practicing teachers and instructional staff. We highlight the online environment that supports student and staff coursework in the learning sciences component of a secondary teacher education curriculum.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;The purpose of this workshop is to promote discussion and collaboration between developers of CSCL environments digital library developers and user communities. This topic is an important and complex one and is comprised of both technical and social challenges. With a few notable exceptions these research strands have not integrated their efforts in any meaningful or scalable manner. Towards this end we are looking for a group of researchers and practitioners who are willing to work together in a workshop to identify challenges and opportunities for the integration of a variety of CSCL environments and digital library applications.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;This paper presents results from a study focusing on text-based electronic interaction in a distance educational setting. The analysis of the interaction identifies three typified genres labeled Query Feedback and Smalltalk. Together they constitute a shared interaction repertoire with marks of a new social landscape for education with changes in roles and behaviours that are important to grasp for designers as well as teachers.;
Proceedings of the Conference on Computer Support for Collaborative Learning: Foundations for a CSCL Community;In a model-based software systems development formal specifications of the components of the system are developed. Thereby different specifications are used to represent the different aspects or views of the components possibly following different paradigms. These heterogeneous viewpoint specifications have to be integrated in order to obtain a consistent global specification of the whole system. In this paper transformation systems are introduced as a common semantic domain where specifications written in different languages can be interpreted and formally compared. A transformation system is a transition system where the transitions are labelled by sets of actions and the states are labelled by algebras representing the data states. Development relations and composition operations for transformation systems are investigated and it is shown that compatible local developments of components induce a global development of their composition. As an application two specifications of the alternating bit protocol are formally compared component-wise one given in the process calculus CCS the other one in the parallel programming language UNITY.;
An Overview of the Integrated Formalism RT-Z;We present an integration of the formal specification languages Z and timed CSP called RT-Z incorporating their combined strengths in a coherent frame. To cope with complex systems RT-Z is equipped with structuring constructs built on top of the integration because both Z and timed CSP lack appropriate facilities. The formal semantics of RT-Z based on the denotational semantics of Z and timed CSP is a prerequisite for preciseness and mathematical rigour. RT-Z is intended to be used in the requirements definition and design phases of the system and software development process. The envisaged application area is the development of real-time embedded systems.;
Combining Component Specifications in Object-Z and CSP;This paper discusses the separation of components from the contexts in which they are used and how this separation can be supported whilst using different specification languages. There are a number of ways in which this might be possible and here we show how the technique of promotion in Object-Z can be used to combine components which are specified using process algebras. We outline two approaches. The first is to separate out a single specification into a number of distinct viewpoints (i.e. partial specifications) each possibly written in a different notation. These viewpoints can be developed separately but combined if necessary by a process of translation and unification. The alternative approach we discuss is to use a single hybrid language which is composed of a combination of notations which we illustrate here by combining CSP and Object-Z. We illustrate both approaches with a simple example and also consider how such component-based descriptions can be refined which involves addressing the question of compositionality.;
Deep Semantic Links of TCSP and Object-Z: TCOZ Approach;Formal methods can be used in effective combination only if the semantic links between individual methods are clearly established. This paper discusses the semantic design of TCOZ a language blended from Object-Z and TCSP. The semantic model adopted is the infinite timed failures model of TCSP extended to include initial state and update events for modelling operations on internal state. An infinite trace model has been used so as to ensure proper account is taken of the potentially unbounded non-determinism allowed by Z schemas.;
An Introduction to Real-Time Object-Z;This paper presents Real-Time Object-Z: an integration of the object-oriented state-based specification language Object-Z with the timed trace notation of the timed refinement calculus. This integration provides a method of formally specifying and refining systems involving continuous variables and real-time constraints. The basis of the integration is a mapping of the existing Object-Z history semantics to timed traces.;
Supporting the end users' views;End users of software have the right to systems that are both useful and usable a property termed usability in the software and human-computer interaction communities. Unfortunately it is not obvious what methods or techniques developers of software should adopt in order to achieve good usability in a product. There are a confounding number of questions. How can different points of view among end users be incorporated into a software development process? What does it mean to treat software developers as end users namely of software tools? How do the limitations of software practice such as minimizing time to release affect what information can be collected and used to make usability decisions? This paper presents a variety of possibilities for supporting all the end users' views in a software development activity. Both tools and methods are suggested roughly organized according to the different activities in software development. Moreover end users are defined to be a variety of stakeholders in a software development project including at the very least the end users of a product but also developers who are end users of software tools.;
Proceedings of the Working Conference on Advanced Visual Interfaces;"The main task of molecular biologists seeking to understand the molecular basis of disease is identifying and interpreting the relationships of genes proteins and pathways in living organisms. While emerging technologies have provided powerful analysis tools to this end they have also produced an explosion of data which biologists need to make sense of. We have built software tools to support the synthesis activities of molecular biologists in particular the activities of organizing retrieving using sharing and reusing diverse biological information. A key aspect of our approach based upon the findings of user studies is the use of narrative structure as a conceptual framework for developing and representing the story"" of how genes proteins and other molecules interact in biological processes. Biological stories are represented both textually and graphically within a simple conceptual model of items collections and stories.""";
Proceedings of the Working Conference on Advanced Visual Interfaces;A user interface softbot is a software agent that controls an interactive system through the graphical user interface relying on visual information from the system rather than an application programming interface or access to source code. Interface softbots have acted as autonomous agents in applications such as drawing and data recording and the core vision processing algorithms have been incorporated into cognitive models for simple problem-solving tasks. Building interface softbots is still a time-consuming task unfortunately requiring experience with complex program components as well as the details of the visual interface. We have developed a prototype development environment that facilitates the development of interface softbots streamlining the programming process and making it more accessible to new developers.;
Proceedings of the Working Conference on Advanced Visual Interfaces;This paper presents an approach to support the designer of Visual Interactive Systems (VISs) in adapting a VIS to the evolution of its users. This process is called co-evolution of users and systems. The approach is based on the identification of the patterns of interaction between the user and an interactive system and on their use for the evolution of the system to facilitate novel usages introduced by the user. The approach is focused on WIMP systems and is based on the recently introduced PCL (Pictorial Computing Laboratory) model of interaction within which we provide a novel definition of interaction pattern. The proposal assumes that the VIS is observed by an external system called SIC (Supporting Interaction Co-evolution) which is in charge of recording the interactions between the user and the VIS and of analyzing the relevant interaction patterns. In particular SIC exploits a UML-based statechart specification of the VIS in order to associate observed user activities with the states of the interactive process. This information provides a useful basis for a variety of pattern recognition techniques. Two techniques called usual state and recurrent sequence recognition are illustrated and the results of a first experiment are discussed.;
Proceedings of the Working Conference on Advanced Visual Interfaces;Data structures and algorithms include abstract concepts and processes which people often find difficult to understand. Examples of these are complex data types and procedural encoding of algorithms. Software visualization can significantly help in solving the problem.In this paper we describe the platform independent Matrix system which combines algorithm animation with algorithm simulation where the user interacts directly with data structures through a graphical user interface. The simulation process created by the user can be stored and played back in terms of algorithm animation. In addition existing library routines can be used for creating illustrations of advanced abstract data types or for animating and simulating user's own algorithms. Moreover Matrix provides an extensive set of visual concepts for algorithm animation. These concepts include visualizations for primitive types arrays lists trees and graphs. This set can be extended further by using arbitrarily nested visualizations;
Proceedings of the Working Conference on Advanced Visual Interfaces;We investigated the effects of varying eye gaze behavior of an embodied conversational agent on the quality of human-agent dialogues. In an experiment we compared three versions of an agent: one with gaze behavior that is typically found to occur in human-human dialogues one with gaze that is fixed most of the time and a third version with random gaze behavior. The versions were found to yield significant differences in efficiency of the dialogues and in user satisfaction amongst others.;
Proceedings of the Working Conference on Advanced Visual Interfaces;This paper presents visualization and layout schemes developed for a novel circular user interface designed for a round tabletop display. Since all the displayed items are in a polar coordinate system many interface and visualization schemes must be revisited to account for this new layout of UI elements. We discuss the direct implications of such a circular interface on document orientation. We describe two types of fisheye deformation of the circular layout and explain how to use them in a multi-person collaborative interface. These two schemes provide a general layout framework for circular interfaces. We have also designed a new visualization technique derived from the particularities of the circular layout we have highlighted. In this technique the user controls the layout of the elements of a hierarchical tree. Our approach is to provide the user rich interaction possibilities to easily and quickly produce a layout comparable to the hyperbolic view developed at Xerox PARC. The visualization work presented in this paper is part of our ongoing Personal Digital Historian (PDH) research project. The overall goal of PDH is to investigate ways to effectively and intuitively organize navigate browse present and visualize digital data in an interactive multi-person conversational setting.;
Proceedings of the Working Conference on Advanced Visual Interfaces;In this paper we develop a generalized approach to visualizing and controlling an optimization process. Our framework called Human-Guided Search actively involves people in the process of optimization. We provide simple and general visual metaphors that allow users to focus and constrain the exploration of the search space. We demonstrate that these metaphors apply to a wide variety of problems and optimization algorithms. Our software toolkit supports rapid development of human-guided search systems.Our approach addresses many often-neglected aspects of optimization that are critical to providing people with practical solutions to their optimization problems. Users need to understand and trust the generated solutions in order to effectively implement justify and modify them. Furthermore it is often impossible for users to specify in advance all appropriate constraints and selection criteria for their problem. Thus automatic methods can only find solutions that are optimal with regard to an invariably over-simplified problem description. In contrast human-in-the-loop optimization allows people to find and better understand solutions that reflect their knowledge of real-world constraints.Finally interactive optimization leverages people's abilities in areas in which humans currently outperform computers such as visual perception learning from experience and strategic assessment. Given a good visualization of the problem people can employ these skills to direct a computer search into the more promising regions of the search space.The software we describe is written in Java and is available under a free research license for research or educational purposes.;
Proceedings of the Working Conference on Advanced Visual Interfaces;We describe the design and functionality of the Scope a glanceable notification summarizer. The Scope is an information visualization designed to unify notifications and minimize distractions. It allows users to remain aware of notifications from multiple sources of information including e-mail instant messaging information alerts and appointments. The design employs a circular radar-like screen divided into sectors that group different kinds of notifications. The more urgent a notification is the more centrally it is placed. Visual emphasis and annotation is used to reveal important properties of notifications. Several natural gestures allow users to zoom in on particular regions and to selectively drill down on items. We present key aspects of the Scope design review the results of an initial user study and describe the motivation and outcome of an iteration on the visual design.;
Proceedings of the Working Conference on Advanced Visual Interfaces;A typical user when learning annotates text figures and other contents so as to better highlight memorize and retrieve relevant information. A few annotation programs exist but either change the contents of the document or do not support distance learning through the web. We report work-in-progress on a &ltu&gtu&lt/u&gtser-&ltu&gtc&lt/u&gtentered &ltu&gta&lt/u&gtnnotation &ltu&gtt&lt/u&gtool (UCAT) which allows students to annotate following their personal styles (using different icons colors and signed versions) any document belonging to authorware within a course. We have chosen Amaya as the working environment since belonging to the World Wide Web Consortium (W3C) it complies with the semantic web specifications on document formats like RDF. An example of the deployment of UCAT will be shown in the paper.;
Proceedings of the Working Conference on Advanced Visual Interfaces;This paper introduces the cultural anthropologist Hofstede's culture dimensions and considers how they might affect user-interface designs. Examples from the Web illustrate the cultural dimensions User-interface designers have identified basic components of user interfaces. An initial mapping of culture dimensions to user-interface components seeks to help user-interface designers cope with global product and service development. Ultimately tools might emerge to facilitate tuning designs per culture.;
Proceedings of the Working Conference on Advanced Visual Interfaces;The Internet and World Wide Web have made a tremendous amount of information available to people today. Taking advantage of and managing this information however is becoming increasingly challenging due to its volume and the variety of sources available. We attempt to reduce this overload with the InfoCanvas an ambient display of a personalized information-driven visual collage. Through a web-based interface people identify information of interest associate a pictorial representation with it and place the representation on a virtual canvas. The end result is an information collage displayed on a secondary monitor or net appliance that allows people to keep tabs on information in a calm unobtrusive manner. This paper presents details on how a person can create and manage information with the InfoCanvas and how we provide such capabilities.;
Proceedings of the Working Conference on Advanced Visual Interfaces;This paper presents a new virtual locomotion interface based on step-in-place action and a smart-turntable system. The interface provides a turntable as walking platform on top of which users will stand at its center and facing a large screen to perform life-like walking actions that steer their navigation through the virtual environment. Steering actions are tracked seamlessly without attachment to the body through a set of pressure sensors embedded within the turntable and a computer vision system. For instance in place stepping is treated as a gesture indicating the intention to move forward. Rotation about the body's vertical axis is treated as a gesture changing the walking direction. However as large screens are usually limited in size and do not allow a surrounding projection a large turning action may put users in a visual-less situation which hamper considerably the effectiveness of the walking experience. To avoid such case and keep users always provided with sufficient visual feedback the turntable will passively and smoothly rotate in opposite direction of users' turning. Rotation speed and acceleration of the turntable are well optimized to keep users well balanced and easily withstand the passive rotation. The interface is shown to be easy and simple to use in virtual environments equipped with large screen.;
Proceedings of the Working Conference on Advanced Visual Interfaces;We have developed a methodology for studying and analyzing the psychology of users performing ecologically valid WWW tasks. A user trace is a record of all significant states and events in the user-WWW interaction based on eye tracking data application-level logs and think-aloud protocols. A user-tracing architecture has been implemented for developing simulation models of user-WWW interaction and for comparing a simulation model (SNIF-ACT) against user-trace data. The user tracing architecture compares each action of the SNIF-ACT simulation directly against observed user actions. The model and architecture have been used to successfully match detailed user trace data from four users working on two tasks each.;
Proceedings of the Working Conference on Advanced Visual Interfaces;The technique of Rapid Serial Visual Presentation (RSVP) comparable with the riffling of a book's pages to acquire an impression of its contents has considerable application potential especially where display space is at a premium. The design of RSVP applications however is not straightforward in view of the many and often conflicting design decisions that must be taken. Specifically it is suspected that many of these decisions will impact on the ability of users to effectively perceive the displayed content as far as carrying out a task is concerned. This paper presents an exploratory study in which we investigated the impact of a number of design decisions on users' eye movements. Four RSVP modes were implemented that represent alternative design decisions. Two of these modes were modeled after existing e-commerce applications and two have been the subject of our ongoing research for some time. For each RSVP mode a set of images was presented to two participants who were required to respond to the appearance of a pre-viewed target image. In the course of these presentations we recorded the participants' eye movements in order to elicit information concerning potential perceptual difficulties. We propose a novel graphical characterization of RSVP modes which is appropriate to their correlation with recorded eye gaze patterns offer an interpretation of the experimental data and provide a motivation for further research into RSVP.;
Proceedings of the Working Conference on Advanced Visual Interfaces;This paper describes the visual analysis tool WebQuilt a web usability logging and visualization system that helps web design teams record and analyze usability tests. The logging portion of WebQuilt unobtrusively gathers clickstream data as users complete specified tasks. This data is then aggregated and presented as an interactive graph where nodes of the graph are images of the web pages visited and arrows are the transitions between pages. To aid analysis of the gathered usability test data the WebQuilt visualization provides filtering capabilities and semantic zooming allowing the designer to understand the test results at the gestalt view of the entire graph and then drill down to sub-paths and single pages. The visualization highlights important usability issues such as pages where users spent a lot of time pages where users get off track during the task navigation patterns and exit pages all within the context of a specific task. WebQuilt is designed to conduct remote usability testing on a variety of Internet-enabled devices and provide a way to identify potential usability problems when the tester cannot be present to observe and record user actions.;
Proceedings of the Working Conference on Advanced Visual Interfaces;"In this paper we discuss the design and use of fisheye view techniques to explore semantic relationships in information. Traditional fisheye and focus + context"" techniques dynamically modify the visual rendering of data in response to the changing interest of the user. ""Interesting"" information is shown in more detail or visually emphasized while less relevant information is shown in less detail de-emphasized or filtered. These techniques are effective for navigating through large sets of information in a constrained display and for discovering hidden relationships in a particular representation. An open area of research with these techniques however is how to redefine interest as a user's tasks and information needs change.We are developing a framework for implementing fisheye views to support multiple semantic contexts. The framework is based on two components: Degree Of Interest functions and visual emphasis algorithms to change the representation of information with respect to interest. The framework supports different contexts through the aggregation of multiple weighted distance metrics in the calculation of interest.Using this framework we have developed a user-configurable interface for browsing tabular data that visually emphasizes objects with respect to different semantic contexts.""";
Proceedings of the Working Conference on Advanced Visual Interfaces;This paper describes a two-handed drawing tool developed on our augmented desk system. Using our real-time finger tracking method a user can draw and manipulate objects interactively by his/her own finger/hand. Based on the former work on two-handed interaction different roles are assigned to each hand. The right hand is used to draw and to manipulate objects. Using gesture recognition primitive objects can be drawn by users' handwriting. On the other hand the left hand is used to manipulate menus and to assist the right hand. By closing all left hand fingers users can initiate the appearance of structural radial menus around their left hands and can select appropriate items by using a left hand finger. The left hand is also used to assist in the performance of drawing tasks e.g. specifying the center of a circle or top-left corner of a rectangle or specifying the object to be copied.;
Proceedings of the Working Conference on Advanced Visual Interfaces;Virtual Reality (VR) interfaces to e-commerce sites have recently begun to appear on the Internet promising to make the e shopping experience more natural attractive and fun for customers. Unfortunately switching to a desktop VR design for an e-commerce site is not trivial and does not guarantee at all that the interface will be effective. In this paper we first briefly discuss the potential advantages of these interfaces stressing the need for a better approach to their design. Then we present the directions we are following to build more usable and effective VR stores i.e.: (i) reformulating design guidelines from real-world stores in the VR context (ii) exploiting VR to create user empowerments that meet both customer and merchant needs and (iii) personalizing the VR store to better reflect customer's taste preferences and interests. For each of the three directions we illustrate and discuss a detailed case study.;
Proceedings of the Working Conference on Advanced Visual Interfaces;There is a need for an overall framework that can support the entire knowledge discovery process. Of special interest is the role of visualization in such a framework. This paper focuses on the exploitation of various visual strategies with a view to discovering knowledge through metarules and association rules.;
Proceedings of the Working Conference on Advanced Visual Interfaces;This paper describes a system for exploring and selecting entries from a music database through a visualization interface. The system is designed for deployment in situations in which the user's attention is a tightly limited resource. The system combines research topics in intelligent user interfaces visualization techniques and cognitive modeling. Informal evaluation of the system has given us useful insights into the design tradeoffs that developers may face when building visual interfaces for off-the-desktop applications.;
Proceedings of the Working Conference on Advanced Visual Interfaces;We report our experiences with application of the optical art techniques of Victor Vasarely and Bridget Riley to visualization of height field and vector field data. The bold use of color and simple form in Op Art engages the preattentive processing ability of the human visual system facilitating a nearly instantaneous perception of image properties without the need for extended scrutiny of component parts. A software system called Op-Glyph was constructed to illustrate the Op Art method for data visualization providing a user with extensive control over a visual representation's primitives including shape size and color. Initial results suggest that this glyph-based approach to data visualization may be a viable alternative or complement to more complex representation schemes particularly in situations where there are limited processing or graphical capabilities such as with PDAs.;
Proceedings of the Working Conference on Advanced Visual Interfaces;We present OZONE (Zoomable Ontology Navigator) for searching and browsing ontological information. OZONE visualizes query conditions and provides interactive guided browsing for DAML (DARPA Agent Markup Language) ontologies on the Web. To visually represent objects in DAML we define a visual model for its classes properties and relationships between them. Properties can be expanded into classes for query refinement. The visual query can be formulated incrementally as users explore class and property structures interactively. Zoomable interface techniques are employed for effective navigation and usability.;
Proceedings of the Working Conference on Advanced Visual Interfaces;"We conducted an experiment that compared three post-WIMP interaction techniques: floating palettes marking menus and toolglasses in a real-world Coloured Petri-Net editor CPN2000. We created six situations in which users performed identical sets of actions with equally-complex nets but with different cognitive contexts. We found significant differences in performance and preferences across interaction techniques. When a user is in a copy"" context floating palettes are more efficient. If the user is problem solving toolglasses or marking menus are preferred. No single interaction technique is clearly superior: each has strengths in different contexts. Since a single application must support different kinds of cognitive tasks interaction designers should consider integrating multiple interaction techniques rather than selecting only one.""";
Proceedings of the Working Conference on Advanced Visual Interfaces;A common problem in visualization applications is the display of one surface overlying another. Unfortunately it is extremely difficult to do this clearly and effectively. Stereoscopic viewing can help but in order for us to be able to see both surfaces simultaneously they must be textured and the top surface must be made partially transparent. There is also abundant evidence that all textures are not equal in helping to reveal surface shape but there are no general guidelines describing the best set of textures to be used in this way. What makes the problem difficult to perceptually optimize is that there are a great many variables involved. Both foreground and background textures must be specified in terms of their component colors texture element shapes distributions and sizes. Also to be specified is the degree of transparency for the foreground texture components. Here we report on a novel approach to creating perceptually optimal solutions to complex visualization problems and we apply it to the overlapping surface problem as a test case. Our approach is a three-stage process. In the first stage we create a parameterized method for specifying a foreground and background pair of textures. In the second stage a genetic algorithm is applied to a population of texture pairs using subject judgments as a selection criterion. Over many trials effective texture pairs evolve. The third stage involves characterizing and generalizing the examples of effective textures. We detail this process and present some early results.;
Proceedings of the Working Conference on Advanced Visual Interfaces;Literature presents a considerable number of techniques that may be used in the process of evaluation of interfaces. Each technique has its own features involves the employment of different resources and allows the obtainment of distinct results depending on the way it is conducted. The present article aims at assessing by means of a set of experiments the costs and benefits found specifically in the application of three techniques: heuristic evaluation user tests and recommendation conformity inspection.;
Proceedings of the Working Conference on Advanced Visual Interfaces;CYNTHIA is a transformation-based editor for a functional subset of ML that lies somewhere between a structure editor and a framework for formal program development. Users construct programs from existing code by applying editing commands that make a semantic analysis of the program's behaviour e.g. whether it is terminating. All analysis is done using the Oyster system which is an implementation of proofs-as-programs. We concentrate on identifying analyses that can be done fully automatically (e.g. using a decision procedure) and hence can be hidden from the user. As a result CYNTHIA represents progress towards a goal of program editors that make an intelligent analysis of their code but in a way that requires no extra input from the programmer.;
Should ML be Object-Oriented?;At a fundamental level functional and object-oriented programming languages are all â€˜higher-orderâ€™ in the sense that they support computing with values that are themselves pieces of program code encapsulated with a local environment. In functional languages these â€˜activeâ€™ values are functions while in object-oriented languages they are objects. Both styles of higher-order language claim to provide good support for writing adaptable programs but functional and object-oriented languages achieve this adaptability in different ways: functional programs rely on parameterisation at the value type and module level while object-oriented languages rely primarily on subtyping and implementation inheritance. Here we compare these two approaches mainly in terms of the features and properties of their type systems and consider the benefits and disadvantages of unifying (or merging) the two paradigms by adding object-oriented features to ML as a base language. We argue that while some of the simpler aspects of object-oriented languages are compatible with ML adding a full- edged class-based object system to ML leads to an excessively complex type system and relatively little expressive gain especially if we aim to preserve that mostly functional style of programming that is a major advantage of ML.;
Institution Morphisms;Institutions formalise the intuitive notion of logical system including syntax semantics and the relation of satisfaction between them. Our exposition emphasises the natural way that institutions can support deduction on sentences and inclusions of signatures theories etc. it also introduces terminology to clearly distinguish several levels of generality of the institution concept. A surprising number of different notions of morphism have been suggested for forming categories with institutions as objects and an amazing variety of names have been proposed for them. One goal of this paper is to suggest a terminology that is uniform and informative to replace the current chaotic nomenclature another goal is to investigate the properties and interrelations of these notions in a systematic way. Following brief expositions of indexed categories diagram categories twisted relations and Kan extensions we demonstrate and then exploit the duality between institution morphisms in the original sense of Goguen and Burstall and the â€˜plain mapsâ€™ of Meseguer obtaining simple uniform proofs of completeness and cocompleteness for both resulting categories. Because of this duality we prefer the name â€˜comorphismâ€™ over â€˜plain mapâ€™ moreover we argue that morphisms are more natural than comorphisms in many cases. We also consider â€˜theoroidalâ€™ morphisms and comorphisms which generalise signatures to theories based on a theoroidal institution construction finding that the â€˜mapsâ€™ of Meseguer are theoroidal comorphisms while theoroidal morphisms are a new concept. We introduce â€˜forwardâ€™ and â€˜semi-naturalâ€™ morphisms and develop some of their properties. Appendices discuss institutions for partial algebra a variant of order sorted algebra two versions of hidden algebra and a generalisation of universal algebra these illustrate various points in the main text. A final appendix makes explicit a greater generality for the institution concept clarifies certain details and proves some results that lift institution theory to this level.;
POP A Broad-Spectrum Programming Language 1967â€“2002;This paper discusses the POP-2 language and Multipop time-sharing system developed during the second half of the 1960s. POP-2's expressiveness spanned numeric and symbolic programming and supported experiments in logic of programming languages (by Boyer and Moore) and programming language concepts (for example Michie's memoisation). The paper also discusses how the goals of POP-2 might be achieved in a successor language.;
The List Introduction Strategy for the Derivation of Logic Programs;We present a new program transformation strategy based on the introduction of lists. This strategy is an extension of the tupling strategy which is based on the introduction of tuples of fixed length. The list introduction strategy overcomes some of the limitations of the tupling strategy and in particular it makes it possible to transform general recursive programs into linear recursive ones also in cases when this transformation cannot be performed by the tupling strategy. The linear recursive programs we derive by applying the list introduction strategy have in most cases very good time and space performance because they avoid repeated evaluations of goals and unnecessary constructions of data structures.;
Dependently Typed Records in Type Theory;The language Pebble of Burstall and Lampson proposed dependent types as the underlying principle in a unified framework to explain facilities for programming in the large such as modules and signatures as well as for programming in the small. This proposal soon extended to large scale formal proof development as well. In fact the functional approach to modularity has turned out to be a hard problem which is still far from a fully satisfactory solution. This paper discusses aspects of this approach including representations of records informative signatures sharing and subtyping. My main contribution in this paper is to show that structures with dependent types and manifest fields (roughly ML style modules) are internally definable in a type theoretic framework extended with inductive-recursive definition. This shows that powerful modules follow from general principles without module-specific assumptions.;
Three Inadequate Models;The connection between operational and denotational semantics is of longstanding interest in the study of programming languages. The emphasis has been on positive results whether for adequacy or full abstraction. One normally considers the standard solution of an evident natural domain equation for the language this is generally adequate but not fully abstract if one uses any of the usual categories of domains. One then tries other categories to get improved results.Here we restrict ourselves to a standard category of domains and show for an untyped Î»-calculus with arithmetic that inadequate models exist if one considers non-standard solutions to the domain equation. One model is inadequate simpliciter a second is adequate but inadequate when the language is extended by a â€œparallel orâ€ construct the third is adequate in the latter sense but in it the Y-combinator does not denote the least fixed point operator.We also consider whether it is possible to do better than the standard solution as regards full abstraction. Surprisingly this question only makes sense for solutions which are adequate for the extended language. For these the standard solution is indeed closest to full abstraction justifying the use of non-standard categories.;
A Collection of Papers and Memoirs Celebrating the Contribution of Rod Burstall to Advances in Computer Science;are dedicated to Professor Rod Burstall and as a collection of papers memoirs and incidental pieces form a Festschrift for Rod. The contributions are made by some of the many who know Rod and have been in uenced by him. The research papers included here represent some of the areas in which Rod has been active and the editors thank their colleagues for agreeing to contribute to this Festschrift.;
A lightweight web-based case tool for sequence diagrams;This paper presents a simple lightweight Case tool to support manipulation of UML sequence diagrams. The tool is intended to have high usability to facilitate communication and discussion in the early part of the design process where sequence diagrams are frequently used to explore and explain object interaction. The tool is web-based to maximise accessibility and use by teams and uses a simple yet effective image tiling technology to allow manipulation of the diagrams from any web browser.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;At the early stages of user interface design it is important to be able to describe the contents and architecture of the interface without prematurely deciding its surface 'look and feel' and behaviour. In this paper the problems of undertaking early design in an object-oriented (OO) context are examined through consideration of the Unified Modelling Language (UML) and the Rational Unified Process (RUP). Within UML the boundary class represents the user-system interface. The work of several researchers in this area is reviewed and compared. All of the approaches selected emphasise the importance of considering user interface issues at an early stage in the development lifecycle and several important principles emerge. Problems with user interface design within the RUP are also identified and suggestions made about improvements although the detail is outside the scope of this paper.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;Few software products have been developed specifically for the severely/profoundly intellectually handicapped users. This paper examines the special hardware needs of this target group explores interface design strategies that would increase the usefulness and usability of software for them suggests types of software that has the potential to support their educational and entertainment needs and explores the special problems that these users pose when evaluating usability. This analysis is based on a set of observations of two groups of severely/profoundly intellectually handicapped high school students. The observations were further augmented by interviews with their teachers.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;Many applications now require access from diverse human-computer interaction devices such as desktop computers web browsers PDAs mobile phones pagers and so on. We describe our experiences developing a multi-device travel planning application built from reusable components many of these developed from several different previous projects. We focus on key user interface design and component adaptation and integration issues as encountered in this problem domain. We report on the results of a useability evaluation of our prototype and our current research directions addressing HCI and interface development problems we encountered.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;"Best practice in interface design suggests that hand-drawn sketches are preferable at the early stages of the design process. This paper describes the FreeForm software which supports informal sketched interface design by acting as a Visual Basic Add-In. The software utilises a digital whiteboard and pen input to support sketching and running"" of an informal prototype.""";
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;"The issue of trust in a virtual community has grown in importance as the Internet has penetrated our daily lives. We believe that co-creative communication"" or creating and sharing a context through physical activities can support trust building. This paper describes a design strategy and a prototype system for supporting co-creative communication between remote locales. We describe an ""inter-real virtual space"" which presents a virtual reflection of a local physical space into a remote locale and which provides an interface space bridging remote locales. We have implemented as a prototype for this concept a ""co-actuated table"": a round rotatable disk placed on a stable table. Each site in the ""inter-real virtual space"" has a ""co-actuated table"". The rotations of the physical disk at each site are synchronized with the appearance of the virtual disk in the inter-real virtual space and with the remote disk at other participating sites. A virtual avatar for each participant also appears in the inter-real virtual space. Initial experimental results indicate that this design is suitable for supporting co-creative communication.""";
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;In this paper we describe work in progress using transcripts of audio files generated with speech recognition software to navigate and manipulate audio information. Three applications are being developed. The first is to find and extract speech segments from a longer recording. The second is to support navigation in a recorded lecture both truncated transcript segments in display bars and full transcripts are used here. The third application is a novel audio editor permitting rearrangement of spoken text by direct manipulation of its transcript. The intended use of this software is to allow speakers to amend recorded lectures.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;This paper reports on the development of a prototype interface for a community discussion forum. The intention of the interface is to not only provide a means of access to a community forum but also to portray information about that forum to the participants. The interface is therefore being designed as being both an access mechanism to content information and a useful information visualisation tool. The interface design uses a metaphor of a 'nation of islands'. The constraints imposed by this metaphor are presented in terms of the techniques used to generate the visual representations of activity within the forum.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;Ever improving speech technology continues to revolutionise the way we interact with computers. This paper describes a speech-driven graphics system that allows the user to construct and manipulate 3-dimensional (3D) graphical images using only their voice averting the need to learn a graphics programming language or the point-and-click options of a conventional graphics software interface. The system combines an inexpensive Java-based speech-to-text package with open-source Java packages for constructive solid geometry and text-to-speech generation to create a completely hands-off graphics application. These components are integrated with context-free input/output grammars modeled from observations about the language used when a person unfamiliar with computer graphics software directs an experienced user in the creation of 3D images. The result is a natural conversation-style interface that allows anyone to make effective use of 3D-graphics packages regardless of their technical expertise.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;Although metaphor is a commonly used device in the design of user-interfaces it is not rigorously understood and most guidance stops at the recommendation of its use. In this paper we seek to provide a systematic taxonomy of user-interface metaphors based on and extending the framework of Lakoff and Johnson. We then suggest that some usability heuristics emerge directly from analysis of the taxonomy. We conclude that the taxonomy and heuristics may provide appreciable benefits in user-interface design and evaluation and address some of the criticisms of metaphor use that have been made.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;This paper presents results from a set of design sessions held in a broadcasting company. The aim of research was to find a user centered design method which includes the future users into the product development in the early stages of new product design. In this case the products were interactive television programs and applications for digital television. The study also aims at creating a design method with the user study participants as equal research partners with the designers.The study started with a user study in study participants' home environment. The user study results a set of user profiles was taken to a broadcasting company. A series of five design sessions with participants from the broadcasting company followed. New concepts of interactive television programs were designed during the design sessions. The study resulted in new concepts of interactive television programs and services for digital television that were created by both TV viewers and designers.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;Some simple approaches for reducing complexity within a prototype email system for older users are described. It is argued that these approaches while successful depend on limiting the richness of the interface and do not scale up to handling feature rich applications. Hence applications that suit older users may remain distinct from the fully featured applications needed by some younger users.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;Gesture based interfaces promise to increase the efficiency of user input particularly in mobile computing where standard input devices such as the mouse and keyboard are impractical. This paper describes an investigation into the low-level physical properties of linear 'flick' gestures that users create using mouse and pen input devices. The study was motivated by our need to determine sensible constraints on values such as the magnitude timing and angular accuracy of gestures for a marking-menu implementation. The results show that pen gestures are substantially larger than mouse gestures that angular errors are larger in the left and right directions with the pen that vertical gestures are 'awkward' with the mouse and that downwards gestures are approximately 11% slower than other directions.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;This paper reports on a study to examine the effect of display type (desktop display verses projected display) on inter-object distance estimation in real and virtual environment (VE). Non-stereo images of real and virtual environments were used as stimulus. Participants were asked to estimate two distances: transverse distance (objects lying in the sagittal plane -- in depth) and lateral distance (objects on the same horizontal line). Our result shows that distances were generally underestimated. For transverse distance no significant difference was found for real and virtual images on both type of display. On average lateral distance estimations yielded more accurate results for virtual image. Participants' performances were better on projected display compared to desktop display on both lateral and transverse distance. A significant effect of display on distance was revealed for lateral distance.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;We survey tools for colour selection reviewing their shortcomings and strengths and suggest a way of integrating their best features into a single tool.;
Proceedings of the SIGCHI-NZ Symposium on Computer-Human Interaction;The Information Age is the period of history in which products and services based on information and knowledge have principal economic value. Information artifacts are implements of use and aesthetic expressions that both reflect and create the ways in which people individually and collectively think and act. Interactive artifacts are designed to engage people in access to and development of knowledge and information. Their human computer interfaces are instances of a broader set of phenomena. Cultural creative technological and everyday frames of reference spoken languages economic positions programming languages and runtime platforms converge through the lens of the interface nexus. It is necessary to abstract and extend our notion of interface and to contextualize the operation of interfaces amidst dynamic meshworks in order to address these phenomena.With regard to life on earth ecology investigates the web of relations between interdependent organisms and their surroundings. In the Information Age people activities codes components and systems form the same kinds of interrelationships. Interfaces are the multidimensional border zones through which these relationships are constituted. Interface ecology investigates the dynamic interactions of media cultures and disciplines that flow through interfaces. The semiotic encodings of these wide-reaching systems of representation are their interactions' building blocks. Interfaces recombine semiotic codes forming hybrids.The ecosystems approach brings the perspectives of diverse disciplines to bear on what interfaces are how they work and how they can work. Disciplines and the media cultural and epistemological forms to which they apply are free to relate in meshworks opening inquiry. No system of representation dominates none are considered subordinate. Rather they are interdependent elements connected by referential flows of interaction.;
Proceedings of the 29th International Conference on Computer Graphics and Interactive Techniques. Electronic Art and Animation Catalog.;One way to reason about parallel processes is to assume that the execution of each process is subdivided into â€˜small enoughâ€™ steps and that these are executed in an interleaved fashion thus obtaining a sequential program. The steps should be so small that for any parallel execution there will in a suitable sense exist a corresponding interleaved execution ending in the same state. The usual way to ensure this is to require that each step should contain at most one global access. However if the global entities are communication channels then larger steps may in some cases be allowed and this may make reasoning about the programs easier. This paper explores these cases and discusses consequences or verification and deadlock avoidance.;
Distributing Finite Automata Through Petri Net Synthesis;The synthesis problem for Petri nets consists in deciding constructively the existence of a Petri net with sequential state graph isomorphic to a given graph. If events are attached to locations one may set as an additional requirement that the synthesised net should be distributable i.e. such that events at different locations have no common input place whence distributed conflicts are avoided. Distributable nets are easily implemented by finite families of automata (one per location) communicating with each other by asynchronous message passing. We show that the general Petri net synthesis problem and its distributed version may both be solved in time polynomial in the size of the given graph. We report on some preliminary experiments of Petri net synthesis applied to the distribution of reactive automata using the tool SYNET.;
Testing Conditions for Communicating Stream X-machine Systems;X-machines were proposed by Holcombe as a possible specification language and since then a number of further investigations have demonstrated that the model is intuitive and easy to use. In particular stream X-machines (SXM) a particular class of X-machines have been found to be extremely useful in practice. Furthermore a method of testing systems specified as SXMs exists and is proved to detect all faults of the implementation provided that the system meets certain â€œdesign for test conditionsâ€. Recently a system of communicating SXMs was introduced as a means of modelling parallel processing. This paper proves that each communicating machine component can be transformed in a straightforward manner so that the entire system will behave like a single stream X-machine - the equivalent SXM of the system. The paper goes on to investigate the applicability of the SXM testing method to a system of communicating SXMs and identifies a class of communicating SXMs for which the equivalent SXM of the system meets the â€œdesign for test conditionsâ€.;
On the Use of Data Refinement in the Development of Secure Communications Systems;We report on experiences gained from the application of data refinement techniques to the development of examples of secure communications systems. The aim was to the carry the development from initial abstract specification of security services through to detailed designs. The development approach was based on action systems with B and CSP being used as concrete notations. The security services in question are a confidential communications service and an authenticated transaction service. Refinements include explicit representations of intruder behaviour. The paper makes several interrelated contributions. It demonstrates the feasibility of applying a refinement approach to this type of problem including an effective way of combining B and CSP in refinements. It introduces a more systematic approach to the development of abstraction invariants and refinement checking. Finally it illustrates the limitation when modelling security protocols of a formalism that does not deal with probability.;
Dynamical Quantities in Net Systems;The paper presents some known material of higher-level Petri nets in analogy to the dynamics of physical systems. Its aim is to widen the view on the role of the incidence matrix in the analysis of net systems. Rather than focusing on constant state quantities (S-invariants) and cyclic actions (T-invariants) i.e. on solutions of the homogeneous equation systems based on the incidence matrix it studies dynamical quantities of net systems in general.;
A Refinement Calculus for Shared-Variable Parallel and Distributed Programming;Parallel computers have not yet had the expected impact on mainstream computing. Parallelism adds a level of complexity to the programming task that makes it very error-prone. Moreover a large variety of very different parallel architectures exists. Porting an implementation from one machine to another may require substantial changes. This paper addresses some of these problems by developing a formal basis for the design of parallel programs in the form of a refinement calculus. The calculus allows the stepwise formal derivation of an abstract low-level implementation from a trusted high-level specification. The calculus thus helps structuring and documenting the development process. Portability is increased because the introduction of a machine-dependent feature can be located in the refinement tree. Development efforts above this point in the tree are independent of that feature and are thus reusable. Moreover the discovery of new possibly more efficient solutions is facilitated. Last but not least programs are correct by construction which obviates the need for difficult debugging. Our programming/specification notation supports fair parallelism shared-variable and message-passing concurrency local variables and channels. The calculus rests on a compositional trace semantics that treats shared-variable and message-passing concurrency uniformly. The refinement relation combines a context-sensitive notion of trace inclusion and assumption-commitment reasoning to achieve compositionality. The calculus straddles both concurrency paradigms that is a shared-variable program can be refined into a distributed message-passing program and vice versa.;
Software engineering;Software engineering is the disciplined application of theories and techniques from computer science to define develop deliver and maintain on time and within budget software products that meet customers' needs and expectations. Software products include the actual program source code and data structures (q.v.) as well as the documents necessary to produce these and documents and interface programs necessary to use them in the intended environment.;
Encyclopedia of Computer Science;Computer-aided software engineering (CASE) encompasses computer-based procedures techniques and tools which can be used to develop maintain and reengineer software. CASE is to the software engineer as computer-aided design/computer-aided manufacturing (CAD/CAM) (q.v.) is to the mechanical engineer and computer-aided electrical engineering (CAEE) is to the electrical engineer. Although the variety of technological alternatives can be bewildering the concepts of CASE provide a common-sense approach to engineering quality software more productively.;
Encyclopedia of Computer Science;Software project management is concerned with managing the resources and work activities needed to develop and modify software-intensive systems. The primary success criteria for software managers are delivery of systems that satisfy stated needs and requirements on time and within budget. Goals for software project managers include better quality increased productivity and improved predictability of software development efforts.;
Encyclopedia of Computer Science;The Software Engineering Institute (SEI) is a federally funded research and development center operated by Carnegie Mellon University in Pittsburgh Pennsylvania. The institute was competitively awarded to Carnegie Mellon in December 1984 by the US Department of Defense (DoD) to improve the state of the practice of software engineering. It was established because the DoD recognized the need for advances in software practice in order to develop higher quality systems more economically.;
Encyclopedia of Computer Science;A software prototype is an executable model of a proposed software system that accurately reflects chosen aspects of the system such as display formats the values computed or response times. Software prototyping is an approach to software development that uses prototypes to help both the developers and their customers visualize the proposed system and predict its properties in an iterative process as shown in Fig. 1.;
Encyclopedia of Computer Science;Programming support environments are software tools that improve programmer productivity and enhance the usability of programming languages. All modern programming languages provide some programming support features such as debugging tools. The Ada (q.v.) language project in particular has emphasized its programming support environment (APSE) from the start. Advanced environments can support programmers in designing coding debugging testing maintaining browsing documenting project tracking reverse engineering and customizing software. In addition online help and embedded instructions assist programmers learning to use programming environments. Some environments support groups of programmers who work collaboratively on large software development projects. CASE (computer-aided software engineering) tools automate aspects of the software development process and encourage the use of particular programming methodologies.;
Encyclopedia of Computer Science;Object-oriented analysis and design (OOAD) is a software engineering approach to constructing software systems by building object-oriented models that abstract key aspects of the target system and by using the models to guide the development process. The model concepts and the notation are intended to capture design decisions that have a large impact on the final system.;
Encyclopedia of Computer Science;The computing profession is the people and institutions that have been created to take care of other people's concerns in information processing and coordination through worldwide communication systems. The profession contains various specialties such as computer science computer engineering software engineering information systems domain-specific applications and computer systems. The discipline of computer science is the body of knowledge and practices used by computing professionals in their work (see PERSONNEL IN THE COMPUTER FIELD).;
Encyclopedia of Computer Science;"From the outset the development of software has been directed toward the apparently contradictory but in fact complementary goals of bringing the computer closer to the user while keeping the user at a distance. The first goal has involved the creation of programming languages and systems to facilitate the development of the applications that make the computer useful. The second has included the operating systems that oversee these applications and manage the hardware and software resources on which they draw. Looking back from the 1990s one may divide the history of software into two major periods: an industrial period during which the main areas of software--programming languages operating systems data handling and software tools techniques and methodologies--were established and a consumer period during which those products were adapted to the personal computer and to the needs and interests of nonexpert users. The second stage in particular has focused on making computers user-friendly"" by interposing layers of transparent software between the user and the machine (see TRANSPARENCY).""";
Encyclopedia of Computer Science;The term software testing can refer to any planned risk-reducing activity that takes place during software development operation or maintenance. Examples of such activities include: (1) analyzing system requirements (2) experimentation with prototypes (3) static reviews of designs and other intermediate engineering products (4) static and dynamic analysis of software products and (5) retesting software products during maintenance. As these example show software testing occurs at many stages of software development and operation. The article being analyzed during a test may be the actual software product an early specification of its design or a model of its intended use.;
Encyclopedia of Computer Science;It is imperative to access the correctness of software for critical applications prior to actual use. Ideally we would like to verify formally that a program is correct. However besides the practical difficulties encountered in applying current formal verification techniques to large programs they cannot cope with the possibility of specification errors. An alternative approach is to use statistical methods to estimate the reliability of the software based on the outcome of program testing.;
Encyclopedia of Computer Science;A software monitor is according to its most general definition a piece of software used for performance measurement purposes. Like other types of instruments (e.g. hardware monitors) a software monitor is capable of measuring the performance of two kinds of objects--computer systems and computer programs. A system-oriented monitor usually measures system performance indices (e.g. response or turnaround times throughput (q.v.) rates component utilizations) as well as system and workload variables (e.g. CPU time demands memory space demands paging rates degrees of multiprogramming--q.v.). A program-oriented monitor is usually capable of measuring such program performance indices as execution times instruction execution counts and frequencies total CPU times uniterrupted CPU interval durations numbers and types of I/O operations performed and so on.;
Encyclopedia of Computer Science;"Software reusability is an attribute of software that facilitates its incorporation into new application programs. Reusable software shares many attributes in common with good"" software (e.g. transportability maintainability flexibility understandability usability and reliability).""";
