Título;Resumo;Selecionado
Compiling a benchmark of documented multi-threaded bugs;Summary form only given. Testing multithreaded, concurrent, or distributed programs is acknowledged to be a very difficult task. We decided to create a benchmark of programs containing documented multithreaded bugs that can be used in the development of testing tool for the domain. In order to augment the benchmark with a sizable number of programs, we assigned students in a software testing class to write buggy multithreaded Java programs and document the bugs. This paper documents this experiment. We explain the task that was given to the students, go over the bugs that they put into the programs both intentionally and unintentionally, and show our findings. We believe this part of the benchmark shows typical programming practices, including bugs, of novice programmers. In grading the assignments, we used our technologies to look for undocumented bugs. In addition to finding many undocumented bugs, which was not surprising given that writing correct multithreaded code is difficult, we also found a number of bugs in our tools. We think this is a good indication of the expected utility of the benchmark for multithreaded testing tool creators.;1
Extraction of Bug Localization Benchmarks from History;Researchers have proposed a number of tools for automatic bug localization. Given a program and a description of the failure, such tools pinpoint a set of statements that are most likely to contain the bug. Evaluating bug localization tools is a difficult task because existing benchmarks are limited in size of subjects and number of bugs. In this paper we present iBUGS, an approach that semiautomatically extracts benchmarks for bug localization from the history of a project. For ASPECTJ, we extracted 369 bugs, 223 out of these had associated test cases. We demonstrate the relevance of our dataset with a case study on the bug localization tool AMPLE.;1
Clash of the Titans: Tools and Techniques for Hunting Bugs in Concurrent Programs;In this work we focus on creating a benchmark suite of concurrent programs for various programming languages to evaluate the bug detection capabilities of various tools and techniques. We have compiled a set of Java benchmarks from various sources and our own efforts. For many of the Java examples we have created equivalent C# programs. All the benchmarks are available for download. In our multi-language benchmark suite we compare results from various tools: CalFuzzer, ConTest, CHESS, and Java Pathfinder. In Java Pathfinder we provide extensive results for state-less random walk, randomized depth-first search, and guided search using abstraction refinement. Using data from our study we argue that iterative context-bounding and dynamic partial order reduction are not sufficient to render model checking for testing concurrent programs tractable and secondary techniques such as guidance strategies are required. As part of this work, we have also created a wiki to publish benchmark details and data from various tools on those benchmarks to a broader research community.;1
(Un-)Covering Equivalent Mutants;"Mutation testing measures the adequacy of a test suite by seeding artificial defects (mutations) into a program. If a test suite fails to detect a mutation, it may also fail to detect real defects-and hence should be improved. However, there also are mutations which keep the program semantics unchanged and thus cannot be detected by any test suite. Such equivalent mutants must be weeded out manually, which is a tedious task. In this paper, we examine whether changes in coverage can be used to detect non equivalent mutants: If a mutant changes the coverage of a run, it is more likely to be non-equivalent. In a sample of 140 manually classified mutations of seven Java programs with 5,000 to 100,000 lines of code, we found that: (a) the problem is serious and widespread-about 45% of all undetected mutants turned out to be equivalent; (b) manual classification takes time-about 15 minutes per mutation; (c) coverage is a simple, efficient, and effective means to identify equivalent mutants-with a classification precision of 75% and a recall of 56%; and (d) coverage as an equivalence detector is superior to the state of the art, in particular violations of dynamic invariants. Our detectors have been released as part of the open source JAVALANCHE framework; the data set is publicly available for replication and extension of experiments.";1
Empirical Evaluation of Bug Linking;To collect software bugs found by users, development teams often set up bug trackers using systems such as Bugzilla. Developers would then fix some of the bugs and commit corresponding code changes into version control systems such as svn or git. Unfortunately, the links between bug reports and code changes are missing for many software projects as the bug tracking and version control systems are often maintained separately. Yet, linking bug reports to fix commits is important as it could shed light into the nature of bug fixing processes and expose patterns in software management. Bug linking solutions, such as ReLink, have been proposed. The demonstration of their effectiveness however faces a number of issues, including a reliability issue with their ground truth datasets as well as the extent of their measurements. We propose in this study a benchmark for evaluating bug linking solutions. This benchmark includes a dataset of about 12,000 bug links from 10 programs. These true links between bug reports and their fixes have been provided during bug fixing processes. We designed a number of research questions, to assess both quantitatively and qualitatively the effectiveness of a bug linking tool. Finally, we apply this benchmark on ReLink to report the strengths and limitations of this bug linking tool.;1
The Eclipse and Mozilla Defect Tracking Dataset: A Genuine Dataset for Mining Bug Information;The analysis of bug reports is an important subfield within the mining software repositories community. It explores the rich data available in defect tracking systems to uncover interesting and actionable information about the bug triaging process. While bug data is readily accessible from systems like Bugzilla and JIRA, a common database schema and a curated dataset could significantly enhance future research because it allows for easier replication. Consequently, in this paper we propose the Eclipse and Mozilla Defect Tracking Dataset, a representative database of bug data, filtered to contain only genuine defects (i.e., no feature requests) and designed to cover the whole bug-triage life cycle (i.e., store all intermediate actions). We have used this dataset ourselves for predicting bug severity, for studying bug-fixing time and for identifying erroneously assigned components. Sharing these data with the rest of the community will allow for reproducibility, validation and comparison of the results obtained in bug report analyses and experiments.;1
42 Variability Bugs in the Linux Kernel: A Qualitative Analysis;Feature-sensitive verification pursues effective analysis of the exponentially many variants of a program family. However, researchers lack examples of concrete bugs induced by variability, occurring in real large-scale systems. Such a collection of bugs is a requirement for goal-oriented research, serving to evaluate tool implementations of feature-sensitive analyses by testing them on real bugs. We present a qualitative study of 42 variability bugs collected from bug-fixing commits to the Linux kernel repository. We analyze each of the bugs, and record the results in a database. In addition, we provide self-contained simplified C99 versions of the bugs, facilitating understanding and tool evaluation. Our study provides insights into the nature and occurrence of variability bugs in a large C software system, and shows in what ways variability affects and increases the complexity of software bugs.;1
Defects4J: A Database of Existing Faults to Enable Controlled Testing Studies for Java Programs;Empirical studies in software testing research may not be comparable, reproducible, or characteristic of practice. One reason is that real bugs are too infrequently used in software testing research. Extracting and reproducing real bugs is challenging and as a result hand-seeded faults or mutants are commonly used as a substitute. This paper presents Defects4J, a database and extensible framework providing real bugs to enable reproducible studies in software testing research. The initial version of Defects4J contains 357 real bugs from 5 real-world open source pro- grams. Each real bug is accompanied by a comprehensive test suite that can expose (demonstrate) that bug. Defects4J is extensible and builds on top of each program’s version con- trol system. Once a program is configured in Defects4J, new bugs can be added to the database with little or no effort. Defects4J features a framework to easily access faulty and fixed program versions and corresponding test suites. This framework also provides a high-level interface to common tasks in software testing research, making it easy to con- duct and reproduce empirical studies. Defects4J is publicly available at http://defects4j.org.;1
On the Effectiveness of Information Retrieval Based Bug Localization for C Programs;Localizing bugs is important, difficult, and expensive, especially for large software projects. To address this problem, information retrieval (IR) based bug localization has increasingly been used to suggest potential buggy files given a bug report. To date, researchers have proposed a number of IR techniques for bug localization and empirically evaluated them to understand their effectiveness. However, virtually all of the evaluations have been limited to the projects written in object-oriented programming languages, particularly Java. Therefore, the effectiveness of these techniques for other widely used languages such as C is still unknown. In this paper, we create a benchmark dataset consisting of more than 7,500 bug reports from five popular C projects and rigorously evaluate our recently introduced IR-based bug localization tool using this dataset. Our results indicate that although the IR-relevant properties of C and Java programs are different, IR-based bug localization in C software at the file level is overall as effective as in Java software. However, we also find that the recent advance of using program structure information in performing bug localization gives less of a benefit for C software than for Java software.;1
Automated Bug Finding in Video Games: A Case Study for Runtime Monitoring;Runtime verification is the process of observing a sequence of events generated by a running system and comparing it to some formal specification for potential violations. We show how the use of a runtime monitor can greatly speed up the testing phase of a video game under development by automating the detection of bugs when the game is being played. We take advantage of the fact that a video game, contrarily to generic software, follows a special structure that contains a “game loop.” This game loop can be used to centralize the instrumentation and generate events based on the game's internal state. We report on experiments made on a sample of six real-world video games of various genres and sizes by successfully instrumenting and efficiently monitoring various temporal properties over their execution, including actual bugs reported in the games' bug tracking database in the course of their development.;1
A Dataset of High Impact Bugs: Manually-Classi?ed Issue Repors;The importance of supporting test and maintenanceactivities in software development has been increasing, sincerecent software systems have become large and complex. Al-though in the ?eld of Mining Software Repositories (MSR) thereare many promising approaches to predicting, localizing, andtriaging bugs, most of them do not consider impacts of eachbug on users and developers but rather treat all bugs with equalweighting, excepting a few studies on high impact bugs includingsecurity, performance, blocking, and so forth. To make MSRtechniques more actionable and effective in practice, we needdeeper understandings of high impact bugs. In this paper weintroduced our dataset of high impact bugs which was createdby manually reviewing four thousand issue reports in four opensource projects (Ambari, Camel, Derby and Wicket.;1
The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs;The field of automated software repair lacks a set of common benchmark problems. Although benchmark sets are used widely throughout computer science, existing benchmarks are not easily adapted to the problem of automatic defect repair, which has several special requirements. Most important of these is the need for benchmark programs with reproducible, important defects and a deterministic method for assessing if those defects have been repaired. This article details the need for a new set of benchmarks, outlines requirements, and then presents two datasets, ManyBugs and IntroClass, consisting between them of 1,183 defects in 15 C programs. Each dataset is designed to support the comparative evaluation of automatic repair algorithms asking a variety of experimental questions. The datasets have empirically defined guarantees of reproducibility and benchmark quality, and each study object is categorized to facilitate qualitative evaluation and comparisons by category of bug or program. The article presents baseline experimental results on both datasets for three existing repair methods, GenProg, AE, and TrpAutoRepair, to reduce the burden on researchers who adopt these datasets for their own comparative evaluations.;1
TaxDC: A Taxonomy of Non-Deterministic Concurrency Bugs in Data Center Distributed Systems;We present TaxDC, the largest and most comprehensive taxonomy of non-deterministic concurrency bugs in distributed systems. We study 104 distributed concurrency (DC) bugs from four widely-deployed cloud-scale datacenter distributed systems, Cassandra, Hadoop MapReduce, HBase and ZooKeeper. We study DC-bug characteristics along several axes of analysis such as the triggering timing condition and input preconditions, error and failure symptoms, and fix strategies, collectively stored as 2,083 classification labels in TaxDC database. We discuss how our study can open up many new research directions in combating DC bugs.;1
A Feasibility Study of Using Automated Program Repair for Introductory Programming Assignments;"Despite the fact an intelligent tutoring system for programming (ITSP) education has long attracted interest, its widespread use has been hindered by the difficulty of generating personalized feedback automatically. Meanwhile, automated program repair (APR) is an emerging new technology that automatically fixes software bugs, and it has been shown that APR can fix the bugs of large real-world software. In this paper, we study the feasibility of marrying intelligent programming tutoring and APR. We perform our feasibility study with four state-of-the-art APR tools (GenProg, AE, Angelix, and Prophet), and 661 programs written by the students taking an introductory programming course. We found that when APR tools are used out of the box, only about 30% of the programs in our dataset are repaired. This low repair rate is largely due to the student programs often being significantly incorrect - in contrast, professional software for which APR was successfully applied typically fails only a small portion of tests. To bridge this gap, we adopt in APR a new repair policy akin to the hint generation policy employed in the existing ITSP. This new repair policy admits partial repairs that address part of failing tests, which results in 84% improvement of repair rate. We also performed a user study with 263 novice students and 37 graders, and identified an understudied problem; while novice students do not seem to know how to effectively make use of generated repairs as hints, the graders do seem to gain benefits from repairs.";1
Automatic detection and demonstrator generation for information ?ow leaks in object-oriented programs;We present a method to generate automatically exploits for information flow leaks in object-oriented programs. The goal, similar to white-box test generation, is to automatically produce executable, reusable test cases that challenge a given information flow policy with a very high degree of guaranteed coverage. Our approach combines self-composition and symbolic execution to create an insecurity formula for a given program and information flow policy. Satisfiability of this formula signifies the presence of information leaks and permits to use model generation for creating exploits. We support different kinds of information flow policies like noninterference, delimited information release, and information erasure. A prototypic tool implementation for Java programs of our approach is available. It generates exploits in the form of self contained, executable JUnit tests. We evaluate our method and tool based on a set of micro-benchmarks and a case-study on e-voting.;1
Code?aws: A Programming Competition Benchmark for Evaluating Automated Program Repair Tools;Several automated program repair techniques have been proposed to reduce the time and effort spent in bugfixing. While these repair tools are designed to be generic such that they could address many software faults, different repair tools may fix certain types of faults more effectively than other tools. Therefore, it is important to compare more objectively the effectiveness of different repair tools on various fault types. However, existing benchmarks on automated program repairs do not allow thorough investigation of the relationship between fault types and the effectiveness of repair tools. We present Codeflaws, a set of 3902 defects from 7436 programs automatically classified across 39 defect classes (we refer to different types of fault as defect classes derived from the syntactic differences between a buggy program and a patched program).;1
ELIXIR: Effective Object-Oriented Program Repair;"This work is motivated by the pervasive use of method invocations in object-oriented (OO) programs, and indeed their prevalence in patches of OO-program bugs. We propose a generate-and-validate repair technique, called ELIXIR designed to be able to generate such patches. ELIXIR aggressively uses method calls, on par with local variables, fields, or constants, to construct more expressive repair-expressions, that go into synthesizing patches. The ensuing enlargement of the repair space, on account of the wider use of method calls, is effectively tackled by using a machine-learnt model to rank concrete repairs. The machine-learnt model relies on four features derived from
the program context, i.e., the code surrounding the potential repair location, and the bug report. We implement ELIXIR and evaluate it on two datasets, the popular Defects4J dataset and a new dataset Bugs.jar created by us, and against 2 baseline versions of our technique, and 5 other techniques representing the state of the art in program repair. Our evaluation shows that ELIXIR is able to increase the number of correctly repaired bugs in Defects4J by 85% (from 14 to 26) and by 57% in Bugs.jar (from 14 to 22), while also significantly out-performing other state-ofthe-art repair techniques including ACS, HD-Repair, NOPOL, PAR, and jGenProg.";1
How Developers Debug Software The DBGBENCH Dataset;How do professional software engineers debug computer programs? In an experiment with 27 real bugs that existed in several widely used programs, we invited 12 professional software engineers, who together spent one month on localizing, explaining, and fixing these bugs. This did not only allow us to study the various tools and strategies used to debug the same set of errors. We could also determine exactly which statements a developer would localize as faults, how a developer would diagnose and explain an error, and how a developer would fix an error – all of which software engineering researchers seek to automate. Until now, it has been difficult to evaluate the effectiveness and utility of automated debugging techniques without a user study. We publish the collected data, called DBGBENCH, to facilitate the effective evaluation of automated fault localization, diagnosis, and repair techniques w.r.t. the judgement of human experts.;1
QuixBugs: a multi-lingual program repair benchmark set based on the Quixey challenge;Recent years have seen an explosion of work in automated program repair. While previous work has focused exclusively on tools for single languages, recent work in multi language transformation has opened the door for multi-language program repair tools. Evaluating the performance of such a tool requires having a benchmark set of similar buggy programs in different languages. We present QuixBugs, consisting of 40 programs translated to both Python and Java, each with a bug on a single line. The QuixBugs benchmark suite is based on problems from the Quixey Challenge, where programmers were given a short buggy program and 1 minute to fix the bug.;1
Secbench: A Database of Real Security Vulnerabilitie;"Currently, to satisfy the high number of system requirements, complex software is created which turns its development costintensive and more susceptible to security vulnerabilities. In software security testing, empirical studies typically use artificial faulty programs because of the challenges involved in the extraction or reproduction of real security vulnerabilities. Thus, researchers tend to use hand-seeded faults or mutations to overcome these issues which might not be suitable for software testing techniques since the two approaches can create samples that inadvertently differ from the real vulnerabilities and thus might lead to misleading assessments of the capabilities of the tools. Although there are databases targeting security vulnerabilities test cases, one database contains only real vulnerabilities, the other ones are a mix
of real and artificial or even only artificial samples. Secbench is a database of real security vulnerabilities mined from Github which hosts millions of open-source projects carrying a considerable number of security vulnerabilities. We mined 248 projects - accounting to almost 2M commits - for 16 different vulnerability patterns, yielding a Database with 682 real security vulnerabilities.";1
Crashing Simulated Planes is Cheap: Can Simulation Detect Robotics Bugs Early?;Robotics and autonomy systems are becoming increasingly important, moving from specialised factory domains to increasingly general and consumer-focused applications. As such systems grow ubiquitous, there is a commensurate need to protect against potentially catastrophic harm. System-level testing in simulation is a particularly promising approach for assuring robotics systems, allowing for more extensive testing in realistic scenarios and seeking bugs that may not manifest at the unit-level. Ideally, such testing could find critical bugs well before expensive field-testing is required. However, simulations can only model coarse environmental abstractions, contributing to a common perception that robotics bugs can only be found in live deployment. To address this gap, we conduct an empirical study on bugs that have been fixed in the widely used, opensource ARDUPILOT system. We identify bug-fixing commits by exploiting commenting conventions in the version-control history. We provide a quantitative and qualitative evaluation of the bugs, focusing on characterising how the bugs are triggered and how they can be detected, with a goal of identifying how they can be best identified in simulation, well before field testing. To our surprise, we find that the majority of bugs manifest under simple conditions that can be easily reproduced in software-based simulation. Conversely, we find that system configurations and forms of input play an important role in triggering bugs. We use these results to inform a novel framework for testing for these and other bugs in simulation, consistently and reproducibly. These contributions can inform the construction of techniques for automated testing of robotics systems, with the goal of finding bugs early and cheaply, without incurring the costs of physically testing for bugs in live systems.;1
Large-Scale Analysis of Framework-Speci?c Exceptions in Android Apps;"Mobile apps have become ubiquitous. For app developers, it is a key priority to ensure their apps' correctness and reliability. However, many apps still suffer from occasional to frequent crashes, weakening their competitive edge. Large-scale, deep analyses of the characteristics of real-world app crashes can provide useful insights to guide developers, or help improve testing and analysis tools. However, such studies do not exist — this paper fills this gap. Over a four-month long effort, we have collected 16,245 unique exception traces from 2,486 open-source Android apps, and observed that framework-specific exceptions account for the majority of these crashes. We then extensively investigated the 8,243 framework-specific exceptions (which took six person-months): (1) identifying their characteristics (e.g., manifestation locations, common fault categories), (2) evaluating their manifestation via state-of-the-art bug detection techniques, and (3) reviewing their fixes. Besides the insights they provide, these findings motivate and enable follow-up research on mobile apps, such as bug detection, fault localization and patch generation. In addition, to demonstrate the utility of our findings, we have optimized Stoat, a dynamic testing tool, and implemented ExLocator, an exception localization tool, for Android apps. Stoat is able to quickly uncover three previously-unknown, confirmed/fixed crashes in Gmail and Google+; ExLocator is capable of precisely locating the root causes of identified exceptions in real-world apps. Our substantial dataset is made publicly available to share with and benefit the community.";1
Mining repair model for exception-related bug;It has long been a hot research topic to detect and to repair bugs automatically. As a common practice, researchers propose approaches for specific bugs, and their approaches typically are limited in handling the variety among bugs. Recently, researchers start to explore automatic program repair. With predefined repair operators and test cases, test-based repair approaches use search algorithms to generate patches for a bug, until a patch passes all the test cases. To improve the effectiveness to generate patches, Martinez and Monperrus (2013b) proposed an approach that mines repair models from past fixes. Although their approach produces positive results, we argue that it can be feasible to further improve their approach, if we mine repair models for bug categories, instead of all bugs. However, the benefits are still unclear, since existing benchmarks do not classify bugs into categories and existing approaches cannot mine repair models for bug categories. In this paper, we implement a tool, called ExFi, that classifies bugs into categories based on their related exceptions. With its support, we construct a benchmark, in which bug categories are marked. Furthermore, we propose an approach, called MiMo, that mines a repair model for each exception. We compared the general repair model with our mined repair models. Our results show that our mined models are all significantly different from the general model. Outside of the projects where our models are mined, we selected 59 real bugs. For each bug, we used our models and the general model to generate correct repair shapes for these bugs. The results show that for 43 out of 59 bugs, our models found faster a correct shape than the general repair model (Martinez and Monperrus, 2013b), and for 5 bugs, our models were able to find correct shapes that were not found by the compared model.;1
Pairika-A Failure Diagnosis Benchmark for C++ Programs;Empirical studies in software testing require realistic benchmarks which are able to mimic industry-like environments. For evaluating automated failure diagnosis techniques, one needs real reproducible bugs with at least one associated failing test. Extracting such bugs is challenging and time-consuming. This paper presents Pairika, a failure diagnosis benchmark for C++ programs. Pairika contains 40 bugs extracted from 7 modules of OpenCV project with more than 490 KLoC and 11129 tests. Each bug is accompanied by at least one failing test. We publish Pairika to facilitate and stimulate further research on automated failure diagnosis techniques. Pairika is available at: https://github.com/tum-i22/Pairika;1
Repairing Crashes in Android Apps;"Android apps are omnipresent, and frequently suffer from crashes — leading to poor user experience and economic loss. Past work focused on automated test generation to detect crashes in Android apps. However, automated repair of crashes has not been studied. In this paper, we propose the first approach to automatically repair Android apps, specifically we propose a technique for fixing crashes in Android apps. Unlike most test-based repair approaches, we do not need a test-suite; instead a single failing test is meticulously analyzed for crash locations and reasons behind these crashes. Our approach hinges on a careful empirical study which seeks to establish common root-causes for crashes in Android apps, and then distills the remedy of these root-causes in the form of eight generic transformation operators. These operators are applied using a search-based repair framework embodied in our repair tool Droix. We also prepare a benchmark DroixBench capturing reproducible crashes in Android apps. Our evaluation of Droix on DroixBench reveals that the automatically produced patches are often syntactically identical to the human patch, and on some rare occasion even better than the human patch (in terms of avoiding regressions). These results confirm our intuition that our proposed transformations form a sufficient set of operators to patch crashes in Android.";1
A Fault Localization and Debugging Support Framework driven by Bug Tracking Data;Fault localization has been determined as a major resource factor in the software development life cycle. Academic fault localization techniques are mostly unknown and unused in professional environments. Although manual debugging approaches can vary significantly depending on bug type (e.g. memory bugs or semantic bugs), these differences are not reflected in most existing fault localization tools. Little research has gone into automated identification of bug types to optimize the fault localization process. Further, existing fault localization techniques leverage on historical data only for augmentation of suspiciousness rankings. This thesis aims to provide a fault localization framework by combining data from various sources to help developers in the fault localization process. To achieve this, a bug classification schema is introduced, benchmarks are created, and a novel fault localization method based on historical data is proposed.;
Poster: EBFL-An Ensemble Classifier based Fault Localization;Fault localization (FL) is the most arduous and timeconsuming task during software debugging. It is delineated in the literature that different FL methods show superior results under distinct scenarios. There is no single technique available that always outperforms all other existing FL techniques for each type of fault. It has also been reported that different learning techniques can be combined using an ensemble classifier to generate better predictive performance that was impossible to be obtained with any of the constituent learning algorithms separately. This has motivated us to use an ensemble classifier for effective fault localization. We focus on three different families of fault localization techniques, viz., neural-network-based(NNBFL), mutation-based(MBFL), and spectrum-based(SBFL), to achieve this. In total, we have considered eleven representative techniques from these three families of FL methods. The proposed underlying model is intuitive and simple as it is based only on the test execution results and statement coverage data. Our proposed Ensemble classifier Based FL (EBFL) method classifies the statements into two different sets viz., Non-Suspicious and Suspicious. It helps to reduce the search space significantly. Our experimental analysis shows that our proposed EBFL technique requires, on average, 58% of less code examination compared to the other contemporary fault localization techniques, viz., Tarantula, DStar, CNN, DNN etc.;
Using Defect Prediction to Improve the Bug Detection Capability of Search-Based Software Testing;Automated test generators, such as search based software testing (SBST) techniques, replace the tedious and expensive task of manually writing test cases. SBST techniques are effective at generating tests with high code coverage. However, is high code coverage sufficient to maximise the number of bugs found? We argue that SBST needs to be focused to search for test cases in defective areas rather in non-defective areas of the code in order to maximise the likelihood of discovering the bugs. Defect prediction algorithms give useful information about the bug-prone areas in software. Therefore, we formulate the objective of this thesis: Improve the bug detection capability of SBST by incorporating defect prediction information. To achieve this, we devise two research objectives, i.e., 1) Develop a novel approach ( (SBSTCL)) that allocates time budget to classes based on the likelihood of classes being defective, and 2) Develop a novel strategy ( (SBSTCL)) to guide the underlying search algorithm (i.e., genetic algorithm) towards the defective areas in a class. Through empirical evaluation on 434 real reported bugs in the Defects4J dataset, we demonstrate that our novel approach, (SBSTCL), is significantly more efficient than the state of the art SBST when they are given a tight time budget in a resource constrained environment.;
Field Testing of Software Applications;When interacting with their software systems, users may have to deal with problems like crashes, failures, and program instability. Faulty software running in the field is not only the consequence of ineffective in-house verification and validation techniques, but it is also due to the complexity and diversity of the interactions between an application and its environment. Many of these interactions can be hardly predicted at testing time, and even when they could be predicted, often there are so many cases to be tested that they cannot be all feasibly addressed before the software is released. This Ph.D. thesis investigates the idea of addressing the faults that cannot be effectively addressed in house directly in the field, exploiting the field itself as testbed for running the test cases. An enormous number of diverse environments would then be available for testing, giving the possibility to run many test cases in many different situations, timely revealing the many failures that would be hard to detect otherwise.;
Improving spectrum-based fault localization using proximity-based weighting of test cases;Spectrum based fault localization techniques such as Tarantula and Ochiai calculate the suspiciousness score of a program statement using the number of failing and passing test cases that execute the statement. These techniques implicitly assume that all test cases are equally important. However, research on test case generation and selection techniques has shown that using certain test cases can lead to more effective fault localization than others. The proposed research aims to improve the effectiveness of spectrum based fault localization by incorporating the relative importance of different test cases in the calculation of suspiciousness scores.;
Software Security Vulnerabilities: Baselining and Benchmarking;The security of a company's software products is of paramount importance, of course, and arguably even more important than software reliability and the other key quality attributes. But companies are currently faced with a troublesome dilemma: Supplying customers with more features at greater speeds than in the past has become the norm;
Genetic Algorithm and Its Application in Software Test Data Generation;Genetic algorithm is a computational technique that simulates the process of natural selection to solve complex problems. It has been widely applied in various fields, including software engineering. One of its applications in software engineering is test data generation. Test data generation is an important component of software testing, aimed at ensuring the quality and reliability of software systems. However, generating effective test data can be challenging and time-consuming, especially for complex systems with large input domains. Genetic algorithm provides a solution to this problem by using population based search methods to generate test data that meets specific criteria. This algorithm starts from the initial population of random test cases and iteratively evolves them through selection, crossover, and mutation operations until a satisfactory solution is found. The effectiveness of genetic algorithms in generating test data has been proven in various studies. It has been proven to generate various effective test cases, covering different parts of the input domain, and revealing hidden faults in the system. In short, genetic algorithms are a powerful tool for software engineers to generate effective test data for complex systems. Its application can significantly improve the quality and reliability of software systems by identifying hidden faults that may not have been discovered. In this study, we analyzed genetic algorithms in current software testing, controlled them based on model data and generation structure in software testing, and obtained effective calculation methods based on various genetic algorithms. By using traditional genetic algorithms and various swarm genetic algorithms to analyze the distribution and optimal value interval of two curves, it is shown that various swarm genetic methods have strong optimization ability, high accuracy, and can quickly jump out of local optima to obtain the final solution. They are a very effective optimization algorithm.;
Improving Automated Crash Reproduction;Fixing bugs is a lengthy process which currently requires several manual steps to be undertaken by a developer. Reproducing a crash often takes a significant amount of time during this process, as it requires a developer to identify where the crash occurred and where the taint began, thus leading to the crash. Several tools, such as EvoCrash, STAR, and Beacon, have been created to automate this process. Proposed research includes creating a benchmark dataset, performing an empirical evaluation of fitness functions for crash reproduction, and combining both evolutionary and static approaches to reduce search spaces and increase the effectiveness of automated crash reproduction tools.;
A Method and Experiment to evaluate Deep Neural Networks as Test Oracles for Scientific Software;Testing scientific software is challenging because usually such type of systems have non-deterministic behaviours and, in addition, they generate non-trivial outputs such as images. Artificial intelligence (AI) is now a reality which is also helping in the development of the software testing activity. In this article, we evaluate seven deep neural networks (DNNs), precisely deep convolutional neural networks (CNNs) with up to 161layers, playing the role of test oracle procedures for testing scientific models. Firstly, we propose a method, TOrC, which starts by generating training, validation, and test image datasets via combinatorial interaction testing applied to the original codes and second-order mutants. Within TOrC we also have classical steps such as transfer learning, a technique recommended for DNNs. Then, we verified the performance of the oracles (CNNs). The main conclusions of this research are: i) not necessarily a greater number of layers means that a CNN will present better performance;
Improving the Software Logging Practices in DevOps;DevOps refers to a set of practices dedicated to accelerating modern software engineering process. It breaks the barriers between software development and IT operations and aims to produce and maintain high quality software systems. Software logging is widely used in DevOps. However, there are few guidelines and tool support for composing high quality logging code and current application context of log analysis is very limited with respect to feedback for developers and correlations among other telemetry data. This thesis proposes automated approaches to improving software logging practices in DevOps by leveraging various types of software repositories (e.g., historical, communication, bug, and runtime repositories). We aim to support the software development side by providing guidelines and tools on developing and maintaining high quality logging code. We aim to support the IT operation side by enriching the log analysis context through systematic estimating code coverage via executing logs and in-depth problem diagnosis by correlating logs with other telemetry data (e.g., traces and APM data). Case studies show that our approaches can provide useful software logging suggestions to both developers and operators in open source and commercial systems.;
Historical Aerospace Software Errors Categorized to Influence Fault Tolerance;"Since the first use of computers in space and aircraft, software errors have occurred. These errors can manifest as loss-of-life or less catastrophically. As the demand for automation increases, software in mission or safety-critical systems should be designed to be tolerant to the most likely software faults. This paper categorizes a set of 56 historic aerospace software error incidents from 1962 to 2023 to determine trends of how and where automation is most likely to fail or behave unexpectedly. A distinction between software producing unexpected (erroneous) output versus no output (fail-silent) is introduced. Of the historical incidents analyzed, 86% were from software producing wrong output rather than simply stopping. Rebooting was found to be ineffective to clear erroneous behavior, and not reliable to recover from silent failures. Error origin was within the code/logic itself in 59% of cases, 16% from configurable data, 14% from unexpected sensor input, and 11% from command/operator input. A substantial forty percent (41%) of unexpected software behavior was indicated by the absence of code, arising from unanticipated situations and missing requirements, and 18% of incidents were subjectively deemed ""unknown-unknowns"". No incidents were found to be the result of programming language, compiler, tool, or operating system";
Mitigating the Effect of Coincidental Correctness in Spectrum Based Fault Localization;Coincidentally correct test cases are those that execute faulty statements but do not cause failures. Such test cases reduce the effectiveness of spectrum-based fault localization techniques, such as Ochiai. These techniques calculate a suspiciousness score for each statement. The suspiciousness score estimates the likelihood that the program will fail if the statement is executed. The presence of coincidentally correct test cases reduces the suspiciousness score of the faulty statement, thereby reducing the effectiveness of fault localization. We present two approaches that predict coincidentally correct test cases and use the predictions to improve the effectiveness of spectrum based fault localization. In the first approach, we assign weights to passing test cases such that the test cases that are likely to be coincidentally correct obtain low weights. Then we use the weights to calculate suspiciousness scores. In the second approach, we iteratively predict and remove coincidentally correct test cases, and calculate the suspiciousness scores with the reduced test suite. In this dissertation, we investigate the cost and effectiveness of our approach to predicting coincidentally correct test cases and utilizing the predictions. We report the results of our preliminary evaluation of effectiveness and outline our research plan.;
Neural Network based Software Defect Prediction using Genetic Algorithm and Particle Swarm Optimization;In the arena of software engineering, software defects prediction is one of the most attractive research topics. Here the main task is to predict if there is any bug in the software or not. For software testing, software defect detection is important for reducing the time and resources consumed. Accurate estimate of defect software prediction process enables effective discovery and identification of the defects. Such prediction methods are important for the big scale systems, where verification specialists need to focus their attention. In this paper, we proposed a method where the features are selected using Genetic Algorithm (GA). Secondly, make cluster of the selected features using Particle Swarm Optimization (PSO) and then train the model with different Neural Network (NN) methods such as: Feedforward Neural Network (FNN), Recurrent Neural Network (RNN), Artificial Neural Network (ANN), and Deep Neural Network (DNN) and finally calculate accuracy, sensitivity, specificity, precision, negative prediction value, F1 score, and Matthews correlation coefficient. We use five different datasets from NASA promise software engineering repository for our study. From our study, we get the best accuracy result using deep neural network. Experimental consequences show that proposed strategy is a decent technique to predict the software defects.;
Software Piracy Forensics: A Proposal for Incorporating Dead Codes and Other Programming Blunders as Important Evidence in AFC Test;Dead code, which is not uncommon in software engineering, is an unexplored area in software piracy forensics. This paper primarily investigates the forensic importance of all programming blunders, including dead codes. Programming Blunder is identified as a variable or a code segment (including dead code) or a field in a database table, which is hardly used or executed in the context of the application or the user's functionality. Blunder genes can be found in many parts of any program. It is the contention of this paper that this phenomenon of blunders needs to be studied systematically from its very genetic origins to their surface realizations in contrast to bugs and flaws, especially in view of their importance in software copyright infringement forensics. The article discusses the idea -- expression merger aspects of programming blunders and finally, proposes the need and a way to incorporate programming blunders into Abstraction-Filtration- Comparison test, the official software copyright infringement investigation procedure of US judiciary.;
Increasing anomaly handling efficiency in large organizations using applied machine learning;Maintenance costs can be substantial for large organizations (several hundreds of programmers) with very large and complex software systems. By large we mean lines of code in the range of hundreds of thousands or millions. Our research objective is to improve the process of handling anomaly reports for large organizations. Specifically, we are addressing the problem of the manual, laborious and time consuming process of assigning anomaly reports to the correct design teams and the related issue of localizing faults in the system architecture. In large organizations, with complex systems, this is particularly problematic because the receiver of an anomaly report may not have detailed knowledge of the whole system. As a consequence, anomaly reports may be assigned to the wrong team in the organization, causing delays and unnecessary work. We have so far developed two machine learning prototypes to validate our approach. The latest, a re-implementation and extension, of the first is being evaluated on four large systems at Ericsson AB. Our main goal is to investigate how large software development organizations can significantly improve development efficiency by replacing manual anomaly report assignment and fault localization with machine learning techniques. Our approach focuses on training machine learning systems on anomaly report databases;
An Improved Approach to Software Defect Prediction using a Hybrid Machine Learning Model;Software defect prediction is an intricate but essential software testing related activity. As a solution to it, we have recently proposed HyGRAR, a hybrid classification model which combines Gradual Relational Association Rules (GRARs) with ANNs. ANNs were used to learn gradual relations that were then considered in a mining process so as to discover the interesting GRARs characterizing the defective and non-defective software entities, respectively. The classification of a new entity based on the discriminative GRARs was made through a non-adaptive heuristic method. In current paper, we propose to enhance HyGRAR through autonomously learning the classification methodology. Evaluation experiments performed on two open-source data sets indicate that the enhanced HyGRAR classifier outperforms the related approaches evaluated on the same two data sets.;
A Software Defect Prediction Approach based on Machine Learning;In recent years, there has been an increasing interest in using machine learning methods to predict software defects. In practical engineering applications, the number of defective software samples is far less than that of non-defective software samples, resulting in unbalanced distribution of samples. In addition, the prediction performance of a single classifier is limited due to the diversity of distribution of defect data. Therefore, a series of methods should be adopted to solve these problems to improve the accuracy and reliability of software defect prediction. Here, the combined sampling method is used to deal with the class imbalance problem, and the minority class defect samples are synthesized. Through improved Bagging, different base classifiers are selected to increase the diversity of classifiers in defect prediction, and the final prediction result is obtained by weighted integration of multiple classifiers according to the Accuracy value of each classifier for the test set classification. Through the above method, a better classification effect is obtained.;
System Testing of Repository-Style Software: An Experience Report;System testing based on a black box approach is a common industrial practice in information systems. Despite its widespread use, however, little guidance is available for testing engineers facing the problem of selecting the best test strategy. In previous work, we proposed to adopt functional models and related testing patterns according to the architectural style of the application under test. In this paper, we present an industrial study that applies this technique to system testing of repository based applications. We define a set of functional models abstracting different concerns of software applications: hierarchy of functions, business processes and states/transitions of application objects. The models are used to derive the functional test cases through the definition of test patterns. We applied this approach in an industrial context for over 5 years. In this paper, we analyze a data set of 37 test projects including about 22000 test cases and 1500 failures. We relate failures to the originating defect types. The study confirms that a system test strategy that uses multiple functional models according to the architectural style of the software application generates a better cost/benefit ratio than the use of just one model. The explanation is that - despite a small overlap - each model detects specific types of software defects. The results of the study can guide testing engineers in selecting the best system test strategy and significantly improve the efficiency of their work.;
Terminal Software Defect Detection Method Based on Association Rules;The research of terminal software defect detection method based on association rules is a research topic in the field of computer science. The main purpose of this study is to find out how much accuracy can be achieved using this type of method. This question has been studied for many years, and there is no clear answer so far. Terminal software defect detection methods have been developed since the beginning of computerization. In order to detect defects in a program before it is released, it is necessary to develop effective methods to help us determine whether there are errors in a given code. The main idea is to use information about how often certain events occur together and predict that they will occur again. Association rules are used for this purpose. A rule is a mathematical statement that describes a relationship between two variables (in our case, different parts of a program). When a variable changes its value, it may trigger another variable to change;
Do System Test Cases Grow Old?;Companies increasingly use either manual or automated system testing to ensure the quality of their software products. As a system evolves and is extended with new features the test suite also typically grows as new test cases are added. To ensure software quality throughout this process the test suite is continously executed, often on a daily basis. It seems likely that newly added tests would be more likely to fail than older tests but this has not been investigated in any detail on large-scale, industrial software systems. Also it is not clear which methods should be used to conduct such an analysis. This paper proposes three main concepts that can be used to investigate aging effects in the use and failure behaviour of system test cases: test case activation curves, test case hazard curves, and test case half-life. To evaluate these concepts and the type of analysis they enable we apply them on an industrial software system containing more than one million lines of code. The data sets comes from a total of 1,620 system test cases executed a total of more than half a million times over a time period of two and a half years. For the investigated system we find that system test cases stay active as they age but really do grow old, they go through an infant mortality phase with higher failure rates which then decline over time. The test case half-life is between 5 to 12 months for the two studied data sets.;
Learning from Software defect datasets;Development of high-quality software is very much essential now-a-days. Prediction of good quality software in the early phase during the development reduces the cost of the testing resources. Various data mining and machine learning algorithms are developed to predict the quality of the software. In the real-life scenarios while dealing with software modules many of the time the underline datasets are imbalanced. In order to increase the efficiency of the prediction or classification algorithms balancing algorithms are implemented as a preprocessing stage before the prediction phase. In this paper we conduct extensive experiments to explore the effect of imbalance learning including undersampling, oversampling and hybrid methods and its interaction with different types of classifiers on various projects. We evaluate six imbalance learning methods with six classifiers on 12 data sets. The imbalance learning methods used are Random Oversampling (ROS), Random under-sampling, SMOTE, TOMEK, SMOTE+TOMEK, and SMOTE+ENN. This study reveals that the appropriate combination of imbalanced method and classifier can improve the accuracy of software fault prediction models.;
Distribution Awareness for AI System Testing;As Deep Learning (DL) is continuously adopted in many safety critical applications, its quality and reliability start to raise concerns. Similar to the traditional software development process, testing the DL software to uncover its defects at an early stage is an effective way to reduce risks after deployment. Although recent progress has been made in designing novel testing techniques for DL software, the distribution of generated test data is not taken into consideration. It is therefore hard to judge whether the identified errors are indeed meaningful errors to the DL application. Therefore, we propose a new distribution aware testing technique which aims to generate new unseen test cases relevant to the underlying DL system task. Our results show that this technique is able to filter up to 55.44% of error test case on CIFAR-10 and is 10.05% more effective in enhancing robustness.;
Exploratory software testing in agile project;Software testing is an important process in a software development life-cycle as validation and verification mechanisms to guarantee the quality of the intended software product. Exploratory testing is a software testing where the testers may interact with the system in whatever way they want and use the information the system provides to react and generally explore the system functionalities without restraint. Exploratory testing allows the full power of the human brain to be brought to bear on finding bugs and verifying functionality without preconceived restrictions. This paper discuss about enacting exploratory software testing in a software project which was developing Student Marking System (SMS) in University XYZ.;
A Framework of Vulnerable Code Dataset Generation by Open-Source Injection;Evaluation benchmark plays an important role in the design of defect detection algorithms and tools. Especially with the development of deep learning techniques, code defect detection models based on deep neural network requires a large number of training and testing cases. Existing test cases are far from meeting the requirements of new algorithm design and verification. On the one hand, the number of test cases designed manually or collected from open source projects is small. On the other hand, the test cases generated automatically according to rules have similar pattern, high redundancy and simple structure. This paper proposes an algorithm of code defect injection and test case generation based on open source projects. The basic idea is to find reaching definitions in open source projects, and modify the source code according to the analysis results, so as to generate defect dataset with a large number of test cases that have similar feature to open source codes. This paper selects 8 open source projects to verify the proposed method and generates more than 6,000 null pointer dereference test cases in total. We use existing tools to evaluate the injected test cases and the results show that the proposed method can generate a large number of high-quality test cases.;
Stacking based approach for prediction of faulty modules;Determination of a software module, prone to fault is important before the defects are discovered;
Heterogeneous Stacked Ensemble Classifier for Software Defect Prediction;Software defect prediction (SDP) is vital to enhance the software quality with reduced testing cost. It stresses to put more testing efforts on those modules which are susceptible to defects. Hence, the focused testing saves resources and increases the probability to deliver failure-free software product exhibiting desired quality levels. One major hinderance in accurate performance of SDP classifiers is class imbalance. This paper proposes to use stacked ensemble to deal with the class imbalance and enhance the performance of SDP classifiers. The experimental study utilizes the publicly available NASA corpus. The study makes a statistical comparison between the proposed model and baseline models. The results show that the proposed model performs better than baseline models over area under the curve (AUC) and accuracy evaluation metrics.;
Software regression testing success story;Many products go through several releases, and can be ported to many platforms (hardware and/or operating system). Every line of code written or modified offers opportunity for bugs to creep in. Regression testing is the way to catch a large class of these bugs quickly and efficiently. Regression testing focuses on ensuring that (theoretically) everything that used to work still works. For six years, nine software releases, ports to one new operating system and three new hardware platforms, our product line has been using a process that includes the use of a regression test system. Regression test is a worthwhile ongoing investment.<>;
A Data Set of Program Invariants and Error Paths;The analysis of correctness proofs and counterexamples of program source code is an important way to gain insights into methods that could make it easier in the future to find invariants to prove a program correct or to find bugs. The availability of high-quality data is often a limiting factor for researchers who want to study real program invariants and real bugs. The described data set provides a large collection of concrete verification results, which can be used in research projects as data source or for evaluation purposes. Each result is made available as verification witness, which represents either program invariants that were used to prove the program correct (correctness witness) or an error path to replay the actual bug (violation witness). The verification results are taken from actual verification runs on 10522 verification problems, using the 31 verification tools that participated in the 8th edition of the International Competition on Software Verification (SV-COMP). The collection contains a total of 125720 verification witnesses together with various meta data and a map to relate a witness to the C program that it originates from. Data set is available at: https://doi.org/10.5281/zenodo.2559175.;
The impact of requirements on software quality across three product generations;In a previous case study, we presented data demonstrating the impact that a well-written and well-reviewed set of requirements had on software defects and other quality indicators between two generations of an Intel product. The first generation was coded from an unorganized collection of requirements that were reviewed infrequently and informally. In contrast, the second was developed based on a set of requirements stored in a Requirements Management database and formally reviewed at each revision. Quality indicators for the second software product all improved dramatically even with the increased complexity of the newer product. This paper will recap that study and then present data from a subsequent Intel case study revealing that quality enhancements continued on the third generation of the product. The third generation software was designed and coded using the final set of requirements from the second version as a starting point. Key product differentiators included changes to operate with a new Intel processor, the introduction of new hardware platforms and the addition of approximately fifty new features. Software development methodologies were nearly identical, with only the change to a continuous build process for source code check-in added. Despite the enhanced functionality and complexity in the third generation software, requirements defects, software defects, software sightings, feature commit vs. delivery (feature variance), defect closure efficiency rates, and number of days from project commit to customer release all improved from the second to the third generation of the software.;
Study of implementation of software test management system based on web;This paper has been studied the theory of software testing and analyzed the existing software test management tool, which are based on the theory big movement in our laboratory, the intensive development projects to change in demand characteristics and a web-based software testing management system. The system is available from the test requirements, test planning, test execution to defect the tracking management of the entire testing process and test related tasks management. System is flexible on the set functions and roles of authority, the system can scale from staff, personnel changes and the constraints;
A study of applying ARIMA and SVM model to software reliability prediction;For more than three decades, Box and Jenkins' Auto-Regressive Integrated Moving Average (ARIMA) technique has been one of the most widely used linear models in time series forecasting. However, it is well documented that many software failure observations are nonlinear and ARIMA is a general univariate model developed based on the assumption that the time series data being predicted are linear. Therefore, in this study, the utilization of Support Vector Machine (SVM) as a nonlinear model and ARIMA as a linear model are integrated in software reliability forecasting. Experiments on real-world data set validate the effectiveness of the hybrid model. These results also show that the proposed methodology can be a more effective way in order to combine linear and nonlinear models together than traditional methodologies. Therefore, it can significantly improve the prediction performance and can be applied as an appropriate alternative approach for software reliability forecasting field, especially when higher prediction performance is needed.;
Managing software evolution through semantic history slicing;Software change histories are results of incremental updates made by developers. As a side-effect of the software development process, version history is a surprisingly useful source of information for understanding, maintaining and reusing software. However, traditional commit-based sequential organization of version histories lacks semantic structure and thus are insufficient for many development tasks that require high-level, semantic understanding of program functionality, such as locating feature implementations and porting hot fixes. In this work, we propose to use well-organized unit tests as identifiers for corresponding software functionalities. We then present a family of automated techniques which analyze the semantics of historical changes and assist developers in many everyday practical settings. For validation, we evaluate our approaches on a benchmark of developer-annotated version history instances obtained from real-world open source software projects on GitHub.;
Emergence of Power-Law Behavior in Defect Distribution of IoT Software;Rapid growth of IoT in various areas is not possible without software. However, IoT software are inherently different from traditional software because of the requirement of supporting multiple types of devices, heterogeneity, distributed and dynamic environment, always-on nature of the system. This has led to altogether new software engineering approach, called IoT-oriented software engineering. Besides, the search for new paradigm of software development, one question worth examining is the distribution of defects in IoT software. The paper investigates the defect distribution in some IoT software to ascertain if they show similar behavior as observed in traditional software or not. To meet this objective, a detailed statistical analysis of defects in IoT software is performed using non-linear regression method. Along with lognormal, Weibull, Pareto and generalized two-parameter Pareto as candidate probability distributions, a new software defect model based on maximum Tsallis entropy framework, called Tsallis distribution, is also included in the study. Tsallis distribution depicts power-law asymptotically. The IoT software are selected from four different categories - in memory database, middleware, data stream processing engine and operating system. Thorough examination of the results of statistical analysis reveal that generalized two-parameter Pareto and Tsallis distributions outperform others leading to the confirmation of emergence of power-law behavior in defect distribution of IoT software a kin to traditional ones. One exception is a relatively new operating system software where lognormal distribution turns out to be best fit. These results augment the IoT-oriented software engineering literature and also help the practitioners in predicting defects in evolving field of IoT software.;
Knowledge transfer software fault learning;A large amount of work has been done on prediction of software defects and prediction of number of bugs. Most of the approaches are based on training and testing of data related to the same project. But there may not be sufficient data of the project for training. The cross project prediction makes use of data from other projects to predict the defects in a particular project. In this work, we proposed a model for cross domain projects prediction. The training data is take from the projects on one domain and prediction of faults of the other domain software projects is performed. In order to learn from other domain knowledge we have used balancing of the source project data. The balanced data of the source project is used to train the Random Forest classifier on which hyper parameter tuning is applied. To examine the benefits of our approach, we perform experiments on nine projects datasets from the PROMISE repository. Additionally we also compare our approach with the recently proposed cross project prediction: HYDRA model. The results show us good f-measure values obtained by the proposed model for some projects over HYDRA.;
Improving Automated Program Repair with Retrospective Fault Localization;Although being recognized as a critical step in automated program repair, fault localization has been only loosely coupled into the fixing process in existing program repair approaches, in the sense that fault localization has limited interactions with other activities in fixing. We propose in this paper to deeply integrate fault localization into the fixing process to achieve more effective and efficient program repair. Our approach introduces a feedback loop in fixing between the activities for locating the fault causes and those for generating and evaluating candidate fixes. The feedback loop enables partial evaluation results of candidate fixes to be used to locate fault localization more accurately, and eventually leads to fixing processes with improved effectiveness and efficiency. We have implemented the approach into a tool, named RESTORE, based on the JAID program repair system. Experiments involving faults from the DEFECTS4J standard benchmark indicate that the integrated fault localization can boost automated program repair: RESTORE produced valid fixes to 63 faults and correct ones to 38 faults, outperforming any other state-of-the-art repair tool for Java while taking 36% less running time compared with JAID.;
Using Control Charts for Detecting and Understanding Performance Regressions in Large Software;Load testing is a very important step in testing of large-scale software systems. For example, studies found that users are likely to abandon an online transaction if the web application fails to response within eight seconds. Performance load tests ensure that performance counters such as response time stays in the acceptable range after each change to the code. Analyzing load tests results to detect performance regression is very time consuming due to the large amount of performance counters. In this thesis, we propose approaches that use control charts, a statistical process control technique, to assist performance engineers in identifying test runs with performance regressions, pinpointing the components which cause the regressions, and determining the causes of regressions in load tests. Using our approaches, engineers will save time in analyzing the results of load tests.;
Removing Coincidental Correctness in Spectrum-Based Fault Localization for Circuit and Spreadsheet Debugging;Spectrum-based fault localization (SBFL) has a wide area of application, ranging from debugging circuits over Java programs to spreadsheets. While SBFL has a low computational complexity and is easy to apply, its results are sometimes imprecise. In this paper, we address one of the reasons for the impreciseness, namely coincidental correctness. Coincidental correctness occurs when a program computes the correct result even though a faulty statement has been executed. We propose a technique which identifies potential coincidentally correct outcomes in circuits and spreadsheets. Our empirical evaluation shows that the removal of the actual coincidentally correct outcomes often positively influences the ranking of the faulty component(s). Furthermore, the evaluation shows that the proposed approach is well suited for identifying potential coincidentally correct outcomes in spreadsheets, but not in circuits.;
On datastore support for agile software development;Most database-base applications support two main sets of features: customer facing transactional capabilities such as purchasing books at an online bookstore and functionality required by managers and business analysts such as identifying trends in sales data by combing through aggregated sales data. The conventional approach of having just one main database to support both features greatly restrict developers freedom in applying the best approach to quickly implement new features, to enhance existing features, or to mend defects because any attempt in changing database schema means code and test cases modifications in many places and may even require a large amount of effort in testing. Such an inherited resistance in changing introduced by data store does not fit the evolutionary development nature of Agile software development methodology. We argue that we should consider having at least two databases: one support transactional capabilities and the other support reporting and possible data warehouse needs, and will show how such an approach supports the Agile software development methodology.;
Error mining: Bug detection through comparison with large code databases;Bugs are hard to find. Static analysis tools are capable of systematically detecting predefined sets of errors, but extending them to find new error types requires a deep understanding of the underlying programming language. Manual reviews on the other hand, while being able to reveal more individual errors, require much more time. We present a new approach to automatically detect bugs through comparison with a large code database. The source file is analyzed for similar but slightly different code fragments in the database. Frequent occurrences of common differences indicate a potential bug that can be fixed by applying the modification back to the original source file. In this paper, we give an overview of the resulting algorithm and some important implementation details. We further evaluate the circumstances under which good detection rates can be achieved. The results demonstrate that consistently high detection rates of up to 50% are possible for certain error types across different programming languages.;
A data-driven model for software reliability prediction;In the actual software development, failure data is rarely pure linear or nonlinear. It is usually formed by the linear and nonlinear patterns at the same time. These models can be divided into two main categories: analytical model and data-driven model. Analytical SRMs are proposed based on underlying assumptions about the nature of software faults, the stochastic behavior of the software processes and the development environments. On the contrary, the so-called data-driven models, borrowing heavily from artificial intelligence techniques, rely directly on the collected data describing input and output characteristics. Compared to analytical SRMs, data-driven models have much less unpractical assumptions and are much abler to make abstractions and generalizations of the software failure process. It has been recognized that the auto regression integrated moving average (ARlMA) and the support vector machine (SVM) perform fairly well in predicting linear and nonlinear time series data. Therefore, we propose a hybrid approach to software reliability forecasting using both ARlMA and SVM models.;
Can a software project be like Einstein?;The author discusses his approach to software quality assurance and considers software projects in the United States and Japan. The author's proposal concerns the collaboration of opposite-typed programmers and organizations. If the US and Japan, for example, work together on software development as a single project, the short-coming of both programmers will be cancelled, and will work like genius.;
CrossPare: A Tool for Benchmarking Cross-Project Defect Predictions;During the last decade, many papers on defect prediction were published. One still for the most part unresolved issue are cross-project defect predictions. Here, the aim is to predict the defects of a project, with data from other projects. Many approaches were suggested and evaluated in recent years. However, due to the usage of different implementations and data sets, the comparison between the work is a hard task. Within this paper, we present the tool CrossPare. CrossPare is designed to facilitate benchmarks for cross-project defect predictions. The tool already implements many techniques proposed within the current state of the art of cross-project defect predictions. Moreover, the tool is able to load different data sets that are commonly used for the evaluation of techniques and supports all major performance metrics. Through the usage of CrossPare other reseachers can improve the comparability of their results and possibly also reduce their implementation efforts for new cross-project defect prediction techniques by reusing features already offered by CrossPare.;
Can explainability and deep-learning be used for localizing vulnerabilities in source code?;Security vulnerabilities are weaknesses of software due for instance to design flaws or implementation bugs that can be exploited and lead to potentially devastating security breaches. Traditionally, static code analysis is recognized as effective in the detection of software security vulnerabilities but at the expense of a high human effort required for checking a large number of produced false positive cases. Deep-learning methods have been recently proposed to overcome such a limitation of static code analysis and detect the vulnerable code by using vulnerability-related patterns learned from large source code datasets. However, the use of these methods for localizing the causes of the vulnerability in the source code, i.e., localize the statements that contain the bugs, has not been extensively explored. In this work, we experiment the use of deep-learning and explainability methods for detecting and localizing vulnerability-related statements in code fragments (named snippets). We aim at understanding if the code features adopted by deep-learning methods to identify vulnerable code snippets can also support the developers in debugging the code, thus localizing the vulnerabilityâ€™s cause Our work shows that deep-learning methods can be effective in detecting the vulnerable code snippets, under certain conditions, but the code features that such methods use can only partially face the actual causes of the vulnerabilities in the code.CCS Conceptsâ€¢ Security and privacy $\rightarrow$ Vulnerability management;
Debugging Multithreaded Programs Using Symbolic Analysis;Debugging multithreaded software is challenging because the basic assumption that underlies sequential software debugging, i.e. the program behavior is deterministic under fixed inputs, is no longer valid due to the nondeterminism brought by thread scheduling. To restore this basic assumption, we propose a proactive debugging method so that programmers can debug multithreaded programs as if they were sequential. Our approach is based on the synergistic integration of a set of new symbolic analysis and dynamic analysis techniques. In particular, symbolic analysis is used to investigate the program behavior under multiple thread interleavings and then drive the dynamic execution to new branches. Dynamic analysis is used to execute these new branches and in turn guide the symbolic analysis further. The net effect of applying this feedback loop is a systematic and complete coverage of the program behavior under a fixed test input.;
Automation of Bug-Report Allocation to Developer using a Deep Learning Algorithm;Software bug maintenance is an important aspect of all software projects. The assignment of bug reports is essential in order to resolve bugs efficiently. In the case of open-source software developments and large projects, where many developers are engaged on different aspects of software development, it can be difficult to assign bug removal tasks to an appropriate developer. An increase in reported bugs, coupled with an increase in the number of software developers, will complicate the bug triage process. In these situations, bug triaging might be slow and may increase the Bug Tossing Length (BTL). An automated system to triage bug reports could potentially reduce BTL, as manual assignment of bug reports is tiresome, costly, and very time-consuming. The assignment of bug reporting to an irrelevant developer who does not possess sufficient experience to deal with the bug will adversely impact BTL and customer satisfaction. Text-based classification methods have the potential to make a strong contribution to automating the bug triaging process. In this research, different types of Information Retrieval and Machine Learning algorithms are used to determine the appropriate developer/s to rectify the reported bugs. This study used deep learning algorithms, such as the Bidirectional Long Short-Term Memory Network, to automate the bug triaging process. Bug reports contain textual data related to the bug information. In this research, the pretrained GloVe model is employed for word-to-vector representation of bug reportsâ€™ textual information. In this framework, developersâ€™ activities are monitored based on their working history. To test the proposed approach, three large datasets, Net-Beans, Eclipse, and Mozilla, are used. It was observed that the proposed technique produced better results in terms of accuracy, recall, precision and f-measure compared to traditional Machine Learning algorithms for bug report recommendation.;
NHPP software reliability growth model incorporating fault detection and debugging;Several software reliability growth models based on nonhomogeneous Poisson process (NHPP) have been presented in the literature in the last three decades. However, existing software reliability growth models have the problem that the considerations of imperfect debugging phenomenon are incompletely. Based on the two important aspects that new faults introduced by fault debugging and incompletely fault debugging, in this paper, we proposed a software reliability growth model in which the total number of fault and fault removal efficient will change over time. Examined by a group of public failure data set, the proposed model is considered to be a model with goodness-of-fit and the predictive power.;
On Improving Management of Duplicate Video-Based Bug Reports;Video-based bug reports have become a promising alternative to text-based reports for programs centered around a graphical user interface (GUI), as they allow for seamless documentation of soft-ware faults by visually capturing buggy behavior on app screens. However, developing automated techniques to manage video-based reports is challenging as it requires identifying and understanding often nuanced visual patterns that capture key information about a reported bug. Therefore, my research endeavors to overcome these challenges by advancing the bug report management task of duplicate detection for video-based reports. The objectives of my research are fourfold: (i) investigate the benefits of tailoring recent advancements in the computer vision domain for learning both visual and textual patterns from video frames depicting GUI screens to detect duplicate reports;
Ranking of Bug Reports into Findbug Categories using the BM25 Function;Bug reporting is a mechanism that is used by software companies to audit and track product quality. The developers and the users can log bug reports via a dedicated system. The quality of the bug reports affects the developers' endeavors to fix and close the bug. The reports include important information for the developers such as severity and priority. However, previous research found that most bugs are left without changing the severity level. Therefore, the developers need to know more information about the reported bug. In this research, we propose to improve the bug report by adding linking bug reports with a pre-specified bug description that was prepared by experts in bug types. i.e. the Findbug tool. The Findbug adds more information to the bug such as the bug type and bug category. The bugs are reclassified using a similarity function, BM25, to match it with more necessary information about the type of reported bugs. Text preprocessing was applied to remove unnecessary terms and to improve the search query in BM25. The proposed methodology could assign extra information to bug reports that help categorize them into different types such as correctness, security, performance, and others.;
A Brief Analysis of Soft Computing Techniques in Software Fault Prediction;Software testing and fault prediction is major part of any software development. It not only reduces the overall cost and efforts but also increase the robustness of the system. Tester has to find or predicts the fault in advance to design premium fault free software. Soft-computing is basically is used for identifying defect in advance through techniques like Fuzzy logic, Neural Network and other metaheuristic techniques. In this paper we are doing a brief analysis of different soft computing techniques used in software fault prediction. Different datasets and parameter selection is used in the calculation of faulty module, model's efficiency and accuracy. Recent studies with their benefit and loss are being compared to find out best possibilities and combination of model for better stabilized results;
Improving software fault-prediction for imbalanced data;Fault-proneness has been studied extensively as a quality factor. The prediction of fault-proneness of software modules can help software engineers to plan evolutions of the system. This plan can be compromised in case prediction models are biased or do not have high prediction performance. One major issue that can impact the prediction performance is the fault distributions such as the data imbalance, i.e., the majority of modules are faultless whereas the minority of modules is only faulty. In this paper, we propose to use the fault content (i.e., the number of faults in a module) to oversample the minority. We applied this technique on a large object-oriented system - Eclipse. The proposed oversampling is tested on three classifiers. The results have shown a better prediction performance than other traditional oversampling techniques. The oversampling technique is more convenient than other sampling techniques because it's guided by information provided from the software history.;
Localizing and Fixing Faults in SQL Predicates;Fault localization is very important to both researchers and practitioners. Running tests is a useful approach to identify the fault location. Researchers have studied how to automatically identify faults in database applications [1], [2], [3]. However, those research considers the entire SQL statement as one line of code, indicating that the whole SQL statement contains errors. Little attention has been paid to ?nding faults in individual components of SQL statements such as a predicate clause. My research includes two major aspects: 1) Finding an effective and ef?cient method to localize faults in SQL predicates 2) Automatically fixing the reported faults The effectiveness is defined in terms of the faults found and the efficiency is defined with regards to the execution time. I have proposed a new approach that is more effective in ?nding fault in SQL predicates than existing methods. This approach and evaluation has been accepted to ICST 2017 [4].;
Prediction of Faults in Embedded Software Using Machine Learning Approaches;Software industry owns the most modern technological developments in this era. A software should be working perfectly without any error before handed over to the customer. The process of this quality assurance should be cost effective, less time-consuming, and reliable. But in practical scenario, it takes time to predict, detect and rectify the faults in a software. There are many models to predict the faults of software but no single model can claim to be perfect. This paper studied seven Machine Learning (ML) algorithms: Ada-Boost, CatBoost, LightGBM, Random Forest, XGBoost, Ensemble using Stacking and Voting to predict faults for an embedded software. Experiments were carried out with six datasets and eight performance metrics: accuracy, sensitivity, specificity, F-measure, balance, AUC, MAE, and precision to observe the performance of the algorithms. Random Forest showed the best results for accuracy, precision and specificity for 35%, 25% and 20% test data ratio with prediction of 0.995, 1 and 0.996 respectively. On the other hand, Ensemble (Stacking) showed the best result for specificity for 35% test ratio with prediction of 0.996. These results proved the suggested model better than the previous ones with acceptable outcome.;
Design and Java Implementation of Intelligent Platform for English Training based on Intelligent Test Data Generation Algorithm;Firstly, the research results of genetic algorithm and particle swarm optimization algorithm, which are most frequently used in the generation of test data based on intelligent optimization algorithm, are summarized and summarized, and the research status is analyzed. Then, the test data based on intelligent optimization algorithm is briefly introduced. Generation tools. Based on the analysis of system functional requirements, the teaching resource library and the front and back functional modules of the learning platform are determined. Based on the technical foundations of Java, JSP, Hibernate framework, etc. Earn points by doing fun English quizzes and learning competitions;
Storage-Based Logic Built-In Self-Test With Partitioned Deterministic Compressed Tests;Logic built-in self-test (LBIST) is important for in-field testing. In a storage-based LBIST approach, deterministic test data are stored on-chip and used for applying tests that are closer to deterministic tests than pseudorandom tests. Using the same stored test data for applying several different tests allows the volume of test data stored on-chip to be reduced, and the fault coverage to be increased. This observation was applied earlier in two ways: 1) by complementing bits of stored test data or applied tests to form additional tests and 2) by forming different tests from different combinations of stored test data entries that are obtained by partitioning deterministic tests. Partitioning was applied earlier to uncompressed deterministic tests. In this article, partitioning is applied for the first time to compressed deterministic tests. Under the resulting LBIST approach, tests are formed on-chip using pseudorandom combinations of partitioned compressed tests. A software procedure is described for deriving a reduced set of test data entries for on-chip storage. With compressed tests, the storage requirements are already reduced, and they are reduced further by the software procedure. Experimental results demonstrate the effectiveness of this LBIST approach considering both single stuck-at and single-cycle gate-exhaustive faults in benchmark circuits.;
Storage-Based Logic Built-in Self-Test With Multicycle Tests;Storing deterministic test data on-chip allows logic built-in self-test (LBIST) to produce a special type of random test that consists of random combinations of deterministic test data. Such tests can achieve a higher fault coverage than random tests whose bits are determined randomly. A bottleneck of this approach is the volume of test data that needs to be stored. This article observes that the use of multicycle tests can address this bottleneck by reducing the number of tests needed for detecting target faults and, thus, the volume of test data needed for producing them. A software procedure is described to support this solution. Experimental results for benchmark circuits demonstrate the effectiveness of multicycle tests in this context.;
FLANDROID: Energy-Efficient Recommendations of Reliable Context Providers for Android Applications;Mobile applications are becoming more and more popular with the prevalence of mobile operating systems and mobile Internet. Many of them consume services provided by the underlying infrastructure and platforms as a part of their application environmental contexts. However, application failures or downgrade in performance may be the results due to inadequate provisions of these environmental issues in the implementations of the mobile applications. In this paper, we propose a framework to enable mobile applications to consume services offered by a reliable context provider with high probability in run time. We report a case study on a suite of five real-world mobile applications with 74 real faults on real mobile phones involving 50 users. The results of the case study show that our framework can significantly improve the reliability of mobile applications with respect to the failures due to buggy-context-provider faults with low slowdown and energy overheads.;
The Effectiveness of Hidden Dependence Metrics in Bug Prediction;Finding and fixing bugs in programs is perhaps one of the most difficult, yet most important, tasks in software maintenance. This is why in the last decades, a lot of work has been done on this topic, most of which is based on machine learning methods. Studies on bug prediction can be found for almost all programming languages. The solutions presented generally try to predict bugs based on information that can be easily extracted from the source code, rather than more expensive solutions that require a deeper understanding of the program. Another feature of these solutions is that they usually try to predict faults at a high level (module/file/class), which is useful, but locating the bug itself is still a difficult task. This work presents a solution that attempts to predict bugs at the method level, while also tracking the dependencies in the program using an efficient algorithm, resulting in an approach that can predict bugs more accurately. The practical measurements show that the defined approach really outperforms predictions based on traditional metrics in most cases, and with proper filtering, the best-performing RandomForest algorithm according to the F-measure can even achieve an improvement of up to 11%. Finally, it is proven that the introduced metrics are even suitable for predicting bugs that will appear later in a given project if sufficient learning data is available.;
Storage and Counter Based Logic Built-In Self-Test;Recent reports of silent data corruption because of hardware faults in large data centers bring to the forefront the importance of in-field testing. In-field testing, enabled by logic built-in self-test ( $LBIST$ ), addresses defects that occur during the lifetime of a chip and ones that escaped manufacturing tests. A class of  $LBIST$  approaches for scan circuits store partitioned deterministic test data on-chip and produce tests by combining stored test data entries in one of two ways: 1) pseudo-random combinations are selected by linear-feedback shift-registers ( $LFSR\text{s}$ );
"Comments on ScottKnottESD in response to ""An empirical comparison of model validation techniques for defect prediction models""";In this article, we discuss the ScottKnottESD test, which was proposed in a recent paper â€œAn Empirical Comparison of Model Validation Techniques for Defect Prediction Modelsâ€ that was published in this journal. We discuss the implications and the empirical impact of the proposed normality correction of ScottKnottESD and come to the conclusion that this correction does not necessarily lead to the fulfillment of the assumptions of the original Scott-Knott test and may cause problems with the statistical analysis.;
A New Fault Classifier in Transmission Lines Using Intrinsic Time Decomposition;As nonstationarity exists in fault signals of transmission lines, their classification and quantification remain a challenging issue. This paper presents a new scheme for feature extraction in an attempt to achieve high fault classification accuracy. The proposed scheme consists of three steps: first, the proper rotation components (PRCs) matrix of current signals captured from one end of the protected line is constructed using the intrinsic time decomposition, a fast time-domain signal processing tool with no need for sensitive tuning parameters. Second, the singular value decomposition and nonnegative matrix factorization are employed to decompose the PRCs into its significant components. Finally, eight new normalized features extracted from the output of the data processing techniques are fed into the probabilistic neural network classifier. The data processing techniques employed for classification substantially improve the overall quality of the input patterns classified and increase the generalization capability of the trained classifiers. The proposed scheme is evaluated through two simulated sample systems in the PSCAD/EMTDC software and field fault data. Moreover, the effects of the current transformer saturation, decaying dc component, and noisy conditions are evaluated. The comparison results and discussion regarding the different aspects of the problem confirm the efficacy of the proposed scheme.;
CAD navigation and diagnostics by linking ATE and EDA;This paper describes a specific methodology and software that links automated test equipment (ATE) and electronic design automation (EDA) tools to identify and diagnose failures at the layout level. The ATE software, named wafer fail layout map (WFLMAP), works in concert with the EDA integrated circuits (IC) design database and provides computer-aided design (CAD) navigation and correlation between the tester failure data and IC design data. With this approach, layout-level defect diagnosis is achieved at the individual chip level, as well as at the wafer level. This method can also be used for improved design for manufacturing (DFM).;
A Method to Improve Parameter Estimation Success;This paper introduces a method for improving parameter estimation in statistical models. Parameter estimation is a popular area of study in statistics, and recent years have seen the introduction of new distributions with more parameters to enhance modelling success. While finding a suitable model for a dataset is crucial, accurately estimating parameters is equally important. In some cases, classical parameter estimation methods fail to provide a closed form of estimation for parameters. As a result, researchers commonly resort to numerical methods and software programs for parameter estimation in models. The success rates of models have gained significance with the rising popularity of novel techniques like machine learning algorithms and artificial neural networks. Robust and reliable models are built on the strong theoretical foundations of statistical distributions. Specific distributions are used in various research fields to model datasets, and the assumptions associated with these distributions provide valuable insights into observations. Additionally, parameter estimation results sometimes lead researchers to direct conclusions. This paper presents an improvement method that relies on the estimation of parameters from other statistical distributions. This novel approach aims to make parameter estimation easier and more successful in certain situations. In the applications in this paper, the proposed methodology improves the success rate by up to 10% which provides an additional 6% success in the models.;
A knowledge-based electrical diagnostic system for mining machine maintenance;To investigate the applicability of expert systems in the area of control circuit diagnostics, the US Bureau of Mines has developed a knowledge-based system to diagnose component malfunctions in the electrical control circuit of a continuous mining machine. The system leads the user through the appropriate procedures required to quickly identify the faulty control-circuit component. Graphical displays are incorporated in the system to assist the user in locating the various components and test points. Once the faulty component has been isolated, the system is capable of accessing a database which can provide mine personnel with information concerning specific component part numbers and the availability and location of spare parts. The expert system development tool used to build the system, the structure and development of the knowledge base, and the software used to implement and graphical display and equipment database are discussed.<>;
An XML-based testing strategy for probing security vulnerabilities in the diameter protocol;Buffer overflows and format string attacks are always at the fingertips of hackers. This poses a threat to every application running over an Internet Protocol (IP) networkâ€”from Web servers in the Internet to the session managers in charge of the call session control function (CSCF) in the IP Multimedia Subsystem (IMS) network. As bugs persist in most software development practices, it is critical to perform thorough security testing before the product is finally deployed. This paper proposes an extensible markup languageâ€“(XML)-based testing strategy to detect vulnerabilities and verify robustness to buffer overflow and format string attacks in the implementation of the Diameter protocol, which plays a vital role in IMS billing and subscriber database interfaces. The paper introduces a test generation strategy built upon the XML Schema language's flexibility in data description. It differs from the traditional finite state machineâ€“(FSM)-based syntax testing strategy in the test description, organization, and automation aspects. The proposed strategy is then applied to Alcatel-Lucent Control Platform (A-LCP) Diameter stack security verification by integrating two open source toolsâ€”Seagull and xmlgen. The result supports our continuous effort to identify software security vulnerabilities. Â© 2007 Alcatel-Lucent.;
Process hypercube comparison for signal validation;A signal validation technique for nuclear power plants which uses a process hypercube comparison (PHC) has been developed. The hypercube is merely a multidimensional joint histogram of the process conditions. The hypercube is created offline during a learning phase using operational plant data. In the event that a newly observed plant state does not match with those in the learned hypercube, the PHC algorithm performs signal validation by progressively hypothesizing that one or more signals is in error. This assumption is then either substantiated or denied. In the case where many signals are found to be in error, a conclusion that the process conditions are abnormal is reached. The global database contained within the hypercube provides a best estimate of the process conditions in the event a signal is deemed failed. The hypercube signal validation methodology was tested using operational data from a commercial pressurized water reactor and the Experimental Breeder Reactor II.<>;
Do Datasets Have Politics? Disciplinary Values in Computer Vision Dataset Development;"Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.";
Effective white-box testing of deep neural networks with adaptive neuron-selection strategy;We present Adapt, a new white-box testing technique for deep neural networks. As deep neural networks are increasingly used in safety-first applications, testing their behavior systematically has become a critical problem. Accordingly, various testing techniques for deep neural networks have been proposed in recent years. However, neural network testing is still at an early stage and existing techniques are not yet sufficiently effective. In this paper, we aim to advance this field, in particular white-box testing approaches for neural networks, by identifying and addressing a key limitation of existing state-of-the-arts. We observe that the so-called neuron-selection strategy is a critical component of white-box testing and propose a new technique that effectively employs the strategy by continuously adapting it to the ongoing testing process. Experiments with real-world network models and datasets show that Adapt is remarkably more effective than existing testing techniques in terms of coverage and adversarial inputs found.;
Abstracting failure-inducing inputs;"A program fails. Under which circumstances does the failure occur? Starting with a single failure-inducing input (""The input ((4)) fails"") and an input grammar, the DDSET algorithm uses systematic tests to automatically generalize the input to an abstract failure-inducing input that contains both (concrete) terminal symbols and (abstract) nonterminal symbols from the grammar—for instance, ""((<expr>))"", which represents any expression <expr> in double parentheses. Such an abstract failure-inducing input can be used (1) as a debugging diagnostic, characterizing the circumstances under which a failure occurs (""The error occurs whenever an expression is enclosed in double parentheses""); (2) as a producer of additional failure-inducing tests to help design and validate fixes and repair candidates (""The inputs ((1)), ((3 * 4)), and many more also fail""). In its evaluation on real-world bugs in JavaScript, Clojure, Lua, and UNIX command line utilities, DDSET’s abstract failure-inducing inputs provided to-the-point diagnostics, and precise producers for further failure inducing inputs.";
Scalable analysis of interaction threats in IoT systems;The ubiquity of Internet of Things (IoT) and our growing reliance on IoT apps are leaving us more vulnerable to safety and security threats than ever before. Many of these threats are manifested at the interaction level, where undesired or malicious coordinations between apps and physical devices can lead to intricate safety and security issues. This paper presents IoTCOM, an approach to automatically discover such hidden and unsafe interaction threats in a compositional and scalable fashion. It is backed with auto-mated program analysis and formally rigorous violation detection engines. IoTCOM relies on program analysis to automatically infer the relevant app’s behavior. Leveraging a novel strategy to trim the extracted app’s behavior prior to translating them to analyzable formal specifications,IoTCOM mitigates the state explosion associated with formal analysis. Our experiments with numerous bundles of real-world IoT apps have corroborated IoTCOM’s ability to effectively detect a broad spectrum of interaction threats triggered through cyber and physical channels, many of which were previously unknown, and to significantly outperform the existing techniques in terms of scalability.;
Reinforcement learning based curiosity-driven testing of Android applications;Mobile applications play an important role in our daily life, while it still remains a challenge to guarantee their correctness. Model-based and systematic approaches have been applied to Android GUI testing. However, they do not show significant advantages over random approaches because of limitations such as imprecise models and poor scalability. In this paper, we propose Q-testing, a reinforcement learning based approach which benefits from both random and model-based approaches to automated testing of Android applications. Q-testing explores the Android apps with a curiosity-driven strategy that utilizes a memory set to record part of previously visited states and guides the testing towards unfamiliar functionalities. A state comparison module, which is a neural network trained by plenty of collected samples, is novelly employed to divide different states at the granularity of functional scenarios. It can determine the reinforcement learning reward in Q-testing and help the curiosity-driven strategy explore different functionalities efficiently. We conduct experiments on 50 open-source applications where Q-testing outperforms the state-of-the-art and state-of-practice Android GUI testing tools in terms of code coverage and fault detection. So far, 22 of our reported faults have been confirmed, among which 7 have been fixed.;
Who’s debugging the debuggers? exposing debug information bugs in optimized binaries;"Despite the advancements in software testing, bugs still plague deployed software and result in crashes in production. When debugging issues —sometimes caused by “heisenbugs”— there is the need to interpret core dumps and reproduce the issue offline on the same binary deployed. This requires the entire toolchain (compiler, linker, debugger) to correctly generate and use debug information. Little attention has been devoted to checking that such information is correctly preserved by modern toolchains’ optimization stages. This is particularly important as managing debug information in optimized production binaries is non-trivial, often leading to toolchain bugs that may hinder post-deployment debugging efforts.
In this paper, we present Debug2, a framework to find debug information bugs in modern toolchains. Our framework feeds random source programs to the target toolchain and surgically compares the debugging behavior of their optimized/unoptimized binary variants. Such differential analysis allows Debug2 to check invariants at each debugging step and detect bugs from invariant violations. Our invariants are based on the (in)consistency of common debug entities, such as source lines, stack frames, and function arguments. We show that, while simple, this strategy yields powerful cross-toolchain and cross-language invariants, which can pinpoint several bugs in modern toolchains. We have used Debug2 to find 23 bugs in the LLVM toolchain (clang/lldb), 8 bugs in the GNU toolchain (GCC/gdb), and 3 in the Rust toolchain (rustc/lldb)—with 14 bugs already fixed by the developers.";
Restorable Shortest Path Tiebreaking for Edge-Faulty Graphs;"The restoration lemma by Afek, Bremler-Barr, Kaplan, Cohen, and Merritt [Dist. Comp. '02] proves that, in an undirected unweighted graph, any replacement shortest path avoiding a failing edge can be expressed as the concatenation of two original shortest paths. However, the lemma is tiebreaking-sensitive: if one selects a particular canonical shortest path for each node pair, it is no longer guaranteed that one can build replacement paths by concatenating two selected shortest paths. They left as an open problem whether a method of shortest path tiebreaking with this desirable property is generally possible.
We settle this question affirmatively with the first general construction of restorable tiebreaking schemes. We then show applications to various problems in fault-tolerant network design. These include a faster algorithm for subset replacement paths, more efficient fault-tolerant (exact) distance labeling schemes, fault-tolerant subset distance preservers and +4 additive spanners with improved sparsity, and fast distributed algorithms that construct these objects. For example, an almost immediate corollary of our restorable tiebreaking scheme is the first nontrivial distributed construction of sparse fault-tolerant distance preservers resilient to three faults.";
AutoGRD: Model Recommendation Through Graphical Dataset Representation;The widespread use of machine learning algorithms and the high level of expertise required to utilize them have fuelled the demand for solutions that can be used by non-experts. One of the main challenges non-experts face in applying machine learning to new problems is algorithm selection - the identification of the algorithm(s) that will deliver top performance for a given dataset, task, and evaluation measure. We present AutoGRD, a novel meta-learning approach for algorithm recommendation. AutoGRD first represents datasets as graphs and then extracts their latent representation that is used to train a ranking meta-model capable of accurately recommending top-performing algorithms for previously unseen datasets. We evaluate our approach on 250 datasets and demonstrate its effectiveness both for classification and regression tasks. AutoGRD outperforms state-of-the-art meta-learning and Bayesian methods.;
Coupling Simulation and Hardware for Interactive Circuit Debugging;Simulation offers many advantages when designing analog circuits. Designers can explore alternatives quickly, without added cost or risk of hardware faults. However, it is challenging to use simulation as an aid during interactive debugging of physical circuits, due to difficulties in comparing simulated analyses with hardware measurements. Designers must continually configure simulations to match the state of the physical circuit (e.g. capturing sensor inputs), and must manually rework the hardware to replicate changes or analyses performed in simulation. We propose techniques leveraging instrumentation and programmable test hardware to create a tight coupling between a physical circuit and its simulated model. Bridging these representations helps designers to compare simulated and measured behaviors, and to quickly perform analytical techniques on hardware (e.g. parameter-response analysis) that are typically cumbersome outside of simulation. We implement these techniques in a prototype and show how it aids in efficiently debugging a variety of analog circuits.;
Computing with CORGIS: Diverse, Real-world Datasets for Introductory Computing;To successfully bring introductory computing to non-CS majors, one needs to create a curriculum that will appeal to students from diverse disciplines. Several educational theories emphasize the need for introductory contexts that align with students' long-term goals and are perceived as useful. Data Science, using algorithms to manipulate real-world data and interpreting the results, has emerged as a field with cross-disciplinary value, and has strong potential as an appealing context for introductory computing courses. However, it is not easy to find, clean, and integrate datasets that will satisfy a broad variety of learners. The CORGIS project (https://think.cs.vt.edu/corgis) enables instructors to easily incorporate data science into their classroom. Specifically, it provides over 40 datasets in areas including history, politics, medicine, and education. Additionally, the CORGIS infrastructure supports the integration of new datasets with simple libraries for Java, Python, and Racket, thus empowering introductory students to write programs that manipulate real data. Finally, the CORGIS web-based tools allow learners to visualize and explore datasets without programming, enabling data science lessons on day one. We have incorporated CORGIS assignments into an introductory course for non-majors to study their impact on learners' motivation, with positive initial results. These results indicate that external adopters are likely to find the CORGIS tools and materials useful in their own pedagogical pursuits.;
Efficient scalable thread-safety-violation detection: finding thousands of concurrency bugs during testing;"Concurrency bugs are hard to find, reproduce, and debug. They often escape rigorous in-house testing, but result in large-scale outages in production. Existing concurrency-bug detection techniques unfortunately cannot be part of industry's integrated build and test environment due to some open challenges: how to handle code developed by thousands of engineering teams that uses a wide variety of synchronization mechanisms, how to report little/no false positives, and how to avoid excessive testing resource consumption.
This paper presents TSVD, a thread-safety violation detector that addresses these challenges through a new design point in the domain of active testing. Unlike previous techniques that inject delays randomly or employ expensive synchronization analysis, TSVD uses lightweight monitoring of the calling behaviors of thread-unsafe methods, not any synchronization operations, to dynamically identify bug suspects. It then injects corresponding delays to drive the program towards thread-unsafe behaviors, actively learns from its ability or inability to do so, and persists its learning from one test run to the next. TSVD is deployed and regularly used in Microsoft and it has already found over 1000 thread-safety violations from thousands of projects. It detects more bugs than state-of-the-art techniques, mostly with just one test run.";
FUDGE: fuzz driver generation at scale;At Google we have found tens of thousands of security and robustness bugs by fuzzing C and C++ libraries. To fuzz a library, a fuzzer requires a fuzz driver—which exercises some library code—to which it can pass inputs. Unfortunately, writing fuzz drivers remains a primarily manual exercise, a major hindrance to the widespread adoption of fuzzing. In this paper, we address this major hindrance by introducing the Fudge system for automated fuzz driver generation. Fudge automatically generates fuzz driver candidates for libraries based on existing client code. We have used Fudge to generate thousands of new drivers for a wide variety of libraries. Each generated driver includes a synthesized C/C++ program and a corresponding build script, and is automatically analyzed for quality. Developers have integrated over 200 of these generated drivers into continuous fuzzing services and have committed to address reported security bugs. Further, several of these fuzz drivers have been upstreamed to open source projects and integrated into the OSS-Fuzz fuzzing infrastructure. Running these fuzz drivers has resulted in over 150 bug fixes, including the elimination of numerous exploitable security vulnerabilities.;
Bugs in the Freezer: Detecting Faults in Supermarket Refrigeration Systems Using Energy Signals;"Refrigeration is a major component of supermarket energy consumption. Ensuring faultless operation of refrigeration systems is essential from both economic and sustainability perspectives. Present day industry practises of monitoring refrigeration systems to detect operational anomalies have several drawbacks: (i) Over-dependence on human skills; (ii) Limited help in identifying the root-cause of the anomaly; and (iii) Presumption about high degree of instrumentation - which prevents their usage in supermarkets in developing economies. Existing approaches in literature to detect anomalies in refrigeration systems either are done in controlled laboratory settings or assume the availability of sensory information other than energy. In this paper, we present an approach to detect anomalous behavior in the operation of refrigeration systems by monitoring their energy signals alone. We test the performance of our approach using data collected from refrigeration systems across 25 stores of a real world supermarket chain. We find that using energy signal, we can not only detect anomalies but also narrow down the possible root-cause of the anomaly to a reduced set. Further, using energy signal along with data collected from other sensors (if available) allows us to reduce the false positive rate while identifying the root-cause of the anomaly.";
Database high availability using SHADOW systems;"Hot standby techniques are widely used to implement highly available database systems. These techniques make use of two separate copies of the database, an active copy and a backup that is managed by the standby. The two database copies are stored independently and synchronized by the database systems that manage them. However, database systems deployed in computing clouds often have access to reliable persistent storage that can be shared by multiple servers. In this paper we consider how hot standby techniques can be improved in such settings.
We present SHADOW systems, a novel approach to hot standby high availability. Like other database systems that use shared storage, SHADOW systems push the task of managing database replication out of the database system and into the underlying storage service, simplifying the database system. Unlike other systems, SHADOW systems also provide write offloading, which frees the active database system from the need to update the persistent database. Instead, that responsibility is placed on the standby system. We present the results of a performance evaluation using a SHADOW prototype on Amazon's cloud, showing that write offloading enables SHADOW to outperform traditional hot standby replication and even a standalone DBMS that does not provide high availability.";
Assessing Incremental Testing Practices and Their Impact on Project Outcomes;Software testing is an important aspect of the development process, one that has proven to be a challenge to formally introduce into the typical undergraduate CS curriculum. Unfortunately, existing assessment of testing in student software projects tends to focus on evaluation of metrics like code coverage over the finished software product, thus eliminating the possibility of giving students early feedback as they work on the project. Furthermore, assessing and teaching the process of writing and executing software tests is also important, as shown by the multiple variants proposed and disseminated by the software engineering community, e.g., test-driven development (TDD) or incremental test-last (ITL). We present a family of novel metrics for assessment of testing practices for increments of software development work, thus allowing early feedback before the software project is finished. Our metrics measure the balance and sequence of effort spent writing software tests in a work increment. We performed an empirical study using our metrics to evaluate the test-writing practices of 157 advanced undergraduate students, and their relationships with project outcomes over multiple projects for a whole semester. We found that projects where more testing effort was spent per work session tended to be more semantically correct and have higher code coverage. The percentage of method-specific testing effort spent before production code did not contribute to semantic correctness, and had a negative relationship with code coverage. These novel metrics will enable educators to give students early, incremental feedback about their testing practices as they work on their software projects.;
Interventional Fairness: Causal Database Repair for Algorithmic Fairness;Fairness is increasingly recognized as a critical component of machine learning systems. However, it is the underlying data on which these systems are trained that often reflect discrimination, suggesting a database repair problem. Existing treatments of fairness rely on statistical correlations that can be fooled by statistical anomalies, such as Simpson's paradox. Proposals for causality-based definitions of fairness can correctly model some of these situations, but they require specification of the underlying causal models. In this paper, we formalize the situation as a database repair problem, proving sufficient conditions for fair classifiers in terms of admissible variables as opposed to a complete causal model. We show that these conditions correctly capture subtle fairness violations. We then use these conditions as the basis for database repair algorithms that provide provable fairness guarantees about classifiers trained on their training labels. We evaluate our algorithms on real data, demonstrating improvement over the state of the art on multiple fairness metrics proposed in the literature while retaining high utility.;
Evaluating Characteristics of CUDA Communication Primitives on High-Bandwidth Interconnects;"Data-intensive applications such as machine learning and analytics have created a demand for faster interconnects to avert the memory bandwidth wall and allow GPUs to be effectively leveraged for lower compute intensity tasks. This has resulted in wide adoption of heterogeneous systems with varying underlying interconnects, and has delegated the task of understanding and copying data to the system or application developer. No longer is a malloc followed by memcpy the only or dominating modality of data transfer; application developers are faced with additional options such as unified memory and zero-copy memory. Data transfer performance on these systems is now impacted by many factors including data transfer modality, system interconnect hardware details, CPU caching state, CPU power management state, driver policies, virtual memory paging efficiency, and data placement.
This paper presents Comm|Scope, a set of microbenchmarks designed for system and application developers to understand memory transfer behavior across different data placement and exchange scenarios. Comm|Scope comprehensively measures the latency and bandwidth of CUDA data transfer primitives, and avoids common pitfalls in ad-hoc measurements by controlling CPU caches, clock frequencies, and avoids measuring synchronization costs imposed by the measurement methodology where possible. This paper also presents an evaluation of Comm|Scope on systems featuring the POWER and x86 CPU architectures and PCIe 3, NVLink 1, and NVLink 2 interconnects. These systems are chosen as representative configurations of current high-performance GPU platforms. Comm|Scope measurements can serve to update insights about the relative performance of data transfer methods on current systems. This work also reports insights for how high-level system design choices affect the performance of these data transfers, and how developers can optimize applications on these systems.";
Pre-training Code Representation with Semantic Flow Graph for Effective Bug Localization;Enlightened by the big success of pre-training in natural language processing pre-trained models for programming languages have been widely used to promote code intelligence in recent years. In particular BERT has been used for bug localization tasks and impressive results have been obtained. However these BERT-based bug localization techniques suffer from two issues. First the pre-trained BERT model on source code does not adequately capture the deep semantics of program code. Second the overall bug localization models neglect the necessity of large-scale negative samples in contrastive learning for representations of changesets and ignore the lexical similarity between bug reports and changesets during similarity estimation. We address these two issues by 1) proposing a novel directed multiple-label code graph representation named Semantic Flow Graph (SFG) which compactly and adequately captures code semantics 2) designing and training SemanticCodeBERT based on SFG and 3) designing a novel Hierarchical Momentum Contrastive Bug Localization technique (HMCBL). Evaluation results show that our method achieves state-of-the-art performance in bug localization.;
Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering;A large number of bug reports are created during the evolution of a software system. Locating the source code files that need to be changed in order to fix these bugs is a challenging task. Information retrieval-based bug localization techniques do so by correlating bug reports with historical information about the source code (e.g. previously resolved bug reports commit logs). These techniques have shown to be efficient and easy to use. However one flaw that is nearly omnipresent in all these techniques is that they ignore code refactorings. Code refactorings are common during software system evolution but from the perspective of typical version control systems they break the code history. For example a class when renamed then appears as two separate classes with separate histories. Obviously this is a problem that affects any technique that leverages code history. This paper proposes a refactoring-aware traceability model to keep track of the code evolution history. With this model we reconstruct the code history by analyzing the impact of code refactorings to correctly stitch together what would otherwise be a fragmented history. To demonstrate that a refactoring aware history is indeed beneficial we investigated three widely adopted bug localization techniques that make use of code history which are important components in existing approaches. Our evaluation on 11 open source projects shows that taking code refactorings into account significantly improves the results of these bug localization techniques without significant changes to the techniques themselves. The more refactorings are used in a project the stronger the benefit we observed. Based on our findings we believe that much of the state of the art leveraging code history should benefit from our work.;
Proceedings of the 45th International Conference on Software Engineering;Automatically localizing software bugs to the changesets that induced them has the potential to improve software developer efficiency and to positively affect software quality. To facilitate this automation a bug report has to be effectively matched with source code changes even when a significant lexical gap exists between natural language used to describe the bug and identifier naming practices used by developers. To bridge this gap we need techniques that are able to capture software engineering-specific and project-specific semantics in order to detect relatedness between the two types of documents that goes beyond exact term matching. Popular transformer-based deep learning architectures such as BERT excel at leveraging contextual information hence appear to be a suitable candidate for the task. However BERT-like models are computationally expensive which precludes them from being used in an environment where response time is important.In this paper we describe how BERT can be made fast enough to be applicable to changeset-based bug localization. We also explore several design decisions in using BERT for this purpose including how best to encode changesets and how to match bug reports to individual changes for improved accuracy. We compare the accuracy and performance of our model to a non-contextual baseline (i.e. vector space model) and BERT-based architectures previously used in software engineering. Our evaluation results demonstrate advantages in using the proposed BERT model compared to the baselines especially for bug reports that lack any hints about related code elements.;
Proceedings of the 44th International Conference on Software Engineering;Bug localization can effectively reduce software maintenance costs. Recently deep learning-based bug localization (DLBL) has demonstrated its effectiveness in bridging the lexical gaps between bug reports (BRs) and source code files (SFs). Deliberate feature selection that considers the unique characteristics of SFs can boost DLBL. Using the various features of SFs we propose the following three methods to identify the features that can improve DLBL 1) text token restriction 2) program graph construction and 3) projection. First the text token information of SFs is used to avoid selecting a text token that can become a noise feature. Second we propose a five rules to construct a program graph that can supplement the textual features. Our program graph can highlight the difference between buggy and non-buggy SFs while preserving the individual characteristics of each SF and interleaved relationships of SFs. We treat the entire program of the project as a knowledge graph whose subgraphs are SFs. Even if the features of the SFs are presented well by existing approaches these approaches have a limitation in that they choose parts irrelevant to the bug as a feature because the same features represent the SF for all of the different input BRs. Therefore we propose projecting the SF feature vectors onto the BR feature vectors to highlight the BR-relative features of the SF for different BRs. We evaluated our proposed method on widely used open-source Java projects. The experimental results on 1928 BRs from 10 Java projects showed the effectiveness of the proposed method. The proposed method can improve bug localization accuracy by an average of 34%.;
Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing;Information Retrieval (IR) methods have been recently employed to provide automatic support for bug localization tasks. However for an IR-based bug localization tool to be useful it has to achieve adequate retrieval accuracy. Lower precision and recall can leave developers with large amounts of incorrect information to wade through. To address this issue in this paper we systematically investigate the impact of combining various IR methods on the retrieval accuracy of bug localization engines. The main assumption is that different IR methods targeting different dimensions of similarity between artifacts can be used to enhance the confidence in each others' results. Five benchmark systems from different application domains are used to conduct our analysis. The results show that a) near-optimal global configurations can be determined for different combinations of IR methods b) optimized IR-hybrids can significantly outperform individual methods as well as other unoptimized methods and c) hybrid methods achieve their best performance when utilizing information-theoretic IR methods. Our findings can be used to enhance the practicality of IR-based bug localization tools and minimize the cognitive overload developers often face when locating bugs.;
Proceedings of the 28th International Conference on Program Comprehension;Despite all efforts to avoid bugs software sometimes crashes in the field leaving crash traces as the only information to localize the problem. Prior approaches on localizing where to fix the root cause of a crash do not scale well to ultra-large scale heterogeneous code bases that contain millions of code files written in multiple programming languages. This paper presents Scaffle the first scalable bug localization technique which is based on the key insight to divide the problem into two easier sub-problems. First a trained machine learning model predicts which lines of a raw crash trace are most informative for localizing the bug. Then these lines are fed to an information retrieval-based search engine to retrieve file paths in the code base predicting which file to change to address the crash. The approach does not make any assumptions about the format of a crash trace or the language that produces it. We evaluate Scaffle with tens of thousands of crash traces produced by a large-scale industrial code base at Facebook that contains millions of possible bug locations and that powers tools used by billions of people. The results show that the approach correctly predicts the file to fix for 40% to 60% (50% to 70%) of all crash traces within the top-1 (top-5) predictions. Moreover Scaffle improves over several baseline approaches including an existing classification-based approach a scalable variant of existing information retrieval-based approaches and a set of hand-tuned industrially deployed heuristics.;
Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis;Information-retrieval-based bug localization (IRBL) generates a ranked list of source files by using bug reports as queries and provides the list to developers to reduce debugging costs. The IRBL performance is typically evaluated by batch because the evaluation process considers the first ranked list as the final ranked list for developers. This process assumes that the developer only examines the ranked list once. However in this conventional IRBL evaluation process the knowledge acquired by the developer through examining the ranked list is omitted. Disregarding this knowledge limits the development of IRBL techniques for effectively reducing effort in identifying all buggy files. An iterative IRBL evaluation process that considers knowledge acquisition based on developer feedback is proposed herein. In this iterative IRBL it is discovered that the first buggy file is a better-quality query than the bug report. Hence we propose a boosting method for IRBL using the first buggy file. We analyze five IRBL methods using 5290 bug reports obtained from 156 projects. By performing large-scale experiments we demonstrate that our boosting method improves the mean average precision from 6% to 17% and reduces the effort in localizing both the second and final buggy files. Our evaluation process facilitates the development of an IRBL method that can effectively reduce the effort required to locate all buggy files.;
Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering;Owing to the increasing size and complexity of software large/small bugs have become inevitable. To fix software bugs in some cases developers may need to spend a considerable amount of time debugging. Some studies have reported that typographical errors in natural and programming languages are nearly identical. We herein propose a method to solve these mistakes automatically. We perform bug localization using an autoencoder and CNN to compute a rank score. In details we extract features from bug reports and program source code. Then we input these features into the autoencoder. Next the output of autoencoder applies to the CNN. Finally we compute a rank score between the bug report and program source code. Regarding bug repair we utilize Seq-GAN algorithm. In details first we convert program source code into multiple lines with tokens. Then we apply the Seq-GAN algorithm to generate the candidate buggy patches. To evaluate the effectiveness of the proposed method performance comparisons with similar related studies were conducted. The comparison shows that our approach produces better results compared to other studies.;
Proceedings of the 35th Annual ACM Symposium on Applied Computing;This paper reports on a large-scale comparative evaluation of IR-based tools for automatic bug localization. We have divided the tools in our evaluation into the following three generations: (1) The first-generation tools now over a decade old that are based purely on the Bag-of-Words (BoW) modeling of software libraries. (2) The somewhat more recent second-generation tools that augment BoW-based modeling with two additional pieces of information: historical data such as change history and structured information such as class names method names etc. And finally (3) The third-generation tools that are currently the focus of much research and that also exploit proximity order and semantic relationships between the terms. It is important to realize that the original authors of all these three generations of tools have mostly tested them on relatively small-sized datasets that typically consisted no more than a few thousand bug reports. Additionally those evaluations only involved Java code libraries. The goal of the present paper is to present a comprehensive large-scale evaluation of all three generations of bug-localization tools with code libraries in multiple languages. Our study involves over 20000 bug reports drawn from a diverse collection of Java C/C++ and Python projects. Our results show that the third-generation tools are significantly superior to the older tools. We also show that the word embeddings generated using code files written in one language are effective for retrieval from code libraries in other languages.;
Proceedings of the 17th International Conference on Mining Software Repositories;Recent findings suggest that Information Retrieval (IR)-based bug localization techniques do not perform well if the bug report lacks rich structured information (e.g. relevant program entity names). Conversely excessive structured information (e.g. stack traces) in the bug report might not always help the automated localization either. In this paper we propose a novel technique--BLIZZARD-- that automatically localizes buggy entities from project source using appropriate query reformulation and effective information retrieval. In particular our technique determines whether there are excessive program entities or not in a bug report (query) and then applies appropriate reformulations to the query for bug localization. Experiments using 5139 bug reports show that our technique can localize the buggy source documents with 7%--56% higher Hit@10 6%--62% higher MAP@10 and 6%--62% higher MRR@10 than the baseline technique. Comparison with the state-of-the-art techniques and their variants report that our technique can improve 19% in MAP@10 and 20% in MRR@10 over the state-of-the-art and can improve 59% of the noisy queries and 39% of the poor queries.;
Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;In recent years the use of Information Retrieval (IR) techniques to automate the localization of buggy files given a bug report has shown promising results. The abundance of approaches in the literature however contrasts with the reality of IR-based bug localization (IRBL) adoption by developers (or even by the research community to complement other research approaches). Presumably this situation is due to the lack of comprehensive evaluations for state-of-the-art approaches which offer insights into the actual performance of the techniques.  We report on a comprehensive reproduction study of six state-of-the-art IRBL techniques. This study applies not only subjects used in existing studies (old subjects) but also 46 new subjects (61431 Java files and 9459 bug reports) to the IRBL techniques. In addition the study compares two different version matching (between bug reports and source code files) strategies to highlight some observations related to performance deterioration. We also vary test file inclusion to investigate the effectiveness of IRBL techniques on test files or its noise impact on performance. Finally we assess potential performance gain if duplicate bug reports are leveraged.;
Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis;In software development bug localization is the process finding portions of source code associated to a submitted bug report. This task has been modeled as an information retrieval task at source code file where the report is the query. In this work we propose a model that instead of working at file level learns feature representations from source changes extracted from the project history at both syntactic and code change dependency perspectives to support bug localization. To that end we structured an end-to-end architecture able to integrate feature learning and ranking between sets of bug reports and source code changes. We evaluated our model against the state of the art of bug localization on several real world software projects obtaining competitive results in both intra-project and cross-project settings. Besides the positive results in terms of model accuracy as we are giving the developer not only the location of the bug associated to the report but also the change that introduced we believe this could give a broader context for supporting fixing tasks.;
Proceedings of the 27th ACM International Conference on Information and Knowledge Management;Bug localization is a technique that has been proposed to support the process of identifying the locations of bugs specified in a bug report. A traditional approach such as information retrieval (IR)-based bug localization calculates the similarity between the bug description and the source code and suggests locations that are likely to contain the bug. However while many approaches have been proposed to improve the accuracy the likelihood of each module having a bug is often overlooked or they are treated equally whereas this may not be the case. For example modules having code smells have been found to be more prone to changes and faults. Therefore in this paper we explore a first step toward leveraging code smells to improve bug localization. By combining the code smell severity with the textual similarity from IR-based bug localization we can identify the modules that are not only similar to the bug description but also have a higher likelihood of containing bugs. Our preliminary evaluation on four open source projects shows that our technique can improve the baseline approach by 142.25% and 30.50% on average for method and class levels respectively.;
Proceedings of the 26th Conference on Program Comprehension;Locating bugs in industry-size software systems is time consuming and challenging. An automated approach for assisting the process of tracing from bug descriptions to relevant source code benefits developers. A large body of previous work aims to address this problem and demonstrates considerable achievements. Most existing approaches focus on the key challenge of improving techniques based on textual similarity to identify relevant files. However there exists a lexical gap between the natural language used to formulate bug reports and the formal source code and its comments. To bridge this gap state-of-the-art approaches contain a component for analyzing bug history information to increase retrieval performance. In this paper we propose a novel approach TraceScore that also utilizes projects' requirements information and explicit dependency trace links to further close the gap in order to relate a new bug report to defective source code files. Our evaluation on more than 13000 bug reports shows that TraceScore significantly outperforms two state-of-the-art methods. Further by integrating TraceScore into an existing bug localization algorithm we found that TraceScore significantly improves retrieval performance by 49% in terms of mean average precision (MAP).;
Proceedings of the 15th International Conference on Mining Software Repositories;[Context] Several static analysis tools allow the development of custom rules for locating application-specific defects. Although this feature is powerful and commonly available it is not well explored in practice. Custom static analysis rules can check design and policies that are shared between applications allowing the reuse of rules. However the benefits scope and concerns that software engineers should have on reusing custom static analysis rules are unknown. [Goal] In this preliminary study we investigate the reuse of custom static analysis rules produced by applying Pattern-Driven Maintenance (PDM). PDM is a method to locate defect patterns in web applications that produces custom static analysis rules as output. [Method] We selected a set of rules produced by a previous usage of the PDM method and applied them to other three applications in two contexts within the same company where the rules were produced and in other companies. [Results] We successfully reused some rules in both scenarios with minor adjustments finding new defects to be fixed. The reuse of rules could discard from 58-90% of source code locations found by a naive search for the defects reducing verification effort. However the reused rules need adjustments to improve precision for defect localization as precision ranged from 40-75%. Finally we identified factors that have an impact on reusing custom rules. [Conclusions] We put forward that reusing customized static analysis rules can be beneficial in particular when similarities in the architecture and programming style are observed. However adjustment of the rules might be needed to enable effective reuse. We shared our insights and methodology on how to reuse custom static analysis rules properly.;
Proceedings of the XIX Brazilian Symposium on Software Quality;The automated task of locating the potential buggy files in a software project given a bug report is called bug localization. Bug localization helps developers focus on crucial files. However the existing automated bug localization approaches face a key challenge called lexical mismatch. Specifically the terms used in bug reports to describe a bug are different from the terms and code tokens used in source files. To address that we present a novel approach that uses deep neural network (DNN) in combination with rVSM an information retrieval (IR) technique. rVSM collects the feature on the textual similarity between bug reports and source files. DNN is used to learn to relate the terms in bug reports to potentially different code tokens and terms in source files. Our empirical evaluation on real-world bug reports in the open-source projects shows that DNN and IR complement well to each other to achieve higher bug localization accuracy than individual models. Importantly our new model DnnLoc with a combination of the features built from DNN rVSM and project's bug-fixing history achieves higher accuracy than the state-of-the-art IR and machine learning techniques. In half of the cases it is correct with just a single suggested file. In 66% of the time a correct buggy file is in the list of three suggested files. With 5 suggested files it is correct in almost 70% of the cases.;
Proceedings of the 25th International Conference on Program Comprehension;Automatic query reformulation techniques for Information Retrieval based Bug Localization (IRBL) have been proposed to improve the quality of queries and IRBL performance. Recently proposed techniques determine the quality of queries via the bugs' description and reformulate them using important terms in the top-N source files retrieved by the initial query. However the bugs' description may not contain enough information about the bugs and the retrieved top-N files may not always provide important terms. In this paper we propose a novel automatic query reformulation approach to improve IRBL performance beyond that of a recent technique. Our method expands bug reports using attachments and expands queries by reducing the noisy terms in them. We experimented with 1546 bug reports. According to our results we found that the quality of 70 reports was wrongly determined and our method improved IRBL performance by up to 118% for these reports. Moreover compared with a state-of-the-art technique our method resulted in improvements of approximately 17% in Top-1 11% in MRR@10 and 10% in MAP@10.;
Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing;Background: Developers spend a significant amount of time and effort to localize bugs. In the literature many researchers proposed state-of-the-art bug localization models to help developers localize bugs easily. The practitioners on the other hand expect a bug localization tool to meet certain criteria such as trustworthiness scalability and efficiency. The current models are not capable of meeting these criteria making it harder to adopt these models in practice. Recently deep-learning-based bug localization models have been proposed in the literature. They show a better performance than the state-of-the-art models.Aim: In this research we would like to investigate whether deep learning models meet the expectations of practitioners or not.Method: We constructed a Convolution Neural Network and a Simple Logistic model to examine their effectiveness in localizing bugs. We train these models on five open source projects written in Java and compare their performance with the performance of other state-of-the-art models trained on these datasets.Results: Our experiments show that although the deep learning models perform better than classic machine learning models they meet the adoption criteria set by the practitioners only partially.Conclusions: This work provides evidence that the practitioners should be cautious while using the current state of the art models for production-level use-cases. It also highlights the need for standardization of performance benchmarks to ensure that bug localization models are assessed equitably and realistically.;
Proceedings of the Fifteenth International Conference on Predictive Models and Data Analytics in Software Engineering;Issue tracking systems are valuable resources during software maintenance activities and contain information about the issues faced during the development of a project as well as after its release. Many projects receive many reports of bugs and it is challenging for developers to manually debug and fix them. To mitigate this problem past studies have proposed information retrieval (IR)-based bug localization techniques which takes as input a textual description of a bug stored in an issue tracking system and returns a list of potentially buggy source code files.These studies often evaluate their effectiveness on issue reports marked as bugs in issue tracking systems using as ground truth the set of files that are modified in commits that fix each bug. However there are a number of potential biases that can impact the validity of the results reported in these studies. First issue reports marked as bugs might not be reports of bugs due to error in the reporting and classification process. Many issue reports are about documentation update request for improvement refactoring code cleanups etc. Second bug reports might already explicitly specify the buggy program files and for these reports bug localization techniques are not needed. Third files that get modified in commits that fix the bugs might not contain the bug.This study investigates the extent these potential biases affect the results of a bug localization technique and whether bug localization researchers need to consider these potential biases when evaluating their solutions. In this paper we analyse issue reports from three different projects: HTTPClient Jackrabbit and Lucene-Java to examine the impact of above three biases on bug localization. Our results show that one of these biases significantly and substantially impacts bug localization results while the other two biases have negligible or minor impact.;
Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering;Recent years have seen a growing interest in deep learning-based approaches to localize faults in software. However existing methods have not reached a satisfying level of accuracy. The main reason is that the feature extraction of faulty code elements is insufficient. Namely these deep learning-based methods will learn some features that are not relevant to fault localization and thus ignore the features related to fault localization. We propose SupConFL a new framework for statement-level fault localization. Our framework combines the statement-level abstract syntax tree with the statement sequence and adopt controllable attention-based LSTM to locate the faulty elements. The training is done through contrastive learning between the faulty code and its fixed version. By comparing the faulty code with the fixed code the model can learn richer features of the faulty code elements. Our experiments on Defects4j-1.2.0 dataset show that our method outperforms the current state-of-the-art. Specifically SupConFL improves Top-1 score by 7.96% in comparison with the current state-of-the-art. In addition our method has also achieved good results in cross-project experiments.;
Proceedings of the 14th Asia-Pacific Symposium on Internetware;Rich datasets have empowered various deep learning (DL) applications leading to remarkable success in many fields.  However data faults hidden in the datasets could result in DL applications behaving unpredictably and even cause massive monetary and life losses.  To alleviate this problem in this paper we propose a dynamic data fault localization approach namely DFauLo to locate the mislabeled and noisy data in the deep learning datasets.  DFauLo is inspired by the conventional mutation-based code fault localization but utilizes the differences between DNN mutants to amplify and identify the potential data faults.  Specifically it first generates multiple DNN model mutants of the original trained model. Then it extracts features from these mutants and maps them into a suspiciousness score indicating the probability of the given data being a data fault.  Moreover DFauLo is the first dynamic data fault localization technique prioritizing the suspected data based on user feedback and providing the generalizability to unseen data faults during training.  To validate DFauLo we extensively evaluate it on 26 cases with various fault types data types and model structures.  We also evaluate DFauLo on three widely-used benchmark datasets.  The results show that DFauLo outperforms the state-of-the-art techniques in almost all cases and locates hundreds of different types of real data faults in benchmark datasets.;
Proceedings of the 22nd International Conference on Evaluation and Assessment in Software Engineering 2018;Debugging often takes much effort and resources. To help developers debug numerous information retrieval (IR)-based and spectrum-based bug localization techniques have been proposed. IR-based techniques process textual information in bug reports while spectrum-based techniques process program spectra (i.e. a record of which program elements are executed for each test case). Both eventually generate a ranked list of program elements that are likely to contain the bug. However these techniques only consider one source of information either bug reports or program spectra which is not optimal. To deal with the limitation of existing techniques in this work we propose a new multi-modal technique that considers both bug reports and program spectra to localize bugs. Our approach adaptively creates a bug-specific model to map a particular bug to its possible location and introduces a novel idea of suspicious words that are highly associated to a bug. We evaluate our approach on 157 real bugs from four software systems and compare it with a state-of-the-art IR-based bug localization method a state-of-the-art spectrum-based bug localization method and three state-of-the-art multi-modal feature location methods that are adapted for bug localization. Experiments show that our approach can outperform the baselines by at least 47.62% 31.48% 27.78% and 28.80% in terms of number of bugs successfully localized when a developer inspects 1 5 and 10 program elements (i.e. Top 1 Top 5 and Top 10) and Mean Average Precision (MAP) respectively.;
Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering;The pressing demand for high-quality mobile applications has a major influence on Software Engineering practices such as testing and debugging. The variety of mobile platforms is permeated with different resources related to communication capabilities sensors and user-controlled options. As a result applications may exhibit unexpected behaviors and resource interactions can introduce failures that manifest themselves in specific resource combinations. These failures can affect the quality of mobile applications and degrade the user experience. To reduce human effort of manual debugging several techniques have been proposed and developed aiming to partially or fully automate fault localization. Fault localization techniques such as Spectrum-based Fault Localization (SBFL) identify suspicious faulty program elements related to a software failure. However we still lack empirical knowledge about the applicability of fault localization techniques in the context of mobile applications specifically considering resource interaction failures. To address this problem this paper evaluates the use of SBFL aiming to locate faults in 8 Android applications and verify the sensitivity of SBFL to variations in resource interactions. We rely on mutation testing to simulate faults and on the Ochiai coefficient as an indicator of the suspicious faulty code. Our results indicate that SBFL is able to rank more than 75% of the faulty code in 6 out of 8 applications. We also observed that the ranking of suspicious code varies depending on the combination of enabled resources (e.g. Wi-Fi and Location) in the mobile applications.;
Proceedings of the XXXVII Brazilian Symposium on Software Engineering;Spectrum-based fault localization (SBFL) techniques can aid in debugging but their practicality in industrial settings has been limited due to the large number of tests needed to execute before applying SBFL. Previous research has explored different trigger modes for SBFL and found that applying it immediately after the first test failure is also effective. However this study only considered single-location bugs while multi-location bugs are prevalent in real-world scenarios and especially at our company Cvent which is interested in integrating SBFL to its CI/CD workflow.  In this work we investigate the effectiveness of SBFL on multi-location bugs and propose a framework called Instant Fault Localization for Multi-location Bugs (IFLM). We compare and evaluate four trigger modes of IFLM using open-source (Defects4J) and close-source (Cvent) bug datasets.  Our study showed that it is not necessary to execute all test cases before applying SBFL. However we also found that that applying SBFL right after the first failed test is less effective than applying it after executing all tests for multi-location bugs which is contrary to the single-location bug study. We also observe differences in performance between real and artificial bugs. Our contributions include the development of IFLM and CVent bug datasets analysis of SBFL effectiveness for multi-location bugs and practical implications for integrating SBFL in industrial environments.;
Proceedings of the 3rd Workshop on Machine Learning and Systems;Automated fault localization techniques collect runtime information as input data to identify suspicious statement potentially responsible for program failures. To discover the statistical coincidences between test results (i.e. failing or passing) and the executions of the different statements of a program (i.e. executed or not executed) researchers developed a suspiciousness methodology (e.g. spectrum-based formulas and deep neural network models). However the occurrences of coincidental correctness (CC) which means the faulty statements were executed but the output of the program was right affect the effectiveness of fault localization. Many researchers seek to identify CC tests using cluster analysis. However the high-dimensional data containing too much noise reduce the effectiveness of cluster analysis.To overcome the obstacle we propose CBCFL: a context-based cluster fault localization approach which incorporates a failure context showing how a failure is produced into cluster analysis. Specifically CBCFL uses the failure context containing the statements whose execution affects the output of a failing test as input data for cluster analysis to improve the effectiveness of identifying CC tests. Since CC tests execute the faulty statement we change the labels of CC tests into failing tests. We take the context and the corresponding changed labels as the input data for fault localization techniques. To evaluate the effectiveness of CBCFL we conduct large-scale experiments on six large-sized programs using five state-of-the-art fault localization approaches. The experimental results show that CBCFL is more effective than the baselines e.g. our approach can improve the MLP-FL method using cluster analysis by at most 200% 250% and 320% under the Top-1 Top-5 and Top-10 accuracies.;
Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension;Bug localization is challenging and time-consuming. Given a bug report a developer may spend tremendous time comprehending the bug description together with code in order to locate bugs. To facilitate bug report comprehension information retrieval (IR)-based bug localization techniques have been proposed to automatically search for and rank potential buggy code elements (i.e. classes or methods). However these techniques do not leverage any dynamic execution information of buggy programs. In this paper we perform the first systematic study on how dynamic execution information can help with static IR-based bug localization. More specifically with the fixing patches and bug reports of 157 real bugs we investigated the impact of various execution information (i.e. coverage slicing and spectrum) on three IR-based techniques: the baseline technique BugLocator and BLUiR.Our experiments demonstrate that both the coverage and slicing information of failed tests can effectively reduce the search space and improve IR-based techniques at both class and method levels. Using additional spectrum information can further improve bug localization at the method but not the class level. Some of our investigated ways of augmenting IR-based bug localization with execution information even outperform a state-of-the-art technique which merges spectrum with an IR-based technique in a complicated way. Different from prior work by investigating various easy-to-understand ways to combine execution information with IR-based techniques this study shows for the first time that execution information can generally bring considerable improvement to IR-based bug localization.;
Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Debugging aims at finding and correcting software defects. To help the developer fault localization techniques were developed using association metrics and code coverage data spectra to identify the most suspicious code snippets. They assist the developer by means of a ranking of the most suspicious spectra that guides the developer in his or her â€huntâ€ for defects. These techniques when based on data flow spectra use definition use associations (DUA) for ranking calculation. However the coverage of given DUAs often guarantees the coverage of other DUAs in a relationship between DUAs called subsumption. In practice the subsumption relationship means that if a given DUA is covered others are also guaranteed to be covered in certain conditions. Based on the subsumption property this work presents an experiment in which fault localization effectiveness is assessed using only the spectra of the set of unconstrained DUAs that is the minimal set of DUAs that may guarantee coverage of all other DUAs of the software under test. For this experiment we use a subset of programs of the Defects4J repository data flow spectra and the Ochiai association metric. Our results compare the rankings produced by the set of unconstrained DUAs against those produced by all DUAs for fault localization. They indicate that most of the faults reached by DUA spectra can be found by inspecting only the unconstrained DUAs.;
Proceedings of the 7th Brazilian Symposium on Systematic and Automated Software Testing;Software projects can grow very rapidly reaching hundreds or thousands of files in a relatively short time span. Therefore manually finding the source code parts that should be changed in order to fix a failure is a difficult task. Static bug localization techniques provide cost-effective means of finding files related to the failure described in a bug report. Recently structured information retrieval (IR) has been used to improve the effectiveness of static bug localization being successfully applied by techniques such as BLUiR BLUiR+ and AmaLgam. However there are some significant shortcomings on how these techniques were evaluated. First virtually all evaluations have been limited to very few projects written in only one object-oriented programming language particularly Java. Therefore the effectiveness of these techniques in other widely-used object-oriented languages such as C# is still unknown. Second the experimental setup for most of the evaluations make simplistic assumptions that do not hold on real-world scenarios thereby raising doubts about the reported effectiveness of these techniques. In this paper we evaluate BLUiR BLUiR+ and AmaLgam on 20 C# projects providing a first assessment of these techniques on a previously untested object-oriented language. Moreover we set up an experiment that addresses the simplistic assumptions commonly present in bug localization studies thereby providing evidence on how their findings may be biased. Finally we extend the algorithms of existing techniques in order to understand if structured information retrieval can benefit from the use of a wider range of program constructs including C# constructs inexistent in Java.;
Proceedings of the XXX Brazilian Symposium on Software Engineering;Compilers for statically typed functional programming languages are notorious for generating confusing type error messages. When the compiler detects a type error it typically reports the program location where the type checking failed as the source of the error. Since other error sources are not even considered the actual root cause is often missed. A more adequate approach is to consider all possible error sources and report the most useful one subject to some usefulness criterion. In our previous work we showed that this approach can be formulated as an optimization problem related to satisfiability modulo theories (SMT). This formulation cleanly separates the heuristic nature of usefulness criteria from the underlying search problem. Unfortunately algorithms that search for an optimal error source cannot directly use principal types which are crucial for dealing with the exponential-time complexity of the decision problem of polymorphic type checking. In this paper we present a new algorithm that efficiently finds an optimal error source in a given ill-typed program. Our algorithm uses an improved SMT encoding to cope with the high complexity of polymorphic typing by iteratively expanding the typing constraints from which principal types are derived. The algorithm preserves the clean separation between the heuristics and the actual search. We have implemented our algorithm for OCaml. In our experimental evaluation we found that the algorithm reduces the running times for optimal type error localization from minutes to seconds and scales better than previous localization algorithms.;
Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming;Modern distributed applications run across numerous microservices and components deployed in cloud datacenters using shared cloud services for computing and storage edge services such as content distribution networks network functions such as rate limiters and firewalls security infrastructures network routers and physical links. When a user-visible fault occurs the first step toward diagnosis is localization to determine where the fault has occurred. However because application delivery spans different layers and different organizations no entity has complete visibility or access to the information required to localize faults quickly. This paper proposes a cross-layer cross-domain and cross-application fault localization primitive with a simple and standardized information interface for the Internet.;
Proceedings of the 21st ACM Workshop on Hot Topics in Networks;Fault Localization (FL) is a precursor step to most Automated Program Repair (APR) approaches which fix the faulty statements identified by the FL tools. We present FixLocator a Deep Learning (DL)-based fault localization approach supporting the detection of faulty statements in one or multiple methods that need to be modified accordingly in the same fix. Let us call them co-change (CC) fixing locations for a fault. We treat this FL problem as dual-task learning with two models. The method-level FL model MethFL learns the methods to be fixed together. The statement-level FL model StmtFL learns the statements to be co-fixed. Correct learning in one model can benefit the other and vice versa. Thus we simultaneously train them with soft-sharing the models' parameters via cross-stitch units to enable the propagation of the impact of MethFL and StmtFL onto each other. Moreover we explore a novel feature for FL: the co-changed statements. We also use Graph-based Convolution Network to integrate different types of program dependencies.  Our empirical results show that FixLocator relatively improves over the state-of-the-art statement-level FL baselines by locating 26.5%â€“155.6% more CC fixing statements. To evaluate its usefulness in APR we used FixLocator in combination with the state-of-the-art APR tools. The results show that FixLocator+DEAR (the original FL in DEAR replaced by FixLocator) and FixLocator+CURE improve relatively over the original DEAR and Ochiai+CURE by 10.5% and 42.9% in terms of the number of fixed bugs.;
Proceedings of the 11th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering;Automatic software debugging mainly includes two tasks of fault localization and automated program repair. Compared with the traditional spectrum-based and mutation-based methods deep learning-based methods are proposed to achieve better performance for fault localization. However the existing methods ignore the deep semantic features or only consider simple code representations. They do not leverage the existing bug-related knowledge from large-scale open-source projects either. In addition existing template-based program repair techniques can incorporate project specific information better than deep-learning approaches. However they are weak in selecting the fix templates for efficient program repair. In this work we propose a novel approach called TRANSFER which leverages the deep semantic features and transferred knowledge from open-source data to improve fault localization and program repair. First we build two large-scale open-source bug datasets and design 11 BiLSTM-based binary classifiers and a BiLSTM-based multi-classifier to learn deep semantic features of statements for fault localization and program repair respectively. Second we combine semantic-based spectrum-based and mutation-based features and use an MLP-based model for fault localization. Third the semantic-based features are leveraged to rank the fix templates for program repair. Our extensive experiments on widely-used benchmark De-fects4J show that TRANSFER outperforms all baselines in fault localization and is better than existing deep-learning methods in automated program repair. Compared with the typical template-based work TBar TRANSFER can correctly repair 6 more bugs (47 in total) on Defects4J.;
Proceedings of the 13th Asia-Pacific Symposium on Internetware;Fast and accurate localization of software defects continues to be a difficult problem since defects can emanate from a large variety of sources and can often be intricate in nature. In this paper we show how version histories of a software project can be used to estimate a prior probability distribution for defect proneness associated with the files in a given version of the project. Subsequently these priors are used in an IR (Information Retrieval) framework to determine the posterior probability of a file being the cause of a bug. We first present two models to estimate the priors one from the defect histories and the other from the modification histories with both types of histories as stored in the versioning tools. Referring to these as the base models we then extend them by incorporating a temporal decay into the estimation of the priors. We show that by just including the base models the mean average precision (MAP) for bug localization improves by as much as 30%. And when we also factor in the time decay in the estimates of the priors the improvements in MAP can be as large as 80%.;
Proceedings of the 9th IEEE Working Conference on Mining Software Repositories;Fault localization is challenging in an online service system due to its monitoring data's large volume and variety and complex dependencies across/within its components (e.g. services or databases). Furthermore engineers require fault localization solutions to be actionable and interpretable which existing research approaches cannot satisfy. Therefore the common industry practice is that for a specific online service system its experienced engineers focus on localization for recurring failures based on the knowledge accumulated about the system and historical failures. More specifically 1) they can identify the underlying root causes and take mitigation actions when pinpointing a group of indicative metrics on the faulty component 2) their diagnosis knowledge is roughly based on how one failure might affect the components in the whole system.  Although the above common practice is actionable and interpretable it is largely manual thus slow and sometimes inaccurate. In this paper we aim to automate this practice through machine learning. That is we propose an actionable and interpretable fault localization approach DejaVu for recurring failures in online service systems. For a specific online service system DejaVu takes historical failures and dependencies in the system as input and trains a localization model offline for an incoming failure the trained model online recommends where the failure occurs (i.e. the faulty components) and which kind of failure occurs (i.e. the indicative group of metrics) (thus actionable) which are further interpreted both globally and locally (thus interpretable). Based on the evaluation on 601 failures from three production systems and one open-source benchmark in less than one second DejaVu can rank the ground truths at 1.66âˆ¼5.03-th among a long candidate list on average outperforming baselines by 54.52%.;
Proceedings of the 7th Asia-Pacific Symposium on Internetware;Identifying the source of a program failure plays an integral role in maintaining software quality. Both fault localisation and defect prediction aim to locate faults: fault localisation aims to locate faults after they are revealed while defect prediction aims to locate yet-to-happen faults. Despite sharing a similar goal fault localisation and defect prediction have been studied as separate topics mainly due to the difference in available data to exploit. In our doctoral research we aim to bridge fault localisation and defect prediction. Our work is divided into three parts: 1) applying defect prediction to fault localisation i.e. DP2FL 2) applying fault localisation to defect prediction i.e. FL2DP 3) consecutive application of DP2FL and FL2DP in a single framework. We expect the synergy between fault localisation and defect prediction not only to improve the accuracy of each process but to allow us to build a single model that gradually improve the overall software quality throughout the entire software development life-cycle.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings;Fault localization is to identify faulty program elements. Among the large number of fault localization approaches in the literature coverage-based fault localization especially spectrum-based fault localization has been intensively studied due to its effectiveness and lightweightness. Despite the rich literature almost all existing fault localization approaches and studies are conducted on imperative programming languages such as Java and C leaving a gap in other programming paradigms. In this paper we aim to study fault localization approaches for the functional programming paradigm using Haskell language as a representation. We build up the first dataset on real Haskell projects including both real and seeded faults which enables the research of fault localization for functional languages. With this dataset we explore fault localization techniques for Haskell. In particular as typically for SBFL approaches we study methods for coverage collection as well as formulae for suspiciousness scores computation and carefully adapt these two components to Haskell considering the language features and characteristics resulting in a series of adaption approaches and a learning-based approach which are evaluated on the dataset to demonstrate the promises of the direction.;
Proceedings of the 2nd International Conference on Computing Advancements;Fault localization is the activity of precisely indicating the faulty commands in a buggy program. It is known to be a highly costly and tedious process. Automating this process has been the goal of many studies showing it to be a challenging problem. The coverage-spectrum based approaches commonly apply heuristics grounded on the execution of control-flow components to calculate the odds of each program element to be the defective one. The present study aims to investigate another source of fault information by assessing how data-flow analysis is useful when computing suspiciousness scores and how the combination of scores from different sources impacts fault localization. We present an approach to calculate the suspiciousness score for each program command by using the execution of data-flow components. Then we use an evolutionary algorithm to search sets of weights to combine heuristics from distinct sources of fault data (both control-flow and data-flow as well as a hybrid strategy). The approach was applied to programs with seeded faults and real faults and evaluated by using absolute metrics to asses its efficacy to locate faults. Furthermore we introduce a new metric to investigate the dependence of tie-break strategies in building the ranking of suspicious commands. Dataflow based methods demonstrate high effectiveness but increase the need for tie-breaks unlike the evolutionary hybrid method that is still effective but also depends less on tie-break strategies.;
Proceedings of the 8th Working Conference on Mining Software Repositories;Automated software fault localization techniques aid developers in program debugging by identifying the probable locations of faults in a program with minimum human intervention. As software is growing in complexity and scale today increasing the efficiency of fault localization techniques is very essential in order to reduce the overall software development cost. The effectiveness of the test suites used in the fault localization process has a significant impact on the efficiency of the process. Previous studies on the other hand have placed less focus on the adequacy of test suites for the fault localization process. We apply optimized test suites in this paper to improve the performance of software fault localization in a single-fault scenario. For our experiments we use spectrum-based fault localization (SBFL) techniques. Because of its minimal computing overhead and scalability spectrum-based fault localization is a popular efficient and yet lightweight fault localization technique. To optimize the test suite we employ a heuristic that asserts that if a faulty statement is executed by a passing test case that test case will have a negative impact on fault localization performance. In contrast if a passing test case does not execute the faulty statement the faulty statement's suspiciousness increases which has a positive impact on fault localization performance. The test suite optimization approach used in this paper significantly improves fault localization performance as demonstrated by our experiments. The results show that the proposed method efficiently reduces the number of statements examined by about 84.94 percent on average.;
Proceedings of the 15th Innovations in Software Engineering Conference;In this paper we propose DEEPRL4FL a deep learning fault localization (FL) approach that locates the buggy code at the statement and method levels by treating FL as an image pattern recognition problem. DEEPRL4FL does so via novel code coverage representation learning (RL) and data dependencies RL for program statements. Those two types of RL on the dynamic information in a code coverage matrix are also combined with the code representation learning on the static information of the usual suspicious source code. This combination is inspired by crime scene investigation in which investigators analyze the crime scene (failed test cases and statements) and related persons (statements with dependencies) and at the same time examine the usual suspects who have committed a similar crime in the past (similar buggy code in the training data).For the code coverage information DEEPRL4FL first orders the test cases and marks error-exhibiting code statements expecting that a model can recognize the patterns discriminating between faulty and non-faulty statements/methods. For dependencies among statements the suspiciousness of a statement is seen taking into account the data dependencies to other statements in execution and data flows in addition to the statement by itself. Finally the vector representations for code coverage matrix data dependencies among statements and source code are combined and used as the input of a classifier built from a Convolution Neural Network to detect buggy statements/methods. Our empirical evaluation shows that DEEPRL4FL improves the top-1 results over the state-of-the-art statement-level FL baselines from 173.1% to 491.7%. It also improves the top-1 results over the existing method-level FL baselines from 15.0% to 206.3%.;
Proceedings of the 43rd International Conference on Software Engineering;A large body of research efforts have been dedicated to automated software debugging including both automated fault localization and program repair. However existing fault localization techniques have limited effectiveness on real-world software systems while even the most advanced program repair techniques can only fix a small ratio of real-world bugs. Although fault localization and program repair are inherently connected their only existing connection in the literature is that program repair techniques usually use off-the-shelf fault localization techniques (e.g. Ochiai) to determine the potential candidate statements/elements for patching. In this work we propose the unified debugging approach to unify the two areas in the other direction for the first time i.e. can program repair in turn help with fault localization? In this way we not only open a new dimension for more powerful fault localization but also extend the application scope of program repair to all possible bugs (not only the bugs that can be directly automatically fixed). We have designed ProFL to leverage patch-execution results (from program repair) as the feedback information for fault localization. The experimental results on the widely used Defects4J benchmark show that the basic ProFL can already at least localize 37.61% more bugs within Top-1 than state-of-the-art spectrum and mutation based fault localization. Furthermore ProFL can boost state-of-the-art fault localization via both unsupervised and supervised learning. Meanwhile we have demonstrated ProFL's effectiveness under different settings and through a case study within Alipay a popular online payment system with over 1 billion global users.;
Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Faults in spreadsheets are not uncommon and they can have significant negative consequences in practice. Various approaches for fault localization were proposed in recent years among them techniques that transferred ideas from spectrum-based fault localization (SFL) to the spreadsheet domain. Applying SFL to spreadsheets proved to be effective but has certain limitations. Specifically the constrained computational structures of spreadsheets may lead to large sets of cells that have the same assumed fault probability according to SFL and thus have to be inspected manually. In this work we propose to combine SFL with a fault prediction method based on spreadsheet metrics in a machine learning (ML) approach. In particular we train supervised ML models using two orthogonal types of features: (i) variables that are used to compute similarity coefficients in SFL and (ii) spreadsheet metrics that have shown to be good predictors for faulty formulas in previous work. Experiments with a widely-used corpus of faulty spreadsheets indicate that the combined model helps to significantly improve fault localization performance in terms of wasted effort and accuracy.;
Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering;Spectrum-Based Fault Localization (SBFL) computes suspicion scores using risk evaluation formulas for program elements (e.g. statements methods or classes) by counting how often each element is executed or not executed by passing versus failing test cases. The elements are then ranked from most suspicious to least suspicious based on their scores. The elements with the highest scores are thought to be the most faulty. The final ranking list of program elements helps testers during the debugging process when attempting to locate the source of a bug in the program under test. In this paper we present an approach that gives more importance to program elements that are executed by more failed test cases compared to other elements. In essence we are emphasizing the failing test cases factor because there are comparably much less failing tests than passing ones. We multiply each element's suspicion score obtained by an SBFL formula by this importance weight which is the ratio of covering failing tests over all failing tests. The proposed approach can be applied to SBFL formulas without modifying their structures. The experimental results of our study show that our approach achieved a better performance in terms of average ranking compared to the underlying SBFL formulas. It also improved the Top-N categories and increased the number of cases in which the faulty method became the top-ranked element.;
Proceedings of the Third International Workshop on Automated Program Repair;This document provides instructions to setup and execute FLACK. FLACK is an automatic fault localization tool for Alloy. Given an Alloy model with violated assertions FLACK automatically outputs a list of expressions ranking based on their suspiciousness to the error. The link to the replication package is https://github.com/guolong-zheng/flack-ae. The replication package contains the source code of FLACK and benchmarks to reproduce all the evaluation results in the ICSE 2021 submission.;
Proceedings of the 43rd International Conference on Software Engineering: Companion Proceedings;Recently the adoption of Software Defined Networking (SDN) as a network infrastructure has gained significant popularity. Although the openness and programmability of SDN ease the construction of large complex networks it is still challenging to diagnose faults in a complex datacenter-scale network which is crucial to guarantee rigorous service level agreement (SLA) of upper-layer applications. Previous network diagnosis tools incur significant overhead in fine-grained telemetry and usually lack the ability to automatically diagnose fine-grained faults. Although on-demand monitoring methods is proposed to reduce telemetry overhead they struggle to effectively set static thresholds which requires expert experience. In this paper we present MARS a lightweight system for anomaly detection with dynamic threshold and automatic root cause localization in programmable networking systems. MARS collects aggregated packet-level telemetry on demand and generates a ranked list of fine-grained fault culprits at multiple levels including port-level switch-level and flow-level. Experimental evaluations show the cost-effectiveness of MARS both in terms of network bandwidth and switch memory usage. Moreover MARS achieves a 0.97 F1 score in anomaly detection and 0.95 Recall at Top-2 and an overall 0.3 Exam Score in root cause localization.;
Proceedings of the 52nd International Conference on Parallel Processing;Databases typically contain many cross-field constraints which must be validated for each entry. Census databases can contain tens of millions of such entries. Finding records which fail the constraints without suggesting a correction is set inclusion. Error-localisation coupled with imputation is the task of finding a minimal correction to a failing record so that it satisfies all constraints. The error-localisation problem alone is intractable since it is known to be NP-complete. The traditional method for solving both problems is due to Fellegi and Holt but current tools based on Fellegi-Holt require cumbersome calibrations and do not scale up to handle millions of records with hundreds of edits in the times required by national statistical agencies. In 2001 Bruni and Sassano suggested that both problems could be recast as simple propositional satisfiability problems without using the Fellegi-Holt method. We describe how we tailered Microsoft's Z3 to handle error localisation and imputation. Experiments show that our prototype can handle a realisitic scenario from the Australian Bureau of Statistics (ABS) national census data in less than 24 hours. Thus efficient error localisation and imputation for census data is now feasible using state-of-the-art SAT/SMT solvers.;
Proceedings of the Australasian Computer Science Week Multiconference;Continuous integration (CI) is the process in which code changes are automatically integrated built and tested in a shared repository. In CI developers frequently merge and test code under development which helps isolate faults with finer-grained change information. To identify faulty code prior research has widely studied and evaluated the performance of spectrum-based fault localization (SBFL) techniques. While the continuous nature of CI requires the code changes to be atomic and presents fine-grained information on what part of the system is being changed traditional SBFL techniques do not benefit from it. To overcome the limitation we propose to integrate the code and coverage change information in fault localization under CI settings. First code changes show how faults are introduced into the system and provide developers with better understanding on the root cause. Second coverage changes show how the code coverage is impacted when faults are introduced. This change information can help limit the search space of code coverage which offers more opportunities for improving fault localization techniques. Based on the above observations we propose three new change-based fault localization techniques and compare them with Ochiai a commonly used SBFL technique. We evaluate these techniques on 192 real faults from seven software systems. Our results show that all three change-based techniques outperform Ochiai on the Defects4J dataset. In particular the improvement varies from 7% to 23% and 17% to 24% for average MAP and MRR respectively. Moreover we find that our change-based fault localization techniques can be integrated with Ochiai and boost its performance by up to 53% and 52% for average MAP and MRR respectively.;
Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis;We describe and evaluate the first spectrum-based fault localization method aimed at finding faulty rules in a context-free grammar. It takes as input a test suite and a modified parser for the grammar that can collect grammar spectra i.e. the sets of rules used in attempts to parse the individual test cases and returns as output a ranked list of suspicious rules. We show how grammar spectra can be collected for both LL and LR parsers and how the ANTLR and CUP parser generators can be modified and used to automate the collection of the grammar spectra. We evaluate our method over grammars with seeded faults as well as real world grammars and student grammars submitted in compiler engineering courses that contain real faults. The results show that our method ranks the seeded faults within the top five rules in more than half of the cases and can pinpoint them in 10%â€“40% of the cases. On average it ranks the faults at around 25% of all rules and better than 15% for a very large test suite. It also allowed us to identify deviations and faults in the real world and student grammars.;
Proceedings of the 12th ACM SIGPLAN International Conference on Software Language Engineering;Detecting Arrays (DAs) are mathematical objects that enable fault localization in combinatorial interaction testing. Each row of a DA serves as a test case whereas a whole DA is treated as a test suite. In real-world testing problems it is often the case that some constraints exist among test parameters. In this paper we show that it may be impossible to construct a DA using only constraint-satisfying test cases. The reason for this is that a set of some faulty interactions may always mask the effect of other faulty interactions in the presence of constraints. Based on this observation we propose the notion of Constrained Detecting Arrays (CDAs) to adapt DAs to practical situations. The definition of CDAs requires that all rows of a CDA must satisfy the constraints and the same fault localization capability as the DA must hold except for such inherently undetectable faults. We then propose a computational method for constructing CDAs. Experimental results obtained by using a program that implements the method show that the method was able to produce CDAs within a reasonable time for practical problem instances.;
Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis;Program debugging is a time-consuming task and researchers have proposed different kinds of automatic fault localization techniques to mitigate the burden of manual debugging. Among these techniques two popular families are spectrum-based fault localization (SBFL) and statistical debugging (SD) both localizing faults by collecting statistical information at runtime. Though the ideas are similar the two families have been developed independently and their combinations have not been systematically explored.In this paper we perform a systematical empirical study on the combination of SBFL and SD. We first build a unified model of the two techniques and systematically explore four types of variations different predicates different risk evaluation formulas different granularities of data collection and different methods of combining suspicious scores.Our study leads to several findings. First most of the effectiveness of the combined approach contributed by a simple type of predicates: branch conditions. Second the risk evaluation formulas of SBFL significantly outperform that of SD. Third fine-grained data collection significantly outperforms coarse-grained data collection with a little extra execution overhead. Fourth a linear combination of SBFL and SD predicates outperforms both individual approaches.According to our empirical study we propose a new fault localization approach PredFL (Predicate-based Fault Localization) with the best configuration for each dimension under the unified model. Then we explore its complementarity to existing techniques by integrating PredFL with a state-of-the-art fault localization framework. The experimental results show that PredFL can further improve the effectiveness of state-of-the-art fault localization techniques. More concretely integrating PredFL results in an up to 20.8% improvement w.r.t the faults successfully located at Top-1 which reveals that PredFL complements existing techniques.;
Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering;In this paper we present a novel debugging method for imperative software featuring both automatic error localization and correction. The input of our method is an incorrect program and a corresponding specification which can be given in form of assertions or as a reference implementation. We use symbolic execution for program analysis. This allows for a wide range of different trade-offs between resource requirements and accuracy of results. Our error localization method rests upon model-based diagnosis and SMT-solving. Error correction is done using a template-based approach which ensures that the computed repairs are readable. Our method can handle all sorts of incorrect expressions not only under a single-fault assumption but also for multiple faults. Finally we present experimental results where an implementation for C programs is used to debug mutants of the TCAS case study of the Siemens suite.;
Proceedings of the International Conference on Formal Methods in Computer-Aided Design;This paper proposes a new mutation operator using neural network to generate plausible code elements to improve performance of mutation-based fault localization on omission faults. Unlike the existing mutation operators the proposed mutation operator synthesizes new code elements at a given mutation site with a neural language model. We extended MUSE to use the proposed mutation operator and conducted a case study with 3 omission faults found in JFreeChart of Defects4J. As a result the accuracy of MUSE with the new mutation operator increased significantly in all three faults.;
Proceedings of the 24th International Conference on Evaluation and Assessment in Software Engineering;Manually finding the program unit (e.g. class method or statement) responsible for a fault is tedious and time-consuming. To mitigate this problem many fault localization techniques have been proposed. A popular family of such techniques is spectrum-based fault localization (SBFL) which takes program execution traces (spectra) of failed and passed test cases as input and applies a ranking formula to compute a suspiciousness score for each program unit. However most existing SBFL techniques fail to consider two facts: 1) not all failed test cases contribute equally to a considered fault(s) and 2) program units collaboratively contribute to the failure/pass of each test case in different ways.In this study we propose a novel idea that first models the SBFL task as a classification problem of predicting whether a test case will fail or pass based on spectra information on program units. We subsequently apply eXplainable Artificial Intelligence (XAI) techniques to infer the local importance of each program unit to the prediction of each executed test case. Applying XAI to the failed test case we retrieve information about which program statements within the test case that are considered the most important (i.e. have the biggest effect in making the test case failed). Such a design can automatically learn the unique contributions of failed test cases to the suspiciousness of a program unit by learning the different and collaborative contributions of program units to each test case's executed result. As far as we know this is the first XAI-supported SBFL approach. We evaluate the new approach on the Defects4J benchmark dataset.We compare the performance of our approach against five popular SBFL techniques: DStar Tarantula Barinel Ochiai and OP. We measure their performance using the Top-K and EXAM scores. In particular we focus on the result of the Top-1 which importance has been highlighted in automated program repair domain where the proposed methods often assume perfect fault localization (i.e. the fault must be found at the first rank of the suspiciousness list). Our results show that our approach named XAI4FL has a statistically significant and substantially better performance in terms of Top-1 than the SBFL approaches. We also compare our approach with a simpler approach to get feature importance in a tree-based model (i.e. using the Mean Decrease in Impurity method). Our results show that XAI4FL statistically significantly outperforms the MDI method in Top-K and EXAM score. Our results and findings highlight that the utilization of XAI for fault localization can improve the overall results of fault localization techniques.;
Proceedings of the 45th International Conference on Software Engineering: New Ideas and Emerging Results;Access control policies in distributed systems particularly implemented in the XACML standard language are increasingly complex. Faults may exist in complex policies for various reasons such as misunderstanding of the access control requirements omissions and coding errors. These faults if not removed before deployment may lead to unauthorized accesses or denial of service. Manual localization of these faults however can be a challenging task. Inspired by spectrum-based fault localization for software debugging this paper presents an approach for automatically localizing the fault(s) in a given XACML policy by exploring test coverage information of the policy elements. We investigate two test coverage criteria (i.e. reachability and firing) of policy elements and 14 scoring methods for ranking policy elements to determine the fault location(s). To evaluate the fault localization methods we have used real-world policy files with different levels of complexity and a large number of policy mutants with one or two seeded faults. The experiment results show that the firing-based Naish2 and CBI-Inc methods are effective in fault localization of XACML policies.;
Proceedings of the 21st ACM on Symposium on Access Control Models and Technologies;Most fault localization techniques take as input a faulty program and produce as output a ranked list of suspicious code locations at which the program may be defective. When researchers propose a new fault localization technique they typically evaluate it on programs with known faults. The technique is scored based on where in its output list the defective code appears. This enables the comparison of multiple fault localization techniques to determine which one is better.Previous research has evaluated fault localization techniques using artificial faults generated either by mutation tools or manually. In other words previous research has determined which fault localization techniques are best at finding artificial faults. However it is not known which fault localization techniques are best at finding real faults. It is not obvious that the answer is the same given previous work showing that artificial faults have both similarities to and differences from real faults.We performed a replication study to evaluate 10 claims in the literature that compared fault localization techniques (from the spectrum-based and mutation-based families). We used 2995 artificial faults in 6 real-world programs. Our results support 7 of the previous claims as statistically significant but only 3 as having non-negligible effect sizes. Then we evaluated the same 10 claims using 310 real faults from the 6 programs. Every previous result was refuted or was statistically and practically insignificant. Our experiments show that artificial faults are not useful for predicting which fault localization techniques perform best on real faults.In light of these results we identified a design space that includes many previously-studied fault localization techniques as well as hundreds of new techniques. We experimentally determined which factors in the design space are most important using an overall set of 395 real faults. Then we extended this design space with new techniques. Several of our novel techniques outperform all existing techniques notably in terms of ranking defective code in the top-5 or top-10 reports.;
Proceedings of the 39th International Conference on Software Engineering;Software testing is crucial to ensure the quality of a software under development. Once a potential bug is identified a Bug Report (BR) is opened with information to describe and reproduce the found issue. Usually in big companies hundreds of BRs are opened weekly by different testing teams which have to be inspected and fixed adequately. This paper is focused on the use of Machine Learning (ML) techniques to automate the Escaped Defect Analysis (EDA) which is an important (but expensive) task to improve the effectiveness of the testing teams. In our work Escaped Defects (EDs) are bugs or issues that should have been opened by a specific team but which was accidentally found by another team. The occurrence of EDs is risky as it is usually related to failures in the testing activities. EDA is usually performed manually by software engineers who read each BRâ€™s textual content to judge whether it is an ED or not. This is challenging and time-consuming. In our solution the BRâ€™s content is preprocessed by textual operations and then a feature representation is adopted by a ML classifier to return the probability of EDA labels. Experiments were performed in a dataset of 3767 BRs provided by the Motorola Mobility Com\'{e;
Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing;Post-silicon bug localization -- the process of identifying the location of a detected hardware bug and the cycle(s) during which the bug produces error(s) -- is a major bottleneck for complex integrated circuits. Instruction Footprint Recording and Analysis (IFRA) is a promising post-silicon bug localization technique for complex processor cores. However applying IFRA to new processor microarchitectures can be challenging due to the manual effort required to implement special microarchitecture-dependent analysis techniques for bug localization. This paper presents the Bug Localization Graph (BLoG) framework that enables application of IFRA to new processor microarchitectures with reduced manual effort. Results obtained from an industrial microarchitectural simulator modeling a state-of-the-art complex commercial microarchitecture (Intel Nehalem the foundation for the Intel Coreâ„¢ i7 and Coreâ„¢ i5 processor families) demonstrate that BLoG-assisted IFRA enables effective and efficient post-silicon bug localization for complex processors with high bug localization accuracy at low cost.;
Proceedings of the 47th Design Automation Conference;Software debugging is tedious and time consuming. To reduce the manual effort needed for debugging researchers have proposed a considerable number of techniques to automate the process of fault localization in particular techniques based on information retrieval (IR) have drawn increased attention in recent years. Although reportedly effective these techniques have some potential limitations that may affect their performance. First their effectiveness is likely to depend heavily on the quality of the bug reports unfortunately high-quality bug reports that contain rich information are not always available. Second these techniques have not been evaluated through studies that involve actual developers which is less than ideal as purely analytical evaluations can hardly show the actual usefulness of debugging techniques. The goal of this work is to evaluate the usefulness of IR-based techniques in real-world scenarios. Our investigation shows that bug reports do not always contain rich information and that low-quality bug reports can considerably affect the effectiveness of these techniques. Our research also shows through a user study that high-quality bug reports benefit developers just as much as they benefit IR-based techniques. In fact the information provided by IR-based techniques when operating on high-quality reports is only helpful to developers in a limited number of cases. And even in these cases such information only helps developers get to the faulty file quickly but does not help them in their most time consuming task: understanding and fixing the bug within that file.;
Proceedings of the 2015 International Symposium on Software Testing and Analysis;Genetic Programming has been successfully applied to learn to rank program elements according to their likelihood of containing faults. However all GP-evolved formul\ae{;
Proceedings of the Genetic and Evolutionary Computation Conference;Spectrum based fault localisation is a widely studied class of heuristics for locating faults within a software program. Unfortunately the current state of the art ignores the inherent dependencies between the methods leading up to the fault hence having a limited diagnostic accuracy. In this paper we present a variant of spectrum based fault localisation which leverages series of method calls by means of sequence mining. We validate our variant (we refer to it as sequenced spectrum analysis) on the Defects4J benchmark demonstrating that sequenced spectrum analysis gains a 12% points improvement against the state of the art.;
Proceedings of the 33rd Annual ACM Symposium on Applied Computing;In the production environment a large part of microservice failures are related to the complex and dynamic interactions and runtime environments such as those related to multiple instances environmental configurations and asynchronous interactions of microservices. Due to the complexity and dynamism of these failures it is often hard to reproduce and diagnose them in testing environments. It is desirable yet still challenging that these failures can be detected and the faults can be located at runtime of the production environment to allow developers to resolve them efficiently. To address this challenge in this paper we propose MEPFL an approach of latent error prediction and fault localization for microservice applications by learning from system trace logs. Based on a set of features defined on the system trace logs MEPFL trains prediction models at both the trace level and the microservice level using the system trace logs collected from automatic executions of the target application and its faulty versions produced by fault injection. The prediction models thus can be used in the production environment to predict latent errors faulty microservices and fault types for trace instances captured at runtime. We implement MEPFL based on the infrastructure systems of container orchestrator and service mesh and conduct a series of experimental studies with two opensource microservice applications (one of them being the largest open-source microservice application to our best knowledge). The results indicate that MEPFL can achieve high accuracy in intraapplication prediction of latent errors faulty microservices and fault types and outperforms a state-of-the-art approach of failure diagnosis for distributed systems. The results also show that MEPFL can effectively predict latent errors caused by real-world fault cases.;
Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Much effort is spent by programmers everyday in trying to reduce long failing execution traces to the cause of the error. We present an algorithm for error cause localization based on a reduction to the maximal satisfiability problem (MAX-SAT) which asks what is the maximum number of clauses of a Boolean formula that can be simultaneously satisfied by an assignment. At an intuitive level our algorithm takes as input a program and a failing test and comprises the following three steps. First using bounded model checking and a bound obtained from the execution of the test we encode the semantics of a bounded unrolling of the program as a Boolean trace formula. Second for a failing program execution (e.g. one that violates an assertion or a post-condition) we construct an unsatisfiable formula by taking the formula and additionally asserting that the input is the failing test and that the assertion condition does hold at the end. Third using MAX-SAT we find a maximal set of clauses in this formula that can be satisfied together and output the complement set as a potential cause of the error.We have implemented our algorithm in a tool called BugAssist that performs error localization for C programs. We demonstrate the effectiveness of BugAssist on a set of benchmark examples with injected faults and show that in most cases BugAssist can quickly and precisely isolate a few lines of code whose change eliminates the error. We also demonstrate how our algorithm can be modified to automatically suggest fixes for common classes of errors such as off-by-one.We have implemented our algorithm in a tool called BugAssist that performs error localization for C programs. We demonstrate the effectiveness of BugAssist on a set of benchmark examples with injected faults and show that in most cases BugAssist can quickly and precisely isolate a few lines of code whose change eliminates the error. We also demonstrate how our algorithm can be modified to automatically suggest fixes for common classes of errors such as off-by-one.;
Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation;Debugging is a costly process that consumes much of developer time and energy. To help reduce debugging effort many studies have proposed various fault localization approaches. These approaches take as input a set of test cases (some failing some passing) and produce a ranked list of program elements that are likely to be the root cause of the failures (i.e. failing test cases). In this work we propose Savant a new fault localization approach that employs a learning-to-rank strategy using likely invariant diffs and suspiciousness scores as features to rank methods based on their likelihood to be a root cause of a failure. Savant has four steps: method clustering &amp test case selection invariant mining feature extraction and method ranking. At the end of these four steps Savant produces a short ranked list of potentially buggy methods. We have evaluated Savant on 357 real-life bugs from 5 programs from the Defects4J benchmark. Out of these bugs averaging over 100 repeated trials with different seeds to randomly break ties we find that on average Savant can identify correct buggy methods for 63.03 101.72 and 122 bugs at top 1 3 and 5 positions in the ranked lists that Savant produces. We have compared Savant against several state-of-the-art fault localization baselines that work on program spectra. We show that Savant can successfully locate 57.73% 56.69% and 43.13% more bugs at top 1 top 3 and top 5 positions than the best performing baseline respectively.;
Proceedings of the 25th International Symposium on Software Testing and Analysis;When programs fail developers face the problem of identifying the code fragments responsible for this failure. To this end fault localization techniques try to identify suspicious program places (program statements) by observing the spectrum of the failing and passing test executions. These statements are then pointed out to assist the debugging activity. This paper considers mutation-based fault localization and suggests the use of a sufficient mutant set to locate effectively the faulty statements. Experimentation reveals that mutation-based fault localization is significantly more effective than current state-of-the-art fault localization techniques. Additionally the results show that the proposed approach is capable of reducing the overheads of mutation analysis. In particular the number of mutants to be considered is reduced to 20% with only a limited loss on the method's effectiveness.;
Proceedings of the 29th Annual ACM Symposium on Applied Computing;Finding and fixing bugs are time-consuming activities in software development. Spectrum-based fault localization aims to identify the faulty position in source code based on the execution trace of test cases. Failing test cases and their assertions form test oracles for the failing behavior of the system under analysis. In this paper we propose a novel concept of spectrum driven test case purification for improving fault localization. The goal of test case purification is to separate existing test cases into small fractions (called purified test cases) and to enhance the test oracles to further localize faults. Combining with an original fault localization technique (e.g. Tarantula) test case purification results in better ranking the program statements. Our experiments on 1800 faults in six open-source Java programs show that test case purification can effectively improve existing fault localization techniques.;
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering;To improve software quality just-in-time defect prediction (JIT-DP) (identifying defect-inducing commits) and just-in-time defect localization (JIT-DL) (identifying defect-inducing code lines in commits) have been widely studied by learning semantic features or expert features respectively and indeed achieved promising performance. Semantic features and expert features describe code change commits from different aspects however the best of the two features have not been fully explored together to boost the just-in-time  defect prediction and localization in the literature yet. Additional JIT-DP identifies defects at the coarse commit level while as the  consequent task of JIT-DP JIT-DL cannot achieve the accurate localization of defect-inducing code lines in a commit without JIT-DP.  We hypothesize that the two JIT tasks can be combined together to boost the accurate prediction and localization of defect-inducing  commits by integrating semantic features with expert features. Therefore we propose to build a unified model JIT-Fine for the  just-in-time defect prediction and localization by leveraging the best of semantic features and expert features. To assess the feasibility  of JIT-Fine we first build a large-scale line-level manually labeled dataset JIT-Defects4J. Then we make a comprehensive comparison  with six state-of-the-art baselines under various settings using ten performance measures grouped into two types: effort-agnostic  and effort-aware. The experimental results indicate that JIT-Fine can outperform all state-of-the-art baselines on both JIT-DP and JITDL  tasks in terms of ten performance measures with a substantial improvement (i.e. 10%-629% in terms of effort-agnostic measures on JIT-DP 5%-54% in terms of effort-aware measures on JIT-DP and 4%-117% in terms of effort-aware measures on JIT-DL).;
Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication;Continuous integration is a best practice adopted in modern software development teams to identify potential faults immediately upon project build. Once a fault is detected it must be repaired immediately hence continuous integration provides an ideal testbed for experimenting with the state of the art in fault localisation. In this paper we propose a variant of what is known as spectrum based fault localisation which leverages patterns of method calls by means of frequent itemset mining. We compare our variant (we refer to it as patterned spectrum analysis) against the state of the art and demonstrate on 351 real bugs drawn from five representative open source java projects that patterned spectrum analysis is more effective in localising the fault. Based on anecdotal evidence from this comparison we suggest avenues for further improvements. Keywords: Automated developer tests Continuous Integration Spectrum based fault localisation Statistical debugging;
Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering;Bug or Fault localization is a process of identifying the specific location(s) or region(s) of source code (at various granularity levels such as the directory path file method or statement) that is faulty and needs to be modified to repair the defect. Fault localization is a routine task in software maintenance (corrective maintenance). Due to the increasing size and complexity of current software applications automated solutions for fault localization can significantly reduce human effort and software maintenance cost.We present a technique (which falls into the class of static techniques for bug localization) for fault localization based on a character n-gram based Information Retrieval (IR) model. We frame the problem of bug localization as a relevant document(s) search task for a given query and investigate the application of character-level n-gram based textual features derived from bug reports and source-code file attributes. We implement the proposed IR model and evaluate its performance on dataset downloaded from two popular open-source projects (JBoss and Apache).We conduct a series of experiments to validate our hypothesis and present evidences to demonstrate that the proposed approach is effective. The accuracy of the proposed approach is measured in terms of the standard and commonly used SCORE and MAP (Mean Average Precision) metrics for the task of fault localization. Experimental results reveal that the median value for the SCORE metric for JBoss and Apache dataset is 99.03% and 93.70% respectively. We observe that for 16.16% of the bug reports in the JBoss dataset and for 10.67% of the bug reports in the Apache dataset the average precision value (computed at all recall levels) is between 0.9 and 1.0.;
Proceedings of the 5th India Software Engineering Conference;Deep neural networks (DNNs) are becoming an integral part of most software systems. Previous work has shown that DNNs have bugs. Unfortunately existing debugging techniques don't support localizing DNN bugs because of the lack of understanding of model behaviors. The entire DNN model appears as a black box. To address these problems we propose an approach and a tool that automatically determines whether the model is buggy or not and identifies the root causes for DNN errors. Our key insight is that historic trends in values propagated between layers can be analyzed to identify faults and also localize faults. To that end we first enable dynamic analysis of deep learning applications: by converting it into an imperative representation and alternatively using a callback mechanism. Both mechanisms allows us to insert probes that enable dynamic analysis over the traces produced by the DNN while it is being trained on the training data. We then conduct dynamic analysis over the traces to identify the faulty layer or hyperparameter that causes the error. We propose an algorithm for identifying root causes by capturing any numerical error and monitoring the model during training and finding the relevance of every layer/parameter on the DNN outcome. We have collected a benchmark containing 40 buggy models and patches that contain real errors in deep learning applications from Stack Overflow and GitHub. Our benchmark can be used to evaluate automated debugging tools and repair techniques. We have evaluated our approach using this DNN bug-and-patch benchmark and the results showed that our approach is much more effective than the existing debugging approach used in the state-of-the-practice Keras library. For 34/40 cases our approach was able to detect faults whereas the best debugging approach provided by Keras detected 32/40 faults. Our approach was able to localize 21/40 bugs whereas Keras did not localize any faults.;
Proceedings of the 6th International Workshop on Automation of Software Test;"Fault localization is a practical research topic that helps developers identify code locations that might cause bugs in a program. Most existing fault localization techniques are designed for imperative programs (e.g. C and Java) and rely on analyzing correct and incorrect executions of the program to identify suspicious statements. In this work we introduce a fault localization approach for models written in a declarative language where the models are not executed"" but rather converted into a logical formula and solved using backend constraint solvers. We present FLACK a tool that takes as input an Alloy model consisting of some violated assertion and returns a ranked list of suspicious expressions contributing to the assertion violation. The key idea is to analyze the differences between counterexamples i.e. instances of the model that do not satisfy the assertion and instances that do satisfy the assertion to find suspicious expressions in the input model. The experimental results show that FLACK is efficient (can handle complex real-world Alloy models with thousand lines of code within 5 seconds) accurate (can consistently rank buggy expressions in the top 1.9% of the suspicious list) and useful (can often narrow down the error to the exact location within the suspicious expressions).""";
Proceedings of the XXII Brazilian Symposium on Software Quality;As dynamically-typed languages grow in popularity especially among beginning programmers there is an increased need to pinpoint their defects. Localization for novice bugs can be ambiguous: not all locations formally implicated are equally useful for beginners. We propose a scalable fault localization approach for dynamic languages that is helpful for debugging and generalizes to handle a wide variety of errors commonly faced by novice programmers. We base our approach on a combination of static dynamic and contextual features guided by machine learning. We evaluate on over 980000 diverse real user interactions across four years from the popular PythonTutor.com website which is used both in classes and by non-traditional learners. We find that our approach is scalable general and quite accurate: up to 77% of these historical novice users would have been helped by our top-three responses compared to 45% for the default interpreter. We also conducted a human study: participants preferred our approach to the baseline ($p = 0.018)$ and found it additionally useful for bugs meriting multiple edits.;
Proceedings of the 51st ACM Technical Symposium on Computer Science Education;We introduce in this paper LocFaults a new flow-driven and constraint-based approach for error localization. The input is a faulty program for which a counter-example and a postcondition are provided. To identify helpful information for error location we generate a constraint system for the paths of the control flow graph for which at most k conditional statements may be erroneous. Then we calculate Minimal Correction Sets (MCS) of bounded size for each of these paths. The removal of one of these sets of constraints yields a maximal satisfiable subset in other words a maximal subset of constraints satisfying the post condition. To compute the MCS we extend the algorithm proposed by Liffiton and Sakallah [21] in order to handle programs with numerical statements more efficiently. The main advantage of this flow-driven approach is that the computed sets of suspicious instructions are small each of them being associated with an identified path. Moreover the constraint-programming based framework of LocFaults allows mixing Boolean and numerical constraints in an efficient and straightforward way. Preliminary experiments are quite encouraging.;
Proceedings of the 30th Annual ACM Symposium on Applied Computing;Software testing consumes the most time and resource-intensive phase of software testing. Test case minimization techniques are used to reduce the test suite which in turn saves time and resources. The main purpose of test case minimization is to eliminate the ineffective test cases in a way that the remaining test cases satisfy all the requirements as before. Many techniques are used for test case minimization. The use of a convoluted neural net a nature-inspired algorithm like fire algorithm data mining technique and coverage-based and hybrid techniques has been reviewed in this paper. In this study a few of the most recent takes on test case minimization has been summarized and sorted depending on their approach. This is a survey paper that reviews the way each paper handled their problem which dataset they used their accuracy on the respective dataset and the shortcomings.;
Proceedings of the 2022 Fourteenth International Conference on Contemporary Computing;In this paper we study the sensor placement problem in urban water networks that maximizes the localization of pipe failures given that some sensors give incorrect outputs. False output of a sensor might be the result of degradation in sensor's hardware software fault or might be due to a cyber attack on the sensor. Incorrect outputs from such sensors can have any possible values which could lead to an inaccurate localization of a failure event. We formulate the optimal sensor placement problem with erroneous sensors as a set multicover problem which is NP-hard and then discuss a polynomial time heuristic to obtain efficient solutions. In this direction we first examine the physical model of the disturbance propagating in the network as a result of a failure event and outline the multi-level sensing model that captures several event features. Second using a combinatorial approach we solve the problem of sensor placement that maximizes the localization of pipe failures by selecting m sensors out of which at most e give incorrect outputs. We propose various localization performance metrics and numerically evaluate our approach on a benchmark and a real water distribution network. Finally using computational experiments we study relationships between design parameters such as the total number of sensors the number of sensors with errors and extracted signal features.;
Proceedings of the 8th International Conference on Cyber-Physical Systems;Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines branches paths) covered by the suite but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric called DDU aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability i.e. the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. Our experiments show that optimizing a test suite with respect to DDU yields a 34% gain in spectrum-based fault localization report accuracy when compared to the standard branch-coverage metric.;
Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering;Today most automated test generators such as search-based software testing (SBST) techniques focus on achieving high code coverage. However high code coverage is not sufficient to maximise the number of bugs found especially when given a limited testing budget. In this paper we propose an automated test generation technique that is also guided by the estimated degree of defectiveness of the source code. Parts of the code that are likely to be more defective receive more testing budget than the less defective parts. To measure the degree of defectiveness we leverage Schwa a notable defect prediction technique.We implement our approach into EvoSuite a state of the art SBST tool for Java. Our experiments on the Defects4J benchmark demonstrate the improved efficiency of defect prediction guided test generation and confirm our hypothesis that spending more time budget on likely defective parts increases the number of bugs found in the same time budget.;
Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering;Many techniques on automated fault localization (AFL) have been introduced to assist developers in debugging. Prior studies evaluate the localization technique from the viewpoint of developers: measuring how many benefits that developers can obtain from the localization technique used when debugging. However these evaluation approaches are not always suitable because it is difficult to quantify precisely the benefits due to the complex debugging behaviors of developers. In addition recent user studies have presented that developers working with AFL do not correct the defects more efficiently than ones working with only traditional debugging techniques such as breakpoints even when the effectiveness of AFL is artificially improved. In this paper we attempt to propose a new research direction of developing AFL techniques from the viewpoint of fully automated debugging including the program repair of automation for which the activity of AFL is necessary. We also introduce the NCP score as the evaluation measurement to assess and compare various techniques from this perspective. Our experiment on 15 popular AFL techniques with 11 subject programs shipping with real-life field failures presents the evidence that these AFL techniques performing well in prior studies do not have better localization effectiveness according to NCP score. We also observe that Jaccard has the better performance over other techniques in our experiment.;
Proceedings of the 2013 International Symposium on Software Testing and Analysis;Manually locating and fixing faults can be tedious and hard. Recent years have seen much progress in automated techniques for fault localization. A particularly promising approach is to analyze passing and failing runs to compute how likely each statement is to be faulty. Techniques based on this approach have so far largely focused on either using statistical analysis or similarity based algorithms which have a natural application in evaluating such runs. We present a novel approach to fault localization using feature selection techniques from machine learning. Our insight is that each additional failing or passing run can provide significantly diverse amount of information which can help localize faults in code -- the statements with maximum feature diversity information can point to most suspicious lines of code. Experimental results show that our approach outperforms state-of-the-art approaches for localizing faults in most subject programs of the Siemens suite which have previously been used to evaluate several fault localization techniques.;
Proceedings of the International Workshop on Machine Learning Technologies in Software Engineering;Programmers maintain and evolve their software in a variety of programming languages to take advantage of various control/data abstractions and legacy libraries. The programming language ecosystem has diversified over the last few decades and non-trivial programs are likely to be written in more than a single language. Unfortunately language interfaces such as Java Native Interface and Python/C are difficult to use correctly and the scope of fault localization goes beyond language boundaries which makes debugging multilingual bugs challenging. To overcome the aforementioned limitations we propose a mutation-based fault localization technique for real-world multilingual programs. To improve the accuracy of locating multilingual bugs we have developed and applied new mutation operators as well as conventional mutation operators. The results of the empirical evaluation for six non-trivial real-world multilingual bugs are promising in that the proposed technique identifies the buggy statements as the most suspicious statements for all six bugs.;
Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering;Learn-to-rank techniques have been successfully applied to fault localisation to produce ranking models that place faulty program elements at or near the top. Genetic Programming has been successfully used as a learning mechanism to produce highly effective ranking models for fault localisation. However the inherent stochastic nature of GP forces its users to learn multiple ranking models and choose the best performing one for the actual use. This train-and-select approach means that the absolute majority of the computational resources that go into the evolution of ranking models are eventually wasted. We introduce Ensemble Model for Fault Localisation (EMF) which is a learn-to-rank fault localisation technique that utilises all trained models to improve the accuracy of localisation even further. EMF ranks program elements using a lightweight voting-based ensemble of ranking models. We evaluate EMF using 389 real-world faults in Defects4J benchmark. EMF can place 30.1% more faults at the top when compared to the best performing individual model from the train-and-select approach. We also apply Genetic Algorithm (GA) to construct the best performing ensemble. Compared to naively using all ranking models GA generated ensembles can localise further 9.2% more faults at the top on average.;
Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1;We present a value profile based approach for ranking program statements according to their likelihood of being faulty. The key idea is to see which program statements exercised during a failing run use values that can be altered so that the execution instead produces correct output. Our approach is effective in locating statements that are either faulty or directly linked to a faulty statement. We present experimental results showing the effectiveness and efficiency of our approach. Our approach outperforms Tarantula which to our knowledge is the most effective prior approach for statement ranking based fault localization using the benchmark programs we studied.;
Proceedings of the 2008 International Symposium on Software Testing and Analysis;Context: The concern with the security of software assets increases and makes the companies seek guarantees that the data stored by them is safe from unauthorized access and theft. These concerns are also applicable to the mobile software context and as the devices have various capabilities many security breaches may occur and expose usersâ€™ data. Thus to guarantee security the software testing process also includes security-related tests. Objective: empirically analyze the perceptions of practitioners from the mobile software testing environment on security-related testing topics. Method: A survey was performed among 49 software testing practitioners from a mobile software development company in Brazil regarding their perception of security testing practices. Results: We observed that there is a concern about security among the practitioners. On the other hand the respondents indicated that there is also a lack of knowledge about the topics discussed. Conclusions: the results showed the general importance of the security testing practices by the practitioners as well as triggered the need for the creation of methods and techniques for better integration of security testing practices in the mobile software development and also reinforced the need for improving the security culture in organizations.;
Proceedings of the XIX Brazilian Symposium on Information Systems;Context: Smart Cities and other Systems-of-Systems (SoS) have attracted attention due to their potential for innovation in the services provided to the society. SoS are composed of several independent systems and often support critical domains. As such failures can cause serious damage or even financial losses that can be avoided by performing quality assurance (QA). Among QA techniques software testing is an essential activity that checks software behaviors against a subset of parameters. However testing SoS can be even more complex since several other factors further elevate the complexity of the test such as interoperability links and multiple independent systems. Goal: Our goal in this paper is to analyze the current state of research on software testing for SoS domain. Method: A protocol was formulated and executed according to the guidelines for performing systematic literature mappings in Software Engineering. Results: This study identified the tools approaches methods and processes that the literature has addressed to test SoS. Conclusions: Software Testing for SoS still faces several problems and presents many questions to be answered particularly in the definition of processes and metrics.;
Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing;We propose an automatic diagnosis technique for isolating the root cause(s) of software failures. We use likely program invariants automatically generated using correct inputs that are close to the fault-triggering input to select a set of candidate program locations which are possible root causes. We then trim the set of candidate root causes using software-implemented dynamic backwards slicing plus two new filtering heuristics: dependence filtering and filtering via multiple failing inputs that are also close to the failing input. Experimental results on reported software bugs of three large open-source servers show that we are able to narrow down the number of candidate bug locations to between 5 and 17 program expressions even in programs that are hundreds of thousands of lines long.;
Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems;"Computer science instructors need to manage the rapid improvement of novice programmers through teaching self-guided learning and assessment. Appropriate feedback both generic and personalised is essential to facilitate student progress. Automated feedback tools can also accelerate the marking process and allow instructors to dedicate more time to other forms of tuition and students to progress more rapidly. Massive Open Online Courses rely on automated tools for both self-guided learning and assessment.Fault localisation takes a significant part of debugging time. Popular spectrum-based methods do not narrow the potential fault locations sufficiently to assist novices. We therefore use a fast and precise model-based fault localisation method and show how it can be used to improve self-guided learning and accelerate assessment. We apply this to a large selection of actual student coursework submissions providing more precise localisation within a sub-second response time. We show this using small test suites already provided in the coursework management system and on expanded test suites demonstrating scaling. We also show compliance with test suites does not predictably score a class of almost correct'' submissions which our tool highlights.""";
Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education;Recently there has been significant interest in employing probabilistic techniques for fault localization. Using dynamic dependence information for multiple passing runs learning techniques are used to construct a probabilistic graph model for a given program. Then given a failing run the probabilistic model is used to rank the executed statements according to the likelihood of them being faulty. In this paper we present a novel probabilistic approach in which universal probabilistic models are learned to characterize the behaviors of various instruction types used by all programs. The universal probabilistic model for an instruction type is in form of a probability distribution that represents how errors in the input (operand) values are propagated as errors in the output (result) of a given instruction type. Once these models have been constructed they can be used in the analysis of any program as follows. Given a set of runs for any program including at least one passing and one failing run a Bayesian network called the Error Flow Graph (EFG) is then constructed from the dynamic dependence graphs of the program runs and the universal probabilistic models. Standard inference algorithms are employed to compute the probability of each executed statement being faulty. We also present optimizations to reduce the runtime cost of inference using the EFG. Our experiments demonstrate that our approach is highly effective in fault localization even when very few passing runs are available. It also performs well in the presence of multiple faults.;
Proceedings of the 9th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering;The Internet of Things (IoT) is a paradigm based on the interaction between intelligent devices (things) and physical and/or virtual resources through the Internet. Thus applications in this domain may become more prone to failures. In this scenario evaluating the quality of applications through software testing can be considered critical and challenging. The focus of this work is to obtain a comprehensive understanding of the adoption of Software Testing in the context of IoT identifying gaps in existing approaches and providing new directions for research in the area. To achieve this goal a systematic mapping covering research papers published in journals and conferences was carried out accessing four relevant electronic databases. As a result a total of 79 studies were selected and analyzed in order to evaluate quantitatively and qualitatively the effective adoption of software testing in the projects.;
Proceedings of the IV Brazilian Symposium on Systematic and Automated Software Testing;"Fault-localization techniques that apply statistical analyses to execution data gathered from multiple tests are quite effective when a large test suite is available. However if no test suite is available what is the best approach to generate one? This paper investigates the fault-localization effectiveness of test suites generated according to several test-generation techniques based on combined concrete and symbolic (concolic) execution. We evaluate these techniques by applying the Ochiai fault-localization technique to generated test suites in order to localize 35 faults in four PHP Web applications. Our results show that the test-generation techniques under consideration produce test suites with similar high fault-localization effectiveness when given a large time budget. However a new directed"" test-generation technique which aims to maximize the similarity between the path constraints of the generated tests and those of faulty executions reaches this level of effectiveness with much smaller test suites. On average when compared to test generation based on standard concolic execution techniques that aims to maximize code coverage the new directed technique preserves fault-localization effectiveness while reducing test-suite size by 86.1% and test-suite generation time by 88.6%.""";
Proceedings of the 19th International Symposium on Software Testing and Analysis;Context: Testing is a fundamental activity in the software development cycle. Revealing software faults is its main objective. Despite that testing is considered unpleasant dull and tedious. As a result there is a lack of expertise among professionals while many projects fail. Gamification is a promising way to address testing issues it is a new trend being used mostly to increase motivation engagement and performance with the use of game elements in non-game contexts. Objective: To describe results of a study that aimed to characterize how gamification has been explored to support software testing. Method: The studies that compose our baseline for analysis and discussion were obtained through a systematic mapping carried out following a research protocol. To retrieve relevant literature we applied automatic search and backward snowballing. At the end we selected 15 studies that we analyzed and classified according to six perspectives: application context used gamifcation elements gamification goals testing techniques testing levels and testing process phases. Results: The most used gamification elements are points leader boards and levels and unit testing and functional testing are the level and technique most addressed in the studies respectively. Conclusion: Gamification is a rising research topic especially in the software testing field. The increasing interest for gamification has the potential do lead to positive outcomes. The map presented in this paper can be a useful resource for the identification of gaps and for triggering new research initiatives.;
Proceedings of the III Brazilian Symposium on Systematic and Automated Software Testing;Debugging takes up a significant portion of developer time. As a result automated debugging techniques including Fault Localization (FL) and Automated Program Repair (APR) have garnered significant attention due to their potential to aid developers in debugging tasks. With the recent advance in techniques that treat the two tasks as closely coupled such as Unified Debugging a framework to formally express these two tasks together would heighten our understanding of automated debugging and provide a way to formally analyze techniques and approaches. To this end we propose a Bayesian framework of understanding automated debugging. We find that the Bayesian framework along with a concrete statement of the objective of automated debugging can recover maximal fault localization formulae from prior work as well as analyze existing APR techniques and their underlying  assumptions.  As a means of empirically demonstrating our framework we further propose BAPP a Bayesian Patch Prioritization technique that incorporates intermediate program values to analyze likely patch locations and repair actions with its core equations being derived by our Bayesian framework. We find that incorporating program values allows BAPP to identify correct patches more precisely: the rankings produced by BAPP reduced the number of required patch evaluations by 68% and consequently reduced the repair time by 34 minutes on average. Further our Bayesian framework suggests a number of changes to the way fault localization information is used in program repair which we validate is useful for BAPP. These results highlight the potential of value-cognizant automated debugging techniques and further verifies our theoretical framework.;
Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis;Spectrum-based fault localization (SBFL) works well for single-fault programs but its accuracy decays for increasing fault numbers. We present FLITSR (Fault Localization by Iterative Test Suite Reduction) a novel SBFL extension that improves the localization of a given base metric specifically in the presence of multiple faults. FLITSR iteratively selects reduced versions of the test suite that better localize the individual faults in the system. This allows it to identify and re-rank faults ranked too low by the base metric because they were masked by other program elements. We evaluated FLITSR over method-level spectra from an existing large synthetic dataset comprising 75000 variants of 15 open-source projects with up to 32 injected faults as well as method- and statement-level spectra from a new dataset with 326 true multi-fault versions from the Defects4J benchmark set containing up to 14 real faults. For all three spectrum types we consistently see substantial reductions of the average wasted efforts at different fault levels of 30%-90% over the best base metric and generally similarly large increases in precision and recall albeit with larger variance across the underlying projects. For the method-level real faults FLITSR also substantially outperforms GRACE a state-of-the-art learning-based fault localizer.;
Proceedings of the 3rd Annual Conference on Systems Programming and Applications: Software for Humanity;Software testing is hard and a testing problem is composed of many sub-problems with different often conflicting solutions. Like many real-world problems it admits no single optimal solution but requires dexterity and the opportunistic combination of many partial solutions. Exploration and experiment even by practitioners are important in real-world critical testing efforts. An important set of research results in the field endorse and codify the value of diversity in test generation. However our current approaches to evaluating research results arguably cut against this fundamental reality: while effective testing may need true diversity combining many partial answers the iron logic of the research results section often imposes a totalizing vision where authors must at least pretend to present a monolithic unitary solution a new â€œking of the hill.â€;
Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas New Paradigms and Reflections on Programming and Software;The objective of IFRA Instruction Footprint Recording and Analysis is to overcome the challenges associated with a very expensive step in post-silicon validation of processors -- bug localization in a system setup. IFRA consists of special design and analysis techniques required to bridge a major gap between system-level and circuit-level debug. Special hardware recorders called Footprint Recording Structures (FRS's) record semantic information about data and control flows of instructions passing through various design blocks of a processor. This information is recorded concurrently during normal operation of a processor in a post-silicon system validation setup. Upon detection of a problem the recorded information is scanned out and analyzed for bug localization. Special program analysis techniques together with the binary of the application executed during post-silicon validation are used for the analysis. IFRA does not require full system-level reproduction of bugs or system-level simulation. Simulation results on a complex super-scalar processor demonstrate that IFRA is effective in accurately localizing bugs with very little impact on overall chip area.;
Proceedings of the 45th Annual Design Automation Conference;"In this paper we present an automated technique for localizing faults in data-centric programs. Data-centric programs primarily interact with databases to get collections of content process each entry in the collection(s) and output another collection or write it back to the database. One or more entries in the output may be faulty. In our approach we gather the execution trace of a faulty program. We use a novel precise slicing algorithm to break the trace into multiple slices such that each slice maps to an entry in the output collection. We then compute the semantic difference between the slices that correspond to correct entries and those that correspond to incorrect ones. The diff"" helps to identify potentially faulty statements.We have implemented our approach for ABAP programs. ABAP is the language used to write custom code in SAP systems. It interacts heavily with databases using embedded SQL-like commands that work on collections of data. On a suite of 13 faulty ABAP programs our technique was able to identify the precise fault location in 12 cases.""";
Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering;Software systems are present in people's lives and they are increasing to the same extent as their complexity and their criticality. Therefore we must ensure that these systems maintain high quality in order to behave as expected. To develop high quality software it is essential to have qualified people who are knowledgeable about Validation and Verification (V&ampV) techniques especially software testing. This paper reports on the teaching process in two undergraduate courses in two different contexts: Computer Science students who can dedicate more time during the day to studying and Information Systems students who can only study during the evenings. To engage and motivate the students in the context of software testing learning we studied ways to bring real industry problems to the classroom in order to adopt the Problem-based Learning (PBL) approach. We chose two real open source projects which considering the feedback from students and professors was a good decision. However the approach requires students to take extra classes rather than teacher-centered approaches. Extra classes may hinder the approach when the class consists of students who work during the day thus developing a balance between student-centered and teacher-centered can be a good solution in such contexts.;
Proceedings of the XXXIII Brazilian Symposium on Software Engineering;Background: Automated diagnosis of software defects can drastically increase debugging efficiency improving reliability and time-to-market. Current low-cost automatic fault diagnosis techniques such as spectrum-based fault localization (SFL) merely use information on whether a component is involved in a passed/failed run or not. However these approaches ignore information on component execution frequency which can improve the accuracy of the diagnostic process. Aim: In this paper we study the impact of exploiting component execution frequency on the diagnostic quality. Method: We present a reasoning-based SFL approach dubbed Zoltar-C that exploits not only component involvement but also their frequency using an approximate Bayesian approach to compute the probabilities of the diagnostic candidates. Zoltar-C is evaluated and compared to other well-known low-cost techniques (such as Tarantula) using a set of programs available from the Software Infrastructure Repository. Results: Results show that although theoretically Zoltar-C can be of added value exploiting component frequency does not improve diagnostic accuracy on average. Conclusions: The major reason for this unexpected result is the highly biased sample of passing and failing tests provided with the programs under analysis. In particular the ratio between passing and failing runs which has a major impact on the probability computations does not correspond to the false negative (failure) rates associated with the actually injected faults.;
Proceedings of the 6th International Conference on Predictive Models in Software Engineering;Like any other distributed system cloud management stacks such as OpenStack are susceptible to faults whose root cause is often hard to diagnose and may take hours or days to fix. We present GRETEL a system that leverages non-intrusive system monitoring to expedite root cause analysis of both operational and performance faults manifesting in OpenStack operations. GRETEL uses unique operational fingerprints to quickly identify faulty operations at runtime. GRETEL is accurate in its diagnosis and achieves &gt98% precision in identifying the faulty operation with very few false positives and negatives even under conditions of stress. GRETEL is lightweight and orders of magnitude faster than prior work sustaining a throughput of ~77 Mbps.;
Proceedings of the 12th International on Conference on Emerging Networking EXperiments and Technologies;During an Open Source Software (OSS) maintenance bug localization is a laborsome and time-consuming work for geographically-separated developers. It is desirable to automatically identify related buggy files once a bug report is submitted. Existing work has proposed information retrieval techniques for this problem. However these proposals tend to neglect the inherent structure in bug localization and they are largely dependent on the comments (annotations) in source files which may be unavailable. In this paper we propose a random walk based approach to detecting buggy source files based on bug reports. In particular we separately process source files and bug reports to make it less sensitive to comments and then apply random walk to capture the inherent structure in bug localization. Experimental evaluations on three real-world open-source projects demonstrate that the proposed approach can outperform several existing methods and that it is less dependent on the comments in source files.;
Proceedings of the 2019 4th International Conference on Distance Education and Learning;Deep Neural Networks (DNNs) are finding a place at the heart of more and more critical systems and it is necessary to ensure they perform in as correct a way as possible. Search-based repair methods that search for new values for target neuron weights in the network to better process fault-inducing inputs have shown promising results. These methods rely on fault localisation to determine what weights the search should target. However as the search progresses and the network evolves the weights responsible for the faults in the system will change and the search will lose in effectiveness. In this work we propose an adaptive search method for DNN repair that adaptively updates the target weights during the search by performing fault localisation on the current state of the model. We propose and implement two methods to decide when to update the target weights based on the progress of the search's fitness value or on the evolution of fault localisation results. We apply our technique to two image classification DNN architectures against a dataset of autonomous driving images and compare it with a state-of-the art search-based DNN repair approach.;
Proceedings of the 38th International Conference on Software Engineering;Deep Neural Networks (DNNs) are used in a wide variety of applications. However as in any software application DNN-based apps are afflicted with bugs. Previous work observed that DNN bug fix patterns are different from traditional bug fix patterns. Furthermore those buggy models are non-trivial to diagnose and fix due to inexplicit errors with several options to fix them. To support developers in locating and fixing bugs we propose DeepDiagnosis a novel debugging approach that localizes the faults reports error symptoms and suggests fixes for DNN programs. In the first phase our technique monitors a training model periodically checking for eight types of error conditions. Then in case of problems it reports messages containing sufficient information to perform actionable repairs to the model. In the evaluation we thoroughly examine 444 models - 53 real-world from GitHub and Stack Overflow and 391 curated by AUTOTRAINER. DeepDiagnosis provides superior accuracy when compared to UMLUAT and DeepLocalize. Our technique is faster than AUTOTRAINER for fault localization. The results show that our approach can support additional types of models while state-of-the-art was only able to handle classification ones. Our technique was able to report bugs that do not manifest as numerical errors during training. Also it can provide actionable insights for fix whereas DeepLocalize can only report faults that lead to numerical errors during training. DeepDiagnosis manifests the best capabilities of fault detection bug localization and symptoms identification when compared to other approaches.;
Proceedings of the 3rd International Conference on Applications in Information Technology;Concurrency fault are difficult to find because they usually occur under specific thread interleavings. Fault-detection tools in this area find data-access patterns among thread interleavings but they report benign patterns as well as actual faulty patterns. Traditional fault-localization techniques have been successful in identifying faults in sequential deterministic programs but they cannot detect faulty data-access patterns among threads. This paper presents a new dynamic fault-localization technique that can pinpoint faulty data-access patterns in multi-threaded concurrent programs. The technique monitors memory-access sequences among threads detects data-access patterns associated with a program's pass/fail results and reports dataaccess patterns with suspiciousness scores. The paper also presents the description of a prototype implementation of the technique in Java and the results of an empirical study we performed with the prototype on several Java benchmarks. The empirical study shows that the technique can effectively and efficiently localize the faults for our subjects.;
Proceedings of the 2018 7th International Conference on Software and Computer Applications;In the last four years the number of distinct autonomous vehicles platforms deployed in the streets of California increased 6-fold while the reported accidents increased 12-fold. This can become a trend with no signs of subsiding as it is fueled by a constant stream of innovations in hardware sensors and machine learning software. Meanwhile if we expect the public and regulators to trust the autonomous vehicle platforms we need to find better ways to solve the problem of adding technological complexity without increasing the risk of accidents. We studied this problem from the perspective of reliability engineering in which a given risk of an accident has severity and probability of occurring. Timely information on accidents is important for engineers to anticipate and reuse previous failures to approximate the risk of accidents in a new city. However this is challenging in the context of autonomous vehicles because of the sparse nature of data on the operational scenarios (driving trajectories in a new city). Our approach was to mitigate data sparsity by reducing the state space through monitoring of multiple-vehicles operations. We then minimized the risk of accidents by determining proper allocation of tests for each equivalence class. Our contributions comprise (1) a set of strategies to monitor the operational data of multiple autonomous vehicles (2) a Bayesian model that estimates changes in the risk of accidents and (3) a feedback control-loop that minimizes these risks by real-locating test effort. Our results are promising in the sense that we were able to measure and control risk for a diversity of changes in the operational scenarios. We evaluated our models with data from two real cities with distinct traffic patterns and made the data available for the community.;
Proceedings of the IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems;[Background]: A variety of software testing techniques have been published by the academia in the last years however the industry rarely embraces their use. The transference of knowledge between academia and industry is a challenge which is mainly occasioned by a lack of a solid base evidence with effective information to help the tester during the selection of a testing technique. [Aim]: This paper presents a computational infrastructure called SeleCTT tool that uses relevant information of concurrent software testing techniques to automate the selection of an adequate testing approach for a concurrent software project. [Method]: A review on the available technical literature was performed to identify attributes and concepts of concurrent software testing that affect the selection process and a characterization approach was developed and used as a kernel of the tool. [Results and Conclusions]: An online repository was built to guide the techniques selection in order to provide interaction with the interested community. This works as a body of evidence for this area. Therefore the SeleCTT tool provides a wide range access to all this information and also supports the decision-making process on the choice of the testing technique suitable for a concurrent software project.;
Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining;Testing is technically and economically crucial for ensuring software quality. One of the most challenging testing tasks is to create test suites that will reveal potential defects in software. However as the size and complexity of software systems increase the task becomes more labour-intensive and manual test data generation becomes infeasible. To address this issue researchers have proposed different approaches to automate the process of generating test data using search techniques an area that is known as Search-Based Software Testing (SBST).SBST methods require a fitness function to guide the search to promising areas of the solution space. Over the years a plethora of fitness functions have been proposed. Some methods use control information others focus on goals. Deciding on what fitness function to use is not easy as it depends on the software system under test. This work investigates the impact of software features on the effectiveness of different fitness functions. We propose the Mapping the Effectiveness of Test Automation (META) Framework which analyses the footprint of different fitness functions and creates a decision tree that enables the selection of the appropriate function based on software features.;
Proceedings of the International Conference for High Performance Computing Networking Storage and Analysis;Compiler bugs can be disastrous since they could affect all the software systems built on the buggy compilers. Meanwhile diagnosing compiler bugs is extremely challenging since usually limited debugging information is available and a large number of compiler files can be suspicious. More specifically when compiling a given bug-triggering test program hundreds of compiler files are usually involved and can all be treated as suspicious buggy files. To facilitate compiler debugging in this paper we propose the first reinforcement compiler bug isolation approach via structural mutation called RecBi. For a given bug-triggering test program RecBi first augments traditional local mutation operators with structural ones to transform it into a set of passing test programs. Since not all the passing test programs can help isolate compiler bugs effectively RecBi further leverages reinforcement learning to intelligently guide the process of passing test program generation. Then RecBi ranks all the suspicious files by analyzing the compiler execution traces of the generated passing test programs and the given failing test program following the practice of compiler bug isolation. The experimental results on 120 real bugs from two most popular C open-source compilers i.e. GCC and LLVM show that RecBi is able to isolate about 23%/58%/78% bugs within Top-1/Top-5/Top-10 compiler files and significantly outperforms the state-of-the-art compiler bug isolation approach by improving 92.86%/55.56%/25.68% isolation effectiveness in terms of Top-1/Top-5/Top-10 results.;
Proceedings of the 2018 International Conference on Software and System Process;Massive datasets are quickly becoming a concern for many industries. For example many web-based applications must be able to handle petabytes worth of transactions on a daily basis and moreover be able to quickly and efficiently act upon data that exists in each transaction. As a result providing testing capabilities for such applications becomes a challenge of scale. We argue that existing approaches such as automated test suite generation may not necessarily scale without assistance. To this end we discuss open issues and possible solutions specific to testing big data applications.;
Proceedings of the 9th International Workshop on Search-Based Software Testing;Software testing is a popular mean of examining the adequacy of a developed product. However in academic institutions more emphasis is given to software development than ensuring its quality. In order to address the gaps between existing university-level software testing education and the training standards used in industry we experiment with employing a popular teaching method Case-Based Learning (CBL) for the first time to facilitate the training of selected software testing concepts at tertiary-level. The CBL exercise is conducted for undergraduate students of DAIICT Gandhinagar (India) to cultivate the decision making skills in a self-learning environment. After the CBL execution we collect students' responses through a short survey and perform an empirical analysis on the survey results. The outcome of this CBL practice is positive as a majority of students are able to achieve the five stated objectives of CBL. We examine that there is a statistically significant difference between students' responses based on gender diversity. We also investigate the difference in students' feedback to the two different CBL cases that we use for practicing some aspects of software testing. Moreover we draw useful inferences from the opinions of TAs (Teaching Assistants) about the CBL sessions.;
Proceedings of the 11th Innovations in Software Engineering Conference;As Deep Learning (DL) systems are widely deployed for mission-critical applications debugging such systems becomes essential. Most existing works identify and repair suspicious neurons on the trained Deep Neural Network (DNN) which unfortunately might be a detour. Specifically several existing studies have reported that many unsatisfactory behaviors are actually originated from the faults residing in DL programs. Besides locating faulty neurons is not actionable for developers while locating the faulty statements in DL programs can provide developers with more useful information for debugging. Though a few recent studies were proposed to pinpoint the faulty statements in DL programs or the training settings (e.g. too large learning rate) they were mainly designed based on predefined rules leading to many false alarms or false negatives especially when the faults are beyond their capabilities.In view of these limitations in this paper we proposed DeepFD a learning-based fault diagnosis and localization framework which maps the fault localization task to a learning problem. In particular it infers the suspicious fault types via monitoring the runtime features extracted during DNN model training and then locates the diagnosed faults in DL programs. It overcomes the limitations by identifying the root causes of faults in DL programs instead of neurons and diagnosing the faults by a learning approach instead of a set of hard-coded rules. The evaluation exhibits the potential of DeepFD. It correctly diagnoses 52% faulty DL programs compared with around half (27%) achieved by the best state-of-the-art works. Besides for fault localization DeepFD also outperforms the existing works correctly locating 42% faulty programs which almost doubles the best result (23%) achieved by the existing works.;
Proceedings of the Ninth ACM Conference on Learning @ Scale;In software development of configurable systems effective software testing is essential. As high configurability entails high testing effort effective testing is required to meet cost constraints while ensuring satisfactory end product quality. In this paper we present an initial study on the potential of using statistical testing techniques for improving the efficiency of test selection for configurable software. The study aims to answer whether statistical testing can reduce the effort of localizing the most critical software faults seen from user perspective. We use probabilistic transition system as the formalism for modeling a probabilistic behavior of the system and usage models to detect faults that would impact users the most. We present an exemplary case study used to assess the performance of statistical test selection compared to manual practice.;
Proceedings of the International Workshop on Formal Methods for Analysis of Business Systems;The existing deep learning (DL)-based automated program repair (APR) models are limited in fixing general software defects. We present DEAR a DL-based approach that supports fixing for the general bugs that require dependent changes at once to one or multiple consecutive statements in one or multiple hunks of code. We first design a novel fault localization (FL) technique for multi-hunk multi-statement fixes that combines traditional spectrum-based (SB) FL with deep learning and data-flow analysis. It takes the buggy statements returned by the SBFL model detects the buggy hunks to be fixed at once and expands a buggy statement s in a hunk to include other suspicious statements around s. We design a two-tier tree-based LSTM model that incorporates cycle training and uses a divide-and-conquer strategy to learn proper code transformations for fixing multiple statements in the suitable fixing context consisting of surrounding subtrees. We conducted several experiments to evaluate DEAR on three datasets: Defects4J (395 bugs) BigFix (+26k bugs) and CPatMiner (+44k bugs). On Defects4J dataset DEAR outperforms the baselines from 42%--683% in terms of the number of auto-fixed bugs with only the top-1 patches. On BigFix dataset it fixes 31--145 more bugs than existing DL-based APR models with the top-1 patches. On CPatMiner dataset among 667 fixed bugs there are 169 (25.3%) multi-hunk/multi-statement bugs. DEAR fixes 71 and 164 more bugs including 52 and 61 more multi-hunk/multi-statement bugs than the state-of-the-art DL-based APR models.;
Proceedings of the Eighteenth ACM SIGSOFT International Symposium on Foundations of Software Engineering;How can we automatically repair semantic bugs in string-processing programs?   A semantic bug is an unexpected program state: The program does not crash (which can be easily detected). Instead the program processes the input incorrectly. It produces an output which users identify as unexpected. We envision a fully automated debugging process for semantic bugs where a user reports the unexpected behavior for a given input and the machine negotiates the condition under which the program fails. During the negotiation the machine learns to predict the user's response and in this process learns an automated oracle for semantic bugs.   In this paper we introduce Grammar2Fix an automated oracle learning and debugging technique for string-processing programs even when the input format is unknown. Grammar2Fix represents the oracle as a regular grammar which is iteratively improved by systematic queries to the user for other inputs that are likely failing. Grammar2Fix implements several heuristics to maximize the oracle quality under a minimal query budget. In our experiments with 3 widely-used repair benchmark sets Grammar2Fix predicts passing inputs as passing and failing inputs as failing with more than 96% precision and recall using a median of 42 queries to the user.;
Proceedings of the 33rd International Conference on Software Engineering;Issue tracking systems are commonly used in modern software development for collecting feedback from users and developers. An ultimate automation target of software maintenance is then the systematization of patch generation for user-reported bugs. Although this ambition is aligned with the momentum of automated program repair the literature has so far mostly focused on generate-and- validate setups where fault localization and patch generation are driven by a well-defined test suite. On the one hand however the common (yet strong) assumption on the existence of relevant test cases does not hold in practice for most development settings: many bugs are reported without the available test suite being able to reveal them. On the other hand for many projects the number of bug reports generally outstrips the resources available to triage them. Towards increasing the adoption of patch generation tools by practitioners we investigate a new repair pipeline iFixR driven by bug reports: (1) bug reports are fed to an IR-based fault localizer (2) patches are generated from fix patterns and validated via regression testing (3) a prioritized list of generated patches is proposed to developers. We evaluate iFixR on the Defects4J dataset which we enriched (i.e. faults are linked to bug reports) and carefully-reorganized (i.e. the timeline of test-cases is naturally split). iFixR generates genuine/plausible patches for 21/44 Defects4J faults with its IR-based fault localizer. iFixR accurately places a genuine/plausible patch among its top-5 recommendation for 8/13 of these faults (without using future test cases in generation-and-validation).;
Proceedings of the 16th International Conference on Mining Software Repositories;The exponential growth of social media platforms such as Facebook Instagram Youtube and TikTok has revolutionized communication and content publication in human society. Users on these platforms can publish multimedia content that delivers information via the combination of text audio images and video. Meanwhile the multimedia content release facility has been increasingly exploited to propagate toxic content such as hate speech malicious advertisement and pornography. To this end content moderation software has been widely deployed on these platforms to detect and blocks toxic content. However due to the complexity of content moderation models and the difficulty of understanding information across multiple modalities existing content moderation software can fail to detect toxic content which often leads to extremely negative impacts (e.g. harmful effects on teen mental health).  We introduce Semantic Fusion a general effective methodology for validating multimedia content moderation software. Our key idea is to fuse two or more existing single-modal inputs (e.g. a textual sentence and an image) into a new input that combines the semantics of its ancestors in a novel manner and has toxic nature by construction. This fused input is then used for validating multimedia content moderation software. We realized Semantic Fusion as DUO a practical content moderation software testing tool. In our evaluation we employ DUO to test five commercial content moderation software and two state-of-the-art models against three kinds of toxic contents. The results show that DUO achieves up to 100% error finding rate (EFR) when testing moderation software and it obtains up to 94.1% EFR when testing the state-of-the-art models. In addition we leverage the test cases generated by DUO to retrain the two models we explored which largely improves model robustness (2.5%âˆ¼5.7% EFR) while maintaining the accuracy on the original test set.;
Proceedings of the 2021 ACM SIGCOMM 2021 Conference;Nowadays many applications do not exist independently but rely on various frameworks or libraries. The frequent evolution and the complex implementation of framework APIs induce lots of unexpected post-release crashes. Starting from the crash stack traces existing approaches either perform application-level call graph (CG) tracing or construct datasets with similar crash-fixing records to locate buggy methods. However these approaches are limited by the completeness of CG or dependent on historical fixing records and some of them only focus on specific manually modeled exception types.To achieve effective debugging on complex framework-specific crashes we propose a code-separation-based locating approach that weakly relies on CG tracing and does not require any prior knowledge. Our key insight is that one crash trace with the description message can be mapped to a definite exception-thrown point in the framework the semantics analysis of which can help to figure out the root causes of the crash-triggering procedure. Thus we can pre-construct reusable summaries for all the framework-specific exceptions to support fault localization in application code. Based on that idea we design the exception-thrown summary (ETS) that describes both the key variables and key APIs related to the exception triggering. Then we perform static analysis to automatically compute such summaries and make a data-tracking of key variables and APIs in the application code to get the ranked buggy candidates. In the scenario of locating Android framework-specific crashing faults our tool CrashTracker exhibited an overall MRR value of 0.91 and outperforms the state-of-the-art tool Anchor with higher precision. It only provides a compact candidate set and gives user-friendly reports with explainable reasons for each candidate.;
Proceedings of the 2011 SIGPLAN/SIGBED Conference on Languages Compilers and Tools for Embedded Systems;Flaky tests which can non-deterministically pass or fail on the same code impose significant burden on developers by providing misleading signals during regression testing. Microsoft developers consider flaky tests as one of the top two reasons for slowing down software development. In order to debug the root-cause of a flaky behavior a developer often needs to first reliably reproduce a failed execution. Unfortunately this is non-trivial. For example most of the flakiness in unit tests are caused by concurrency and reproducing their failures requires specific thread interleaving. To address this challenge we introduce FlakeRepro that helps developers reproduce a failed execution of a flaky test caused by concurrency. FlakeRepro combines static and dynamic analysis to quickly identify an interleaving that makes a flaky test fail with the same original error message. FlakeRepro is efficient: it can reproduce a failed execution after exploring few tens of interleavings. FlakeRepro integrates well with existing systems: it automatically instruments test binaries that can run on existing and unmodified test pipelines. We have implemented FlakeRepro for .NET and used it in Microsoft. In an experiment with 22 Microsoft projects FlakeRepro could reproduce 26 of total 31 concurrent-related flaky tests after exploring only &lt7 interleavings and within 6 minutes on average.;
Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings;Automated Program Repair (APR) is one of the most recent advances in automated debugging and can directly fix buggy programs with minimal human intervention. Although various advanced APR techniques (including search-based or semantic-based ones) have been proposed they mainly work at the source-code level and it is not clear how bytecode-level APR performs in practice. Also empirical studies of the existing techniques on bugs beyond what has been reported in the original papers are rather limited. In this paper we implement the first practical bytecode-level APR technique PraPR and present the first extensive study on fixing real-world bugs (e.g. Defects4J bugs) using JVM bytecode mutation. The experimental results show that surprisingly even PraPR with only the basic traditional mutators can produce genuine fixes for 17 bugs with simple additional commonly used APR mutators PraPR is able to produce genuine fixes for 43 bugs significantly outperforming state-of-the-art APR while being over 10X faster. Furthermore we performed an extensive study of PraPR and other recent APR tools on a large number of additional real-world bugs and demonstrated the overfitting problem of recent advanced APR tools for the first time. Lastly PraPR has also successfully fixed bugs for other JVM languages (e.g. for the popular Kotlin language) indicating PraPR can greatly complement existing source-code-level APR.;
Proceedings of the Ninth Annual International ACM Conference on International Computing Education Research;The software engineering practice of automated testing helps programmers find defects earlier during development. With growing software projects and longer-running test suites frequency and immediacy of feedback decline thereby making defects harder to repair. Regression test prioritization (RTP) is concerned with running relevant tests earlier to lower the costs of defect localization and to improve feedback.Finding representative data to evaluate RTP techniques is non-trivial as most software is published without failing tests. In this work we systematically survey a wide range of RTP literature regarding whether their dataset uses real or synthetic defects or tests whether they are publicly available and whether datasets are reused. We observed that some datasets are reused however many projects study only few projects and these rarely resemble real-world development activity.In light of these threats to ecological validity we describe the construction and characteristics of a new dataset named RTPTorrent based on 20 open-source Java programs.Our dataset allows researchers to evaluate prioritization heuristics based on version control meta-data source code and test results from fine-grained automated builds over 9 years of development history. We provide reproducible baselines for initial comparisons and make all data publicly available.We see this as a step towards better reproducibility ecological validity and long-term availability of studied software in the field of test prioritization.;
Proceedings of the 7th International Workshop on Automation of Software Test;Programming errors that degrade the performance of systems are widespread yet there is very little tool support for finding and diagnosing these bugs. We present a method and a tool based on differential performance analysis---we find inputs for which the performance varies widely despite having the same size. To ensure that the differences in the performance are robust (i.e. hold also for large inputs) we compare the performance of not only single inputs but of classes of inputs where each class has similar inputs parameterized by their size. Thus each class is represented by a performance function from the input size to performance. Importantly we also provide an explanation for why the performance differs in a form that can be readily used to fix a performance bug. The two main phases in our method are discovery with fuzzing and explanation with decision tree classifiers each of which is supported by clustering. First we propose an evolutionary fuzzing algorithm to generate inputs that characterize different performance functions. For this fuzzing task the unique challenge is that we not only need the input class with the worst performance but rather a set of classes exhibiting differential performance. We use clustering to merge similar input classes which significantly improves the efficiency of our fuzzer. Second we explain the differential performance in terms of program inputs and internals (e.g. methods and conditions). We adapt discriminant learning approaches with clustering and decision trees to localize suspicious code regions. We applied our techniques on a set of micro-benchmarks and real-world machine learning libraries. On a set of micro-benchmarks we show that our approach outperforms state-of-the-art fuzzers in finding inputs to characterize differential performance. On a set of case-studies we discover and explain multiple performance bugs in popular machine learning frameworks for instance in implementations of logistic regression in scikit-learn. Four of these bugs reported first in this paper have since been fixed by the developers.;
Proceedings of the 3rd ACM/IEEE International Conference on Automation of Software Test;With the end of conventional CMOS scaling efficient resiliency solutions are needed to address the increased likelihood of hardware errors. Silent data corruptions (SDCs) are especially harmful because they can create unacceptable output without the user's knowledge. Several resiliency analysis techniques have been proposed to identify SDC-causing instructions but they remain too slow for practical use and/or sacrifice accuracy to improve analysis speed. We develop Minotaur a novel toolkit to improve the speed and accuracy of resiliency analysis. The key insight behind Minotaur is that modern resiliency analysis has many conceptual similarities to software testing therefore adapting techniques from the rich software testing literature can lead to principled and significant improvements in resiliency analysis. Minotaur identifies and adapts four concepts from software testing: 1) it introduces the concept of input quality criteria for resiliency analysis and identifies PC coverage as a simple but effective criterion 2) it creates (fast) minimized inputs from (slow) standard benchmark inputs using the input quality criteria to assess the goodness of the created input 3) it adapts the concept of test case prioritization to prioritize error injections and invoke early termination for a given instruction to speed up error-injection campaigns and 4) it further adapts test case or input prioritization to accelerate SDC discovery across multiple inputs. We evaluate Minotaur by applying it to Approxilyzer a state-of-the-art resiliency analysis tool. Minotaur's first three techniques speed up Approxilyzer's resiliency analysis by 10.3X (on average) for the workloads studied. Moreover they identify 96% (on average) of all SDC-causing instructions explored compared to 64% identified by Approxilyzer alone. Minotaur's fourth technique (input prioritization) enables identifying all SDC-causing instructions explored across multiple inputs at a speed 2.3X faster (on average) than analyzing each input independently for our workloads.;
Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems;This paper is a report on the 8th International Workshop on Search-Based Software Testing at the 37th International Conference on Sofrware Engineering (ICSE). Search-Based Software Testing (SBST) is a form of Search-Based Software Engineering (SBSE) that optimizes testing through the use of computational search. SBST is used to generate test data prioritize test cases minimize test suites reduce human oracle cost verify software models test service-orientated architectures construct test suites for interaction testing and validate real-time properties. The objectives of this workshop are to bring together researchers and industrial practitioners from SBST and the wider software engineering community to share experience and provide directions for future research and to encourage the use of search techniques to combine aspects of testing with other aspects of the software engineering lifecycle.Three full research papers three short papers and three position papers will be presented in the two-day workshop. Additionally six development groups have pitted their test generation tools against a common set of programs and benchmarks and will present their techniques and results. This report will give the background of the workshop and detail the provisional program.;
Proceedings of the 37th International Conference on Software Engineering - Volume 2;Numerous automated techniques have been proposed to reduce the cost of software debugging a notoriously time-consuming and human-intensive activity. Among these techniques Statistical Fault Localization (SFL) is particularly popular. One issue with SFL is that it is based on strong often unrealistic assumptions on how developers behave when debugging. To address this problem we propose Enlighten an interactive feedback-driven fault localization technique. Given a failing test Enlighten (1) leverages SFL and dynamic dependence analysis to identify suspicious method invocations and corresponding data values (2) presents the developer with a query about the most suspicious invocation expressed in terms of inputs and outputs (3) encodes the developer feedback on the correctness of individual data values as extra program specifications and (4) repeats these steps until the fault is found. We evaluated Enlighten in two ways. First we applied Enlighten to 1807 real and seeded faults in 3 open source programs using an automated oracle as a simulated user for over 96% of these faults Enlighten required less than 10 interactions with the simulated user to localize the fault and a sensitivity analysis showed that the results were robust to erroneous responses. Second we performed an actual user study on 4 faults with 24 participants and found that participants who used Enlighten performed significantly better than those not using our tool in terms of both number of faults localized and time needed to localize the faults.;
Proceedings of the 40th International Conference on Software Engineering;Software developers often rely on regression testing to ensure that recent changes made to the source code do not introduce bugs. Flaky tests which non-deterministically pass or fail regardless of any change to the code can negatively impact the effectiveness of the regression testing. While state-of-the-art is advancing the techniques for test-flakiness detection and mitigation the community is missing a systematic approach for generating high-quality benchmarks of flaky tests to compare the effectiveness of such techniques. Inspired by the power of mutation testing in evaluating the fault-detection ability of tests this paper proposes Croissant a framework for injecting flakiness into the test suites to assess the effectiveness of test-flakiness detection tools in finding these tests. Croissant implements 18 flakiness-inducing mutation operators. We designed these operators to allow controlling the non-determinism involved in flakiness i.e. making many mutants deterministically pass or fail to observe flaky behavior. Our extensive empirical evaluation of Croissant on the test suites of 15 real-world projects confirms the ability of designed mutation operators to generate high-quality mutants and their effectiveness in challenging test-flakiness detection tools in revealing flaky tests.;
Proceedings of the 1st Brazilian Symposium on Systematic and Automated Software Testing;The current increased demand for distributed applications in domains such as web services and cloud computing has significantly increased interest in concurrent programming. This demand in turn has resulted in new testing methodologies for such systems which take account of the challenges necessary to test these applications. This paper presents a systematic review of the published research related to concurrent testing approaches bug classification and testing tools. A systematic review is a process of collection assessment and interpretation of the published papers related to a specific search question designed to provide a background for further research. The results include information about the research relationships and research teams that are working in the different areas of concurrent programs testing.;
Proceedings of the Workshop on Parallel and Distributed Systems: Testing Analysis and Debugging;Bug localization refers to the automated process of locating the potential buggy files for a given bug report. To help developers focus their attention to those files is crucial. Several existing automated approaches for bug localization from a bug report face a key challenge called lexical mismatch in which the terms used in bug reports to describe a bug are different from the terms and code tokens used in source files. This paper presents a novel approach that uses deep neural network (DNN) in combination with rVSM an information retrieval (IR) technique. rVSM collects the feature on the textual similarity between bug reports and source files. DNN is used to learn to relate the terms in bug reports to potentially different code tokens and terms in source files and documentation if they appear frequently enough in the pairs of reports and buggy files. Our empirical evaluation on real-world projects shows that DNN and IR complement well to each other to achieve higher bug localization accuracy than individual models. Importantly our new model HyLoc with a combination of the features built from DNN rVSM and project's bug-fixing history achieves higher accuracy than the state-of-the-art IR and machine learning techniques. In half of the cases it is correct with just a single suggested file. Two out of three cases a correct buggy file is in the list of three suggested files.;
Proceedings of the 10th International Workshop on Automation of Software Test;Virtual Reality (VR) is an emerging technique that provides a unique real-time experience for users. VR technologies have provided revolutionary user experiences in various scenarios (e.g. training education gaming etc.). However testing VR applications is challenging due to their nature which necessitates physical interactivity and their reliance on specific hardware systems. Despite the recent advancements in VR technology and its usage scenarios we still know little about VR application testing. To fill up this knowledge gap we performed an empirical study on 314 open-source VR applications. Our analysis identified that 79% of the VR projects evaluated did not have any automatic tests and for the VR projects that did the median functional-method to test-method ratios were lower than those of other project types. Moreover we uncovered tool support issues concerning the measurement of VR code coverage and the assertion density results we were able to generate were relatively low with an average of 17.63%. Finally through a manual analysis of 370 test cases we identified the different categories of test cases being used to validate VR application quality attributes. Furthermore we extracted which of these categories are VR-attention meaning that test writers need to pay special attention to VR characteristics when writing tests of these categories. We believe that our findings constitute a call to action for the VR development community to improve their automatic testing practices and provide directions for software engineering researchers to develop advanced techniques for automatic test case generation and test quality analysis for VR applications. Our replication package containing the dataset we used software tools we developed and the results we found is accessible atâ€„â€https://doi.org/10.6084/m9.figshare.19678938.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training;Federated Learning (FL) is a privacy-preserving distributed machine learning technique that enables individual clients (e.g. user participants edge devices or organizations) to train a model on their local data in a secure environment and then share the trained model with an aggregator to build a global model collaboratively. In this work we propose FedDefender a defense mechanism against targeted poisoning attacks in FL by leveraging differential testing. FedDefender first applies differential testing on clientsâ€™ models using a synthetic input. Instead of comparing the output (predicted label) which is unavailable for synthetic input FedDefender fingerprints the neuron activations of clientsâ€™ models to identify a potentially malicious client containing a backdoor. We evaluate FedDefender using MNIST and FashionMNIST datasets with 20 and 30 clients and our results demonstrate that FedDefender effectively mitigates such attacks reducing the attack success rate (ASR) to 10% without deteriorating the global model performance.;
Proceedings of the 1st International Workshop on Dependability and Trustworthiness of Safety-Critical Systems with Machine Learned Components;Failed error propagation (FEP) is known to hamper software testing yet it remains poorly understood. We introduce an information theoretic formulation of FEP that is based on measures of conditional entropy. This formulation considers the situation in which we are interested in the potential for an incorrect program state at statement s to fail to propagate to incorrect output. We define five metrics that differ in two ways: whether we only consider parts of the program that can be reached after executing s and whether we restrict attention to a single program path of interest .We give the results of experiments in which it was found that on average one in 10 tests suffered from FEP earlier studies having shown that this figure can vary significantly between programs. The experiments also showed that our metrics are well-correlated with FEP. Our empirical study involved 30 programs for which we executed a total of 7140000 test cases. The results reveal that the metrics differ in their performance but the Spearman rank correlation with failed error propagation is close to 0.95 for two of the metrics. These strong correlations in an experimental setting in which all information about both FEP and conditional entropy is known open up the possibility in the longer term of devising inexpensive information theory based metrics that allow us to minimise the effect of FEP.;
Proceedings of the 36th International Conference on Software Engineering;Android apps are ubiquitous and serve many aspects of our daily lives. Ensuring their functional correctness is crucial for their success. To date we still lack a general and in-depth understanding of functional bugs which hinders the development of practices and techniques to tackle functional bugs. To fill this gap we conduct the first systematic study on 399 functional bugs from 8 popular open-source and representative Android apps to investigate the root causes bug symptoms test oracles and the capabilities and limitations of existing testing techniques. This study took us substantial effort. It reveals several new interesting findings and implications which help shed light on future research on tackling functional bugs. Furthermore findings from our study guided the design of a proof-of-concept differential testing tool RegDroid to automatically find functional bugs in Android apps. We applied RegDroid on 5 real-world popular apps and successfully discovered 14 functional bugs 10 of which were previously unknown and affected the latest released versionsâ€”all these 10 bugs have been confirmed and fixed by the app developers. Specifically 10 out of these 14 found bugs cannot be found by existing testing techniques. We have made all the artifacts (including the dataset of 399 functional bugs and RegDroid) in our work publicly available at https://github.com/Android-Functional-bugs-study/home.;
Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing;A good test suite is one that detects real faults. Because the set of faults in a program is usually unknowable this definition is not useful to practitioners who are creating test suites nor to researchers who are creating and evaluating tools that generate test suites. In place of real faults testing research often uses mutants which are artificial faults -- each one a simple syntactic variation -- that are systematically seeded throughout the program under test. Mutation analysis is appealing because large numbers of mutants can be automatically-generated and used to compensate for low quantities or the absence of known real faults. Unfortunately there is little experimental evidence to support the use of mutants as a replacement for real faults. This paper investigates whether mutants are indeed a valid substitute for real faults i.e. whether a test suiteâ€™s ability to detect mutants is correlated with its ability to detect real faults that developers have fixed. Unlike prior studies these investigations also explicitly consider the conflating effects of code coverage on the mutant detection rate. Our experiments used 357 real faults in 5 open-source applications that comprise a total of 321000 lines of code. Furthermore our experiments used both developer-written and automatically-generated test suites. The results show a statistically significant correlation between mutant detection and real fault detection independently of code coverage. The results also give concrete suggestions on how to improve mutation analysis and reveal some inherent limitations.;
Proceedings of the XXXI Brazilian Symposium on Software Engineering;Static analysis is an important tool for detecting bugs in real-world software. The advent of numerous analysis algorithms with their own tradeoffs has led to the proliferation of configurable static analysis tools but their complex undertested configuration spaces are obstacles to their widespread adoption. To improve the reliability of these tools my research focuses on developing new approaches to automatically test and debug them. First I describe an empirical study that helps to understand the performance and behavior of configurable taint analysis tools for Android. The findings of this study motivate the development of ECSTATIC a framework for testing and debugging that goes beyond taint analysis to test any configurable static analysis tool. The next steps for this research involve the automatic creation of real-world benchmarks for static analysis with associated ground truths and analysis features.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering;Machine translation systems have penetrated our daily lives providing translation services from source language to target language to millions of users online daily. Word Sense Disambiguation (WSD) is one of the essential functional requirements of machine translation systems which aims to determine the exact sense of polysemes in the given context. Commercial machine translation systems (e.g. Google Translate) have been shown to fail in identifying the proper sense and consequently cause translation errors. However to our knowledge no prior studies focus on testing such WSD bugs for machine translation systems. To tackle this challenge we propose a novel testing method Back Deduction based Testing for Word Sense Disambiguation (BDTD). Our methodâ€™s main idea is to obtain the hidden senses of source words via back deduction from the target language i.e. employ translation words in the target language to deduce senses of original words identified in the translation procedure. To evaluate BDTD we conduct an extensive empirical study with millions of sentences under three popular translators including Google Translate and Bing Microsoft Translator. The experimental results indicate that BDTD can identify a considerable number of WSD bugs with high accuracy more than 80% under all three translators.;
Proceedings of the 19th International Conference on Predictive Models and Data Analytics in Software Engineering;Interrupt-driven embedded software is widely used in aerospace automotive electronics medical equipment IoT and other industrial fields. This type of software is usually programmed with interrupts to interact with hardware and respond to external stimuli on time. However uncertain interleaving execution of interrupts may cause concurrency bugs resulting in task failure or serious safety issues. A deep understanding of real-world concurrency bugs in embedded software will significantly improve the ability of techniques in combating concurrency bugs such as bug detection testing and fixing.This paper performs the first comprehensive and large-scale empirical study on concurrency bugs in industrial interrupt-driven embedded software. A total number of 132 real-world concurrency bugs in 102 industrial embedded software have been rigorously analyzed. Not only have the root causes impacts and fix strategies of bugs been studied but also the manifestation including triggering scopes racing variables access interleaving patterns and variables correlations. This study reveals several significant findings which can guide future research in developing techniques and tools to combat concurrency bugs for interrupt-driven embedded software.;
Proceedings of the 5th International Conference on Computer Science and Software Engineering;Background and Context: Struggling with programming assignments while learning to program is a common phenomenon in programming courses around the world. Supporting struggling students is a common theme in Computing Education Research (CER) where a wide variety of support methods have been created and evaluated. An important stream of research here focuses on program repair where methods for automatically fixing erroneous code are used for supporting students as they debug their code. Work in this area has so far assessed the performance of the methods by evaluating the closeness of the proposed fixes to the original erroneous code. The evaluations have mainly relied on the use of edit distance measures such as the sequence edit distance and there is a lack of research on which distance measure is the most appropriate. Objectives: Provide insight into measures for quantifying the distance between erroneous code written by a student and a proposed change. We conduct the evaluation in an introductory programming context where insight into the distance measures can provide help in choosing a suitable metric that can inform which fixes should be suggested to novices. Method: A team of five experts annotated a subset of the Dublin dataset creating solutions for over a thousand erroneous programs written by students. We evaluated how the prominent edit distance measures from the CER literature compare against measures used in Natural Language Processing (NLP) tasks for retrieving the expertsâ€™ solutions from a pool of proposed solutions. We also evaluated how the expert-generated solutions compare against the solutions proposed by common program repair algorithms. The annotated dataset and the evaluation code are published as part of the work. Findings: Our results highlight that the ROUGE score classically used for evaluating the performance of machine summarization tasks performs well as an evaluation and selection metric for program repair. We also highlight the practical utility of NLP metrics which allow an easier interpretation and comparison of the performance of repair techniques when compared to the classic methods used in the CER literature. Implications: Our study highlights the variety of distance metrics used for comparing source codes. We find issues with the classically used distance measures that can be combated by using NLP metrics. Based on our findings we recommend including NLP metrics and in particular the ROUGE metric in evaluations when considering new program repair methodologies. We also suggest incorporating NLP metrics into other areas where source codes are compared including plagiarism detection.;
Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1;Dynamic regression test selection (RTS) techniques aim to minimize testing efforts by selecting tests using per-test execution traces. However most existing RTS techniques are not applicable to microservice-based or more generally distributed systems as the dynamic program analysis is typically limited to a single system. In this paper we describe our distributed RTS approach microRTS which targets automated and manual end-to-end testing in microservice-based software systems. We employ microRTS in a case study on a set of 20 manual end-to-end test cases across 12 versions of the German COVID-19 contact tracing application a modern microservice-based software system. The results indicate that initially microRTS selects all manual test cases for each version. Yet through semi-automated filtering of test traces we are able to effectively reduce the testing effort by 10--50%. In contrast with prior results on automated unit tests we find method-level granularity of per-test execution traces to be more suitable than class-level for manual end-to-end testing.;
Proceedings of the 39th International Conference on Software Engineering Companion;This paper is a report on The 8th IEEE/ACM International Workshop on Automation of Software Test (AST 2013) at the 35th InternaÂ¬tional Conference on Software Engineering (ICSE 2013). It sets a special theme on testing-as-a-service (TaaS). Keynote speech and charette discussions are organized around this special theme. Eighteen full research papers and six short papers will be presented in the two-day workshop. The report will give the background of the workshop and the selection of the special theme and report on the organization of the workshop. The provisional program will be presented with a list of the sessions and papers to be presented at the workshop.;
Proceedings of the 2013 International Conference on Software Engineering;Type systems are responsible for assigning types to terms in programs. That way they enforce the actions that can be taken and can consequently detect type errors during compilation. However while they are able to flag the existence of an error they often fail to pinpoint its cause or provide a helpful error message. Thus without adequate support debugging this kind of errors can take a considerable amount of effort. Recently neural network models have been developed that are able to understand programming languages and perform several downstream tasks. We argue that type error debugging can be enhanced by taking advantage of this deeper understanding of the languageâ€™s structure. In this paper we present a technique that leverages GPT-3â€™s capabilities to automatically fix type errors in OCaml programs. We perform multiple source code analysis tasks to produce useful prompts that are then provided to GPT-3 to generate potential patches. Our publicly available tool Mentat supports multiple modes and was validated on an existing public dataset with thousands of OCaml programs. We automatically validate successful repairs by using Quickcheck to verify which generated patches produce the same output as the user-intended fixed version achieving a 39% repair rate. In a comparative study Mentat outperformed two other techniques in automatically fixing ill-typed OCaml programs.;
Proceedings of the 16th ACM SIGPLAN International Conference on Software Language Engineering;Graph database systems (GDBs) allow efficiently storing and retrieving graph data and have become the critical component in many applications e.g. knowledge graphs social networks and fraud detection. It is important to ensure that GDBs operate correctly. Logic bugs can occur and make GDBs return an incorrect result for a given query. These bugs are critical and can easily go unnoticed by developers when the graph and queries become complicated. Despite the importance of GDBs logic bugs in GDBs have received less attention than those in relational database systems. In this paper we present Grand an approach for automatically finding logic bugs in GDBs that adopt Gremlin as their query language. The core idea of Grand is to construct semantically equivalent databases for multiple GDBs and then compare the results of a Gremlin query on these databases. If the return results of a query on multiple GDBs are different the likely cause is a logic bug in these GDBs. To effectively test GDBs we propose a model-based query generation approach to generate valid Gremlin queries that can potentially return non-empty results and a data mapping approach to unify the format of query results for different GDBs. We evaluate Grand on six widely-used GDBs e.g. Neo4j and HugeGraph. In total we have found 21 previously-unknown logic bugs in these GDBs. Among them developers have confirmed 18 bugs and fixed 7 bugs.;
Proceedings of the 1st ACM Symposium on Cloud Computing;Many spectrum-based fault localization techniques have been proposed to measure how likely each program element is the root cause of a program failure. For various bugs the best technique to localize the bugs may differ due to the characteristics of the buggy programs and their program spectra. In this paper we leverage the diversity of existing spectrum-based fault localization techniques to better localize bugs using data fusion methods. Our proposed approach consists of three steps: score normalization technique selection and data fusion. We investigate two score normalization methods two technique selection methods and five data fusion methods resulting in twenty variants of Fusion Localizer. Our approach is bug specific in which the set of techniques to be fused are adaptively selected for each buggy program based on its spectra. Also it requires no training data i.e. execution traces of the past buggy programs.We evaluate our approach on a common benchmark dataset and a dataset consisting of real bugs from three medium to large programs. Our evaluation demonstrates that our approach can significantly improve the effectiveness of existing state-of-the-art fault localization techniques. Compared to these state-of-the-art techniques the best variants of Fusion Localizer can statistically significantly reduce the amount of code to be inspected to find all bugs. Our best variants can increase the proportion of bugs localized when developers only inspect the top 10% most suspicious program elements by more than 10% and increase the number of bugs that can be successfully localized when developers only inspect up to 10 program blocks by more than 20%.;
Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering;This paper reports on our experience implementing a technique for sifting through static analysis reports using dynamic symbolic execution. Our insight is that if a static analysis tool produces a partial trace through the program under analysis annotated with conditions that the analyser believes are important for the bug to trigger then a dynamic symbolic execution tool may be able to exploit the trace by (a) guiding the search heuristically so that paths that follow the trace most closely are prioritised for exploration and (b) pruning the search using the conditions associated with each step of the trace. This may allow the bug to be quickly confirmed using dynamic symbolic execution if it turns out to be a true positive yielding an input that triggers the bug.  To experiment with this approach we have implemented the idea in a tool chain that allows the popular open-source static analysis tools Clang Static Analyzer (CSA) and Infer to be combined with the popular open-source dynamic symbolic execution engine KLEE. Our findings highlight two interesting negative results. First while fault injection experiments show the promise of our technique they also reveal that the traces provided by static analysis tools are not that useful in guiding search. Second we have systematically applied CSA and Infer to a large corpus of real-world applications that are suitable for analysis with KLEE and find that the static analysers are rarely able to find non-trivial true positive bugs for this set of applications.  We believe our case study can inform static analysis and dynamic symbolic execution tool developers as to where improvements may be necessary and serve as a call to arms for researchers interested in combining symbolic execution and static analysis to identify more suitable benchmark suites for evaluation of research ideas.;
Proceedings of the 2nd Brazilian Symposium on Systematic and Automated Software Testing;Test-based generate-and-validate automated program repair (APR) systems often generate many patches that pass the test suite without fixing the bug.  The generated patches must be manually inspected by the developers so previous research proposed various techniques for automatic correctness assessment of APR-generated patches.  Among them dynamic patch correctness assessment techniques rely on the assumption that when running the originally passing test cases the correct patches will not alter the program behavior in a significant way e.g. removing the code implementing correct functionality of the program.  In this paper we propose and evaluate a novel technique named Shibboleth for automatic correctness assessment of the patches generated by test-based generate-and-validate APR systems.  Unlike existing works the impact of the patches is captured along three complementary facets allowing more effective patch correctness assessment.  Specifically we measure the impact of patches on both production code (via syntactic and semantic similarity) and test code (via code coverage of passing tests) to separate the patches that result in similar programs and that do not delete desired program elements.  Shibboleth assesses the correctness of patches via both ranking and classification.  We evaluated Shibboleth on 1871 patches generated by 29 Java-based APR systems for Defects4J programs. The technique outperforms state-of-the-art ranking and classification techniques.  Specifically in our ranking data set in 43% (66%) of the cases Shibboleth ranks the correct patch in top-1 (top-2) positions and in classification mode applied on our classification data set it achieves an accuracy and F1-score of 0.887 and 0.852 respectively.;
Proceedings of the Eighteenth International Symposium on Software Testing and Analysis;Bug localization is well-known to be a difficult problem in software engineering and specifically in compiler development where it is beneficial to reduce the input program to a minimal reproducing example this technique is more commonly known as delta debugging. What additionally contributes to the problem is that every new programming language has its own unique quirks and foibles making it near impossible to reuse existing tools and approaches with full efficiency. In this experience paper we tackle the delta debugging problem w.r.t. Kotlin a relatively new programming language from JetBrains. Our approach is based on a novel combination of program slicing hierarchical delta debugging and Kotlin-specific transformations which are synergistic to each other. We implemented it in a prototype called ReduKtor and did extensive evaluation on both synthetic and real Kotlin programs we also compared its performance with classic delta debugging techniques. The evaluation results support the practical usability of our approach to Kotlin delta debugging and also shows the importance of using both language-agnostic and language-specific techniques to achieve best reduction efficiency and performance.;
Proceedings of the 18th Asian Internet Engineering Conference;Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs. This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex CodeGen CodeT5 PLBART and InCoder) four fine-tuned LLMs and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench) (2) design code transformations to address the training and test data overlapping threat to Codex (3) create a new Java vulnerability repair benchmark VJBench and its transformed version VJBench-trans to better evaluate LLMs and APR techniques and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities in VJBench-trans. Our findings include that (1) existing LLMs and APR models fix very few Java vulnerabilities. Codex fixes 10.2 (20.4%) the most number of vulnerabilities. Many of the generated patches are uncompilable patches. (2) Fine-tuning with general APR data improves LLMsâ€™ vulnerability-fixing capabilities. (3) Our new VJBench reveals that LLMs and APR models fail to fix many Common Weakness Enumeration (CWE) types such as CWE-325 Missing cryptographic step and CWE-444 HTTP request smuggling. (4) Codex still fixes 8.7 transformed vulnerabilities outperforming all the other LLMs and APR models on transformed vulnerabilities. The results call for innovations to enhance automated Java vulnerability repair such as creating larger vulnerability repair training data tuning LLMs with such data and applying code simplification transformation to facilitate vulnerability repair.;
Proceedings of the 2011 ACM Symposium on Research in Applied Computation;Testing is a promising way to gain trust in a learned action policy Ï€ in particular if Ï€ is a neural network. A â€œbugâ€ in this context constitutes undesirable or fatal policy behavior e.g. satisfying a failure condition. But how do we distinguish whether such behavior is due to bad policy decisions or whether it is actually unavoidable under the given circumstances? This requires knowledge about optimal solutions which defeats the scalability of testing. Related problems occur in software testing when the correct program output is not known. Metamorphic testing addresses this issue through metamorphic relations specifying how a given change to the input should affect the output thus providing an oracle for the correct output. Yet how do we obtain such metamorphic relations for action policies? Here we show that the well explored concept of relaxations in the Artificial Intelligence community can serve this purpose. In particular if state sâ€² is a relaxation of state s i.e. sâ€² is easier to solve than s and Ï€ fails on easier sâ€² but does not fail on harder s then we know that Ï€ contains a bug manifested on sâ€². We contribute the first exploration of this idea in the context of failure testing of neural network policies Ï€ learned by reinforcement learning in simulated environments. We design fuzzing strategies for test-case generation as well as metamorphic oracles leveraging simple manually designed relaxations. In experiments on three single-agent games our technology is able to effectively identify true bugs i.e. avoidable failures of Ï€ which has not been possible until now.;
Proceedings of the Nineteenth Australasian Computing Education Conference;Software defect prediction research has adopted various evaluation measures to assess the performance of prediction models. In this paper we further stress on the importance of the choice of appropriate measures in order to correctly assess strengths and weaknesses of a given defect prediction model especially given that most of the defect prediction tasks suffer from data imbalance.  Investigating 111 previous studies published between 2010 and 2020 we found out that over a half either use only one evaluation measure which alone cannot express all the characteristics of model performance in presence of imbalanced data or a set of binary measures which are prone to be biased when used to assess models especially when trained with imbalanced data. We also unveil the magnitude of the impact of assessing popular defect prediction models with several evaluation measures based for the first time on both statistical significance test and effect size analyses.  Our results reveal that the evaluation measures produce a different ranking of the classification models in 82% and 85% of the cases studied according to the Wilcoxon statistical significance test and \^{A;
Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security;Test-based automated program repair has been a prolific field of research in software engineering in the last decade. Many approaches have indeed been proposed which leverage test suites as a weak but affordable approximation to program specifications. Although the literature regularly sets new records on the number of benchmark bugs that can be fixed several studies increasingly raise concerns about the limitations and biases of state-of-the-art approaches. For example the correctness of generated patches has been questioned in a number of studies while other researchers pointed out that evaluation schemes may be misleading with respect to the processing of fault localization results. Nevertheless there is little work addressing the efficiency of patch generation with regard to the practicality of program repair. In this paper we fill this gap in the literature by providing an extensive review on the efficiency of test suite based program repair. Our objective is to assess the number of generated patch candidates since this information is correlated to (1) the strategy to traverse the search space efficiently in order to select sensical repair attempts (2) the strategy to minimize the test effort for identifying a plausible patch (3) as well as the strategy to prioritize the generation of a correct patch. To that end we perform a large-scale empirical study on the efficiency in terms of quantity of generated patch candidates of the 16 open-source repair tools for Java programs. The experiments are carefully conducted under the same fault localization configurations to limit biases. Eventually among other findings we note that: (1) many irrelevant patch candidates are generated by changing wrong code locations (2) however if the search space is carefully triaged fault localization noise has little impact on patch generation efficiency (3) yet current template-based repair systems which are known to be most effective in fixing a large number of bugs are actually least efficient as they tend to generate majoritarily irrelevant patch candidates.;
Proceedings of the 15th Workshop on Search-Based Software Testing;Microservice-based applications consist of multiple services that can evolve independently. When services are modified they are typically tested before being deployed. However the test suites that are executed are usually designed without the exact knowledge about how the services will be accessed and used in the field therefore they may easily miss relevant test scenarios failing to prevent the deployment of faulty services.To address this problem we introduce ExVivoMicroTest an approach that analyzes the execution of deployed services at runtime in the field in order to generate test cases for future versions of the same services. ExVivoMicroTest exploits cloud technologies containers in particular to generate a mocked environment that fully isolates the service under test from the rest of the system. It then reproduces service interactions as previously analyzed thus testing the new version of the service against usage scenarios that capture the field usages of its earlier versions.We evaluate our approach on an open sourced microservices application and show that ExVivoMicroTest can effectively reveal faults based on automatically collected data.;
Proceedings of the IEEE/ACM 1st International Conference on Automation of Software Test;Software testing is sometimes plagued with intermittently failing tests and finding the root causes of such failing tests is often difficult. This problem has been widely studied at the unit testing level for open source software but there has been far less investigation at the system test level particularly the testing of industrial embedded systems. This paper describes our investigation of the root causes of intermittently failing tests in the embedded systems domain with the goal of better understanding explaining and categorizing the underlying faults. The subject of our investigation is a currently-running industrial embedded system along with the system level testing that was performed. We devised and used a novel metric for classifying test cases as intermittent. From more than a half million test verdicts we identified intermittently and consistently failing tests and identified their root causes using multiple sources. We found that about 1-3% of all test cases were intermittently failing. From analysis of the case study results and related work we identified nine factors associated with test case intermittence. We found that a fix for a consistently failing test typically removed a larger number of failures detected by other tests than a fix for an intermittent test. We also found that more effort was usually needed to identify fixes for intermittent tests than for consistent tests. An overlap between root causes leading to intermittent and consistent tests was identified. Many root causes of intermittence are the same in industrial embedded systems and open source software. However when comparing unit testing to system level testing especially for embedded systems we observed that the test environment itself is often the cause of intermittence.;
Proceedings of the 13th International Conference on Mining Software Repositories;Automated generate-and-validate (GV) program repair techniques (APR) typically rely on hard-coded rules thus only fixing bugs following specific fix patterns. These rules require a significant amount of manual effort to discover and it is hard to adapt these rules to different programming languages. To address these challenges we propose a new G&ampV techniqueâ€”CoCoNuT which uses ensemble learning on the combination of convolutional neural networks (CNNs) and a new context-aware neural machine translation (NMT) architecture to automatically fix bugs in multiple programming languages. To better represent the context of a bug we introduce a new context-aware NMT architecture that represents the buggy source code and its surrounding context separately. CoCoNuT uses CNNs instead of recurrent neural networks (RNNs) since CNN layers can be stacked to extract hierarchical features and better model source code at different granularity levels (e.g. statements and functions). In addition CoCoNuT takes advantage of the randomness in hyperparameter tuning to build multiple models that fix different bugs and combines these models using ensemble learning to fix more bugs. Our evaluation on six popular benchmarks for four programming languages (Java C Python and JavaScript) shows that CoCoNuT correctly fixes (i.e. the first generated patch is semantically equivalent to the developerâ€™s patch) 509 bugs including 309 bugs that are fixed by none of the 27 techniques with which we compare.;
Proceedings of the Sixth Conference on Computer Systems;Container isolation is implemented through OS-level virtualization such as Linux namespaces. Unfortunately these mechanisms are extremely challenging to implement correctly and in practice suffer from functional interference bugs which compromise container security. In particular functional interference bugs allow an attacker to extract information from another container running on the same machine or impact its integrity by modifying kernel resources that are incorrectly isolated. Despite their impact functional interference bugs in OS-level virtualization have received limited attention in part due to the challenges in detecting them. Instead of causing memory errors or crashes many functional interference bugs involve hard-to-catch logic errors that silently produce semantically incorrect results.  This paper proposes KIT a dynamic testing framework that discovers functional interference bugs in OS-level virtualization mechanisms such as Linux namespaces. The key idea of KIT is to detect inter-container functional interference by comparing the system call traces of a container across two executions where it runs with and without the preceding execution of another container. To achieve high efficiency and accuracy KIT includes two critical components: an efficient algorithm to generate test cases that exercise inter-container data flows and a system call trace analysis framework that detects functional interference bugs and clusters bug reports. KIT discovered 9 functional interference bugs in Linux kernel 5.13 of which 6 have been confirmed. All bugs are caused by logic errors showing that this approach is able to detect hard-to-catch semantic bugs.;
Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems Volume 2;Over the past decade there has been a growing interest in applying machine learning (ML) to address a myriad of tasks. Owing to this interest the adoption of ML-based systems has gone mainstream. However this widespread adoption of ML-based systems poses new challenges for software testers that must improve the quality and reliability of these ML-based solutions. To cope with the challenges of testing ML-based systems we propose novel test adequacy criteria based on decision tree models. Differently from the traditional approach to testing ML models which relies on manual collection and labelling of data our criteria leverage the internal structure of decision tree models to guide the selection of test inputs. Thus we introduce decision tree coverage (DTC) and boundary value analysis (BVA) as approaches to systematically guide the creation of effective test data that exercises key structural elements of a given decision tree model. To evaluate these criteria we carried out an experiment using 12 datasets. We measured the effectiveness of test inputs in terms of the difference in modelâ€™s behavior between the test input and the training data. The experiment results indicate that our testing criteria can be used to guide the generation of effective test data.;
Proceedings of the 6th Brazilian Symposium on Systematic and Automated Software Testing;Quality assurance (QA) tools are receiving more and more attention and are widely used by developers. Given the wide range of solutions for QA technology it is still a question of evaluating QA tools. Most existing research is limited in the following ways: (i) They compare tools without considering scanning rules analysis. (ii) They disagree on the effectiveness of tools due to the study methodology and benchmark dataset. (iii) They do not separately analyze the role of the warnings. (iv) There is no large-scale study on the analysis of time performance. To address these problems in the paper we systematically select 6 free or open-source tools for a comprehensive study from a list of 148 existing Java QA tools. To carry out a comprehensive study and evaluate tools in multi-level dimensions we first mapped the scanning rules to the CWE and analyze the coverage and granularity of the scanning rules. Then we conducted an experiment on 5 benchmarks including 1425 bugs to investigate the effectiveness of these tools. Furthermore we took substantial effort to investigate the effectiveness of warnings by comparing the real labeled bugs with the warnings and investigating their role in bug detection. Finally we assessed these toolsâ€™ time performance on 1049 projects. The useful findings based on our comprehensive study can help developers improve their tools and provide users with suggestions for selecting QA tools.;
Proceedings of the 2023 9th International Conference on Computer Technology Applications;Recently neural networks have spread into numerous fields including many safety-critical systems. Neural networks are built (and trained) by programming in frameworks such as TensorFlow and PyTorch. Developers apply a rich set of pre-defined layers to manually program neural networks or to automatically generate them (e.g. through AutoML). Composing neural networks with different layers is error-prone due to the non-trivial constraints that must be satisfied in order to use those layers. In this work we propose an approach to automatically repair erroneous neural networks. The challenge is in identifying a minimal modification to the network so that it becomes valid. Modifying a layer might have cascading effects on subsequent layers and thus our approach must search recursively to identify a ''globally'' minimal modification. Our approach is based on an executable semantics of deep learning layers and focuses on four kinds of errors which are common in practice. We evaluate our approach for two usage scenarios i.e. repairing automatically generated neural networks and manually written ones suffering from common model bugs. The results show that we are able to repair 100% of a set of randomly generated neural networks (which are produced with an existing AI framework testing approach) effectively and efficiently (with an average repair time of 21.08s) and 93.75% of a collection of real neural network bugs (with an average time of 3min 40s).;
Proceedings of the 41st International Conference on Software Engineering;"For ensuring the reliability of Android apps there has been tremendous continuous progress on improving automated GUI testing in the past decade. Specifically dozens of testing techniques and tools have been developed and demonstrated to be effective in detecting crash bugs and outperform their respective prior work in the number of detected crashes. However an overarching question How effectively and thoroughly can these tools find crash bugs in practice?"" has not been well-explored which requires a ground-truth benchmark with real-world bugs. Since prior studies focus on tool comparisons w.r.t. some selected apps they cannot provide direct in-depth answers to this question.  To complement existing work and tackle the above question this paper offers the first ground-truth empirical evaluation of automated GUI testing for Android. To this end we devote substantial manual effort to set up the Themis benchmark set including (1) a carefully constructed dataset with 52 real reproducible crash bugs (taking two person-months for its collection and validation) and (2) a unified extensible infrastructure with six recent state-of-the-art testing tools. The whole evaluation has taken over 10920 CPU hours. We find a considerable gap in these tools finding the collected real bugs --- 18 bugs cannot be detected by any tool. Our systematic analysis further identifies five major common challenges that these tools face and reveals additional findings such as factors affecting these tools in bug finding and opportunities for tool improvements. Overall this work offers new concrete insights most of which are previously unknown/unstated and difficult to obtain. Our study presents a new complementary perspective from prior studies to understand and analyze the effectiveness of existing testing tools as well as a benchmark for future research on this topic. The Themis benchmark is publicly available at https://github.com/the-themis-benchmarks/home.""";
Proceedings of the 17th Asian Internet Engineering Conference;The current implementation of automated mobile apps testing generally relies on internal program information such as reading code or GUI layout files capturing event streams. This paper proposes an approach of automated mobile apps testing from a completely visual perspective. It uses computer vision technology to enable computer to judge the internal functions from the external GUI information of mobile apps as we humans do and generates test strategy for execution which improves the interactivity flexibility and authenticity of testing. We believe that this vision-based testing approach will further help alleviate the contradiction between the current huge test requirements of mobile apps and the relatively lack of testers.;
Proceedings of the 14th International Conference on Predictive Models and Data Analytics in Software Engineering;NOTICE OF RETRACTION: The authors Zhiming Li Xiaofei Xie Haoliang Li Zhengzi Xu Yi Li and Yang Liu  of the paper â€œCross-lingual transfer learning for statistical type inferenceâ€ have requested their paper be Retracted due to errors in the paper. The authors all agree the major conclusions are erroneous:1. (Major) In RQ4 the results of LambadaNet and Typilus baseline methods are erroneous and the PLATO results are implemented without the incorporation of cross-lingual data. And some numbers are recorded erroneously in the table which makes the important conclusion of the paper â€œPlato can significantly outperform the baselineâ€ erroneous.2. (Major) In RQ1 the implementations of the rule-based tools (CheckJS and Pytype) (Page 8) are erroneous and we find it not possible to compare PLATO with the Pytype tool fairly. This renders the conclusion of the paper â€œWith Plato one can achieve comparative or even better performance by using cross-lingual labeled data instead of implementing rule-based tool from scratch that requires significant manual effort and expert knowledge.â€ erroneous.3. Besides for RQ1 we realize that the type set used for the Python &amp TypeScript transfer only uses 6 and 4 meta-types which are somewhat inconsistent with the description on Page 6. The implementation of the ADV baseline for the Java transfer benchmarks and the supervised_o of TypeScript baselines are erroneous. And the ensemble method used for PLATO is inconsistent with the description in the methodology section. And RQ1 has used an outdated checkpoint of ours (different from the one used in other RQs.) The pre-trained model training process and ensemble strategy are implemented in settings somewhat different from the description in the methodology section.4. The visualizations of Figure 6 &amp 8 are somewhat inconsistent with real cases.5. In RQ3 the description of the baseline method (Bert with supervised learning) is wrong (Page 9) (It should be â€œonly trained on partially labeled target language dataâ€). And we find that some tokens are erroneously normalized during preprocessing. And some data pointsâ€™ results are erroneous thus â€œPlato without Kernelâ€ and â€œPLATOâ€ methods would not achieve as high improvements as claimed.6. In RQ2 the ablation of the PLATO model is erroneous and we find that the sequence submodel performs better than the kernel submodel (Table 3).;
Proceedings of the 19th International Conference on Mining Software Repositories;Software development life cycle is profoundly influenced by bugs their introduction identification and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting treating this as an infilling task. However these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper we proposeâ€¯: a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.  combines a Retriever â€“ transformer encoder model pretrained via contrastive learning objective which aims at searching for semantically equivalent bugs and corresponding fixes and a Generator â€“ an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach we curated  a novel metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that  outperforms strong LLM baselines with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of  alongside Infer at Microsoft which offers an end-to-end solution for detection classification and localization of bugs as well as fixing and validation of candidate patches integrated in the continuous integration (CI) pipeline to automate the software development workflow.;
Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security;Due to increasingly complex software design and rapid iterative development code defects and security vulnerabilities are prevalent in modern software. In response programmers rely on static analysis tools to regularly scan their codebases and find potential bugs. In order to maximize coverage however these tools generally tend to report a significant number of false positives requiring developers to manually verify each warning. To address this problem we propose a Transformer-based learning approach to identify false positive bug warnings. We demonstrate that our models can improve the precision of static analysis by 17.5%. In addition we validated the generalizability of this approach across two major bug types: null dereference and resource leak.;
Proceedings of the 36th Annual ACM Symposium on Applied Computing;"Deep learning techniques have shown promising performance in automated software maintenance tasks associated with bug reports. Currently all existing studies learn the customized representation of bug reports for a specific downstream task. Despite early success training multiple models for multiple downstream tasks faces three issues: complexity cost and compatibility due to the customization disparity and uniqueness of these automated approaches. To resolve the above challenges we propose RepresentThemAll a pre-trained approach that can learn the universal representation of bug reports and handle multiple downstream tasks. Specifically RepresentThemAll is a universal bug report framework that is pre-trained with two carefully designed learning objectives: one is the dynamic masked language model and another one is a contrastive learning objective find yourself"". We evaluate the performance of RepresentThemAll on four downstream tasks including duplicate bug report detection bug report summarization bug priority prediction and bug severity prediction. Our experimental results show that RepresentThemAll outperforms all baseline approaches on all considered downstream tasks after well-designed fine-tuning.""";
Proceedings of the Eighteenth European Conference on Computer Systems;Machine learning and its promising branch deep learning have shown success in a wide range of application domains. Recently much effort has been expended on applying deep learning techniques (e.g. graph neural networks) to static vulnerability detection as an alternative to conventional bug detection methods. To obtain the structural information of code current learning approaches typically abstract a program in the form of graphs (e.g. data-flow graphs abstract syntax trees) and then train an underlying classification model based on the (sub)graphs of safe and vulnerable code fragments for vulnerability prediction. However these models are still insufficient for precise bug detection because the objective of these models is to produce classification results rather than comprehending the semantics of vulnerabilities e.g. pinpoint bug triggering paths which are essential for static bug detection. This paper presents ContraFlow a selective yet precise contrastive value-flow embedding approach to statically detect software vulnerabilities. The novelty of ContraFlow lies in selecting and preserving feasible value-flow (aka program dependence) paths through a pretrained path embedding model using self-supervised contrastive learning thus significantly reducing the amount of labeled data required for training expensive downstream models for path-based vulnerability detection. We evaluated ContraFlow using 288 real-world projects by comparing eight recent learning-based approaches. ContraFlow outperforms these eight baselines by up to 334.1% 317.9% 58.3% for informedness markedness and F1 Score and achieves up to 450.0% 192.3% 450.0% improvement for mean statement recall mean statement precision and mean IoU respectively in terms of locating buggy statements.;
Proceedings of the 2014 International Symposium on Software Testing and Analysis;With the prevalence of smartphones people nowadays can access a wide variety of services through diverse apps. A good Graphical User Interface (GUI) can make an app more appealing and competitive in app markets. Icon widgets as an essential part of an appâ€™s GUI leverage icons to visually convey their functionalities to facilitate user interactions. Whereas designing intuitive icon widgets can be a non-trivial job. Developers should follow a series of guidelines and make appropriate choices from a plethora of possibilities. Inappropriately designed or misused icons may cause user confusion lead to wrong operations and even result in security risks (e.g. revenue loss and privacy leakage). To investigate the problem we manually checked 9075 icons of 1111 top-ranked commercial apps from Google Play and found 640 misleading icons in 312 (â€„â€28%) of these apps. This shows that misleading icons are prevalent among real-world apps even the top ones. Manually identifying misleading icons to improve app quality is time-consuming and laborious. In this work we propose the first framework IconSeer to automatically detect misleading icons for mobile apps. Our basic idea is to find the discrepancies between the commonly perceived intentions of an icon and the actual functionality of the corresponding icon widget. IconSeer takes an Android app as input and reports potential misleading icons. It is powered by a comprehensive icon-intention mapping constructed by analyzing 268353 icons collected from 15571 popular Android apps in Google Play. The mapping includes 179 icon classes and 852 intention classes. Given an icon widget under analysis IconSeer first employs a pre-trained open-set deep learning model to infer the possible icon class and the potential intentions. IconSeer then extracts developer-specified text properties of the icon widget which indicate the widgetâ€™s actual functionality. Finally IconSeer determines whether an icon is misleading by comparing the semantic similarity between the inferred intentions and the extracted text properties of the widget. We have evaluated IconSeer on the 1111 Android apps with manually established ground truth. IconSeer successfully identified 1172 inconsistencies (with an accuracy of 0.86) among which we further found 482 real misleading icons.;
Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering;Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries e.g. TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g. Python) syntax/semantics and the DL API input/shape constraints for tensor computations.  To address these limitations we propose TitanFuzz â€“ the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically we use both generative and infilling LLMs (e.g. Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38%/50.84% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore TitanFuzz is able to detect 65 bugs with 44 already confirmed as previously unknown bugs.  This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades while being fully automated generalizable and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.;
Proceedings of the 15th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Unit testing is a critical part of software development process ensuring the correctness of basic programming units in a program (e.g. a method). Search-based software testing (SBST) is an automated approach to generating test cases. SBST generates test cases with genetic algorithms by specifying the coverage criterion (e.g. branch coverage). However a good test suite must have different properties which cannot be captured by using an individual coverage criterion. Therefore the state-of-the-art approach combines multiple criteria to generate test cases. As combining multiple coverage criteria brings multiple objectives for optimization it hurts the test suitesâ€™ coverage for certain criteria compared with using the single criterion. To cope with this problem we propose a novel approach named smart selection. Based on the coverage correlations among criteria and the coverage goalsâ€™ subsumption relationships smart selection selects a subset of coverage goals to reduce the number of optimization objectives and avoid missing any properties of all criteria. We conduct experiments to evaluate smart selection on 400 Java classes with three state-of-the-art genetic algorithms. On average smart selection outperforms combining all goals on of the classes having significant differences between the two approaches.;
Proceedings of the 17th ACM/IEEE Joint Conference on Digital Libraries;Assigning appropriate developers to the bugs is one of the main challenges in bug triage. Demands for automatic bug triage are increasing in the industry as manual bug triage is labor-intensive and time-consuming in large projects. The key to the bug triage task is extracting semantic information from a bug report. In recent years large Pre-trained Language Models (PLMs) including BERT [4] have achieved dramatic progress in the natural language processing (NLP) domain. However applying large PLMs to the bug triage task for extracting semantic information has several challenges. In this paper we address the challenges and propose a novel framework for bug triage named LBT-P standing for Light Bug Triage framework with a Pre-trained language model. It compresses a large PLM into small and fast models using knowledge distillation techniques and also prevents catastrophic forgetting of PLM by introducing knowledge preservation fine-tuning. We also develop a new loss function exploiting representations of earlier layers as well as deeper layers in order to handle the overthinking problem. We demonstrate our proposed framework on the real-world private dataset and three public real-world datasets [11]: Google Chromium Mozilla Core and Mozilla Firefox. The result of the experiments shows the superiority of LBT-P.;
Proceedings of the 9th International Symposium on Information and Communication Technology;Neural networks have had discernible achievements in a wide range of applications. The wide-spread adoption also raises the concern of their dependability and reliability. Similar to traditional decision-making programs neural networks can have defects that need to be repaired. The defects may cause unsafe behaviors raise security concerns or unjust societal impacts. In this work we address the problem of repairing a neural network for desirable properties such as fairness and the absence of backdoor. The goal is to construct a neural network that satisfies the property by (minimally) adjusting the given neural network's parameters (i.e. weights). Specifically we propose CARE (CAusality-based REpair) a causality-based neural network repair technique that 1) performs causality-based fault localization to identify the 'guilty' neurons and 2) optimizes the parameters of the identified neurons to reduce the misbehavior. We have empirically evaluated CARE on various tasks such as backdoor removal neural network repair for fairness and safety properties. Our experiment results show that CARE is able to repair all neural networks efficiently and effectively. For fairness repair tasks CARE successfully improves fairness by 61.91% on average. For backdoor removal tasks CARE reduces the attack success rate from over 98% to less than 1%. For safety property repair tasks CARE reduces the property violation rate to less than 1%. Results also show that thanks to the causality-based fault localization CARE's repair focuses on the misbehavior and preserves the accuracy of the neural networks.;
Proceedings of the 38th International Conference on Software Engineering Companion;Machine learning (ML) systems have achieved remarkable performance across a wide area of applications. However they frequently exhibit unfair behaviors in sensitive application domains (e.g. employment and loan) raising severe fairness concerns. To evaluate and test fairness engineers often generate individual discriminatory instances to expose unfair behaviors before model deployment. However existing baselines ignore the naturalness of generation and produce instances that deviate from the real data distribution which may fail to reveal the actual model fairness since these unnatural discriminatory instances are unlikely to appear in practice. To address the problem this paper proposes a framework named Latent Imitator (LIMI) to generate more natural individual discriminatory instances with the help of a generative adversarial network (GAN) where we imitate the decision boundary of the target model in the semantic latent space of GAN and further samples latent instances on it. Specifically we first derive a surrogate linear boundary to coarsely approximate the decision boundary of the target model which reflects the nature of the original data distribution. Subsequently to obtain more natural instances we manipulate random latent vectors to the surrogate boundary with a one-step movement and further conduct vector calculation to probe two potential discriminatory candidates that may be more closely located in the real decision boundary. Extensive experiments on various datasets demonstrate that our LIMI outperforms other baselines largely in effectiveness (\texttimes{;
Proceedings of the 16th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement;We propose the use of crowdsourcing and human computation to help solve difficult problems in verification and debugging that can benefit from human insight. As a specific scenario we explain how non-expert humans can assist in the verification process by finding patterns in portions of simulation or execution traces which are represented as images. Such patterns can be used in a variety of ways including assertion-based verification improving coverage bug localization and error explanation. Several related issues are discussed including privacy and incentive mechanisms.;
Proceedings of the 49th Annual Design Automation Conference;We study fault localization techniques for identification of incompatible configurations and implementations in service-based applications (SBAs). Practice has shown that standardized interfaces alone do not guarantee compatibility of services originating from different partners. Hence dynamic runtime instantiations of such SBAs pose a great challenge to reliability and dependability. The aim of this work is to monitor and analyze successful and faulty executions in SBAs in order to detect incompatible configurations at runtime. We propose an approach using pooled decision trees for localization of faulty service parameter and binding configurations explicitly addressing transient and changing fault conditions. The presented fault localization technique works on a per-request basis and is able to take individual service inputs into account. Considering not only the service configuration but also the service input data as parameters for the fault localization algorithm increases the computational complexity by an order of magnitude. Hence our performance evaluation is targeted at large-scale SBAs and illustrates the feasibility and decent scalability of the approach.;
Proceedings of the 28th Annual ACM Symposium on Applied Computing;Deep Learning (DL) models to analyze source code have shown immense promise during the past few years.  More recently self-supervised pre-training has gained traction for learning generic code representations valuable for many downstream SE tasks such as clone and bug detection.  While previous work successfully learned from different code abstractions (e.g. token AST graph) we argue that it is also essential to factor in how developers code day-to-day for learning general-purpose representation. On the one hand human developers tend to write repetitive programs referencing existing code snippets from the current codebase or online resources (e.g. Stack Overflow website) rather than implementing functions from scratch such behaviors result in a vast number of code clones. In contrast a deviant clone by mistake might trigger malicious program behaviors.  Thus as a proxy to incorporate developers' coding behavior into the pre-training scheme we propose to include code clones and their deviants. In particular we propose CONCORD a self-supervised pre-training strategy to place benign clones closer in the representation space while moving deviants further apart. We show that CONCORD's clone-aware pre-training drastically reduces the need for expensive pre-training resources while improving the performance of downstream SE tasks. We also empirically demonstrate that CONCORD can improve existing pre-trained models to learn better representations that consequently become more efficient in both identifying semantically equivalent programs and differentiating buggy from non-buggy code.;
Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing Companion;Modern Java software development extensively depends on existing libraries written by other developer teams from the same or a different organization. When a developer executes the test the execution trace may go across the boundaries of multiple dependencies and create cross-project failures (CPFs). A readable executable and concise CPF report may enable the most effective communication but creating such a report is often challenging in Java ecosystems. We developed PExReport-Maven to automatically create the ideal CPF reports in the Maven build system. PExReport-Maven leverages the Maven build system to prune source code dependencies and the build environment to create a concise stand-alone executable CPF reproduction package from the original CPF project. The reproduction package includes the source code dependencies and build environment necessary to reproduce the CPF making it an ideal CPF report. We performed an evaluation on 74 software project issues with 198 cross-project failures and the evaluation results show that PExReport can create pruned reproduction packages for 184 out of the 198 test failures in our dataset with an average reduction of 72.97% in Java classes. A future study will be conducted based on user feedback from using this tool to report real-world CPFs. PExReport-Maven is publicly available at https://github.com/wereHuang/PExReport-Maven. The tool demo is available on the PExReport website: https://sites.google.com/view/pexreport/home.;
Proceedings of the 2022 11th International Conference on Software and Computer Applications;Thanks to the recent breakthroughs in deep learning (DL) methods and ever-increasing computation power nowadays DL models are being increasingly applied to all kinds of fields. They along with other software modules compose complex DL systems such as autonomous driving systems. Unfortunately fatalities happen to these systems as is reported in real-life situations e.g. traffic accidents involving autonomous driving vehicles. Further analyses show that this is because DL systems contain defects. To this end understanding defects in DL systems is critical for preventing such accidents. To help improve the reliability of DL systems many researchers have devoted efforts to their testing. In this paper we investigated state-of-the-art methods through in-depth exploration. Firstly we made a detailed analysis of deep learning system defects. We proposed a defect classification scheme and summarized the characteristics of defects and their impacts on the system. Secondly we systematically investigated the detection methods and tools and evaluated their capability in defect detection.;
Proceedings of the 2nd International Conference on Software Engineering and Information Management;We present PyTER an automated program repair (APR) technique for Python type errors. Python developers struggle with type error exceptions that are prevalent and difficult to fix. Despite the importance however automatically repairing type errors in dynamically typed languages such as Python has received little attention in the APR community and no existing techniques are readily available for practical use. PyTER is the first technique that is carefully designed to fix diverse type errors in real-world Python applications. To this end we present a novel APR approach that uses dynamic and static analyses to infer correct and incorrect types of program variables and leverage their difference to effectively identify faulty locations and patch candidates. We evaluated PyTER on 93 type errors collected from open-source projects. The result shows that PyTER is able to fix 48.4% of them with a precision of 77.6%.;
Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering;Modern software applications rely heavily on the usage of libraries which provide reusable functionality to accelerate the development process. As libraries evolve and release new versions the software systems that depend on those libraries (the clients) should update their dependencies to use these new versions as the new release could for example include critical fixes for security vulnerabilities. However updating is not always a smooth process as it can result in software failures in the clients if the new version includes breaking changes. Yet there is little research on how these breaking changes impact the client projects in the wild. To identify if changes between two library versions cause breaking changes at the client end we perform an empirical study on Java projects built using Maven. For the analysis we used 18415 Maven artifacts which declared 142355 direct dependencies of which 71.60% were not up-to-date. We updated these dependencies and found that 11.58% of the dependency updates contain breaking changes that impact the client. We further analyzed these changes in the library which impact the client projects and examine if libraries have adhered to the semantic versioning scheme when introducing breaking changes in their releases. Our results show that changes in transitive dependencies were a major factor in introducing breaking changes during dependency updates and almost half of the detected client impacting breaking changes violate the semantic versioning scheme by introducing breaking changes in non-Major updates.;
Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence;Embracing software-driven smart contracts to fulfill legal agreements is a promising direction for digital transformation in the legal sector. Existing solutions mostly consider smart contracts as simple add-ons without leveraging the programmability of smart contracts to realize complex semantics of legal agreements. In this paper we propose iSyn the first end-to-end system that synthesizes smart contracts to fulfill the semantics of financial legal agreements with minimal human interventions. The design of iSyn centers around a novel intermediate representation (SmartIR) that closes the gap between the natural language sentences and smart contract statements. Specifically iSyn includes a synergistic pipeline that unifies multiple NLP-techniques to accurately construct SmartIR instances given legal agreements and performs template-based synthesis based on the SmartIR instances to synthesize smart contracts. We also design a validation framework to verify the correctness and detect known vulnerabilities of the synthesized smart contracts.We evaluate iSyn using legal agreements centering around financial transactions. The results show that iSyn-synthesized smart contracts are syntactically similar and semantically correct (or within a few edits) compared with the â€œground truthâ€ smart contracts manually developed by inspecting the legal agreements.;
Proceedings of the 4th International Conference on Information Management &amp Machine Intelligence;Inspired by the great success of using code coverage as guidance in software testing a lot of neural network coverage criteria have been proposed to guide testing of neural network models (e.g. model accuracy under adversarial attacks). However while the monotonic relation between code coverage and software quality has been supported by many seminal studies in software engineering it remains largely unclear whether similar monotonicity exists between neural network model coverage and model quality. This paper sets out to answer this question. Specifically this paper studies the correlation between DNN model quality and coverage criteria effects of coverage guided adversarial example generation compared with gradient decent based methods effectiveness of coverage based retraining compared with existing adversarial training and the internal relationships among coverage criteria.;
Proceedings of the 5th European Conference on Computer Systems;DDLDroid is a static analyzer for detecting data loss issues in Android apps during activity restart or app relaunch. It is bootstrapped by a saving-restoring bipartite graph which correlates variables that need saving to those that need restoring according to their carrier widgets and is based on the analysis of saving and restoring data flows. It reports data loss issues once missed or broken data flows are identified. DDLDroid detects 302 true data loss issues out of 66 Android apps in 73 minutes including 180 previously-unknown issues demonstrating its effectiveness and efficiency.;
Proceedings of the 13th International Workshop on Automating Test Case Design Selection and Evaluation;Daily horror stories related to software vulnerabilities necessitates the understanding of how vulnerabilities are discovered. Identification of data sources that can be leveraged to understand how vulnerabilities are discovered could aid cybersecurity researchers to characterize exploitation of vulnerabilities. The goal of the paper is to help cybersecurity researchers in characterizing vulnerabilities by conducting an empirical study of software bug reports. We apply qualitative analysis on 729 908 and 5336 open source software (OSS) bug reports respectively collected from Gentoo LibreOffice and Mozilla to investigate if bug reports include vulnerability discovery strategies i.e. sequences of computation and/or cognitive activities that an attacker performs to discover vulnerabilities where the vulnerability is indexed by a credible source such as the National Vulnerability Database (NVD). We evaluate two approaches namely text feature-based approach and regular expression-based approach to automatically identify bug reports that include vulnerability discovery strategies.We observe the Gentoo LibreOffice and Mozilla bug reports to include vulnerability discovery strategies. Using text feature-based prediction models we observe the highest prediction performance for the Mozilla dataset with a recall of 0.78. Using the regular expression-based approach we observe recall to be 0.83 for the same dataset. Findings from our paper provide the groundwork for cybersecurity researchers to use OSS bug reports as a data source for advancing the science of vulnerabilities.;
Proceedings of the 7th Symposium on Hot Topics in the Science of Security;The deep feedforward neural networks (DNNs) are increasingly deployed in socioeconomic critical decision support software systems. DNNs are exceptionally good at finding minimal sufficient statistical patterns within their training data. Consequently DNNs may learn to encode decisions---amplifying existing biases or introducing new ones---that may disadvantage protected individuals/groups and may stand to violate legal protections. While the existing search based software testing approaches have been effective in discovering fairness defects they do not supplement these defects with debugging aids---such as severity and causal explanations---crucial to help developers triage and decide on the next course of action. Can we measure the severity of fairness defects in DNNs? Are these defects symptomatic of improper training or they merely reflect biases present in the training data? To answer such questions we present DICE: an information-theoretic testing and debugging framework to discover and localize fairness defects in DNNs.The key goal of DICE is to assist software developers in triaging fairness defects by ordering them by their severity. Towards this goal we quantify fairness in terms of protected information (in bits) used in decision making. A quantitative view of fairness defects not only helps in ordering these defects our empirical evaluation shows that it improves the search efficiency due to resulting smoothness of the search space. Guided by the quantitative fairness we present a causal debugging framework to localize inadequately trained layers and neurons responsible for fairness defects. Our experiments over ten DNNs developed for socially critical tasks show that DICE efficiently characterizes the amounts of discrimination effectively generates discriminatory instances (vis-a-vis the state-of-the-art techniques) and localizes layers/neurons with significant biases.;
Proceedings of the 11th ACM Symposium on Cloud Computing;Open-source software (OSS) projects rely on core and peripheral developers to develop release and maintain software. The former group plays a crucial role in initiating the project and making key decisions while the latter contributes less frequently and has little decision-making power. Prior studies have explored the relationship between developer experience and test code quality. However there is limited empirical evidence regarding the survivability of test smells during software evolution and maintenance. In this study we investigate the relationship between developersâ€™ experience and the survivability of test smells during test case refactorings in OSS projects. We empirically studied four OSS Java projects in which we identified test smells using manual and automated approaches and analyzed the authorship of the insertion and removal of test smells. Our findings reveal that test smells are commonly inserted during class creation and 10.39% of them are removed between 366 and 2911 days. &nbspWhile peripheral developers remove more test smells core developers remove different types of test smells.;
Proceedings of the 29th Symposium on Operating Systems Principles;Security of smart contracts has attracted increasing attention in recent years. Many researchers have devoted themselves to devising testing tools for vulnerability detection. Each published tool has demonstrated its effectiveness through a series of evaluations on their own experimental scenarios. However the inconsistency of evaluation settings such as different data sets or performance metrics may result in biased conclusion.  In this paper based on an empirical evaluation of widely used smart contract testing tools we propose a unified standard to eliminate the bias in the assessment process. First we collect 46186 source-available smart contracts from four influential organizations. This comprehensive dataset is open to the public and involves different code characteristics vulnerability patterns and application scenarios. Then we propose a 4-step evaluation process and summarize the difference among relevant work in these steps. We use nine representative tools to carry out extensive experiments. The results demonstrate that different choices of experimental settings could significantly affect tool performance and lead to misleading or even opposite conclusions. Finally we generalize some problems of existing testing tools and propose some possible directions for further improvement.;
Proceedings of the 14th International Workshop on Automation of Software Test;With the increasing popularity of blockchain automatically detecting vulnerabilities in smart contracts is becoming a significant problem. Prior research mainly identifies smart contract vulnerabilities without considering the interactions between multiple contracts. Due to the lack of analyzing the fine-grained contextual information during cross-contract invocations existing approaches often produced a large number of false positives and false negatives. This paper proposes SmartDagger a new framework for detecting cross-contract vulnerability through static analysis at the bytecode level. SmartDagger integrates a set of novel mechanisms to ensure its effectiveness and efficiency for cross-contract vulnerability detection. Particularly SmartDagger effectively recovers the contract attribute information from the smart contract bytecode which is critical for accurately identifying cross-contract vulnerabilities. Besides instead of performing the typical whole-program analysis which is heavy-weight and time-consuming SmartDagger selectively analyzes a subset of functions and reuses the data-flow results which helps to improve its efficiency. Our further evaluation over a manually labelled dataset showed that SmartDagger significantly outperforms other state-of-the-art tools (i.e. Oyente Slither Osiris and Mythril) for detecting cross-contract vulnerabilities. In addition running SmartDagger over a randomly selected dataset of 250 smart contracts in the real-world SmartDagger detects 11 cross-contract vulnerabilities all of which are missed by prior tools.;
Proceedings of the Thirty-Fifth Australasian Computer Science Conference - Volume 122;Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility app automation and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI a large dataset of 400000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain where less labeled data is available: (i) element detection (ii) screen classification and (iii) screen similarity.;
Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems;Performance is a key factor for big data applications and much research has been devoted to optimizing these applications. While prior work can diagnose and correct data skew the problem of computation skew---abnormally high computation costs for a small subset of input data---has been largely overlooked. Computation skew commonly occurs in real-world applications and yet no tool is available for developers to pinpoint underlying causes.To enable a user to debug applications that exhibit computation skew we develop a post-mortem performance debugging tool. PerfDebug automatically finds input records responsible for such abnormalities in a big data application by reasoning about deviations in performance metrics such as job execution time garbage collection time and serialization time. The key to PerfDebug's success is a data provenance-based technique that computes and propagates record-level computation latency to keep track of abnormally expensive records throughout the pipeline. Finally the input records that have the largest latency contributions are presented to the user for bug fixing. We evaluate PerfDebug via in-depth case studies and observe that remediation such as removing the single most expensive record or simple code rewrite can achieve up to 16X performance improvement.;
Proceedings of the ACM Symposium on Cloud Computing;Test cases that pass and fail without changes to the code under test are known as flaky. The past decade has seen increasing research interest in flaky tests though little attention has been afforded to the views and experiences of software developers. In this study we utilized a multi-source approach to obtain insights into how developers define flaky tests their experiences of the impacts and causes of flaky tests and the actions they take in response to them. To that end we designed a literature-guided developer survey that we deployed on social media receiving 170 total responses. We also searched on StackOverflow and analyzed 38 threads relevant to flaky tests offering a distinct perspective free of any self-reporting bias. Through a mixture of numerical and thematic analyses this study reveals a number of findings including (1) developers strongly agree that flaky tests hinder continuous integration (2) developers who experience flaky tests more often may be more likely to ignore potentially genuine test failures and (3) developers rate issues in setup and teardown to be the most common causes of flaky tests.;
Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice;Developing and integrating software in the automotive industry is a complex task and requires extensive testing. An important cost factor in testing and debugging is the time required to analyze failing tests. In the context of regression testing usually large numbers of tests fail due to a few underlying faults. Clustering failing tests with respect to their underlying faults can therefore help in reducing the required analysis time. In this paper we propose a clustering technique to group failing hardware-in-the-loop tests based on non-code-based features retrieved from three different sources. To effectively reduce the analysis effort the clustering tool selects a representative test for each cluster. Instead of analyzing all failing tests testers only inspect the representative tests to find the underlying faults. We evaluated the effectiveness and efficiency of our solution in a major automotive company using 86 regression test runs 8743 failing tests and 1531 faults. The results show that utilizing our clustering tool testers can reduce the analysis time more than 60% and find more than 80% of the faults only by inspecting the representative tests.;
Proceedings of the XXXVI Brazilian Symposium on Software Engineering;Ethereum is the largest and most prominent smart contract platform. One key property of Ethereum is that once a contract is deployed it can not be updated anymore. This increases the importance of thoroughly testing the behavior and constraints of the smart contract before deployment. Existing approaches in related work either do not scale or are only focused on finding crashing inputs. In this tool demo we introduce SynTest-Solidity an automated test case generation and fuzzing framework for Solidity. SynTest-Solidity implements various metaheuristic search algorithms including random search (traditional fuzzing) and genetic algorithms (i.e. NSGA-II MOSA and DynaMOSA). Finally we performed a preliminary empirical study to assess the effectiveness of SynTest-Solidity in testing Solidity smart contracts.;
Proceedings of the XXXIV Brazilian Symposium on Software Engineering;Documentation among the phases of software development is a crucial step for product acceptance given that poorly made documentation can compromise product quality. In the context of mobile development it is not always easy to deal with the rise in the number of released devices the new technologies and specifications the frequent updates to the Android operating system and the lack of experience of the people responsible for the development itself. Considering this the authors of this paper conducted an experiment aiming to assist the development of technical documentation reducing the time spent preparing and raising the degree of reliability in this information. Through simulations in a controlled environment a group of employees were able to utilize this new approach to prove its efficiency. The automation of this process shows a reduction of up to 33.2% that is 10.3 hours less in the documentationâ€™s total execution time. Furthermore this paper shows that it is possible to raise the reliability of information since the average error rate shown is around 5.3%. However for employees who have an average experience level in the team (between 6 and 18 months) the error rate is under 1.7%. In a setting where one must deal with adverse variables such as new employees off-standard databases a rise in demand among others those values are substantially satisfactory and the new process becomes essential for the team.;
Proceedings of the 2023 5th World Symposium on Software Engineering;The execution of smart contracts on the Ethereum blockchain consumes gas paid for by users submitting contracts' invocation requests. A contract execution proceeds as long as the users dedicate enough gas within the limit set by Ethereum. If insufficient gas is provided the contract execution halts and changes made during execution get reverted. Unfortunately contracts may contain code patterns that increase execution cost causing the contracts to run out of gas. These patterns can be manipulated by malicious attackers to induce unwanted behavior in the targeted victim contracts e.g. Denial-of-Service (DoS) attacks. We call these gas-related vulnerabilities. We propose eTainter a static analyzer for detecting gas-related vulnerabilities based on taint tracking in the bytecode of smart contracts. We evaluate eTainter by comparing it with the prior work MadMax on a dataset of annotated contracts. The results show that eTainter outperforms MadMax in both precision and recall and that eTainter has a precision of 90% based on manual inspection. We also use eTainter to perform large-scale analysis of 60612 real-world contracts on the Ethereum blockchain. We find that gas-related vulnerabilities exist in 2763 of these contracts and that eTainter analyzes a contract in eight seconds on average.;
Proceedings of the 2022 8th International Conference on Computer Technology Applications;The Cancer Registry of Norway (CRN) collects curates and manages data related to cancer patients in Norway supported by an interactive human-in-the-loop socio-technical decision support software system. Automated software testing of this software system is inevitable however currently it is limited in CRNâ€™s practice. To this end we present an industrial case study to evaluate an AI-based system-level testing tool i.e. EvoMaster in terms of its effectiveness in testing CRNâ€™s software system. In particular we focus on GURI CRNâ€™s medical rule engine which is a key component at the CRN. We test GURI with EvoMasterâ€™s black-box and white-box tools and study their test effectiveness regarding code coverage errors found and domain-specific rule coverage. The results show that all EvoMaster tools achieve a similar code coverage i.e. around 19% line 13% branch and 20% method and find a similar number of errors i.e. 1 in GURIâ€™s code. Concerning domain-specific coverage EvoMasterâ€™s black-box tool is the most effective in generating tests that lead to applied rules i.e. 100% of the aggregation rules and between 12.86% and 25.81% of the validation rules and to diverse rule execution results i.e. 86.84% to 89.95% of the aggregation rules and 0.93% to 1.72% of the validation rules pass and 1.70% to 3.12% of the aggregation rules and 1.58% to 3.74% of the validation rules fail. We further observe that the results are consistent across 10 versions of the rules. Based on these results we recommend using EvoMasterâ€™s black-box tool to test GURI since it provides good results and advances the current state of practice at the CRN. Nonetheless EvoMaster needs to be extended to employ domain-specific optimization objectives to improve test effectiveness further. Finally we conclude with lessons learned and potential research directions which we believe are applicable in a general context.;
Proceedings of the 2021 ACM Conference on Fairness Accountability and Transparency;Program merging is standard practice when developers integrate their individual changes to a common code base. When the merge algorithm fails this is called a merge conflict. The conflict either manifests as a textual merge conflict where the merge fails to produce code or as a semantic merge conflict where the merged code results in compiler errors or broken tests. Resolving these conflicts for large code projects is expensive because it requires developers to manually identify the sources of conflicts and correct them.   In this paper we explore the feasibility of automatically repairing merge conflicts (both textual and semantic) using k-shot learning with pre-trained large neural language models (LM) such as GPT-3. One of the challenges in leveraging such language models is fitting the examples and the queries within a small prompt (2048 tokens). We evaluate LMs and k-shot learning for both textual and semantic merge conflicts for Microsoft Edge. Our results are mixed: on one-hand LMs provide the state-of-the-art (SOTA) performance on semantic merge conflict resolution for Edge compared to earlier symbolic approaches on the other hand LMs do not yet obviate the benefits of special purpose domain-specific languages (DSL) for restricted patterns for program synthesis.;
Proceedings of the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering;Programming education at scale increasingly relies on automated feedback to help students learn to program. An important form of feedback is to point out semantic errors in student programs and provide hints for program repair. Such automated feedback depends essentially on solving the tasks of classification localization and repair of semantic errors. Although there are datasets for the tasks we observe that they do not have the annotations supporting all three tasks. As such existing approaches for semantic error feedback treat error classification localization and repair as independent tasks resulting in sub-optimal performance on each task. Moreover existing datasets either contain few programming assignments or have few programs for each assignment. Therefore existing approaches often leverage rule-based methods and evaluate them with a small number of programming assignments. To tackle the problems we first describe the creation of a new dataset COJ2022 that contains 5914 C programs with semantic errors submitted to 498 different assignments in an introductory programming course where each program is annotated with the error types and locations and is coupled with the repaired program submitted by the same student. We show the advantages of COJ2022 over existing datasets on various aspects. Second we treat semantic error classification localization and repair as dependent tasks and propose a novel two-stage method ErrorCLR to solve them. Specifically in the first stage we train a model based on graph matching networks to jointly classify and localize potential semantic errors in student programs and in the second stage we mask error spans in buggy programs using information of error types and locations and train a CodeT5 model to predict correct spans. The predicted spans replace the error spans to form repaired programs. Experimental results show that ErrorCLR remarkably outperforms the comparative methods for all three tasks on COJ2022 and other public datasets. We also conduct a case study to visualize and interpret what is learned by the graph matching network in ErrorCLR. We have released the source code and COJ2022 at https://github.com/DaSESmartEdu/ErrorCLR.;
Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval;Probabilistic programming languages offer an intuitive way to model uncertainty by representing complex probability models as simple probabilistic programs. Probabilistic programming systems (PP systems) hide the complexity of inference algorithms away from the program developer. Unfortunately if a failure occurs during the run of a PP system a developer typically has very little support in finding the part of the probabilistic program that causes the failure in the system.  This paper presents Storm a novel general framework for reducing probabilistic programs. Given a probabilistic program (with associated data and inference arguments) that causes a failure in a PP system Storm finds a smaller version of the program data and arguments that cause the same failure. Storm leverages both generic code and data transformations from compiler testing and domain-specific probabilistic transformations. The paper presents new transformations that reduce the complexity of statements and expressions reduce data size and simplify inference arguments (e.g. the number of iterations of the inference algorithm).  We evaluated Storm on 47 programs that caused failures in two popular probabilistic programming systems Stan and Pyro. Our experimental results show Stormâ€™s effectiveness. For Stan our minimized programs have 49% less code 67% less data and 96% fewer iterations. For Pyro our minimized programs have 58% less code 96% less data and 99% fewer iterations. We also show the benefits of Storm when debugging probabilistic programs.;
Proceedings of the 2nd ACM International Workshop on AI and Software Testing/Analysis;Mutation testing is an established approach for checking whether code satisfies a code-independent functional specification and for evaluating whether a test set is adequate. Current mutation testing approaches however do not account for accuracy requirements that appear with numerical specifications implemented in floating- point arithmetic code but which are a frequent part of safety-critical software. We present Magneto an instantiation of mutation testing that fully automatically generates a test set from a real-valued specification. The generated tests check numerical code for accuracy robustness and functional behavior bugs. Our technique is based on formulating test case and oracle generation as a constraint satisfaction problem over interval domains which soundly bounds errors but is nonetheless efficient. We evaluate Magneto on a standard floating-point benchmark set and find that it outperforms a random testing baseline for producing useful adequate test sets.;
Proceedings of the 43rd International Conference on Software Engineering: New Ideas and Emerging Results;We share our experience in developing Code Understanding Linter an automated code review tool based on language models of code. We introduce several ideas to make the tool be more practical including combining two different language models filtering meaningless outputs from the model and generating developer-friendly diagnosis messages by interpreting the outputs from the model. On top of those ideas we describe the design and implementation of an automated code review tool to detect variable-misuse&nbsp defects in Python codes and suggest how to fix them. We evaluated the tool with a set of code repositories in Samsung Electronics which contains real-world Python codes. Our experiment proves that our tool can discover hidden defects in the real-world codes but the false positive rate is far higher than we expected. After manually investigating every false positives we discuss the limitations of the language models and possible solutions.;
Proceedings of the 10th International Workshop on Search-Based Software Testing;Effective locating and fixing defects requires detailed defect reports. Unlike traditional software systems machine learning applications are subject defects caused from changes in the input data streams (concept drift) and assumptions encoded into models. Without appropriate training developers face difficulties understanding and interpreting faults in machine learning (ML). However little research is done on how to prepare developers to detect and investigate machine learning system defects. Software engineers often do not have sufficient knowledge to fix the issues themselves without the help of data scientists or domain experts. To investigate this issue we analyse issue templates and check how developers report machine learning related issues in open-source applied AI projects. The overall goal is to develop a tool for automatically repairing ML defects or generating defect reports if a fix cannot be made. Previous research has identified classes of faults specific to machine learning systems such as performance degradation arising from concept drift where the machine learning model is no longer aligned with the real-world environment. However the current issue templates that developers use do not seem to capture the information needed. This research seeks to systematically develop a two-way human-machine information exchange protocol to support domain experts software engineers and data scientists to collaboratively detect report and respond to these new classes of faults.;
Proceedings of the 2017 Symposium on Cloud Computing;Test-based generate-and-validate automated program repair (APR) systems often generate plausible patches that pass the test suite without fixing the bug. So far several approaches for automatic assessment of the APR-generated patches are proposed. Among them dynamic patch correctness assessment relies on comparing run-time information obtained from the program before and after patching. Object similarity-based dynamic patch ranking approaches specifically capture system state snapshots after the impact point of patches and express behavior differences in term of object graphs similarities. Dynamic approaches rely on the assumption that when running the originally passing test cases the correct patches will not alter the program behavior in a significant way but such patches will significantly change program behavior for the failing test cases.This paper presents the results of an extensive empirical study on two object similarity-based approaches i.e. ObjSim and CIP to rank 1290 APR-generated patches used in previous APR research. We found that although ObjSim outperforms CIP in terms of the number of patches ranked in top-1 position it still does not offer an improvement over random baseline ranking representing the setting with no automatic patch correctness assessment in place. This observation warrants further research on the validity of the assumptions underlying these two techniques and the techniques based on similar assumptions.;
Proceedings of the 8th ACM SIGSOFT International Workshop on Automated Software Testing;Test-case prioritization (TCP) aims to detect regression bugs faster via reordering the tests run. While TCP has been studied for over 20 years it was almost always evaluated using seeded faults/mutants as opposed to using real test failures. In this work we study the recent change-aware information retrieval (IR) technique for TCP. Prior work has shown it performing better than traditional coverage-based TCP techniques but it was only evaluated on a small-scale dataset with a cost-unaware metric based on seeded faults/mutants. We extend the prior work by conducting a much larger and more realistic evaluation as well as proposing enhancements that substantially improve the performance. In particular we evaluate the original technique on a large-scale real-world software-evolution dataset with real failures using both cost-aware and cost-unaware metrics under various configurations. Also we design and evaluate hybrid techniques combining the IR features historical test execution time and test failure frequencies. Our results show that the change-aware IR technique outperforms stateof-the-art coverage-based techniques in this real-world setting and our hybrid techniques improve even further upon the original IR technique. Moreover we show that flaky tests have a substantial impact on evaluating the change-aware TCP techniques based on real test failures.;
Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation;In the last decades numerous program analyzers have been developed both in academia and industry. Despite their abundance however there is currently no systematic way of comparing the effectiveness of different analyzers on arbitrary code. In this paper we present the first automated technique for differentially testing soundness and precision of program analyzers. We used our technique to compare six mature state-of-the art analyzers on tens of thousands of automatically generated benchmarks. Our technique detected soundness and precision issues in most analyzers and we evaluated the implications of these issues to both designers and users of program analyzers.;
Proceedings of the 25th International Symposium on Research in Attacks Intrusions and Defenses;Although the strongest test criteria traditional mutation testing has shown to not scale with modern incremental development practices. In this work we describe our proposal of commit-aware mutation testing and introduce the concept of commit-relevant mutants suitable to evaluate the system's behaviour after being affected by regression changes. We show that commit-relevant mutants represent a small but effective set that assesses the delta of behaviours between two consecutive software versions. Commit-aware mutation testing provides the guidance for developers to quantify to which extent they have tested error-prone locations impacted by program changes. In this paper we portray our efforts to make mutation criteria change-aware as we study characteristics of commit-relevant mutants striving to bring mutation testing closer to being worthwhile for evolving systems.;
Proceedings of the 1st ACM International Workshop on AI and Software Testing/Analysis;Symbolic execution is powered by constraint solving. The advancement of constraint solving boosts the development and the applications of symbolic execution. Modern SMT solvers provide the mechanism of solving strategy that allows the users to control the solving procedure which significantly improves the solver's generalization ability. We observe that the symbolic executions of different programs are actually different constraint solving problems. Therefore we propose synthesizing a solving strategy for a program to fit the program's symbolic execution best. To achieve this we divide symbolic execution into two stages. The SMT formulas solved in the first stage are used to online synthesize a solving strategy which is then employed during the constraint solving in the second stage. We propose novel synthesis algorithms that combine offline trained deep learning models and online tuning to synthesize the solving strategy. The algorithms balance the synthesis overhead and the improvement achieved by the synthesized solving strategy.  We have implemented our method on the state-of-the-art symbolic execution engine KLEE for C programs. The results of the extensive experiments indicate that our method effectively improves the efficiency of symbolic execution. On average our method increases the numbers of queries and paths by 58.76% and 66.11% respectively. Besides we applied our method to a Java Pathfinder-based concolic execution engine to validate the generalization ability. The results indicate that our method has a good generalization ability and increases the numbers of queries and paths by 100.24% and 102.6% for the benchmark Java programs respectively.;
Proceedings of the 11th Asia-Pacific Symposium on Internetware;Compilers are critical widely-used complex software. Bugs in them have significant impact and can cause serious damage when they silently miscompile a safety-critical application. An in-depth understanding of compiler bugs can help detect and fix them. To this end we conduct the first empirical study on the characteristics of the bugs in two main-stream compilers GCC and LLVM. Our study is significant in scale â€” it exhaustively examines about 50K bugs and 30K bug fix revisions over more than a decadeâ€™s span. This paper details our systematic study. Summary findings include: (1) In both compilers C++ is the most buggy component accounting for around 20% of the total bugs and twice as many as the second most buggy component (2) the bug revealing test cases are typically small with 80% having fewer than 45 lines of code (3) most of the bug fixes touch a single source file with small modifications (43 lines for GCC and 38 for LLVM on average) (4) the average lifetime of GCC bugs is 200 days and 111 days for LLVM and (5) high priority tends to be assigned to optimizer bugs most notably 30% of the bugs in GCCâ€™s inter-procedural analysis component are labeled P1 (the highest priority). This study deepens our understanding of compiler bugs. For application developers it shows that even mature production compilers still have many bugs which may affect development. For researchers and compiler developers it sheds light on interesting characteristics of compiler bugs and highlights challenges and opportunities to more effectively test and debug compilers.;
Proceedings of the 4th International Conference on Advanced Information Science and System;We present a method for automatically repairing arbitrary software defects in embedded systems which have limited memory disk and CPU capacities but exist in great numbers. We extend evolutionary computation (EC) algorithms that search for valid repairs at the source code level to assembly and ELF format binaries compensating for limited system resources with several algorithmic innovations. Our method does not require access to the source code or build toolchain of the software under repair does not require program instrumentation specialized execution environments or virtual machines or prior knowledge of the bug type.We repair defects in ARM and x86 assembly as well as ELF binaries observing decreases of 86% in memory and 95% in disk requirements with 62% decrease in repair time compared to similar source-level techniques. These advances allow repairs previously possible only with C source code to be applied to any ARM or x86 assembly or ELF executable. Efficiency gains are achieved by introducing stochastic fault localization with much lower overhead than comparable deterministic methods and low-level program representations.When distributed over multiple devices our algorithm finds repairs faster than predicted by naive parallelism. Four devices using our approach are five times more efficient than a single device because of our collaboration model. The algorithm is implemented on Nokia N900 smartphones with inter-phone communication fitting in 900 bytes sent in 7 SMS text messages per device per repair on average.;
Proceedings of the 9th International Conference on Software and Information Engineering;Effective bug triaging is critical for efficient software development as bugs can cause software failures and unexpected behavior. The bug triaging process involves report summarization severity classification and assignment of bugs to developers. This paper introduced a novel developer recommendation algorithm designed to rank developers to reduce the bug tossing length. To automate and improve the accuracy of bug triaging various machine learning models deep learning models and bio-inspired algorithms are utilized. In this project we compared the effectiveness of bio-inspired algorithms with traditional machine learning algorithms such as SVM Random Forest Logistic Regression K-Nearest Neighbors Decision Tree and Random Forest. We utilized open-source datasets such as the eclipse bug dataset and Firefox dataset for our analysis. We preprocessed the data and used the Artificial Bee Colony (ABC) algorithm for optimizing bug triaging. Our results indicate that the ABC algorithm yields more accurate results with fitness score 78.603 as compared to traditional machine learning algorithms in which highest accuracy obtained was 0.56 by decision tree.;
Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing;Testing Deep Learning (DL) based systems inherently requires large and representative test sets to evaluate whether DL systems generalise beyond their training datasets. Diverse Test Input Generators (TIGs) have been proposed to produce artificial inputs that expose issues of the DL systems by triggering misbehaviours. Unfortunately such generated inputs may be invalid i.e. not recognisable as part of the input domain thus providing an unreliable quality assessment. Automated validators can ease the burden of manually checking the validity of inputs for human testers although input validity is a concept difficult to formalise and thus automate.In this paper we investigate to what extent TIGs can generate valid inputs according to both automated and human validators. We conduct a large empirical study involving 2 different automated validators 220 human assessors 5 different TIGs and 3 classification tasks. Our results show that 84% artificially generated inputs are valid according to automated validators but their expected label is not always preserved. Automated validators reach a good consensus with humans (78% accuracy) but still have limitations when dealing with feature-rich datasets.;
Proceedings of the 2020 Genetic and Evolutionary Computation Conference;Software testing is an essential activity for quality assurance but it is an error-prone and effort consuming task when conducted manually. Because of this the use of automated tools is fundamental as well as the evaluation of these tools in practice. However there is not so much evidence on how such tools perform on highly-configurable systems. Highly-configurable systems are commonly observed in industry as an approach to develop families of products where products have different configuration options to meet customer needs. To fulfill such a gap this paper reports results on the use of the tool Randoop which is widely used in industry to test variants of the Graph Product Line (GPL) family of products. Our goal is to evaluate reusability of a test data set generated by Randoop for one product when reused for testing other GPL products. Besides we also investigate the impact of using different values of runtime the main Randoop parameter on the number of reused test data. The results show that the used value for runtime in general does not contribute to increase the coverage of test data reused in different products. Furthermore similarity among products does not ensure a greater reusability.;
Proceedings of the 12th International Workshop on Search-Based Software Testing;Given that a relational database is a critical component of many software applications it is important to thoroughly test the integrity constraints of a database's schema because they protect the data. Although automated test data generation techniques ameliorate the otherwise manual task of database schema testing they often create test suites that contain many sometimes redundant tests. Since prior work presented a hybridized test suite reduction technique called STICCER that beneficially combined Greedy test suite reduction with a test merging method customized for database schemas this paper experimentally evaluates a different hybridization. Motivated by prior results showing that test suite reduction with the Harrold-Gupta-Soffa (HGS) method can be more effective than Greedy at reducing database schema test suites this paper evaluates an HGS-driven STICCER variant with both a computational and a human study. Using 34 database schemas and tests created by two test data generators the results from the computational study reveal that while STICCER is equally efficient and effective when combined with either Greedy or HGS it is always better than the isolated use of either Greedy or HGS. Involving 27 participants the human study shows that when compared to test suites reduced by HGS those reduced by a STICCER-HGS hybrid allow humans to inspect test cases faster but not always more accurately.;
Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice;Ensuring determinism is mandatory when writing blockchain software.  When determinism is not met it can lead to serious implications in the blockchain network while compromising the software development release and patching processes.  In the industrial context it is widespread to adopt general-purpose languages such as Go for developing blockchain solutions.  However it is not surprising that non-deterministic behaviors may arise being these programming languages not originally designed for blockchain purposes.  In this paper we present an experience report on ensuring determinism in blockchain software with GoLiSA a static analyzer based on abstract interpretation for Go applications in an industrial context. In particular we ran GoLiSA on Commercio.network a blockchain-based solution for exchanging electronic documents in a legally binding way.  Thanks to GoLiSA non-trivial bugs got detected and the analysis performed made it possible to identify the critical points where to apply the fixes.;
Proceedings of the 11th ACM SIGPLAN International Workshop on the State Of the Art in Program Analysis;Local databases underpin important features in many mobile applications such as responsiveness in the face of poor connectivity. However failure to use such databases correctly can lead to high resource consumption or even security vulnerabilities. We present SAND an extensible static analysis approach that checks for misuse of local databases also known as SQL antipatterns in mobile apps. SAND features novel abstractions for common forms of application/database interactions which enables concise and precise specification of the antipatterns that SAND checks for. To validate the efficacy of SAND we have experimented with a diverse suite of 1000 Android apps. We show that the abstractions that power SAND allow concise specification of all the known antipatterns from the literature (12-74 LOC) and that the antipatterns are modeled accurately (99.4-100% precision). As for performance SAND requires on average 41 seconds to complete a scan on a mobile app.;
Proceedings of the 11th International Workshop on Search-Based Software Testing;"Mutation testing is widely used in research as a metric for evaluating the quality of test suites. Mutation testing runs the test suite on generated mutants (variants of the code under test) where a test suite kills a mutant if any of the tests fail when run on the mutant. Mutation testing implicitly assumes that tests exhibit deterministic behavior in terms of their coverage and the outcome of a test (not) killing a certain mutant. Such an assumption does not hold in the presence of flaky tests whose outcomes can non-deterministically differ even when run on the same code under test. Without reliable test outcomes mutation testing can result in unreliable results e.g. in our experiments mutation scores vary by four percentage points on average between repeated executions and 9% of mutant-test pairs have an unknown status. Many modern software projects suffer from flaky tests. We propose techniques that manage flakiness throughout the mutation testing process largely based on strategically re-running tests. We implement our techniques by modifying the open-source mutation testing tool PIT. Our evaluation on 30 projects shows that our techniques reduce the number of unknown"" (flaky) mutants by 79.4%.""";
Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2;Testing is an integral part of release engineering and continuous integration. In theory a failed test on a build indicates a problem that should be fixed and the build should not be released. In practice tests decay and developers often release builds ignoring failing tests. In this paper we studying the link between builds with failing tests and the number of crash reports on the Firefox webbrowser. Builds with all tests passing have a median of only two crash reports. In contrast builds with one or more failing tests are associated with a median of 508 and 291 crash reports for Beta and Production builds respectively. We further investigate the impact of ``flaky'' tests which can both pass and fail on the same build and find that they have a median of 514 and 234 crash reports for Beta and Production builds. Finally building on previous research that has shown that tests that have failed frequently in the past will fail frequently in the future we find that Builds with HighFailureTests have a median of 585 and 780 crash reports for Beta and Production builds. Unlike other types of test failures HighFailureTests have a larger impact on Production releases than on Beta builds and they have a median of 2.7 times more crashes than builds with normal test failures. We conclude that ignoring test failures is related to a dramatic increase in the number of crashes reported by users.;
Proceedings of the 37th International Conference on Software Engineering - Volume 1;There are increasing uses of deep learning (DL) compilers to generate optimized code boosting the runtime performance of DL models on specific hardware. Like their traditional counterparts DL compilers can generate incorrect code resulting in unexpected model behaviors that may cause catastrophic consequences in mission-critical systems. On the other hand the DL models processed by DL compilers differ fundamentally from imperative programs in that the program logic in DL models is implicit. As such various characteristics of the bugs arising from traditional compilers need to be revisited in the context of DL compilers.  In this paper we present the first systematic study of DL compiler bugs by analyzing 603 bugs arising in three popular DL compilers (i.e. TVM from Apache Glow from Facebook and nGraph from Intel). We analyzed these bugs according to their root causes symptoms and the stages where they occur during compilation. We obtain 12 findings and provide a series of valuable guidelines for future work on DL compiler bug detection and debugging. For example a large portion (nearly 20%) of DL compiler bugs are related to types especially tensor types. The analysis of these bugs helps design new mutation operators (e.g. adding type cast for a tensor to promote implicit type conversion in subsequent tensor computations) to facilitate type-related bug detection. Further we developed TVMfuzz as a proof-of-concept application of our findings to test the TVM DL compiler. It generates new tests based on TVM's original test suite. They expose 8 TVM bugs that are missed by the original test suite. The result demonstrates the usefulness of our findings.;
Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering;Database design is an important part of software development because it manages the data consistency and makes sure that the data is not in an invalid state. In each software development cycle the percentages of complexity and size of the database are likely to increase dramatically. Changes in a database schema impact related source code and test cases which often lead to software process failure. Some studies [1-4] analyzed the impact of these changes using several techniques such as configuration management traceability relationships and program slicing to identify factors that caused changes. However these studies do not emphasize the impact on source code and test cases [5]. Therefore our research proposes an approach to analyze impacts on Hibernate source code and test cases caused by changing the database schema. In addition our approach can notify users about changes that occur in the database schema and line numbers of the affected source code and test cases. Lastly we also update source code and test cases based on the schema changes.;
Proceedings of the 2019 3rd International Conference on Software and E-Business;Security is unarguably the most serious concern for Web applications to which SQL injection (SQLi) attack is one of the most devastating attacks. Automatically testing SQLi vulnerabilities is of ultimate importance yet is unfortunately far from trivial to implement. This is because the existence of a huge or potentially infinite number of variants and semantic possibilities of SQL leading to SQLi attacks on various Web applications. In this paper we propose a deep natural language processing based tool dubbed DeepSQLi to generate test cases for detecting SQLi vulnerabilities. Through adopting deep learning based neural language model and sequence of words prediction DeepSQLi is equipped with the ability to learn the semantic knowledge embedded in SQLi attacks allowing it to translate user inputs (or a test case) into a new test case which is se- mantically related and potentially more sophisticated. Experiments are conducted to compare DeepSQLi with SQLmap a state-of-the-art SQLi testing automation tool on six real-world Web applications that are of different scales characteristics and domains. Empirical results demonstrate the effectiveness and the remarkable superiority of DeepSQLi over SQLmap such that more SQLi vulnerabilities can be identified by using a less number of test cases whilst running much faster.;
Proceedings of the 9th International Conference on Applied Computing &amp Information Technology;Recent advances in program repair techniques have raised the possibility of patching bugs automatically. For an automatically generated patch to be accepted by developers it should not only resolve the bug but also satisfy certain human-related factors including readability and comprehensibility. In this paper we focus on the simplicity of patches (the size of changes). We present a novel semantics-based repair method that generates the simplest patch such that the program structure of the buggy program is maximally preserved. To take into account the simplicity of repairs in an efficient way (i.e. without explicitly enumerating each repair candidate for each fault location) our method fuses fault localization and repair generation into one step. We do so by leveraging partial MaxSAT constraint solving and component-based program synthesis. We compare our prototype implementation DirectFix with the state-of-the-art semantics-based repair tool SemFix that performs fault localization before repair generation. In our experiments with SIR programs and GNU Coreutils DirectFix generates repairs that are simpler than those generated by SemFix. Since both DirectFix and SemFix are test-driven repair tools they can introduce regressions for other tests which do not drive the repair. We found that DirectFix causes substantially less regression errors than SemFix.;
Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems;Existing mutation techniques produce vast numbers of equivalent trivial and redundant mutants. Selective mutation strategies aim to reduce the inherent redundancy of full mutation analysis to obtain most of its benefit for a fraction of the cost. Unfortunately recent research has shown that there is no fixed selective mutation strategy that is effective across a broad range of programs the utility (i.e. usefulness) of a mutant produced by a given mutation operator varies greatly across programs.  This paper hypothesizes that mutant utility in terms of equivalence triviality and dominance can be predicted by incorporating context information from the program in which the mutant is embedded. Specifically this paper (1) explains the intuition behind this hypothesis with a motivational example (2) proposes an approach for modeling program context using a program's abstract syntax tree and (3) proposes and evaluates a series of program-context models for predicting mutant utility. The results for 129 mutation operators show that program context information greatly increases the ability to predict mutant utility. The results further show that it is important to consider program context for individual mutation operators rather than mutation operator groups.;
Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation;Mutation analysis evaluates a testing technique by measur- ing how well it detects seeded faults (mutants). Mutation analysis is hampered by inherent scalability problems â€” a test suite is executed for each of a large number of mutants. Despite numerous optimizations presented in the literature this scalability issue remains and this is one of the reasons why mutation analysis is hardly used in practice. Whereas most previous optimizations attempted to stati- cally reduce the number of executions or their computational overhead this paper exploits information available only at run time to further reduce the number of executions. First state infection conditions can reveal â€” with a single test execution of the unmutated program â€” which mutants would lead to a different state thus avoiding unnecessary test executions. Second determining whether an infected execution state propagates can further reduce the number of executions. Mutants that are embedded in compound expressions may infect the state locally without affecting the outcome of the compound expression. Third those mutants that do infect the state can be partitioned based on the resulting infected state â€” if two mutants lead to the same infected state only one needs to be executed as the result of the other can be inferred. We have implemented these optimizations in the Major mu- tation framework and empirically evaluated them on 14 open source programs. The optimizations reduced the mutation analysis time by 40% on average.;
Proceedings of the 14th International Conference on Mining Software Repositories;Symbolic execution (SE) is a widely used program analysis technique. Existing SE engines model the memory space by associating memory objects with concrete addresses where the representation of each allocated object is determined during its allocation. We present a novel addressing model where the underlying representation of an allocated object can be dynamically modified even after its allocation by using symbolic addresses rather than concrete ones. We demonstrate the benefits of our model in two application scenarios: dynamic inter- and intra-object partitioning. In the former we show how the recently proposed segmented memory model can be improved by dynamically merging several object representations into a single one rather than doing that a-priori using static pointer analysis. In the latter we show how the cost of solving array theory constraints can be reduced by splitting the representations of large objects into multiple smaller ones. Our preliminary results show that our approach can significantly improve the overall effectiveness of the symbolic exploration.;
Proceedings of the 2009 ACM Symposium on Applied Computing;Software testing is an activity in the software development process that looks for defects. Automated testing is composed of code that allows run software testing scenarios more quickly avoiding manual rework. However testers are likely to employ practices that might negatively impact test quality regarding maintainability understandability and effectiveness when writing test code. Such bad practices are also known as test smells. Although test smells are a language-independent concept different programming languages could present different occurrence standards. Therefore studies in one programming language may not be generalizable. This study aims to investigate how test smells occurrence in Python test files. Python became the most widely used programming language globally in 2020. However most research on test code quality only considers the Java language. To accomplish our goals we built a dataset with 5303 test files from 90 Python projects collected from GitHub repositories to understand and analyze strategies for handling test smells in Python. This analysis allowed us to propose four new test smells discussing their potential problems. We carried out a preliminary evaluation with 40 Python developers to validate their thoughts on the proposed test smells. These results are part of an ongoing research project aiming to propose a foundation to better support automation tests in Python.;
Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Automating formal verification of safety and security prop-erties in both hardware and software systems is challengingdue to a number of issues. In this paper we tried to addresstwo important challenges in this regard. The first challengethat we discuss is the scalable co-verification of hardwareand firmware in a modern system-on-chip (SoC) platformto guarantee end-to-end security of the system. We havediscussed two specific problems in this regard that we havetried to solve and our approach to address this challenge (i) we designed a verification methodology for end-to-end secu-rity property verification for authenticated firmware loaderprotocol running on a SoC platform and (ii) we proposeda unified framework called HyperFuzzing for specifyinghardware security properties and automatically testing forviolations of these properties using fuzzing. The second chal-lenge we have discussed in this paper is to verify hardwareor software systems that use closed-box functions or opera-tions. To address this challenge we have introduced a newtheory for SMT solvers called closed-box function theoryand have implemented it in our prototype solver Sundefineddhak. Our solver Sundefineddhak can handle SMT constraints with closed-box functions which can be used by verification and testingtools for solving closed-box constraints.;
Companion Proceedings of the 2022 ACM SIGPLAN International Conference on Systems Programming Languages and Applications: Software for Humanity;Software defect prediction is an essential technology to provide guidance and assistance for software testers and developers. However the problem of imbalanced data sets limits the effect and application of the software defect prediction. To address this issue this paper proposes a software defect prediction method based on hybrid sampling which combines the strategies of over-sampling with under-sampling. For minority class over-sampling uses k-means to cluster samples then adopts SMOTE to generate artificial data based on safe areas of the clustering outcome. For majority class under-sampling uses logistic regression classifier to get the misclassification probability of each sample and its instance hardness value. Then the samples whose instance hardness values are lower than the threshold are removed from the datasets. The experimental results show that our method is superior to the previous methods. Compared with SMOTE-kNN SMOTE-Tomek SMOTE and DBSMOTE the accuracy of our method is improved by 17.60% 6.99% 8.66% and 26.18% on average respectively.;
International Conference on Frontiers of Electronics Information and Computation Technologies;Aiming at the problems of poor reusability of domestic operating system test cases and insufficient sharing of test case design experience at this stage a method for constructing knowledge graphs in the field of domestic operating system testing is proposed and ontology construction and natural language processing technologies are applied to the field of software testing. Use the strong correlation of the knowledge graph to mine the experience knowledge in the design of historical test cases select and reuse test cases that meet the test requirements for testers and help them design test cases more efficiently. Through empirical research this method gives full play to the advantages of knowledge graphs in relational network analysis and retrieval and the coverage rate of reused test cases reaches 71% which can greatly save test costs and improve test efficiency and has strong engineering application value.;
Proceedings of the 4th International Conference on Computer Science and Software Engineering;Software hang bugs are notoriously difficult to debug which often cause serious service outages in cloud systems. In this paper we present HangFix a software hang bug fixing framework which can automatically fix a hang bug that is triggered and detected in production cloud environments. HangFix first leverages stack trace analysis to localize the hang function and then performs root cause pattern matching to classify hang bugs into different types based on likely root causes. Next HangFix generates effective code patches based on the identified root cause patterns. We have implemented a prototype of HangFix and evaluated the system on 42 real-world software hang bugs in 10 commonly used cloud server applications. Our results show that HangFix can successfully fix 40 out of 42 hang bugs in seconds.;
Proceedings of the 2021 IEEE/ACM International Symposium on Code Generation and Optimization;Programmers often have to spend a significant amount of time in- specting the software code and execution traces to identify the cause of a bug. For a multithreaded program debugging is even more challenging due to the subtle interactions between threads and the often astronomical number of interleavings. In this work we pro- pose a logical constraint based symbolic analysis method to aid in the diagnosis of concurrency bugs and to recommend repairs. Both diagnosis and repair are formulated as constraint solving prob- lems. Our method by leveraging the power of satisfiability (SAT) solvers and a bounded model checker performs a semantic analy- sis of the sequential computation as well as thread interactions. The constraint based analysis is designed for handling critical software with small to medium code size but complex concurrency control such as device drivers implementations of synchronization proto- cols and concurrent data structures. We have implemented our new method in a software tool and demonstrated its effectiveness in di- agnosing bugs in multithreaded C programs.;
Proceedings of the Genetic and Evolutionary Computation Conference Companion;Automatic type inference is a popular feature of functional programming languages. If a program cannot be typed the compiler typically reports a single program location in its error message. This location is the point where the type inference failed but not necessarily the actual source of the error. Other potential error sources are not even considered. Hence the compiler often misses the true error source which increases debugging time for the programmer. In this paper we present a general framework for automatic localization of type errors. Our algorithm finds all minimum error sources where the exact definition of minimum is given in terms of a compiler-specific ranking criterion. Compilers can use minimum error sources to produce more meaningful error reports and for automatic error correction. Our approach works by reducing the search for minimum error sources to an optimization problem that we formulate in terms of weighted maximum satisfiability modulo theories (MaxSMT). The reduction to weighted MaxSMT allows us to build on SMT solvers to support rich type systems and at the same time abstract from the concrete criterion that is used for ranking the error sources. We have implemented an instance of our framework targeted at Hindley-Milner type systems and evaluated it on existing OCaml benchmarks for type error localization. Our evaluation shows that our approach has the potential to significantly improve the quality of type error reports produced by state of the art compilers.;
Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages &amp Applications;SAT and SMT solvers have automated a spectrum of programming tasks including program synthesis code checking bug localization program repair and programming with oracles. In principle we obtain all these benefits by translating the program (once) to a constraint system understood by the solver. In practice however compiling a language to logical formulas is a tricky process complicated by having to map the solution back to the program level and extend the language with new solver-aided constructs such as symbolic holes used in synthesis.This paper introduces ROSETTE a framework for designing solver-aided languages. ROSETTE is realized as a solver-aided language embedded in Racket from which it inherits extensive support for meta-programming. Our framework frees designers from having to compile their languages to constraints: new languages and their solver-aided constructs are defined by shallow (library-based) or deep (interpreter-based) embedding in ROSETTE itself.We describe three case studies by ourselves and others of using ROSETTE to implement languages and synthesizers for web scraping spatial programming and superoptimization of bitvector programs.;
Proceedings of the 2013 ACM International Symposium on New Ideas New Paradigms and Reflections on Programming &amp Software;The implementation of network protocol must comply with respective Request for Comments (RFC) and updated as RFCs evolve. However due to the richness of RFCs and the complex relationships between them systematically discovering the evolution of RFC requirements is non-trivial which consequently brings in inconsistency bugs when modifying code to support new RFC documents. This can lead to inconsistency bugs when modifying code to support new RFC documents known as RFC-evolutionary bugs or ebugs. Recent approaches have used natural language processing techniques to extract RFC rules and employed differential testing or static analysis to discover inconsistency bugs in protocol implementations. However they seldom consider the evolution of RFC requirements nor their related bugs. In this paper we present EBugDec. Given a protocol implementation and the RFCs it claims to support our approach identifies evolutionary relationships between RFC documents and their corresponding requirement changes. From this we derive two major types of evolutionary rules: primitive rules that dictate requirements for newly-introduced packet items and derivative rules that describe the influence the new items made on requirements stipulated in earlier RFCs. Both of them are represented in formal expressions that dictate packet-related operations should be guarded by specific conditions under special cases (if necessary). Then we use clues found in code annotations and release notes to locate rule-related code in the implementation and leverage a predominator-based algorithm to discover rule violations in the implementation. We also uncover incomplete error handling logic when the rule-specified conditions fail. We implemented a prototype of EBugDec and demonstrated its efficiency by applying it on 12 implementations of protocol services along with 178 RFC documents their historical releases claim to support. On average EBugDec consumed 37.29 seconds to finish its analysis and detected 17 new ebugs 5 of which can only be triggered under harsh prerequisites.;
Proceedings of the 26th International Symposium on Research in Attacks Intrusions and Defenses;Test-suite reduction (TSR) speeds up regression testing by removing redundant tests from the test suite thus running fewer tests in the future builds. To decide whether to use TSR or not a developer needs some way to predict how well the reduced test suite will detect real faults in the future compared to the original test suite. Prior research evaluated the cost of TSR using only program versions with seeded faults but such evaluations do not explicitly predict the effectiveness of the reduced test suite in future builds.  We perform the first extensive study of TSR using real test failures in (failed) builds that occurred for real code changes. We analyze 1478 failed builds from 32 GitHub projects that run their tests on Travis. Each failed build can have multiple faults so we propose a family of mappings from test failures to faults. We use these mappings to compute Failed-Build Detection Loss (FBDL) the percentage of failed builds where the reduced test suite misses to detect all the faults detected by the original test suite. We find that FBDL can be up to 52.2% which is higher than suggested by traditional TSR metrics. Moreover traditional TSR metrics are not good predictors of FBDL making it difficult for developers to decide whether to use reduced test suites.;
Proceedings of the 11th ACM SIGPLAN International Workshop on Programming Based on Actors Agents and Decentralized Control;Fuzzing is a key tool used to reduce bugs in production software. At Google fuzzing has uncovered tens of thousands of bugs. Fuzzing is also a popular subject of academic research. In 2020 alone over 120 papers were published on the topic of improving developing and evaluating fuzzers and fuzzing techniques. Yet proper evaluation of fuzzing techniques remains elusive. The community has struggled to converge on methodology and standard tools for fuzzer evaluation. To address this problem we introduce FuzzBench as an open-source turnkey platform and free service for evaluating fuzzers. It aims to be easy to use fast reliable and provides reproducible experiments. Since its release in March 2020 FuzzBench has been widely used both in industry and academia carrying out more than 150 experiments for external users. It has been used by several published and in-the-work papers from academic groups and has had real impact on the most widely used fuzzing tools in industry. The presented case studies suggest that FuzzBench is on its way to becoming a standard fuzzer benchmarking platform.;
Proceedings of the ACM India Joint International Conference on Data Science and Management of Data;Energy efficiency is an important criterion to judge the quality of mobile apps but one third of our randomly sampled apps suffer from energy issues that can quickly drain battery power. To understand these issues we conducted an empirical study on 27 well-maintained apps such as Chrome and Firefox whose issue tracking systems are publicly accessible. Our study revealed that the main root causes of energy issues include unnecessary workload and excessively frequent operations. Surprisingly these issues are beyond the application of present technology on energy issue detection. We also found that 25.0% of energy issues can only manifest themselves under specific contexts such as poor network performance but such contexts are again neglected by present technology. In this paper we propose a novel testing framework for detecting energy issues in real-world mobile apps. Our framework examines apps with well-designed input sequences and runtime contexts. To identify the root causes mentioned above we employed a machine learning algorithm to cluster the workloads and further evaluate their necessity. For the issues concealed by the specific contexts we carefully set up several execution contexts to catch them. More importantly we designed leading edge technology e.g. pre-designing input sequences with potential energy overuse and tuning tests on-the-fly to achieve high efficacy in detecting energy issues. A large-scale evaluation shows that 91.6% issues detected in our experiments were previously unknown to developers. On average these issues double the energy costs of the apps. Our testing technique achieves a low number of false positives.;
Proceedings of the International Conference on Computer-Aided Design;Applying code changes to software systems and testing these code changes can be a complex task that involves many different types of software testing strategies e.g. system and integration tests. However not all test failures reported during code integration are hinting towards code defects. Testing large systems such as the Microsoft Windows operating system requires complex test infrastructures which may lead to test failures caused by faulty tests and test infrastructure issues. Such false test alarms are particular annoying as they raise engineer attention and require manual inspection without providing any benefit. The goal of this work is to use empirical data to minimize the number of false test alarms reported during system and integration testing. To achieve this goal we use association rule learning to identify patterns among failing test steps that are typically for false test alarms and can be used to automatically classify them. A successful classification of false test alarms is particularly valuable for product teams as manual test failure inspection is an expensive and time-consuming process that not only costs engineering time and money but also slows down product development. We evaluating our approach on system and integration tests executed during Windows 8.1 and Microsoft Dynamics AX development. Performing more than 10000 classifications for each product our model shows a mean precision between 0.85 and 0.90 predicting between 34% and 48% of all false test alarms.;
Proceedings of the 2nd ACM International Conference on Embedded Systems for Energy-Efficient Built Environments;[Background]: There are more bugs in real-world programs than human programmers can realistically address. Several approaches have been proposed to aid debugging. A recent research direction that has been increasingly gaining interest to address the reduction of costs associated with defect repair is automatic program repair. Recent work has shown that some kind of bugs are more suitable for automatic repair techniques. [Aim]: The detection and characterization of common bug-fix patterns in software repositories play an important role in advancing the field of automatic program repair. In this paper we aim to characterize the occurrence of known bug-fix patterns in Java repositories at an unprecedented large scale. [Method]: The study was conducted for Java GitHub projects organized in two distinct data sets: the first one (i.e. Boa data set) contains more than 4 million bug-fix commits from 101471 projects and the second one (i.e. Defects4J data set) contains 369 real bug fixes from five open-source projects. We used a domain-specific programming language called Boa in the first data set and conducted a manual analysis on the second data set in order to confront the results. [Results]: We characterized the prevalence of the five most common bug-fix patterns (identified in the work of Pan et al.) in those bug fixes. The combined results showed direct evidence that developers often forget to add IF preconditions in the code. Moreover 76% of bug-fix commits associated with the IF-APC bug-fix pattern are isolated from the other four bug-fix patterns analyzed. [Conclusion]: Targeting on bugs that miss preconditions is a feasible alternative in automatic repair techniques that would produce a relevant payback.;
Proceedings of the 11th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement;Build automation is critical for developers to check if their code compiles passes all tests and is safe to deploy to the server. Many companies adopt Continuous Integration (CI) services to make sure that the code changes from multiple developers can be safely merged at the head of the project. Internally CI triggers builds to make sure that the new code change compiles and passes the tests. For any large company which has a monolithic code repository and thousands of developers it is hard to make sure that all code changes are safe to submit in a timely manner. The reason is that each code change may involve multiple builds and the company needs to run millions of builds every day to guarantee developersâ€™ productivity.  Google is one of those large companies that need a scalable build service to support developersâ€™ work. More than 100000 code changes are submitted to our repository on average each day including changes from either human users or automated tools. More than 15 million builds are executed on average each day. In this paper we first describe an overview of our scalable build service architecture. Then we discuss more details about how we make build scheduling decisions. Finally we discuss some experience in the scalability of the build service system and the performance of the build scheduling service.;
Proceedings of the 12th Working Conference on Mining Software Repositories;Software testing is a widely used technique to ensure the quality of software systems. Code coverage measures are commonly used to evaluate and improve the existing test suites. Based on our industrial and open source studies existing state-of-the-art code coverage tools are only used during unit and integration testing due to issues like engineering challenges performance overhead and incomplete results. To resolve these issues in this paper we have proposed an automated approach called LogCoCo to estimating code coverage measures using the readily available execution logs. Using program analysis techniques LogCoCo matches the execution logs with their corresponding code paths and estimates three different code coverage criteria: method coverage statement coverage and branch coverage. Case studies on one open source system (HBase) and five commercial systems from Baidu and systems show that: (1) the results of LogCoCo are highly accurate (&gt96% in seven out of nine experiments) under a variety of testing activities (unit testing integration testing and benchmarking) and (2) the results of LogCoCo can be used to evaluate and improve the existing test suites. Our collaborators at Baidu are currently considering adopting LogCoCo and use it on a daily basis.;
Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages &amp Applications;Database Management Systems (DBMS) are used ubiquitously. To efficiently access data they apply sophisticated optimizations. Incorrect optimizations can result in logic bugs which cause a query to compute an incorrect result set. We propose Non-Optimizing Reference Engine Construction (NoREC) a fully-automatic approach to detect optimization bugs in DBMS. Conceptually this approach aims to evaluate a query by an optimizing and a non-optimizing version of a DBMS to then detect differences in their returned result set which would indicate a bug in the DBMS. Obtaining a non-optimizing version of a DBMS is challenging because DBMS typically provide limited control over optimizations. Our core insight is that a given potentially randomly-generated optimized query can be rewritten to one that the DBMS cannot optimize. Evaluating this unoptimized query effectively corresponds to a non-optimizing reference engine executing the original query. We evaluated NoREC in an extensive testing campaign on four widely-used DBMS namely PostgreSQL MariaDB SQLite and CockroachDB. We found 159 previously unknown bugs in the latest versions of these systems 141 of which have been fixed by the developers. Of these 51 were optimization bugs while the remaining were error and crash bugs. Our results suggest that NoREC is effective general and requires little implementation effort which makes the technique widely applicable in practice.;
Proceedings of the 8th International Conference on Software and Information Engineering;With the increasing popularity of embedded devices ARM is becoming the dominant architecture for them. In the meanwhile there is a pressing need to perform security assessments for these devices. Due to different types of peripherals it is challenging to dynamically run the firmware of these devices in an emulated environment. Therefore the static analysis is still commonly used. Existing work usually leverages off-the-shelf tools to disassemble stripped ARM binaries and (implicitly) assume that reliable disassembling binaries and function recognition are solved problems. However whether this assumption really holds is unknown. In this paper we conduct the first comprehensive study on ARM disassembly tools. Specifically we build 1896 ARM binaries (including 248 obfuscated ones) with different compilers compiling options and obfuscation methods. We then evaluate them using eight state-of-the-art ARM disassembly tools (including both commercial and noncommercial ones) on their capabilities to locate instructions and function boundaries. These two are fundamental ones which are leveraged to build other primitives. Our work reveals some observations that have not been systematically summarized and/or confirmed. For instance we find that the existence of both ARM and Thumb instruction sets and the reuse of the BL instruction for both function calls and branches bring serious challenges to disassembly tools. Our evaluation sheds light on the limitations of state-of-the-art disassembly tools and points out potential directions for improvement. To engage the community we release the data set and the related scripts at https://github.com/valour01/arm_disasssembler_study.;
Proceedings of the International Conference on Mobile Software Engineering and Systems;In the realm of Software Engineering (SE) automation has become a tangible reality. Artificial Intelligence (AI) has suc-cessfully addressed challenges in project management mod-eling testing and development. Among the latest innova-tions is ChatGPT an ML-infused chatbot capable of gen-erating programming codes and software testing strategies. Although there is speculation that AI-based computation can boost productivity and even substitute software engineers in software development empirical evidence supporting such claims is lacking. Moreover questions remain about their po-tential to address overlooked evaluation metrics like energy efficiency vulnerability fairness (i.e. human bias) and safety. This paper probes into these issues with an empirical study comparing ChatGPT with both novice and expert program-mers using LeetCode contest problems. The investigation focuses on performance and memory-efficiency while also acknowledging the need for a broader assessment of non-functional requirements. The results suggest that ChatGPT is better than beginners at solving easy and medium prob-lems but it is not yet proven to beat expert programmers. This paper posits that a comprehensive comparison of soft-ware engineers and AI-based solutions considering various evaluation criteria is pivotal in fostering human-machine collaboration enhancing the reliability of AI-based meth-ods and understanding task suitability for humans or AI. Furthermore it facilitates the effective implementation of co-operative work structures and human-in-the-loop processes.;
Proceedings of the Eighth International Workshop on Search-Based Software Testing;Popular Android applications undergo frequent releases. Ensuring functional testing of the new features as well as regression testing of the previous functionality are time-consuming and error-prone. Thus there is a need for a tool that eases the testing efforts as well as saves the overall time of the product release cycle. In this work we present QADroid the first activity- and event-aware regression selection tool for Android apps. Salient features of QADroid are: (i) a richer change-set analyzer that covers code as well as non-code components for regression (ii) it presents a pictorial representation of the appâ€™s functioning and (iii) it displays the regression points in the app as a mapping between activities to user-elements to events. Features (ii) and (iii) help the testers in understanding the technical findings better. We evaluated QADroid on 1105 releases of 50 open source Android projects. The results show that QADroid reduced the activity selection by 58% and event selection by 74% compared to the traditional way of exhaustive testing of all activities and events thereby significantly reducing the manual testing efforts.;
Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice;Random program generation â€” fuzzing â€” is an effective technique for discovering bugs in compilers but successful fuzzers require extensive development effort for every language supported by the compiler and often leave parts of the language space untested. We introduce DeepSmith a novel machine learning approach to accelerating compiler validation through the inference of generative models for compiler inputs. Our approach infers a learned model of the structure of real world code based on a large corpus of open source code. Then it uses the model to automatically generate tens of thousands of realistic programs. Finally we apply established differential testing methodologies on them to expose bugs in compilers. We apply our approach to the OpenCL programming language automatically exposing bugs with little effort on our side. In 1000 hours of automated testing of commercial and open source compilers we discover bugs in all of them submitting 67 bug reports. Our test cases are on average two orders of magnitude smaller than the state-of-the-art require 3.03\texttimes{;
Proceedings of the 12th Asia-Pacific Symposium on Internetware;Mobile apps have been developed with the aim of attracting a large and diverse number of users. An impediment factor especially for the Android platform is a large number of hardware and software configurations available in the market so app developers face the challenge of producing a highly compatible app. For compatibility testing an app can be tested in a subset of devices that sufficiently covers the characteristics of devices adopted by users. Moreover this subset needs to be extracted from up-to-date sources since new devices and APIs are frequently introduced in the market while others are deprecated. This paper presents an always-updated app-specific approach called DeSeCT for mobile Device Selection for Compatibility Testing. Our approach is divided into the following steps: first it crawls the Web to obtain an updated list of devices second attributes of the app under test are used to filter unwanted mobile devices and a multiobjective genetic algorithm is employed to tailor a feature-coverage optimized set of mobile devices. The results provide evidence that DeSeCT can produce a better selection of mobile devices for compatibility testing in comparison with the state-of-the-art. DeSeCT avoids the selection of approximately 15% to 18% of unwanted devices.;
Proceedings of the 37th Annual Computer Security Applications Conference;The heavy fragmentation of the Android ecosystem has led to severe compatibility issues with apps including those that crash at runtime or cannot be installed on certain devices but work well on other devices. To address this problem various approaches have been proposed to detect and fix compatibility issues automatically. However these all come with various limitations on fixing the compatibility issues e.g. can only fix one specific type of issues cannot deal with multi-invocation issues in a single line and issues in released apps. To overcome these limitations we propose a generic approach that aims at fixing more types of compatibility issues in released Android apps. To this end our prototype tool RepairDroid provides a generic app patch description language for users to create fix templates for compatibility issues. The created templates will then be leveraged by RepairDroid to automatically fix the corresponding issue at the bytecode level (e.g. right before users install the app). RepairDroid can support template creations for OS-induced device-specific and inter-callback compatibility issues detected by three state-of-the-art approaches. Our experimental results show that RepairDroid can fix 7660 out of 8976 compatibility issues in 1000 randomly selected Google Play apps. RepairDroid is generic to configure new compatibility issues and outperforms the state-of-the-art on effectively repairing compatibility issues in released Android apps.;
Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation;Much research on software testing makes an implicit assumption that test failures are deterministic such that they always witness the presence of the same defects. However this assumption is not always true because some test failures are due to so-called flaky tests i.e. tests with non-deterministic outcomes. To help testing researchers better investigate flakiness we introduce a test flakiness assessment and experimentation platform called FlakiMe. FlakiMe supports the seeding of a (controllable) degree of flakiness into the behaviour of a given test suite. Thereby FlakiMe equips researchers with ways to investigate the impact of test flakiness on their techniques under laboratory-controlled conditions. To demonstrate the application of FlakiMe we use it to assess the impact of flakiness on mutation testing and program repair (the PRAPR and ARJA methods). These results indicate that a 10% flakiness is sufficient to affect the mutation score but the effect size is modest (2% - 5% ) while it reduces the number of patches produced for repair by 20% up to 100% of repair problems a devastating impact on this application of testing. Our experiments with FlakiMe demonstrate that flakiness affects different testing applications in very different ways thereby motivating the need for a laboratory-controllable flakiness impact assessment platform and approach such as FlakiMe.;
Proceedings of the 5th ACM International Workshop on Verification and MOnitoring at Runtime EXecution;Built on the WeChat social platform WeChat Mini-Programs are widely used by more than 400 million users every day. Consequently the reliability of Mini-Programs is particularly crucial. However WeChat Mini-Programs suffer from various bugs related to execution environment lifecycle management asynchronous mechanism etc. These bugs have seriously affected users' experience and caused serious impacts.In this paper we conduct the first empirical study on 83 WeChat Mini-Program bugs and perform an in-depth analysis of their root causes impacts and fixes. From this study we obtain many interesting findings that can open up new research directions for combating WeChat Mini-Program bugs. Based on the bug patterns found in our study we further develop WeDetector to detect WeChat Mini-Program bugs. Our evaluation on 25 real-world Mini-Programs has found 11 previously unknown bugs and 7 of them have been confirmed by developers.;
Proceedings of the 26th International Conference on Evaluation and Assessment in Software Engineering;Program repair techniques attempt to fix programs by looking for patches within a search space of fix candidates. These techniques require a specification of the program to be repaired used as an acceptance criterion for fix candidates that often also plays an important role in guiding some search processes. Most tools use tests as specifications which constitutes a risk since the incompleteness of tests as specifications may lead one to obtain spurious repairs that pass all tests but are in fact incorrect. This problem has been identified by various researchers raising concerns about the validity of program fixes. More thorough studies have been proposed using different sets of tests for fix validation and resorting to manual inspection showing that while tools reduce their program fixing rate they are still able to repair a significant number of cases.In this paper we perform a different analysis of the suitability of tests as acceptance criteria for automated program fixes by checking patches produced by automated repair tools using a bug-finding tool as opposed to previous works that used tests or manual inspections. We develop a number of experiments in which faulty programs from a known benchmark are fed to the program repair tools GenProg Angelix AutoFix and Nopol using test suites of varying quality and extension including those accompanying the benchmark. We then check the produced patches against formal specifications using a bug-finding tool. Our results show that in general automated program repair tools are significantly more likely to accept a spurious program fix than producing an actual one in the studied scenarios.;
Proceedings of the 13th International Workshop on Automation of Software Test;For coverage-guided fuzzers many of their adopted seeds are usually underused by exploring limited program states since essentially all their executions have to abide by rigorous program dependencies while only limited seeds are capable of accessing dependencies. Moreover even when iteratively executing such limited seeds the fuzzers have to repeatedly access the covered program states before uncovering new states. Such facts indicate that exploration power on program states of seeds has not been sufficiently leveraged by the existing coverage-guided fuzzing strategies. To tackle these issues we propose a coverage-guided fuzzer namely MirageFuzz to mitigate the program dependencies when executing seeds for enhancing their exploration power on program states. Specifically MirageFuzz first creates a â€œphantomâ€ program of the target program by reducing its program dependencies corresponding to conditional statements while retaining their original semantics. Accordingly MirageFuzz performs dual fuzzing i.e. the source fuzzing to fuzz the original program and the phantom fuzzing to fuzz the phantom program simultaneously. Then MirageFuzz applies the taint-based mutation mechanism to generate a new seed by updating the target conditional statement of a given seed from the source fuzzing with the corresponding condition value derived by the phantom fuzzing. To evaluate the effectiveness of MirageFuzz we build a benchmark suite with 18 projects commonly adopted by recent fuzzing papers and select seven open-source fuzzers as baselines for performance comparison with MirageFuzz. The experiment results suggest that MirageFuzz outperforms our baseline fuzzers from 13.42% to 77.96% averagely. Furthermore MirageFuzz exposes 29 previously unknown bugs where 4 of them have been confirmed and 3 have been fixed by the corresponding developers.;
Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Research has produced many approaches to automatically locate explain and repair software bugs. But do these approaches relate to the way practitioners actually locate understand and fix bugs? To help answer this question we have collected a dataset named DBGBENCH --- the correct fault locations bug diagnoses and software patches of 27 real errors in open-source C projects that were consolidated from hundreds of debugging sessions of professional software engineers. Moreover we shed light on the entire debugging process from constructing a hypothesis to submitting a patch and how debugging time difficulty and strategies vary across practitioners and types of errors. Most notably DBGBENCH can serve as reality check for novel automated debugging and repair techniques.;
Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering;To process massive quantities of data developers leverage data-intensive scalable computing (DISC) systems in the cloud such as Google's MapReduce Apache Hadoop and Apache Spark. In terms of debugging DISC systems support post-mortem log analysis but do not provide interactive debugging features in realtime. This tool demonstration paper showcases a set of concrete usecases on how BigDebug can help debug Big Data Applications by providing interactive realtime debug primitives. To emulate interactive step-wise debugging without reducing throughput BigDebug provides simulated breakpoints to enable a user to inspect a program without actually pausing the entire computation. To minimize unnecessary communication and data transfer BigDebug provides on-demand watchpoints that enable a user to retrieve intermediate data using a guard and transfer the selected data on demand. To support systematic and efficient trial-and-error debugging BigDebug also enables users to change program logic in response to an error at runtime and replay the execution from that step. BigDebug is available for download at http://web.cs.ucla.edu/~miryung/software.html;
Proceedings of the 2020 Asia Service Sciences and Software Engineering Conference;We report on the results of the seventh edition of the JUnit tool competition. This year four tools were executed on a benchmark with (i) new classes selected from real-world software projects and (ii) challenging classes from the previous edition. We use Randoop and manual test suites from the projects as baselines. Given the interesting findings of last year we analyzed the effectiveness of the combined test suites generated by all competing tools and compared results are confronted with the manual test suites of the projects as well as those generated by the competing tools. This paper describes our methodology and the results highlight challenges faced during the contest.;
Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation;The advent of Persistent Memory (PM) opens the door to novel application designs that explore its performance and durability benefits. However there is no free lunch and to program PM applications developers need to be aware of potential inconsistent application state upon machine or application crashes. To overcome this difficulty several tools have been proposed to detect the presence of the so-called crash-consistency bugs. While these are effective in detecting a variety of bugs they present several key limitations namely relying on application-specific semantics requiring the programmer to manually annotate the program or modify the PM library and relying on techniques with poor scalability making them impractical for production code.In this paper we introduce Mumak a tool that detects bugs in PM applications in an efficient and black-box manner. Our key insight to reduce the search space is to use a two-pronged approach with a first pass that is highly efficient by focusing only on key error-prone code points without exhaustively testing all possible persistence orderings and a second pass based on heuristics that try to compensate the shortcomings of the initial approach. Furthermore we avoid application-specific knowledge or annotations by relying on the application's own recovery procedure as an (imperfect) consistency oracle. Our experimental results with different applications and libraries show that Mumak has bug coverage on par with the other state-of-the-art tools while being up to 25\texttimes{;
Proceedings of the 5th International Conference on Algorithms Computing and Systems;Many software bugs are reported manually particularly bugs that manifest themselves visually in the user interface. End-users typically report these bugs via app reviewing websites issue trackers or in-app built-in bug reporting tools if available. While these systems have various features that facilitate bug reporting (e.g. textual templates or forms) they often provide limited guidance concrete feedback or quality verification to end-users who are often inexperienced at reporting bugs and submit low-quality bug reports that lead to excessive developer effort in bug report management tasks.  We propose an interactive bug reporting system for end-users (Burt) implemented as a task-oriented chatbot. Unlike existing bug reporting systems Burt provides guided reporting of essential bug report elements (i.e. the observed behavior expected behavior and steps to reproduce the bug) instant quality verification and graphical suggestions for these elements. We implemented a version of Burt for Android and conducted an empirical evaluation study with end-users who reported 12 bugs from six Android apps studied in prior work. The reporters found that Burtâ€™s guidance and automated suggestions/clarifications are useful and Burt is easy to use. We found that Burt reports contain higher-quality information than reports collected via a template-based bug reporting system. Improvements to Burt informed by the reporters include support for various wordings to describe bug report elements and improved quality verification. Our work marks an important paradigm shift from static to interactive bug reporting for end-users.;
Proceedings of the 7th International Workshop on Metamorphic Testing;In this work we investigate the practice of patch construction in the Linux kernel development focusing on the differences between three patching processes: (1) patches crafted entirely manually to fix bugs (2) those that are derived from warnings of bug detection tools and (3) those that are automatically generated based on fix patterns. With this study we provide to the research community concrete insights on the practice of patching as well as how the development community is currently embracing research and commercial patching tools to improve productivity in repair. The result of our study shows that tool-supported patches are increasingly adopted by the developer community while manually-written patches are accepted more quickly. Patch application tools enable developers to remain committed to contributing patches to the code base. Our findings also include that in actual development processes patches generally implement several change operations spread over the code even for patches fixing warnings by bug detection tools. Finally this study has shown that there is an opportunity to directly leverage the output of bug detection tools to readily generate patches that are appropriate for fixing the problem and that are consistent with manually-written patches.;
Proceedings of the 5th International Workshop on Software Mining;Software bugs cost time money and lives. They drive software research and development efforts and are central to modern software engineering. Yet we lack a clear and general definition of what bugs are. Some bugs are defects clearly defined as failures to meet some requirement or specification. However there are many forms of undesirable program behaviour that are completely compatible with a typical program's specification.In this paper we argue that the lack of a criterion for identifying non-defect bugs is hampering the development of tools that find and fix bugs. We propose such a criterion based on the idea of wasted effort discuss how bugs that meet our definition of software ticks can complement defects and sketch how our definition can help guide future work on software tools.;
Proceedings of the 2017 International Conference on Information Technology;Metamorphic testing has been shown to be a simple yet effective technique in addressing the quality assurance of applications that do not have test oracles i.e. for which it is difficult or impossible to know what the correct output should be for arbitrary input. In metamorphic testing existing test case input is modified to produce new test cases in such a manner that when given the new input the application should produce an output that can easily be computed based on the original output. That is if input x produces output f(x) then we create input x' such that we can predict f(x') based on f(x) if the application does not produce the expected output then a defect must exist and either f(x) or f(x') (or both) is wrong.In practice however metamorphic testing can be a manually intensive technique for all but the simplest cases. The transformation of input data can be laborious for large data sets or practically impossible for input that is not in human-readable format. Similarly comparing the outputs can be error-prone for large result sets especially when slight variations in the results are not actually indicative of errors (i.e. are false positives) for instance when there is non-determinism in the application and multiple outputs can be considered correct.In this paper we present an approach called Automated Metamorphic System Testing. This involves the automation of metamorphic testing at the system level by checking that the metamorphic properties of the entire application hold after its execution. The tester is able to easily set up and conduct metamorphic tests with little manual intervention and testing can continue in the field with minimal impact on the user. Additionally we present an approach called Heuristic Metamorphic Testing which seeks to reduce false positives and address some cases of non-determinism. We also describe an implementation framework called Amsterdam and present the results of empirical studies in which we demonstrate the effectiveness of the technique on real-world programs without test oracles.;
Proceedings of the 2013 International Symposium on Memory Management;The rapid expansion of the Android ecosystem is accompanied by continuing diversification of platforms and devices resulting in increasing incompatibility issues which damage user experiences and impede app development productivity. In this paper we conducted a large-scale longitudinal study of compatibility issues in 62894 benign apps developed in the past eight years to understand the symptoms and causes of these issues. We further investigated the incompatibilities that are actually exercised at runtime through the system logs and execution traces of 15045 apps. Our study revealed that among others (1) compatibility issues were prevalent and persistent at both installation and run time with greater prevalence of run-time incompatibilities (2) there were no certain Android versions that consistently saw more or less app incompatibilities than others (3) installation-time incompatibilities were strongly correlated with the minSdkVersion specified in apps while run-time incompatibilities were most significantly correlated with the underlying platformâ€™s API level and (4) installation-time incompatibilities were mostly due to appsâ€™ use of architecture-incompatible native libraries while run-time incompatibilities were mostly due to API changes during SDK evolution. We offered further insights into app incompatibilities as well as recommendations on dealing with the issues for bother developers and end users of Android apps.;
Proceedings of the 11th International Workshop on Automation of Software Test;Random testing has the benefit of being simple to implement. However if left unmanaged random testing can easily exhaust the allocated computation time without being effective. In a previous work we extended an automated random testing tool called T3 with a budget management algorithm. Given a time budget and a target class with multiple methods to test the algorithm tries to spread the budget over the methods by dividing it into multiple budget slices. While this guarantees a certain measure of fairness the algorithm was programmed towards using up the budget. This does deliver extra coverage but beyond a certain point this becomes quite costly. In an attempt to improve this we consider an austere budgeting policy as an alternative. While this work is still in progress we decided to participate in the SBST Unit Testing Tool Competition 2019 to obtain insight on the performance of the policy. This paper discussed its results.;
Proceedings of the SC '23 Workshops of The International Conference on High Performance Computing Network Storage and Analysis;Reproducibility is the ability of recreating identical binaries under pre-defined build environments. Due to the need of quality assurance and the benefit of better detecting attacks against build environments the practice of reproducible builds has gained popularity in many open-source software repositories such as Debian and Bitcoin. However identifying the unreproducible issues remains a labour intensive and time consuming challenge because of the lacking of information to guide the search and the diversity of the causes that may lead to the unreproducible binaries.In this paper we propose an automated framework called RepLoc to localize the problematic files for unreproducible builds. RepLoc features a query augmentation component that utilizes the information extracted from the build logs and a heuristic rule-based filtering component that narrows the search scope. By integrating the two components with a weighted file ranking module RepLoc is able to automatically produce a ranked list of files that are helpful in locating the problematic files for the unreproducible builds. We have implemented a prototype and conducted extensive experiments over 671 real-world unreproducible Debian packages in four different categories. By considering the topmost ranked file only RepLoc achieves an accuracy rate of 47.09%. If we expand our examination to the top ten ranked files in the list produced by RepLoc the accuracy rate becomes 79.28%. Considering that there are hundreds of source code scripts Makefiles etc. in a package RepLoc significantly reduces the scope of localizing problematic files. Moreover with the help of RepLoc we successfully identified and fixed six new unreproducible packages from Debian and Guix.;
Proceedings of the Brazilian Symposium on Multimedia and the Web;Automated testing is considered an essential process for ensuring software quality. However writing and maintaining high-quality test code is challenging and frequently considered of secondary importance. For production code many open source and industrial software projects employ code review a well-established software quality practice but the question remains whether and how code review is also used for ensuring the quality of test code. The aim of this research is to answer this question and to increase our understanding of what developers think and do when it comes to reviewing test code. We conducted both quantitative and qualitative methods to analyze more than 300000 code reviews and interviewed 12 developers about how they review test files. This work resulted in an overview of current code reviewing practices a set of identified obstacles limiting the review of test code and a set of issues that developers would like to see improved in code review tools. The study reveals that reviewing test files is very different from reviewing production files and that the navigation within the review itself is one of the main issues developers currently face. Based on our findings we propose a series of recommendations and suggestions for the design of tools and future research.;
Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering;Software testing is an integral part of modern software development. However test runs can produce thousands of lines of logged output that make it difficult to find the cause of a fault in the logs. This problem is exacerbated by environmental failures that distract from product faults. In this paper we present techniques with the goal of capturing the maximum number of product faults while flagging the minimum number of log lines for inspection.We observe that the location of a fault in a log should be contained in the lines of a failing test log. In contrast a passing test log should not contain the lines related to a failure. Lines that occur in both a passing and failing log introduce noise when attempting to find the fault in a failing log. We introduce an approach where we remove the lines that occur in the passing log from the failing log.After removing these lines we use information retrieval techniques to flag the most probable lines for investigation. We modify TF-IDF to identify the most relevant log lines related to past product failures. We then vectorize the logs and develop an exclusive version of KNN to identify which logs are likely to lead to product faults and which lines are the most probable indication of the failure.Our best approach LogFaultFlagger finds 89% of the total faults and flags less than 1% of the total failed log lines for inspection. LogFaultFlagger drastically outperforms the previous work cam. We implemented LogFaultFlagger as a tool at Ericsson where it presents fault prediction summaries to base station testers.;
Proceedings of the 19th ACM Workshop on Hot Topics in Networks;More and more companies use static analysis to perform regular code reviews to detect security vulnerabilities in their code configuring them to detect various types of bugs and vulnerabilities such as the SANS top 25 or the OWASP top 10. For such analyses to be as precise as possible they must be adapted to the code base they scan. The particular challenge we address in this paper is to provide analyses with the correct security-relevant methods (Srm): sources sinks etc. We present SWAN a fully-automated machine-learning approach to detect sources sinks validators and authentication methods for Java programs. SWAN further classifies the Srm into specific vulnerability classes of the SANS top 25. To further adapt the lists detected by SWAN to the code base and to improve its precision we also introduce SWANAssist an extension to SWAN that allows analysis users to refine the classifications. On twelve popular Java frameworks SWAN achieves an average precision of 0.826 which is better or comparable to existing approaches. Our experiments show that SWANAssist requires a relatively low effort from the developer to significantly improve its precision.;
Proceedings of the Sixth Workshop on Data Management for End-To-End Machine Learning;Grey-box fuzzing is an evolutionary process which maintains and evolves a population of test cases with the help of a fitness function. Fitness functions used by current grey-box fuzzers are not informative in that they cannot distinguish different program executions as long as those executions achieve the same coverage. The problem is that current fitness functions only consider a union of data but not their combination. As such fuzzers often get stuck in a local optimum during their search. In this paper we introduce Ankou the first grey-box fuzzer that recognizes different combinations of execution information and present several scalability challenges encountered while designing and implementing Ankou. Our experimental results show that Ankou is 1.94\texttimes{;
Proceedings of the 2012 Joint EDBT/ICDT Workshops;Concolic testing is popular in unit testing because it can detect bugs quickly in a relatively small search space. But in system-level testing it suffers from the symbolic path explosion and often misses bugs. To resolve this problem we have developed a focused compositional concolic testing technique FOCAL for effective bug detection. Focusing on a target unit failure v (a crash or an assert violation) detected by concolic unit testing FOCAL generates a system-level test input that validates v. This test input is obtained by building and solving symbolic path formulas that represent system-level executions raising v. FOCAL builds such formulas by combining function summaries one by one backward from a function that raised v to main. If a function summary Ï†a of function a conflicts with the summaries of the other functions FOCAL refines Ï†a to Ï†aâ€² by applying a refining constraint learned from the conflict. FOCAL showed high system-level bug detection ability by detecting 71 out of the 100 real-world target bugs in the SIR benchmark while other relevant cutting edge techniques (i.e. AFL-fast KATCH Mix-CCBSE) detected at most 40 bugs. Also FOCAL detected 13 new crash bugs in popular file parsing programs.;
Proceedings of the 20th ACM SIGPLAN International Conference on Managed Programming Languages and Runtimes;"There is a dramatically increasing interest in the quality assurance for DNN-based systems in the software engineering community. An emerging hot topic in this direction is structural coverage criteria for testing neural networks which are inspired by coverage metrics used in conventional software testing. In this short paper we argue that these criteria could be misleading because of the fundamental differences between neural networks and human written programs. Our preliminary exploration shows that (1) adversarial examples are pervasively distributed in the finely divided space defined by such coverage criteria while available natural samples are very sparse and as a consequence (2) previously reported fault-detection capabilities"" conjectured from high coverage testing are more likely due to the adversary-oriented search but not the real ""high"" coverage.""";
Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results;SMT solvers are at the basis of many applications such as program verification program synthesis and test case generation. For all these applications to provide reliable results SMT solvers must answer queries correctly. However since they are complex highly-optimized software systems ensuring their correctness is challenging. In particular state-of-the-art testing techniques do not reliably detect when an SMT solver is unsound.In this paper we present an automatic approach for generating test cases that reveal soundness errors in the implementations of string solvers as well as potential completeness and performance issues. We synthesize input formulas that are satisfiable or unsatisfiable by construction and use this ground truth as test oracle. We automatically apply satisfiability-preserving transformations to generate increasingly-complex formulas which allows us to detect many errors with simple inputs and thus facilitates debugging.The experimental evaluation shows that our technique effectively reveals bugs in the implementation of widely-used SMT solvers and applies also to other types of solvers such as automata-based solvers. We focus on strings here but our approach carries over to other theories and their combinations.;
Managing Large-Scale Systems via the Analysis of System Logs and the Application of Machine Learning Techniques;Today machine learning (ML) models are increasingly applied in decision making. This induces an urgent need for quality assurance of ML models with respect to (often domain-dependent) requirements. Monotonicity is one such requirement. It specifies a software as ''learned'' by an ML algorithm to give an increasing prediction with the increase of some attribute values. While there exist multiple ML algorithms for ensuring monotonicity of the generated model approaches for checking monotonicity in particular of black-box models are largely lacking.  In this work we propose verification-based testing of monotonicity i.e. the formal computation of test inputs on a white-box model via verification technology and the automatic inference of this approximating white-box model from the black-box model under test. On the white-box model the space of test inputs can be systematically explored by a directed computation of test cases. The empirical evaluation on 90 black-box models shows that verification-based testing can outperform adaptive random testing as well as property-based techniques with respect to effectiveness and efficiency.;
Proceedings of the 2020 3rd International Conference on Big Data and Education;Automated Program Repair (APR) aims to automatically fix bugs in the source code. Recently with advances in Deep Learning (DL) field there has been an increase of Neural Program Repair (NPR) studies that use neural networks to model the patch-generation process. NPR approaches have a significant benefit in applicability over prior APR techniques because they do not require any specifications (e.g. a test suite) when generating patches. For this reason NPR has recently become a popular research topic. In this paper We undertake a literature review of latest NPR systems to help interested readers understand advancements in this emerging field. We begin by introducing background information of NPR. Next to make the various NPR systems more understandable we split them into a four-phase pipeline and discuss various design choices for each phase. To investigate the motivations of different design choices We further highlight a number of challenges and summarize corresponding solutions adopted by existing NPR systems. Finally we suggest some intriguing directions for the future research.;
Proceedings of the 6th International Conference on Software and Computer Applications;With the rise in the growth of the software industry it is essential to identify software defects in earlier stages to save costs and improve the efficiency of the software development lifecycle process. We have devised a hybrid software defect prediction (SDP) model that integrates Binary Particle Swarm Optimization (Binary PSO) Synthetic Minority Oversampling Technique (SMOTE) and Artificial Neural Network (ANN). BPSO is applied as a wrapper feature selection process utilizing AUC as a fitness function SMOTE handles the dataset imbalance and ANN is used as a classification algorithm for predicting software defects. We analyze the proposed BPSO-SMOTE-ANN model's predictive capability using the AUC and G-mean performance metrics. The proposed hybrid model is found helpful in predicting software defects. The statistical results suggest the enhanced performance of the proposed hybrid model concerning AUC and G-mean values. Also the hybrid model was found to be competitive with other machine learning(ML) algorithms in determining software defects.;
Proceedings of the 2023 6th International Conference on Software Engineering and Information Management;Chemical reaction networks (CRNs) are an emerging distributed computational paradigm where programs are encoded as a set of abstract chemical reactions. CRNs can be compiled into DNA strands which perform the computations in vitro creating a foundation for intelligent nanodevices. Recent research proposed a software testing framework for stochastic CRN programs in simulation however it relies on existing program specifications. In practice specifications are often lacking and when they do exist transforming them into test cases is time-intensive and can be error prone. In this work we propose an inference technique called ChemFlow which extracts 3 types of invariants from an existing CRN model. The extracted invariants can then be used for test generation or model validation against program implementations. We applied ChemFlow to 13 CRN programs ranging from toy examples to real biological models with hundreds of reactions. We find that the invariants provide strong fault detection and often exhibit less flakiness than specification derived tests. In the biological models we showed invariants to developers and they confirmed that some of these point to parts of the model that are biologically incorrect or incomplete suggesting we may be able to use ChemFlow to improve model quality.;
Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture;Concurrency bugs are extremely difficult to detect. Recently several dynamic techniques achieve sound analysis. M2 is even complete for two threads. It is designed to decide whether two events can occur consecutively. However real-world concurrency bugs can involve more events and threads. Some can occur when the order of two or more events can be exchanged even if they occur not consecutively. We propose a new technique SeqCheck to soundly decide whether a sequence of events can occur in a specified order. The ordered sequence represents a potential concurrency bug. And several known forms of concurrency bugs can be easily encoded into event sequences where each represents a way that the bug can occur. To achieve it SeqCheck explicitly analyzes branch events and includes a set of efficient algorithms. We show that SeqCheck is sound and it is also complete on traces of two threads.  We have implemented SeqCheck to detect three types of concurrency bugs and evaluated it on 51 Java benchmarks producing up to billions of events. Compared with M2 and other three recent sound race detectors SeqCheck detected 333 races in ~30 minutes while others detected from 130 to 285 races in ~6 to ~12 hours. SeqCheck detected 20 deadlocks in ~6 seconds. This is only one less than Dirk but Dirk spent more than one hour. SeqCheck also detected 30 atomicity violations in ~20 minutes. The evaluation shows SeqCheck can significantly outperform existing concurrency bug detectors.;
Proceedings of the 36th Annual Computer Security Applications Conference;Microservice is an architecture style that decomposes complex software into loosely coupled services which could be developed maintained and deployed independently. In recent years the microservice architecture has been drawing more and more attention from both industrial and academic communities. Many companies such as Google Netflix Amazon and IBM have applied microservice architecture in their projects. Researchers have also studied microservices in different directions such as microservices extraction fault localization and code quality analysis. The recent work has presented cross-service code clones are prevalent in microservice projects and have caused considerable co-modifications among different services which undermines the independence of microservices. But there is no systematic study to reveal the underlying reasons for the emergence of such clones. In this paper we first build a dataset consisting of 2722 pairs of cross-service clones from 22 open-source microservice projects. Then we manually inspect the implementations of files and methods involved in cross-service clones to understand why the clones are introduced. In the file-level analysis we categorize files into three types: DPFile (Data-processing File) DRFile (Data-related File) and DIFile (Data-irrelevant File) and have presented that DRFiles are more likely to encounter cross-service clones. For each type of files we further classify them into specific cases. Each case describes the characteristics of involved files and why the clones happen. In the method-level analysis we dig information from the code of involved methods. On this basis we propose a catalog containing 4 categories with 10 subcategories of method-level implementations that result in cross-service clones. We believe our analyses have provided the fundamental knowledge of cross-service clones which can help developers better manage and resolve such clones in microservice projects.;
Proceedings of the 2nd International Workshop on Software Engineering Education for Millennials;Test suites should test exceptional behavior to detect faults in error-handling code. However manually-written test suites tend to neglect exceptional behavior. Automatically-generated test suites on the other hand lack test oracles that verify whether runtime exceptions are the expected behavior of the code under test.  This paper proposes a technique that automatically creates test oracles for exceptional behaviors from Javadoc comments. The technique uses a combination of natural language processing and run-time instrumentation. Our implementation Toradocu can be combined with a test input generation tool. Our experimental evaluation shows that Toradocu improves the fault-finding effectiveness of EvoSuite and Randoop test suites by 8% and 16% respectively and reduces EvoSuiteâ€™s false positives by 33%.;
Proceedings of the 32nd Annual International Conference on Computer Science and Software Engineering;Despite the trend of incorporating heterogeneity and specialization in hardware the development of heterogeneous applications is limited to a handful of engineers with deep hardware expertise. We propose HeteroGen that takes C/C++ code as input and automatically generates an HLS version with test behavior preservation and better performance. Key to the success of HeteroGen is adapting the idea of search-based program repair to the heterogeneous computing domain while addressing two technical challenges. First the turn-around time of HLS compilation and simulation is much longer than the usual C/C++ compilation and execution time therefore HeteroGen applies pattern-oriented program edits guided by common fix patterns and their dependences. Second behavior and performance checking requires testing but test cases are often unavailable. Thus HeteroGen auto-generates test inputs suitable for checking C to HLS-C conversion errors while providing high branch coverage for the original C code.  An evaluation of HeteroGen shows that it produces an HLS-compatible version for nine out of ten real-world heterogeneous applications fully automatically applying up to 438 lines of edits to produce an HLS version 1.63x faster than the original version.;
Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems;The correctness of compilers is instrumental in the safety and reliability of other software systems as bugs in compilers can produce executables that do not reflect the intent of programmers. Such errors are difficult to identify and debug. Random test program generators are commonly used in testing compilers and they have been effective in uncovering bugs. However the problem of guiding these test generators to produce test programs that are more likely to find bugs remains challenging.In this paper we use the code snippets in the bug reports to guide the test generation. The main idea of this work is to extract insights from the bug reports about the language features that are more prone to inadequate implementation and using the insights to guide the test generators. We use the GCC C compiler to evaluate the effectiveness of this approach. In particular we first cluster the test programs in the GCC bugs reports based on their features. We then use the centroids of the clusters to compute configurations for Csmith a popular test generator for C compilers. We evaluated this approach on eight versions of GCC and found that our approach provides higher coverage and triggers more miscompilation failures than the state-of-the-art test generation techniques for GCC.;
Proceedings of the Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems;In languages like C out-of-bounds array accesses lead to security vulnerabilities and crashes. Even in managed languages like Java which check array bounds at run time out-of-bounds accesses cause exceptions that terminate the program.  We present a lightweight type system that certifies at compile time that array accesses in the program are in-bounds. The type system consists of several cooperating hierarchies of dependent types specialized to the domain of array bounds-checking. Programmers write type annotations at procedure boundaries allowing modular verification at a cost that scales linearly with program size.  We implemented our type system for Java in a tool called the Index Checker. We evaluated the Index Checker on over 100000 lines of open-source code and discovered array access errors even in well-tested industrial projects such as Google Guava.;
Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design;When a new bug report is received developers usually need to reproduce the bug and perform code reviews to find the cause a process that can be tedious and time consuming. A tool for ranking all the source files of a project with respect to how likely they are to contain the cause of the bug would enable developers to narrow down their search and potentially could lead to a substantial increase in productivity. This paper introduces an adaptive ranking approach that leverages domain knowledge through functional decompositions of source code files into methods API descriptions of library components used in the code the bug-fixing history and the code change history. Given a bug report the ranking score of each source file is computed as a weighted combination of an array of features encoding domain knowledge where the weights are trained automatically on previously solved bug reports using a learning-to-rank technique. We evaluated our system on six large scale open source Java projects using the before-fix version of the project for every bug report. The experimental results show that the newly introduced learning-to-rank approach significantly outperforms two recent state-of-the-art methods in recommending relevant files for bug reports. In particular our method makes correct recommendations within the top 10 ranked source files for over 70% of the bug reports in the Eclipse Platform and Tomcat projects.;
Proceedings of the 2011 International Symposium on Software Testing and Analysis;"We present Wolverine an integrated Debug-Repair environment for heap manipulating programs. Wolverine facilitates stepping through a concrete program execution provides visualizations of the abstract program states (as box-and-arrow diagrams) and integrates a novel proof-directed repair algorithm to synthesize repair patches. To provide a seamless environment Wolverine supports hot-patching"" of the generated repair patches enabling the programmer to continue the debug session without requiring an abort-compile-debug cycle. We also propose new debug-repair possibilities ""specification refinement"" and ""specification slicing"" made possible by Wolverine. We evaluate our framework on 1600 buggy programs (generated using fault injection) on a variety of data-structures like singly doubly and circular linked-lists Binary Search Trees AVL trees Red-Black trees and Splay trees Wolverine could repair all the buggy instances within reasonable time (less than 5 sec in most cases). We also evaluate Wolverine on 247 (buggy) student submissions Wolverine could repair more than 80% of programs where the student had made a reasonable attempt.""";
Proceedings of the 1st International Workshop on Mining Software Repositories Applications for Privacy and Security;Mobile apps are indispensable for peopleâ€™s daily life. Complementing with automated GUI testing manual testing is the last line of defence for app quality. However the repeated actions and easily missing of functionalities make manual testing time-consuming and inefficient. Inspired by the game candy crush with flashy candies as hint moves for players we propose an approach named NaviDroid for navigating testers via highlighted next operations for more effective and efficient testing. Within NaviDroid we construct an enriched state transition graph with the triggering actions as the edges for two involved states. Based on it we utilize the dynamic programming algorithm to plan the exploration path and augment the GUI with visualized hints for testers to quickly explore untested activities and avoid duplicate explorations. The automated experiments demonstrate the high coverage and efficient path planning of NaviDroid and a user study further confirms its usefulness. The NaviDroid can help us develop more robust software that works in more mission-critical settings not only by performing more thorough testing with the same effort that has been put in before but also by integrating these techniques into different parts of development pipeline.;
2020 IEEE Workshop on Validation Analysis and Evolution of Software Tests (VST);Finding a bug in the software is an expensive task however debugging is a crucial part of the software development life cycle. Spectrum-Based Fault Localization (SBFL) algorithms can reduce the time spent with debugging. Despite the fact that SBFL is a very well researched topic there are not many tools that implement it. Many studies have dealt with the effectiveness of SBFL algorithms although these have been evaluated on Java and C++ programming languages. We performed an empirical study on JavaScript programs (using BugsJS benchmark) to evaluate the relationship between algorithms efficiency and the bug-fix types. First we implemented three popular SBFL approaches i.e. Tarantula Ochiai and DStar then examined whether there was a correlation/connection between the positions of the faulty methods in the suspiciousness ranks and bug-fix types. Results show that certain bug-fix types can be significantly differentiated from the others (in both positive and negative direction) based on the fault localization effectiveness of the investigated algorithms.;
2019 9th International Conference on Cloud Computing Data Science & Engineering (Confluence);Software Bug Localization (SBL) is a task of locating the buggy source code. There are various ways of doing SBL and one of them is static SBL which utilizes the power of Text Mining (TM) in association with software repositories. Most of static SBL models are based on Information Retrieval (IR) methodology in which bug report works as a query and source code as database. In this paper we review state of the art SBL models which uses text mining techniques as their back bone in conjunction with other techniques. Essential features are extracted and summarized with the help of tabular representation. Aim of doing this study is to find the gaps in previous SBL models for proposing a novel SBL model in future.;
2010 Second World Congress on Software Engineering;Localization testing ensures that localized software meets the requirements of local language market and user's habits it is an important part of international software testing. In this paper based on localization testing theory and applications the concept content and purpose of localization testing are described first then three commonly used testing models have been compared moreover the testing environment setting the testing implementation strategies the localization testing phases and their flows has been analyzed and discussed.;
BugBuilder: An Automated Approach to Building Bug Repository;Bug-related research e.g. fault localization program repair and software testing relies heavily on high-quality and large-scale software bug repositories. The importance of such repositories is twofold. On one side real-world bugs and their associated patches may inspire novel approaches for finding locating and repairing software bugs. On the other side the real-world bugs and their patches are indispensable for rigorous and meaningful evaluation of approaches to software testing fault localization and program repair. To this end a number of software bug repositories e.g. iBUGS and Defects4J have been constructed recently by mining version control systems and bug tracking systems. However fully automated construction of bug repositories by simply taking bug-fixing commits from version control systems often results in inaccurate patches that contain many bug-irrelevant changes. Although we may request experts or developers to manually exclude the bug-irrelevant changes (as the authors of Defects4J did) such extensive human intervention makes it difficult to build large-scale bug repositories. To this end in this paper we propose an automatic approach called BugBuilder to construct bug repositories from version control systems. Different from existing approaches it automatically extracts complete and concise bug-fixing patches and excludes bug-irrelevant changes. It first detects and excludes software refactorings involved in bug-fixing commits. BugBuilder then enumerates all subsets of the remaining part and discards invalid subsets by compilation and software testing. If exactly a single subset survives the validation this subset is taken as the complete and concise bug-fixing patch for the associated bug. In case multiple subsets survive BugBuilder employs a sequence of heuristics to select the most likely one. Evaluation results on 809 real-world bug-fixing commits in Defects4J suggest that BugBuilder successfully extracted complete and concise bug-fixing patches from forty-three percent of the bug-fixing commits and its precision (99%) was even higher than human experts. We also built a bug repository called GrowingBugs with the proposed approach. The resulting repository serves as evidence of the usefulness of the proposed approach as well as a publicly available benchmark for bug-related research.;
2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR);Bug-fix benchmarks are essential for evaluating methodologies in automatic program repair (APR) and fault localization (FL). However existing benchmarks exemplified by Defects4J need to evolve to incorporate recent bug-fixes aligned with contemporary development practices. Moreover reproducibility a key scientific principle has been lacking in bug-fix benchmarks. To address these gaps we present GitBug-Java a reproducible benchmark of recent Java bugs. GitBug-Java features 199 bugs extracted from the 2023 commit history of 55 notable open-source repositories. The methodology for building GitBug-Java ensures the preservation of bug-fixes in fully-reproducible environments. We publish GitBug-Java at https://github.com/gitbugactions/gitbug-java.;
2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW);Fault localization has been determined as a major resource factor in the software development life cycle. Academic fault localization techniques are mostly unknown and unused in professional environments. Although manual debugging approaches can vary significantly depending on bug type (e.g. memory bugs or semantic bugs) these differences are not reflected in most existing fault localization tools. Little research has gone into automated identification of bug types to optimize the fault localization process. Further existing fault localization techniques leverage on historical data only for augmentation of suspiciousness rankings. This thesis aims to provide a fault localization framework by combining data from various sources to help developers in the fault localization process. To achieve this a bug classification schema is introduced benchmarks are created and a novel fault localization method based on historical data is proposed.;
2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion);Software engineering studies such as bug detection localization repair and prediction often require benchmark bug datasets for their experiments. Few publicly available reproducible bug datasets exist for research consumption. Such datasets which publicly exist tend to be applicable exclusively towards the most popular traditional programming languages (e.g. Defects4J for Java and CoreBench for C). Thus the creation and widespread usage of bug datasets for other popular modern JVM (Java Virtual Machine) programming languages serve to provide vital resources for software engineering research. This paper introduces Defexts a family of bug datasets currently containing child datasets for Kotlin (DefextsKotlin) and Groovy (DefextsGroovy). Each dataset contains reproducible real-world bugs and their corresponding patches scraped from real-world projects. Our introductory versions of DefextsKotlin and DefextsGroovy include 225 Kotlin and 302 Groovy bugs and patches. As development of Defexts continues we aim to include other JVM languages notably Scala. A video demonstration of Defexts is located at following link:https://youtu.be/lenYcVzRGGQ.;
Improving Software Fault Localization by Combining Spectrum and Mutation;The performance of software fault localization techniques is critical to software debugging and the reliability of software. Spectrum-based fault localization (SBFL) and mutation-based fault localization (MBFL) are the two most popular fault localization methods. However the accuracies of the two methods are still limited. For example only 10.63% of faults can be detected by inspecting the top 3 suspicious elements reported by Ochiai which is a famous SBFL technique. Unfortunately programmers only examine the first few suspicious elements before losing patience. Since the information used in SBFL and MBFL are quite different and complementary this paper proposes a novel approach by combining spectrum and mutation to improve the fault localization accuracy. First the faulty program is evaluated by using SBFL and the potential faulty statements are ranked according to their suspiciousness. Then mutants of the program are generated and executed by MBFL. Finally the statements that are ranked in the top tied ${n;
2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C);How do professional software engineers debug computer programs? In an experiment with 27 real bugs that existed in several widely used programs we invited 12 professional software engineers who together spent one month on localizing explaining and fixing these bugs. This did not only allow us to study the various tools and strategies used to debug the same set of errors. We could also determine exactly which statements a developer would localize as faults how a developer would diagnose and explain an error and how a developer would fix an error â€“ all of which software engineering researchers seek to automate. Until now it has been difficult to evaluate the effectiveness and utility of automated debugging techniques without a user study. We publish the collected data called DBGBENCH to facilitate the effective evaluation of automated fault localization diagnosis and repair techniques w.r.t. the judgement of human experts.;
2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion);Empirical studies in software testing require realistic benchmarks which are able to mimic industry-like environments. For evaluating automated failure diagnosis techniques one needs real reproducible bugs with at least one associated failing test. Extracting such bugs is challenging and time-consuming. This paper presents Pairika a failure diagnosis benchmark for C++ programs. Pairika contains 40 bugs extracted from 7 modules of OpenCV project with more than 490 KLoC and 11129 tests. Each bug is accompanied by at least one failing test. We publish Pairika to facilitate and stimulate further research on automated failure diagnosis techniques. Pairika is available at: https://github.com/tum-i22/Pairika;
2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE);Realistic benchmarks of reproducible bugs and fixes are vital to good experimental evaluation of debugging and testing approaches. However there is no suitable benchmark suite that can systematically evaluate the debugging and testing methods of quantum programs until now. This paper proposes Bugs4Q a benchmark of thirty-six real manually validated Qiskit bugs from four popular Qiskit elements (Terra Aer Ignis and Aqua) supplemented with the test cases for reproducing buggy behaviors. Bugs4Q also provides interfaces for accessing the buggy and fixed versions of the Qiskit programs and executing the corresponding test cases facilitating the reproducible empirical studies and comparisons of Qiskit program debugging and testing tools. Bugs4Q is publicly available at https://github.com/Z-928/Bugs4Q;
2010 IEEE 34th Annual Computer Software and Applications Conference;This paper presents an approach of bug localization using a frequency weighting function. In an existing approach only binary information of execution count from test executions is used. Information of each program statement being executed and not executed by a particular test is used indicated by 1 and 0 respectively. In our proposed approach frequency execution count of each program statement executed by a respective test is used. We evaluate several well-known spectra metrics using our proposed approach and the existing approach (using binary information of execution count) on two test suites Siemens Test Suite and Unix datasets. We show that the bug localization performance is improved by using our proposed approach. We conduct statistical test and show that the improved bug localization performance using our approach (using frequency execution count) is statistically significant than using the existing approach (using binary information of execution count).;
2021 IEEE/ACM 2nd International Workshop on Quantum Software Engineering (Q-SE);Reproducibility and comparability of empirical results are at the core tenet of the scientific method in any scientific field. To ease reproducibility of empirical studies several benchmarks in software engineering research such as Defects4J have been developed and widely used. For quantum software engineering research however no benchmark has been established yet. In this position paper we propose a new benchmark-named QBugs-which will provide experimental subjects and an experimental infrastructure to ease the evaluation of new research and the reproducibility of previously published results on quantum software engineering.;
Network-Clustered Multi-Modal Bug Localization;Developers often spend much effort and resources to debug a program. To help the developers debug numerous information retrieval (IR)-based and spectrum-based bug localization techniques have been devised. IR-based techniques process textual information in bug reports while spectrum-based techniques process program spectra (i.e. a record of which program elements are executed for each test case). While both techniques ultimately generate a ranked list of program elements that likely contain a bug they only consider one source of information-either bug reports or program spectra-which is not optimal. In light of this deficiency this paper presents a new approach dubbed Network-clustered Multi-modal Bug Localization (NetML) which utilizes multi-modal information from both bug reports and program spectra to localize bugs. NetML facilitates an effective bug localization by carrying out a joint optimization of bug localization error and clustering of both bug reports and program elements (i.e. methods). The clustering is achieved through the incorporation of network Lasso regularization which incentivizes the model parameters of similar bug reports and similar program elements to be close together. To estimate the model parameters of both bug reports and methods NetML employs an adaptive learning procedure based on Newton method that updates the parameters on a per-feature basis. Extensive experiments on 355 real bugs from seven software systems have been conducted to benchmark NetML against various state-of-the-art localization methods. The results show that NetML surpasses the best-performing baseline by 31.82 22.35 19.72 and 19.24 percent in terms of the number of bugs successfully localized when a developer inspects the top 1 5 and 10 methods and Mean Average Precision (MAP) respectively.;
2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion);Bug-fix benchmarks are fundamental in advancing various sub-fields of software engineering such as automatic program repair (APR) and fault localization (FL). A good benchmark must include recent examples that accurately reflect technologies a nd development practices of today. To be executable in the long term a benchmark must feature test suites that do not degrade over-time due to for example dependencies that are no longer available. Existing benchmarks fail in meeting both criteria. For instance Defects4J one of the foremost Java benchmarks last received an update in 2020. Moreover full-reproducibility has been neglected by the majority of existing benchmarks. In this paper we present GitBug-Actions: a novel tool for building bug-fix benchmarks with modern and fully-reproducible bug-fixes. GITBuG-ACTIONS relies on the most popular CI platform GitHub Actions to detect bug-fixes and smartly locally execute the CI pipeline in a controlled and reproducible environment. To the best of our knowledge we are the first torely on G it Hub Actions to collect bug-fixes. To demonstrate our toolchain we deploy GITBuG-ACTIONS to build a proof-of-concept Go bug-fix benchmark containing executable fully-reproducible bug-fixes from different repositories. A video demonstrating GITBuG-AcTIONS is available at: https://youtu.be/aBWwa1sJYBs.;
2020 27th Asia-Pacific Software Engineering Conference (APSEC);As software systems are becoming larger and more complex debugging poses great challenges to software developers and maintainers. Among various efforts on easing the burden of debugging bug localization techniques are developed to help locate where a bug occurs in source code files automatically. Information retrieval and deep neural network techniques are often adopted in existing research to achieve bug localization through capturing the textual or semantic similarity between bug reports and source code files. At the same time some domain- specific eatures in software engineering are also utilized to locate the buggy files. However the dependency relationship between classes (A depends on $B$ if $A$ references B) is not considered or utilized by existing approaches. In this work we propose a novel framework DependLoc for bug localization which leverages the dependency relationship among source code files. DependLoc is based on the observation that buggy files may not be highly similar to a bug report but have a dependency relationship with one or more files that are quite similar to the bug report. DependLoc adopts a customized Ant Colony algorithm to quantify the intrinsic dependency relationship (called reference heat) and designs a segment-based encoder to learn this feature. Experimental results on six widely-used benchmark datasets for bug localization show that our approach outperforms the state-of-the-art methods and Accuracy@10 is improved by 4% on average.;
RLocator: Reinforcement Learning for Bug Localization;Software developers spend a significant portion of time fixing bugs in their projects. To streamline this process bug localization approaches have been proposed to identify the source code files that are likely responsible for a particular bug. Prior work proposed several similarity-based machine-learning techniques for bug localization. Despite significant advances in these techniques they do not directly optimize the evaluation measures. We argue that directly optimizing evaluation measures can positively contribute to the performance of bug localization approaches. Therefore in this paper we utilize Reinforcement Learning (RL) techniques to directly optimize the ranking metrics. We propose RLocator a Reinforcement Learning-based bug localization approach. We formulate RLocator using a Markov Decision Process (MDP) to optimize the evaluation measures directly. We present the technique and experimentally evaluate it based on a benchmark dataset of 8316 bug reports from six highly popular Apache projects. The results of our evaluation reveal that RLocator achieves a Mean Reciprocal Rank (MRR) of 0.62 a Mean Average Precision (MAP) of 0.59 and a Top 1 score of 0.46. We compare RLocator with three state-of-the-art bug localization tools FLIM BugLocator and BL-GAN. Our evaluation reveals that RLocator outperforms both approaches by a substantial margin with improvements of 38.3% in MAP 36.73% in MRR and 23.68% in the Top K metric. These findings highlight that directly optimizing evaluation measures considerably contributes to performance improvement of the bug localization problem.;
2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Background: Fault localization in software maintenance and debugging can be a costly process. Spectrum-Based Fault Localization (SBFL) is a widely-used method for fault localization. It assigns suspicion scores to code elements based on tests indicating the likelihood of defects in specific code lines. However the effectiveness of SBFL approaches varies depending on the subject code. Aims: In this paper our aim is to present an approach that combines multiple SBFL formulae using evidence theory. Method: We first introduce a taxonomy of SBFL techniques. Then we describe how we fuse suspiciousness scores obtained from a set of SBFL formulae. We also introduce a concept of fuzzy windows and describe how they can enhance localization accuracy and how they can be tuned to further refine results. Results: We present an empirical evaluation of our approach using the Defects4J dataset. Our results demonstrate improvements in fault localization accuracy over existing statement-level SBFL techniques. Specifically by fusing three SBFL methods our approach reduces code inspection effort by up to 34.5 % with a size-4 window and increases the hit rate for the top 10% most suspicious lines by 27.9 % using a size-7 window. Moreover in multi-line bug scenarios our approach reduces code inspection effort by up to 35.6% and achieves a maximum increase of 43.2% in the hit rate of the top 10% most suspicious lines. Additionally our approach outperforms state-of-the-art machine learning-based method-level fusion approaches in terms of top rank fault localization accuracy. Conclusions: Our study highlights the applicability of evidence theory in addressing fault localization as an uncertain and ambiguous information fusion problem involving multiple SBFL techniques. The combination of SBFL formulae using evidence theory along with the use of fuzzy windows shows promise in enhancing fault localization accuracy.;
2024 IEEE International Conference on Artificial Intelligence Testing (AITest);Spectrum-based fault localization approaches utilize the statistical information about the execution of test cases to rank statements denoting the most specious ones leading to the failure of test cases. We propose a new approach for software fault localization called SpecNLP which combines natural language processing (NLP) techniques with spectrum-based fault localization (SBFL). SpecNLP uses a pre-trained NLP model called CodeBERT to extract semantic features. These features together with spectrum information from test executions are fed into a multi-layer perceptron (MLP) to predict the start and end locations of bugs. The key innovation is the integration of SBFL execution test cases with CodeBERT code embeddings enabling more accurate bug localization. SpecNLP outperforms previous ML and NLP methods on the Codeflaws benchmark. On the key Top-N metric SpecNLP achieves 31.9% accuracy on Top-1 predictions versus 5.4% for SBFL techniques. The results demonstrate that SpecNLP outperforms previous methods on a benchmark and achieves higher accuracy in predicting fault locations.;
2023 12th International Conference on Awareness Science and Technology (iCAST);As part of their learning journey students frequently encounter challenges and make errors especially with algorithmic programming questions. Regrettably providing tailored solutions for these mistakes can impose a significant burden on instructors in terms of time and effort. To address this automated program repair (APR) techniques have been explored to generate such fixes automatically. Previous research has investigated the use of symbolic and neural approaches for APR in the educational domain. However both types of approaches necessitate substantial engineering endeavors or extensive data and training. In this study we propose the utilization of a large language model trained on code to construct an APR system specifically designed for student programs. Our system has the capability to rectify semantic errors by employing a few-shot example generation pipeline solely based on the input code. We assess the performance of our system on one dataset of algorithm implementations namely QuixBugs. The results demonstrate that the novel example generation pipeline not only enhances the overall systemâ€™s performance but also ensures its stability.;
A Variability Fault Localization Approach for Software Product Lines;Software fault localization is one of the most expensive tedious and time-consuming activities in program debugging. This activity becomes even much more challenging in Software Product Line (SPL) systems due to variability of failures. These unexpected behaviors are induced by variability faults which can only be exposed under some combinations of system features. The interaction among these features causes the failures of the system. Although localizing bugs in single-system engineering has been studied in-depth variability fault localization in SPL systems still remains mostly unexplored. In this article we present VarCop a novel and effective variability fault localization approach. For an SPL system failed by variability bugs VarCop isolates suspicious code statements by analyzing the overall test results of the sampled products and their source code. The isolated suspicious statements are the statements related to the interaction among the features which are necessary for the visibility of the bugs in the system. In VarCop the suspiciousness of each isolated statement is assessed based on both the overall test results of the products containing the statement as well as the detailed results of the test cases executed by the statement in these products. On a large public dataset of buggy SPL systems our empirical evaluation shows that VarCop significantly improves two state-of-the-art techniques by 33% and 50% in ranking the incorrect statements in the systems containing a single bug each. In about two-thirds of the cases VarCop correctly ranks the buggy statements at the top-3 positions in the ranked lists. For the cases containing multiple bugs VarCop outperforms the state-of-the-art approaches 2 times and 10 times in the proportion of bugs localized at the top-1 positions. Especially in 22% and 65% of the buggy versions VarCop correctly ranks at least one bug in a system at the top-1 and top-5 positions.;
2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE);Software defect datasets are crucial to facilitating the evaluation and comparison of techniques in fields such as fault localization test generation and automated program repair. However the reproducibility of software defect artifacts is not immune to breakage. In this paper we conduct a study on the reproducibility of software defect artifacts. First we study five state-of-the-art Java defect datasets. Despite the multiple strategies applied by dataset maintainers to ensure reproducibility all datasets are prone to breakages. Second we conduct a case study in which we systematically test the reproducibility of 1795 software artifacts during a 13-month period. We find that 62.6% of the artifacts break at least once and 15.3% artifacts break multiple times. We manually investigate the root causes of breakages and handcraft 10 patches which are automatically applied to 1055 distinct artifacts in 2948 fixes. Based on the nature of the root causes we propose automated dependency caching and artifact isolation to prevent further breakage. In particular we show that isolating artifacts to eliminate external dependencies increases reproducibility to 95% or higher which is on par with the level of reproducibility exhibited by the most reliable manually curated dataset.;
2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code);Automated debugging is an emerging research field that aims to automatically find and repair bugs. In this field Fault Localization (FL) and Automated Program Repair (APR) gain the most research efforts. Most recently researchers have adopted pre-trained Large Language Models (LLMs) to facilitate FL and APR and their results are promising. However the LLMs they used either vanished (such as Codex) or outdated (such as early versions of GPT). In this paper we evaluate the performance of recent commercial closed-source general-purpose LLMs on FL and APR i.e. ChatGPT 3.5 ERNIE Bot 3.5 and IFlytek Spark 2.0. We select three popular LLMs and evaluate them on 120 real-world Java bugs from the benchmark Defects4J. For FL and APR we designed three kinds of prompts for each considering different kinds of information. The results show that these LLMs could successfully locate 53.3% and correctly fix 12.5% of these bugs.CCS CONCEPTSâ€¢ Software and its engineering â†’ Search-based software engineering Software testing and debugging.;
Why My App Crashes? Understanding and Benchmarking Framework-Specific Exceptions of Android Apps;Mobile apps have become ubiquitous. Ensuring their correctness and reliability is important. However many apps still suffer from occasional to frequent crashes weakening their competitive edge. Large-scale deep analyses of the characteristics of real-world app crashes can provide useful insights to both developers and researchers. However such studies are difficult and yet to be carried out â€” this work fills this gap. We collected 16245 and 8760 unique exceptions from 2486 open-source and 3230 commercial Android apps respectively and observed that the exceptions thrown from Android framework (termed â€œframework-specific exceptionsâ€) account for the majority. With one-year effort we (1) extensively investigated these framework-specific exceptions and (2) further conducted an online survey of 135 professional app developers about how they analyze test reproduce and fix these exceptions. Specifically we aim to understand the framework-specific exceptions from several perspectives: (i) their characteristics (e.g. manifestation locations fault taxonomy) (ii) the developersâ€™ testing practices (iii) existing bug detection techniquesâ€™ effectiveness (iv) their reproducibility and (v) bug fixes. To enable follow-up research (e.g. bug understanding detection localization and repairing) we further systematically constructed DroidDefects the first comprehensive and largest benchmark of Android app exception bugs. This benchmark contains 33 reproducible exceptions (with test cases stack traces faulty and fixed app versions bug types etc.) and 3696 ground-truth exceptions (real faults manifested by automated testing tools) which cover the apps with different complexities and diverse exception types. Based on our findings we also built two prototype tools: Stoat+ an optimized dynamic testing tool which quickly uncovered three previously-unknown fixed crashes in Gmail and Google+ ExLocator an exception localization tool which can locate the root causes of specific exception types. Our dataset benchmark and tools are publicly available on https://github.com/tingsu/droiddefects.;
2020 IEEE 27th International Conference on Software Analysis Evolution and Reengineering (SANER);Spectrum-Based Fault Localization (SBFL) is a well-understood statistical approach to software fault localization and there have been numerous studies performed that tackle its effectiveness. However mostly Java and C/C++ programs have been addressed to date. We performed an empirical study on SBFL for JavaScript programs using a recent bug benchmark BugsJS. In particular we examined (1) how well some of the most popular SBFL algorithms Tarantula Ochiai and DStar can predict the faulty source code elements in these JavaScript programs (2) whether there is a significant difference between the effectiveness of the different SBFL algorithms and (3) whether there is any relationship between the bug-fix types and the performance of SBFL methods. For the latter we performed a manual classification of each benchmark bug according to an existing classification scheme. Results show that the performance of the SBFL algorithms is similar but there are some notable differences among them as well and that certain bug-fix types can be significantly differentiated from the others (in both positive and negative direction) based on the fault localization effectiveness of the investigated algorithms.;
Electrical Engineering (ICEE) Iranian Conference on;Nowadays automatic defect prediction has attracted wide attention but many researchers neglected the availability of huge amount of data in version control systems. Deploying the next release of the project on time and on schedule urges software project managers to optimize efforts based on their limited human resources. Usually software projects have longterm version history from which we can build a repository of rnetrics defects fixes and causes. Having an accurate estimate of the distribution of bugs across components helps project managers to optimize the available resources by focusing on the problematic system parts. We have introduced a benchmark for interested readers in this field which provides all the data needed to apply a large array of prediction techniques proposed in the literature. Our dataset allows the reproduction of the experiments reported in this paper and their comparison with novel defect prediction approaches. We evaluated a selection of representative classification approaches and compared the performance of major classifiers using various evaluation measures such as Precision Recall F-measure G-mean and AUC. The experimental results show that Random Forest is a powerful method and as a good candidate for software defect prediction can be used for further improvements.;
2019 Joint 8th International Conference on Informatics Electronics & Vision (ICIEV) and 2019 3rd International Conference on Imaging Vision & Pattern Recognition (icIVPR);For developers the debugging process is a huge consumer of time and effort. They receive many bug reports that they must address by reproducing the bugs and reviewing the code for errors. Therefore an automated system to help the developers in these tasks is very much required. This paper presents a system to find potential solutions in the Stack Overflow (SO) forum of questions and answers focusing on programming issues. It finds the similar problems which have relevance to the reported bugs in a bug report analyzed by the experts in SO. We combine two similarity measures to rank relevant SO posts that suggests the solutions for software bugs. Our experimental evaluations on several open-source projects show that the combination of similarity measures performs better than applying the similarity measures individually.;
2019 12th IEEE Conference on Software Testing Validation and Verification (ICST);In our recent work we proposed BUGSJS a benchmark of several hundred bugs from popular JavaScript server-side programs. In this abstract paper we report the results of our initial evaluation in adopting BUGSJS to support an experiment in fault localization. First we describe how BUGSJS facilitated accessing the information required to perform the experiment namely test case code their outcomes their associated code coverage and related bug information. Second we illustrate how BUGSJS can be improved to further enable easier application to fault localization research for instance by filtering out failing test cases that do not directly contribute to a bug. We hope that our preliminary results will foster researchers in using BUGSJS to enable highly-reproducible empirical studies and comparisons of JavaScript analysis and testing tools.;
2009 IEEE International Conference on Software Maintenance;We previously presented a fault localization technique called value replacement that repeatedly alters the state of an executing program to locate a faulty statement [9]. The technique searches for program statements involving values that can be altered during runtime to cause the incorrect output of a failing run to become correct. We showed that highly effective fault localization results could be achieved by the technique on programs containing single faults. In the current work we generalize value replacement so that it can also perform effectively in the presence of multiple faults. We improve scalability by describing two techniques that significantly improve the efficiency of value replacement. In our experimental study our generalized technique effectively isolates multiple simultaneous faults in time on the order of minutes in each case whereas in  the technique had sometimes required time on the order of hours to isolate only single faults.;
2024 IEEE 22nd World Symposium on Applied Machine Intelligence and Informatics (SAMI);Code metrics and static checker information can be used to increase the performance of Information Retrieval Fault Localization (IRFL). While previous work focused on the calculation of bug proneness scores for reranking IRFL tool outputs we propose a dynamic reranking approach based on code smells. We hypothesize that code smell information can be predicted from textual bug reports and that these insights can support the fault localization task. To test this hypothesis we implemented a fault localization pipeline consisting of a static checker (PMD) and a Neural Network based classifier to predict code smells. We apply this pipeline to predict code smells for a given textual bug report and use this information to rerank the outputs of BugLocator BLIA and BRTracer. We trained and evaluated our pipeline on the Bench4BL bug benchmark. While overall performance on the Bench4BL benchmark stayed the same we found significant MAP localization performance increases for specific input software projects. We identify and discuss the characteristics of debugging benchmarks that limit their suitability for machine learning experiments. Despite these issues we demonstrated that predicting certain smells based on textual bug reports is possible and that this information may be beneficial to fault localization.;
2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM);Spectrum-Based Fault Localization (SBFL) uses a mathematical formula to determine a suspicion score for each program element (such as a statement method or class) based on fundamental statistics (e.g. how many times each element is executed and not executed in passed and failed tests) taken from test coverage and results. Based on the calculated scores program elements are then ordered from most suspicious to least suspicious. The elements with the highest scores are thought to be the most prone to error. The final ranking list of program elements aids developers in debugging when looking for the source of a fault in the program under test. In this paper we present a new SBFL ranking formula that enhances a base formula by ranking code elements slightly higher than others that are executed by more failed tests and less passing ones. Its novelty is that it breaks ties between the elements that share the same suspicion score of the base formula. Experiments were conducted on six single-fault programs of the Defects4J dataset to evaluate the effectiveness of the proposed formula. The results show that our new formula when compared to three widely-studied SBFL formulas achieved a better performance in terms of average ranking. It also achieved positive results in all of the Top-N categories and increased the number of cases where the faulty element became the top-ranked element by 13â€“23%.;
2018 IEEE Symposium on Computer Applications & Industrial Electronics (ISCAIE);Finding bugs in a software is a cumbersome and tedious task. When a new bug is reported the developers find it challenging to replicate the unexpected behavior of the software in order to fix the original fault. In this paper an automated model is presented to find and sort the classes present in the source code according to their proneness of containing a bug depending upon the bug reports. The model uses a text mining approach and recommends a list of classes based upon the lexical similarity between bug reports and the API descriptions and also the changes previously recommended during bug fixing. To maximize the similarity index and at the same time reduce the number of classes recommended a Non-dominant Sorting Genetic Algorithm (NSGA-II) is employed. This model was evaluated on three java based open source applications and it is observed that the model created using multi-objective NSGA-II outperforms the traditional methods of bug localization.;
2021 IEEE 21st International Conference on Software Quality Reliability and Security (QRS);Software fault localization which is an important software quality assurance technology provides the location of the faults in software to improve the efficiency of debugging and repairing. In previous research software fault localization techniques such as spectrum-based mutation-based and program slicing have been widely used and achieved good results. However many statements could have same suspicious values by using these techniques which will consume large amount of manual effort to confirm and affect the accuracy of fault localization. For example using Ochiai or DStar to locate 395 faulty versions of 6 projects in Defects4J nearly 70 % of the faulty versions have more than one suspicious statement are ranked as top tied 1. To address the above problem this paper proposes a complexity-based fault localization (CBFL) technique to further improve the accuracy of fault localization. Firstly a set of metrics for measuring the complexity of statements is proposed and the metrics of each statement in projects are extracted to construct a classification model. Then the classification model is used to predict the faulty probability of the statements which are ranked as top tied 1 by SBFL MBFL or other techniques and these statements are reranked according to the estimated faulty probability to improve the accuracy of fault localization. This paper implements a fault localization tool CDStar based on the CBFL and conducts experiments on the Defects4J dataset. Comparing with the DStar the results show that CBFL outperforms DStar in terms of Einspect @1 and EXAM.;
Historical Spectrum Based Fault Localization;Spectrum-based fault localization (SBFL) techniques are widely studied and have been evaluated to be effective in locating faults. Recent studies also showed that developers from industry value automated SBFL techniques. However their effectiveness is still limited by two main reasons. First the test coverage information leveraged to construct the spectrum does not reflect the root cause directly. Second SBFL suffers from the tie issue so that the buggy code entities can not be well differentiated from non-buggy ones. To address these challenges we propose to leverage the information of version histories in fault localization based on the following two intuitions. First version histories record how bugs are introduced to software projects and this information reflects the root cause of bugs directly. Second the evolution histories of code can help differentiate those suspicious code entities ranked in tie by SBFL. Our intuitions are also inspired by the observations on debugging practices from large open source projects and industry. Based on the intuitions we propose a novel technique HSFL (historical spectrum based fault localization). Specifically HSFL identifies bug-inducing commits from the version history in the first step. It then constructs historical spectrum (denoted as Histrum) based on bug-inducing commits which is another dimension of spectrum orthogonal to the coverage based spectrum used in SBFL. HSFL finally ranks the suspicious code elements based on our proposed Histrum and the conventional spectrum. HSFL outperforms the state-of-the-art SBFL techniques significantly on the Defects4J benchmark. Specifically it locates and ranks the buggy statement at Top-1 for 77.8 percent more bugs as compared with SBFL and 33.9 percent more bugs at Top-5. Besides for the metrics MAP and MRR HSFL achieves an average improvement of 28.3 and 40.8 percent over all bugs respectively. Moreover HSFL can also outperform other six families of fault localization techniques and our proposed Histrum model can be integrated with different families of techniques and boost their performance.;
2022 International Conference on Advancements in Smart Secure and Intelligent Computing (ASSIC);Software accuracy and dependability become very important issues now-a-days. It is more difficult to identify software program errors due to the growing size and complexity of programs. Traditional fault localization methods fall short of finding all the defects in a huge real-world program. The use of machine learning in that situation is effective. In this research we present an R-CNN model-based fault localization technique. The coverage matrix is used as the model's input during training and it uses test data to determine each program statement's suspiciousness score. Each statement is given a rank based on its score. Three benchmark programs have been looked at to evaluate the proposed work's reliability. The analysis of the results demonstrates that the suggested method can effectively identify false statements.;
2017 IEEE International Conference on Software Quality Reliability and Security (QRS);In the past spectrum-based fault localization (SBFL) techniques have been developed to pinpoint a fault location in a program given a set of failing and successful test executions. Most of the algorithms use similarity coefficients and have only been evaluated on established but small benchmark programs from the Software-artifact Infrastructure Repository (SIR). In this paper we evaluate the feasibility of applying 33 state-of-the-art SBFL techniques to a large real-world project namely ASPECTJ. From an initial set of 350 faulty version from the iBugs repository of ASPECTJ we manually classified 88 bugs where SBFL techniques are suitable. Notably only 11 bugs of these bugs can be found after examining the 1000 most suspicious lines and on average 250 source code files need to be inspected per bug. Based on these results the study showcases the limitations of current SBFL techniques on a larger program.;
2022 IEEE International Conference on Software Analysis Evolution and Reengineering (SANER);Bug localization is the task of identifying parts of the source code that needs to be changed to resolve a bug report. As this task is difficult automatic bug localization tools have been proposed. The development and evaluation of these tools rely on the availability of high-quality bug report datasets. In 2014 Kochhar et al. identified three biases in datasets used to evaluate bug localization techniques: (1) misclassified bug report (2) already localized bug report and (3) incorrect ground truth file in a bug report. They reported that already localized bug reports statistically significantly and substantially impact bug localization results and thus should be removed. However their evaluation is still limited as they only investigated 3 projects written in Java. In this study we replicate the study of Kochhar et al. on the effect of biases in bug report dataset for bug localization. Further investigation on this topic is necessary as new and larger bug report datasets have been proposed without being checked for these biases. We conduct our analysis on a collection of 2913 bug reports taken from the recently released Bugzbook dataset that fix Python files. To investigate the prevalence of the biases we check the bias distributions. For each bias we select and label a set of bug reports that may contain the bias and compute the proportion of bug reports in the set that exhibit the bias. We find that 5% 23% and 30% of the bug reports that we investigated are affected by biases 1 2 and 3 respectively. Then we investigate the effect of the three biases on bug localization by measuring the performance of IncBL a recent bug localization tool and the classical Vector Space Model (VSM) based bug localization tool which was used in the Kochhar et al. study. Our experiment results highlight that bias 2 significantly impact the bug localization results while bias 1 and 3 do not have a significant impact. We also find that the effect sizes of bias 2 to IncBL and VSM are different where IncBL has a higher effect size than VSM. Our findings corroborate the result reported by Kochhar et al. and demonstrate that bias 2 not only affects the 3 Java projects investigated in their study but also others in another programming language (i.e. Python). This highlights the need to eliminate bias 2 from the evaluation of future bug localization tools. As a by-product of our replication study we have released a benchmark dataset which we refer to as CAPTURED that has been cleaned from the three biases. CAPTURED contains Python programs and therefore augments the cleaned dataset released by Kochhar et al. which only contains Java programs.;
2017 Second International Conference on Reliability Systems Engineering (ICRSE);The study of multiple faults is becoming a hot spot. In the large software program Multiple faults may interact with each other in some ways. In this paper we investigated the property of multi-faults through the method of fault-injection in Siemens suits. Inspired by previous research we focused our attention on three types of fault interaction: independent faults faults masking faults construction and explored what factors lead their interference in nature. The empirical study in Siemens suits showed that: 1). the probability of two faults interference is less than 1% which means the independent assumption holds true in most cases. 2). faults masking is more frequent than the fault construction. 3). the occurrence of faults interference is not random. By focusing on and analyzing the double-faults versions that occur high-frequency interference we find they always involve the same variable which means the occurrence of fault interference have a certain condition.;
2006 12th Pacific Rim International Symposium on Dependable Computing (PRDC'06);Automated diagnosis of software faults can improve the efficiency of the debugging process and is therefore an important technique for the development of dependable software. In this paper we study different similarity coefficients that are applied in the context of a program spectral approach to software fault localization (single programming mistakes). The coefficients studied are taken from the systems diagnosis/automated debugging tools Pinpoint Tarantula and AMPLE and from the molecular biology domain (the Ochiai coefficient). We evaluate these coefficients on the Siemens Suite of benchmark faults and assess their effectiveness in terms of the position of the actual fault in the probability ranking of fault candidates produced by the diagnosis technique. Our experiments indicate that the Ochiai coefficient consistently outperforms the coefficients currently used by the tools mentioned. In terms of the amount of code that needs to be inspected this coefficient improves 5% on average over the next best technique and up to 30% in specific cases;
2010 Fourth International Conference on Secure Software Integration and Reliability Improvement;Software reliability can be enhanced considerably during testing with faults being detected and corrected by testers. The allocation of testing resources such as man power and CPU hours during testing phase can largely influence fault detection speed and the time to correct a detected fault. The testing resources allocation is usually depicted by testing effort function which has been incorporated into software reliability models in some recent papers. Fault correction process (FCP) is usually modeled as a delayed process of fault detection process (FDP). In addition debugging is usually not perfect and new faults can be introduced during testing. In this paper flexible testing effort dependent paired models of FDP and FCP are derived with consideration of fault introduction. A real dataset is used to illustrate the application of proposed models.;
2019 IEEE 19th International Conference on Software Quality Reliability and Security Companion (QRS-C);The fault localization is an active research topic in the field of software engineering in which the program spectrum-based fault localization(SFL) is an effective method. It's a base for program spectrum-based fault localization to find the internal linkage between program spectrum and executive result. In this paper through analysis of the internal linkage between program spectrum and executive result the conception of the conditional probability in statistics is introduced and four models of the conditional probability (-model) are designed to quantify the relationship between both. Based on model and combined with the information theory of the low-probability events containing more information a new method of fault localization is proposed-SCP (Suspiciousness based on Conditional Probability). In order to verify the effectiveness of the SCP method experiments are conducted with eight public data sets. From the results it's shown that the SCP method has certain advantages in the fault localization.;
Automated Test Generation for Debugging Multiple Bugs in Arithmetic Circuits;Optimized and custom arithmetic circuits are widely used in embedded systems such as multimedia applications cryptography systems signal processing and console games. Debugging of arithmetic circuits is a challenge due to increasing complexity coupled with non-standard implementations. Existing algebraic rewriting techniques produce a remainder to indicate the presence of a potential bug. However bug localization remains a major bottleneck. Simulation-based validation using random or constrained-random tests are not effective for complex arithmetic circuits due to bit-blasting. In this paper we present an automated test generation and bug localization technique for debugging arithmetic circuits. This paper makes four important contributions. We propose an automated approach for generating directed tests by suitable assignments of input variables to make the remainder non-zero. The generated tests are guaranteed to activate bugs. We also propose an automatic bug fixing technique by utilizing the patterns of the remainder terms as well as by analyzing the regions activated by the generated tests to detect and correct the error(s). We also propose an efficient debugging algorithm that can handle multiple dependent as well as independent bugs. Finally our proposed framework consisting of directed test generation bug localization and bug correction is fully automated. In other words our framework is capable of producing a corrected implementation of arithmetic circuits without any manual intervention. Our experimental results demonstrate that the proposed approach can be used for automated debugging of large and complex arithmetic circuits.;
2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE);High-quality and large-scale repositories of real bugs and their concise patches collected from real-world applications are critical for research in software engineering community. In such a repository each real bug is explicitly associated with its fix. Therefore on one side the real bugs and their fixes may inspire novel approaches for finding locating and repairing software bugs on the other side the real bugs and their fixes are indispensable for rigorous and meaningful evaluation of approaches for software testing fault localization and program repair. To this end a number of such repositories e.g. Defects4J have been proposed. However such repositories are rather small because their construction involves expensive human intervention. Although bug-fixing code commits as well as associated test cases could be retrieved from version control systems automatically existing approaches could not yet automatically extract concise bug-fixing patches from bug-fixing commits because such commits often involve bug-irrelevant changes. In this paper we propose an automatic approach called BugBuilder to extracting complete and concise bug-fixing patches from human-written patches in version control systems. It excludes refactorings by detecting refactorings involved in bug-fixing commits and reapplying detected refactorings on the faulty version. It enumerates all subsets of the remaining part and validates them on test cases. If none of the subsets has the potential to be a complete bug-fixing patch the remaining part as a whole is taken as a complete and concise bug-fixing patch. Evaluation results on 809 real bug-fixing commits in Defects4J suggest that BugBuilder successfully generated complete and concise bug-fixing patches for forty percent of the bug-fixing commits and its precision (99%) was even higher than human experts.;
2019 International Conference on Frontiers of Information Technology (FIT);Early prediction of faulty modules provides a way to support software quality assurance activities through improved scheduling and effectiveness of process control. Different fault prediction models have been proposed by researchers for early prediction of faults. However despite predicting faulty classes these techniques don't provide information about identifying the location of occurrence of faults. In this paper we aim to propose a methodology not only to predict faults but also for fault localization as well. We first make use of various datasets to build a software fault prediction model based. We make use of random forest machine learning technique to train our model. We also extract CK-metrics from different modules and we then make use of these metrics for fault localization. In order to do validation we make use of case studies where we do fault prediction fault localization and then run test cases to see if our prediction was correct.;
Enhancing Spectrum-Based Fault Localization Using Fault Influence Propagation;With the rapidly increasing complexity and indispensable status of software systems unprecedented challenges have been brought to software debugging and fault repair. Among the states of art automated fault localization techniques spectrum-based fault localization (SBFL) is one of the most widely studied heuristic approaches. While existing SBFL techniques are mostly focused on the analysis of the test spectrum which loses sight of the effectiveness implied in interactions of software entities. In this paper an optimized fault localization approach is proposed which integrates spectrum-based fault localization and fault influence propagation analysis. The intuition is that the entity associated with more suspicious entities is more likely to be faulty. (1) A dynamic-instrumenting execution tracer is developed to record test coverage data and method call relations simultaneously. (2) The Fault Influence Network (FIN) based on complex network theory is constructed of which the network topology is abstracted from method call relations and the weights of nodes are calculated applying a raw fault locator. Thus the test spectrum and the method interactive relations are combined for further collaborative analysis. (3) A PageRank-based fault localization approach is proposed. By the computation of fault influence propagation the suspiciousness score PR-Susp of the real faulty method can be enhanced significantly. Also a candidate set pruning based on failing tests is implemented which is used for the narrowing of investigation. Experiments are conducted over real-world fault dataset Defects4J with 33 raw spectrum-based fault locators which proves that the proposed approach improves the baseline 14.9% averagely on the metric acc@5 with a growth rate of over 39% on all metrics of acc@1 acc@3 acc@5 MAP and MWE.;
2017 IEEE International Conference on Software Maintenance and Evolution (ICSME);Spectrum-based fault localization (SFL) the technique producing a rank list of statements in descending order of their suspiciousness values is nowadays widely used in current automated program repair tools. There are two different algorithms for these tools to choose statements selected for modification to produce candidate patches from the list: one is the rank-first algorithm based on suspiciousness rankings of statements the other is the suspiciousness-first algorithm based on suspiciousness value of statements. However to our knowledge there is no research work implementing the two algorithms in the same repair tool or comparing their effectiveness. In this paper we conduct an empirical research based on the automated repair tool Nopol with the benchmark set of Defects4J to compare these two algorithms. Preliminary results suggest that the suspiciousness-first algorithm is not equivalent to the rank-first algorithm and behaves better in parallel repair and patch diversity.;
Tracking Buggy Files: New Efficient Adaptive Bug Localization Algorithm;Upon receiving a new bug report developers need to find its cause in the source code. Bug localization can be helped by a tool that ranks all source files according to how likely they include the bug. This problem was thoroughly examined by numerous scientists. We introduce a novel adaptive bug localization algorithm. The concept behind it is based on new feature weighting approaches and an adaptive selection algorithm utilizing pointwise learnâ€“toâ€“rank method. The algorithm is evaluated on publicly available datasets and is competitive in terms of accuracy and required computational resources compared to stateâ€“ofâ€“theâ€“art. Additionally to improve reproducibility we provide extended datasets that include computed features and partial steps and we also provide the source code.;
Multi-Objective Software Defect Prediction via Multi-Source Uncertain Information Fusion and Multi-Task Multi-View Learning;Effective software defect prediction (SDP) is important for software quality assurance. Numerous advanced SDP methods have been proposed recently. However how to consider the task correlations and achieve multi-objective SDP accurately and efficiently still remains to be further explored. In this paper we propose a novel multi-objective SDP method via multi-source uncertain information fusion and multi-task multi-view learning (MTMV) to accurately and efficiently predict the proneness location and type of defects. Firstly multi-view features are extracted from multi-source static analysis results reflecting uncertain defect location distribution and semantic information. Then a novel MTMV model is proposed to fully fuse the uncertain defect information in multi-view features and realize effective multi-objective SDP. Specifically the convolutional GRU encoders capture the consistency and complementarity of multi-source defect information to automatically filter the noise of false and missed alarms and reduce location and type uncertainty of static analysis results. A global attention mechanism combined with the hard parameter sharing in MTMV fuse features according to their global importance of all tasks for balanced learning. Then considering the latent task and feature correlations multiple task-specific decoders jointly optimize all SDP tasks by sharing the learning experience. Through the extensive experiments on 14 datasets the proposed method significantly improves the prediction performance over 12 baseline methods for all SDP objectives. The average improvements are 30.7% 31.2% and 32.4% for defect proneness location and type prediction respectively. Therefore the proposed multi-objective SDP method can provide more sufficient and precise insights for developers to significantly improve the efficiency of software analysis and testing.;
Deep Transfer Bug Localization;Many projects often receive more bug reports than what they can handle. To help debug and close bug reports a number of bug localization techniques have been proposed. These techniques analyze a bug report and return a ranked list of potentially buggy source code files. Recent development on bug localization has resulted in the construction of effective supervised approaches that use historical data of manually localized bugs to boost performance. Unfortunately as highlighted by Zimmermann et al. sufficient bug data is often unavailable for many projects and companies. This raises the need for cross-project bug localization - the use of data from a project to help locate bugs in another project. To fill this need we propose a deep transfer learning approach for cross-project bug localization. Our proposed approach named TRANP-CNN extracts transferable semantic features from source project and fully exploits labeled data from target project for effective cross-project bug localization. We have evaluated TRANP-CNN on curated high-quality bug datasets and our experimental results show that TRANP-CNN can locate buggy files correctly at top 1 top 5 and top 10 positions for 29.9 51.7 61.3 percent of the bugs respectively which significantly outperform state-of-the-art bug localization solution based on deep learning and several other advanced alternative solutions considering various standard evaluation metrics.;
2022 IEEE/ACM 44th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion);Classifying production and test bug reports can significantly improve not only the accuracy of performance evaluation but also the performance of information retrieval-based bug localization (IRBL). However it is time-consuming for developers to classify these bug reports manually. This study proposes a production and test bug report classification method based on deep learning. Our method uses a set of source files and model tuning to solve the problem of insufficient and sparse bug reports when applying deep learning. Our experimental results reveal that the macro f1-score of our method is 0.84 and can improve the IRBL performance by 20%.;
2022 IEEE Conference on Software Testing Verification and Validation (ICST);Mutations are small often token-level changes to program code typically performed during mutation testing for evaluating the quality of test suites. Recently code mutations have come in use for creating benchmarks of buggy code. Such bug benchmarks present valuable aids for the evaluation of testing debugging or bug repair tools. Moreover they can serve as training data for learning-based (neural) bug detectors. Key to all these applications is the creation of realistic bugs which closely resemble mistakes made by software developers. In this paper we present a learning-based approach to mutation. We propose a novel contextual mutation operator which incorporates knowledge about the mutation context to inject natural and more realistic bugs into code. Our approach employs a masked language model to produce a context-dependent distribution over feasible token replacements. The strategy for producing realistic mutations is thus learned. Our experimental evaluation on Java JavaScript and Python programs shows that sampling from a language model does not only produce mutants which more accurately represent real bugs (with a reproduction score nearly 70% higher than for mutations employed in testing) but also lead to better performing bug detectors when trained on thus generated bug benchmarks.;
2022 IEEE International Conference on Sensing Diagnostics Prognostics and Control ( SDPC);Software quality has become an important factor affecting quality and it is the key to ensure high reliability of the system. The concept of software engineering is highly valued in various R&D units. In the procedure of software development and operation a large amount of historical fault data is generated and accumulated but these historical data have not been fully researched and used. The concept of software engineering is highly valued in developers. In the procedure of software development a large amount of historical fault data is generated and accumulated but the data havs not been fully researched and used. Software failure prediction technology can forecast possible failures of a lot of software before testing helping software engineers find error-prone modules and possible failure types as early as possible and then repair them. However through investigation it is found that the construction of a high-performance software defect prediction model for system software faces the following problems. Firstly modern system software fault problems are diverse and difficult to find. Secondly the fault data is cluttered repetitive and incomplete. Thirdly there is a lack of predictive models with good performance and strong model interpretability. In this paper aiming at the fault prediction requirements of system software the research on the construction technology of software defect prediction model is carried out.;
2015 9th Malaysian Software Engineering Conference (MySEC);Software testing is an essential activity in software development process that has been widely used as a means of achieving software reliability and quality. Software practitioners rely on test coverage to decide whether software under test has achieved an acceptable level of reliability and can be released. The researchers in the field of software testing focus on defining meaningful test coverage as measures which are fre-quently used interchangeably with the notion of test adequacy criteria. Test and defect-based information are among widely used adequacy criteria in the literature. However little work has been conducted into integrating the two important indicators from the analytics perspective. Therefore in this paper Test and Defect Coverage Analytics Model (TDCAM) is proposed. TDCAM provides an analytical view for practitioners to assess and validate the testing results. A case study has been conducted to reveal the practical implications of the proposed model. One of the findings shows that components with low branch coverage percentage tend to have more number of defects detected in which supports previous work.;
2013 IEEE 7th International Conference on Software Security and Reliability;Fault localization has been widely recognized as one of the most costly activities in software engineering. Most of existing techniques target a single faulty entity as the root cause of a failure. However these techniques often fail to reveal the context of a failure which can be valuable for the developers and testers to understand and correct faults. Thus some tentative solutions have been proposed to localize faults as sequences of software entities. However as far as we know none of these pioneering works consistently handles execution data in a sequence-oriented way i.e. they analyze suspiciousness of software entities separately before or after the construction of a faulty sequence. In this paper we establish a systematic framework based on sequential-pattern mining to assist fault localization. We model the executions of test cases as sequences of predicates. Our framework outputs sequential patterns which are more likely related to the actual faults based on a 3-stage procedure: a preprocessing stage to prune sequences of predicates a mining stage to discover candidate sequential patterns based on the revised SPADE mining algorithm and a ranking stage to obtain top K results according to our novel metrics. The obtained sequential patterns of predicates can not only provide information about the locations of faults but also convey valuable context information for understanding the root causes of software failures. A preliminary experiment on some widely used benchmarks was conducted to evaluate the performance of our framework. The experimental results show that our technique is effective and efficient in revealing causes of failures.;
2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE);As software systems grow larger and more complex debugging takes up an increasingly significant portion of developers' time and efforts during software maintenance. To aid software engineers in debugging many automated debugging and repair techniques have been proposed. Both the development and evaluation of these automated techniques depend on benchmarks of bugs. While many different defect benchmarks have been developed only a few benchmarks are widely used due to the origin of the collected bugs as well as the usability of the benchmarks themselves risking a biased research landscape. This paper presents BUGSC++ a new benchmark that contains 209 real-world bugs collected from 22 open-source C/C++ projects. BugsC++ aims to provide high usability by providing a similar user interface to the widely used Defects4J. Further BugsC++ ensures the replicability of the bugs in its collection by encapsulating each buggy program in a Docker container. By providing a highly usable real-world defect benchmark for C/C++ we hope to promote debugging research for C/C++.;
2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR);We present Bugs.jar a large-scale dataset for research in automated debugging patching and testing of Java programs. Bugs.jar is comprised of 1158 bugs and patches drawn from 8 large popular opensource Java projects spanning 8 diverse and prominent application categories. It is an order of magnitude larger than Defects4J the only other dataset in its class. We discuss the methodology used for constructing Bugs.jar the representation of the dataset several use-cases and an illustration of three of the use-cases through the application of 3 specific tools on Bugs.jar namely our own tool Elixir and two third-party tools Ekstazi and JaCoCo.;
2024 IEEE 24th International Conference on Software Quality Reliability and Security Companion (QRS-C);Software debugging plays a crucial role in fault localization tasks and spectrum-based fault localization (SBFL) is a hot topic in software automation debugging research. However existing SBFL technologies are generally limited by tie within ranks where a large number of elements share the same suspiciousness which in turn severely limits the performance of SBFL. To this end we propose an SBFL model based on eigenvector centrality (FLEC). This algorithm first utilizes the statement coverage information in the program spectrum to construct a statement network and adopts the correlation between statements as edge weights. Then FLEC takes statement suspiciousness as node weight. On this basis the algorithm utilizes the eigenvector centrality to calculate the weighted suspiciousness of each statement while considering both node importance and correlation between nodes. Finally FLEC conducted experimental validation on 3 datasets of Defects4J and the results showed an average improvement of 10.7% in ACC@N compared to the optimal baseline.;
2015 2nd International Conference on Information Science and Control Engineering;This paper researches the classification of fault injection technology software fault injection and program-oriented mutation testing technology. On the basis of existing work this paper puts forward a software fault injection model based on program mutation with the idea of fault injection analyses the key technology of the model and compares with other fault injection techniques. The model in this paper can be used to evaluate the adequacy of the test suite by using mutation testing which provides a basis to improve the fault test suite. To some extent applying this model can improve the ability of fault detection and provide some useful reference data for software reliability evaluation.;
2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE);Automated test generators such as search based software testing (SBST) techniques replace the tedious and expensive task of manually writing test cases. SBST techniques are effective at generating tests with high code coverage. However is high code coverage sufficient to maximise the number of bugs found? We argue that SBST needs to be focused to search for test cases in defective areas rather in non-defective areas of the code in order to maximise the likelihood of discovering the bugs. Defect prediction algorithms give useful information about the bug-prone areas in software. Therefore we formulate the objective of this thesis: Improve the bug detection capability of SBST by incorporating defect prediction information. To achieve this we devise two research objectives i.e. 1) Develop a novel approach ($(\mathrm{SBST;
2019 IEEE 1st International Workshop on Intelligent Bug Fixing (IBF);State-of-the-art fault localization tools provide a ranked list of suspicious code elements to aid the user in this debugging activity. Statistical (or Spectrum-Based) Fault Localization (SFL/SBFL) uses code coverage information of test cases and their execution outcomes to calculate the ranks. We propose an approach (called iFL) in which the developer interacts with the fault localization algorithm by giving feedback on the elements of the prioritized list. Contextual knowledge of the user about the current item (e. g. a statement) is exploited in the ranked list and with this feedback larger code entities (e. g. a whole function) can be repositioned in the list. In our initial set of experiments we evaluated the approach on the SIR benchmark using simulated users. Results showed significant improvements in fault localization accuracy: the ranking position of the buggy element was reduced by 72% on average and iFL was able to double the number of faults that were positioned between 1-5.;
Estimation of Defects Based on Defect Decay Model: ED^{3;An accurate prediction of the number of defects in a software product during system testing contributes not only to the management of the system testing process but also to the estimation of the product's required maintenance. Here a new approach called ED3M is presented that computes an estimate of the total number of defects in an ongoing testing process. ED3M is based on estimation theory. Unlike many existing approaches the technique presented here does not depend on historical data from previous projects or any assumptions about the requirements and/or testers' productivity. It is a completely automated approach that relies only on the data collected during an ongoing testing process. This is a key advantage of the ED3M approach as it makes it widely applicable in different testing environments. Here the ED3M approach has been evaluated using five data sets from large industrial projects and two data sets from the literature. In addition a performance analysis has been conducted using simulated data sets to explore its behavior using different models for the input data. The results are very promising they indicate the ED3M approach provides accurate estimates with as fast or better convergence time in comparison to well-known alternative techniques while only using defect data as the input.;
2015 6th IEEE International Conference on Software Engineering and Service Science (ICSESS);Test coverage is a effective approach of testing effectiveness and adequacy which has positive impact on software reliability and defect coverage. The test coverage function describes the change of test coverage during the test procedure and it is an important factor of software reliability models with test coverage. In this paper the change of test coverage is represented by the generalized logistic function. On the basic of this generalized test coverage function a new software reliability growth model and a new fault defection model are proposed. The models can be used for quantitative evaluation and predict the software reliability. We test the goodness of fit of the proposed models by using several sets of software testing data and the result is better.;
2015 4th International Conference on Reliability Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions);In past four decades many nonhomogeneous Poisson process (NHPP) based software reliability growth models (SRGMs) have been proposed to measure and assess the reliability growth of software. During the testing process the faults which causes failure are detected and removed. One common assumption of many traditional SRGMs is that the fault removal rate is constant. In practical the fault removal rate increases with time as learning and maturity of software engineer increases. Hence time variant fault removal rate has been considered in this study. A complex software system may contain different category of faults. Some of faults can be easily detected and removed and some of faults required more effort to be detected and removed. Therefore in this article a NHPP based SRGM has been proposed which incorporates mainly two type of faults major and minor. The concepts of imperfect debugging and change point have also been incorporated in the proposed SRGM. The parameters of the proposed SRGM is estimated using Statistical Package for Social Sciences (SPSS) software and validation of the proposed SRGM has been done using real life data set.;
2020 IEEE 44th Annual Computers Software and Applications Conference (COMPSAC);Identifying the location of faults in real-world programs is one of the most costly processes during software debugging. In order to reduce debugging effort many fault localization techniques have been proposed. One of the most widely studied technique is called Spectrum-based fault localization (SBFL) which uses the coverage information and execution results of test cases to do fault localization. Most SBFL techniques only consider the binary coverage information and ignore the execution frequency so their fault localization accuracy is limited especially when faults occur in the iteration entities or loop bodies. In this paper we propose IRBFL a novel fault localization technique based on information retrieval to extract information from execution frequencies of program entities. IRBFL uses mutation analysis to reduce the low suspicious classes and then it adopts information retrieval techniques to calculate the suspiciousness value. We evaluate IRBFL on 205 real-world faults from 5 programs in Defects4J benchmark. The experimental results show that our proposed method outperforms the other five state-of-the-art SBFL techniques. More specifically no matter in single-fault or multi-fault programs IRBFL can identify 2 to 3 times more faulty methods than the other five SBFL techniques when checking the top 1 method. More empirical results in terms of other metrics including acc@3 acc@5 EXAM MRR and MAP also indicate that IRBFL technique is better than the other five SBFL techniques.;
2022 29th Asia-Pacific Software Engineering Conference (APSEC);Multi-source cross-project defect prediction (MSCPDP) refers to transferring defect knowledge from multiple source projects to the target project. MSCPDP has drawn increasing attention of academic and industry communities owing to its advantages compared with single-source cross-project defect prediction (SSCPDP) and some MSCPDP models have been proposed. However to the best of our knowledge there are no empirical studies to investigate the effect of different MSCPCP models on the performance of MSCPDP. To comprehensively investigate the performance of different MSCPDP models we first conduct the literature research about MSCPDP studies and then identify and compare 7 state-of-the-art MSCPDP models in terms of multiple performance measures including PD PF area under ROC curve (AUC) F1 precision Matthews correlation coefficient (MCC) and Popt20% on 20 publicly available defect datasets. Furthermore a robust multiple comparison method i.e. the Scott-Knott effect-size difference (ESD) test is used for statistical test. The experiment results show that 1) Burakâ€™s Filter always performs best in terms of precision AUC MCC Popt20% except for F12) MSCPDP models outperform the mean performance of SSCPDP models on most datasets 3) the performance of MSCPDP models still needs to be further improved. We suggest software engineers use MSCPDP models but not SSCPDP models for CPDP and pay more attention to both the distribution difference of different datasets and the problems of sample similarity and weight when building MSCPDP models.;
2021 14th IEEE Conference on Software Testing Verification and Validation (ICST);We present a case study of an industry scale application of automated fault localisation to SAP HANA2 database. When a test breaks in the Continuous Integration (CI) pipeline the bug needs to be triaged and assigned to the appropriate development team. Given the scale and complexity of SAP HANA2 the assignment itself can be a challenging task. The current practice depends on the static mapping between test scripts and software components as well as human domain knowledge. We apply automated fault localisation to aid the issue allocation in the CI pipeline: once a test failure is observed the automated fault localisation technique identifies the suspicious software component using the information from the test failure. The localisation result can be used by the issue manager to allocate the incoming test failure issues more efficiently. We have analysed 137 CI test executions with at least one failing test script using Spectrum Based Fault Localisation. The results show that automated fault localisation can identify the faulty software component for 61 out of 137 studied test failures within top 10 places out of over 200 components. Out of the 61 faults 36 faults were not identifiable based on the static mapping between test script and software components at all.;
International Conference on Recent Advances and Innovations in Engineering (ICRAIE-2014);The most important component of software quality is software reliability. Every software industry wants to develop error and fault free software. Software is systematically checked and detected faults are removed before it delivered into the market. Software reliability growth models help the software industries to develop fault free and reliable software. In this project we have done an analysis of NHPP software reliability growth model based on the logistic-exponential testing-effort in imperfect debugging environment and also software release-time for reaching different reliability level is calculated. Calculations are done on the actual dataset which is study by Ohba 1984. Parameters are estimated using LSE in Matlab platform some measures are calculated for evaluation of proposed model and compare our model with few existing model and observed that our proposed model is better fitted compare to other existing models.;
2016 IEEE International Conference on Software Quality Reliability and Security (QRS);In engineering a service software developers often construct and deploy a newer (forthcoming) version of the service to replace the current version. A forthcoming version is often placed online for users to consume and report feedback. In the case of observed failures the forthcoming version should be debugged and further evolved. In this paper we propose the model of dual-service fault localization (DFL) to aid this evolution process. Many prior research studies on spectrum-based fault localization (SBFL) consider each version separately. The DFL model correlates the dynamic execution spectra of the current and the forthcoming versions of the same service placed for live test of the forthcoming version and dynamically generates an adaptive fault localization formula to estimate the code regions in the forthcoming service responsible for the observed failures. We report an experiment in which we initialized the DFL model into six instances each using an ensemble technique dynamically composed from 11 existing SBFL formulas and applied the model to four benchmarks. The results show that DFL is feasible and multiple instances are statistically more effective than if not as effective as the best of these individual SBFL formulas on each benchmark.;
2019 27th Iranian Conference on Electrical Engineering (ICEE);Spectral-based fault localization is a statistical technique that aims at helping software developers to find programming faults quickly. In this technique fault locations are found by analyzing abstractions of program traces to provide a ranked list of most probable faulty components (e.g. program statement). Although the semantic structure of code is not considered in Spectral-based fault localization methods they are widely known as high-performance and state-of-the-art methods. Many studies have been conducted in this area that have led to the creation of various methods with different accuracy and efficiency. Nevertheless the relative performance of these methods are neither examined nor discussed in the literature. In this paper we introduce an empirical framework for implementation of SBFL methods in large-scale real bug java programs. Implementation results are reported using evaluation metrics to provide a clear comparison of the performance of the most effective methods.;
2019 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC);In this work we are going to explore how to conduct defect software prediction on unlabelled datasets by exploiting unsupervised machine learning techniques. In previous literature various approaches have been proposed over time with the aim of labelling an unlabelled dataset (i.e. classifying dataset instances/modules in terms of their defectiveness) they can usually rely on other software datasets software experts or metrics' thresholds. In this study we intend to show the results obtained by exploiting CLAMI and CLAMI+ two approaches that overcome the various limitation of the previous ones adopted by researches since they are independent on metrics' threshold do not need experts software knowledge and can be easily automated.Our prediction model takes as input a set of unlabelled datasets and machine learning techniques. Its output is composed of the values of several performance indicators on training datasets and predictions on test datasets. The latter can be employed to deduce information on the status of software code and consequently concentrate the software developers' effort only where necessary.;
Can Higher-Order Mutants Improve the Performance of Mutation-Based Fault Localization?;First-order mutants (FOMs) have been widely used in mutation-based fault localization (MBFL) approaches and have achieved promising results in single-fault localization scenarios (SFL-scenario). Higher-order mutants (HOMs) are proposed to simulate complex faults and can be applied in MBFL theoretically for multiple-fault localization scenarios (MFL-scenario). However whether HOMs can improve MBFLâ€™s performance is not investigated and the effectiveness is not thoroughly evaluated. In this empirical study we investigate the impact of HOMs on the performance of MBFL in SFL-scenario and MFL-scenario. The experiments on two real-world benchmarks reveal that 1) 2-HOMs can help improve the MBFL performance in SFL-scenarios 2) in MFL-scenarios both 2-HOMs and 3-HOMs can achieve better performance than FOMs and 3) huge computational cost cannot be ignored in the practice of HOMs. Therefore effective methods to reduce the number of HOMs for future MBFL studies should be considered.;
2013 IEEE International Conference on Software Maintenance;Spectrum-based fault localization refers to the process of identifying program units that are buggy from two sets of execution traces: normal traces and faulty traces. These approaches use statistical formulas to measure the suspiciousness of program units based on the execution traces. There have been many spectrum-based fault localization approaches proposing various formulas in the literature. Two of the best performing and well-known ones are Tarantula and Ochiai. Recently Xie et al. find that theoretically under certain assumptions two families of spectrum-based fault localization formulas outperform all other formulas including those of Tarantula and Ochiai. In this work we empirically validate Xie et al.'s findings by comparing the performance of the theoretically best formulas against popular approaches on a dataset containing 199 buggy versions of 10 programs. Our empirical study finds that Ochiai and Tarantula statistically significantly outperforms 3 out of 5 theoretically best fault localization techniques. For the remaining two Ochiai also outperforms them albeit not statistically significantly. This happens because an assumption in Xie et al.'s work is not satisfied in many fault localization settings.;
2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP);Developers often use crash reports to understand the root cause of bugs. However locating the buggy source code snippet from such information is a challenging task mainly when the log database contains many crash reports. To mitigate this issue recent research has proposed and evaluated approaches for grouping crash report data and using stack trace information to locate bugs. The effectiveness of such approaches has been evaluated by mainly comparing the candidate buggy code snippets with the actual changed code in bug-fix commits-which happens in the context of retrospective repository mining studies. Therefore the existing literature still lacks discussing the use of such approaches in the daily life of a software company which could explain the developers' perceptions on the use of these approaches. In this paper we report our experience of using an approach for grouping crash reports and finding buggy code on a weekly basis for 18 months within three development teams in a software company. We grouped over 750000 crash reports opened over 130 issues and collected feedback from 18 developers and team leaders. Among other results we observe that the amount of system logs related to a crash report group is not the only criteria developers use to choose a candidate bug to be analyzed. Instead other factors were considered such as the need to deliver customer-prioritized features and the difficulty of solving complex crash reports (e.g. architectural debts) to cite some. The approach investigated in this study correctly suggested the buggy file most of the time-the approach's precision was around 80%. In this study the developers also shared their perspectives on the usefulness of the suspicious files and methods extracted from crash reports to fix related bugs.;
2010 2nd IEEE International Conference on Information Management and Engineering;Software reliability is a very important and active research field in software engineering. There have been one hundred of prediction model since the first prediction model published. But most of them are adapted after software test and only few of them can be used before test. The paper proposed an idea that to predict the software reliability making use of the similar projects measurement data based on software process benchmark. Its prediction uses benchmark measurement and software process data before software test.;
2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE);Fault-detection localization and repair methods are vital to software quality but it is difficult to evaluate their generality applicability and current effectiveness. Large diverse realistic datasets of durably-reproducible faults and fixes are vital to good experimental evaluation of approaches to software quality but they are difficult and expensive to assemble and keep current. Modern continuous-integration (CI) approaches like TRAVIS-CI which are widely used fully configurable and executed within custom-built containers promise a path toward much larger defect datasets. If we can identify and archive failing and subsequent passing runs the containers will provide a substantial assurance of durable future reproducibility of build and test. Several obstacles however must be overcome to make this a practical reality. We describe BUGSWARM a toolset that navigates these obstacles to enable the creation of a scalable diverse realistic continuously growing set of durably reproducible failing and passing versions of real-world open-source systems. The BUGSWARM toolkit has already gathered 3091 fail-pass pairs in Java and Python all packaged within fully reproducible containers. Furthermore the toolkit can be run periodically to detect fail-pass activities thus growing the dataset continually.;
2015 Asia-Pacific Software Engineering Conference (APSEC);A bug report is mainly used to find a fault location in software maintenance. It contains several fields such as summary description status and version. The description field includes detail scenario and stack traces if exceptional messages are presented. Recently researchers have proposed several approaches for automatic bug localization by using information retrieval and data mining. We propose BLIA a statically integrated analysis approach of IR-based bug localization by utilizing texts and stack traces in bug reports structured information of source files and source code change histories. We performed experiments on three open source projects namely AspectJ SWT and ZXing. Compared with prior tools our experiment results showed that BLIA outperforms the existing tools in terms of mean average precision. Our approach on average improved the metric of BugLocator BLUiR BRTracer and AmaLgam by 34% 23% 17% and 8% respectively.;
2016 2nd International Conference on Computational Intelligence and Networks (CINE);This paper presents a novel concept in cross-project software defect prediction. Defects in real world software systems are predicted using defects data of academic projects as training data. Relevant training data are filtered using patterns by ordered projections algorithm by [14]. A satisfactory Area under curve(AUC) value of at least 0.7 and above is obtained for 12 out the 16 investigated real world software systems with Bayes Network classifier. This result is quite significant in the current scenario where many software startups are being launched by fresh graduates from Universities particularly in India. At the beginning such startup companies do not have any defects data of real projects and hence defect datasets of academic projects collected at Universities can be really useful.;
2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR);With the introduction of smart contacts Ethereum has become one of the most popular blockchain networks. In the wake of its popularity an increasing number of Ethereum-based software have been developed. However the carbon emissions resulting from these software has been pointed out as a global issue. It is necessary to reduce the energy consumed by these software to reduce carbon emissions. Recently most studies have focused on smart contracts and proposed energy-efficient methods for the development of carbon friendly Ethereum networks. However in addition to smart contracts the energy used by client software in Ethereum networks should also be reviewed. This is because the client software performs all functions occurring in the Ethereum network including smart contracts. Therefore energy bugs that waste energy in Ethereum client software should be investigated and solved. The first task to enable this is to build an energy bug benchmark of Ethereum client software. This study introduces ECench an energy bug benchmark of Ethereum client software. ECench includes 507 energy buggy commits from 7 series of client software that are officially operated in the Ethereum network. We carefully collected and manually reviewed them for cleaner commits. A key strength of our benchmark is that it provides eight energy wastage categories which can serve as a cornerstone for researchers to identify energy waste codes. ECench can provide a valuable starting point for studies on energy reduction and carbon reduction in Ethereum.;
2021 9th International Conference on Cyber and IT Service Management (CITSM);Software defect prediction is an important part to ensure software quality and increase cost-efficiency. The core aspect prior to software defect prediction is software metrics. More research of process metrics existed and rapidly developed as the fact that process metrics can outperform code metrics. The development of process metrics is diverse aligning with various process metrics generated in the different publication using different dataset and granularity level thus the development state of process metrics need to be further tracked. Recent research on software defect prediction using process metrics has been carried which complements or argues another studied related to the implementation of process metrics dataset and granularity level. This literature review has collected 17 literature studies that aim to depict the current research used of software defect prediction applying software process metrics dataset and granularity. Seven commonly used process metrics are identified such as NDC NML ADEV EXP LA LD and COMM. Process metrics development has been implemented in the previous research such as the application of aggregated process metrics and commits detailed information metrics. The selected research shows that 87&#x0025 of research are using a public dataset while the rest are using a combined dataset. This result depicts the limited accessibility of private and industrial dataset for defect prediction. Following analysis of software granularity presents 4 levels of granularity used in selected research such as a functional class file and features level. File-level defect predictions are mostly used for defect prediction in selected research and prove good defect prediction performance. The results of this literature review also identify the proposed studies which is software defect prediction using developed process metrics in the different datasets and features-level granularity to strengthen the previous research.;
2016 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW);"Previous studies have defined different types of software bugs based on their complexity and reproducibility. Simple bugs which involve only direct factors and are often easy to reproduce have been called Bohrbugs"" while complex bugs with at least one indirect factor and generally much more difficult to reproduce were called Mandelbugs. Locating Mandelbugs in software is often difficult and expensive during the development phase due to their complexity. In this paper we consider the relationship between different types of software bugs and the average t-way interaction involved in triggering them. Analysis suggests that Mandelbugs have a higher interaction strength when triggering their faults. This suggests that both direct and indirect factors play a role in triggering the fault. By using combinatorial testing methods we can have high assurance of locating Mandelbugs as long as the indirect factors are present at the time of testing.""";
2020 6th International Symposium on System and Software Reliability (ISSSR);To reduce the cost of software debugging Automatic Bug Fixing (ABF) techniques have been proposed for efficiently fixing and maintaining software aiming to rapidly correct bugs in software. In this paper we conduct a survey analysing the capabilities of existing ABF techniques based on the test case set. We organize knowledge in this area by surveying 133 high-quality papers from 1990 to June 2020 and supplement 57 latest high-quality papers from 2017 to June 2020. This paper shows that existing ABF approaches can be divided into three main strategies: search-based semantic-based and template-based. Search-based ABF considers using search strategies such as genetic programming context similarity to change the programs into the correct one. Semantic-based ABF involves symbolic execution and constraint solving such as satisfiability modulo theories solver contracts to fix bugs. Different from the two kinds of theories above template-based ABF is mainly based on fixing templates such as other programs bug reports to fix bugs. Besides we provide a summary of the commonly used defect benchmarks and all the available tools that are frequently used in the field of ABF. We also discuss the empirical foundations and argumentation in the area and prospect the trend of future study.;
2021 28th Asia-Pacific Software Engineering Conference (APSEC);Contemporary software engineering tools employ deep learning methods to identify bugs and defects in source code. Being data-hungry supervised deep neural network models require large labeled datasets for their robust and accurate training. In distinction to say Java there is lack of such datasets for Python. Most of the known datasets containing the labeled Python source code are of relatively small size. Those datasets are suitable for testing built deep learning models but not for their training. Therefore larger labeled datasets have to be created based on some well-received algorithmic principles to select relevant source code from the available public codebases. In this work a large dataset of the labeled Python source code is created named PyTraceBugs. It is intended for training validating and evaluating large deep learning models to identify a special class of low-level bugs in source code snippets manifested by throwing error exceptions reported in standard traceback messages. Here a code snippet is assumed to be either a function or a method implementation. The dataset contains 5.7 million correct source code snippets and 24 thousands buggy snippets from the Github public repositories. Most represented bugs are: absence of attribute empty object index out of range and text encoding/decoding errors. The dataset is split into training validation and test samples. Confidence in labeling of the snippets into buggy and correct is about 85% according to our estimates. Labeling of the snippets in the test sample is additionally manually validated to be almost 100% confident. To demonstrate advantages of our dataset it is used to train a binary classification model for distinguishing the buggy and correct source code. This model employs the pretrained BERT-like contextual embeddings. Its performances are as follows: precision on the test set is 96 % for the buggy source code and 61 % for the correct source code whereas recall is 34 % and 99 % respectively. The model performance is also estimated on the known BugsInPy dataset: here it reports approximately 14% of buggy snippets.;
2020 IEEE International Conference on Communication Networks and Satellite (Comnetsat);In software world researcher work is always focusing on number of faults present in a software deformity prone datasets model. The main goal of researcher work is that to find and fix present faults in software deformity prone as soon as possible. This has much to do with software deformity prone datasets models and its accuracy growth. Currently world immense software companies they are used their own accuracy repository system which handling the software deformity prone issues and controlled the accuracy of deformity prone datasets models. This research paper presents the current issues on software deformity prone datasets models and the significant method used on these issues. Our research model method is that to boost the accuracy of forecasts in software deformity prone based on LinearNNsearch Classification method. This method used with K parameters where K=N=1 to 6. The experimental analyses showed that the parameter K=N=3 4 and 5 are good for linearNNsearch and can enhanced the positive accuracy of software deformity prone with linearNNsearch. The analysis experiments of IBK Filtered neighbor search at K=N=5 6 can also increase the positive accuracy of software deformity prone.;
2023 IEEE 32nd Asian Test Symposium (ATS);Information Retrieval-based Bug Localization (IRBL) and Mutation-based Fault Localization (MBFL) are two widely used static and dynamic fault localization techniques respectively. IRBL takes less time and utilizes more static information of software while MBFL achieves high accuracy and the results are not easily affected by coincidental correctness test cases. However the granularity of IRBL is coarse and MBFL consumes a lot of time to generate and execute mutants. In this paper we propose IRMBFL (Information Retrieval and Mutation Analysis Based Software Fault Localization) a software fault localization technique that combines information retrieval and mutation analysis. First the suspiciousness of source code files is measured by calculating the text similarity between the bug report and the source code to extract the files which may contain bugs. Then the extracted files are mutated and tested. Finally the bug statements are located by analyzing the changes in the execution results of the test cases. The experiments are conducted on the Defects4J dataset and $E_{inspect;
Testing: Academic and Industrial Conference Practice and Research Techniques - MUTATION (TAICPART-MUTATION 2007);Spectrum-based fault localization shortens the test- diagnose-repair cycle by reducing the debugging effort. As a light-weight automated diagnosis technique it can easily be integrated with existing testing schemes. However as no model of the system is taken into account its diagnostic accuracy is inherently limited. Using the Siemens Set benchmark we investigate this diagnostic accuracy as a function of several parameters (such as quality and quantity of the program spectra collected during the execution of the system) some of which directly relate to test design. Our results indicate that the superior performance of a particular similarity coefficient used to analyze the program spectra is largely independent of test design. Furthermore near- optimal diagnostic accuracy (exonerating about 80% of the blocks of code on average) is already obtained for low-quality error observations and limited numbers of test cases. The influence of the number of test cases is of primary importance for continuous (embedded) processing applications where only limited observation horizons can be maintained.;
2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR);Bug localization is the task of recommending source code locations (typically files) that probably contain the cause of a bug and hence need to be changed to fix the bug. Along these lines information retrieval-based bug localization (IRBL) approaches have been adopted which identify the most bug-prone files from the source code space. In current practice a series of state-of-the-art IRBL techniques leverage the combination of different components e.g. similar reports version history code structure to achieve better performance. ABLoTS is a recently proposed approach with the core component TraceScore that utilizes requirements and traceability information between different issue reports i.e. feature requests and bug reports to identify buggy source code snippets with promising results. To evaluate the accuracy of these results and obtain additional insights into the practical applicability of ABLoTS supporting of future more efficient and rapid replication and comparison we conducted a replication study of this approach with the original data set and also on an extended data set. The extended data set includes 16 more projects comprising 25893 bug reports and corresponding source code commits. While we find that the TraceScore component as the core of ABLoTS produces comparable results with the extended data set we also find that the ABLoTS approach no longer achieves promising results due to an overlooked side effect of incorrectly choosing a cut-off date that led to training data leaking into test data with significant effects on performance.;
2023 30th Asia-Pacific Software Engineering Conference (APSEC);The high quality of input data serves as the foundation for various tasks. Inaccurate data may decrease the effectiveness of elaborate algorithms and significantly impact the output. This also applies to fault localization as accurate and reliable data is crucial for effective fault localization techniques. Many fault localization techniques analyze the coverage information for detecting bug positions. However the source coverage data suffers from various problems such as the imbalanced data and the coincidental correctness. These problems make the source coverage data unreliable for fault localization. To mitigate the potential adverse effect of these unreliable factors we propose Orlando a cOveRage-based decoupLing And recoNstructingData apprOach for fault localization. Or-landooptimizes the coverage data by synthesizing passing coverage with less coincidental correctness and failing coverage with more balanced data. The reconstructed data can provide more reliable source data for fault localization. We evaluate Orlando using the widely used Defects4J benchmark and demonstrate its effectiveness in improving two spectrum-based and two deep learning-based methods. Furthermore Orlando outperforms state-of-the-art data optimization approaches in fault localization.;
2023 IEEE International Conference on Data Mining (ICDM);The process of software bug localization can be described as identifying the source code files (i.e. bug location) corresponding to the bug described in the bug report. Most existing bug localization approaches fall short in handling the following three aspects including (L1) only using partial content in the bug report (i.e. title and description) (L2) direct semantic understanding of the entire bug reports and source files and (L3) relying solely on semantic matching between bug reports and source files. To overcome these limitations this paper constructs datasets in which the content of each bug report is augmented with prefix comments for addressing Ll and presents a novel model named BRS_BL for bug localization. Specifically the proposed BRS_BL designs a specially tailored bug report summarization module to extract core information for semantic representation in bug reports and a chunking source file module to split the source code files into blocks based on lines and words for addressing L2. It further uses a fine-grained matching module utilizing semantic matching and incorporating some well-characterized software-specific features for addressing L3. The experimental results show that our model BRS_BL significantly outperforms the existing representative bug localization techniques in terms of several evaluation metrics across four real-world projects.;
Convolutional Neural Networks-Based Locating Relevant Buggy Code Files for Bug Reports Affected by Data Imbalance;Software bug localization is very important in software engineering but it is also complicated and time consuming. To improve the efficiency of developers researchers have developed various traditional bug localization and machine learning bug localization methods. In this paper we propose a novel method that improves bug localization performance. First surface lexical correlation matching between bug reports and source code files is used to obtain features by deep neural network. Second to solve the lexical gap between bug reports and source code files semantic correlation matching between them is used to obtain features based on word embedding and sentence embedding by deep neural network. Then the joint features obtained by the surface lexical and semantic correlation matching are fused into a unified feature representation for bug reports and source code files. In addition since our experimental datasets are imbalanced data we use a focal loss function to solve the impact of data imbalance. Finally our method obtains the relatively high bug localization performance compared to other classic methods.;
Testing: Academic & Industrial Conference - Practice And Research Techniques (TAIC PART'06);The research described studies delayed failures in software using high volume automated testing (HVAT) and investigates the effectiveness of different HVAT techniques such techniques include genetic algorithms model-based testing penetration testing robustness testing and random (stochastic) testing. A delayed failure is a failure that occurs some time after the conditions that lead to the failure are applied. There appear to be no studies of delayed failures of software in the literature and no comparative studies of the effectiveness of different HVAT techniques therefore research in this area can make an important contribution. Delayed failures in software are unlikely to be revealed by conventional testing techniques a HVAT technique that systematically reveals delayed failures could lead to improved reliability of software and reduced costs. Experimental work is in progress using the MySQL database server as the software under test.;
2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE);Automated program repair can potentially reduce debugging costs and improvesoftware quality but recent studies have drawn attention to shortcomings inthe quality of automatically generated repairs. We propose a new kind ofrepair that uses the large body of existing open-source code to findpotential fixes. The key challenges lie in efficiently finding codesemantically similar (but not identical) to defective code and thenappropriately integrating that code into a buggy program. We presentSearchRepair a repair technique that addresses these challenges by(1) encoding a large database of human-written code fragments as SMTconstraints on input-output behavior (2) localizing a given defect to likelybuggy program fragments and deriving the desired input-output behavior forcode to replace those fragments (3) using state-of-the-art constraintsolvers to search the database for fragments that satisfy that desiredbehavior and replacing the likely buggy code with these potential patches and (4) validating that the patches repair the bug against program testsuites. We find that SearchRepair repairs 150 (19%) of 778 benchmark Cdefects written by novice students 20 of which are not repaired by GenProg TrpAutoRepair and AE. We compare the quality of the patches generated by thefour techniques by measuring how many independent not-used-during-repairtests they pass and find that SearchRepair-repaired programs pass 97.3% ofthe tests on average whereas GenProg- TrpAutoRepair- and AE-repairedprograms pass 68.7% 72.1% and 64.2% of the tests respectively. We concludethat SearchRepair produces higher-quality repairs than GenProg TrpAutoRepair and AE and repairs some defects those tools cannot.;
2022 12th International Conference on Cloud Computing Data Science & Engineering (Confluence);Software has become part of every sphere of life. This increasing dependence on software has put tremendous pressure on software development teams to deliver software applications as early as possible at the cost of compromised software quality and reliability. Software quality requires extensive testing and validation of software which is not possible with limited human resources time and budget so researchers moved to a new paradigm of software quality assurance i.e. Software Defect Prediction (SDP). SDP aims to build automated Machine Learning (ML) models to aid development teams in prioritizing the key aspects of software testing while maintaining the short software development life cycle. SDP requires huge amount of data to train and test ML models traditionally PROMISE and NASA defect datasets are most prominently used by researchers but with changes in programming languages programming styles and limited size of datasets has made them infeasible for SDP in current scenarios. In this paper we have developed a software defect dataset collection framework which mines commit level defect data from GitHub. The efficiency of data mining accuracy of data and validity of data is verified by SDP models. Results shows that proposed method is feasible as well as efficient to execute even on regular computer systems.;
2022 2nd International Conference on Digital Futures and Transformative Technologies (ICoDT2);Software testing is one of the important ways to ensure the quality of software. It is found that testing cost more than 50% of overall project cost. Effective and efficient software testing utilizes the minimum resources of software. Therefore it is important to construct the procedure which is not only able to perform the efficient testing but also minimizes the utilization of project resources. The goal of software testing is to find maximum defects in the software system. As world is continuously moving toward data driven approach for making important decision. Therefore in this research paper we performed the machine learning analysis on the publicly available datasets and tried to achieve the maximum accuracy. The major focus of the paper is to apply different machine learning techniques on the datasets and find out which technique produce efficient result. Particularly we proposed an ensemble learning models and perform comparative analysis among KNN Decision tree SVM and NaÃ¯ve Bayes on different datasets and it is demonstrated that performance of Ensemble method is more than other methods in term of accuracy precision recall and F1-score. The classification accuracy of ensemble model trained on CM1 is 98.56% classification accuracy of ensemble model trained on KM2 is 98.18% similarly the classification accuracy of ensemble learning model trained on PC1 is 99.27%. This reveals that ensemble learning is more efficient method for making the defect prediction as compared other techniques.;
2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011);Spectrum based fault localization techniques such as Tarantula and Ochiai calculate the suspiciousness score of a program statement using the number of failing and passing test cases that execute the statement. These techniques implicitly assume that all test cases are equally important. However research on test case generation and selection techniques has shown that using certain test cases can lead to more effective fault localization than others. The proposed research aims to improve the effectiveness of spectrum based fault localization by incorporating the relative importance of different test cases in the calculation of suspiciousness scores.;
2019 IEEE 15th International Colloquium on Signal Processing & Its Applications (CSPA);Due to fault-to-failure complexity in the existence of multiple faults debugging faults is extremely hard. Many studies were done to improve localization effectiveness in the existence of multiple faults. Some studies attempt to isolate faults into separate fault-focused clusters that target single faults. However isolating failures to their causative faults is still an issue and needs improvement. In this paper we propose the use of a network community clustering algorithm to isolate faults into separate fault-focused communities each targeting a single fault. These fault-focused communities will be given to developers to debug the faults simultaneously in parallel. The method is evaluated on 5 well-known multiple-fault subject programs from the Siemens test suite benchmark. The experimental results show that the network community clustering algorithm is relatively effective in isolating different faults into distinct fault-focused communities with improvements in faults localization effectiveness. The result also shows improvement in terms of reducing the expense to produce a failure-free program.;
2010 17th Working Conference on Reverse Engineering;Software quality researchers build software quality models by recovering traceability links between bug reports in issue tracking repositories and source code files. However all too often the data stored in issue tracking repositories is not explicitly tagged or linked to source code. Researchers have to resort to heuristics to tag the data (e.g. to determine if an issue is a bug report or a work item) or to link a piece of code to a particular issue or bug. Recent studies by Bird et al. and by Antoniol et al. suggest that software models based on imperfect datasets with missing links to the code and incorrect tagging of issues exhibit biases that compromise the validity and generality of the quality models built on top of the datasets. In this study we verify the effects of such biases for a commercial project that enforces strict development guidelines and rules on the quality of the data in its issue tracking repository. Our results show that even in such a perfect setting with a near-ideal dataset biases do exist - leading us to conjecture that biases are more likely a symptom of the underlying software development process instead of being due to the used heuristics.;
2008 IEEE International Conference on Software Testing Verification and Validation Workshop;We describe a benchmark of publicly-available multi-threaded programs with documented bugs in them. This project was initiated a few years ago with the goal of helping research groups in the fields of concurrent testing and debugging to develop tools and algorithms that improve the quality of concurrent programs. We present a survey of usage of the benchmark concluding that the benchmark had an impact on the research in the field of testing and debugging of concurrent programs. We also present new possible directions to foster a discussion about new goals to be set for this initiative.;
2015 24th Australasian Software Engineering Conference;"Debugging is crucial for producing reliable software. One of the effective bug localization techniques is Spectral-Based Fault Localization (SBFL). It locates a buggy statement by applying an evaluation metric to program spectra and ranking program components on the basis of the score it computes. Recently genetic programming has been proposed as a way to find good metrics. We have found that the huge search space for metrics can cause this approach to be slow and unreliable even for relatively simple data sets. Here we propose a restricted class of hyperbolic"" metrics with a small number of numeric parameters. This class of functions is based on past theoretical and empirical results. We show that genetic programming can reliably discover effective metrics over a wide range of data sets of program spectra. We evaluate the performance for both real programs and model programs with single bugs multiple bugs ""deterministic"" bugs and nondeterministic bugs.""";
2023 IEEE International Conference on Systems Man and Cybernetics (SMC);According to whether the program under test is executed software bug localization methods can be divided into static bug localization and dynamic bug localization. Among them Information Retrieval-based Bug Localization (IRBL) and Spectrum-based Fault Localization (SFL) are widely used static and dynamic bug localization methods respectively. But the localization granularity of IRBL is coarse and the localization accuracy of SFL is easily reduced by the information which is unrelated to the bug. In order to refine the localization granularity of IRBL and improve the localization accuracy of SFL this paper proposes ISBL (Combine Information Retrieval and Spectrum for Bug Localization) a statement-level software bug localization method based on information retrieval and spectrum. Firstly the suspicious files are filtered using information retrieval technique and then the suspicious files are used to reduce spectrum information for statement-level bug localization. To evaluate the performance of ISBL experiments were conducted on the Defects4J dataset and MRR and TOP@N were used as metrics for evaluation. As the experimental results show for MRR ISBL increased 3.0% and 3.1% compared to Ochiai and DStar respectively for TOP@1 ISBL locates 4 more bug statements than Ochiai and DStar.;
2021 International Conference on Information Technology (ICIT);Analytical and stochastic modelling methods can provide quantitative measures of software systemsâ€™ reliability during the debugging process. As software increases in complexity debugging assumes more development time and becomes less deterministic. Many of the factors influencing the debugging-process activities are stochastic such as effort complexity efficiency and debugger skill. With this motivation in this paper an integrated software-reliability modelling approach based on a Poisson process to address these factors subject to the categorization of the faults under imperfect-debugging and learning-process phenomena. The software faults encountered are categorized into three types based on their debugging-complexity. The debugging-complexity is proportional to the level of effort expenditures required to correct the fault. Correspondingly the entire debugging-process is the summing of the three debugging activities processes. A numerical example is provided based on a real software-reliability dataset to demonstrate the descriptive and predictive power capabilities and evaluate software-reliability measures as per the proposed integrated modelling approach and other well-documented models.;
2016 5th International Conference on Informatics Electronics and Vision (ICIEV);Performance of an application is a vital issue for user satisfaction. Performance bug refers to a specific kind of bugs that create lags and overheads in application execution. Often it is difficult to localize and fix performance bugs due to insufficient developer knowledge regarding the characteristics of these bugs. Eliminating performance bugs manually from the application is time consuming and costly. This paper proposes a characterization and localization approach of performance bugs using Naive Bayes. It first detects the structures and behaviors responsible for the performance issues in source code. Then it learns the association of performance bugs with those coding characteristics from the training data set. Finally it localizes potential performance bugs in source codes from the given bug report using Naive Bayes Classifier. Experimental result shows that our proposed approach can successfully predicts 75% of the performance bugs from various source codes.;
2012 IEEE 23rd International Symposium on Software Reliability Engineering Workshops;This paper highlights the issues of detecting Java concurrency bugs using static code analysis tools. Concurrency bugs are often hard to find because of interleaving threads and there is need to use static analysis tools to detect the concurrency bugs. In the literature review we established that there are number of static analysis tools such as FindBugs JLint and Chord used in experiments to determine their ability to detect the Java concurrency bugs. However there are still tools in the class of open source static analysis that needs experimental evidence for their ability to find concurrency bugs. In this study we selected three tools CheckThread RacerX and RELAY. The experiment and survey is used to find out the answers for formulated research questions in the introduction section.;
2019 International Conference on Quality Reliability Risk Maintenance and Safety Engineering (QR2MSE);Software defect prediction (SDP) is a hot topic in the modern software engineering research community to analyze software quality and reliability. Many data mining and machine learning methods were used to judge whether software models are defective or non-defective by analyzing software source codes or developing processes extracting some critical metrics and then building predictor. Isolation forest being an anomaly detection method was modified and introduced firstly in this application community a novel SDP method based on isolation forest was proposed in this paper. Experiment conducted on five real NASA datasets demonstrated the proposed method effective.;
2020 IEEE 13th International Conference on Software Testing Validation and Verification (ICST);A natural method to evaluate the effectiveness of a testing technique is to measure the defect detection rate when applying the created test cases. Here real or artificial software defects can be injected into the source code of software. For a more extensive evaluation injection of artificial defects is usually needed and can be performed via mutation testing using code mutation operators. However to simulate complex defects arising from a misunderstanding of design specifications mutation testing might reach its limit in some cases. In this paper we present an open-source benchmark testbed application that employs a complement method of artificial defect injection. The application is compiled after artificial defects are injected into its source code from predefined building blocks. The majority of the functions and user interface elements are covered by creating front-end-based automated test cases that can be used in experiments.;
2012 12th International Conference on Quality Software;Defects in every software must be handled properly and the number of defects directly reflects the quality of a software. In recent years researchers have applied data mining and machine learning methods to predicting software defects. However in their studies the method in which the machine learning models are directly adopted may not be precise enough. Optimizing the machine learning models used in defects prediction will improve the prediction accuracy. In this paper aiming at the characteristics of the metrics mined from the open source software we proposed three new defect prediction models based on C4.5 model. The new models introduce the Spearman's rank correlation coefficient to the basis of choosing root node of the decision tree which makes the models better on defects prediction. In order to verify the effectiveness of the improved models an experimental scheme is designed. In the experiment we compared the prediction accuracies of the existing models and the improved models and the result showed that the improved models reduced the size of the decision tree by 49.91% on average and increased the prediction accuracy by 4.58% and 4.87% on two modules used in the experiment.;
Evolutionary Optimization of Software Quality Modeling with Multiple Repositories;A novel search-based approach to software quality modeling with multiple software project repositories is presented. Training a software quality model with only one software measurement and defect data set may not effectively encapsulate quality trends of the development organization. The inclusion of additional software projects during the training process can provide a cross-project perspective on software quality modeling and prediction. The genetic-programming-based approach includes three strategies for modeling with multiple software projects: Baseline Classifier Validation Classifier and Validation-and-Voting Classifier. The latter is shown to provide better generalization and more robust software quality models. This is based on a case study of software metrics and defect data from seven real-world systems. A second case study considers 17 different (nonevolutionary) machine learners for modeling with multiple software data sets. Both case studies use a similar majority-voting approach for predicting fault-proneness class of program modules. It is shown that the total cost of misclassification of the search-based software quality models is consistently lower than those of the non-search-based models. This study provides clear guidance to practitioners interested in exploiting their organization's software measurement data repositories for improved software quality modeling.;
Failure Diagnosis for Distributed Systems Using Targeted Fault Injection;This paper introduces a novel approach to automating failure diagnostics in distributed systems by combining fault injection and data analytics. We use fault injection to populate the database of failures for a target distributed system. When a failure is reported from production environment the database is queried to find â€œmatchedâ€ failures generated by fault injections. Relying on the assumption that similar faults generate similar failures we use information from the matched failures as hints to locate the actual root cause of the reported failures. In order to implement this approach we introduce techniques for (i) reconstructing end-to-end execution flows of distributed software components (ii) computing the similarity of the reconstructed flows and (iii) performing precise fault injection at pre-specified executing points in distributed systems. We have evaluated our approach using an OpenStack cloud platform a popular cloud infrastructure management system. Our experimental results showed that this approach is effective in determining the root causes e.g. fault types and affected components for 71-100 percent of tested failures. Furthermore it can provide fault locations close to actual ones and can easily be used to find and fix actual root causes. We have also validated this technique by localizing real bugs that occurred in OpenStack.;
2020 IEEE/ACM 42nd International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER);Bug severity is an important factor in prioritizing which bugs to fix first. The process of triaging bug reports and assigning a severity requires developer expertise and knowledge of the underlying software. Methods to automate the assignment of bug severity have been developed to reduce the developer cost however many of these methods require 70-90% of the project's bug reports as training data and delay their use until later in the development process. Not being able to automatically predict a bug report's severity early in a project can greatly reduce the benefits of automation. We have developed a new bug report severity prediction method that leverages how bug reports are written rather than what the bug reports contain. Our method allows for the prediction of bug severity at the beginning of the project by using an organization's historical data in the form of bug reports from past projects to train the prediction classier. In validating our approach we conducted over 1000 experiments on a dataset of five NASA robotic mission software projects. Our results demonstrate that our method was not only able to predict the severity of bugs earlier in development but it was also able to outperform an existing keyword-based classifier for a majority of the NASA projects.;
2022 IEEE International Conference on Software Maintenance and Evolution (ICSME);As the current COBOL workforce retires entry-level developers are left to keep complex legacy systems maintained and operational. This creates a massive gap in knowledge and ability as companies are having their veteran developers replaced with a new inexperienced workforce. Additionally the lack of COBOL and mainframe technology in the current academic curriculum further increases the learning curve for this new generation of developers. These issues are becoming even more pressing due to the business-critical nature of these systems which makes migrating or replacing the mainframe and COBOL unlikely anytime soon. As a result there is now a huge need for tools and resources to increase new developersâ€™ code comprehension and ability to perform routine tasks such as debugging and defect location. Extensive work has been done in the software engineering field on the creation of such resources. However the proprietary nature of COBOL and mainframe systems has restricted the amount of work and the number of open-source tools available for this domain. To address this issue our work leverages the publicly available technical forum data to build an open-source collection of COBOL programs embodying issues/defects faced by COBOL developers. These programs were reconstructed and organized in a benchmark suite to facilitate the testing of developer tools. Our goal is to provide an open-source COBOL benchmark and testing suite that encourage community contribution and serve as a resource for researchers and tool-smiths in this domain.;
2009 24th International Symposium on Computer and Information Sciences;Application of defect predictors in software development helps the managers to allocate their resources such as time and effort more efficiently and cost effectively to test certain sections of the code. In this research we have used naive Bayes classifier (NBC) to construct our defect prediction framework. Our proposed framework uses the hierarchical structure information about the source code of the software product to perform defect prediction at a functional method level and source file level. We have applied our model on SoftLAB and Eclipse datasets. We have measured the performance of our proposed model and applied cost benefit analysis. Our results reveal that source file level defect prediction improves the verification effort while decreasing the defect prediction performance in all datasets.;
2022 7th International Conference on Computer Science and Engineering (UBMK);Explainability is one of the most investigated quality attributes and nowadays it has an increasing interest of the stakeholders using Artificial Intelligence (AI) especially Machine Learning software. Since AI-based software is different from traditional software in having a black-box nature it has become very important to understand the logic behind the predictions made. In this study we focus on the explainability of Gradient Boosting (GB) classifier used for software defect prediction (SDP). We apply post-hoc model-agnostic methods namely â€œExplain like I am a 5-year oldâ€ (ELl5) â€œLocal Interpretable Model Agnostic Explanationsâ€ (LIME) and â€œSHapley Additive exPlanationsâ€ (SHAP) over an SDP dataset offered by NASA in order to shed light on the explainability of GB classifier. More specifically we use ELI5 and LIME to explain instances locally and SHAP to get both local and global explanations. The results suggest a post-hoc and model-agnostic way to quantify explainability and indicate that all three methods used in this study performed consistent results with each other while explaining the GB model.;
2015 International Conference on Green Computing and Internet of Things (ICGCIoT);A lot of importance has been attached to the testing phase of the Software Development Life Cycle (SDLC). It is during this phase it is checked whether the software product meets user requirements or not. Any discrepancies that are identified are removed. But testing needs to be monitored to increase its effectiveness. Software Reliability Growth Models (SRGMs) that specify mathematical relationships between the failure phenomenon and time have proved useful. Our propose method develop a reliability model will provides a method for purpose of testing-effort functions for software reliability growth model based on non-homogeneous Poisson process (NHPP). In this propose method we will consider the case where the time dependent behaviors of testing-effort expenditures are described by Weibull-Type Testing-Effort Function. In the proposed model contained of four stages namely: Initial Stage: In this stage we will collect basic assumption attribute for model. After that we will got for First stage here we will present Modeling Software Reliability and Testing Effort functions and the same time software release policy. A new imperfect debugging discrete software reliability growth model with testing effort. In third stage: we will get performance analysis model to extend for the tradeoff analysis with respect to aspiration level for reliability of the SRGM. The predictive on cost reliability and intensity of the model has been worked on two real failure datasets. The results obtained show remarkable improvements and are fairly encouraging.;
PyBugHive: A Comprehensive Database of Manually Validated Reproducible Python Bugs;Python is currently the number one language in the TIOBE index and has been the second most popular language on GitHub for years. But so far there are only a few bug databases that contain bugs for Python projects and even fewer in which bugs can be reproduced. In this paper we present a manually curated database of reproducible Python bugs called PyBugHive. The initial version of PyBugHive is a benchmark of 149 real manually validated bugs from 11 Python projects. Each entry in our database contains the summary of the bug report the corresponding patch and the test cases that expose the given bug. PyBugHive features a rich command line interface for accessing both the buggy and fixed versions of the programs and provides the abstraction for executing the corresponding test cases. The interface facilitates highly reproducible empirical research and tool comparisons in fields such as testing automated program repair or bug prediction. The usage of our database is demonstrated through a use case involving a large language model GPT-3.5. First we evaluated the bug detection capabilities of the model with the help of the bug repository. Using multiple prompts we found out that GPT-3.5 was able to detect 67 out of 149 bugs (45%). Furthermore we leveraged the constructed bug dataset in assessing the automatic program repair capabilities of GPT-3.5 by comparing the generated fixes with the real patches contained in the dataset. However its performance was far worse in this task compared to bug detection as it was able to fix only one of the detected issues.;
2015 2nd International Symposium on Dependable Computing and Internet of Things (DCIT);To contribute software testing and save testing costs a wide range of machine learning approachs have been studied to predict defects in software modules. Unfortunately the imbalanced nature of this type of data increases the learning difficulty of such a task. In this paper we present UCRF a method based on undersampling technique and conditional random field (CRF) for software defect prediction in imbalance distribution. In our proposed method firstly we leverage meanshift clustering method to reduce the samples of majority class for balancing the train data set. Secondly we propose to apply CRF model in the above balanced train data set because the CRF model can handle complex features without any change in training procedure. Interestingly we find that the UCRF method achieves much better final results than the other approach as shown in the software defect data classification task.;
Software defect association mining and defect correction effort prediction;Much current software defect prediction work focuses on the number of defects remaining in a software system. In this paper we present association rule mining based methods to predict defect associations and defect correction effort. This is to help developers detect software defects and assist project managers in allocating testing resources more effectively. We applied the proposed methods to the SEL defect data consisting of more than 200 projects over more than 15 years. The results show that for defect association prediction the accuracy is very high and the false-negative rate is very low. Likewise for the defect correction effort prediction the accuracy for both defect isolation effort prediction and defect correction effort prediction are also high. We compared the defect correction effort prediction method with other types of methods - PART C4.5 and Naive Bayes - and show that accuracy has been improved by at least 23 percent. We also evaluated the impact of support and confidence levels on prediction accuracy false-negative rate false-positive rate and the number of rules. We found that higher support and confidence levels may not result in higher prediction accuracy and a sufficient number of rules is a precondition for high prediction accuracy.;
DreamLoc: A Deep Relevance Matching-Based Framework for bug Localization;To improve the software debugging efficiency bug localization techniques have been developed to automatically locate buggy files based on bug reports. Traditional information retrieval-based bug localization cannot deal with the lexical mismatch thus its performance is limited. In recent years some deep learning models have been proposed to learn the semantics of bug reports and source files to bridge the lexical gap. However their accuracy is still limited as building accurate semantic representations of bug reports and source files is very challenging. Recently relevance matching was proposed to identify whether a document is relevant to a given query by considering both local matching and global matching. In this work we propose a novel framework DreamLoc which utilizes a relevance matching model to locate buggy files. Specifically DreamLoc conducts the local matching by employing an attention-based mechanism to calculate the matching scores between bug report terms and code snippets. It also conducts the global matching by employing a gating mechanism to aggregate results of local matching and obtain the final matching score between a bug report and a source file. Since the local matching considers the relevance between each word and the global matching differentiates the importance of words DreamLoc can effectively model the characteristics of bug reports and source files. Experimental results on five benchmark datasets show that DreamLoc outperforms five state-of-the-art models. For example compared with DeepLoc a recently proposed approach the evaluation measures Accuracy@10 MAP and MRR are improved by 6.4% 7.4% and 7.2% respectively.;
2018 IEEE/ACM 1st International Workshop on Security Awareness from Design to Deployment (SEAD);The security of a company's software products is of paramount importance of course and arguably even more important than software reliability and the other key quality attributes. But companies are currently faced with a troublesome dilemma: Supplying customers with more features at greater speeds than in the past has become the norm high feature velocity fairly static engineering headcounts and shorter release cycles are conspiring to threaten both software reliability and security. The work described in this paper is an attempt to baseline and (internally) benchmark the state of our company's software security and also includes some data regarding the state of software reliability across the company's products. Of particular interest in this study is learning more about the extent of software vulnerabilities emanating from the open source software that we import and use in our commercial products. Prior evidence had been building that suggested that such 'third-party software' (TPS) is inherently more vulnerable to security (and reliability) problems. We have examined the software vulnerability occurrences across all the company's software in the aggregate and have found that the TPS used in our products primarily open source software initially contains more vulnerabilities than internally-produced software. Security and reliability problems both in terms of bug counts and percentages of total code volume correlate quite well and examples of this are also shown but we cannot rely on this concurrence in our study: Software security on its own has been examined in detail and while some findings are documented here many questions remain.;
Evaluating Automatic Program Repair Capabilities to Repair API Misuses;API misuses are well-known causes of software crashes and security vulnerabilities. However their detection and repair is challenging given that the correct usages of (third-party) apis might be obscure to the developers of client programs. This paper presents the first empirical study to assess the ability of existing automated bug repair tools to repair api misuses which is a class of bugs previously unexplored. Our study examines and compares 14 Java test-suite-based repair tools (11 proposed before 2018 and three afterwards) on a manually curated benchmark (APIRepBench) consisting of 101 api misuses. We develop an extensible execution framework (APIARTy) to automatically execute multiple repair tools. Our results show that the repair tools are able to generate patches for 28 percent of the api misuses considered. While the 11 less recent tools are generally fast (the median execution time of the repair attempts is 3.87 minutes and the mean execution time is 30.79 minutes) the three most recent are less efficient (i.e. 98 percent slower) than their predecessors. The tools generate patches for api misuses that mostly belong to the categories of missing null check missing value missing exception and missing call. Most of the patches generated by all tools are plausible (65 percent) but only few of these patches are semantically correct to human patches (25 percent). Our findings suggest that the design of future repair tools should support the localisation of complex bugs including different categories of api misuses handling of timeout issues and ability to configure large software projects. Both APIRepBench and APIARTy have been made publicly available for other researchers to evaluate the capabilities of repair tools on detecting and fixing api misuses.;
2022 14th International Conference on Knowledge and Systems Engineering (KSE);This paper proposes a cooperative coevolutionary approach namely COESDP to the software defect prediction (SDP) problem. The proposed method consists of three main phases. The first one conducts data preprocessing including data sampling and cleaning. The second phase utilizes a multi-population coevolutionary approach (MPCA) to find out optimal instance selection solutions. These first two phases help to deal with the imbalanced data challenge of the SDP problem. While the data sampling method aids in the creation of a more balanced data set MPCA supports in the elimination of unnecessary data samples (or instances) and the selection of crucial instances. The output of phase 2 is a set of different optimal solutions. Each solution is a way of selecting instances from which to create a classifier (or weak learners). Phase 3 utilizes an ensemble learning method to combine these weak learners and produce the final result. The proposed algorithm is compared with conventional machine learning algorithms ensemble learning algorithms computational intelligence algorithms and an other multi-population algorithm on 6 standard SDP datasets. Experimental results show that the proposed method gives better and more stable results in comparison with other methods and it can tackle the challenge of imbalance in the SDP data.;
2016 3rd International Conference on Computing for Sustainable Global Development (INDIACom);Bug localization is the process of identifying the elements of source code that require modification to fix the bug. By automating the task of bug localization efficiently the cost of software can also be reduced. For performing bug localization many Information Retrieval models have been used in past. In this paper bug localization has been performed using Pachinko Allocation Model (PAM). PAM is also an IR model which falls under the category of topic models and has not been used for locating bugs yet. This paper describes the proposed PAM based approach for bug localization at file level. The PAM based approach is compared with LDA based approach and it has been shown that PAM based bug localization performs better as compared to LDA based bug localization. For evaluating the performance of PAM and LDA based approaches the datasets downloaded from two open source projects i.e. Rhino and ModeShape have been used.;
2024 International Conference on Advances in Data Engineering and Intelligent Computing Systems (ADICS);The purpose of this research is to compare and contrast the effectiveness of the traditional K-Nearest Neighbor (KNN) method with a new approach based on random forests (RF) for detecting software bugs (SB). The main goal is to evaluate how well the proposed technique finds and predicts software problems while keeping security risks to a minimum. The KNN technique and a new RF based methodology are compared in this research to see which one is better at predicting SB. In order to gather information on software projects and the bug reports that are associated with them we make use of the Eclipse Bug Data dataset. This dataset is accessible to the general public and contains information about the number of lines of code the complexity of the code and the number of developers that participated in the project. In order to evaluate the effectiveness of different approaches the dataset is randomly split into two groups every consisting of 10 samples. We train and test the KNN technique with one set of data and then we train and test the innovative RF - based approach with the other set of data. Both approaches are executed using Python and the scikit-learn package for machine learning (ML). Statistical power (G-power) = 0.85 alpha = 0.5 beta = 0.2 and confidence interval = 95% were used to perform the research and guarantee the findings' validity and reliability. Results from the experiments showed that compared to the KNN method's 75.59% accuracy the proposed RF - based technique reached an impressive 78.59%. According to these results the innovative strategy reduced security risks better than the KNN technique for SB prediction. The values obtained were 0.000 (p<0.05) indicating statistical significance. Research shows that when dealing with missing data and high-dimensional data both of which are common in software issue prediction the RF based approach performs better.;
2021 International Conference on Electronic Information Technology and Smart Agriculture (ICEITSA);In view of the inconvenience of parameter setting in the existing fault location method based on deep neural network this paper combines the global random search ability of Genetic Algorithm L2 regularization to prevent model overfitting and deep neural network to learn complex nonlinear ability a fault location algorithm based on G-DNN is proposed. The optimal number of hidden layer neurons learning rate training period and L2 regularization coefficient of deep neural network are obtained by Genetic Algorithm Input the statement coverage information and state values into the deep neural network to calculate the suspiciousness value of each executable statement Locate defects from high to low according to the suspiciousness values. The Siemens Suite is used as the experimental sample and the G-DNN is compared with the five defect location algorithms. The results show that the defect of the G-DNN can locate defects more accurately and the positioning efficiency is improved.;
2019 6th International Conference on Dependable Systems and Their Applications (DSA);Industrial software testing is the key part before the release of industrial software. The software test engineers without industrial knowledge and manufacturing experience cannot test for its unique functional performance requirements and industry characteristics. Therefore the industrial software testing knowledgeis studied basedon ontologyinthis paper. The knowledge of industrial software testing domain is represented by the ontology whichis constructed by the improved seven-step method. Andthe graphdatabase is usedto store knowledge. The management of industrial software testing knowledge is standardized by the Industrial Software Testing Knowledge Base which is helpful to improve the quality and efficiency of industrial software test.;
An Empirical Study of Boosting Spectrum-Based Fault Localization via PageRank;Manual debugging is notoriously tedious and time-consuming. Therefore various automated fault localization techniques have been proposed to help with manual debugging. Among the existing fault localization techniques spectrum-based fault localization (SBFL) is one of the most widely studied techniques due to being lightweight. The focus of the existing SBFL techniques is to consider how to differentiate program entities (i.e. one dimension in program spectra) indeed this focus is aligned with the ultimate goal of finding the faulty lines of code. Our key insight is to enhance the existing SBFL techniques by additionally considering how to differentiate tests (i.e. the other dimension in program spectra) which to the best of our knowledge has not been studied in prior work. We present our basic approach PRFL a lightweight technique that boosts SBFL by differentiating tests using PageRank algorithm. Specifically given the original program spectrum information PRFL uses PageRank to recompute the spectrum by considering the contributions of different tests. Next traditional SBFL techniques are applied on the recomputed spectrum to achieve more effective fault localization. On top of PRFL we explore PRFL+ and PRFLMA two variants which extend PRFL by optimizing its components and integrating Method-level Aggregation technique respectively. Though being simple and lightweight PRFL has been demonstrated to outperform state-of-the-art SBFL techniques significantly (e.g. ranking 39.2% / 82.3% more real/artificial faults at Top-1 compared with the most effective traditional SBFL technique) with low overhead (e.g. around 6 minutes average extra overhead on real faults) on 395 real faults from 6 Defects4J projects and 96925 artificial (i.e. mutation) faults from 240 GitHub projects. To further validate PRFL's effectiveness we compare PRFL with multiple recent proposed fault localization techniques (e.g. Multric Metallaxis and MBFL-hybrid-avg) and the experimental results show that PRFL outperforms them as well. Furthermore we study the performance of PRFLMA and the experimental results present it can locate 137 real faults (73.4% / 24.5% more compared with the most effective SBFL/PRFL technique) and 35058 artificial faults (159.6% / 28.1% more than SBFL/PRFL technique) at Top-1. At last we study the generalizability of PRFL on another benchmark Bugs.jar and the result shows PRFL can help locate around 30 percent more faults at Top 1.;
2020 IEEE International Conference on Software Maintenance and Evolution (ICSME);Fault localization is considered a difficult and time consuming activity. However tool support for automated fault localization is still limited because state-of-the-art algorithms often fail to provide efficient help to the user. They usually offer a ranked list of suspicious code elements but the fault is not guaranteed to be found among the highest ranks. In Spectrum-Based Fault Localization (SBFL) - which uses code coverage information of test cases and their execution outcomes to calculate the ranks - the developer has to investigate several locations before finding the faulty code element. Yet all the knowledge she a priori has or acquires during this process is not reused by the SBFL tool. We propose an approach in which the developer interacts with the SBFL algorithm by giving feedback on the elements of the prioritized list. We exploit contextual knowledge of the user about the next item in the ranked list (e. g. a statement) with which larger code entities (e. g. a whole function) can be repositioned in their suspiciousness. First we evaluated the approach using simulated users incorporating two types of imperfections their knowledge and confidence levels. On SIR and Defects4J results showed notable improvements in fault localization efficiency even with strong user imperfections. We then empirically evaluated the effectiveness of the approach with real users which also showed promising results.;
2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM);Background: Static analysis security testing (SAST) tools may be evaluated using synthetic micro benchmarks and benchmarks based on real-world software. Aims: The aim of this study is to address the limitations of the existing SAST tool benchmarks: lack of vulnerability realism uncertain ground truth and large amount of findings not related to analyzed vulnerability. Method: We propose Delta-Bench - a novel approach for the automatic construction of benchmarks for SAST tools based on differencing vulnerable and fixed versions in Free and Open Source (FOSS) repositories. To test our approach we used 7 state of the art SAST tools against 70 revisions of four major versions of Apache Tomcat spanning 62 distinct Common Vulnerabilities and Exposures (CVE) fixes and vulnerable files totalling over 100K lines of code as the source of ground truth vulnerabilities. Results: Our experiment allows us to draw interesting conclusions (e.g. tools perform differently due to the selected benchmark). Conclusions: Delta-Bench allows SAST tools to be automatically evaluated on the real-world historical vulnerabilities using only the findings that a tool produced for the analysed vulnerability.;
Evaluating and Improving Unified Debugging;Automated debugging techniques including fault localization and program repair have been studied for over a decade. However the only existing connection between fault localization and program repair is that fault localization computes the potential buggy elements for program repair to patch. Recently a pioneering work ProFL explored the idea of unified debugging to unify fault localization and program repair in the other direction for the first time to boost both areas. More specifically ProFL utilizes the patch execution results from one state-of-the-art repair system PraPR to help improve state-of-the-art fault localization. In this way ProFL not only improves fault localization for manual repair but also extends the application scope of automated repair to all possible bugs (not only the small ratio of bugs that repair systems can automatically fix). However ProFL only considers one program repair system (i.e. PraPR) and it is not clear how other existing program repair systems based on different designs contribute to unified debugging. In this work we perform an extensive study of the unified debugging approach on 16 state-of-the-art program repair systems for the first time. Our initial experimental results on the widely studied Defects4J benchmark suite reveal various practical guidelines for unified debugging such as (1) nearly all 16 studied repair systems positively contribute to unified debugging despite their varying repair capabilities (2) repair systems targeting multi-edit patches can bring extraneous noise into unified debugging (3) repair systems with more executed/plausible patches tend to perform better for unified debugging (4) unified debugging effectiveness does not rely on the availability of correct patches from automated repair and (5) we propose a new unified debugging technique UniDebug++ which localizes over 20% more bugs within Top-1 than state-of-the-art unified debugging technique ProFL (evaluated against four Defects4J subjects). Furthermore we conduct more comprehensive studies to extend the above experiments to make the following additional contributions: we (6) further perform an extensive study on 76.3% additional buggy versions from Defects4J (for Closure and Mockito) and confirm that UniDebug++ again outperforms ProFL by localizing 185 (out of 395 in total) bugs within Top-1 14% more than ProFL (7) investigate the impact of 33 SBFL formulae on unified debugging and observe that UniDebug++ consistently improves upon all formulae e.g. 61% and 53% average improvement on MFR / MAR (8) demonstrate that UniDebug++ can substantially boost state-of-the-art learning-based method-level fault localization techniques (9) extend unified debugging to the statement level for first time and observe that UniDebug++ localizes 78 (out of 395 in total) bugs within Top-1 (22% more bugs than ProFL) and outperforms state-of-the-art learning-based fault localization techniques by 30% and finally (10) propose a new technique UniDebug+$^\star$â˜… based on detailed patch statistics to improve upon UniDebug++ e.g. further localizing up to 9% more bugs within Top-1 than UniDebug++.;
2015 International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE);Integrated software products are complex in design. They are prone to defects caused by integrated and non-integrated modules of the entire integrated software suite. In such software products a small proportion of defects are fixed as soon as they are reported. Rest of the defects are targeted for fixes in future product release cycles. Among such targeted defects most of them seem to be insignificant and innocuous in the current version but have the potential to become acute in future versions. In this paper we propose an approach to study defect dependency of the reported defect using a dependency metric. Identifying the dependency of a defect in an integrated product suite can help the product stake-owners to prioritize them and help improve software quality.;
2022 Applied Informatics International Conference (AiIC);detecting defect in a software product prior to testing reduces the cost of testing and improve the quality of the software product. Various methods for enhancing the accuracy of defect prediction model have been published. The goal of this review is to identify and analyze the dataset models framework and the performance of software defect prediction model. The IEEExplore Science Direct Scopus and Google Scholar databases were used to search and download the relevant papers. Sixty-eight (68) papers published between 2017 to 2021 were selected based on exclusion and inclusion criteria. Analysis of the selected studies revealed that 100% of the selected articles used the publicly available dataset from NASA PROMISE and others. The most frequently used models in software defect prediction studies were identified. The analysis also revealed IEEE Transactions on Software Engineering Journal is the most significant journal with respect to software defect prediction studies using Scimago Journal Ranking as criteria. The review also identified studies on enhancing the predictive performance of defect prediction models. Software defect prediction is still active and sound. Thus needs more research especially on enhancement methods.;
2024 5th International Conference on Electronic Communication and Artificial Intelligence (ICECAI);This paper proposes an artificial intelligence-based solution to the problem of C language code defect localization. A systematic analysis of the types and characteristics of C language code defects is conducted. A hybrid model framework integrating machine learning and deep learning is constructed and various defect localization models are designed and implemented including random forests support vector machines convolutional neural networks and graph neural networks. Comprehensive experimental evaluations are conducted on common datasets such as PROMISE and CGD indicating that the proposed models outperform traditional methods in terms of defect localization accuracy recall and other metrics with the highest Fl score reaching 0.91. Additionally various model fusion and integration strategies are explored to further enhance defect localization performance. The paper also discusses the application scenarios optimization strategies and interpretability issues of the models in practical software development providing new insights for improving software reliability and security.;
2009 Eighth IEEE/ACIS International Conference on Computer and Information Science;Software used in safety-critical system must have high dependability. Software testing and V&V (Verification and Validation) activities are very important for assuring high software quality. If we can predict the risky modules in safety-critical software testing activities and regulation activities can be applied to them more intensively. In this paper we classify the estimated risk classes which can be used for deep testing and V&V. We predict the risk class for each module using support vector machines. We can consider that the modules classified to risk class 5 or 4 are more risky than others relatively. For all classification error rates we expect that the results can be useful and practical for software testing V&V and activities for regulatory reviews. In the future works to improve the practicality we will have to investigate other machine learning algorithms and datasets.;
2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE);Software Defect Prediction is an important activity used in the Testing Phase of the software development life cycle. Within the research of new defect prediction approaches and the selection of training sets for the classification task different benchmarks have been analyzed in the literature. They provide several features and defective information over specific software archives. Therefore they are commonly used in research to evaluate new approaches. However the current benchmarks contain several limitations such as lack of project variability outdated benchmarks single-version projects a small number of projects and metrics unavailable resources poor usability and non-extensible tools. Therefore we introduce a novel tool Bgu rEpository mlning foR bUg predicIion (BEIRUT) for benchmark generation for defect prediction composed of three main features: Given an open-source repository from GitHub BEIRUT mines the software repository by (1) selecting the best $k$ versions based on the defective rate of each version (2) generating training sets and a testing set for defect prediction composed of a large number of metrics and defective information extracted from each of the selected versions and (3) creating defect prediction models from those extracted metrics. In the end BEIRUT extracts a diversified catalog of 644 metrics and the defective information from each component of $k$ versions automatically selected based on the rate of defects in each version. They were collected from 512 different projects starting from 2009. The tool is also supplemented with an easy-to-use web interface that provides a configurable selection of projects and metrics and an interface to manage the defect prediction tasks. Moreover this tool is adapted to be extended with new projects and new extractors introducing new metrics to the benchmark. The web service tool can be found at rps.ise.bgu.ac.il/beirut.;
2023 International Conference on Applied Intelligence and Sustainable Computing (ICAISC);Genetic algorithm is a computational technique that simulates the process of natural selection to solve complex problems. It has been widely applied in various fields including software engineering. One of its applications in software engineering is test data generation. Test data generation is an important component of software testing aimed at ensuring the quality and reliability of software systems. However generating effective test data can be challenging and time-consuming especially for complex systems with large input domains. Genetic algorithm provides a solution to this problem by using population based search methods to generate test data that meets specific criteria. This algorithm starts from the initial population of random test cases and iteratively evolves them through selection crossover and mutation operations until a satisfactory solution is found. The effectiveness of genetic algorithms in generating test data has been proven in various studies. It has been proven to generate various effective test cases covering different parts of the input domain and revealing hidden faults in the system. In short genetic algorithms are a powerful tool for software engineers to generate effective test data for complex systems. Its application can significantly improve the quality and reliability of software systems by identifying hidden faults that may not have been discovered. In this study we analyzed genetic algorithms in current software testing controlled them based on model data and generation structure in software testing and obtained effective calculation methods based on various genetic algorithms. By using traditional genetic algorithms and various swarm genetic algorithms to analyze the distribution and optimal value interval of two curves it is shown that various swarm genetic methods have strong optimization ability high accuracy and can quickly jump out of local optima to obtain the final solution. They are a very effective optimization algorithm.;
2010 Asia Pacific Software Engineering Conference;This paper investigates the relationship between the use of predicate-based and statement-based program spectra for bug localization. Branch and path spectra are also considered. Although statement and predicate spectra can be based on the same raw data the way the data is aggregated results in different information being lost. We propose a simple and cheap modification to the statement-based approach which retains strictly more information. This allows us to compare statement and predicate ''metrics'' (functions used to rank the statements predicates or paths). We show that improved bug localization performance is possible using single-bug models and benchmarks.;
2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE);This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding design requirements repair refactoring performance improvement documentation and analytics. However these very same emergent properties also pose significant technical challenges we need techniques that can reliably weed out incorrect solutions such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable efficient and effective LLM-based SE.;
2010 International Conference on Computational Intelligence and Software Engineering;Although the value of using static code attributes to learn defect predictor has been widely debated there is no doubt that software defect predictions can effectively improve software quality and testing efficiency. Many data mining methods have already been introduced into defect predictions. We noted there have several versions of defect predictor based on Naive Bayes theory and analyzed their difference estimation method and algorithm complexity. We found the best one which is Multi- variants Gauss Naive Bayes (MvGNB) by performing prediction performance evaluation and we compared this model with decision tree learner J48. Experiment results on the benchmarking data sets of MDP made us believe that MvGNB would be useful for defect predictions.;
2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA);The use of Machine Learning (ML) classifiers to predict defective software modules are useful to help on planning software testing activities. Most of those studies use the accuracy as the main metric to evaluate the quality of the ML classifier. However when unbalanced datasets are used to train and test the classifier the ML model becomes biased. Biased ML models hide their real accuracy. In this context this study proposes an approach to enhance the use of ML classifiers for predicting defective software modules even with unbalanced datasets. The results indicate: (1) a significant reduction on the number of false negatives (2) a considerable gain on the efficacy of the software testing (3) an increase of the number of modules correctly indicated as defective however there were also (4) an increase of the scope of the test suggested by the model (5) a reduction of the software testing efficiency (6) an increase of the number of the false positives and (7) reduction of the overall accuracy. Therefore the proposed approach imposes a trade-off to be considered when planning the software testing activities. Finally this study also proposes an approach to help managers to deal with those trade-offs considering the resource constraints.;
2013 Joint Conference of the 23rd International Workshop on Software Measurement and the 8th International Conference on Software Process and Product Measurement;The two ongoing repositories of software projects in the software engineering community are the ISBSG (International Software Benchmarking Standards Group) Repository and PROMISE (Predictor Models In Software Engineering). These repositories lack structured documentation and a researcher interested in using the datasets has to conduct his own investigation to identify the datasets that are suitable for his purposes. This paper provides additional information on these datasets by identifying the topics addressed highlighting the availability of the data file and of the description of attributes related to the datasets and indicating their usefulness for benchmarking studies.;
2021 International Conference on Data and Software Engineering (ICoDSE);defect prediction (SDP) is process of identifying software defect on the early testing stage of SDLC. SDP can saving time software tester on the development process. There are some issues on the way to develop SDP to be more effective one of the issues is how to increase accuracy for predicting whereas most of dataset for SDP typically has imbalanced data for the defect class. In other words the dataset will naturally affecting appearance of prediction error on the classification model. This paper is to proposed Synthetic Minority Oversampling Technique (SMOTE) and artificial neural network to address the issues. The SMOTE is used to handling imbalance data and the artificial neural network is used to build predicting model. SMOTE and artificial neural network are applied to discover result of classification performance. The scenario is comparing imbalanced dataset that already processed with SMOTE and without SMOTE than classifying using artificial neural network and measured using value of precision recall and f-measure. The experimental result show that the proposed SMOTE and Artificial Neural Network (ANN) and Association Rule Mining (ARM) method increase predicting performance for software defect prediction comparing with only Artificial Neural Network method. For parameter precision recall accuracy and F-measure improving increase are 2.2% 18.4% 22.4% and 8.8% At comparing ANN+ARM with ANN+ARM+SMOTE and beside that comparison about ANN+ARM with ANN+ARM+SMOTE also improve by 32.2% 70.24% 7% and 63.38%. The last comparison show different results from the others the ANN+ARM+SMOTE get smaller performance value than combination ANN + SMOTE with gap score 17.2% 7.8% 1% 15.6%. It happen because feature selection with Association Rule Mining didnâ€™t help to improve predicting accuracy performance.;
2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR);A growing interest in deep learning (DL) has instigated a concomitant rise in DL-related software (DLSW). Therefore the importance of DLSW quality has emerged as a vital issue. Simultaneously researchers have found DLSW more complicated than traditional SW and more difficult to debug owing to the black-box nature of DL. These studies indicate the necessity of automatic debugging techniques for DLSW. Although several validated debugging techniques exist for general SW no such techniques exist for DLSW. There is no standard bug benchmark to validate these automatic debugging techniques. In this study we introduce a novel bug benchmark for DLSW Denchmark consisting of 4577 bug reports from 193 popular DLSW projects collected through a systematic dataset construction process. These DLSW projects are further classified into eight categories: framework platform engine compiler tool library DL-based application and others. All bug reports in Denchmark contain rich textual information and links with bug-fixing commits as well as three levels of buggy entities such as files methods and lines. Our dataset aims to provide an invaluable starting point for the automatic debugging techniques of DLSW.;
2006 IEEE International Conference on Information Reuse & Integration;Genetic programming (GP) is a parallel searching technique where many solutions can be obtained simultaneously in the searching process. However when applied to real-world classification tasks some of the obtained solutions may have poor predictive performances. One of the reasons is that these solutions only match the shape of the training dataset failing to learn and generalize the patterns hidden in the dataset. Therefore unexpected poor results are obtained when the solutions are applied to the test dataset. This paper addresses how to remove the solutions which will have unacceptable performances on the test dataset. The proposed method in this paper applies a multi-dataset validation phase as a filter in GP-based classification tasks. By comparing our proposed method with a standard GP classifier based on the datasets from seven different NASA software projects we demonstrate that the multi-dataset validation is effective and can significantly improve the performance of GP-based software quality classification models;
2023 Congress in Computer Science Computer Engineering & Applied Computing (CSCE);This paper introduces a cost-effective metric for association rule mining in software defect prediction where defective module conditions are represented as association rules. The metric calculates the expected number of defects discovered in modules that satisfy an association rule considering a limited test effort or test cases. Since conducting full testing on all modules is impractical due to resource limitations the proposed metric helps identify the most cost-effective modules to test within given constraints. It is based on the extended exponential Software Reliability Growth Model (SRGM) incorporating the module size parameter to account for the increased effort required to detect defects in larger modules. To evaluate the metric's effectiveness association rules were extracted and prioritized using the proposed metric across datasets from four open source software projects. The assessment employed the widely used LOC-based cumulative-lift chart to measure the cost-effectiveness of defect prediction. The findings demonstrate that the proposed metric effectively prioritizes rules with a higher potential for defect discovery compared to conventional association rule metrics like confidence and odds ratio.;
2013 17th European Conference on Software Maintenance and Reengineering;To collect software bugs found by users development teams often set up bug trackers using systems such as Bugzilla. Developers would then fix some of the bugs and commit corresponding code changes into version control systems such as svn or git. Unfortunately the links between bug reports and code changes are missing for many software projects as the bug tracking and version control systems are often maintained separately. Yet linking bug reports to fix commits is important as it could shed light into the nature of bug fixing processes and expose patterns in software management. Bug linking solutions such as ReLink have been proposed. The demonstration of their effectiveness however faces a number of issues including a reliability issue with their ground truth datasets as well as the extent of their measurements. We propose in this study a benchmark for evaluating bug linking solutions. This benchmark includes a dataset of about 12000 bug links from 10 programs. These true links between bug reports and their fixes have been provided during bug fixing processes. We designed a number of research questions to assess both quantitatively and qualitatively the effectiveness of a bug linking tool. Finally we apply this benchmark on ReLink to report the strengths and limitations of this bug linking tool.;
2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE);Automatic software debugging mainly includes two tasks of fault lo-calization and automated program repair. Compared with the traditional spectrum-based and mutation-based methods deep learning-based methods are proposed to achieve better performance for fault localization. However the existing methods ignore the deep seman-tic features or only consider simple code representations. They do not leverage the existing bug-related knowledge from large-scale open-source projects either. In addition existing template-based program repair techniques can incorporate project specific information better than deep-learning approaches. However they are weak in selecting the fix templates for efficient program repair. In this work we propose a novel approach called TRANSFER which lever-ages the deep semantic features and transferred knowledge from open-source data to improve fault localization and program repair. First we build two large-scale open-source bug datasets and design 11 BiLSTM-based binary classifiers and a BiLSTM-based multi-classifier to learn deep semantic features of statements for fault localization and program repair respectively. Second we combine semantic-based spectrum-based and mutation-based features and use an MLP-based model for fault localization. Third the semantic-based features are leveraged to rank the fix templates for program repair. Our extensive experiments on widely-used benchmark De-fects4J show that TRANSFER outperforms all baselines in fault localization and is better than existing deep-learning methods in automated program repair. Compared with the typical template-based work TBar TRANSFER can correctly repair 6 more bugs (47 in total) on Defects4J.;
Software fault interactions and implications for software testing;Exhaustive testing of computer software is intractable but empirical studies of software failures suggest that testing can in some cases be effectively exhaustive. We show that software failures in a variety of domains were caused by combinations of relatively few conditions. These results have important implications for testing. If all faults in a system can be triggered by a combination of n or fewer parameters then testing all n-tuples of parameters is effectively equivalent to exhaustive testing if software behavior is not dependent on complex event sequences and variables have a small set of discrete values.;
2008 Sixth IEEE International Conference on Software Engineering and Formal Methods;Error diagnosis which is the process of identifying the root causes of bugs in software is a time-consuming process. In general it is hard to automate error diagnosis due to the unavailability of a full ldquogoldenrdquo specification of the system behavior in realistic software development. We propose a repair-based proof-guided error diagnosis (PED) framework that provides a first-line attack to find the root causes of the errors in programs by pin-pointing the possible error-sites (buggy statements) and suggesting possible repair fixes. Our framework does not need a complete system specification. Instead it automatically ldquominesrdquo partial specifications of the intended program behavior from the proofs obtained by static program analysis for standard safety checkers. It uses these partial specifications along with the multiple error traces provided by a model checker to narrow down the possible error sites. It also exploits inherent correlations among the program statements. To capture common programming mistakes it directs the search to those statements that could be buggy due to simple copy-paste operations or syntactic mistakes such as using les instead of <. To further improve debugging it prioritizes the repair solutions. We implemented and integrated the PED tool as a plug-in module to a software verification framework. We show the efficacy of such a framework on public benchmarks.;
2019 International Conference on Information Technology and Computer Application (ITCA);As we all know there are a lot of software testing related technologies and tools in the market at this stage and there are also a lot of professional organizations and organizations working in this field. How to evaluate and measure the software testing capabilities of these tools and organizations has important value. In fact as the software industry grows the scale of software will continue to expand and the resulting consequences are more and even more difficult to find more deadly software errors. At this point the correct choice of software testing tools is not only from the consideration of saving development costs but also directly affects whether the software can be put into normal operation and whether it needs to spend huge costs in post-maintenance. For a long time the relevant research on software testing ability evaluation is not perfect. This paper makes the testing ability of software testing tools can be quantitatively evaluated by constructing an evaluation model of software testing capabilities. At the same time this paper also designs a benchmark test set based on software error injection technology. Through the operation of the benchmark test set on different test tools the corresponding evaluation indicators can be obtained and the different test tools are finally compared in the evaluation model. This paper selects several representative test methods currently available on the market. The test set is based on the Siemens Suite. The experimental results show that the performance of these software test methods can be effectively found in accordance with the evaluation system proposed in the paper.;
2020 IEEE/ACM 28th International Conference on Program Comprehension (ICPC);Information Retrieval (IR) methods have been recently employed to provide automatic support for bug localization tasks. However for an IR-based bug localization tool to be useful it has to achieve adequate retrieval accuracy. Lower precision and recall can leave developers with large amounts of incorrect information to wade through. To address this issue in this paper we systematically investigate the impact of combining various IR methods on the retrieval accuracy of bug localization engines. The main assumption is that different IR methods targeting different dimensions of similarity between artifacts can be used to enhance the confidence in each others' results. Five benchmark systems from different application domains are used to conduct our analysis. The results show that a) near-optimal global configurations can be determined for different combinations of IR methods b) optimized IR-hybrids can significantly outperform individual methods as well as other unoptimized methods and c) hybrid methods achieve their best performance when utilizing information-theoretic IR methods. Our findings can be used to enhance the practicality of IR-based bug localization tools and minimize the cognitive overload developers often face when locating bugs.;
2024 2nd International Conference on Sustainable Computing and Smart Systems (ICSCSS);Software testing is essential for ensuring the reliability and quality of software systems. Fault prediction and proneness have become critical concerns for the tech industry and software professionals. Traditional methods rely on past fault occurrences or faulty modules which are often resource-intensive and exhaustive. Consequently there's a growing interest in predictive techniques for early fault detection during the development lifecycle. In this research Machine learning (ML) classification models have been proposed for fault prediction in software testing using historical data to train models that recognize patterns indicative of faulty code. Automated software fault recovery models driven by ML further enhance performance reduce faults and optimize time and costs. Software defect predictive development models using various ML classification models including Neural Networks (NN) applied to a real-world testing dataset have been proposed. To overcome Class imbalance problem SMOTE ENN (Synthetic Minority Oversampling Technique Edited Nearest Neighbor) method has been implemented and accuracy has been used as the primary evaluation metric. The Random Forest model achieved a notable fault prediction accuracy of 93 %. Additionally through comprehensive literature analysis the research delineates trends highlights strengths and suggests potential future research directions.;
2018 7th International Conference on Reliability Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO);Rapid development of software technology has influence on substantial industrial growth. Wide application of software in business related matters leads to development of reliable and defect free software system which is a challenging task. It requires development of effective techniques for prediction of software defects at early stage. For complexities in manual prediction of defects automated techniques have come into effect. They are basically based on learning of pattern from earlier versions of software development and finding out the defects from the current version. Considerable impact of these techniques on industrial growth by predicting defects in software system attracted researchers in this field.In-spite of many studies performed by applying these techniques desirable performance level and accurate defect prediction still remains a challenging task. For solving this problem a hybrid technique based on Nonlinear Manifold Detection Techniques (Nonlinear MDTs) and machine learning for prediction of defects has been proposed in this paper. A new hybrid Nonlinear Manifold Detection (Nonlinear MD) Model has been applied for selecting and optimizing the features of software datasets that have been processed using Decision Tree (DT) and Random Forest (RF) classifications. Finally a comparison and statistical evaluation of the experimental results obtained using new hybrid Nonlinear MD Model-DT have been made by Friedman test followed by Wilcoxon Sign rank test. The statistical outcome revealed that the proposed new hybrid Nonlinear MD Model-DT classification is better result oriented and more accurate in software defect prediction.;
2024 2nd International Conference on Software Engineering and Information Technology (ICoSEIT);In the dynamic landscape of software development the pursuit of creating flawless and efficient software is a perpetual challenge. However the presence of software defects stands as an inherent reality in this complex process. Software Defect Prediction (SDP) has been a common topic in study literature. Different methods and approaches have been developed to do the prediction in different datasets. In this research outlier detection algorithms are used to conduct experiments in SDP. Isolation Forest Local Outlier Factor and One-Class SVM are the three outlier detection models used in this research. The experimental results show that One-Class SVM has better performance than the other models with the F1 score reaching 0.9101 and accuracy up to 0.84.;
Two Mistakes and Error-Free Software: A Confession;The software development process and the resulting product are so complex that no error-detecting approach will ever be able to produce error-free software. The test coverage analyzer was a wonderful tool for measuring how well-tested a piece of software. First the software being tested is instrumented so that the tool would capture which of the software's logic segments had been executed. Then a suite of test cases are run against that software and learned which segments had been executed and how many times. The Test Coverage Analyzer concept in whatever form it takes today is still important and useful. And so are all the other error- removal processes we've developed over the years. But it will take a pretty elaborate combination of testing approaches to even let us produce truly reliable software.;
2009 Testing: Academic and Industrial Conference - Practice and Research Techniques;In this article we briefly state the idea behind model-based diagnosis and its application to debugging RTL (Register Transfer Level) Verilog designs. In providing a debugging model for the Verilog HDL (Hardware Description Language) we rely on a specific abstraction (trace semantics) that captures solely quiescent states of the design. In this vein we manage to overcome the inherent complexity issues of event-based Verilog without relying on specific fault models. To leverage test patterns for design error localization we propose the filtering approach and relate it to the concept of Ackermann constraints. Notably our empirical results demonstrate that our novel technique considerably increases the diagnosis resolution even under presence of only a couple of test cases. The article outlines a case study comprising several circuits where the proposed technique allowed one for excluding 95 per cent of the Verilog code from being faulty by merely considering a couple of test cases.;
2024 IEEE 48th Annual Computers Software and Applications Conference (COMPSAC);As a key phase in software testing and debugging fault localization can significantly influence the efficiency of fixing software faults. Among the various techniques Mutation-Based Fault Localization (MBFL) is a widely studied fault localization technique that uses mutation analysis to guide the process of localizing faults. However as the essential input source for MBFL traditional mutation generates syntactical mutants which cannot mimic the real faults and may affect the fault localization effectiveness. To address this issue we resort to a code pre-trained model for program mutation which is called neural mutation. Neural mutation can generate semantical mutants and even utilize the context information surrounding the mutation position. Based on the neural mutation we propose Neural-MBFL by utilizing the high-quality mutants generated by neural mutation. To evaluate the effectiveness of Neural- MBFL we conduct experiments on 393 faulty programs from the Defects4J benchmark. The experiment results show that Neural-MBFL can localize more faults than traditional MBFL in terms of TOP-N (i.e. 9 for TOP-I 17 for TOP-3 and 18 for TOP-5 on average) and MAP (i.e. 2.32% relative improvement on average). We also analyze the unique faults localized by Neural-MBFL and traditional MBFL. The statistical results show their complementarity. It motivates further analysis into the repair pattern distributions between Neural-MBFL and traditional MBFL to better understand their complementarity. By further comprehensive analysis of the repair pattern distribution traditional MBFL has advantages in localizing faults related to rule-based code modifications. In contrast Neural-MBFL has advantages in localizing complex faults requiring deep code comprehension. These findings show that incorporating neural mutation is promising in improving the effectiveness of MBFL.;
2020 4th International Conference on Informatics and Computational Sciences (ICICoS);One of the goal in software testing is to discover software defects before the software is used by customer. Successful software testing leads to high quality software. However exposing a defect in software testing is very resources consuming. Therefore an automated software defect prediction is needed. In order to build accurate model for prediction a relevant subset of features must be carefully determined as an input to the classifier. Therefore this research compares the performance of feature selection method between a kind of filter method namely ReliefF and a kind of embedded method namely SVM-RFE (Support Vector Machine - Recursive Feature Elimination). Those methods are free from the assumption of conditional independence among features. Then SVM is applied as classification algorithm. Previously SMOTE (Synthetic Minority Oversampling Technique) is used to balance the training data. The experiments are run on benchmark public dataset NASA MDP dataset. The experiment results show that SVM-RFE perform better than ReliefF in term of g-mean while ReliefF perform better SVM-RFE in term of accuracy. However when using SVM-RFE feature selection the best classifier performance can be achieved with smaller number of features as compared to ReliefF. Future research may explore ensemble feature selection method as an attempt to improve performance of the resulting classifier both in g-mean and accuracy.;
Mulr4FL: Effective Fault Localization of Evolution Software Based on Multivariate Logistic Regression Model;Fault localization is indeed tedious and costly work during software maintenance. Studies indicate that combining both structural features and behavior characteristics of programs can be beneficial for improving the efficiency of fault locating. In this paper we proposed a framework called Mulr4FL for fault localization using a multivariate logistic regression model that combined both static and dynamic features collected from the program under debugging. Firstly the hybrid metrics data set with both program structural features and behavior characteristics combined is constructed by static program analyzing and dynamically tracing that runs with a designed metrics set. Meanwhile the fault information of the legacy program is also obtained from the bug tracking system. Secondly Bivariate logistic analysis is performed to filter the metrics that are significantly related to faults and then with the selected metrics and their measurements a multivariate logistic regression model was constructed and trained. Finally based on the trained logistic model we conduct the multivariate logistic analysis on the features of the evolved software and predict the buggy class methods. An empirical study was conducted based on a set of benchmarks that are used widely in program debugging research. The results indicate that the Mulr4FL can significantly improve the effectiveness of locating faults in contrast to 5 baseline techniques.;
2024 IEEE/ACM 5th International Workshop on Quantum Software Engineering (Q-SE);Automated Program Repair (APR) is a vital area in software engineering that generates automatic patches for vulnerable programs. While numerous techniques have been proposed for repairing classical programs quantum programming lacks a comparable automated repair technique. In this initial exploration we investigate the use of ChatGPT for quantum program repair and evaluate its performance on Bugs4Q a benchmark suite of quantum program bugs. Our findings demonstrate the feasibility of employing ChatGPT for quantum program repair. Specifically we assess ChatGPTâ€™s ability to address bugs within the Bugs4Q benchmark revealing its success in repairing 29 out of 38 bugs. This research represents a promising step towards automating the repair process for quantum programs.CCS CONCEPTSâ€¢ Software and its engineering â†’ Software testing and debugging.;
NAFIPS 2007 - 2007 Annual Meeting of the North American Fuzzy Information Processing Society;Due to the tremendous complexity and sophistication of software improving software reliability is an enormously difficult task. We study the software defect prediction problem which focuses on predicting which modules will experience a failure during operation. Numerous studies have applied machine learning to software defect prediction however skewness in defect-prediction datasets usually undermines the learning algorithms. The resulting classifiers will often never predict the faulty minority class. This problem is well known in machine learning and is often referred to as learning from unbalanced datasets. We examine stratification a widely used technique for learning unbalanced data that has received little attention in software defect prediction. Our experiments are focused on the SMOTE technique which is a method of over-sampling minority-class examples. Our goal is to determine if SMOTE can improve recognition of defect-prone modules and at what cost. Our experiments demonstrate that after SMOTE resampling we have a more balanced classification. We found an improvement of at least 23% in the average geometric mean classification accuracy on four benchmark datasets.;
2009 IEEE International Conference on Industrial Engineering and Engineering Management;Maintenance of software involves debugging of errors and implementations of enhancement requested by users these both cause the reliability of software decreased. For the systems that have been used for a considerably long period of time the various details concerning the initial development phase are usually not known to the users who are responsible for the maintenance of these systems. These cause the estimation of software reliability more difficult. In this paper a prediction model based on back-propagation neural network (BPN) is proposed to estimate the failures of the software system in the maintaining phase. The Â¿failure correctionÂ¿ records and the Â¿enhancementÂ¿ records are chosen as the input data of the prediction model the future failure time is the output. A numerical example of a commercial shop floor control system (SFC) is used to illustrate the validation and application of the proposed method.;
2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT);Software testing is a crucial step in the development procedure. Typically the defects or errors caused by developers are often dealt with a while later in software development leading to an increased effect or influence of these flaws. In order to stop this from happening issues must be identified early in the software development process allowing for the effective use of testing resources. As part of the defect prediction process software modules are categorized as either defect-prone or non-defect-prone. To automate and enhance the prediction of defective software modules a key criterion for the analysis numerous methods have been anticipated. In this paper we create a combined model that assesses the presence of defects in a software module. The proposed work has been based on pre-processing feature dimensionality reduction and classification. The model is tested through a publicly available NASA dataset. We have applied principal component analysis (PCA) for feature dimensionality reduction which reduces the dimension of the feature vector. During the prediction task the boosting technique called AdaBoost has been applied to a random forest named ABRF to determine the prediction rate. Several performance metrics which include accuracy sensitivity specificity F1 score and MCC are measured to validate the planned model. The results of the PCA+ABRF method show that the model has an average accuracy of 0.9862 for the KC2 dataset. From the experimental results it has been observed that the proposed model provides better defect prediction accuracy as compared to other existing models.;
2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom);Software testing is an important and critical phase of software development life cycle to find software faults or defects and then correct those faults. However testing process is a time-consuming activity that requires good planning and a lot of resources. Therefore technique and methodology for predicting the testing effort is important process prior the testing process to significantly increase efficiency of time effort and cost usage. Correspond to software metric usage for measuring software quality software metric can be used to identify the faulty modules in software. Furthermore implementing machine learning technique will allow computer to â€œlearnâ€ and able to predict the fault prone modules. Research in this field has become a hot issue for more than ten years ago. However considering the high importance of software quality with support of machine learning methods development this research area is still being highlighted until this year. In this paper a survey of various software metric used for predicting software fault by using machine learning algorithm is examined. According to our review this is the first study of software fault prediction that focuses to PROMISE repository dataset usage. Some conducted experiments from PROMISE repository dataset are compared to contribute a consensus on what constitute effective software metrics and machine learning method in software fault prediction.;
2021 International Conference on Information and Communication Technology for Development for Africa (ICT4DA);Fault-based testing is a powerful technique to ensure the quality of software by evaluating the efficacy of the test suits and also used to check the thoroughness of testing performed by other software testing techniques. However it is very complicated and computationally expensive testing method. Literature shows that there is a tremendous effort to give formal solutions and heuristics methods. Recently state-of-the-art approaches based on hybrid optimization techniques have been proven to be suitable for cost effective results. This work implements and presents a multi-objective novel hybrid method by combining Backtracking search optimization algorithm and Integer programming approach(BackIP). Unlike some other approaches BackIP is a test input data generation method which includes test data generation mutation analysis and test suite reduction simultaneously. Experimental comparison is conducted on a widely used benchmark java programs and results show that the proposed approach achieves test data generation with mutation score up to 94% and improved test suite reduction between 70% to 94% as compared to the state-of-the-art techniques.;
Restore: Retrospective Fault Localization Enhancing Automated Program Repair;Fault localization is a crucial step of automated program repair because accurately identifying program locations that are most closely implicated with a fault greatly affects the effectiveness of the patching process. An ideal fault localization technique would provide precise information while requiring moderate computational resourcesâ€”to best support an efficient search for correct fixes. In contrast most automated program repair tools use standard fault localization techniquesâ€”which are not tightly integrated with the overall program repair process and hence deliver only subpar efficiency. In this paper we present retrospective fault localization: a novel fault localization technique geared to the requirements of automated program repair. A key idea of retrospective fault localization is to reuse the outcome of failed patch validation to support mutation-based dynamic analysisâ€”providing accurate fault localization information without incurring onerous computational costs. We implemented retrospective fault localization in a tool called Restoreâ€”based on the Jaid Java program repair system. Experiments involving faults from the Defects4J standard benchmark indicate that retrospective fault localization can boost automated program repair: Restore efficiently explores a large fix space delivering state-of-the-art effectiveness (41 Defects4J bugs correctly fixed 8 of which no other automated repair tool for Java can fix) while simultaneously boosting performance (speedup over 3 compared to Jaid). Retrospective fault localization is applicable to any automated program repair techniques that rely on fault localization and dynamic validation of patches.;
2024 IEEE Conference on Software Testing Verification and Validation (ICST);While Large Language Models (LLMs) have demon-strated strong natural language and code processing capabilities concern has been raised as to whether existing bug benchmarks are included in their training data. We examine the training data of the open-source LLM StarCoder and find it likely that data from the widely used Defects4J benchmark was included raising the possibility of its inclusion in the training data of the GPT model as well. This makes it difficult to tell how well LLM-based results on Defects4J would generalize as for any results it would be unclear whether a technique's performance is due to LLM generalization or memorization. To remedy this issue and facilitate continued research on LLM-based SE we present the GitHub Recent Bugs (GHRB) framework which continuously gathers real-world Java bugs for use in evaluation of LLM-based techniques. To date we have gathered 89 bugs reported after the GPT-3.5 training data cutoff point of September 2021.;
2019 International Conference on Automation Computational and Technology Management (ICACTM);In this paper review of existing literature in the field of software reliability models based on machine learning techniques presented. Software reliability is very useful tool in determining the software quality. By using machine learning techniques for getting unhidden parameters affecting software fault prediction for exploring various parameters leading to obsoleteness of software by presenting category of papers of software reliability software fault prediction software trustworthiness software reusability using machine learning techniques based on statistical inferences which could predict useful pattern on hidden data of faulty software database of empirical datasets related to software testing. After studying plenary relevant papers on faults generated during fault removal faults already present we proposed a novel approach based on identifying most relevant parameter affecting the software reliability using Machine Learning Techniques.;
2021 IEEE 45th Annual Computers Software and Applications Conference (COMPSAC);Defect prediction forecasts defect proneness or the number of defects contained in software systems. It is frequently employed to efficiently prioritize and allocate the limited testing resources to the modules that are more likely to be defective during the process of software development and maintenance. Consequently a number of defect prediction approaches have been proposed. Most of the existing approaches on defect prediction regard defect prediction as a classification problem in which programs are classified as buggy or non-buggy. However identifying the defect proneness of a given software module is not sufficient in practical software testing. The research on predicting the number of defects is limited and the performances of these approaches are constantly being optimized and improved. Therefore in this paper we propose a novel approach that leverages a convolutional neural network to predict the number of defects in software systems automatically. First we preprocess the PROMISE dataset which involves performing natural logarithm transformation and data normalization. Second we feed the preprocessed dataset to a specially designed convolutional neural network-based model to predict the number of defects. Third we rank the software modules according to the corresponding predicted number of defects in descending order. We also evaluate the proposed approach on a well-known dataset by cross-validation. The evaluation results suggest that the proposed approach is both accurate and robust and it improves the state of the art. On average it significantly improves the Kendall correlation coefficient by 16% and the fault-percentile-average by 4%.;
2015 2nd International Conference on Computing for Sustainable Global Development (INDIACom);Estimating software reliability is always a keen interest of researchers for last three decades due to day to day increase in software industry. Various Software Reliability Growth Models (SRGM) have been proposed to estimate software failure rate number of faults remaining and software reliability for the same. This paper describes the review of the various software faults performance testing detection of fault tolerance and evaluation of reliability of software systems.;
2024 IEEE/ACM International Workshop on Automated Program Repair (APR);This is the ET tool participating in APR-Comp 2024. It is an end-to-end program repair approach that performs fault localization patch generation and patch validation. ET is ranked as #1 in the Functional Errors - Java track.;
Benchmarking Classification Models for Software Defect Prediction: A Proposed Framework and Novel Findings;Software defect prediction strives to improve software quality and testing efficiency by constructing predictive classification models from code attributes to enable a timely identification of fault-prone modules. Several classification models have been evaluated for this task. However due to inconsistent findings regarding the superiority of one classifier over another and the usefulness of metric-based classification in general more research is needed to improve convergence across studies and further advance confidence in experimental results. We consider three potential sources for bias: comparing classifiers over one or a small number of proprietary data sets relying on accuracy indicators that are conceptually inappropriate for software defect prediction and cross-study comparisons and finally limited use of statistical testing procedures to secure empirical findings. To remedy these problems a framework for comparative software defect prediction experiments is proposed and applied in a large-scale empirical comparison of 22 classifiers over 10 public domain data sets from the NASA Metrics Data repository. Overall an appealing degree of predictive accuracy is observed which supports the view that metric-based classification is useful. However our results indicate that the importance of the particular classification algorithm may be less than previously assumed since no significant performance differences could be detected among the top 17 classifiers.;
2021 IEEE 21st International Working Conference on Source Code Analysis and Manipulation (SCAM);"Locating bugs is an important but effort-intensive and time-consuming task when dealing with large-scale systems. To address this Information Retrieval (IR) techniques are increasingly being used to suggest potential buggy source code locations for given bug reports. While IR techniques are very scalable in practice their effectiveness in accurately localizing bugs in a software system remains low. Results of empirical studies suggest that the effectiveness of bug localization techniques can be augmented by the configuration of queries used to locate buggy code. However in most IR-based bug localization techniques presented by researchers the impact of the queriesâ€™ configurations is not fully considered. In a similar vein techniques consider all code elements as equally suspicious of being buggy while localizing bugs but this is not always the case either.In this paper we present a new method-level information-retrieval-based bug localization technique called BoostNSift"". BoostNSift exploits the important information in queries by â€˜boostâ€™ing that information and then â€˜siftâ€™s the identified code elements based on a novel technique that emphasizes the code elementsâ€™ specific relatedness to a bug report over its generic relatedness to all bug reports. To evaluate the performance of BoostNSift we employed a state-of-the-art empirical design that has been commonly used for evaluating file level IR-based bug localization techniques: 6851 bugs are selected from commonly used Eclipse AspectJ SWT and ZXing benchmarks and made openly available for method-level analyses. The performance of BoostNSift is compared with the openly-available state-of-the-art IR-based BugLocator BLUiR and BLIA techniques. Experiments show that BoostNSift improves on BLUiR by up to 324% on BugLocator by up to 297% and on BLIA up to 120% in terms of Mean Reciprocal Rank (MRR). Similar improvements are observed in terms of Mean Average Precision (MAP) and Top-N evaluation measures.""";
2023 IEEE 29th International Symposium on On-Line Testing and Robust System Design (IOLTS);The accelerated growth of computing systems' complexity makes comprehensive design verification challenging and time-consuming. In practice hard-to-model complex environments are unfeasible to be simulated exhaustively within a reasonable time frame. Therefore some corner-case conditions can be overlooked and design errors might escape to the final product. This means that it is imperative for the system to be able to detect and locate bugs to enable self-repair. This is particularly crucial during long-term remote missions in order to apply graceful degradation. This paper proposes a novel online design error localization methodology for microprocessors by immediate analysis of traced and buffered signals upon a failure detection event using a pre-trained Neural Network (NN) and existing processor components i.e. trace buffers and AI accelerators. An in-house Neural Architecture Search (NAS) framework is used to train a tailored Multi-Layer Perceptron (MLP) NN for error localization at the microprocessor module-level resolution. The proposed approach is validated by simulating a RISC-V implementation with different workload programs. It is demonstrated to be capable of localizing the microprocessor module of bug origin with 92.81% accuracy on average.;
2013 10th Working Conference on Mining Software Repositories (MSR);The analysis of bug reports is an important subfield within the mining software repositories community. It explores the rich data available in defect tracking systems to uncover interesting and actionable information about the bug triaging process. While bug data is readily accessible from systems like Bugzilla and JIRA a common database schema and a curated dataset could significantly enhance future research because it allows for easier replication. Consequently in this paper we propose the Eclipse and Mozilla Defect Tracking Dataset a representative database of bug data filtered to contain only genuine defects (i.e. no feature requests) and designed to cover the whole bug-triage life cycle (i.e. store all intermediate actions). We have used this dataset ourselves for predicting bug severity for studying bug-fixing time and for identifying erroneously assigned components. Sharing these data with the rest of the community will allow for reproducibility validation and comparison of the results obtained in bug-report analyses and experiments.;
A Comprehensive Empirical Study of Count Models for Software Fault Prediction; Count models such as the Poisson regression model and the negative binomial regression model can be used to obtain software fault predictions. With the aid of such predictions the development team can improve the quality of operational software. The zero-inflated and hurdle count models may be more appropriate when for a given software system the number of modules with faults are very few. Related literature lacks quantitative guidance regarding the application of count models for software quality prediction. This study presents a comprehensive empirical investigation of eight count models in the context of software fault prediction. It includes comparative hypothesis testing model selection and performance evaluation for the count models with respect to different criteria. ;
2023 IEEE International Conference on Control Electronics and Computer Technology (ICCECT);In order to solve the trustworthiness risk problems of artificial intelligence software such as algorithm model security data security and privacy risk infrastructure security and other types of trustworthiness risks we investigate the trustworthiness mechanism and defect patterns of artificial intelligence software and proposes a comprehensive analysis method of artificial intelligence software trustworthiness based on SFMEA and SFTA which realizes a comprehensive analysis of artificial intelligence software trustworthiness. Through example analysis this method can effectively improve the quality level of artificial intelligence software.;
2018 5th International Conference on Information Science and Control Engineering (ICISCE);As with the advance of automated program repair many novel repair approaches have been proposed in recent. There also exist empirical work focusing on the performance comparison among those approaches. In this paper we survey recent repair work in five main venues and plan to answer the question of how to measure the performance of automated program repair in term of evaluation metrics. We summary the evaluation metrics in literature and conduct the discussion on how to construct the common metrics for further research in the area of automated program repair.;
2017 5th International Conference on Cyber and IT Service Management (CITSM);Good quality software is a supporting factor that is important in any line of work in of society. But the software component defective or damaged resulting in reduced performance of the work and can increase the cost of development and maintenance. An accurate prediction on software module prone defects as part of efforts to reduce the increasing cost of development and maintenance of software. An accurate prediction on software module prone defects as part of efforts to reduce the increasing cost of development and maintenance of software. From the results of these studies are known there are two problems that can decrease performance prediction of classifiers such imbalances in the distribution of the class and irrelevant of the attributes that exist in the dataset. So as to handle both of these issues we conducted this research using integrated a sample technique with feature selection method. Based on research done previously there are two methods of samples including random under sampling and SMOTE for random over sampling. While on feature selection method such as chi square information gain and relief methods. After doing the research process integration SMOTE technique with relief method used on NaÃ¯ve Bayes classifiers the result of the predicted value better than any other method that is 82%.;
2022 IEEE Intl Conf on Dependable Autonomic and Secure Computing Intl Conf on Pervasive Intelligence and Computing Intl Conf on Cloud and Big Data Computing Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech);Software testing refers to a process that improves the quality of software systems through bug detection but software testing is one of the time and cost-consuming stages in software development. Hence software test automation is regarded as a solution which can facilitate heavy and laborious tasks of testing. Problem: Automatic generation of data with maximum coverage of program branches is regarded as an NP-complete optimization problem. Several heuristic algorithms have been proposed for this problem. Failure to maximise branch coverage the poor success rate in optimal test data generation and low stable results are the major demerits of the previous methods. Goal: Enhancing the branch coverage rate of the generated test data enhancing the success rate in generating the test data with maximum coverage and enhancing the stability and speed criteria are the main goals of this study. Method: In this study a combination of grey wolf optimization algorithm and genetic algorithm have been used to automatically generate optimal test data. The proposed hybrid method (Fuzuli1) tries to generate test data with maximum branch coverage at the software source code level. Results: The results obtained from the proposed algorithm were compared with those of the following algorithms: Shuffled Frog Leaping Algorithm (SFLA) Artificial Bee Colony (ABC) Particle Swarm Optimization (PSO) and Genetic Algorithm (GA).The results obtained from running a wide range of tests on standard benchmark programs showed that the proposed algorithm outperforms other algorithms with an average coverage of %99.98 a success rate of %99.97 and an average output of 2.86.;
2013 IEEE 37th Annual Computer Software and Applications Conference;Automated software debugging can have a signifi-cant impact on the cost and quality of software development and maintenance. In recent years researchers have invested a considerable amount of effort in developing automated techniques and have demonstrated their effectiveness in helping developers in certain debugging tasks by pinpointing faulty statements. But there is still a gap between examining a faulty statement and understanding root causes of the cor-responding bug. As a step in this direction we believe good developers have defensive programming in minds and software debugging is a process in search of arguments about why a statement is faulty. Therefore a fault localization problem is rephrased as a dispute game between statements involved in successful runs and failing runs. A statement is OK if it can always provide arguments against other's blames whereas a less defensive statement is thought to be faulty. In doing so we propose a probabilistic dispute graph which is built upon dynamic dependencies between statements and statistics of program runs. Using such a graph we put executed statements in dispute compute acceptable statements and thus figure out faulty statements if they have not strong arguments about their correctness. For empirical purpose we carry out experiments on the well-known Siemens benchmark and conclude that our approach not only casts new light on the causes of bugs in various cases but also is statistically more effective in fault localization than competitors like Tarantula SOBER CT and PPDG.;
2019 International Conference on Advances in the Emerging Computing Technologies (AECT);In recently all the developers programmer and software engineers they are working specially on software component and software testing to compete the software technology in the world. For this competition they are using different kind of sources to analysis the software reliability and importance. Nowadays Data mining is one of source which is used in software for overcome the problem of software fault which occur during the software test and its analysis. This kind of problem leads software deformity prophecy in software. In this research paper we are also trying to overcome the software deformity prophecy problem with the help of our proposed solution called ONER rule attribute. We have used REPOSITORY datasets models these datasets models are defected and non-defected datasets models. Our analysis class of interest is defected models. In our research we have analyzed the efficiency of our proposed solution methods. The experiments results showed that using of ONER with discretize have improved the efficiency of correctly classified instances in all. Using percentage split and training datasets with ONER discretize rule attribute have improved correctly classified in all datasets models. The analysis of positive accuracy f-measure is also increased in percentage split during the use of ONER with discretize but in some datasets models the training data and cross validation is better with use of ONER rule attribute. The area under curve (ROC) in both scenarios using ONER rule attribute and discretize with ONER rule attribute is almost same or equal with each other.;
2022 3rd International Conference on Communication Computing and Industry 4.0 (C2I4);Software maintenance is a very important phase in the life cycle of software development. As part of maintenance we need to identify bugs within the code and fix them for every release. Software bug prediction (SBP) allows us to identify modules in the software that may have the tendency to be buggy. This enables us to perform targeted testing and properly plan maintenance cycles. In most research performed we observed that dataset of software programs written in C language were used. Each programming language are inherently different and has it's own constructs practices and nuances. In this research we focus on identifying if there exists a specific classifier that works well for each programming language which in turn is used to analyze the effect of programming language on Software Bug Prediction. Datasets of software written in C C++ and Java has been collected and the most accurate classifier for each dataset of a programming language has been identified. The ML models used in this paper include Naive Bayes Decision Tree and Random Forest.;
Integrated Approach to Software Defect Prediction;Software defect prediction provides actionable outputs to software teams while contributing to industrial success. Empirical studies have been conducted on software defect prediction for both cross-project and within-project defect prediction. However existing studies have yet to demonstrate a method of predicting the number of defects in an upcoming product release. This paper presents such a method using predictor variables derived from the defect acceleration namely the defect density defect velocity and defect introduction time and determines the correlation of each predictor variable with the number of defects. We report the application of an integrated machine learning approach based on regression models constructed from these predictor variables. An experiment was conducted on ten different data sets collected from the PROMISE repository containing 22838 instances. The regression model constructed as a function of the average defect velocity achieved an adjusted R-square of 98.6% with a p-value of < 0.001. The average defect velocity is strongly positively correlated with the number of defects with a correlation coefficient of 0.98. Thus it is demonstrated that this technique can provide a blueprint for program testing to enhance the effectiveness of software development activities.;
2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC);Concept drift is a known phenomenon in software data analytics. It refers to the changes in the data distribution over time. The performance of analytic and prediction models degrades due to the changes in the data over time. To improve prediction performance most studies propose that the prediction model be updated when concept drift occurs. In this work we investigate the existence of concept drift and its associated effects on software defect prediction performance. We adopt the strategy of an empirically proven method DDM (Drift Detection Method) and evaluate its statistical significance using the chi-square test with Yates continuity correction. The objective is to empirically determine the concept drift and to calibrate the base model accordingly. The empirical study indicates that the concept drift occurs in software defect datasets and its existence subsequently degrades the performance of prediction models. Two types of concept drifts (gradual and sudden drifts) were identified using the chi-square test with Yates continuity correction in the software defect datasets studied. We suggest concept drift should be considered by software quality assurance teams when building prediction models.;
2017 IEEE 2nd Advanced Information Technology Electronic and Automation Control Conference (IAEAC);Due to the confusion of fault-prone software modules and non-fault-prone ones and the limit of traditional mothed such as LDA and PCA the performance of software defect prediction model is difficult to improve. In this paper we present GMCRF a method based on dimensionality reduction technique and conditional random field (CRF) for software defect prediction. In our proposed method firstly we leverage geometric mean for subspace learning to choose the best combination of features from data set. Secondly we propose to apply the best combination of features which is selected by geometric mean-based approach in CRF model. Interestingly we find that the GMCRF method achieves much better final results than the other approach as shown in the software defect data classification task.;
2022 IEEE 22nd International Conference on Software Quality Reliability and Security Companion (QRS-C);Current research begins to apply unlabelled test cases to fault localization. However in these methods the labeled test cases randomly selected as the basis for fault localization cannot cover enough execution information which will reduce fault localization efficiency. In this paper a method based on K-Means clustering and similarity is proposed. At the beginning of the test K-Means clustering is performed on the test case suite and the test cases filtered can cover more execution information. Next for the test cases with failed execution results the test cases with similar execution information are filtered to better highlight the fault information in the failed test cases. Experiments on Defects4J datasets show that the proposed method can be combined with other technologies to improve their efficiency and the proposed method also has good compatibility with traditional software fault localization algorithms. The average improvement reached 13.37% in 8 scenarios.;
2023 IEEE International Conference on Software Testing Verification and Validation Workshops (ICSTW);In path-based testing various test coverage criteria can be used to generate test paths from a system model. The question of the realistic economic effectiveness of these individual criteria deserves further investigation as the answer strongly depends on the presence of defects in a system topology of the model of a system under test and other factors. This study presents an open benchmark testbed for measuring the effectiveness of test paths in detecting artificially introduced defects in a tested system. This framework offers a good level of scalability for various experiments in this field. To document its functionality and added value an example use case comparing the effectiveness of test paths satisfying Edge Edge-pair Test Depth Level 3 and Prime Path coverage for the detection of 75 artificial defects is presented.;
2010 Third International Conference on Software Testing Verification and Validation;This paper proposes a strategy for automatically fixing faults in a program by combining the processes of mutation and fault localization. Statements that are ranked in order of their suspiciousness of containing faults can then be mutated in the same order to produce possible fixes for the faulty program. The proposed strategy is evaluated against the seven benchmark programs of the Siemens suite and the Ant program. Results indicate that the strategy is effective at automatically suggesting fixes for faults without any human intervention.;
2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT);This research work focuses on analyzing the performance of a proposed random forest (RF) method with that of Gaussian Naive Bayes in predicting software problems. The database utilized in this research was gathered from the Kaggle repository and contained information about software projects and their bug reports. A total of 20 samples were used in this study with two groups formed and 10 samples randomly selected for each group. Group 1 was used for training and testing the Gaussian Naive Bayes algorithm while Group 2 was used for training and testing the novel RF algorithm. Python and relevant libraries such as scikit-learn were utilized for implementation. The dataset was preprocessed to remove irrelevant features and perform feature engineering. The algorithms were tested on the training set and their performance was assessed using accuracy metric on the testing data. A statistical power of 0.8 was set and alpha and beta qualities of 0.05 and 0.2 respectively were used with a confidence interval of 95%. The accuracy of the novel RF approach was 78.59% on average whereas the accuracy of the Gaussian Naive Bayes approach was 75.57% on average. The p-value for the statistically distinct in accuracy among the both approaches was 0.001 ($\mathbf{p;
2015 IEEE/ACM 12th Working Conference on Mining Software Repositories;The bug tracking repositories of software projects capture initial defect (bug) reports and the history of interactions among developers testers and customers. Extracting and mining information from these repositories is time consuming and daunting. Researchers have focused mostly on analyzing the frequency of the occurrence of defects and their attributes (e.g. The number of comments and lines of code changed count of developers). However the counting process eliminates information about the temporal alignment of events leading to changes in the attributes count. Software quality teams could plan and prioritize their work more efficiently if they were aware of these temporal sequences and knew their frequency of occurrence. In this paper we introduce a novel dataset mined from the Fire fox bug repository (Bugzilla) which contains information about the temporal alignment of developer interactions. Our dataset covers eight years of data from the Fire fox project on activities throughout the project's lifecycle. Some of these activities have not been reported in frequency-based or other temporal datasets. The dataset we mined from the Fire fox project contains new activities such as reporter experience file exchange events code-review process activities and setting of milestones. We believe that this new dataset will improve analysis of bug reports and enable mining of temporal relationships so that practitioners can enhance their bug-fixing process.;
LocSeq: Automated Localization for Compiler Optimization Sequence Bugs of LLVM;Compiler bugs may be triggered when programs are optimized with optimization sequences. However diagnosing compiler optimization sequence bugs is difficult due to limited debugging information. Although some techniques (e.g. DiWi and RecBi) have been proposed to automatically localize compiler bugs no systematic work has been conducted to automatically localize compiler optimization sequence bugs. In this article we propose LocSeq a novel technique to automatically localize compiler optimization sequence bugs of LLVM. The core insight of LocSeq is based on the fact that the behaviors of optimizations may be influenced by each other and thus the innocent files may be excluded by constructing bug-free optimization sequences. First given a buggy optimization sequence that triggers a compiler bug in LocSeq we transform the problem of the localization for a compiler optimization sequence bug to the problem of the construction for bug-free optimization sequences which are helpful to localize buggy compiler files. Then a constrained genetic algorithm is presented in LocSeq to generate a set of bug-free optimization sequences that share similar compiler execution traces with the buggy optimization sequence. Finally LocSeq leverages a spectrum-based bug localization technique to localize the compiler optimization sequence bug by comparing the execution traces between bug-free optimization sequences and the buggy optimization sequence. To evaluate the effectiveness of LocSeq we build a benchmark including 60 optimization sequence bugs of LLVM and compare LocSeq with the state-of-the-art techniques DiWi and RecBi. The experimental results show that LocSeq significantly outperforms DiWi and RecBi by up to 366.66%/72.27% and 250.00%/56.00% for localizing optimization sequence bugs within Top-1/5 files respectively.;
2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR);This paper reports on a large-scale comparative evaluation of IR-based tools for automatic bug localization. We have divided the tools in our evaluation into the following three generations: (1) The firstgeneration tools now over a decade old that are based purely on the Bag-of-Words (BoW) modeling of software libraries. (2) The somewhat more recent second-generation tools that augment BoW-based modeling with two additional pieces of information: historical data such as change history and structured information such as class names method names etc. And finally (3) The third-generation tools that are currently the focus of much research and that also exploit proximity order and semantic relationships between the terms. It is important to realize that the original authors of all these three generations of tools have mostly tested them on relatively small-sized datasets that typically consisted no more than a few thousand bug reports. Additionally those evaluations only involved Java code libraries. The goal of the present paper is to present a comprehensive large-scale evaluation of all three generations of bug-localization tools with code libraries in multiple languages. Our study involves over 20000 bug reports drawn from a diverse collection of Java C/C++ and Python projects. Our results show that the third-generation tools are significantly superior to the older tools. We also show that the word embeddings generated using code files written in one language are effective for retrieval from code libraries in other languages.;
2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR);Over the last few years researchers proposed a multitude of automated bug-detection approaches that mine a class of bugs that we call API misuses. Evaluations on a variety of software products show both the omnipresence of such misuses and the ability of the approaches to detect them. This work presents MuBench a dataset of 89 API misuses that we collected from 33 real-world projects and a survey. With the dataset we empirically analyze the prevalence of API misuses compared to other types of bugs finding that they are rare but almost always cause crashes. Furthermore we discuss how to use it to benchmark and compare API-misuse detectors.;
2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE);Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article we provide a benchmark for CPDP. We replicate 24 approaches proposed by researchers between 2008 and 2015 and evaluate their performance on software products from five different data sets. Based on our benchmark we determined that an approach proposed by Camargo Cruz and Ochimizu (2009) based on data standardization performs best and is always ranked among the statistically significant best results for all metrics and data sets. Approaches proposed by Turhan et al. (2009) Menzies et al. (2011) and Watanabe et al. (2008) are also nearly always among the best results. Moreover we determined that predictions only seldom achieve a high performance of 0.75 recall precision and accuracy. Thus CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.;
2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA);Context: Software projects are common inputs in Empirical Software Engineering (ESE) studies although they are often selected with ad-hoc strategies that reduce the generalizability of the results. An alternative is the usage of available datasets of software projects which should be current and follow explicit rules for ensuring their validity over time. Goal: In this context it is important to assess the general state of software datasets in terms of purpose last update project characterization source code metrics and tools to extract source-code-related artifacts. Method: We conducted a systematic mapping study retrieving software datasets used in ESE studies published from January 2013 to December 2021. Results: We selected 74 datasets created mainly for software defects software estimation and software maintainability studies. The majority of these datasets (64%) explicitly stated the characteristics to select the projects and the most common programming languages were Java and C. Conclusions: Our study identified scarce efforts to keep datasets updated over time and also provides recommendations to support their construction and consumption for ESE studies.;
2017 4th International Conference on Information Science and Control Engineering (ICISCE);Computer software size continues to grow recently. But it is difficult to collect information to support software development and maintenances. Data mining technology can be used to automatically discover knowledge from software testing data. It is helpful to increase software developing process and improve software quality. At first correlation analysis is adopted to study the relevance among the software parameters. Subordination ingredients are eliminated software parameters are pretreated according to parameter correlation. Software size testing case number and testing defect number are kept down as analysis object. Association rule algorithm can't be applied to deal continuous quantity. Thus testing case density per hundred line and defect density per thousand line are introduced and dispersed to build the analyzing model. Next Apriori algorithm is used to construct association rule algorithm model. By iterative analysis construct associations are obtained between testing case density and defect density. Finally this paper analyzed the construct associations and discussed their purposes.;
2023 IEEE International Conference on Acoustics Speech and Signal Processing Workshops (ICASSPW);In this work we curate and investigate a dataset named Turkish Software Report - Module Classification (TSRMC) consisting of commercial software bug reports of a company. Automated bug classification is required in large-scale software projects due to the vast amount of bugs. We analyze and report the statistical features and classification difficulty of the dataset. We use several methods from the text classification literature to assign each bug report of the TSRMC dataset a suitable software module. The utilized methods include traditional machine learning (ML) methods such as support vector machine (SVM) and logistic regression sequential deep learning (DL) models such as gated recurrent unit (GRU) and convolutional neural networks (CNN) and Bidirectional Encoder Representations from Transformers (BERT)-based pre-trained language models (PLMs). Our work is one of the first efforts in automated bug report classification literature that focuses on commercial bugs and uses bilingual (Turkish and English) texts.;
2022 IEEE/ACM International Conference on Automation of Software Test (AST);Testing scientific software is challenging because usually such type of systems have non-deterministic behaviours and in addition they generate non-trivial outputs such as images. Artificial intelligence (AI) is now a reality which is also helping in the development of the software testing activity. In this article we evaluate seven deep neural networks (DNNs) precisely deep convolutional neural networks (CNNs) with up to 161layers playing the role of test oracle procedures for testing scientific models. Firstly we propose a method TOrC which starts by generating training validation and test image datasets via combinatorial interaction testing applied to the original codes and second-order mutants. Within TOrC we also have classical steps such as transfer learning a technique recommended for DNNs. Then we verified the performance of the oracles (CNNs). The main conclusions of this research are: i) not necessarily a greater number of layers means that a CNN will present better performance ii) transfer learning is a valuable technique but eventually we may need extended solutions to get better performances iii) data-centric AI is an interesting path to follow and iv) there is not a clear correlation between the software bugs in the scientific models and the errors (image misclassifications) presented by the CNNs. CCS CONCEPTS â€¢ Software and its engineering â†’ Software testing and debugging. Computing methodologies â†’ Neural networks Supervised learning by classification Computer vision.;
2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC);Defects are a major constraint in the software development process. Defects can cause a lot of trouble if not found in earlier stages of software development. They can result in cost overruns and can even lead to a complete system failure. Many supervised machine learning algorithms have been used over the past few decades for software defect prediction. However the huge variety of software projects causes a problem of varying performance. No machine learning algorithm can deliver the best results consistently for all datasets. Also a given dataset can have a variety of tuples having different similarities and dissimilarities. Therefore there is a need to address these problems while predicting defects in any project. This paper introduces an approach for defect prediction which takes into consideration the variety of software projects available. This approach is based on dividing the training dataset into multiple subsets and applying multiple supervised learning algorithms on each such subset to determine the best algorithms for each such subset and then using this information to predict software defect in future projects by making use of similarities in datasets. The given dataset is divided into four parts based on whether the results of applying any random machine learning algorithm on that dataset were true positive true negative false positive or false negative. Experimental results on the PROMISE data repository show an improvement in performance over the existing machine learning algorithms.;
2018 12th International Conference on Reliability Maintainability and Safety (ICRMS);"The aging"" phenomenon occurs after the long-term running of software with the fault rate rising and running efficiency dropping. As there is no corresponding testing type for this phenomenon among conventional software tests ""software runtime accumulative testing"" is proposed. Through analyzing several examples of software aging causing serious accidents software is placed in the system environment required for running and the occurrence mechanism of software aging is analyzed. In addition corresponding testing contents and recommended testing methods are designed with regard to all factors causing software aging and the testing process and key points of testing requirement analysis for carrying out runtime accumulative testing are summarized thereby providing a method and guidance for carrying out ""software runtime accumulative testing"" in software engineering.""";
Automated Generation and Evaluation of JMH Microbenchmark Suites From Unit Tests;Performance is a crucial non-functional requirement of many software systems. Despite the widespread use of performance testing developers still struggle to construct and evaluate the quality of performance tests. To address these two major challenges we implement a framework dubbed ju2jmh to automatically generate performance microbenchmarks from JUnit tests and use mutation testing to study the quality of generated microbenchmarks. Specifically we compare our ju2jmh generated benchmarks to manually written JMH benchmarks and to automatically generated JMH benchmarks using the AutoJMH framework as well as directly measuring system performance with JUnit tests. For this purpose we have conducted a study on three subjects (Rxjava Eclipse-collections and Zipkin) with $\sim$âˆ¼454K source lines of code (SLOC) 2417 JMH benchmarks (including manually written and generated AutoJMH benchmarks) and 35084 JUnit tests. Our results show that the ju2jmh generated JMH benchmarks consistently outperform using the execution time and throughput of JUnit tests as a proxy of performance and JMH benchmarks automatically generated using the AutoJMH framework while being comparable to JMH benchmarks manually written by developers in terms of testsâ€™ stability and ability to detect performance bugs. Nevertheless ju2jmh benchmarks are able to cover more of the software applications than manually written JMH benchmarks during the microbenchmark execution. Furthermore ju2jmh benchmarks are generated automatically while manually written JMH benchmarks require many hours of hard work and attention therefore our study can reduce developersâ€™ effort to construct microbenchmarks. In addition we identify three factors (too low test workload unstable tests and limited mutant coverage) that affect a benchmark's ability to detect performance bugs. To the best of our knowledge this is the first study aimed at assisting developers in fully automated microbenchmark creation and assessing microbenchmark quality for performance testing.;
Characterizing Crowds to Better Optimize Worker Recommendation in Crowdsourced Testing;Crowdsourced testing is an emerging trend in which test tasks are entrusted to the online crowd workers. Typically a crowdsourced test task aims to detect as many bugs as possible within a limited budget. However not all crowd workers are equally skilled at finding bugs Inappropriate workers may miss bugs or report duplicate bugs while hiring them requires nontrivial budget. Therefore it is of great value to recommend a set of appropriate crowd workers for a test task so that more software bugs can be detected with fewer workers. This paper first presents a new characterization of crowd workers and characterizes them with testing context capability and domain knowledge. Based on the characterization we then propose Multi-Objective Crowd wOrker recoMmendation approach (MOCOM) which aims at recommending a minimum number of crowd workers who could detect the maximum number of bugs for a crowdsourced testing task. Specifically MOCOM recommends crowd workers by maximizing the bug detection probability of workers the relevance with the test task the diversity of workers and minimizing the test cost. We experimentally evaluate MOCOM on 532 test tasks and results show that MOCOM significantly outperforms five commonly-used and state-of-the-art baselines. Furthermore MOCOM can reduce duplicate reports and recommend workers with high relevance and larger bug detection probability because of this it can find more bugs with fewer workers.;
2023 International Conference on Advances in Computation Communication and Information Technology (ICAICCIT);In the ever-evolving world of software development ensuring high-quality software is crucial for meeting user expectations. Software Defect Prediction (SDP) identifies the modules which may contain defects and require substantial testing. Therefore predicting software defects at an early stage is very much helpful for companies. However problems like class imbalance and noise in dataset needs to be addressed to build a better model. This paper uses SMOTE for resampling the data and explores the use of ensemble boosting algorithms for predicting software defects. The study utilizes several boosting algorithms including CatBoost XGBoost and LightGBM and compares their performance on publicly available software defect dataset such as NASA(PROMISE). The proposed ensemble learning model significantly improved the predictive accuracy outperforming conventional machine learning methods like Logistic Regression and NaÃ¯ve Bayes. The experimental outcomes show that ensemble boosting model has achieved better results in predicting defects with 86% Accuracy 0.85 G-mean and 0.92 AUC measures.;
2023 8th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS);Effort-aware Just-in-Time Software Defect Prediction is a fine-grained technique and takes the cost of detection into account to detect more defective changes with limited testing resources. Since many existing models lack better performance an effort-aware just-in-time software defect prediction model is proposed called EALGB based on LightGBM in this paper. Intensive simulation experiments have been conducted on six open-source datasets to demonstrate the performance of the proposed method. The prediction model is evaluated by two widely recognized metrics ACC and Popt in three scenarios called cross-validation cross-project cross-validation and time-aware cross-validation. Empirical results demonstrate that the proposed algorithm EALGB has good prediction performance.;
2007 International Multi-Conference on Computing in the Global Information Technology (ICCGI'07);We report on an empirical study performed in an industrial environment in which the impact of modifying test practices is measured. First the efficiency of the existing test practices is measured by analyzing the software defects using a modified version of Orthogonal Defect Classification (ODC). The study was conducted in two phases lasting seven months each. In the first phase (Phase A) defects were recorded using existing implicit testing practices. Developers were then required to make those testing activities explicit based on a simple scheme. After a few months of employing this explicit testing practice a new defect recording phase (Phase B) which also lasted seven months was conducted. The impacts of explicit test practices are presented in terms of the ratios of defects found by the users and the nature of the testing activities performed. Results show that even a small improvement such as requiring testing activities to be explicit can have a measurable positive impact on the quality of the product.;
2022 IEEE 22nd International Conference on Software Quality Reliability and Security (QRS);Spectrum-Based Fault Localization (SBFL) is based on risk formulas to rank program elements which work generally well in various situations. However it cannot be ruled out that zero division might happen during score calculation which has negative consequences e.g. essential elements will not be in the top part of the rank list. The literature has given several strategies to tackle the problem although there is little knowledge on which one to use. In our work we performed mathematical analysis and an empirical study to find out how this phenomenon affects SBFL. Results show that division by zero happens in many cases and the strategies can mitigate their consequences with varying success. Thus we propose a combined method to avoid the threat of division by zero and improve the trustworthiness of SBFL. Our proposals should be taken into consideration whenever a formula is being used or a new one is proposed.;
2012 IEEE Fifth International Conference on Software Testing Verification and Validation;Coincidentally correct test cases are those that execute faulty statements but do not cause failures. Such test cases reduce the effectiveness of spectrum-based fault localization techniques such as Ochiai. These techniques calculate a suspiciousness score for each statement. The suspiciousness score estimates the likelihood that the program will fail if the statement is executed. The presence of coincidentally correct test cases reduces the suspiciousness score of the faulty statement thereby reducing the effectiveness of fault localization. We present two approaches that predict coincidentally correct test cases and use the predictions to improve the effectiveness of spectrum based fault localization. In the first approach we assign weights to passing test cases such that the test cases that are likely to be coincidentally correct obtain low weights. Then we use the weights to calculate suspiciousness scores. In the second approach we iteratively predict and remove coincidentally correct test cases and calculate the suspiciousness scores with the reduced test suite. In this dissertation we investigate the cost and effectiveness of our approach to predicting coincidentally correct test cases and utilizing the predictions. We report the results of our preliminary evaluation of effectiveness and outline our research plan.;
2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE);One of the most important tasks related to managing bug reports is localizing the fault so that a fix can be applied. As such prior work has aimed to automate this task of bug localization by formulating it as an information retrieval problem where potentially buggy files are retrieved and ranked according to their textual similarity with a given bug report. However there is often a notable semantic gap between the information contained in bug reports and identifiers or natural language contained within source code files. For user-facing software there is currently a key source of information that could aid in bug localization but has not been thoroughly investigated â€“ information from the graphical user interface (GUI). In this paper we investigate the hypothesis that for end user-facing applications connecting information in a bug report with information from the GUI and using this to aid in retrieving potentially buggy files can improve upon existing techniques for text retrieval-based bug localization. To examine this phenomenon we conduct a comprehensive empirical study that augments four baseline text-retrieval techniques for bug localization with GUI interaction information from a reproduction scenario to (i) filter out potentially irrelevant files (ii) boost potentially relevant files and (iii) reformulate text-retrieval queries. To carry out our study we source the current largest dataset of fully-localized and reproducible real bugs for Android apps with corresponding bug reports consisting of 80 bug reports from 39 popular open-source apps. Our results illustrate that augmenting traditional techniques with GUI information leads to a marked increase in effectiveness across multiple metrics including a relative increase in Hits@10 of 13-18%. Additionally through further analysis we find that our studied augmentations largely complement existing techniques pushing additional buggy files into the top-10 results while generally preserving top ranked files from the baseline techniques.;
2015 First International Conference on Reliability Systems Engineering (ICRSE);Software defect (Bug) prediction plays an important role in improving software quality. Many software defect prediction approaches have been proposed and achieved great effects in the real-world. However the existing works are usually constrained in only one project hence their effectiveness on cross-project defect prediction (cross-prediction) is usually poor. This is mainly because of the problem of class imbalance and feature distribution differences between the source and target projects. In this paper we proposed an effective software defect prediction method called Transfer Component Analysis Neural Network (TCANN) by adequately considering the noise data the class imbalance in data settings and transfer learning among cross-project. There are three parts in TCANN aiming to solve the above mentioned three problems respectively. First the Inter Quartile Range (IQR) based method is proposed for noise removal in datasets. Second The transfer component analysis method is used to reduce the feature distribution differences between source and target data. Third dynamic sampling neural network is proposed for dealing with class imbalance problem of the training dataset. Based on the classic open-source datasets collected by previous researchers our experimental results show that TCANN improves the performance of both within-project and cross-project defect prediction in comparison with other methods.;
2020 29th International Conference on Computer Communications and Networks (ICCCN);Defects are inherent in software and can lead to many serious problems during the use of software. Software defect prediction is an important method for finding defects and can help developers improve their testing efficiency. To build accurate prediction models previous software defect prediction techniques focus on design of functions related to the code of potential defects. But these methods do not adequately capture the semantic features of the program. In this paper we propose a software defect prediction model based on program slice and deep learning. We extract program slice based on system dependence graph and leverage Gated Recurrent Unit (GRU) to generate features. We conducted experiments both within-project defect prediction and cross-project defect prediction using the dataset of the public PROMISE database. The results show that our method improves on average by 11.0% in F1-measure in within-project and 10.4% in F1-measure in cross-project defect prediction compared to the Tree-LSTM method.;
2020 4th International Conference on Trends in Electronics and Informatics (ICOEI)(48184);Software defect prediction provides development groups with observable outcomes while contributing to industrial results and development faults predicting defective code areas can help developers identify bugs and organize their test activities. The percentage of classification providing the proper prediction is essential for early identification. Moreover software-defected data sets are supported and at least partially recognized due to their enormous dimension. This Problem is handled by hybridized approach that includes the PCA randomforest naÃ¯ve bayes and the SVM Software Framework which as five datasets as PC3 MW1 KC1 PC4 and CM1 are listed in software analysis using the weka simulation tool. A systematic research analysis is conducted in which parameters of confusion precision recall recognition accuracy etc Are measured as well as compared with the prevailing schemes. The analytical analysis indicates that the proposed approach will provide more useful solutions for device defects prediction.;
2022 9th International Conference on Dependable Systems and Their Applications (DSA);Automatic program repair (APR) which aims to fix software bugs without human intervention is getting in-creasing attention from academic and industrial communities. Although promising outcomes regarding correctly-fixed bugs have been achieved recently existing APR tools still suffer from the low accuracy of generated patches. In fact it is fundamentally difficult to avoid generating incorrect patches due to the weak available test suite. In this paper to improve the accuracy of patches generated by APR tools we propose a novel HUman-machine interactive patch filterinG apprOach (HUGO) to help developers identify correct patches by generating additional test cases. We also implement the approach as an Eclipse plugin and evaluate the effectiveness and usefulness of the implementation. The results on the Defects4J dataset show that the proposed method can filter out 82.61 % of the incorrect patches and improve the accuracy of patches by 25%.;
Ninth Asia-Pacific Software Engineering Conference 2002.;An embedded system is an electronically controlled system combining hardware and software. Many systems used in real life such as power plants medical instrument systems and home appliances are embedded. However studies related to embedded system testing are insufficient. In embedded systems it is necessary to develop a test technique to detect faults in interaction between hardware and software. We propose a test data selection technique using fault injection for the interaction between hardware and software. The proposed test data selection technique first simulates behavior of a software program from requirements specification. Hardware faults after being converted to software faults are then injected into the simulated program. We finally select effective test data to detect faults caused by the interactions between hardware and software. We apply our technique to a digital plant protection system and evaluate the effectiveness of selected test data through experiments.;
2024 IEEE Aerospace Conference;"Since the first use of computers in space and aircraft software errors have occurred. These errors can manifest as loss-of-life or less catastrophically. As the demand for automation increases software in mission or safety-critical systems should be designed to be tolerant to the most likely software faults. This paper categorizes a set of 56 historic aerospace software error incidents from 1962 to 2023 to determine trends of how and where automation is most likely to fail or behave unexpectedly. A distinction between software producing unexpected (erroneous) output versus no output (fail-silent) is introduced. Of the historical incidents analyzed 86% were from software producing wrong output rather than simply stopping. Rebooting was found to be ineffective to clear erroneous behavior and not reliable to recover from silent failures. Error origin was within the code/logic itself in 59% of cases 16% from configurable data 14% from unexpected sensor input and 11% from command/operator input. A substantial forty percent (41%) of unexpected software behavior was indicated by the absence of code arising from unanticipated situations and missing requirements and 18% of incidents were subjectively deemed unknown-unknowns"". No incidents were found to be the result of programming language compiler tool or operating system and only eighteen percent (18%) of all incidents were considered traditional computer science/programming-related in nature. These findings indicate that for fault tolerance erroneous automation behavior must be a primary consideration especially at critical moments and reboot recoverability may not be viable. Based on this data we recommend some best practices for pre-flight software error prevention and in-flight error mitigation. Care should be taken to validate configurable data and commands prior to use. ""Test-like-you-fly"" including hardware-in-the-loop combined with robust off-nominal testing should be used to uncover missing logic arising from unanticipated situations not covered by requirements alone. Monitoring override and backup systems should be architected and employed in accordance with time and safety criticality. This study uniquely focuses on manifestations of unexpected flight software behavior independent of ultimate root cause. We characterize software error behavior and origin to improve software design test and operations for resilience to the most common manifestations and provide a rich dataset for further study.""";
Rate-Based Queueing Simulation Model of Open Source Software Debugging Activities;Open source software (OSS) approach has become increasingly prevalent for software development. As the widespread utilization of OSS the reliability of OSS products becomes an important issue. By simulating the testing and debugging processes of software life cycle the rate-based queueing simulation model has shown its feasibility for closed source software (CSS) reliability assessment. However the debugging activities of OSS projects are different in many ways from those of CSS projects and thus the simulation approach needs to be calibrated for OSS projects. In this paper we first characterize the debugging activities of OSS projects. Based on this we propose a new rate-based queueing simulation framework for OSS reliability assessment including the model and the procedures. Then a decision model is developed to determine the optimal version-updating time with respect to two objectives: minimizing the time for version update and maximizing OSS reliability. To illustrate the proposed framework three real datasets from Apache and GNOME projects are used. The empirical results indicate that our framework is able to effectively approximate the real scenarios. Moreover the influences of the core contributor staffing levels are analyzed and the optimal version-updating times are obtained.;
2018 IEEE International Conference on Software Maintenance and Evolution (ICSME);Research on the characteristics of error propagation can guide fault localization more efficiently. Spectrum-based fault localization (SFL) and slice-based fault localization are effective fault localization techniques. The former produces a list of statements in descending order of suspicious values and the latter generates statements that affect failure statements. We propose a new dynamic slicing and spectrum-based fault localization (DSFL) method which combines the list of suspicious statements generated by SFL with dynamic slicing and take the characteristics of error propagation into account. To the best of our knowledge DSFL has not yet been implemented in automated repair tools. In this study we use the dynamic slicing tool Javaslicer to determine the error propagation chain of faulty programs and the statements related to failure execution. We implement the DSFL algorithm in the automated repair tool Nopol and conduct repair experiments on dataset Defects4j to compare the effects of SFL and DSFL on the efficiency of automated repair. Preliminary results indicate that the scope of error propagation for most programs is a single class and the DSFL makes automated repair more efficient.;
Mitigating False Positive Static Analysis Warnings: Progress Challenges and Opportunities;Static analysis (SA) tools can generate useful static warnings to reveal the problematic code snippets in a software system without dynamically executing the corresponding source code. In the literature static warnings are of paramount importance because they can easily indicate specific types of software defects in the early stage of a software development process which accordingly reduces the maintenance costs by a substantial margin. Unfortunately due to the conservative approximations of such SA tools a large number of false positive (FP for short) warnings (i.e. they do not indicate real bugs) are generated making these tools less effective. During the past two decades therefore many false positive mitigation (FPM for short) approaches have been proposed so that more accurate and critical warnings can be delivered to developers. This paper offers a detailed survey of research achievements on the topic of FPM. Given the collected 130 surveyed papers we conduct a comprehensive investigation from five different perspectives. First we reveal the research trends of this field. Second we classify the existing FPM approaches into five different types and then present the concrete research progress. Third we analyze the evaluation system applied to examine the performance of the proposed approaches in terms of studied SA tools evaluation scenarios performance indicators and collected datasets respectively. Fourth we summarize the four types of empirical studies relating to SA warnings to exploit the insightful findings that are helpful to reduce FP warnings. Finally we sum up 10 challenges unresolved in the literature from the aspects of systematicness effectiveness completeness and practicability and outline possible research opportunities based on three emerging techniques in the future.;
2023 IEEE/ACM International Conference on Automation of Software Test (AST);The rising popularity and adoption of source-code management systems in combination with Continuous Integration and Continuous Delivery (CI/CD) processes have contributed to the adoption of agile software development with short release and feedback cycles between software producers and their customers. DevOps platforms streamline and enhance automation around source-code management systems by providing a uniform interface for managing all the aspects of the software development lifecycle starting from software development until software deployment and by integrating and orchestrating various tools that provide automation around software development processes such as automated bug detection security testing dependency scanning etc..Applying changes to the DevOps platform or to one of the integrated tools without providing data regarding its real world impact increases the risk of having to remove/revert the change. This could lead to service disruption or loss of confidence in the platform if it does not perform as expected. In addition integrating alpha or beta features which may not meet the robustness of a finalised feature may pose security or stability risks to the entire platform. Hence short release cycles require testing and benchmarking approaches that make it possible to prototype test and benchmark ideas quickly and at scale to support Data-Driven Decision Making with respect to the features that are about to be integrated into the platform.In this paper we propose a scalable testing and benchmarking approach called SourceWarp that is targeted towards DevOps platforms and supports both testing and benchmarking in a cost effective and reproducible manner. We have implemented the proposed approach in the publicly available SourceWarp tool which we have evaluated in the context of a real-world industrial case-study. We successfully applied SourceWarp to test and benchmark a newly developed feature at GitLab which has been successfully integrated into the product. In the case study we demonstrate that SourceWarp is scalable and highly effective in supporting agile Data-Driven Decision Making by providing automation for testing and benchmarking proof-of-concept ideas for CI/CD tools chained CI/CD tools (also referred to as pipeline) for the DevOps platform or a combination of them without having to deploy features to the staging or production environments.;
2023 6th International Symposium on Autonomous Systems (ISAS);Knowledge graph (KG) can represent the domain knowledge in the structural entities and relations and have become a popular AI technique. Software knowledge provides a deep understanding of the software development process. In this paper we firstly provide a brief review on the related techniques construction methods and applications of KG in the software development process. Then we detailedly review and discuss the specific applications of KG in the whole software development process including the phases of software requirement analysis software design software testing software vulnerability detection software bug detection and software fault diagnosis respectively. Moreover this paper provides some unsolved problems about the KGâ€™s applications in the field of spacecraft control software development to facilitate future research.;
Software Testing With Large Language Models: Survey Landscape and Vision;Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language processing and artificial intelligence with the ability to handle large-scale datasets and exhibit remarkable performance across a wide range of tasks. Meanwhile software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability of software products. As the scope and complexity of software systems continue to grow the need for more effective software testing techniques becomes increasingly urgent making it an area ripe for innovative approaches such as the use of LLMs. This paper provides a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software testing from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for which LLMs are commonly used among which test case preparation and program repair are the most representative. It also analyzes the commonly used LLMs the types of prompt engineering that are employed as well as the accompanied techniques with these LLMs. It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research in this area highlighting potential avenues for exploration and identifying gaps in our current understanding of the use of LLMs in software testing.;
2021 2nd International Conference On Smart Cities Automation & Intelligent Computing Systems (ICON-SONICS);For years Software Defect Prediction (SDP) has been used as a way to improve software reliability. It is used as a tool to detect the defects on software module before the testing phase. The steps consist of building machine learning model by training dataset with classifier and predict on defective modules. Many datasets suffer from high dimensionality because of the high number of features and those features are mostly irrelevant to predict defect. This results the data to be unnecessarily bulky and the classification process to be time-consuming. We propose a feature extraction technique called FLDA for handling dimensionality problem of dataset and improving the classification performance. We use a total of four dataset from NASA MDP. For classifiers we use Support Vector Machine (SVM) Random Forest (RF) Naive Bayes (NF) and Multi Layer Perceptron (MLP). Based on the study results FLDA can significantly reduced the dimension of datasets by creating new feature that contains the most relevant information. FLDA can also shorten the processing time of the classifiers. When compared to another feature extraction technique such as PCA FLDA can easily outperform it in terms of Recall and AUC.;
2022 4th International Conference on Advanced Science and Engineering (ICOASE);Software systems have gotten increasingly complicated and adaptable in today's computer world. As a result it's critical to track down and fix software design flaws on a regular basis. Software fault prediction in early phase is useful for enhancing software quality and for reducing software testing time and expense it's a technique for predicting problems using historical data. To anticipate software flaws from historical databases several machine learning approaches are applied. This paper focuses on creating a predictor to predict software defects Based on previous data. For this purpose a supervised machine learning techniques was utilized to forecast future software failures K-Nearest Neighbor (KNN) and Random Forest (RF) applied technique applied to the defective data set belonging to the NASA's PROMISE repository. Also a set of performance measures such as accuracy precision recall and f1 measure were used to evaluate the performance of the models. This paper showed a good performance of the RF model compared to the KNN model resulting in a maximum and minimum accuracy are 99%88% on the MC1 and KC1 responsibly. In general the study's findings suggest that software defect metrics may be used to determine the problematic module and that the RF model can be used to anticipate software errors.;
2021 4th International Conference on Bio-Engineering for Smart Technologies (BioSMART);Software testing is a time-consuming and costly task as it involves testing all software modules. To minimize the cost and effort of software testing automatic defect detection can be used to identify the defective modules during the early stages. These aid software testers in detecting the modules that require intensive testing. Therefore automatically predicting software defects has become a critical factor in software engineering. This paper explores the existing methods and techniques on software defect prediction (SDP) and lists the most popular datasets that are used as benchmarks in SDP. In addition it discusses the approaches to overcome the class imbalance problem which usually occurs in the benchmark datasets for SDP problems. This paper can be helpful for researchers in software engineering and other related areas.;
2019 IEEE International Conference On Artificial Intelligence Testing (AITest);Fault localization problem is one of the most difficult processes in software debugging. Several spectrum-based ranking metrics have been proposed and none is shown to be empirically optimal. In this paper we consider the fault localization problem as a multicriteria decision making problem. The proposed approach tackles the different metrics by aggregating them into a single metric using a weighted linear formulation. A learning step is used to maintain the right expected weights of criteria. This approach is based on Analytic Hierarchy Process (AHP) where a ranking is given to a statement in terms of suspiciousness according to a comparison of ranks given by the different metrics. Experiments performed on standard benchmark programs show that our approach enables to propose a more precise localization than existing spectrum-based metrics.;
2012 10th International Conference on Frontiers of Information Technology;Similar software have similar software measurements. Defect data from one software can be used to anticipate defects in a similar software. Although not many defect datasets are made public in software engineering domain PROMISE repository is a reasonable collection of software data. This paper presents a two step approach to identify similar software and applies the proposed technique to find similar datasets in PROMISE repository. As step 1 the approach generates associations rules for each dataset to determine dataset's behavior in terms of frequent patterns. As step 2 overlap between the association rules is calculated using Fuzzy Inference Systems (FIS). The FIS generated for the study have been expert-based as well as auto-generated. Similarity between 28 dataset pairs has been found KC2 and PC1 turned out to be most similar datasets with 86% similarity using Mamdani 92% with Sugeno models. Results from expert-based and auto generated FIS have been comparable.;
2023 IEEE International Conference on Engineering Veracruz (ICEV);The quality compliance has become an aspect of big importance in the development of software engineering here the term â€˜defect metricsâ€™ comes in the prevention of errors failures and defects in the software. As a result of applying this type of metrics we can obtain quality and more reliable systems for today's world. Therefore establishing criteria for defect metrics is a relevant step within the components that make up the software product. The main objective of this research is to show an overview of defect metrics in software products. We aim to show their benefits and limitations and the causes of vulnerabilities in applications in order to obtain better built applications. This study was carried out using different sources of information obtained from academic databases which were: ACM Digital Library IEEE Xplore Springer Link and Science Direct. The study recovered a total of 20 research papers that met the necessary guidelines to belong to the systematic literature review these primary studies were previously subjected to multiple quality tests. The use of software metrics contributes significantly to the quality of a software product however limiting factors that interfere with the full use of defect metrics are also discussed. Finding the option with the lowest risk of limiting the use of these metrics and greater gain is relevant to the creation of a software product. In addition to supporting the testing process early on they also prevent software vulnerabilities due to their nature and incorporation in the components of a system.;
2013 22nd Australian Software Engineering Conference;"Numerous set similarity metrics have been used for ranking suspiciousness"" of code in spectral fault localization which uses execution profiles of passed and failed test cases to help locate bugs. Research in data mining has identified several forms of possibly desirable symmetry in similarity metrics. Here we define several forms of ""duals"" of metrics based on these forms of symmetries. Use of these duals plus some other slight modifications leads to several new similarity metrics. We show that versions of several previously proposed metrics are optimal or nearly optimal for locating single bugs. We also show that a form of duality exists between locating single bugs and locating ""deterministic"" bugs (execution of which always results in test case failure). Duals of the various single bug optimal metrics are optimal for locating such bugs. This more theoretical work leads to a conjecture about how different metrics could be chosen for different stages of software development.""";
2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC);Spectra Based Fault Localization (SBFL) is a technique to improve the efficiency of software fault localization. The performance of SBFL largely depends on the input information provided by an executed test suite. Due to the randomness existing in the testing process the output of SBFL may not be stable. In practice testers do not have the chance to run the whole testing process many times. They are not sure whether the actually obtained SBFL output has a large deviation from the ideal output (i.e. the SBFL output obtained under the assumption that the amount of testing resources is unlimited). Thus concerning the application of SBFL in real cases such instability of its performance (SBFL instability for short) is a challenge. In this paper the SBFL instability is discussed and its characteristics are further explored. Specifically we define SBFL instability as a stochastic quantity and introduce the measure of StabilityLevel to quantify it. Then based on the definition and measurement we conduct experimental studies to demonstrate that SBFL instability is indeed a prevalent phenomenon and also a serious problem. Besides two factors which influence the intensity of SBFL instability i.e. the test suite size and risk evaluation formula are observed and analyzed.;
2006 IEEE Region 5 Conference;In software technology today several development methodologies such as extreme programming and open source development increasingly use feedback from customer testing. This makes the customer defect data become more readily available. This paper proposes an effective use of reliability models and defect data to help managers make software release decisions by applying a strategy for selecting a suitable reliability model which best fits the customer defect data as testing progresses. We validate the proposed approach in an empirical study using a dataset of defect reports obtained from testing of three releases of a large medical system. The paper describes detailed results of our experiments and concludes with suggested guidelines on the usage of reliability models and defect data.;
2023 7th International Conference on I-SMAC (IoT in Social Mobile Analytics and Cloud) (I-SMAC);The software industry is rapidly evolving due to increasing demand and technology. Software created by humans can contain a number of errors which are known as defects. The primary responsibility of a tester is to identify these errors. Because defects can manifest at any stage during software development it can be difficult to begin testing at an early stage. When the manager misinterprets customer needs it can result in a defect during the system design phase. Quality assurance is essential for software and as the demand for software applications increases the complexity of software designs also rises leading to a greater number of bugs. This can lead to manual detection of the errors which takes more time to complete. The only way to improve software quality is to fix the defects. By implementing a time-saving method of software defect prediction through an enhanced Machine Learning and Artificial Neural Network techniques this paper increase the quality of the software.;
2019 1st International Conference on Advances in Science Engineering and Robotics Technology (ICASERT);In the arena of software engineering software defects prediction is one of the most attractive research topics. Here the main task is to predict if there is any bug in the software or not. For software testing software defect detection is important for reducing the time and resources consumed. Accurate estimate of defect software prediction process enables effective discovery and identification of the defects. Such prediction methods are important for the big scale systems where verification specialists need to focus their attention. In this paper we proposed a method where the features are selected using Genetic Algorithm (GA). Secondly make cluster of the selected features using Particle Swarm Optimization (PSO) and then train the model with different Neural Network (NN) methods such as: Feedforward Neural Network (FNN) Recurrent Neural Network (RNN) Artificial Neural Network (ANN) and Deep Neural Network (DNN) and finally calculate accuracy sensitivity specificity precision negative prediction value F1 score and Matthews correlation coefficient. We use five different datasets from NASA promise software engineering repository for our study. From our study we get the best accuracy result using deep neural network. Experimental consequences show that proposed strategy is a decent technique to predict the software defects.;
2019 10th International Conference on Computing Communication and Networking Technologies (ICCCNT);Software Defect Prediction (SDP) identifies the defect-prone modules from software source code which helps to serve good quality software. Mostly previous cross-project SDP models were built based on single project data where single project was used to prepare prediction models. However this investigation represents an empirical study of SDP where multiple projects data have been used to prepare prediction models. In this study multiple projects data have been used to prepare a balance and an imbalance datasets. After that this datasets have been used in different prediction models with eight different classifier algorithms. The trained models have been cross-checked by one balanced and imbalanced test datasets. Five evaluation metrics have been considered for evaluating the performance of the models. The experimental results show that there was no significant changes observed between balanced and imbalanced training models. Only AUC (Area Under the Curve) scores have increased significantly in terms of balanced training model with imbalanced test datasets. In the same training model with the balanced test accuracy and AUC score have increased significantly. However this study covers widely by creating the classification model from multiple projects' historical data. Further it proves that if the sufficient number of non-defective and defective data are supplied in the prediction model it can predict balanced and imbalanced both categories dataset alike. Here recommendation will be to consider the imbalanced learning while building the prediction model for cross-projects.;
Defect Prediction With Semantics and Context Features of Codes Based on Graph Representation Learning;To optimize the process of software testing and to improve software quality and reliability many attempts have been made to develop more effective methods for predicting software defects. Previous work on defect prediction has used machine learning and artificial software metrics. Unfortunately artificial metrics are unable to represent the features of syntactic semantic and context information of defective modules. In this article therefore we propose a practical approach for identifying software defect patterns via the combination of semantics and context information using abstract syntax tree representation learning. Graph neural networks are also leveraged to capture the latent defect information of defective subtrees which are pruned based on a fix-inducing change. To validate the proposed approach for predicting defects we define mining rules based on the GitHub workflow and collect 6052 defects from 307 projects. The experiments indicate that the proposed approach performs better than the state-of-the-art approach and five traditional machine learning baselines. An ablation study shows that the information about code concepts leads to a significant increase in accuracy.;
2016 24th Iranian Conference on Electrical Engineering (ICEE);Since 2009 several scalable and promising techniques to automatic program repair have been proposed with each technique often accompanied with a prototype tool. These techniques work in different levels of code with various types of defects and designed for different programming languages. Now the subfield of automatic program repair is mature enough to merit evaluate existing techniques and tools. This evaluation helps us identify the strengths and weaknesses of current research and provides future direction. To this end in this paper we present a family of criteria grouped into seven sets for evaluating automatic program repair techniques and tools. Moreover a five-level maturity model is proposed for the mentioned subfield. To the best of our knowledge no research yet evaluates automatic program repair techniques and tools in a general broad and comprehensive manner and this is the first attempt towards this goal. We employed our criteria to three existing mutation-based techniques and their corresponding tools and reported the results of preliminary evaluation. The proof-of-concept results demonstrate different aspects capabilities and shortcomings of each technique and provide evidence to the applicability and utility of our criteria.;
2009 16th Asia-Pacific Software Engineering Conference;Software faults can be diagnosed using program spectra. The program spectra considered here provide information about which statements are executed in each one of a set of test cases. This information is used to compute a value for each statement which indicates how likely it is to be buggy and the statements are ranked according to these values. We present two improvements to this method. First we associate varying weights with failed test cases --- test cases which execute fewer statements are given more weight and have more influence on the ranking. This generally improves diagnosis accuracy with little additional cost. Second the ranking is computed incrementally. After the top-ranked statement is identified the weights are adjusted in order to compute the rest of the ranking. This further improves accuracy. The cost is more significant but not prohibitive.;
Eurocon 2013;The purpose of this study is to analyze the reliability growth of Open Source Software (OSS) using Software Reliability Growth Models (SRGM). This study uses defects data of twenty five different releases of five OSS projects. For each release of the selected projects two types of datasets have been created datasets developed with respect to defect creation date (created date DS) and datasets developed with respect to defect updated date (updated date DS). These defects datasets are modelled by eight SRGMs Musa Okumoto Inflection S-Shaped Goel Okumoto Delayed S-Shaped Logistic Gompertz Yamada Exponential and Generalized Goel Model. These models are chosen due to their widespread use in the literature. The SRGMs are fitted to both types of defects datasets of each project and the their fitting and prediction capabilities are analysed in order to study the OSS reliability growth with respect to defects creation and defects updating time because defect analysis can be used as a constructive reliability predictor. Results show that SRGMs fitting capabilities and prediction qualities directly increase when defects creation date is used for developing OSS defect datasets to characterize the reliability growth of OSS. Hence OSS reliability growth can be characterized with SRGM in a better way if the defect creation date is taken instead of defects updating (fixing) date while developing OSS defects datasets in their reliability modelling.;
2012 IEEE 36th Annual Computer Software and Applications Conference Workshops;Dead code which is not uncommon in software engineering is an unexplored area in software piracy forensics. This paper primarily investigates the forensic importance of all programming blunders including dead codes. Programming Blunder is identified as a variable or a code segment (including dead code) or a field in a database table which is hardly used or executed in the context of the application or the user's functionality. Blunder genes can be found in many parts of any program. It is the contention of this paper that this phenomenon of blunders needs to be studied systematically from its very genetic origins to their surface realizations in contrast to bugs and flaws especially in view of their importance in software copyright infringement forensics. The article discusses the idea -- expression merger aspects of programming blunders and finally proposes the need and a way to incorporate programming blunders into Abstraction-Filtration- Comparison test the official software copyright infringement investigation procedure of US judiciary.;
2013 14th ACIS International Conference on Software Engineering Artificial Intelligence Networking and Parallel/Distributed Computing;A large open source software (OSS) project receives many bug reports on a daily basis. Bug localization techniques automatically pinpoint source code fragments that are relevant to a bug report thus enabling faster correction. Even though many bug localization methods have been introduced their performance is still not efficient. In this research we improved on existing bug localization methods by taking into account co-change histories. We conducted experiments on two OSS datasets the Eclipse SWT 3.1 project and the Android ZXing project. We validated our approach by evaluating effectiveness compared to the state-of-the-art approach Bug Locator. In the Eclipse SWT 3.1 project our approach reliably identified source code that should be fixed for a bug in 72.46% of the total bugs while Bug Locator identified only 51.02%. In the Android ZXing project our approach identified 85.71% while Bug Locator identified 60%.;
TANDEM: A Taxonomy and a Dataset of Real-World Performance Bugs;The detection of performance bugs like those causing an unexpected execution time has gained much attention in the last years due to their potential impact in safety-critical and resource-constrained applications. Much effort has been put on trying to understand the nature of performance bugs in different domains as a starting point for the development of effective testing techniques. However the lack of a widely accepted classification scheme of performance faults and more importantly the lack of well-documented and understandable datasets makes it difficult to draw rigorous and verifiable conclusions widely accepted by the community. In this paper we present TANDEM a dual contribution related to real-world performance bugs. Firstly we propose a taxonomy of performance bugs based on a thorough systematic review of the related literature divided into three main categories: effects causes and contexts of bugs. Secondly we provide a complete collection of fully documented real-world performance bugs. Together these contributions pave the way for the development of stronger and reproducible research results on performance testing.;
2023 IEEE International Conference on Software Analysis Evolution and Reengineering (SANER);Bug localization is an important aspect of software maintenance because it can locate modules that need to be changed to fix a specific bug. Although method-level bug localization is helpful for developers there are only a few tools and techniques for this task moreover there is no large-scale framework for their evaluation. In this paper we present FinerBench4BL an evaluation framework for method-level information retrieval-based bug localization techniques and a comparative study using this framework. This framework was semi-automatically constructed from Bench4BL a file-level bug localization evaluation framework using a repository transformation approach. We converted the original file-level version repositories provided by Bench4BL into method-level repositories by repository transformation. Method-level data components such as oracle methods can also be automatically derived by applying the oracle generation approach via bug-commit linking in Bench4BL to the generated method repositories. Furthermore we tailored existing file-level bug localization technique implementations at the method level. We created a framework for method-level evaluation by merging the generated dataset and implementations. The comparison results show that the method-level techniques decreased accuracy whereas improved debugging efficiency compared to file-level techniques.;
Experimental Validation of Inheritance Metricsâ€™ Impact on Software Fault Prediction;Software faults can cause trivial annoyance to catastrophic failures. Recent work in software fault prediction (SFP) advocates the need for predicting faults before deployment to aid testing process. Object-oriented programming is complex while comparing it with procedural languages having multiple dimensions wherein inheritance is an important aspect. In this paper we aim to investigate how much inheritance metrics assist in predicting software fault proneness. We first select the Chidamber and Kemerer (CK) metrics most accepted metric suite for predicting software faults and inheritance metrics. We use 65 publicly available base datasets having CK metrics and some other inheritance metrics to evaluate the impact of inheritance on SFP. We split each dataset into further two datasets: inheritance with CK and CK without inheritance for comparison of results. An artificial neural network (ANN) is used for model building and accuracy recall precision F1 measures and true negative rate (TNR) are used for measuring performance. Comparison is made and the results show an acceptable contribution of inheritance metrics in SFP. The testing community can safely use inheritance metrics in predicting software faults. Moreover high inheritance is not desirable as this can potentially lead to software faults.;
2020 IEEE 20th International Conference on Software Quality Reliability and Security (QRS);By comparing the predicted number of defects with the number found in crowdsourced test in real time people can dynamically assess the progress of crowdsourced test tasks. In this paper we propose a cross-project dynamic defect prediction model (CPDDPM) for crowdsourced test to predict the number of defects in real time. In the construction of training dataset we use density-based clustering method to select instances from the multiple source project datasets and build the initial training dataset. In the dynamic correction CPDDPM iteratively corrects the prediction model using crowdsourced test reports and ability attributes of the crowdsourced testers until the predicted results converge. We collected project defect datasets on the crowdsourced test platform and evaluated prediction accuracy of CPDDPM by using relative error and prediction at level l. The results show that CPDDPM can greatly improve the prediction performance of defect number.;
2013 35th International Conference on Software Engineering (ICSE);Maintenance costs can be substantial for large organizations (several hundreds of programmers) with very large and complex software systems. By large we mean lines of code in the range of hundreds of thousands or millions. Our research objective is to improve the process of handling anomaly reports for large organizations. Specifically we are addressing the problem of the manual laborious and time consuming process of assigning anomaly reports to the correct design teams and the related issue of localizing faults in the system architecture. In large organizations with complex systems this is particularly problematic because the receiver of an anomaly report may not have detailed knowledge of the whole system. As a consequence anomaly reports may be assigned to the wrong team in the organization causing delays and unnecessary work. We have so far developed two machine learning prototypes to validate our approach. The latest a re-implementation and extension of the first is being evaluated on four large systems at Ericsson AB. Our main goal is to investigate how large software development organizations can significantly improve development efficiency by replacing manual anomaly report assignment and fault localization with machine learning techniques. Our approach focuses on training machine learning systems on anomaly report databases this is in contrast to many other approaches that are based on test case execution combined with program sampling and/or source code analysis.;
Enhancing Bug Localization Using Phase-Based Approach;Software bug localization is an important step in the software maintenance process. Automatic bug localization can reduce the time consumed in the process of localization. Some techniques are applied in the bug localization process but those techniques suffer from limitations in time and accuracy. This paper proposes a phase-based bug localization approach to overcome these limitations. The approach is composed of three main phases which are raw data preparation package classification and source code recommendation. The main input to our approach is a bug report and the source code of the past versions for the target system of interest. From the bug report various information is utilized: the summary the description the stack traces and the fixed source code files. The raw data preparation phase is used to restructure those inputs. The package classification phase aims to locate the package that would include the source code to be modified as a first step hence reducing the time needed to locate the source code file due to the lexical mismatch between those files and the bug report data. Bidirectional Encoder Representations from Transformers (BERT) which is a sentence embedding technique is utilized in the package classification and source code recommendation phases. The experimental results show that our approach outperforms existing approaches according to TOP-N rank and Mean Reciprocal Rank (MRR) evaluation metrics.;
2024 International Conference on Emerging Smart Computing and Informatics (ESCI);Ever since software development bug free software is major challenge to all software industry. Both software developers and testers require ongoing enhancements to their development and testing processes to deliver high-quality software. Early detection and assessment of software project failure can aid in improving project outcomes and guiding them towards success. During the software development process several risks could have an impact on the project and perhaps cause it to fail. Making a distinction between classes with and without defects from continuous defect counts is common procedure when developing defect prediction model and apply it as a class attribute. Regression models could be used to create defect classifiers by categorizing the projected defect counts into classes that are defective and non-defective. In this study we developed model for bug prediction by computing Gradient Descent and cost value for Logistic regression. We have performed our experiment on CM1 defect dataset and result shows that logistic regression gives good accuracy for defect prediction when used with Gradient Descent and cost function. We therefore recommend that regression-based classifiers should be used for further defect classification research especially in cases when the modelled dataset's defective ratio is miserable.;
2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010);Software engineering process information extracted from version control systems and bug tracking databases are widely used in empirical software engineering. In prior work we showed that these data are plagued by quality deficiencies which vary in its characteristics across projects. In addition we showed that those deficiencies in the form of bias do impact the results of studies in empirical software engineering. While these findings affect software engineering researchers the impact on practitioners has not yet been substantiated. In this paper we therefore explore (i) if the process data quality and characteristics have an influence on the bug fixing process and (ii) if the process quality as measured by the process data has an influence on the product (i.e. software) quality. Specifically we analyze six Open Source as well as two Closed Source projects and show that process data quality and characteristics have an impact on the bug fixing process: the high rate of empty commit messages in Eclipse for example correlates with the bug report quality. We also show that the product quality - measured by number of bugs reported - is affected by process data quality measures. These findings have the potential to prompt practitioners to increase the quality of their software process and its associated data quality.;
2021 2nd International Conference on Intelligent Engineering and Management (ICIEM);Software is continuously evolving and hence it is essential for the production of quality and stable software by every software provider. Recently there is a paradigm shift in how software is designed. One of the biggest challenges of software engineering is predicting defects in software modules to save quality testing time. As software development challenges and constraints rise unexpected effects such as failure and errors decrease the consistency of software and user loyalty rendering error-free software more complex and frustrating. In this paper we analyze the use of Multi-Layer Perceptron Neural Network [5] (MLP-NN) for the efficient prediction of defects. We have also executed the MLP-NN with a subset of features selected using popular feature selection methods. The model was evaluated on 5 datasets from the AEEEM dataset. The results were compared with other common classifiers like Logistic Regression MLP-NN and Random Tree. The findings indicate that feature selection has a major role in increasing the accuracy of prediction. Our model had higher accuracy in few cases while at par with others in some.;
2013 21st International Conference on Software Telecommunications and Computer Networks - (SoftCOM 2013);Debugging of sensor nodes is tiresome and time-consuming mainly because of limited debug features of nodes and complex interactions in sensor networks. Besides each software level (hardware drivers communication protocols applications) needs a different approach to trace bugs. This paper surveys practical techniques that support bug tracing on nodes at various levels. Bugs may disappear when the program is being tested for debugging results in extra processing delays. In this paper we attack this problem by performing a set of micro-benchmarks for common debug techniques. We show their impact on the execution time and also their memory footprint. Based on our experience we claim assertions to be the most effective debug technique for sensor networks. They result in negligible delays less than a microsecond making them suitable for any software level: from hardware drivers to applications. Further since assertions stop the program execution just after detecting a failure they narrow down the root cause of the problem. Finally assertions support bug tracing in PC simulations and on real sensor nodes.;
2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS);SDP has been an evolved and important step in the Software Development Life Cycle during the testing phase. Significant research has gone through the prediction of defects thereby enhancing the quality of software produced quickly and efficiently. SDP datasets are quite imbalanced and this has caused the predictive models to suffer in terms of performance. In this research we have observed and studied the impact that Over Sampling Technique like Synthetic Minority Over Sampling Technique and Under Sampling Technique like Random Under Sampling Technique have on the prediction of software defects. Useful features were extracted from the datasets using Random Forest then we have implemented ensemble classification models such as AdaBoost and Bagging Classifier in addition to that we have also observed the predictive nature of Support Vector Machine. Finally we compared the results obtained between the various models the different sampling techniques using performance measures like El-Score Accuracy Area under the Receiver Operating Curve as well as G-Mean.;
2020 IEEE 31st International Symposium on Software Reliability Engineering (ISSRE);Traditional software reliability growth models only consider defect discovery data yet the practical concern of software engineers is the removal of these defects. Most attempts to model the relationship between defect discovery and resolution have been restricted to differential equation-based models associated with these two activities. However defect tracking databases offer a practical source of information on the defect lifecycle suitable for more complete reliability and performance models. This paper explicitly connects software reliability growth models to software defect tracking. Data from a NASA project has been employed to develop differential equation-based models of defect discovery and resolution as well as distributional and Markovian models of defect resolution. The states of the Markov model represent thirteen unique stages of the NASA software defect lifecycle. Both state transition probabilities and transition time distributions are computed from the defect database. Illustrations compare the predictive and computational performance of alternative approaches. The results suggest that the simple distributional approach achieves the best tradeoff between these two performance measures but that enhanced data collection practices could improve the utility of the more advanced approaches and the inferences they enable.;
2022 19th International Bhurban Conference on Applied Sciences and Technology (IBCAST);Machine learning based software defect prediction (SDP) approaches assist in estimating where faults are likely to occur in source code. In real-life projects fault-free modules are higher in number than faulty modules. This is referred to as class imbalance problem. Random over-sampling and random under-sampling (RUS) are the basic sampling strategies in data-level approaches for class imbalance problem. The RUS approach removes the instances randomly and due to randomness loss of useful information may occur. On the other hand over-sampling may lead to biased modeling. In this paper we propose a new technique known as Structured Under-Sampling (SUS) to address both of these problems. The proposed approach systematically removes inconsistent and redundant instances. After that most similar instances to the existing instances are removed to ensure minimum loss of information. For empirical evaluation C4.5 classifier has been used to compare SUS with RUS and Tomek RUS while performance difference has been analyzed using F1-score and ROC. The results of our investigation show improved performance of SUS over other approaches. Moreover it has been observed that the Imbalance ratio (IR) affects the performance of SUS. More specifically when IR > 5 SUS outperformed in all results.;
2018 IEEE International Conference on Big Data Cloud Computing Data Science & Engineering (BCD);Software maintenance is an important activity on the software lifecycle. In this study we try to establish a benchmark of software maintenance cost. To establish the benchmark factors affecting work efficiency and unit cost should be clarified using a dataset collected from various organizations (cross-company dataset). We used dataset includes 837 data points collected by Economic Research Association from 2006 to 2016 and analyzed factors affecting work efficiency of software maintenance and unit cost of engineers. In the analysis we defined two types of work efficiency. Also as unit cost of engineers we defined two types of unit cost. As attributes related to work efficiency we analyzed address to process improvement business sector and required availability rate. As attributes related to unit cost we analyzed address to process improvement business sector and social impact of faults. First we showed correlation ratio of attributes to work efficiency and unit cost. Then we analyzed each attributes using boxplots. As a result business sectors related to both work efficiency and unit cost. The boxplots are useful to estimate software maintenance cost roughly.;
Evaluating Stratification Alternatives to Improve Software Defect Prediction;Numerous studies have applied machine learning to the software defect prediction problem i.e. predicting which modules will experience a failure during operation based on software metrics. However skewness in defect-prediction datasets can mean that the resulting classifiers often predict the faulty (minority) class less accurately. This problem is well known in machine learning and is often referred to as â€œlearning from imbalanced datasets.â€ One common approach for mitigating skewness is to use stratification to homogenize class distributions however it is unclear what stratification techniques are most effective both generally and specifically in software defect prediction. In this article we investigate two major stratification alternatives (under- and over-sampling) for software defect prediction using Analysis of Variance. Our analysis covers several modern software defect prediction datasets using a factorial design. We find that the main effect of under-sampling is significant at Î± = 0.05 as is the interaction between under- and over-sampling. However the main effect of over-sampling is not significant.;
2012 CSI Sixth International Conference on Software Engineering (CONSEG);Software Reliability growth models are helping the software society in predicting and analyzing the software product in terms of quality. In this context several software reliability growth models are proposed in the literature. Majority of models concentrated on fault detection process ignoring the correction. Error detection correction and dependency are the important phenomenon for the software reliability models. In this paper we proposed a new SRGM model based on correction lag and error dependency with incorporating the testing effort. All numerical calculations are carried out on real datasets and results are analyzed. By analyzing the results our proposed model fits well for the datasets.;
MASTER: Multi-Source Transfer Weighted Ensemble Learning for Multiple Sources Cross-Project Defect Prediction;Multi-source cross-project defect prediction (MSCPDP) attempts to transfer defect knowledge learned from multiple source projects to the target project. MSCPDP has drawn increasing attention from academic and industry communities owing to its advantages compared with single-source cross-project defect prediction (SSCPDP). However two main problems which are how to effectively extract the transferable knowledge from each source dataset and how to measure the amount of knowledge transferred from each source dataset to the target dataset seriously restrict the performance of existing MSCPDP models. In this paper we propose a novel multi-source transfer weighted ensemble learning (MASTER) method for MSCPDP. MASTER measures the weight of each source dataset based on feature importance and distribution difference and then extracts the transferable knowledge based on the proposed feature-weighted transfer learning algorithm. Experiments are performed on 30 software projects. We compare MASTER with the latest state-of-the-art MSCPDP methods with statistical test in terms of famous effort-unaware measures (i.e. PD PF AUC and MCC) and two widely used effort-aware measures ($P_{opt;
Defect Detection and Localization in Fiber-Optic Panels Based on Discrete Wavelet and Multiobjective Morphological Optimization;The concentric optical camera based on the optical fiber relay image can meet the needs of the miniaturization lightweight and large field-of-view detection of the space target detection system. However due to the inevitable thermal stretching and torque processes involved in the production of fiber-optic panels (FOPs) defects of unknown shape size and location are formed increasing the difficulty of space target information acquisition and causing center-of-mass localization errors. To efficiently and accurately detect and locate defects in FOPs we propose an improved defect detection and localization method for FOPs based on discrete wavelet and multiobjective morphological optimization by using the gray value of the image sensor. We compare this method with the Canny edge detection method and the fuzzy C-means (FCM) clustering method and find that the method has higher detection accuracy and stronger robustness in an environment with a large number of dark filament interferences and the detection results are not affected by the various image sizes of the FOPs. The method also maintains a high degree of consistency in detection metrics with the F_Score detection accuracy of 85%. This research provides a reliable solution for FOP defect detection and localization lays the foundation for image quality improvement of concentric optical cameras based on fiber-optic relay imaging and contributes to space target detection and localization.;
18th International Parallel and Distributed Processing Symposium 2004. Proceedings.;Summary form only given. Testing multithreaded concurrent or distributed programs is acknowledged to be a very difficult task. We decided to create a benchmark of programs containing documented multithreaded bugs that can be used in the development of testing tool for the domain. In order to augment the benchmark with a sizable number of programs we assigned students in a software testing class to write buggy multithreaded Java programs and document the bugs. This paper documents this experiment. We explain the task that was given to the students go over the bugs that they put into the programs both intentionally and unintentionally and show our findings. We believe this part of the benchmark shows typical programming practices including bugs of novice programmers. In grading the assignments we used our technologies to look for undocumented bugs. In addition to finding many undocumented bugs which was not surprising given that writing correct multithreaded code is difficult we also found a number of bugs in our tools. We think this is a good indication of the expected utility of the benchmark for multithreaded testing tool creators.;
37th Annual Hawaii International Conference on System Sciences 2004. Proceedings of the;The potential cost savings from handling software errors within a development cycle rather than subsequent cycles has been estimated at 38.3 billion dollars. Such figures emphasize that current testing methods are inadequate and that helping reduce software bugs and errors is an important area of research with a substantial payoff. This paper reports on research using genetic algorithms for test case generation for systems level testing building on past work at the unit testing level. The goals of the paper are to explore the use of genetic algorithms for testing complex distributed systems as well as to develop a framework or vocabulary of important environmental attributes that characterize complex systems failures. In addition preliminary visualization techniques that might help software developers to understand and uncover complex systems failures are explored.;
Proceedings 27th Annual International Computer Software and Applications Conference. COMPAC 2003;Software defect curves describe the behavior of the estimate of the number of remaining software defects as software testing proceeds. They are of two possible patterns: single-trapezoidal-like curves or multiple-trapezoidal-like curves. In this paper we present some necessary and/or sufficient conditions for software defect curves of the Goel-Okumoto NHPP model. These conditions can be used to predict the effect of the detection and removal of a software defect on the variations of the estimates of the number of remaining defects. A field software reliability dataset is used to justify the trapezoidal shape of software defect curves and our theoretical analyses. The results presented in this paper may provide useful feedback information for assessing software testing progress and have potentials in the emerging area of software cybernetics that explores the interplay between software and control.;
2021 28th Asia-Pacific Software Engineering Conference Workshops (APSEC Workshops);Debugging and locating faulty source files are tedious and time-consuming tasks. To improve the productivity and to help developers focus on crucial files automated bug localization models have been proposed for years. These models recommend buggy source files by ranking them according to their relevance to a given bug report. There are two significant challenges in this research field: (i) narrowing the lexical gap between bug reports which are typically described using natural languages and source files written in programming languages (ii) reducing the impact of imbalanced data distribution in model training as a far fewer of source files relate to a given bug report while the majority of them are not relevant. In this paper we propose a deep neural network model to investigate essential information hidden within bug reports and source files through capturing not only lexical relations but also semantic details as well as domain knowledge features such as historical bug fixings code change history. To address the skewed class distribution we apply a focal loss function combining with a bootstrapping method to rectify samples of the minority class within iterative training batches to our proposed model. We assessed the performance of our approach over six large scale Java open-source projects. The empirical results have showed that the proposed method outperformed other state-of-the-art models by improving the Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR) scores from 3% to 11% and from 2% to 14% respectively.;
2020 IEEE 20th International Conference on Software Quality Reliability and Security Companion (QRS-C);Spectral fault localization is an automatic fault-localization technique to expedite debugging which uses risk evaluation formula to rank the risk of fault existence in each program entity after collecting testing information. To assess the potential usefulness of a test suite and improves the accuracy for spectral fault localization methods of assessing and optimizing test suite are proposed in this paper which. Firstly Average Ranking Cost of the test suite quality and two kinds of constrains are defined and test suite quality assessment method based on these definitions is given. Secondly a new test suite optimization method based on greedy algorithm is proposed. Finally two widely used program databases (SIR and Defects4j) and 8 SFL techniques are applied to verify the effectiveness of our method and the fault localization cost before and after optimizing test suites of test objects are analyzed using effect size. The largest effect size reaches 0.5398 and Each SFL technology has different degrees of improvement in the rankings of faulty statements in different programs by optimizing test suite.;
2016 6th International Conference - Cloud System and Big Data Engineering (Confluence);Software has become a vital part of human's life - hence building defect free software is a must. Various studies have been carried out to predict defects probability of defect prone modules and implementation of defect prediction for real life softwares. The focus of this paper is towards building a framework using attribute selection for defect prediction based on five classifiers IBk KStar LWL Random Tree and Random Forest. Performance comparison is done on the basis of accuracy and ROC values. The result and analysis shows that the framework has reduced total number of attributes used for each dataset by 6 folds on average also LWL performed better than other four classifiers when tested with 10 Cross Validation (10CV) and percentage split of 66%.;
2018 IEEE International Conference on Data Mining (ICDM);Software Quality Assurance (SQA) is essential in software development and many defect prediction methods based on machine learning have been proposed to identify defective modules. However most existing defect prediction models do not provide good defect prediction results and the semantic features reflecting the detective patterns may not be well-captured via traditional feature extraction methods. More information such as code comments should be also be embedded to generate semantic features respecting the source code functionality. Therefore how to embed code comments for defect prediction is a big challenge and another problem is that many comments of source code are missing in real-world applications. In this paper we propose a novel defect prediction model named CAP-CNN (Convolutional Neural Network for Comments Augmented Programs) which is a deep learning model that automatically embeds code comments in generating semantic features from the source code for software defect prediction. To overcome the missing comments problem a novel training strategy is used in CAP-CNN that the network encodes and absorb comments information to generate semantic features automatically during training process which does not need testing modules to contain comments. Experimental results on several widely-used software data sets indicate that the comment features are able to improve defect prediction performance.;
Proceedings of 2013 3rd International Conference on Computer Science and Network Technology;The advent and advancements of software testing automation helped the whole software testing process to be carried out efficiently and effectively. Regression test is a testing process which seeks to uncover new software bugs or regressions in existing functional and non-functional areas of a system after changes. Automation brings significant enhancements to regression test. STAF (The Software Testing Automation Framework) is an open source multi-platform multi-language automated testing framework. In this paper we design and implement a software regression test automation tool (RTAT) based on STAF. The high-level design components design as well as its J2EE based implementation will be covered additionally we applied it to the testing process of a real world regression test process and conducted evaluation based on the application. The evaluation results indicate that our tool helped to improve the regression test efficiency significantly.;
2019 International Conference on Electrical Computer and Communication Engineering (ECCE);Software defect prediction is related to the testing area of software industry. Several methods have been developed for the prediction of bugs in software source codes. The objective of this study is to find the inconsistency of performance between imbalances and balance data set and to find the distinction of performance between single classifier and aggregate classifier (voting). In this investigation eight publicly available data sets have collected also seven algorithms and hard voting are used for finding precision recall and F-1 score to predict software defect. In these collected data two sets are almost balanced. For this investigation these balanced data sets have converted into imbalanced sets as average non-defective and defective ratio of the other 6 data sets. The experiment result shows that performance of the two balanced data sets is lower than other six sets. After conversion of two data sets the performance has increased as like as other six data sets. Another observation is the performance metric that shows the results of precision recall and F1-score for voting are 0.92 0.84 and 0.87 respectively which are better than other single classifier. This study has been able to shows that- imbalance of non-defective and defective classes have a big impact on software defect prediction and the voting is the best performer among the classifiers.;
2017 24th Asia-Pacific Software Engineering Conference (APSEC);Background: Localizing buggy files automatically speeds up the process of bug fixing so as to improve the efficiency and productivity of software quality teams. There are other useful semantic information available in bug reports and source code but are mostly underutilized by existing bug localization approaches. Aims: We propose DeepLocator a novel deep learning based model to improve the performance of bug localization by making full use of semantic information. Method: DeepLocator is composed of an enhanced CNN (Convolutional Neural Network) proposed in this study considering bug-fixing experience together with a new rTF-IDuF method and pretrained word2vec technique. DeepLocator is then evaluated on over 18500 bug reports extracted from AspectJ Eclipse JDT SWT and Tomcat projects. Results: The experimental results show that DeepLocator achieves 9.77% to 26.65% higher Fmeasure than the conventional CNN and 3.8% higher MAP than a state-of-the-art method HyLoc using less computation time. Conclusion: DeepLocator is capable of automatically connecting bug reports to the corresponding buggy files and successfully achieves better performance based on a deep understanding of semantics in bug reports and source code.;
2018 20th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC);Software defect prediction is an intricate but essential software testing related activity. As a solution to it we have recently proposed HyGRAR a hybrid classification model which combines Gradual Relational Association Rules (GRARs) with ANNs. ANNs were used to learn gradual relations that were then considered in a mining process so as to discover the interesting GRARs characterizing the defective and non-defective software entities respectively. The classification of a new entity based on the discriminative GRARs was made through a non-adaptive heuristic method. In current paper we propose to enhance HyGRAR through autonomously learning the classification methodology. Evaluation experiments performed on two open-source data sets indicate that the enhanced HyGRAR classifier outperforms the related approaches evaluated on the same two data sets.;
2017 International Conference on Robotics and Automation Sciences (ICRAS);Predicting software defect at the class level is important in defect prediction studies. In addition class level defect prediction enables software team to have an idea on the possible number of defects in an upcoming product release prior to testing. Considerable effort is needed to investigate factors which influence the number of defects at the class level of a software product. In this paper we investigate few factors namely time and defect velocity in relation to defect density of a class using a defect density correlation technique. An experiment was conducted on 69 open source Java projects containing 131034 classes. Results show that the defect density achieved a correlation coefficient of 61.41% defect introduction time achieved a correlation coefficient of -11.413% and the defect velocity achieved 93.56% respectively. Defect velocity is positively correlated with the number of defects at the class level.;
2009 XXIII Brazilian Symposium on Software Engineering;An approach to software reliability modeling based on code coverage is used to derive the Infinite Failure software reliability Model Based on Code Coverage - IFMBC. Our aim was to verify the soundness of the approach under different assumptions. The IFMBC was assessed with test data from a real application making use of the following structural testing criteria: all-nodes all-edges and potential-uses - a data-flow based family of criteria. The IFMBC was shown to be as good as the Geometric Model - GEO found to be the best traditional time-based model that fits the data. Results from the analysis also show that the IFMBC is as good as the BMBC - Binomial software reliability Model Based on Coverage - a model previously derived using the code coverage approach indicating it to be effective under different modeling assumptions.;
2024 IEEE/ACIS 22nd International Conference on Software Engineering Research Management and Applications (SERA);Spectrum-Based Fault Localization (in short SBFL) is one of the popular techniques to localize faulty statements of a given program. SBFL utilizes the information about which statements are executed in each of the successful or failed test cases. Even if multiple programs have the same functionality the accuracy of SBFL can differ due to their structural variations. Thus changing program structures to be suitable for SBFL may improve the accuracy of fault localization while maintaining functionality. In previous research by Sasaki et al SBFL-Score was proposed to discover program structures suitable for SBFL. SBFL-Score is one of the metrics used to evaluate how well a program is suitable for SBFL. Furthermore the previous research measured SBFL-Scores for pairs of programs with different structures but the same functionality and obtained a program structure suitable for SBFL. However a small number of programs and a small number of mutation operators used in the experiments were shortcomings. Thus in this study we conducted an experiment with approximately 36 times more programs and about 2.5 times more mutation operators than in the previous research. As a result of this experiment we identified four new program structures suitable for SBFL.;
2012 35th Annual IEEE Software Engineering Workshop;The purpose of this study is to compare the fitting (goodness of fit) and prediction capability of eight Software Reliability Growth Models (SRGM) using fifty different failure Data sets. These data sets contain defect data collected from system test phase operational phase (field defects) and Open Source Software (OSS) projects. The failure data are modelled by eight SRGM (Musa Okumoto Inflection S-Shaped Goel Okumoto Delayed S-Shaped Logistic Gompertz Yamada Exponential and Generalized Goel Model). These models are chosen due to their prevalence among many software reliability models. The results can be summarized as follows: Fitting capability: Musa Okumoto fits all data sets but all models fit all the OSS datasets. : Prediction capability: Musa Okumoto Inflection S-Shaped and Goel Okumoto are the best predictors for industrial data sets Gompertz and Yamada are the best predictors for OSS data sets. : Fitting and prediction capability: Musa Okumoto and Inflection are the best performers on industrial datasets. However this happens only on slightly more than 50% of the datasets. Gompertz and Inflection are the best performers for all OSS datasets.;
Fault Analysis and Debugging of Microservice Systems: Industrial Survey Benchmark System and Empirical Study;The complexity and dynamism of microservice systems pose unique challenges to a variety of software engineering tasks such as fault analysis and debugging. In spite of the prevalence and importance of microservices in industry there is limited research on the fault analysis and debugging of microservice systems. To fill this gap we conduct an industrial survey to learn typical faults of microservice systems current practice of debugging and the challenges faced by developers in practice. We then develop a medium-size benchmark microservice system (being the largest and most complex open source microservice system within our knowledge) and replicate 22 industrial fault cases on it. Based on the benchmark system and the replicated fault cases we conduct an empirical study to investigate the effectiveness of existing industrial debugging practices and whether they can be further improved by introducing the state-of-the-art tracing and visualization techniques for distributed systems. The results show that the current industrial practices of microservice debugging can be improved by employing proper tracing and visualization techniques and strategies. Our findings also suggest that there is a strong need for more intelligent trace analysis and visualization e.g. by combining trace visualization and improved fault localization and employing data-driven and learning-based recommendation for guided visual exploration and comparison of traces.;
Proceedings 26th Annual International Computer Software and Applications;The method of choice of the software reliability models based on the analysis of assumptions and compatibility both input and output parameters is offered. This method is illustrated on the software reliability growth models (SRGM). The classification of SRGMs is carried out and its accordance to the known classifications is ascertained. The approach to build SRGMs database is designed and its analysis is fulfilled. For choice of SRGM it is offered to use assumptions matrix taking into account the features of software engineering and testing processes. The procedures of SRGM choice and complexing are designed. The examples of implementation and testing of these procedures are performed.;
2021 8th International Conference on Smart Computing and Communications (ICSCC);Software practitioners are continuing to build advanced software defect prediction (SDP) models to help the tester find fault-prone modules. However the Class Imbalance (CI) problem consists of uncommonly few defective instances and more non-defective instances cause inconsistency in the performance. We have conducted 880 experiments to analyze the variation in the performance of 10 SDP models by concerning the class imbalance problem. In our experiments we have used 22 public datasets consists of 41 software metrics 10 baseline SDP methods and 4 sampling techniques. We used Mathews Correlation Coefficient (MCC) which is more useful when a dataset is highly imbalanced. We have also compared the predictive performance of various ML models by applying 4 sampling techniques. To examine the performance of different SDP models we have used the F-measure. We found the performance of the learning models is unsatisfactory which needs to mitigate. We have also found a few surprising results some logical patterns between classifier and sampling technique. It provides a connection between sampling technique software matrices and a classifier.;
2023 IEEE 23rd International Conference on Software Quality Reliability and Security (QRS);Software fault injection is a fundamental technique for studying the dependability of software systems. The code mutation based defect injections encounter efficiency (i.e. dormant faults) and accuracy (when they are not done at the source code level) issues. Software error injections directly emulate the effects of software defects which is more efficient and practical. But whether the injected errors truly represent the impact of bugs in the real world is still an open problem. Several studies have investigated the representativeness problem of component interface (API) errors. However the component API error injections are relatively coarse in granularity because they regard the component programs as black boxes. Thus they cannot be used to analyze the internal error behaviors within the components. To overcome this issue we propose a finite state machine for generating representative code mutations (as baseline) and a novel tracing approach for collecting function call interface data. That enables the analysis of the representativeness of program internal errors from the perspective of function call interface for C/C++ programs by fault-free and fault injection control experiments. The experimental results imply that the traditional error models cannot accurately emulate software defects at function call interfaces. We provide useful suggestions based on our findings for improving the representativeness of function call interface error injection.;
An Experimental Assessment of Using Theoretical Defect Predictors to Guide Search-Based Software Testing;Automated test generators such as search-based software testing (SBST) techniques are primarily guided by coverage information. As a result they are very effective at achieving high code coverage. However is high code coverage alone sufficient to detect bugs effectively? In this paper we propose a new SBST technique predictive many objective sorting algorithm (PreMOSA) which augments coverage information with defect prediction information to decide where to increase the test coverage in the class under test (CUT). Through an experimental evaluation using 420 labelled bugs on the Defects4J benchmark and using theoretical defect predictors we demonstrate the improved effectiveness and efficiency of PreMOSA in detecting bugs when using any acceptable defect predictor i.e. a defect predictor with recall and precision $\geq$â‰¥ 75% compared to the state-of-the-art dynamic many objective sorting algorithm (DynaMOSA). PreMOSA detects up to 8.3% more labelled bugs on average than DynaMOSA when given a time budget of 2 minutes for test generation per CUT.;
2024 IEEE 7th Advanced Information Technology Electronic and Automation Control Conference (IAEAC);In recent years there has been an increasing interest in using machine learning methods to predict software defects. In practical engineering applications the number of defective software samples is far less than that of non-defective software samples resulting in unbalanced distribution of samples. In addition the prediction performance of a single classifier is limited due to the diversity of distribution of defect data. Therefore a series of methods should be adopted to solve these problems to improve the accuracy and reliability of software defect prediction. Here the combined sampling method is used to deal with the class imbalance problem and the minority class defect samples are synthesized. Through improved Bagging different base classifiers are selected to increase the diversity of classifiers in defect prediction and the final prediction result is obtained by weighted integration of multiple classifiers according to the Accuracy value of each classifier for the test set classification. Through the above method a better classification effect is obtained.;
2020 25th International Computer Conference Computer Society of Iran (CSICC);The performance of the fault localization techniques plays a significant role in their practical adoption. This paper reports an empirical study of two states of the art fault localization techniques. The main differences from previous studies are: (1) the specialized focus on two methods to present effective advice (2) considering different suspiciousness formulae to limit their effect on the fault localization accuracy and (3) two different test suites containing small and large scale projects to test all aspects of the methods. Important factors of each fault localization methods have defined the accuracy and execution time. Our results provide proper information about spectrum-based and mutation-based fault localization to help other scholars to choose the best method based on their requirements. The empirical results indicate that the mutation- based fault localization is relatively 12 percent slower and 5.2 percent more accurate than the spectrum-based fault localization.;
2023 IEEE 47th Annual Computers Software and Applications Conference (COMPSAC);MBFL (Mutation-Based Fault Localization) is one of the most commonly studied fault localization techniques due to its promising fault localization effectiveness. However MBFL incurs a high execution cost as it needs to execute the test suite on a large number of mutants. While previous studies have proposed mutant reduction methods for FOMs (First-Order Mutants) to help alleviate the cost of MBFL the reduction of HOMs (Higher-Order Mutants) has not been thoroughly investigated. In this study we propose SGS (Statement Granularity Sampling) a method which conducts HOMs reduction for HMBFL (Higher-Order Mutation-Based Fault Localization). Considering the relationship between HOMs and statements we sample HOMs at the statement level to ensure each statement has corresponding HOMs. We empirically evaluate the fault localization effectiveness of HMBFL using SGS on 237 multiple-fault programs taken from the SIR and Codeflaws benchmarks. The experimental results show that (1) The best sampling ratio for HMBFL with SGS is 20% which preserves the performance and reduces execution costs by 80%  (2) The fault localization accuracy of HMBFL with SGS outperforms the state-of-the-art SBFL (Spectrum-Based Fault Localization) and MBFL techniques by 20%.;
A Data Transfer and Relevant Metrics Matching Based Approach for Heterogeneous Defect Prediction;Heterogeneous defect prediction (HDP) is a promising research area in the software defect prediction domain to handle the unavailability of the past homogeneous data. In HDP the prediction is performed using source dataset in which the independent features (metrics) are entirely different than the independent features of target dataset. One important assumption in machine learning is that independent features of the source and target datasets should be relevant to each other for better prediction accuracy. However these assumptions do not generally hold in HDP. Further in HDP the selected source dataset for a given target dataset may be of small size causing insufficient training. To resolve these issues we have proposed a novel heterogeneous data preprocessing method namely Transfer of Data from Target dataset to Source dataset selected using Relevance score (TDTSR) for heterogeneous defect prediction. In the proposed approach we have used chi-square test to select the relevant metrics between source and target datasets and have performed experiments using proposed approach with various machine learning algorithms. Our proposed method shows an improvement of at least 14% in terms of AUC score in the HDP scenario compared to the existing state of the art models.;
2016 IEEE 23rd International Conference on Software Analysis Evolution and Reengineering (SANER);Software fault prediction promises to be a powerful tool in supporting test engineers upon their decision where to define testing hotspots. However there are limitations on a cross project prediction and a lack of reports upon application to industrial software as well as the power of metrics to represent bugs. In this paper we present a novel analysis based upon faults discovered in model-based automotive software projects and their relationship to metrics used to perform fault prediction. Using our previously released dataset on software metrics we report bug classes discovered during heavy testing of those automotive software. As the software has been developed following strict coding and development guidelines we present the results based on a comparison between the discovered error classes and those which might derive a reduced potential error set. Using the three projects from our dataset we determine if any of these bug classes are project specific.;
2023 IEEE Conference on Software Testing Verification and Validation (ICST);This paper presents BugOss a benchmark of real-world regression bugs found in OSS-Fuzz for experimenting with regression fuzzing techniques. To reproduce the real project context where the bugs were introduced each study artifact of BugOss indicates the exact bug-inducing commit and provides the information about the target bug together with the existing bugs in the same commit. The experiment results with five fuzzing techniques show that the 18 C/C++ artifacts currently registered for BugOss encompass various cases of regression bugs in real-world. We believe that BugOss offers a useful basis for empirically investigating regression fuzzing techniques.;
2022 4th International Conference on Inventive Research in Computing Applications (ICIRCA);The defect in the software arrives from building it and it can be solved by the default prediction which aims to give the outputs as the defection prone components or the code parts in which there is a defect during the testing stage of the development procedure. The main outcome of the prediction of the particular models is to see that testing is performed and all the defects that are present in the particular part of the software too comes into play. Traditionally the defect prediction focuses on the design features which are done manually and involves the complexity metrics to provide the input to the ML classifiers for finding the defects in a certain area or entire program. Instead as per the trend the features which are semantically and structural to the programs generally fail during the testing phase. Further it should be detected properly to develop a proper software. This research work intends to showcase the cutting edge approach of the clustering module as a part of the machine learning technique and find the defects in the software.;
2010 ACM/IEEE 32nd International Conference on Software Engineering;Reproducing bug symptoms is a prerequisite for performing automatic bug diagnosis. Do bugs have characteristics that ease or hinder automatic bug diagnosis? In this paper we conduct a thorough empirical study of several key characteristics of bugs that affect reproducibility at the production site. We examine randomly selected bug reports of six server applications and consider their implications on automatic bug diagnosis tools. Our results are promising. From the study we find that nearly 82% of bug symptoms can be reproduced deterministically by re-running with the same set of inputs at the production site. We further find that very few input requests are needed to reproduce most failures in fact just one input request after session establishment suffices to reproduce the failure in nearly 77% of the cases. We describe the implications of the results on reproducing software failures and designing automated diagnosis tools for production runs.;
2014 International Conference on Advances in Computing Communications and Informatics (ICACCI);Removal of defects is the key in ensuring long-term error free operation of a software system. Although improvements in the software testing process has resulted in better coverage it is evident that some parts of a software system tend to be more defect prone than the other parts and identification of these parts can greatly benefit the software practitioners in order to deliver high quality maintainable software products. A defect prediction model is built by training a learner using the software metrics. These models can later be used to predict defective classes in a software system. Many studies have been conducted in the past for predicting defective classes in the early phases of the software development. However the evolutionary computation techniques have not yet been explored for predicting defective classes. The nature of evolutionary computation techniques makes them better suited to the software engineering problems. In this study we explore the predictive ability of the evolutionary computation and hybridized evolutionary computation techniques for defect prediction. This work contributes to the literature by examining the effectiveness of the 15 evolutionary computation and hybridized evolutionary computation techniques to 5 datasets obtained from the Apache Software Foundation using the Defect Collection and Reporting System. The results are evaluated in terms of the values of accuracy. We further compare the evolutionary computation techniques using the Friedman ranking. The results suggest that the defect prediction models built using the evolutionary computation techniques perform well over all the datasets in terms of prediction accuracy.;
2013 Ninth International Conference on Computational Intelligence and Security;In order to solve the problems of traditional SVM classifier for software defect prediction this paper proposes a novel dynamic SVM method based on improved cost-sensitive SVM (CSSVM) which is optimized by the Genetic Algorithm (GA). Through selecting the geometric classification accuracy as the fitness function the GA method could improve the performance of CSSVM by enhancing the accuracy of defective modules and reducing the total cost in the whole decision. Experimental results show that the GA-CSSVM method could achieve higher AUC value which denotes better prediction accuracy both for minority and majority samples in the imbalanced software defect data set.;
Improving Cross-Project Software Defect Prediction Method Through Transformation and Feature Selection Approach;In the traditional software defect prediction methodology the historical record (dataset) of the same project is partitioned into training and testing data. In a practical situation where the project to be predicted is new traditional software defect prediction cannot be employed. An alternative method is cross-project defect prediction where the historical record of one project (source) is used to predict the defect status of another project (target). The cross-project defect prediction method solves the limitations of the historical records in the traditional software defect prediction method. However the performance of cross-project defect prediction is relatively low because of the distribution differences between the source and target projects. Furthermore the software defect dataset used for cross-project defect prediction is characterized by high-dimensional features some of which are irrelevant and contribute to low performance. To resolve these two issues this study proposes a transformation and feature selection approach to reduce the distribution difference and high-dimensional features in cross-project defect prediction. A comparative experiment was conducted on publicly available datasets from the AEEEM. Analysis of the results obtained shows that the proposed approach in conjugation with random forest as the classification model outperformed the other four state-of-the-art cross-project defect prediction methods based on the commonly used performance evaluation metric F1_score.;
2021 International Conference on Electrical Engineering and Informatics (ICEEI);The software project director has to keep estimating the required resources and planning the schedule for deliverables. Unfortunately such estimation and planning are not accurate unless careful monitoring and control plan is maintained because software development is risky. In this paper an investigation was carried out by integrating a promising metaheuristic algorithm with an artificial neural network to optimize the network parameters to address predicting the size of a software test team. The target of this integration was to enhance the accuracy of network prediction. The proposed method has been evaluated on two datasets. These datasets have different characteristics and have been extracted from the industry repository. The comparative results proved the superiority of the proposed method over the other methods.;
Watch Out for Extrinsic Bugs! A Case Study of Their Impact in Just-In-Time Bug Prediction Models on the OpenStack Project;Intrinsic bugs are bugs for which a bug-introducing change can be identified in the version control system of a software. In contrast extrinsic bugs are caused by external changes to a software such as errors in external APIs thereby they do not have an explicit bug-introducing change in the version control system. Although most previous research literature has assumed that all bugs are of intrinsic nature in a previous study we show that not all bugs are intrinsic. This paper shows an example of how considering extrinsic bugs can affect software engineering research. Specifically we study the impact of extrinsic bugs in Just-In-Time bug prediction by partially replicating a recent study by McIntosh and Kamei on JIT models. These models are trained using properties of earlier bug-introducing changes. Since extrinsic bugs do not have bug-introducing changes in the version control system we manually curate McIntosh and Kameiâ€™s dataset to distinguish between intrinsic and extrinsic bugs. Then we address their original research questions this time removing extrinsic bugs to study whether bug-introducing changes are a moving target in Just-In-Time bug prediction. Finally we study whether characteristics of intrinsic and extrinsic bugs are different. Our results show that intrinsic and extrinsic bugs are of different nature. When removing extrinsic bugs the performance is different up to 16 percent Area Under the Curve points. This indicates that our JIT models obtain a more accurate representation of the real world. We conclude that extrinsic bugs negatively impact Just-In-Time models. Furthermore we offer evidence that extrinsic bugs should be further investigated as they can significantly impact how software engineers understand bugs.;
2023 IEEE 34th International Symposium on Software Reliability Engineering Workshops (ISSREW);"Building defect prediction models based on online learning can enhance prediction accuracy. It continuously rebuilds a new prediction model when adding a new data point. However predicting a module as non-defective"" (i.e. negative prediction) can result in fewer test cases for such modules. Therefore defects can be overlooked during testing even when the module is defective. The erroneous test results are used as learning data by online learning which could negatively affect prediction accuracy. In our experiment we demonstrate this negative influence on prediction accuracy.""";
2020 IEEE International Systems Conference (SysCon);Software Engineers are battling always with defects from the earliest starting point of the software history. The defect has significant commitment and assumes an important job in the hour of freeing software. Software defect- prone might be recognized before the software announcement or after the announcement. Although the desire for designers is to give defect free software to their customers. Hence recognizing the software defect-prone before announcement makes a decent preferred position for the designers. Here the difficult assignment is to discover the defect-prone region or defective module of software. On the off chance that defective modules are distinguished before the arrival of software at that point it could be effectively counteracted and fixed by the designer. In most recent two decades scientists have concentrated on software deformity prophecy issue by applying a few statistical and machine learning systems. The software defect-prone information experiences the class-imbalance issue due to the slanted conveyance of defective and non-defective software modules. Generally machine learning calculations consider equivalent circulation of information tests in each class and expect the misclassification cost of each class is similarly significant. We have used SMOTE with ONE-R by using its MinBucketsize number n=1 2 3 4 5 & 6 for over-fit the data and resultant we got that minbucketsize n1 & 2 are highly good for base accuracy and efficiency for defect-prone datasets model. We have used datasets model in three different ways and we observed that use training datasets is very suitable for our experiments as compare to other two ways. We also observed that al evaluation measures results are highly good at use of training datasets model.;
2024 3rd International Conference on Applied Artificial Intelligence and Computing (ICAAIC);The field of software engineering has seen an increase in research aimed at predicting software defects. The importance of non-functional defects in this study can effectively predict software defects thus simplifying software testing reducing costs and improving the overall software testing process. However the presence of noise in the data set often causes software bug prediction performance to decrease. In this work a Genetic Algorithm (GA) is used to improve the accuracy of software fault prediction. It is used as a feature selection (FS) algorithm. The technology was evaluated using NASAâ€™s Metrics Data Repository dataset. The results show that the prediction performance of most products is greatly improved when the proposed method is used.;
2016 7th International Conference on Information and Communication Systems (ICICS);We target the problem of identifying the severity of a bug report. Our main aim is to develop an intelligent system that is capable of predicting the severity of a newly submitted bug report through a bug tracking system. For this purpose we build a dataset consisting of 59 features characterizing 163 instances that belong to two classes: severe and non-severe. We combine the proposed feature set with strong classification algorithms to assist in predicting the severity of bugs. Moreover the proposed algorithms are integrated within a boosting algorithm for an enhanced performance. Our results show that the proposed technique has proved successful with a classification performance accuracy of more than 76% with the AdaBoost algorithm and cross validation test. Moreover boosting has been effective in enhancing the performance of its base classifiers with improvements of up to 4.9%.;
2022 International Conference on Inventive Computation Technologies (ICICT);Software system quality can be enhanced by reducing the possible software defects in the system this can be achieved by regular monitoring of the system for any defect alerts. Identifying the defects with the features is difficult and this system is researched less in the literature. The automated tool will be useful for maintaining high quality of the system. The defects may create a huge loss to enterprises thus detecting early and accurately is mandatory for the system quality and helps in Software development life cycle (SDLC). The proposed work introduced machine learning algorithm NaÃ¯ve Bayes and deep learning algorithm Long Short Term Memory(LSTM) and Deep Neural Network (DNN). The dataset considered for the proposed study is PROMISE dataset as a binary prediction. As the software defect prediction is binary the classification model is opted for this study. Thus NB on ML model is used and DNN LSTM are compared with their accuracy. Experimental study showed that DNN algorithm outperform in accurate detection of software defects.;
32nd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO'06);Software engineering is a tedious job that includes people tight deadlines and limited budgets. Delivering what customer wants involves minimizing the defects in the programs. Hence it is important to establish quality measures early on in the project life cycle. The main objective of this research is to analyze problems in software code and propose a model that will help catching those problems earlier in the project life cycle. Our proposed model uses machine learning methods. Principal Component Analysis is used for dimensionality reduction and Decision Tree Multi Layer Perceptron and Radial Basis Functions are used for defect prediction. The experiments in this research are carried out with different software metric datasets that are obtained from real-life projects of three big software companies in Turkey. We can say that the improved method that we proposed brings out satisfactory results in terms of defect prediction.;
2022 5th International Conference on Computational Intelligence and Networks (CINE);Software defects may cause severe crashes in the system leading to the software's high maintenance costs. Early identification of these defects would lead to high-quality software thus saving time and money. This study proposes five feature selection approaches based on evolutionary computing algorithms each coupled with a majority voting ensemble for Software defect prediction. The objective is to improve the existing process by targeting the metric selection stage. The study was conducted on thirty open-source defect datasets. The proposed feature selection techniques were applied on a within-project defect prediction model and a heterogeneous defect prediction model. The Friedman and the Wilcoxon Signed-rank test concluded that the proposed techniques were promising and generated results comparable to some other state-of-the-art feature selection methodologies.;
A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches;Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article we provide a benchmark for CPDP. We replicate 24 approaches proposed by researchers between 2008 and 2015 and evaluate their performance on software products from five different data sets. Based on our benchmark we determined that an approach proposed by Camargo Cruz and Ochimizu (2009) based on data standardization performs best and is always ranked among the statistically significant best results for all metrics and data sets. Approaches proposed by Turhan et al. (2009) Menzies et al. (2011) and Watanabe et al. (2008) are also nearly always among the best results. Moreover we determined that predictions only seldom achieve a high performance of 0.75 recall precision and accuracy. Thus CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.;
2016 IEEE 35th Symposium on Reliable Distributed Systems (SRDS);The size and complexity of supercomputing clusters are rapidly increasing to cater to the needs of complex scientific applications. At the same time the feature size and operating voltage level of the internal components are decreasing. This dual trend makes these machines extremely vulnerable to soft errors or random bit flips. For complex parallel applications these soft errors can lead to silent data corruption which could lead to large inaccuracies in the final computational results. Hence it is important to determine the presence and severity of such errors early on so that proper counter measures can be taken. In this paper we introduce a tool called Sirius which can accurately identify silent data corruptions based on the simple insight that there exist spatial and temporal locality within most variables in such programs. Spatial locality means that values of the variable at nodes that are close by in a network sense are also close numerically. Similarly temporal locality means that the values change slowly and in a continuous manner with time. Sirius uses neural networks to learn such locality patterns separately for each critical variable and produces probabilistic assertions which can be embedded in the code of the parallel program to detect silent data corruptions. We have implemented this technique on parallel benchmark programs - LULESH and CoMD. Our evaluations show that Sirius can detect silent errors in the code with much higher accuracy compared to previously proposed methods. Sirius detected 98% of the silent data corruptions with a false positive rate of less than 0.02 as compared to the false positive rate 0.06 incurred by the state of the art acceleration based prediction (ABP) based technique.;
2016 IEEE Frontiers in Education Conference (FIE);Most introductory programming courses count on automated assessment systems (AAS) to support practical programming assignments and give fast feedback. AAS usually rely on tests results to check the program's functional correctness to provide feedback to students. Novice programmers however may find it difficult to map such feedback to the root failures' cause in their programs. It can be even more frustrating when the code is â€œalmost rightâ€. In this paper we investigated the use of a fault localization technique on programs produced by students of introductory programming. Our proposed approach is grounded on spectrum-based fault localization (SBFL). The results of our empirical study showed that this lightweight technique is promising. It can be easily adapted to different AAS to generate useful feedback not only to students but also to instructors. We also delineate the scope where SBFL use is jeopardized. The main contribution of this paper is to present the benefits and drawbacks of applying SBFL in the context of programming learning as a novel source of information about students' programming assignments faults.;
2011 IEEE International Conference on High Performance Computing and Communications;The fatal effect of soft errors is that the execution of software is influenced. Dynamic implementation for software-based soft error tolerance method which can protect more types of codes can cover more soft errors. Based on requirement of dynamic soft error tolerance to know dynamic software behaviors this paper proposes an approach to analyze dynamic software behaviors under the effects of soft errors on hardware. In our analyses we use a special program model which combines abstract computing on the high level with instructions on the low level. On the high level programs are divided with the granularity of function. On the low level every function is implemented by instructions. Those effects of soft errors on hardware to instructions on the low level are passed to the computing results of function on the high level. Backed by the computing results of function on the high level those instruction errors which can cause wrong program outcome are analyzed in function. Based on those instruction errors in function program reliability model is built under the effects of soft errors. From the reliability model we can know different behaviors of different software under the effects of soft errors. Finally in our fault injection experiments those experimental results demonstrate our analyses of soft errors to dynamic software behaviors.;
2014 IEEE International Conference on Software Maintenance and Evolution;Localizing bugs is important difficult and expensive especially for large software projects. To address this problem information retrieval (IR) based bug localization has increasingly been used to suggest potential buggy files given a bug report. To date researchers have proposed a number of IR techniques for bug localization and empirically evaluated them to understand their effectiveness. However virtually all of the evaluations have been limited to the projects written in object-oriented programming languages particularly Java. Therefore the effectiveness of these techniques for other widely used languages such as C is still unknown. In this paper we create a benchmark dataset consisting of more than 7500 bug reports from five popular C projects and rigorously evaluate our recently introduced IR-based bug localization tool using this dataset. Our results indicate that although the IR-relevant properties of C and Java programs are different IR-based bug localization in C software at the file level is overall as effective as in Java software. However we also find that the recent advance of using program structure information in performing bug localization gives less of a benefit for C software than for Java software.;
An Approach for the Prediction of Number of Software Faults Based on the Dynamic Selection of Learning Techniques;Determining the most appropriate learning technique(s) is vital for the accurate and effective software fault prediction (SFP). Earlier techniques used for SFP have reported varying performance for different software projects and none of them has always reported the best performance across different projects. The problem of varying performance can be solved by using an approach which partitions the fault dataset into different module subsets trains learning techniques for each subset and integrates the outcomes of all the learning techniques. This paper presents an approach that dynamically selects learning techniques to predict the number of software faults. For a given testing module the presented approach first locates its neighbor module subset that contained modules similar to testing module using a distance function and then chooses the best learning technique in the region of that module subset to make the prediction for testing module. The learning technique is selected based on its past performance in the region of module subset. We have performed an evaluation of the proposed approach using fault datasets garnered from the PROMISE data repository and Eclipse bug data repository. Experimental results showed that the proposed approach led to an improved performance when predicting the number of faults in software systems.;
Practical Combinatorial Testing: Beyond Pairwise;With new algorithms and tools developers can apply high-strength combinatorial testing to detect elusive failures that occur only when multiple components interact. In pairwise testing all possible pairs of parameter values are covered by at least one test and good tools are available to generate arrays with the value pairs. In the past few years advances in covering-array algorithms integrated with model checking or other testing approaches have made it practical to extend combinatorial testing beyond pairwise tests. The US National Institute of Standards and Technology (NIST) and the University of Texas Arlington are now distributing freely available methods and tools for constructing large t-way combination test sets (known as covering arrays) converting covering arrays into executable tests and automatically generating test oracles using model checking (http://csrc.nist.gov/acts). In this review we focus on real-world problems and empirical results from applying these methods and tools.;
2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC);The growing complexity of software systems poses significant challenges to error prevention underscoring the importance of automatically predicting errors in software modules. This enables developers to optimize their use of limited resources. Concerns about anticipating software bugs and vulnerabilities have long been prevalent among software developers and the technology industry. Traditionally identifying software errors required expertise or a deep understanding of the application's problematic modules. This research study has introduced a machine learning-based predictive model for software defect evolution designed to facilitate uninterrupted software operation. The study has also evaluated the model's efficacy using established criteria such as accuracy precision recall specificity and F1 measures. The research findings demonstrate outstanding classification performance ranging from 98% to 100% achieved using SVM across three error datasets as assessed by the F1 score. This study offers valuable insights for software researchers and practitioners equipping them with automated decision-making capabilities to select appropriate tasks for their specific applications.;
2020 IEEE 6th International Conference on Computer and Communications (ICCC);Software defects are common in software projects and threaten the security of software. Software defect prediction has been proven to be an effective method to solve software security problems assisting developers in finding potential errors and effectively allocating test resources in the early stage of the software life cycle. Traditional defect prediction models are designed based on hand-designed metric features but these features usually cannot capture the semantic and structural information of code. In order to solve this problem this paper proposes a novel software defect prediction model called CB-Path2Vec which can automatically learn features composed of Cross Block path for representing source code and use them for software defect prediction. An evaluation on the public PROMISE dataset shows that on average CB-Path2Vec improvements over the state-of-the-art method both on within-project defect prediction (WPDP) and cross-project defect prediction (CPDP).;
Proceedings 12th International Symposium on Software Reliability Engineering;We propose a criterion to determine a more appropriate software reliability growth model in the early development phase. The criterion with a discrete software reliability growth model determines the absolute worth of a model because the discrete software reliability growth model perfectly reproduces the parameter estimates when the data are used as an exact solution of the equation. The values of the proposed criterion of a discrete software reliability growth model are smaller than those of another software reliability growth model in all periods during the test phase with actual data sets. The discrete software reliability growth models are described with difference equations which have exact solutions. The models yield accurate parameter estimates in spite of a small amount of input data in an actual software testing. Therefore the criterion and discrete software reliability growth models enable us to predict in the early development phase when software can be released.;
2017 IEEE/ACM 10th International Workshop on Search-Based Software Testing (SBST);JTeXpert is a software testing tool that automatically generates a whole test suite to satisfy the branch-coverage criterion. It takes as inputs a Java source code and its dependencies and automatically produces a test-case suite in JUnit format. In this paper we summarize our results for the Unit Testing Tool Competition held at the fifth SBST Contest where JTeXpert received 849 points and was ranked second. We also analyze our tool's performance.;
2017 IEEE 28th International Symposium on Software Reliability Engineering (ISSRE);Predicting the number of defects in software modules can be more helpful in the case of limited testing resources. The highly imbalanced distribution of the target variable values (i.e. the number of defects) degrades the performance of models for predicting the number of defects. As the first effort of an in-depth study this paper explores the potential of using resampling techniques and ensemble learning techniques to learn from imbalanced defect data for predicting the number of defects. We study the use of two extended resampling strategies (i.e. SMOTE and RUS) for regression problem and an ensemble learning technique (i.e. the AdaBoost.R2 algorithm) to handle imbalanced defect data for predicting the number of defects. We refer to the extension of SMOTE and RUS for predicting the Number of Defects as SmoteND and RusND respectively. Experimental results on 6 datasets with two performance measures show that these approaches are effective in handling imbalanced defect data. To further improve the performance of these approaches we propose two novel hybrid resampling/boosting algorithms called SmoteNDBoost and RusNDBoost which introduce SmoteND and RusND into the AdaBoost.R2 algorithm respectively. Experimental results show that SmoteNDBoost and RusNDBoost both outperform their individual components (i.e. SmoteND RusND and AdaBoost.R2).;
2023 10th International Conference on Computing for Sustainable Global Development (INDIACom);Nowadays people are becoming self-employed software developers due to the growing demand for mobile apps and other forms of computerized software. However Software Engineering is a broad field since it necessitates open lines of communication among all parties involved in the system's development and the timely and cost-effective delivery of the system itself. Acquiring excellent performance by reducing the size of the system is an integral part of meeting consumer expectations. But the most expensive part of developing software is defects estimation. Metrics collected from software may provide some insight into the presence of defects. In the final stages of software testing defect estimates may be produced. Furthermore estimating defects in the early stages of the software development life cycle (SDLC) is among the critical fields of study only with the goal of cost-effectiveness and appropriate resource planning. In order to improve the efficiency of defect estimation various data mining techniques have been applied including Support Vector Machines C4.5 Bagging Naive Bayes K-Nearest Neighbors Neural Networks Random Forest Decision Trees and Radial Bias. These techniques are applied to datasets from NASA dataset repositories and evaluated using various metrics for software defects estimation (SDE). The results of our study indicated that the Support Vector Machine algorithm had the highest performance among the data mining techniques evaluated. The algorithm achieved a precision of 43.74% recall of 50.00% accuracy of 87.48% and an F-1 measure of 81.64%. It is essential to consider various evaluation metrics including recall F-measure precision and accuracy when performing software defects estimation.;
2023 5th International Congress on Human-Computer Interaction Optimization and Robotic Applications (HORA);In order to improve software dependability Software Fault Prediction (SFP) has become an important research topic in the area of software engineering. To improve program dependability program defect predictions are being utilized to aid developers in anticipating prospective issues and optimizing testing resources. As a result of this method the amount of software defects may be forecast and software testing resources are directed toward the software modules that have the greatest issues enabling the defects to be fixed as soon as possible. As a result this paper handles the issue related for SFP based on using a dataset known as JM1 provided by NASA with 21 features. In this study several Machine Learning (ML) techniques will be studied which include Logistic Regression (LR) Random Forest (RF) Naive Bias (NB) Support Vector Machine (SVM) K-Nearest Neighbor (KNN) with three distance metric Decision Tree (DT). Three cases of normalization will be involved with investigation which are the without sampling Random over Sample and the SMOTE. Performance evaluation will be based on various parameters such as the ACC Recall Precision and F1-Score. Results obtained indicate that RF achieve the higher ACC with values of 0.81% 0.92% and 0.88% respectively. The comprehensive findings of this study may be utilized as a baseline for subsequent studies allowing any claim of improved prediction using any new approach model or framework to be compared and confirmed. In future the variation of feature number will be involved with performance evaluation in handling SFP.;
2013 20th Working Conference on Reverse Engineering (WCRE);Information Retrieval (IR) based bug localization techniques use a bug reports to query a software repository to retrieve relevant source files. These techniques index the source files in the software repository and train a model which is then queried for retrieval purposes. Much of the current research is focused on improving the retrieval effectiveness of these methods. However little consideration has been given to the efficiency of such approaches for software repositories that are constantly evolving. As the software repository evolves the index creation and model learning have to be repeated to ensure accuracy of retrieval for each new bug. In doing so the query latency may be unreasonably high and also re-computing the index and the model for files that did not change is computationally redundant. We propose an incremental update framework to continuously update the index and the model using the changes made at each commit. We demonstrate that the same retrieval accuracy can be achieved but with a fraction of the time needed by current approaches. Our results are based on two basic IR modeling techniques - Vector Space Model (VSM) and Smoothed Unigram Model (SUM). The dataset we used in our validation experiments was created by tracking commit history of AspectJ and JodaTime software libraries over a span of 10 years.;
Flakify: A Black-Box Language Model-Based Predictor for Flaky Tests;Software testing assures that code changes do not adversely affect existing functionality. However a test case can be flaky i.e. passing and failing across executions even for the same version of the source code. Flaky test cases introduce overhead to software development as they can lead to unnecessary attempts to debug production or testing code. Besides rerunning test cases multiple times which is time-consuming and computationally expensive flaky test cases can be predicted using machine learning (ML) models thus reducing the wasted cost of re-running and debugging these test cases. However the state-of-the-art ML-based flaky test case predictors rely on pre-defined sets of features that are either project-specific i.e. inapplicable to other projects or require access to production code which is not always available to software test engineers. Moreover given the non-deterministic behavior of flaky test cases it can be challenging to determine a complete set of features that could potentially be associated with test flakiness. Therefore in this article we propose Flakify a black-box language model-based predictor for flaky test cases. Flakify relies exclusively on the source code of test cases thus not requiring to (a) access to production code (black-box) (b) rerun test cases (c) pre-define features. To this end we employed CodeBERT a pre-trained language model and fine-tuned it to predict flaky test cases using the source code of test cases. We evaluated Flakify on two publicly available datasets (FlakeFlagger and IDoFT) for flaky test cases and compared our technique with the FlakeFlagger approach the best state-of-the-art ML-based white-box predictor for flaky test cases using two different evaluation procedures: (1) cross-validation and (2) per-project validation i.e. prediction on new projects. Flakify achieved F1-scores of 79% and 73% on the FlakeFlagger dataset using cross-validation and per-project validation respectively. Similarly Flakify achieved F1-scores of 98% and 89% on the IDoFT dataset using the two validation procedures respectively. Further Flakify surpassed FlakeFlagger by 10 and 18 percentage points (pp) in terms of precision and recall respectively when evaluated on the FlakeFlagger dataset thus reducing the cost bound to be wasted on unnecessarily debugging test cases and production code by the same percentages (corresponding to reduction rates of 25% and 64%). Flakify also achieved significantly higher prediction results when used to predict test cases on new projects suggesting better generalizability over FlakeFlagger. Our results further show that a black-box version of FlakeFlagger is not a viable option for predicting flaky test cases.;
2008 The 9th International Conference for Young Computer Scientists;Fault injection plays a critical role in the verification of fault-tolerant mechanism software testing and dependability benchmarking for computer systems. In this paper according to the characteristics of software faults we propose a new fault injection design pattern based on the PIN framework provided by Intel company and develop a PIN-based dynamic software fault injection system (PDSFIS). Faults can be injected by PDSFIS without the source code of target applications under assessment nor does the injection process involve interruption or software traps. Experimental assessment results of an Apache Web server obtained by the dependability benchmarking are presented to demonstrate the potentials of PDSFIS.;
2022 9th International Conference on Electrical Engineering Computer Science and Informatics (EECSI);Software defect prediction enhances the quality efficiency and effectiveness of time and expenses for software testing by focusing on defect modules. Software defect prediction technology uses machine learning to predict defect modules making allocating limited resources easier quickly. Software defect prediction datasets naturally have imbalanced class problems with significantly few defective modules compared to non-defective modules. In this study software defect prediction data was classified by implementing the LSSVM algorithm with ReliefF (K=10) feature selection and applying the SMOTE method to overcome the imbalanced class problem in the dataset. The datasets used are software defect prediction datasets of the public NASA MDP Promise project namely CM1 PC1 KC1 and KC2. Dataset divided into training and testing data using Fold Cross-Validation with ten folds. The classifier achieved the highest average accuracy on the PC1 dataset which was 9387% while the highest Area Under the ROC Curve (AUC) was achieved by the classifier for the KC2 dataset which was 7835%. The results also indicate that AUC values for classifiers that use SMOTE always higher than non-SMOTE in each dataset;
2022 IEEE 7th International conference for Convergence in Technology (I2CT);In the field of Software Engineering defect prediction is the most comprehensive and active area of study. It determines which modules are prone to errors and requires rigorous testing. This allows the testing resources to be used effectively while still adhering to the limits. Our project aims to find the model which gives the best results in identifying the defects. We have used the most commonly used machine learning (ML) models K Nearest Neighbours (KNN) Support Vector Machine (SVM) Radial Bias Function (RBF) Decision Tree (DT) Naive Bayes (NB) and the least commonly used model Hidden Markov Model (HMM). The datasets are taken from the NASA and SOFTLAB repository. We have chosen six datasets from the NASA CM1 KC1 JM1 MC1 MW1 and PC1 and four from SOFTLAB AR1 AR3 AR4 and AR5. Principal Component Analysis (PCA) is used to reduce the dimensions of the dataset as there were upto 39 metrics. The best performing model is then determined based on various performance measures including accuracy precision F1 score and recall. Six out of ten datasets showed that SVM performed better than other techniques. HMM performed the best on the AR4 dataset which had the least data imbalance and the worst on the AR5 dataset which had the fewest instances.;
2019 6th International Conference on Computing for Sustainable Global Development (INDIACom);Today Software plays a very vital role in an individual life but as the demand is increasing its complexity is also increasing which makes it more prone to defects that leads to increase in software development time and cost. Predicting defects at the early stage of development will reduce the cost and also enable to deliver the software in time avoiding the loss of resources. Predicting defects in software is one of the important challenges in the software engineering field many researchers have conducted research in various fields of defect prediction such class imbalance problem cross-project prediction etc. through the use of various algorithms of machine learning. However defect prediction in cross-project has a great scope of improvement as the performance of the defect prediction model can be optimized by using existing dataset to build prediction model for new project. So this research focus on developing a new set of software metrics that can be applied on the cross-project to improve the performance of the system.;
2023 13th International Conference on Cloud Computing Data Science & Engineering (Confluence);Recently Software Bug Prediction (SBP) has become a serious issue in maintaining as well as developing the software that concerns the overall success of the software. In this case the prediction of the bug in the software in its earlier phase may enhance the efficiency quality and reliability of the software as well as reduce the cost. Moreover designing a robust software bug prediction model has become a challenging issue as well as several techniques have been recommended in the literature. Initially the data from the relevant dataset is gathered. Then the gathered data is fed to the pre-processing stage. The pre-processed data is fed to the optimal feature selection phase in which the features are optimized with the aid of the Group Counseling Optimization (GCO) algorithm. Then the Improved Long Short Term Memory (ILSTM) technique is used for prediction and the parameters in LSTM are also optimized with the same GCO algorithm. Then the bug- predicted outcomes are attained by comparing the model with other conventional techniques including Principal Component Analysis (PCA) Linear Discriminant Analysis (LDA) Kernel-based Support Vector Machine (SVM) etc.;
2024 Asia Pacific Conference on Innovation in Technology (APCIT);This paper addresses the escalating complexity of software design and the rising frequency of defects necessitating efficient defect analysis methods. Manual analysis becomes inadequate with increasing defect numbers prompting the need for automatic defect classification. The study introduces defect management concepts and stresses the importance of defect classification in enhancing software quality and testing efficiency. Recent research has explored various methods for defect classification yet the accuracy achieved often falls short of market demands. To address this gap the paper proposes a comprehensive framework for defect prediction. The framework comprises data preprocessing feature extraction via correlation-based analysis and application of machine learning models like linear regression. Results demonstrate a promising accuracy of 98.7% with the proposed method. This paper explores the increasing complexity of software design and the growing need for efficient defect analysis and classification methods. It highlights the significance of defect analysis in improving software quality and reducing maintenance costs. Existing research on defect classification is summarized emphasizing the gap between manual and automatic classification methods. In essence the paper advocates for the use of software defect classification to enhance software quality optimize testing resources and reduce the effort involved in locating defects ultimately leading to more efficient and reliable software development processes.;
A Comprehensive Investigation of the Impact of Class Overlap on Software Defect Prediction;Software Defect Prediction (SDP) is one of the most vital and cost-efficient operations to ensure the software quality. However there exists the phenomenon of class overlap in the SDP datasets (i.e. defective and non-defective modules are similar in terms of values of metrics) which hinders the performance as well as the use of SDP models. Even though efforts have been made to investigate the impact of removing overlapping technique on the performance of SDP many open issues are still challenging yet unknown. Therefore we conduct an empirical study to comprehensively investigate the impact of class overlap on SDP. Specifically we first propose an overlapping instances identification approach by analyzing the class distribution in the local neighborhood of a given instance. We then investigate the impact of class overlap and two common overlapping instance handling techniques on the performance and the interpretation of seven representative SDP models. Through an extensive case study on 230 diversity datasets we observe that: i) 70.0% of SDP datasets contain overlapping instances ii) different levels of class overlap have different impacts on the performance of SDP models iii) class overlap affects the rank of the important feature list of SDP models particularly the feature lists at the top 2 and top 3 ranks IV) Class overlap handling techniques could statistically significantly improve the performance of SDP models trained on datasets with over 12.5% overlap ratios. We suggest that future work should apply our KNN method to identify the overlap ratios of datasets before building SDP models.;
MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction;Highly imbalanced data typically make accurate predictions difficult. Unfortunately software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study we introduce MAHAKIL a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE Borderline-SMOTE ADASYN Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant pf values than the other oversampling approaches based on Brunner's statistical significance test and Cliff's effect sizes. Therefore MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.;
2022 International Conference on Decision Aid Sciences and Applications (DASA);The software development life cycle is a long and complicated process. It consists of analysis design development testing and deployment. Defect prediction is the technique of creating models that detect defective systems such as units or classes in the early stages of the process. The major goal of Software Defect Prediction is to detect defects prone in the program and thereby reduce the effort time and cost involved to the minimum. This paper gives a comprehensive review of all the techniques to approach defect prediction. The PROMISE repository which is a public software defect prediction dataset which is owned by the National Aeronautics and Space Administration (NASA) is used. More than 30 research papers in the domain of software defect prediction were analysed and reviewed. In each paper surveyed the processes involved in Software Defect prediction were captured. About 30 papers with different Machine Learning Algorithms were identified and entered into the table. The results were tabulated into columns like Dataset Used Supervised Learning Algorithm Un-supervised Learning Algorithm and Computational Intelligence. The bar graphs were generated to determine the most used Supervised Learning Algorithm Unsupervised Learning Algorithm and Dataset used for Software Defect Prediction among all the 40 papers surveyed thoroughly.;
2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C);System testing based on a black box approach is a common industrial practice in information systems. Despite its widespread use however little guidance is available for testing engineers facing the problem of selecting the best test strategy. In previous work we proposed to adopt functional models and related testing patterns according to the architectural style of the application under test. In this paper we present an industrial study that applies this technique to system testing of repository based applications. We define a set of functional models abstracting different concerns of software applications: hierarchy of functions business processes and states/transitions of application objects. The models are used to derive the functional test cases through the definition of test patterns. We applied this approach in an industrial context for over 5 years. In this paper we analyze a data set of 37 test projects including about 22000 test cases and 1500 failures. We relate failures to the originating defect types. The study confirms that a system test strategy that uses multiple functional models according to the architectural style of the software application generates a better cost/benefit ratio than the use of just one model. The explanation is that - despite a small overlap - each model detects specific types of software defects. The results of the study can guide testing engineers in selecting the best system test strategy and significantly improve the efficiency of their work.;
2024 IEEE/ACM 2nd International Workshop on Interpretability Robustness and Benchmarking in Neural Software Engineering (InteNSE);In this paper we address the following question: How can we use Large Language Models (LLMs) to improve code independently of a human while ensuring that the improved code(1)does not regress the properties of the original code ?(2)improves the original in a verifiable and measurable way ?To address this question we advocate Assured LLM-Based Software Engineering a generate-and-test approach inspired by Genetic Improvement. Assured LLMSE applies a series of semantic filters that discard code that fails to meet these twin guarantees. This overcomes the potential problem of LLMâ€™s propensity to hallucinate. It allows us to generate code using LLMs independently of any human. The human plays the role only of final code reviewer as they would do with code generated by other human engineers.This paper is an outline of the content of the keynote by Mark Harman at the International Workshop on Interpretability Robustness and Benchmarking in Neural Software Engineering Monday 15th April 2024 Lisbon Portugal.;
2016 IEEE/ACM 9th International Workshop on Search-Based Software Testing (SBST);We propose to use Search-Based Software Engineering to automatically evolve coverage criteria that are well correlated with fault revelation through the use of existing fault databases. We explain how problems of bloat and overfitting can be ameliorated in our approach and show how this new method will yield insight into faults --- as well as better guidance for Search-Based Software Testing.;
2009 International Conference on Advances in Recent Technologies in Communication and Computing;Data mining techniques are applied in building software fault prediction models for improving the software quality. Early identification of high-risk modules can assist in quality enhancement efforts to modules that are likely to have a high number of faults. Classification tree models are simple and effective as software quality prediction models and timely predictions of defects from such models can be used to achieve high software reliability. In this paper the performance of five data mining classifier algorithms named J48 CART Random Forest BFTree and NaÃ¯ve Bayesian classifier(NBC) are evaluated based on 10 fold cross validation test. Experimental results using KC2 NASA software metrics dataset demonstrates that decision trees are much useful for fault predictions and based on rules generated only some measurement attributes in the given set of the metrics play an important role in establishing final rules and for improving the software quality by giving correct predictions. Thus we can suggest that these attributes are sufficient for future classification process. To evaluate the performance of the above algorithms Mean Absolute Error (MAE) Root Mean Squared Error (RMSE) Receiver Operating Characteristic (ROC) and Accuracy measures are applied.;
2024 International Conference on Information Technology Research and Innovation (ICITRI);In software engineering accurately predicting software defects is critical for maintaining software quality and reducing development costs. This research aims to improve the performance of software defect prediction models by employing forward selection with linear regression on imbalanced datasets. We utilized 12 datasets from the NASA Metrics Data Program (MDP) repository to comprehensively evaluate the impact of feature selection on prediction accuracy and the Area Under the Curve (AUC). The results showed that the model with feature selection has a higher average accuracy (91.11%) than without (78.67%). Additionally the AUC increased from an average of 75.33% to 81.12% following feature selection. The paired t-test indicates that this difference is statistically significant $(t(11)=-3.2017 p\lt0.05)$. These findings emphasize the importance of feature selection in improving model performance. The improvement in accuracy and AUC highlights the effectiveness of forward selection in enhancing the predictive performance of linear regression models especially when dealing with imbalanced data. These insights provide valuable guidance for software quality assurance practices suggesting that integrating forward selection with linear regression can lead to more reliable defect prediction outcomes.;
2015 IEEE/ACM 37th IEEE International Conference on Software Engineering;We propose a new automated debugging method for regression testing based on a synergistic application of both dynamic and semantic analysis. Our method takes a failure- inducing test input a buggy program and an earlier correct version of the same program and computes a minimal set of code changes responsible for the failure as well as explaining how the code changes lead to the failure. Although this problem has been the subject of intensive research in recent years existing methods are rarely adopted by developers in practice since they do not produce sufficiently accurate fault explanations for real applications. Our new method is significantly faster and more accurate than existing methods for explaining failed regression tests in real applications due to its synergistic analysis framework that iteratively applies both dynamic analysis and a constraint solver based semantic analysis to leverage their complementary strengths. We have implemented our new method in a software tool based on the LLVMcompiler and the KLEE symbolic virtual machine. Our experiments on large real Linux applications show that the new method is both efficient and effective in practice.;
2018 International Workshop on Big Data and Information Security (IWBIS);Predicting defect in software is a complicated process and time-consuming. AI-Based software defect predictor can predict 75% defect in software and help developer team to detect and to fix defect module before performing unit testing/system testing by quality assurance. Some research tried to construct prediction model using other project datasets which is called cross-project defect prediction. Nevertheless the project should have the same software metric attribute. Recently web application takes a crucial part in human life for that reason assuring the quality of web application is very serious. This research will implement defect prediction on the petstore web application with other project datasets. CK OO metric is employed as the parameter. Naive bayes algorithm is an effortless and successful algorithm for predicting defect on software. The objective of this research is to apply naive bayes algorithm in cross-project defect prediction for the web application using pandas and scikit-learn. The outcome of this research is naive bayes algorithm has an good accuracy level of 72.30% â€“ 89.30% and slightly low false alarm around by 5% â€“ 26.67%. However it has low precision and recall score around 125% â€“ 25% and 20%â€“60%. Then naive bayes algorithm predicting more defect module on software than code review.;
2023 15th International Congress on Advanced Applied Informatics Winter (IIAI-AAI-Winter);Rapid progress in the field of artificial intelligence has created opportunities for extensive applications in software development. One area that receives attention is the evaluation of code quality using machine learning techniques. In this investigation we examined the possible application of machine learning to predict the likelihood of defects in computer code. We employ NASA archival data as case studies. Machine learning models employ neural network algorithms. Our exploration involves partitioning the dataset into training data and test data for performance evaluation. The findings indicate that the Neural Organize technique with resampling yields a high level of accuracy in predicting software defects. Our simulated neural network is capable of identifying intricate patterns in the data and providing precise measurements of the size and intensity of defects. These results have significant implications in the software business enabling developers to promptly identify possible vulnerabilities and take preventive measures before product release.;
2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR);Android apps must be able to deal with both stop events which require immediately stopping the execution of the app without losing state information and start events which require resuming the execution of the app at the same point it was stopped. Support to these kinds of events must be explicitly implemented by developers who unfortunately often fail to implement the proper logic for saving and restoring the state of an app. As a consequence apps can lose data when moved to background and then back to foreground (e.g. to answer a call) or when the screen is simply rotated. These faults can be the cause of annoying usability issues and unexpected crashes. This paper presents a public benchmark of 110 data loss faults in Android apps that we systematically collected to facilitate research and experimentation with these problems. The benchmark is available on GitLab and includes the faulty apps the fixed apps (when available) the test cases to automatically reproduce the problems and additional information that may help researchers in their tasks.;
Proceedings 17th IEEE International Conference on Automated Software Engineering;In this paper we describe a technique for generating expected results for automated black-box testing. Generating expected results allows larger automated test suites to be created moving us toward continuous product testing. Our technique uses a program's Input-Output (IO) relationships to identify unique combinations of program inputs that influence program outputs. With this information a small set of test cases is executed and checked for correctness. Given the correctness of this set the expected results for the larger combinatorial test set can be generated automatically. Included in the paper is an experimental study in which checking the results of 384 test cases allows us to generate expected results and fully automate nearly 600000 test cases.;
2018 IEEE 25th International Conference on Software Analysis Evolution and Reengineering (SANER);In crowdsourced mobile application testing crowd workers help developers perform testing and submit test reports for unexpected behaviors. These submitted test reports usually provide critical information for developers to understand and reproduce the bugs. However due to the poor performance of workers and the inconvenience of editing on mobile devices the quality of test reports may vary sharply. At times developers have to spend a significant portion of their available resources to handle the low-quality test reports thus heavily decreasing their efficiency. In this paper to help developers predict whether a test report should be selected for inspection within limited resources we propose a new framework named TERQAF to automatically model the quality of test reports. TERQAF defines a series of quantifiable indicators to measure the desirable properties of test reports and aggregates the numerical values of all indicators to determine the quality of test reports by using step transformation functions. Experiments conducted over five crowdsourced test report datasets of mobile applications show that TERQAF can correctly predict the quality of test reports with accuracy of up to 88.06% and outperform baselines by up to 23.06%. Meanwhile the experimental results also demonstrate that the four categories of measurable indicators have positive impacts on TERQAF in evaluating the quality of test reports.;
2009 2nd IEEE International Conference on Computer Science and Information Technology;In this paper we present our approach of using non redundant test cases with program spectra (one of the automated bug localization techniques) to locate software bugs in a program. We evaluate several spectra metrics (functions mapped from program spectra) using the non redundant test cases. Extensive evaluation on Siemens Test Suite and subset of Unix datasets shows the effectiveness of locating bug using non redundant test cases with program spectra. In this paper we also show that by adding duplicates of non redundant test cases the stability and performance of spectra metrics are affected.;
2015 IEEE International Transportation Electrification Conference (ITEC);"The Current Methodologies of virtual and Automated Testing on touch screen displays are limited since minor screen changes and display software updates will cause the automated tests to fail and hence there will be a need to fix them. Addition of new items to a drop-down list movement of buttons reusability and conversion of Test scripts for similar devices will be a cumbersome job. The general approach of testing Display manually is not feasible due to sluggishness monotony and repetitiveness of work which can cause manual errors in different volumes at different times it will also reduce the option of Batch executions of tests 24âˆ—7. The automated approach for testing such Displays through XY coordinates pointing on screen taking Screen captures and using optical character recognition for verification methods are non-reliable and affects the performance of testing. This makes automating a test difficult causes a high amount of risk as well as high maintenance costs. This paper offers recent ideas and its implementation of software testing on touch screen Displays which are widely used in sophisticated passenger cars as well as in off-highway equipment like tractors construction and Forestry etc. In this method of testing the Display's User interface we use â€˜Test Eventsâ€™ which are linked with different objects/Icons on displays. Every user action like selecting menu item from dropdown pressing button swiping turning pages are considered as unique actions and these actions are then bundled with unique Object Id data to create the events on the Display. These user events are simulated automatically and the response is monitored and logged for identifying and analyzing Software defects. The architecture is based on Data Driven Model"" where test data is separated from script in order to take care of any changes in quick and agile way. The Data such as unique references to objects and Pools on the screen are placed in SQL Database this enables to access data from different locations by multiple users. Though the approach can be widely applied to majority of Touch screen applications we restrict the scope of this paper to automotive domain due to the Standards and protocol used during implementation.""";
2014 International Conference on Information Systems and Computer Networks (ISCON);Considering the current scenario the crucial need for software developer is the generous enhancement in the quality of the software product we deliver to the end user. Lifecycle models development methodologies and tools have been extensively used for the same but the prime concern remains is the software defects that hinders our desire for good quality software. A lot of research work has been done on defect reduction defect identification and defect prediction to solve this problem. This research work focus on defect prediction a fairly new filed to work on. Artificial intelligence and data mining are the most popular methods researchers have been using recently. This research aims to use the Twin Support Vector Machine (TSVM) for predicting the number of defects in a new version of software product. This model gives a nearly perfect efficiency which compared to other models is far better. Twin Support Vector Machine based software defects prediction model using Gaussian kernel function obtains better performance as compare to earlier proposed approaches of software defect prediction. By predicting the defects in the new version we thereby attempt to take a step to solve the problem of maintaining the high software quality. This proposed model directly shows its impact on the testing phase of the software product by simply plummeting the overall cost and efforts put in.;
2022 International Conference on Knowledge Engineering and Communication Systems (ICKES);The research of terminal software defect detection method based on association rules is a research topic in the field of computer science. The main purpose of this study is to find out how much accuracy can be achieved using this type of method. This question has been studied for many years and there is no clear answer so far. Terminal software defect detection methods have been developed since the beginning of computerization. In order to detect defects in a program before it is released it is necessary to develop effective methods to help us determine whether there are errors in a given code. The main idea is to use information about how often certain events occur together and predict that they will occur again. Association rules are used for this purpose. A rule is a mathematical statement that describes a relationship between two variables (in our case different parts of a program). When a variable changes its value it may trigger another variable to change In other words each event involves some causes and effects.;
2016 International Conference on Machine Learning and Cybernetics (ICMLC);Software fault prediction (SFP) is useful for helping the software engineer to locate potential faulty modules in software testing more easily so that it can save a lot of time and budgets to improve the software quality. In this paper aiming at solving the problem that the faulty samples are too rare to train a classifier an one-class SFP model is proposed by using only non-faulty samples based on one-class SVM. The empirical validation is conducted on 6 extremely imbalanced datasets collected from real-world software containing only small amounts of faulty instances. The test results suggest that the proposed model can achieve a reasonable fault prediction performance when using only a small proportion of training samples and performs much better than conventional and class imbalanced learning based SFP models in terms of G-mean measure. Thus the proposed model provided a considerable solution for SFP with a few faulty modules in early life of software testing.;
2018 8th International Conference on Cloud Computing Data Science & Engineering (Confluence);It is a challenging task to accurately assign bug reports to an expert developer in both Open source project (OSP) as well as closed source projects (CSP). Objective of any triaging techniques is to reduce tossing length thereby minimizing bug fixing time. Developing such an efficient triaging technique is even more challenging for CSP due to limited accessibility of bug reports. As a result most of the existing triaging techniques have been trained and tested using bugs from OSP leaving CSP untapped to a larger extent. In this paper we have built a metric based score for identifying and ranking an expert developer independent of the nature of the project. We have proposed two metrics based on information theory i.e. developer specialization and bug importance score. Developer specialization score and Importance score are computed using information gain on bug component and bug importance fields. In order to validate our proposed approach we choose bug reports from a closed source project developed by company XYZ pvt. Ltd. India (the real name of the company is not disclosed due to confidentiality reason). Our proposed triaging approach has achieved good prediction results up to 88.9% on the chosen closed source project dataset.;
2020 11th International Conference on Computing Communication and Networking Technologies (ICCCNT);In the Software Engineering concept the prediction of the software defects plays a vital role in increasing the quality of the software systems which is one of the most critical and expensive phases of the software development lifecycle. While the use of software systems is increasing in our daily lives their dependencies and complexities are also increasing and this results in a suitable environment for defects. Due to the existence of software defects the software produces incorrect results and behaviors. What is more critical than defects is finding them before they occur. Therefore detection (and also prediction) of the software defects enables the managers of the software to make an efficient allocation of the resources for the maintenance and testing phases. In the literature there are different proposals for the prediction of software defects. In this paper we made a comparative analysis about the machine learning-based software defect prediction systems by comparing 10 learning algorithms like Decision Tree Naive Bayes K-Nearest Neighbor Support Vector Machine Random Forest Extra Trees Adaboost Gradient Boosting Bagging and Multi-Layer Perceptron on the public datasets CM1 KC1 KC2 JM1 and PC1 from the PROMISE warehouse. The experimental results showed that proposed models result in proper accuracy levels for software defect prediction to increase the quality of the software.;
T-Evos: A Large-Scale Longitudinal Study on CI Test Execution and Failure;Continuous integration is widely adopted in software projects to reduce the time it takes to deliver the changes to the market. To ensure software quality developers also run regression test cases in a continuous fashion. The CI practice generates commit-by-commit software evolution data that provides great opportunities for future testing research. However such data is often unavailable due to space limitation (e.g. developers only keep the data for a certain period) and the significant effort involved in re-running the test cases on a per-commit basis. In this paper we present T-Evos a dataset on test result and coverage evolution covering 8093 commits across 12 open-source Java projects. Our dataset includes the evolution of statement-level code coverage for every test case (either passed and failed) test result all the builds information code changes and the corresponding bug reports. We conduct an initial analysis to demonstrate the overall dataset. In addition we conduct an empirical study using T-Evos to study the characteristics of test failures in CI settings. We find that test failures are frequent and while most failures are resolved within a day some failures require several weeks to resolve. We highlight the relationship between code changes and test failure and provide insights for future automated testing research. Our dataset may be used for future testing research and benchmarking in CI. Our findings provide an important first step in understanding code coverage evolution and test failures in a continuous environment.;
2006 39th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO'06);Dynamic software bug detection tools are commonly used because they leverage run-time information. However they suffer from a fundamental limitation the path coverage problem: they detect bugs only in taken paths but not in non-taken paths. In other words they require bugs to be exposed in the monitored execution. This paper makes one of the first attempts to address this fundamental problem with a simple hardware extension. First we propose PathExpander a novel design that dynamically increases the code path coverage of dynamic bug detection tools with no programmer involvement. As a program executes PathExpander selectively executes non-taken paths in a sandbox without side effects. This enables dynamic bug detection tools to find bugs that are present in these non-taken paths and would otherwise not be detected. Second we propose a simple hardware extension to control the huge overhead in its pure software implementation to a moderate level. To further minimize overhead PathExpander provides an optimization option to execute non-taken paths on idle cores in chip multi-processor architectures that support speculative execution. To evaluate PathExpander we use three dynamic bug detection methods: dynamic software-only checker (CCured) dynamic hardware-assisted checker (iWatcher) and assertions and conduct side-by-side comparison with PathExpander's counterpart software implementation. Our experiments with seven buggy programs using general inputs that do not expose the tested bugs show that PathExpander is able to help these tools detect 21 (out of 38) tested bugs that are otherwise missed. This is because PathExpander increases the code coverage of each test case from 40% to 65% on average based on the branch coverage metric. When applications are tested with multiple inputs the cumulative coverage also significantly improves by 19%. We also show that PathExpander introduces modest false positives (4 on average) and overhead (less than 9.9%). The 3-4 orders of magnitude lower overhead compared with pure-software implementation further justifies the hardware design in PathExpander;
2017 43rd Euromicro Conference on Software Engineering and Advanced Applications (SEAA);"Context: Software Bug Severity Classification can help to improve the software bug triaging process. However severity levels present a high-level of data imbalance that needs to be taken into account. Aim: We investigate cost-sensitive strategies in multi-class bug severity classification to counteract data imbalance. Method: We transform datasets from three severity classification papers to a common format totaling 17 projects. We test different cost sensitive strategies to penalize majority classes. We adopt a Support Vector Machine (SVM) classifier that we also compare to a baseline majority class"" classifier. Results: A model weighting classes based on the inverse of instance frequencies yields a statistically significant improvement (low effect size) over the standard unweighted SVM model in the assembled dataset. Conclusions: Data imbalance should be taken more into consideration in future severity classification research papers.""";
2023 International Conference on Network Multimedia and Information Technology (NMITCON);The Software testing is critical for ensuring the quality of software but it can consume more than half of a software project's total expenses. This research can help software development teams identify potential bugs early on leading to efficient and effective software creation. To improve the efficiency of software testing this report presents research on software defect prediction using a hybrid machine learning algorithm that combines supervised and unsupervised learning techniques. The study used publicly available datasets to train and evaluate various machine learning models including an ensemble learning model. A comparative analysis was conducted among KNN Random Forest Adaboost Multilayer Perceptron CNN and Gaussian NaÃ¯ve Bayes on different datasets. Feature selection was performed using various methods including Recurrent Feature Elimination (RFE) SelectKBest and Correlation implemented by a tool created to select any feature selection algorithm and compare the results for various combinations with the above mentioned classifiers. The results achieved by the model are showed in detail for each of the algorithms on the selected datasets. The main objectives of the research are to create a tool to apply various machine learning techniques to the datasets and determine the most effective ones as well as to explore different feature selection methods for improving the accuracy of defect prediction.;
2021 IEEE International Conference on Software Maintenance and Evolution (ICSME);Spectrum-Based Fault Localisation (SBFL) is a well-known technique to find faulty statements in a program. To date various techniques aiming to improve SBFL from different aspects have been proposed following their own theories and assumptions. Therefore it is challenging to make a fair assessment of their rationale and practicability. In this paper we propose the SPectra Illustration for Comprehensive Analysis (SPICA) a methodology for reviewing and analysing existing SBFL works using spectrum visualisation. Specifically taking as input a specific SBFL technique (e.g. a suspiciousness metric) SPICA illustrates the relevant artefacts within the spectrum space and then analyse the visualised spectra distribution following the steps of 1) examining the Geometric Characteristics (GCs) and 2) knowledge mining. In this way we can do overall reviews for various SBFL techniques and get analysis results. As examples we use SPICA to analyse five representative SBFL techniques which provide fundamental theories or experimental results. Finally we provide an overall assessment of the rationale for each technique attached with suggestions that could be useful for future validation and extension.;
Mapping Bug Reports to Relevant Files: A Ranking Model a Fine-Grained Benchmark and Feature Evaluation;When a new bug report is received developers usually need to reproduce the bug and perform code reviews to find the cause a process that can be tedious and time consuming. A tool for ranking all the source files with respect to how likely they are to contain the cause of the bug would enable developers to narrow down their search and improve productivity. This paper introduces an adaptive ranking approach that leverages project knowledge through functional decomposition of source code API descriptions of library components the bug-fixing history the code change history and the file dependency graph. Given a bug report the ranking score of each source file is computed as a weighted combination of an array of features where the weights are trained automatically on previously solved bug reports using a learning-to-rank technique. We evaluate the ranking system on six large scale open source Java projects using the before-fix version of the project for every bug report. The experimental results show that the learning-to-rank approach outperforms three recent state-of-the-art methods. In particular our method makes correct recommendations within the top 10 ranked source files for over 70 percent of the bug reports in the Eclipse Platform and Tomcat projects.;
2019 International Conference on Intelligent Sustainable Systems (ICISS);Software Defect (SD) prediction motivates as basic position in upgrading software program and also it helps for software testing in reducing time as well as value of it. Defect prediction in software program is distinct as an enormously vital capacity when arranging a software task and considerably more endeavour is needed to comprehend this complicated problem utilizing a software measurements and defect dataset. Measurements are the association among the numerical and categorical attribute value and it applied at the software consequently its miles utilized for predicting defect. In this paper we discussed about a study on new classification algorithm as know as Mixed Mode Database Miner (MMDBM) utilizing NASA MDP datasets. Finally the proposed algorithm MMDBM classifier progress to less processing time and high level of accuracy rate.;
2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW);JointCloud provides a large-scale flexible and elastic computing resource platform. Big data systems such as MapReduce and Spark are widely deployed on this platform for big data processing. How to choose a cloud platform in accordance with the need of customers is a problem. Current performance benchmarking suites can choose suitable cloud platforms for customers. However they do not consider the reliability of applications running atop big data systems. These systems have high scalability but the applications running atop them often generate runtime errors such as out of memory errors I/O exceptions and task timeouts. For users they want to know whether the developed applications have potential application faults. For system designers and manag-ers they want to know whether the deployed/updated systems have potential system faults. In addition current benchmarks for big data system are also only designed for performance testing. To fill this gap we propose a reliability benchmark which contains representative applications an abnormal data generator and a configuration combination generator. Differ-ent from performance benchmarks this benchmark (1) gener-ates abnormal test data according to the application character-istics and (2) reduces the configuration combination space based on configuration features. Currently we implemented this benchmark on Spark system. In our preliminary test we found three types of errors (i.e. out of memory errors timeout and wrong results) in five SQL Machine Learning and Graph applications.;
2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW);Bug fixing is a major activity in software development and maintenance. Developers use information reported in bug reports to identify bug causes and to provide a fix. Previous studies have shown that bug report fields are often reassigned to different development teams after the report is sent to developers. This can introduce considerable time delays in the bug handling process. To overcome this issue there exist numerous methods to automatically predict bug report fields by examining historical data. In this paper we combine a neural network based model with stack traces to predict bug report fields. When applied to bug reports of the Eclipse repository we found that our approach achieves improvement of about 73% in product prediction accuracy and 85% in component prediction accuracy over the well-known K-nearest neighbors (KNN) algorithm. The results of this preliminary study suggest that neural networks provide a robust alternative to traditional classification techniques.;
2014 IEEE Seventh International Conference on Software Testing Verification and Validation;Companies increasingly use either manual or automated system testing to ensure the quality of their software products. As a system evolves and is extended with new features the test suite also typically grows as new test cases are added. To ensure software quality throughout this process the test suite is continously executed often on a daily basis. It seems likely that newly added tests would be more likely to fail than older tests but this has not been investigated in any detail on large-scale industrial software systems. Also it is not clear which methods should be used to conduct such an analysis. This paper proposes three main concepts that can be used to investigate aging effects in the use and failure behaviour of system test cases: test case activation curves test case hazard curves and test case half-life. To evaluate these concepts and the type of analysis they enable we apply them on an industrial software system containing more than one million lines of code. The data sets comes from a total of 1620 system test cases executed a total of more than half a million times over a time period of two and a half years. For the investigated system we find that system test cases stay active as they age but really do grow old they go through an infant mortality phase with higher failure rates which then decline over time. The test case half-life is between 5 to 12 months for the two studied data sets.;
2017 Pattern Recognition Association of South Africa and Robotics and Mechatronics (PRASA-RobMech);Automated software testing allows testers and managers for generating the quality of test data during each phase of software development. Path coverage based testing is the most effective technique in structural testing. The major challenge in path coverage based testing is to generate the test data to cover complete path from beginning till end. Therefore we require a novel automated test data generation method for the same. Various soft computing techniques are being used to generate the path coverage tests for search-based software testing. In this paper we have focused on resolving the multi-objective optimization of coverage based test data by proposing Multi-Objective Ant Lion Optimization (MOALO) algorithm. Further we have discussed that how the proposed algorithm enhance the path coverage with reduced number of tests. To validate the proposed algorithm we have compared the obtained experimental results with random resting and conventional genetic algorithm's data. These results shows that proposed algorithm outperforms the existing algorithms.;
2012 International Conference on Systems and Informatics (ICSAI2012);Software vulnerabilities become methods by which an attacker can take control of the victim's system and those critical bugs cluster in dangerous spot codes. However fuzz testing provides low code coverage and serious security bugs may be missed potentially while symbolic execution based testing encounters path explosion and bug trigger problem. To deal with the security issue above we highlight two kinds of dangerous spot codes which mostly likely to trigger buffer overflows at runtime: dangerous functions and instructions. We define the conditions on which dangerous spot code can trigger a bug: input-dependent operand feasible execution path and trigger conditions. Then we give algorithm for trigger point directed search in order to find the shortest feasible path in CFG and formalize the trigger conditions for integer overflow string buffer overflow array out of bound and division by zero bugs. At last we evaluate the implementation in four benchmark programs in Ubuntu Linux showing that our method improves the coverage rate of trigger point and trigger rate of overflows efficiently.;
2023 3rd International Conference on New Energy and Power Engineering (ICNEPE);Current methods for detecting partial discharge sound sources in transformers are not very accurate and are susceptible to interference from environmental factors and calculation algorithms. Therefore this study proposes a deep learning method of convolutional neural network to locate partial discharge in transformers. The generalized cross-correlation positioning algorithm is utilized along with a deep learning framework to compute the cross-correlation delay between audio signals. This enables the identification of the source location for partial discharge sounds. Through the audio data set collected by the simulated microphone array of the partial discharge signal the partial discharge positioning calculation model was trained and finally the trained calculation model was used for positioning testing which verified the accuracy of the partial discharge sound source positioning algorithm. Experimental results show that the network used not only completes the localization of partial discharge sound sources but also improves the accuracy of sound source localization.;
2021 8th International Conference on Dependable Systems and Their Applications (DSA);The paper reviews three classifications of big data-based software testing in the last 10 years. Testing for big data system big data evaluation benchmarks and the application of big data technology to software testing are studied in the paper. This research helps readers understand the development and classification of big data-based software testing.;
2020 17th International Bhurban Conference on Applied Sciences and Technology (IBCAST);Software Fault Prediction (SFP) techniques are commonly used to determine the fault proneness of software modules to complement the development and testing process. In SFP fault prediction is based on software metrics that reflect any aspect of the software where coupling is one of them. Software coupling is one such metric which is a measure of the interdependency of software modules. Coupling induces complexity in the coupled module and makes it difficult to comprehend. Eventually more coupled modules are likely to be faultier. This spurs a need to evaluate the impact of coupling exclusively on fault proneness. Since coupling by inheritance is harmless as it promotes reusability so coupling through inheritance is not considered. We evaluated seven coupling metrics on 87 different publicly available datasets. After pre-processing selected datasets are split with all possible coupling metrics. Resulting 474 split datasets are used for the experiments. These datasets have only coupling metrics and nominal-binary class labels. Model building and validation are done for Support Vector Machine. Results of entropy-loss shows that coupling metrics are good predictors of faults in software. Furthermore {Coupling Between Objects Design Complexity Fan-in;
2018 25th Asia-Pacific Software Engineering Conference (APSEC);Recently computer systems have become increasingly complex involving a wide range of infrastructure and software technologies in the same system. Because these complex technologies affect each other it is difficult to identify the causes of system faults while the system is running. Faults caused by a mix of software and infrastructure issues are particularly difficult for software engineers to resolve. We therefore propose a framework for identifying the causes of system faults that targets both software and infrastructure problems. The aim of this research is to identify faults that are related to software and/or infrastructure. The framework is based on system logs including both software and infrastructure logs. When a fault occurs while a system is running software and infrastructure logs are first collected and then compared with a large dataset of past logs to rapidly identify the cause of the fault. After that debug mode level logs are collected in order to identify proper bugs of source code level and/or setting values of infrastructure configuration file level. The framework is also applied to two examples of real system faults. We find that the first fault was caused by software bugs but the second was caused by both software bugs and infrastructure problems. We have also implemented a tracing and replay tool based on the framework. We tried to detect the true causes of 17 system faults that were randomly picked up past log dataset. 96% system logs in the 17 faults occurrence operation patterns were detected the differences between fault and normal cases. Then the two concrete session error faults occurred by two causes infrastructure problems and software bugs. In this way the framework will help software engineers to identify the causes of faults even when they find it difficult to separate software and infrastructure issues.;
2015 IEEE 39th Annual Computer Software and Applications Conference;Coverage-based fault localization techniques leverage coverage information to identify the suspicious program entities for inspection. However coincidental correctness (CC) widely occurs during software debugging and brings negative impact to the effectiveness of CBFL techniques. In this paper we propose a regression approach to identity CC execution with weighted clustering analysis. Based on the observation that program entities with different suspiciousness have different contributions to identify coincidental correctness we make use of the suspiciousness calculated by CBFL techniques as the weight of each program entity and conduct weighted clustering to identify coincidental correctness regressively. To evaluate the effectiveness of our approach we construct controlled experiments built on benchmark programs and the experimental results show that our approach is able to improve the accuracy of the identification of coincidental correctness executions and further improve the effectiveness of CBFL techniques.;
2023 International Seminar on Application for Technology of Information and Communication (iSemantic);In recent years the use of Artificial Intelligence (AI) has become increasingly common in various fields including in software development. One such field is where AI can automatically detect and fix bugs in code. GPT-3.5 is a state-of-the-art language model developed by OpenAI that has been trained on a massive amount of text data to generate natural language responses to a wide range of prompts. One of the main challenges in software development is bug fixing which can be a time-consuming and complicated process. QuixBugs is a framework for evaluating automatic program repair techniques which can be used to test the effectiveness of GPT-3.5 and similar bug-fixing tools. This paper evaluates the effectiveness of GPT-3.5 in automatically fixing bugs in Python code using QuixBugs. Through testing with 40 different Python bugs We discovered that GPT-3.5 was able to accurately fix 30 out of 40 bugs cases from QuixBugs benchmark. Compared with other tools like standard program repair and Codex ChatGPT outperformed them significantly. These findings highlight the potential of ChatGPT as a powerful tool for enhancing code quality and reducing the burden of manual bug fixing.;
2021 9th International Conference in Software Engineering Research and Innovation (CONISOFT);Software fault prediction makes software quality assurance process more efficient and economic. Most of the works related to software fault prediction have mainly focused on classifying software modules as faulty or not which does not produce sufficient information for developers and testers. In this paper we explore a novel approach using a streamlined process linking Stream X-Machine and machine learning techniques to predict if software modules are prone to having a particular type of runtime error in Java programs. In particular Stream X-Machine is used to model and generate test cases for different types of Java runtime errors which will be employed to extract error-type data from the source codes. This data is subsequently added to the collected software metrics to form new training data sets. We then explore the capabilities of three machine learning techniques (Support Vector Machine Decision Tree and Multi-layer Perceptron) for error-type proneness prediction. The experimental results showed that the new data sets could significantly improve the performances of machine learning models in terms of predicting error-type proneness.;
2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR);Already from the early days of testing practitioners distinguish between unit tests and integration tests as a strategy to locate defects. Unfortunately the mining software engineering community rarely distinguishes between these two strategies mainly because it is not straightforward to separate them in the code repositories under study. In this paper we exploited the TravisTorrent dataset provided for the MSR 2017 mining challenge separated unit tests from integration tests and correlated these against the workflow as recorded in the corresponding issue reports. Further analysis confirmed that it is worthwhile to treat unit tests and integration tests differently: we discovered that unit tests cause more breaking builds that fixing the defects exposed by unit tests takes longer and implies more coordination between team members.;
2019 5th International Conference on Web Research (ICWR);Considering the importance of software systems in human life their quality assurance is very important. Fault localization is one of the software testing steps it tries to find the exact location of fault in code. Most of automatic fault localization techniques use coverage information and results of test cases to calculate the program entities suspiciousness by similarity coefficients. The similarity coefficients designed based on the insight and understanding of developers from software system and they do not have the same performance in different scenarios. To overcome with this problem we use the Back Propagation neural network and investigate the effect of weighted the neural network to accuracy of locating faults in software programs because the Back propagation neural network is sensitive to weight and by the initial proper weights to the input layer neurons connections the search space to achieve optimal weight is decreasing and network accuracy improves. We analyze the effectiveness of the proposed method with randomly weighting the input layer neurons and some basic and efficient similarity coefficients on Siemens suite benchmark. The results show that proposed method has a satisfactory performance for the software fault localization process.;
12th Asia-Pacific Software Engineering Conference (APSEC'05);In modern societies software is everywhere and we need software to be reliable. In practice during software development processes software reliability assessment can greatly help managers to understand effectiveness of consumed testing-effort and deploy testing-resource. In the 1970s-2000 many software reliability growth models (SRGMs) have been proposed for estimation of reliability growth of software products. In this paper the concept of multiple change-points is incorporated into Weibull-type testing-effort dependent SRGM because the consumption phenomenon of testing resource may vary at some moments. The performance and application of proposed models are demonstrated through one real data set. The experimental results show that the models give an excellence performance on failure prediction. Besides we also discuss the optimal release time problems based on reliability requirement and cost criteria.;
2021 IEEE 21st International Conference on Software Quality Reliability and Security Companion (QRS-C);Effort-Aware Software Defect Prediction (EADP) ranks software modules according to the defect density of software modules which allows testers to find more defects while reviewing a certain amount of code and allocates testing resources more effectively. However the recently proposed CBS+ and EASC methods tend to rank the software modules with more LOC (Lines of Code) first. Therefore there are less inspected modules when inspecting the top 20% LOC via CBS+ and EASC. Although the two methods achieve the high Precision@20% value the Recall@20% and PofB@20% (Proportion of the found Bugs when inspecting the top 20% LOC) values of the two methods are low. Therefore we propose a method called EALTR to construct the EADP model by directly maximizing the found bugs when inspecting the top 20% LOC. EALTR uses the linear model to build the EADP model and then employs the composite differential evolution algorithm to generate a set of coefficient vectors for the linear model. Finally EALTR selects the coefficient vector that achieves the highest PofB@20% value on the training dataset to construct the EADP model. Our experimental results on eleven project datasets with 41 releases show that the EALTR method performs better than CBS+ and EASC in terms of Recall@20% and PofB@20%.;
2024 IEEE International Conference on Software Testing Verification and Validation Workshops (ICSTW);In a large-scale Continuous Integration (CI) environment regression testing can encounter high time and resource demands in ad hoc execution. Therefore Test Case Prioritization (TCP) is crucial for enhancing the regression testing efficiency of CI. TCP methods aim to optimize regression testing by ordering test cases to effectively cover new code changes and their potential side effects and to maximize early fault detection. Traditional prioritization processes use diverse data sources including code coverage analysis test execution history and domain-specific features. Heuristic-based or code-coverage-driven prioritization techniques may not be sufficient for accurate results in a rapidly changing environment. For this reason there has been a significant shift towards employing Machine Learning (ML) techniques in TCP in recent years to harness the vast and complex datasets generated by CI practices. ML-based TCP approaches integrate multifaceted test case features from various sources to enhance the accuracy of test case prioritization. This trend reflects a broader movement towards data-driven decisionmaking in software testing offering the potential to significantly reduce the regression testing burden by tailoring test suites more effectively to the needs of each software build thereby saving time and resources while maintaining or improving the software quality. Recent studies have shown that the ML-based methods used in TCP can be categorized into four groups: Supervised Learning Unsupervised Learning Reinforcement Learning and Natural Language Processing. Codebases for software projects can be changed rapidly by introducing new feature distributions into the CI systems. We analyzed a Java applicationâ€™s CI and version control system (VCS) history data received from the International Business Machines Corporation (IBM) [1] [6] [7]. The frequent inclusion of new test suites introduced new patterns into the dataset properties. To keep up with these changes ML models require frequent re-training on old and new datasets to maintain high accuracy on new data. The volume of the dataset tends to increase with time as more data becomes available. Frequent re-training of ML models on the entire dataset is computationally costly and requires extensive storage. Reinforcement Learning focuses on finding the best solution through reward maximization [2] and restricts the learning goal. Learning incrementally from new non-stationary data without requiring an old dataset to solve this TCP problem. Continual Learning (CL) or life-long learning/ incremental learning adapts to changes without needing old training samples. While CL has recently been studied in several works for different domains we could not find effective research on implementing CL in the TCP domain. Given the dynamic environment of software testing we apply CL in industrial test case prioritization is critical for maintaining the efficiency and effectiveness of software testing processes in dynamic environments. However modifying ML models on new datasets may introduce other problems such as catastrophic forgetting. This can occur when the model is trained on a new distribution and the model weights change drastically. Different strategies have been suggested to solve the problem of catastrophic forgetting in CL. This abstract discusses the integration of pre-training and replay-based continual learning methods to enhance test case prioritization. Pre-trainingbased continual learning leverages the strong representation of pre-training models on a large dataset. This approach helps initialize the model with a broad understanding which can be further incrementally trained to accommodate new tasks without significant performance loss on previous tasks. The dataset we obtained from IBM has a few years of test execution data for the CI and VCS. The model can be trained using a large volume of data for the pre-training method. Replay-based continual learning however involves retaining a small buffer of old training samples. This strategy includes a small fraction of old samples with a new dataset while incrementally training the model enabling it to maintain its performance on older tasks by reinforcing the previous learning. Integrating pre-training and replay-based methods is most effective in the literature [3]. Pre-training provides a solid foundation for generic knowledge replay-based methods complement this by continuously reinforcing past learning ensuring that the adaptation to new tasks does not come at the expense of previously acquired knowledge. Several design choices leverage the benefits of this combined method. The frequency of incremental training on new datasets is an important design decision. This frequency can be timedriven or property-driven. Experimental work will guide the decision on incremental training frequency. Next in replay-based approaches the memory buffer size number of old samples and criteria for old sample selection are some of the decision parameters. In addition a small buffer memory requires effective management in terms of data-retaining strategies. The empirical evidence supports the effectiveness of this integrated approach. Hu et al. [4] introduced prioritized experience replay in continual learning emphasizing the selection of representative experiences to alleviate catastrophic forgetting. Similarly Merlin et al. [5] provided practical recommendations for replay-based continual learning methods highlighting the importance of memory size and data augmentation in enhancing the performance. We will conduct detailed investigations to determine the optimal values for these decision parameters. For time-based frequency we will experiment at different intervals such as weekly every ten or 15 days monthly three months and six months of incremental training. Property-based choices can be new test suite additions significant changes in test suites and an increase or decrease in the test case failure rate. Similarly for the replay-based method samples can be selected from each incremental training dataset the selection can be random or property-based. For example an even distribution of passed or failed samples could be selected to avoid overfitting. In conclusion integrating pretraining and replay-based continual learning methods presents a promising research direction for enhancing large-scale test case prioritization in CI. Future research should explore different strategies to maximize the benefits of continual learning in test case prioritization.;
2007 International Joint Conference on Neural Networks;Much of the current research in software defect prediction focuses on building classifiers to predict only whether a software module is fault-prone or not. Using these techniques the effort to test the software is directed at modules that are labelled as fault-prone by the classifier. This paper introduces a novel algorithm based on constructive RBF neural networks aimed at predicting the probability of errors in fault-prone modules it is called RBF-DDA with Probabilistic Outputs and is an extension of RBF-DDA neural networks. The advantage of our method is that we can inform the test team of the probability of defect in a module instead of indicating only if the module is fault-prone or not. Experiments carried out with static code measures from well-known software defect datasets from NASA show the effectiveness of the proposed method. We also compared the performance of the proposed method in software defect prediction with kNN and two of its variants the S-POC-NN and R-POC-NN. The experimental results showed that the proposed method outperforms both S-POC-NN and R-POC-NN and that it is equivalent to kNN in terms of performance with the advantage of producing less complex classifiers.;
2018 International Conference on Recent Innovations in Electrical Electronics & Communication Engineering (ICRIEECE);Components that have defects after release but not during testing are very undesirable as they point to `holes' in the testing process. In this work the main objective is to provide a relation between pre-release & post-release defects. This work describes the initial effort of building analysis for defects in system testing carried out by an independent testing team. The motivation to have such correlation analysis in software defects is to serve as an early quality indicator of the software entering system testing and assist the testing team to manage and control test execution activities. Dataset is analysed with curve fitting methods & then sets are validated using correlation methods. After this different performance parameters are calculated using probabilistic analysis tools.;
2022 International Conference on Machine Learning Big Data Cloud and Parallel Computing (COM-IT-CON);The amount of information on web is expanding as the client of the web develops. Presently Software is sufficiently skilled to replace all that requires human intervention or presence. SDLC (Software Defect LifeCycle) is process that is continued in fostering the Software which contains thorough testing. To try not to sit around and exertion on Bugs Software Bug Prediction plays a pivotal part in the beginning stage of improvement in keeping up with and fostering the great nature of Software. Programming Bug Prediction worries with by and large accomplishment as early programming expectation can work on the quality dependability proficiency decreased cost of Software. We have used different AI approaches on NASA dataset and contrasted them and as of late presented calculation called Catboost. The results achieved when contrasted and other approaches CatBoost method rout them for all dataset.;
A Learning-to-Rank Approach to Software Defect Prediction;Software defect prediction can help to allocate testing resources efficiently through ranking software modules according to their defects. Existing software defect prediction models that are optimized to predict explicitly the number of defects in a software module might fail to give an accurate order because it is very difficult to predict the exact number of defects in a software module due to noisy data. This paper introduces a learning-to-rank approach to construct software defect prediction models by directly optimizing the ranking performance. In this paper we build on our previous work and further study whether the idea of directly optimizing the model performance measure can benefit software defect prediction model construction. The work includes two aspects: one is a novel application of the learning-to-rank approach to real-world data sets for software defect prediction and the other is a comprehensive evaluation and comparison of the learning-to-rank method against other algorithms that have been used for predicting the order of software modules according to the predicted number of defects. Our empirical studies demonstrate the effectiveness of directly optimizing the model performance measure for the learning-to-rank approach to construct defect prediction models for the ranking task.;
2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS);Predicting the number of defects in a project is critical for project test managers to allocate budget resources and schedule for testing support and maintenance efforts. Software Defect Prediction models predict the number of defects in given projects after training the model with historical defect related information. The majority of defect prediction studies focused on predicting defect-prone modules from methods and class-level static information whereas this study predicts defects from project-level information based on a cross-company project dataset. This study utilizes software sizing metrics effort metrics and defect density information and focuses on developing defect prediction models that apply various machine learning algorithms. One notable issue in existing defect prediction studies is the lack of transparency in the developed models. Consequently the explain-ability of the developed model has been demonstrated using the state-of-the-art post-hoc model-agnostic method called Shapley Additive exPlanations (SHAP). Finally important features for predicting defects from cross-company project information were identified.;
2012 34th International Conference on Software Engineering (ICSE);There are more bugs in real-world programs than human programmers can realistically address. This paper evaluates two research questions: â€œWhat fraction of bugs can be repaired automatically?â€ and â€œHow much does it cost to repair a bug automatically?â€ In previous work we presented GenProg which uses genetic programming to repair defects in off-the-shelf C programs. To answer these questions we: (1) propose novel algorithmic improvements to GenProg that allow it to scale to large programs and find repairs 68% more often (2) exploit GenProg's inherent parallelism using cloud computing resources to provide grounded human-competitive cost measurements and (3) generate a large indicative benchmark set to use for systematic evaluations. We evaluate GenProg on 105 defects from 8 open-source programs totaling 5.1 million lines of code and involving 10193 test cases. GenProg automatically repairs 55 of those 105 defects. To our knowledge this evaluation is the largest available of its kind and is often two orders of magnitude larger than previous work in terms of code or test suite size or defect count. Public cloud computing prices allow our 105 runs to be reproduced for $403 a successful repair completes in 96 minutes and costs $7.32 on average.;
2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC);This paper focuses on the digital innovation brought about by the advancement of ICT technology in the healthcare field. In particular the introduction of cutting-edge technologies such as AI are contributing to the improvement of health care services but at the same time the risk of cybersecurity threats and software security problems in medical devices are emerging as well. Therefore the importance of SBOM (Software Bill of Materials) to respond to such problems has now been emphasized and this paper focuses on strengthening the cybersecurity of medical devices through the creation and application of SBOM. This study develops an AI-based software defect detection method and seeks to ensure the reliability and safety of medical devices by proposing an efficient method compared to existing rule-based approaches. This study aims to contribute to strengthening security by detecting flaws in medical devices through AI and establishing a technical foundation for providing ultimate quality healthcare services.;
2011 18th Asia-Pacific Software Engineering Conference;Defect tracking systems such as Bugzilla and JIRA and source code version control systems such as CVS and SVN are widely used applications to support software development and maintenance activities. Previous studies show that bug databases and version databases are often used as standalone and separate repositories without explicit linkages between issue reports and corresponding commit transactions. This is because developers often do not explicitly mention or tag commit transactions with the relevant bug report IDs. The lack of explicit links between these two databases has been identified as a serious process data quality issue (incomplete and biased data) having implications in predictive model building (such as defect density and error proneness computation) and hypothesis-testing based on the dataset. Researchers have proposed solutions to link the two databases and performed experiments on open source projects such as Fire Fox Mozilla. We review previous approaches and propose a novel technique (based on Fellegi-Sunter (FS) Model for record linkages) to automatically integrate the two databases that overcomes some of the drawbacks of traditional methods. We validate the proposed approach by performing experiments on publicly available bug and version dataset obtained from two open-source projects (Apache HTTP Server and WikiMedia). The results of our experiments demonstrate that the proposed solution is effective in recovering trace ability links (missing links) between bug-fixing commits and corresponding bug reports.;
Researcher Bias: The Use of Machine Learning in Software Defect Prediction;Background. The ability to predict defect-prone software components would be valuable. Consequently there have been many empirical studies to evaluate the performance of different techniques endeavouring to accomplish this effectively. However no one technique dominates and so designing a reliable defect prediction model remains problematic. Objective. We seek to make sense of the many conflicting experimental results and understand which factors have the largest effect onpredictive performance. Method. We conduct a meta-analysis of all relevant high quality primary studies of defect prediction to determine what factors influence predictive performance. This is based on 42 primary studies that satisfy our inclusion criteria that collectively report 600 sets of empirical prediction results. By reverse engineering a common response variable we build arandom effects ANOVA model to examine the relative contribution of four model building factors (classifier data set input metrics and researcher group) to model prediction performance. Results. Surprisingly we find that the choice of classifier has little impact upon performance (1.3 percent) and in contrast the major (31 percent) explanatory factor is the researcher group. It matters more who does the work than what is done. Conclusion.  To overcome this high level of researcher bias defect prediction researchers should (i) conduct blind analysis (ii) improve reporting protocols and (iii) conduct more intergroup studies in order to alleviate expertise issues. Lastly research is required to determine whether this bias is prevalent in other applications domains.;
2019 IEEE/ACM 12th International Workshop on Search-Based Software Testing (SBST);EvoSuite is a search-based tool that automatically generates executable unit tests for Java code (JUnit tests). This paper summarises the results and experiences of EvoSuite's participation at the seventh unit testing competition at SBST 2019 where EvoSuite achieved the highest overall score (255.43 points) for the sixth time in seven editions of the competition.;
15th International Symposium on Software Reliability Engineering;Bugs in software are costly and difficult to find and fix. In recent years many tools and techniques have been developed for automatically finding bugs by analyzing source code or intermediate code statically (at compile time). Different tools and techniques have different tradeoffs but the practical impact of these tradeoffs is not well understood. In this paper we apply five bug finding tools specifically Bandera ESC/Java 2 FindBugs JLint and PMD to a variety of Java programs. By using a variety of tools we are able to cross-check their bug reports and warnings. Our experimental results show that none of the tools strictly subsumes another and indeed the tools often find nonoverlapping bugs. We discuss the techniques each of the tools is based on and we suggest how particular techniques affect the output of the tools. Finally we propose a meta-tool that combines the output of the tools together looking for particular lines of code methods and classes that many tools warn about.;
TENCON 2023 - 2023 IEEE Region 10 Conference (TENCON);Software testing is a crucial component of software development. With the increasing complexity of software systems traditional manual testing methods are becoming less feasible. Artificial Intelligence (AI) has emerged as a promising approach to software testing in recent years. This review paper aims to provide an in-depth understanding of the current state of software testing using AI. The review will examine the various approaches techniques and tools used in this area and assess their effectiveness. The selected articles for this study have been extracted from different research databases using the advanced search string strategy. Initially 40 articles have been extracted from different research libraries. After gradual filtering finally 20 articles have been selected for the study. After studying all the selected papers we find that various testing tasks can be automated successfully using AI (Machine Learning and Deep Learning) such as Test Case Generation Defect Prediction Test Case Prioritization Metamorphic Testing Android Testing Test Case Validation and White Box Testing. This study also finds that the integration of AI in software testing is making software testing activities easier along with better performance. This literature review paper provides a thorough analysis of the impact AI can have on the software testing process.;
10th International Symposium on Software Metrics 2004. Proceedings.;Software measurement data is often used to model software quality classification models. Related literature has focussed on developing new classification techniques and schemes with the aim of improving classification accuracy. However the quality of software measurement data used to build such classification models plays a critical role in their accuracy and usefulness. We present empirical case studies which demonstrate that despite using a very large number of diverse classification techniques for building software quality classification models the classification accuracy does not show a dramatic improvement. For example a simple lines-of-code based classification performs comparatively to some other more advanced classification techniques such as neural networks decision trees and case-based reasoning. Case studies of the NASA JM1 and KC2 software measurement datasets (obtained through the NASA Metrics Data Program) are presented. Some possible reasons that affect the quality of a software measurement dataset include presence of data noise errors due to improper software data collection exclusion of software metrics that are better representative software quality indicators and improper recording of software fault data. This study shows through an empirical study that instead of searching for a classification technique that perform well for given software measurement dataset the software quality and development teams should focus on improving the quality of the software measurement dataset.;
PerfJIT: Test-Level Just-in-Time Prediction for Performance Regression Introducing Commits;Performance issues may compromise user experiences increase the cost resources and cause field failures. One of the most prevalent performance issues is performance regression. Due to the importance and challenges in performance regression detection prior research proposes various automated approaches that detect performance regressions. However the performance regression detection is conducted after the system is built and deployed. Hence large amounts of resources are still required to locate and fix performance regressions. In our paper we propose an approach that automatically predicts whether a test would manifest performance regressions given a code commit. In particular we extract both traditional metrics and performance-related metrics from the code changes that are associated with each test. For each commit we build random forest classifiers that are trained from all prior commits to predict in this commit whether each test would manifest performance regression. We conduct case studies on three open-source systems (Hadoop Cassandra and OpenJPA). Our results show that our approach can predict tests that manifest performance regressions in a commit with high AUC values (on average 0.86). Our approach can drastically reduce the testing time needed to detect performance regressions. In addition we find that our approach could be used to detect the introduction of six out of nine real-life performance issues from the subject systems during our studied period. Finally we find that traditional metrics that are associated with size and code change histories are the most important factors in our models. Our approach and the study results can be leveraged by practitioners to effectively cope with performance regressions in a timely and proactive manner.;
Metric-Based Fault Prediction for Spreadsheets;Electronic spreadsheets are widely used in organizations for various data analytics and decision-making tasks. Even though faults within such spreadsheets are common and can have significant negative consequences today's tools for creating and handling spreadsheets provide limited support for fault detection localization and repair. Being able to predict whether a certain part of a spreadsheet is faulty or not is often central for the implementation of such supporting functionality. In this work we propose a novel approach to fault prediction in spreadsheet formulas which combines an extensive catalog of spreadsheet metrics with modern machine learning algorithms. An analysis of the individual metrics from our catalog reveals that they are generally suited to discover a wide range of faults. Their predictive power is however limited when considered in isolation. Therefore in our approach we apply supervised learning algorithms to obtain fault predictors that utilize all data provided by multiple spreadsheet metrics from our catalog. Experiments on different datasets containing faulty spreadsheets show that particularly Random Forests classifiers are often effective. As a result the proposed method is in many cases able to make highly accurate predictions whether a given formula of a spreadsheet is faulty.11.Results of a preliminary study were published in [1] .;
2009 2nd International Conference on Power Electronics and Intelligent Transportation System (PEITS);Effective prediction of the fault-proneness plays a very important role in the analysis of software quality and balance of software cost and it also is an important problem of software engineering. Importance of software quality is increasing leading to development of new sophisticated techniques which can be used in constructing models for predicting quality attributes. In this paper we use fuzzy c-means clustering (FCM) and radial basis function neural network (RBFNN) to construct prediction model of the fault-proneness RBFNN is used as a classificatory and FCM is as a cluster. Object-oriented software metrics are as input variables of fault prediction model. Experiments results confirm that designed model is very effective for predicting a class's fault-proneness it has a high accuracy and its implementation requires neither extra cost nor expert's knowledge. It also is automated. Therefore proposed model was very useful in predicting software quality and classing the fault-proneness.;
2021 IEEE International Conference on Software Analysis Evolution and Reengineering (SANER);Identifying defective software components as early as their commit helps to reduce significant software development and maintenance costs. In recent years several studies propose to use just-in-time (JIT) defect prediction techniques to identify changes that could introduce defects at check-in time. To predict defect introducing changes JIT defect prediction approaches use change metrics collected from software repositories. These change metrics however capture code and code change related information. Information related to the change requests (e.g. clarity of change request and difficulty to implement the change) that could determine the changeâ€™s proneness to introducing new defects are not studied. In this study we propose to augment the publicly available change metrics dataset with six change request- based metrics collected from issue tracking systems. To build the prediction model we used five machine learning algorithms: AdaBoost XGBoost Deep Neural Network Random Forest and Logistic Regression. The proposed approach is evaluated using a dataset collected from four open source software systems i.e. Eclipse platform Eclipse JDT Bugzilla and Mozilla. The results show that the augmented dataset improves the performance of JIT defect prediction in 19 out of 20 cases. F1-score of JIT defect prediction in the four systems is improved by an average of 4.8% 3.4% 1.7% 1.1% and 1.1% while using AdaBoost XGBoost Deep Neural Network Random Forest and Logistic Regression respectively.;
2014 International Conference on Service Sciences;Cloud-management infrastructure plays an important role as a part of cloud computing stacks serving as the resource manager of cloud platforms. The complexity of cloud-management infrastructure makes its high availability (HA) one of the most critical requirements. Various technologies have been developed to increase the reliability and availability of cloud management infrastructure however little work focused on quantitative analysis of its availability. In this paper we designed a new availability benchmarking method for cloud management infrastructure. By using our measurement method a private cloud customer or public cloud provider can estimate the availability of deployment of its cloud management stack. We have evaluated our method on Open Stack cloud infrastructure. We show that with various HA technologies and configurations the availability of the cloud management infrastructure can be greatly different.;
2019 5th International Conference on Signal Processing Computing and Control (ISPCC);Development of high-quality software is very much essential now-a-days. Prediction of good quality software in the early phase during the development reduces the cost of the testing resources. Various data mining and machine learning algorithms are developed to predict the quality of the software. In the real-life scenarios while dealing with software modules many of the time the underline datasets are imbalanced. In order to increase the efficiency of the prediction or classification algorithms balancing algorithms are implemented as a preprocessing stage before the prediction phase. In this paper we conduct extensive experiments to explore the effect of imbalance learning including undersampling oversampling and hybrid methods and its interaction with different types of classifiers on various projects. We evaluate six imbalance learning methods with six classifiers on 12 data sets. The imbalance learning methods used are Random Oversampling (ROS) Random under-sampling SMOTE TOMEK SMOTE+TOMEK and SMOTE+ENN. This study reveals that the appropriate combination of imbalanced method and classifier can improve the accuracy of software fault prediction models.;
2010 IEEE/IFIP International Conference on Dependable Systems & Networks (DSN);Despite of the existence of several techniques for emulating software faults there are still open issues regarding representativeness of the faults being injected. An important aspect not considered by existing techniques is the non-trivial activation condition (trigger) of real faults which causes them to elude testing and remain hidden until operation. In this paper we investigate how the representativeness of injected software faults can be improved regarding the representativeness of triggers by proposing a set of generic criteria to select representative faults from afaultload. We used the G-SWFIT technique to inject software faults in a DBMS resulting in over 40 thousands faults and 2 million runs of a real test suite. We analyzed faults with respect to their triggers and concluded that a non-negligible share (15%) would not realistically elude testing. Our proposed criteria decreased the percentage of non-elusive faults in the faultload improving its representativeness.;
Strider: Signal Value Transition-Guided Defect Repair for HDL Programming Assignments;Hardware description languages (HDLs) are pivotal for the development of hardware designs. The programming courses for HDLs are also popular in both universities and online course platforms. Similar to programming assignments of software languages (SLs) these of HDLs also actively call for automated program repair (APR) techniques to provide personalized feedback for students. However the research of APR techniques targeting HDL programming assignments is still in an early stage. Due to the significantly different programming mechanism of HDLs from SLs the only APR technique (i.e. CirFix) targeting HDL programming assignments contributes a customized repair pipeline. However the fundamental challenges in the design of HDL-oriented fault localization and patch generation still remain unresolved. In this work we propose a signal value transition-guided defect repair technique named Strider by capturing the intrinsic features of HDLs. This technique consists of a time-aware dynamic defect localization approach to precisely localize defects and a signal value transition-guided patch synthesis approach to effectively generate fixes. We further construct a dataset of 57 real defects from HDL programming assignments for tool evaluation. The evaluation reveals the overfitting issue of the pioneering tool CirFix and the significant improvement of Strider over CirFix in terms of both effectiveness and efficiency. In particular Strider is more effective by correctly fixing  $2.3\times $  as many defects as CirFix in the real defect dataset and is  $23\times $  more efficient by generating a correct fix within 5 min on average in the synthetic defect dataset while CirFix takes around 2 h on average.;
BL-GAN: Semi-Supervised Bug Localization via Generative Adversarial Network;Various automated bug localization technologies have recently emerged that require adequate bug-fix records available to train a predictive model. However many projects in practice might not provide these necessities especially for new projects in the first release due to the expensive human effort for constructing a large amount of bug-fix records. Aiming to capture the potential relevance distribution between the bug report and code file from a limited number of available bug-fix records we present the first semi-supervised bug localization model named BL-GAN in this paper. For this purpose the promising Generative Adversarial Network is introduced in BL-GAN in which synthetic bug-fix records close to the real ones are constructed by searching the project directory tree to generate file paths instead of traversing the contents of all code files. For processing bug reports the proposed BL-GAN adopts an attention-based Transformer architecture to capture semantic and sequence information. In order to capture the proprietary structural information in code files BL-GAN incorporates a novel multilayer Graph Convolutional Network to process the source code in a graphical view. Extensive experiments on large-scale real-world datasets reveal that our model BL-GAN significantly outperforms the state-of-the-art on all evaluation measures.;
2018 3rd International Conference on Contemporary Computing and Informatics (IC3I);In present days quality software has become a necessity in almost all line of work. But on the other hand defective software system gives undesired products resulting in user dissatisfaction as well as huge hike in development and maintenance cost. That's why an accurate prediction of defect prone areas is needed for reducing development and maintenance cost. From various research work already undertaken in this field it has been observed that basically due to two problems such as imbalance in class distribution and irrelevant attributes present in high dimensional datasets the prediction performance of classification techniques are below the desired level and inaccurate. For solving these problems a model has been proposed by integrating Sampling Methods (SM) such as Random Under Sampling method Synthetic Minority Over Sampling Technique for random over sampling with Nonlinear Manifold Detection Techniques (Nonlinear MDTs) like ISOMAP FASTMVU and Diffusion Maps for evaluating the impact of this integrated model on prediction performance of classifiers. The statistical results obtained after conducting Friedman test validated that integrated model SMOTE with Nonlinear MDTs used on Bayesian Belief Network classifier showed significantly different and accurate prediction performance than other methods for all high dimensional software datasets.;
2006 5th IEEE International Conference on Cognitive Informatics;Improving the quality of software products is one of the principal objectives of software engineering. Software metrics are the key tool in software quality management. In this paper we propose to use naive Bayes and RIPPER for software quality classification and use random projection to improve the performance of classifiers. Feature extraction via random projection has attracted considerable attention in recent years. The approach has interesting theoretical underpinnings and offers computational advantages. Results on benchmark dataset MIS using Accuracy and Recall as performance measures indicate that random projection can improve the classification performance of all four learners we investigate: Naive Bayes RIPPER MLP and IB1. With the help of random projection naive Bayes and RIPPER are better than MLP and IB1 in finding fault-high software modules which can be sought as potentially highly faulty modules where most of our testing and maintenance effort should be focused;
2022 3rd International Conference on Computer Science and Management Technology (ICCSMT);The field of software engineering data mining has become increasingly interested in cross-project defect prediction (CPDP) which uses defect codes from other projects to develop prediction models addressing the problem of insufficient data in the model construction process. However the source and target projects usually have large differences in data distribution which reduces the prediction performance. Based on the learning idea of instance migration the distribution of target project features is changed to be close to the distribution of source project features thus improving the performance of cross-project defect prediction. Specifically the cross-project software defect prediction is investigated by combining software metric features with instance migration methods. First we analyze the difficulty of class imbalance in the training set and extract features from the instances in the training set. Then the idea of improved AdaBoost is proposed. Finally the algorithm based on instance migration is proposed and experimented and the result analysis shows the effectiveness and feasibility of the method.;
2017 IEEE International Conference on Software Quality Reliability and Security Companion (QRS-C);This paper proposes a conceptual performance-based ranking framework that prioritises the output of multiple Static Analysis Tools to improve the tool effectiveness and usefulness. The framework weights the performance of Static Analysis Tools per defect type and cross-validates the findings between different Static Analysis Tools' reports. An initial validation shows the potential benefits of the proposed framework.;
2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE);Quality of a software component can be measured in terms of fault proneness of data. Quality estimations are made using fault proneness data available from previously developed similar type of projects and the training data consisting of software measurements. To predict faulty modules in software data different techniques have been proposed which includes statistical method machine learning methods neural network techniques and clustering techniques. Predicting faults early in the software life cycle can be used to improve software process control and achieve high software reliability. The aim of proposed approach is to investigate that whether metrics available in the early lifecycle (i.e. requirement metrics) metrics available in the late lifecycle (i.e. code metrics) and metrics available in the early lifecycle (i.e. requirement metrics) combined with metrics available in the late lifecycle (i.e. code metrics) can be used to identify fault prone modules using decision tree based Model in combination of K-means clustering as preprocessing technique. This approach has been tested with CM1 real time defect datasets of NASA software projects. The high accuracy of testing results show that the proposed Model can be used for the prediction of the fault proneness of software modules early in the software life cycle.;
Eighth IEEE International High-Level Design Validation and Test Workshop;It is now common for design teams to develop systems where hardware and software components cooperate they are thus facing the challenging task of validating and testing systems where hardware and software parts exist. In this paper a high-level test generation approach is presented which is able to produce input stimuli that can be fruitfully exploited for test and validation purposes of both hardware and software components. Experimental results are reported showing that the proposed approach produces high quality vectors in terms of the adopted metrics for hardware and software faults.;
2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion);As Deep Learning (DL) is continuously adopted in many safety critical applications its quality and reliability start to raise concerns. Similar to the traditional software development process testing the DL software to uncover its defects at an early stage is an effective way to reduce risks after deployment. Although recent progress has been made in designing novel testing techniques for DL software the distribution of generated test data is not taken into consideration. It is therefore hard to judge whether the identified errors are indeed meaningful errors to the DL application. Therefore we propose a new distribution aware testing technique which aims to generate new unseen test cases relevant to the underlying DL system task. Our results show that this technique is able to filter up to 55.44% of error test case on CIFAR-10 and is 10.05% more effective in enhancing robustness.;
2018 7th Brazilian Conference on Intelligent Systems (BRACIS);Various software metrics and statistical models have been developed to help companies to predict software defects. Traditional software defect prediction approaches use historical data about previous bugs on a project in order to build predictive machine learning models. However in many cases the historical testing data available in a project is scarce i.e. very few or even no labeled training instances are available which will result on a low quality defect prediction model. In order to overcome this limitation Cross-Project Defect Prediction (CPDP) can be adopted to learn a defect prediction model for a project of interest (i.e. a target project) by reusing (transferring) data collected from several previous projects (i.e. source projects). In this paper we focused on neighborhood-based instance selection techniques for CPDP which select labeled instances in the source projects that are similar to the unlabeled instances available in the target project. Despite its simplicity these techniques have limitations which were addressed in our work. First although they can select representative source instances the quality of the selected instances is usually not addressed. Additionally bug prediction datasets are normally unbalanced (i.e. there are more nondefect instances than defect ones) which can harm learning performance. In this paper we proposed a new transfer learning approach for CPDP in which instances selected by a neighborhood-based technique are filtered by the Fuzzy-Rough Instance Selection (FRIS) technique in order to remove noisy instances in the training set. Following in order to solve class balancing problems the Synthetic Minority Oversampling Technique (SMOTE) technique is adopted to oversample the minority (defect-prone) class thus increasing the chance of finding bugs correctly. Experiments were performed on a benchmark set of Java projects achieving promising results.;
Automated System-Level Regression Test Prioritization in a Nutshell;Westermo Research and Development has developed SuiteBuilder an automated tool to determine an effective ordering of regression test cases. The ordering is based on factors such as fault detection success the interval since the last execution and code modifications. SuiteBuilder has enabled Westermo to overcome numerous regression-testing problems including lack of time to run a complete regression suite failure to detect bugs in a timely manner and repeatedly omitted tests. In the tool's first two years of use reordered test suites finished in the available time most fault-detecting test cases were located in the first third of suites no important test case was omitted and the necessity for manual work on the suites decreased greatly.;
2015 IEEE International Conference on Software Maintenance and Evolution (ICSME);Developers often take much time and effort to find buggy program elements. To help developers debug many past studies have proposed spectrum-based fault localization techniques. These techniques compare and contrast correct and faulty execution traces and highlight suspicious program elements. In this work we propose constrained feature selection algorithms that we use to localize faults. Feature selection algorithms are commonly used to identify important features that are helpful for a classification task. By mapping an execution trace to a classification instance and a program element to a feature we can transform fault localization to the feature selection problem. Unfortunately existing feature selection algorithms do not perform too well and we extend its performance by adding a constraint to the feature selection formulation based on a specific characteristic of the fault localization problem. We have performed experiments on a popular benchmark containing 154 faulty versions from 8 programs and demonstrate that several variants of our approach can outperform many fault localization techniques proposed in the literature. Using Wilcoxon rank-sum test and Cliff's d effect size we also show that the improvements are both statistically significant and substantial.;
